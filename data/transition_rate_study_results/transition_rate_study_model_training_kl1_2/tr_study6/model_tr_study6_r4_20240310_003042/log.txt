Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r4', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r4', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3125475209

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.210793745164885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.210793745164885 | validation: 9.784280866742026]
	TIME [epoch: 105 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.061964560067931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.061964560067931 | validation: 9.123035849590106]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.873311022041385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.873311022041385 | validation: 8.83601817632364]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.399268436013875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.399268436013875 | validation: 8.553313964402866]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.14943202502013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.14943202502013 | validation: 8.377131522078022]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.947718394772798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.947718394772798 | validation: 8.23778039319313]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.865174443198888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.865174443198888 | validation: 8.096809468765334]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.548134933708838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.548134933708838 | validation: 7.812359817388794]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.869971856137443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.869971856137443 | validation: 6.361078752697194]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.943052113391159		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.943052113391159 | validation: 5.636437753567525]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.083744528763301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.083744528763301 | validation: 4.785332511510529]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.385168115708431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.385168115708431 | validation: 4.1146396275212025]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6517788838210885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6517788838210885 | validation: 4.029466743817519]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8938692443806437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8938692443806437 | validation: 3.7728405729735313]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9795865411304128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9795865411304128 | validation: 4.332504410933047]
	TIME [epoch: 27.7 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8253895936490125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8253895936490125 | validation: 3.678829924497468]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.57379537667362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.57379537667362 | validation: 3.6165286155363696]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.866477995742649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.866477995742649 | validation: 3.5174987958484714]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6530376987292126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6530376987292126 | validation: 3.5227062247512175]
	TIME [epoch: 27.7 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.371552575756428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.371552575756428 | validation: 3.466643170299858]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.295976282474606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.295976282474606 | validation: 3.5144767959550074]
	TIME [epoch: 27.6 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.529765907802286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.529765907802286 | validation: 3.35264332566547]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1055870660023617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1055870660023617 | validation: 4.188523063151124]
	TIME [epoch: 27.6 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5718253444665145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5718253444665145 | validation: 3.4416829734244607]
	TIME [epoch: 27.6 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.393615146399686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.393615146399686 | validation: 3.594829432336945]
	TIME [epoch: 27.6 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2184030414044487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2184030414044487 | validation: 3.044036947723182]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9870228686039515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9870228686039515 | validation: 3.004250090378532]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.103750197573146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.103750197573146 | validation: 3.4596137856169906]
	TIME [epoch: 27.6 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1608681676327013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1608681676327013 | validation: 2.7574352503644275]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.857329212554765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.857329212554765 | validation: 3.3701837472675855]
	TIME [epoch: 27.6 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8617080085734115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8617080085734115 | validation: 2.724874708527101]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9039766465305368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9039766465305368 | validation: 2.6831999741303423]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1237570701118633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1237570701118633 | validation: 3.378860964482093]
	TIME [epoch: 27.7 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.973924129541059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.973924129541059 | validation: 4.045424102176076]
	TIME [epoch: 27.7 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.454396868795376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.454396868795376 | validation: 3.595896405106284]
	TIME [epoch: 27.7 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.06964717826197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.06964717826197 | validation: 4.4320912887975075]
	TIME [epoch: 27.7 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0900163718110445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0900163718110445 | validation: 3.4763128725192165]
	TIME [epoch: 27.6 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2571429747304776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2571429747304776 | validation: 2.4644825882691266]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4042388548780003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4042388548780003 | validation: 2.7336234209109573]
	TIME [epoch: 27.7 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.419287397194561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.419287397194561 | validation: 2.234716053175047]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3853614896887807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3853614896887807 | validation: 2.1934132455420134]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6919198323329026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6919198323329026 | validation: 3.068305528314712]
	TIME [epoch: 27.7 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.795575565454369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.795575565454369 | validation: 2.7276670600638266]
	TIME [epoch: 27.7 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.336170764366991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.336170764366991 | validation: 2.8517373369443306]
	TIME [epoch: 27.7 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.586485500750869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.586485500750869 | validation: 2.3471697698654737]
	TIME [epoch: 27.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4640436982423735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4640436982423735 | validation: 3.3519967465110314]
	TIME [epoch: 27.7 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6654200219010504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6654200219010504 | validation: 4.090114178366402]
	TIME [epoch: 27.7 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.106841228648874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.106841228648874 | validation: 4.045166641347006]
	TIME [epoch: 27.7 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.32879954394541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.32879954394541 | validation: 3.836641508837971]
	TIME [epoch: 27.7 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4043953070873165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4043953070873165 | validation: 4.023491830572458]
	TIME [epoch: 27.7 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.435791149588737		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.435791149588737 | validation: 2.4733553936400017]
	TIME [epoch: 27.7 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0983509060351917		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.0983509060351917 | validation: 4.301148228835017]
	TIME [epoch: 27.7 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.181784651669485		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.181784651669485 | validation: 2.4590020941327855]
	TIME [epoch: 27.7 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5166860591722067		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.5166860591722067 | validation: 3.0110815553871637]
	TIME [epoch: 27.7 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.474929567920446		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.474929567920446 | validation: 3.357700925859548]
	TIME [epoch: 27.7 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4531195073483145		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.4531195073483145 | validation: 4.2097644162018435]
	TIME [epoch: 27.7 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5385848909377313		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.5385848909377313 | validation: 4.306944533789111]
	TIME [epoch: 27.6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8629570258178774		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.8629570258178774 | validation: 2.71519695376036]
	TIME [epoch: 27.7 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.796365742181517		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.796365742181517 | validation: 3.502102690852256]
	TIME [epoch: 27.7 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1522476339529346		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.1522476339529346 | validation: 3.0556336533840445]
	TIME [epoch: 27.6 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5851274784209384		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.5851274784209384 | validation: 5.597488171607207]
	TIME [epoch: 27.7 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.550928685026359		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.550928685026359 | validation: 3.2520920313690693]
	TIME [epoch: 27.7 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.126100325661409		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.126100325661409 | validation: 2.5243045383989617]
	TIME [epoch: 27.7 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0082515359898427		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.0082515359898427 | validation: 3.384999845293146]
	TIME [epoch: 27.7 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2163365320678965		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 4.2163365320678965 | validation: 3.200630091667674]
	TIME [epoch: 27.7 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9406113507528095		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.9406113507528095 | validation: 2.8902038104377494]
	TIME [epoch: 27.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.27924454259831		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.27924454259831 | validation: 2.8099249892418605]
	TIME [epoch: 27.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.780339176844923		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.780339176844923 | validation: 3.1728891961373957]
	TIME [epoch: 27.7 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0522299089673486		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.0522299089673486 | validation: 2.777440195536766]
	TIME [epoch: 27.7 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4762913948562564		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.4762913948562564 | validation: 2.209880087988777]
	TIME [epoch: 27.7 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2497106938624394		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.2497106938624394 | validation: 2.341075408934395]
	TIME [epoch: 27.7 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3478737996396912		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.3478737996396912 | validation: 2.978986482432187]
	TIME [epoch: 27.7 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.150742858764015		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 4.150742858764015 | validation: 5.41874936720442]
	TIME [epoch: 27.7 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.461302618379593		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 5.461302618379593 | validation: 5.924127089511285]
	TIME [epoch: 27.7 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.88159064963944		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 4.88159064963944 | validation: 3.8853535936457155]
	TIME [epoch: 27.7 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7500029434166855		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.7500029434166855 | validation: 4.238415451100304]
	TIME [epoch: 27.6 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.942090768629665		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.942090768629665 | validation: 3.637877276577747]
	TIME [epoch: 27.6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6166002999312816		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.6166002999312816 | validation: 3.731561536136059]
	TIME [epoch: 27.6 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4495070466999245		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.4495070466999245 | validation: 3.481298563589162]
	TIME [epoch: 27.7 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8060753004267207		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.8060753004267207 | validation: 3.993062788720729]
	TIME [epoch: 27.7 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6022032767848637		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.6022032767848637 | validation: 3.786779291065484]
	TIME [epoch: 27.7 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.25723602638458		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.25723602638458 | validation: 2.459993219900469]
	TIME [epoch: 27.7 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4464118656097336		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.4464118656097336 | validation: 2.2133063333470937]
	TIME [epoch: 27.7 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3102188053589847		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.3102188053589847 | validation: 2.2608397765497164]
	TIME [epoch: 27.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1707665842834345		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.1707665842834345 | validation: 1.8598245226395722]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8628343722950593		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.8628343722950593 | validation: 1.8391958205200967]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8114854948042152		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.8114854948042152 | validation: 1.6865819548839904]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.745221552293844		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.745221552293844 | validation: 1.8351638698773474]
	TIME [epoch: 27.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6840445161584352		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.6840445161584352 | validation: 1.9946196068770508]
	TIME [epoch: 27.7 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8162814789255477		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.8162814789255477 | validation: 1.7765897787325866]
	TIME [epoch: 27.6 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6456129863195212		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.6456129863195212 | validation: 1.6768643142737398]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4533843877409403		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.4533843877409403 | validation: 1.4970205155496081]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7073831906395982		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.7073831906395982 | validation: 1.9214954068431522]
	TIME [epoch: 27.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6172086166659858		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.6172086166659858 | validation: 2.5815041790889097]
	TIME [epoch: 27.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7722313518339483		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.7722313518339483 | validation: 1.7597721221944698]
	TIME [epoch: 27.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8073885392493378		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.8073885392493378 | validation: 2.4022549092813517]
	TIME [epoch: 27.6 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.967717579226701		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.967717579226701 | validation: 2.030423839109436]
	TIME [epoch: 27.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6455377817234376		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.6455377817234376 | validation: 1.4708116367872066]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3718994220009253		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.3718994220009253 | validation: 1.370222428951174]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.351479896970413		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.351479896970413 | validation: 1.485468827351469]
	TIME [epoch: 27.6 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3391776321689433		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.3391776321689433 | validation: 1.1021463022495033]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1849000840463773		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.1849000840463773 | validation: 1.41874612247811]
	TIME [epoch: 27.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2854076907775414		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.2854076907775414 | validation: 1.3318535951006905]
	TIME [epoch: 27.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1562662872322624		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.1562662872322624 | validation: 1.0324449459354454]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1542081837891254		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.1542081837891254 | validation: 1.1680432310299087]
	TIME [epoch: 27.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0350545781405665		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.0350545781405665 | validation: 1.079145915771796]
	TIME [epoch: 27.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0773784678264393		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.0773784678264393 | validation: 1.0157280588520685]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0755831047295614		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.0755831047295614 | validation: 0.8798871091148956]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0941275894857219		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.0941275894857219 | validation: 1.11471701439144]
	TIME [epoch: 27.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0392768054891193		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.0392768054891193 | validation: 1.0036391948249348]
	TIME [epoch: 27.7 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9505397349284581		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.9505397349284581 | validation: 0.7423545048792076]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0008283481752736		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.0008283481752736 | validation: 2.178992481629286]
	TIME [epoch: 27.7 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3241570009555186		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.3241570009555186 | validation: 0.9932478941481455]
	TIME [epoch: 27.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9270846220493898		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.9270846220493898 | validation: 0.7942182005861826]
	TIME [epoch: 27.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0286174798671104		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.0286174798671104 | validation: 1.0020937690477216]
	TIME [epoch: 27.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.103323307891296		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.103323307891296 | validation: 0.8847772127260697]
	TIME [epoch: 27.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9755669600959438		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.9755669600959438 | validation: 0.8293475391814112]
	TIME [epoch: 27.7 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8170551889438763		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.8170551889438763 | validation: 0.7994621864042397]
	TIME [epoch: 27.7 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2031749859963308		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.2031749859963308 | validation: 0.9460322990225525]
	TIME [epoch: 27.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8369747152128713		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.8369747152128713 | validation: 1.025513650840405]
	TIME [epoch: 27.7 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.009399996148526		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.009399996148526 | validation: 0.903947508685345]
	TIME [epoch: 27.7 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8952921867303374		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.8952921867303374 | validation: 1.228380070502604]
	TIME [epoch: 27.7 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.327411597784894		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.327411597784894 | validation: 1.0566327478331567]
	TIME [epoch: 27.7 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9249605961980248		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.9249605961980248 | validation: 1.0115586390040803]
	TIME [epoch: 27.7 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0148265102135976		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.0148265102135976 | validation: 0.9024575080942425]
	TIME [epoch: 27.7 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8599985215078688		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.8599985215078688 | validation: 1.0661790194097152]
	TIME [epoch: 27.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9083017236190531		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.9083017236190531 | validation: 0.7942272785498591]
	TIME [epoch: 27.7 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8109469711281435		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.8109469711281435 | validation: 0.9774990592837898]
	TIME [epoch: 27.7 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8678047438871934		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.8678047438871934 | validation: 0.7692041679576057]
	TIME [epoch: 27.7 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8199951074075695		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.8199951074075695 | validation: 0.7584465716984068]
	TIME [epoch: 27.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8113166472694566		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.8113166472694566 | validation: 1.3598553513991676]
	TIME [epoch: 27.7 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0337313970663564		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.0337313970663564 | validation: 1.0285992565908795]
	TIME [epoch: 27.7 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9503770077660415		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.9503770077660415 | validation: 0.7237121687864527]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7758689706461355		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.7758689706461355 | validation: 0.8105331151336773]
	TIME [epoch: 27.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8501410868487146		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.8501410868487146 | validation: 0.6715506487671]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.739988862078324		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.739988862078324 | validation: 0.6958839057607179]
	TIME [epoch: 27.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.907218171777515		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.907218171777515 | validation: 0.7339453573071032]
	TIME [epoch: 27.7 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0356410899811694		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.0356410899811694 | validation: 1.0263420189765797]
	TIME [epoch: 27.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9128980142258882		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.9128980142258882 | validation: 0.8076394601357677]
	TIME [epoch: 27.7 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8947816797808366		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.8947816797808366 | validation: 0.6874762078685482]
	TIME [epoch: 27.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7437817326020726		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.7437817326020726 | validation: 0.8980213448815861]
	TIME [epoch: 27.7 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8854284715219475		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.8854284715219475 | validation: 1.0539642880513695]
	TIME [epoch: 27.7 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0118486142021503		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.0118486142021503 | validation: 0.8735220001970473]
	TIME [epoch: 27.7 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7673159386650481		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.7673159386650481 | validation: 0.8319360589185454]
	TIME [epoch: 27.7 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7690963058332887		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.7690963058332887 | validation: 0.7796156099470335]
	TIME [epoch: 27.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7327064501979375		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.7327064501979375 | validation: 0.6478993711873858]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7957949371156037		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.7957949371156037 | validation: 0.7229511058706359]
	TIME [epoch: 27.7 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2004943471428215		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.2004943471428215 | validation: 0.94199030229734]
	TIME [epoch: 27.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8685921557350762		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.8685921557350762 | validation: 0.7039866143445787]
	TIME [epoch: 27.7 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7780546780674583		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.7780546780674583 | validation: 0.9979505246939248]
	TIME [epoch: 27.7 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8254563675079072		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.8254563675079072 | validation: 0.6658053525959464]
	TIME [epoch: 27.7 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7169356618499634		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.7169356618499634 | validation: 0.9892953001261208]
	TIME [epoch: 27.7 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3230137018035015		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.3230137018035015 | validation: 0.8571009417444171]
	TIME [epoch: 27.7 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9201787686708847		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.9201787686708847 | validation: 0.9787063640803968]
	TIME [epoch: 27.7 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9004500503679309		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.9004500503679309 | validation: 0.9800725418811312]
	TIME [epoch: 27.7 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0827102506818196		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.0827102506818196 | validation: 1.0833721177523403]
	TIME [epoch: 27.7 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0097067512918412		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.0097067512918412 | validation: 1.1313026341764996]
	TIME [epoch: 27.7 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3865343640774648		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.3865343640774648 | validation: 1.0156977072203262]
	TIME [epoch: 27.7 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9220802682683222		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.9220802682683222 | validation: 0.7789410068505795]
	TIME [epoch: 27.7 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1544295466738537		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.1544295466738537 | validation: 0.6980261261583924]
	TIME [epoch: 27.7 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7983347405288661		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.7983347405288661 | validation: 0.8299086202979816]
	TIME [epoch: 27.7 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8631256386510124		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.8631256386510124 | validation: 1.1482099097918246]
	TIME [epoch: 27.7 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0110541376454736		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.0110541376454736 | validation: 0.8740822835356267]
	TIME [epoch: 27.7 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1308706264328978		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.1308706264328978 | validation: 0.7036946775237126]
	TIME [epoch: 27.7 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7269870798698439		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.7269870798698439 | validation: 0.7609181330011596]
	TIME [epoch: 27.7 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7344117261809764		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.7344117261809764 | validation: 0.8514225334975095]
	TIME [epoch: 27.7 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7288826073766853		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.7288826073766853 | validation: 0.793973659737967]
	TIME [epoch: 27.7 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9345579838511446		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.9345579838511446 | validation: 1.2027015316232441]
	TIME [epoch: 27.7 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0953643262035417		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.0953643262035417 | validation: 0.9020873411053707]
	TIME [epoch: 27.7 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.872201413964921		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.872201413964921 | validation: 0.881145094232516]
	TIME [epoch: 27.7 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.802925293471098		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.802925293471098 | validation: 0.9304254203879547]
	TIME [epoch: 27.7 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8862898978452132		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.8862898978452132 | validation: 0.6838510761279932]
	TIME [epoch: 27.7 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8370614022880034		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.8370614022880034 | validation: 0.7656206486335049]
	TIME [epoch: 27.7 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7593218303407758		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.7593218303407758 | validation: 0.7424669290776484]
	TIME [epoch: 27.7 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7221438156129021		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.7221438156129021 | validation: 0.7260710234987068]
	TIME [epoch: 27.7 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7808775904722334		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.7808775904722334 | validation: 0.9030106772803445]
	TIME [epoch: 27.7 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7731963772730938		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.7731963772730938 | validation: 0.6629279820344942]
	TIME [epoch: 27.7 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6409144275834202		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.6409144275834202 | validation: 0.7889029000985727]
	TIME [epoch: 27.7 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.830939019231208		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.830939019231208 | validation: 0.7531327842970583]
	TIME [epoch: 27.7 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217412452727545		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.7217412452727545 | validation: 0.725235604850159]
	TIME [epoch: 27.7 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7881743124404419		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.7881743124404419 | validation: 1.444719041027845]
	TIME [epoch: 27.7 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0922235763660995		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.0922235763660995 | validation: 0.7747421446834248]
	TIME [epoch: 27.7 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8192536046207722		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.8192536046207722 | validation: 0.9447893014124782]
	TIME [epoch: 27.7 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9444026542845836		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.9444026542845836 | validation: 1.0881820505845277]
	TIME [epoch: 27.7 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7970232280368086		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.7970232280368086 | validation: 0.6698721552103888]
	TIME [epoch: 27.7 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7475496352914228		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.7475496352914228 | validation: 0.7159836879746354]
	TIME [epoch: 27.7 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6894126368222707		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.6894126368222707 | validation: 0.5980060305808433]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0314082100791135		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.0314082100791135 | validation: 1.7252798319432345]
	TIME [epoch: 27.7 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0083783731329703		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 2.0083783731329703 | validation: 1.246416774421394]
	TIME [epoch: 27.7 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9081062367599325		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.9081062367599325 | validation: 0.7117871295793485]
	TIME [epoch: 27.7 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7510530399630464		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.7510530399630464 | validation: 0.7768962996810649]
	TIME [epoch: 27.7 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9111422309630988		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.9111422309630988 | validation: 0.9834755135640697]
	TIME [epoch: 27.7 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.961679621463692		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.961679621463692 | validation: 0.8026691556182811]
	TIME [epoch: 27.7 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8234371587341609		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.8234371587341609 | validation: 0.7980340952991634]
	TIME [epoch: 27.7 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7447838932840256		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.7447838932840256 | validation: 0.587250659986326]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6418166235508117		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.6418166235508117 | validation: 0.6799390828813128]
	TIME [epoch: 27.7 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840736293349582		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.6840736293349582 | validation: 0.6388607964296438]
	TIME [epoch: 27.7 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.61746782236039		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.61746782236039 | validation: 0.6445459132992514]
	TIME [epoch: 27.7 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234557924212498		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.7234557924212498 | validation: 0.7934956661806228]
	TIME [epoch: 27.7 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7158451382505888		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.7158451382505888 | validation: 0.5915898066413854]
	TIME [epoch: 27.7 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6113617035796526		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.6113617035796526 | validation: 0.6397567446565688]
	TIME [epoch: 27.8 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6361223764131221		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.6361223764131221 | validation: 0.552318845620025]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6281122366389489		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.6281122366389489 | validation: 0.8245635993477509]
	TIME [epoch: 27.7 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0877789542804082		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.0877789542804082 | validation: 0.8427492747305706]
	TIME [epoch: 27.7 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7938044380070948		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.7938044380070948 | validation: 0.8060514508420846]
	TIME [epoch: 27.7 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7455509178031992		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.7455509178031992 | validation: 0.8041698720082064]
	TIME [epoch: 27.7 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8962372748933891		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.8962372748933891 | validation: 0.7030632904018669]
	TIME [epoch: 27.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7172971482968141		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.7172971482968141 | validation: 0.6665762837121781]
	TIME [epoch: 27.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6545004551505466		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.6545004551505466 | validation: 0.7773247090891658]
	TIME [epoch: 27.7 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.781283695346304		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.781283695346304 | validation: 0.6467833779175777]
	TIME [epoch: 27.7 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9437597159641948		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.9437597159641948 | validation: 0.9128234490438771]
	TIME [epoch: 27.7 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7879093512206132		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.7879093512206132 | validation: 0.6110748864424853]
	TIME [epoch: 27.7 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7477407505696991		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.7477407505696991 | validation: 0.7113679473144343]
	TIME [epoch: 27.7 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7348131417699099		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.7348131417699099 | validation: 0.7619244929403408]
	TIME [epoch: 27.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8467063591409851		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.8467063591409851 | validation: 0.6472056351136574]
	TIME [epoch: 27.7 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6202192524698786		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.6202192524698786 | validation: 0.5867433029396554]
	TIME [epoch: 27.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6394892650015583		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.6394892650015583 | validation: 0.6243632107815446]
	TIME [epoch: 27.7 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6980458834871879		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.6980458834871879 | validation: 0.7459816672291553]
	TIME [epoch: 27.7 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849678719212657		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.6849678719212657 | validation: 0.6024588717599483]
	TIME [epoch: 27.7 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6531993816898676		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.6531993816898676 | validation: 0.5713752259622634]
	TIME [epoch: 27.7 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6229083655384161		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.6229083655384161 | validation: 0.5906712231228336]
	TIME [epoch: 27.7 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5926635562465077		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.5926635562465077 | validation: 0.9052470731697224]
	TIME [epoch: 27.7 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8543019690710829		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.8543019690710829 | validation: 1.1046642570594416]
	TIME [epoch: 27.7 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2524952822588868		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.2524952822588868 | validation: 0.7440008282676958]
	TIME [epoch: 27.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234544932280129		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.7234544932280129 | validation: 0.7901716652040424]
	TIME [epoch: 27.7 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.85984480307384		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.85984480307384 | validation: 1.2075456302586205]
	TIME [epoch: 27.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.982236003124609		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.982236003124609 | validation: 0.7396156886956636]
	TIME [epoch: 27.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.714057441736121		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.714057441736121 | validation: 0.7132740218848648]
	TIME [epoch: 27.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6974594642757059		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.6974594642757059 | validation: 0.6244548661593973]
	TIME [epoch: 27.7 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6720548117990977		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.6720548117990977 | validation: 0.6625130066810115]
	TIME [epoch: 27.7 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7825832630375027		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.7825832630375027 | validation: 1.306695675720784]
	TIME [epoch: 27.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.343226640195588		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.343226640195588 | validation: 0.871740334324664]
	TIME [epoch: 27.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9301635602329685		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.9301635602329685 | validation: 0.7790217602312515]
	TIME [epoch: 27.7 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.774801507898343		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.774801507898343 | validation: 0.8739643288120519]
	TIME [epoch: 27.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9514963791993193		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.9514963791993193 | validation: 0.8187834038338252]
	TIME [epoch: 27.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8200577327573894		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.8200577327573894 | validation: 0.6516277882091432]
	TIME [epoch: 27.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7094592051094324		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.7094592051094324 | validation: 0.6868728325109769]
	TIME [epoch: 27.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7045660040602606		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.7045660040602606 | validation: 0.758533116378373]
	TIME [epoch: 27.7 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7490777657304197		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.7490777657304197 | validation: 0.7885350141515227]
	TIME [epoch: 27.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8056213219945031		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.8056213219945031 | validation: 0.6518617123398915]
	TIME [epoch: 27.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6315992525038617		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.6315992525038617 | validation: 0.7403533223662546]
	TIME [epoch: 27.7 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7325125937690896		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.7325125937690896 | validation: 0.584242304128544]
	TIME [epoch: 27.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.578149903552637		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.578149903552637 | validation: 0.5497880607003376]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5674398345983012		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.5674398345983012 | validation: 0.5784545085925239]
	TIME [epoch: 27.7 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6657552758490104		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.6657552758490104 | validation: 0.6720945025819852]
	TIME [epoch: 27.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5922217291533729		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.5922217291533729 | validation: 0.5048145925094285]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_246.pth
	Model improved!!!
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5533795238509538		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.5533795238509538 | validation: 0.9000254421382351]
	TIME [epoch: 27.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0006190526790275		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.0006190526790275 | validation: 0.7782122441334505]
	TIME [epoch: 27.7 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0236858194660927		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.0236858194660927 | validation: 0.9894114961528075]
	TIME [epoch: 27.7 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7912661014852116		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.7912661014852116 | validation: 0.8603516370673865]
	TIME [epoch: 27.7 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8997654815433621		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.8997654815433621 | validation: 0.8004305912976065]
	TIME [epoch: 27.7 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842986825312685		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.6842986825312685 | validation: 0.5925804157834325]
	TIME [epoch: 27.8 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5385930382994812		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.5385930382994812 | validation: 0.5660520126401323]
	TIME [epoch: 27.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6042951707341926		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.6042951707341926 | validation: 0.8886423424952224]
	TIME [epoch: 27.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9411289440890342		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.9411289440890342 | validation: 0.7495614872404395]
	TIME [epoch: 27.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7719738136283505		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.7719738136283505 | validation: 0.7466862946426869]
	TIME [epoch: 27.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7403451163350484		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.7403451163350484 | validation: 0.700611310220404]
	TIME [epoch: 27.7 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9939513309862832		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.9939513309862832 | validation: 0.9843238247544163]
	TIME [epoch: 27.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8192539371708415		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.8192539371708415 | validation: 0.571735155977742]
	TIME [epoch: 27.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5862091277522252		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.5862091277522252 | validation: 0.5716354374619271]
	TIME [epoch: 27.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6036547880468375		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.6036547880468375 | validation: 0.5409888769651887]
	TIME [epoch: 27.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6164786738115663		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.6164786738115663 | validation: 0.5814837221946296]
	TIME [epoch: 27.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.603392447282302		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.603392447282302 | validation: 0.555145352805]
	TIME [epoch: 27.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5748343187246138		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.5748343187246138 | validation: 0.616004744176699]
	TIME [epoch: 27.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6097231063734163		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.6097231063734163 | validation: 0.5143782970980557]
	TIME [epoch: 27.7 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5136312863721343		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.5136312863721343 | validation: 0.482177300644087]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4996098749148686		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.4996098749148686 | validation: 0.9437346911925352]
	TIME [epoch: 27.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9707709406211223		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.9707709406211223 | validation: 0.7305105060902725]
	TIME [epoch: 27.7 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.686795256645985		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.686795256645985 | validation: 0.562295096004439]
	TIME [epoch: 27.7 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5631382773075967		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.5631382773075967 | validation: 0.5277490983362213]
	TIME [epoch: 27.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8301367889011857		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.8301367889011857 | validation: 0.6830596136642094]
	TIME [epoch: 27.7 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6777797813153541		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.6777797813153541 | validation: 0.8695561328602824]
	TIME [epoch: 27.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8027844194584683		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.8027844194584683 | validation: 0.5667266325980204]
	TIME [epoch: 27.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5734129682627379		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.5734129682627379 | validation: 0.49329893075288445]
	TIME [epoch: 27.7 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5261789438553255		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.5261789438553255 | validation: 0.5490801303597167]
	TIME [epoch: 27.7 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6190293316914144		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.6190293316914144 | validation: 0.7770380243448411]
	TIME [epoch: 27.7 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7173548974520556		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.7173548974520556 | validation: 0.6513779834430239]
	TIME [epoch: 27.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.583665527515073		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.583665527515073 | validation: 0.4950328290879775]
	TIME [epoch: 27.7 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5329427728083709		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.5329427728083709 | validation: 0.6183193228654725]
	TIME [epoch: 27.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6365665646269332		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.6365665646269332 | validation: 0.7571009409354196]
	TIME [epoch: 27.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6672939808782716		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.6672939808782716 | validation: 0.600897960082212]
	TIME [epoch: 27.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5731196062522277		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.5731196062522277 | validation: 0.6626435947655226]
	TIME [epoch: 27.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6190571811717618		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.6190571811717618 | validation: 0.6433441690487902]
	TIME [epoch: 27.7 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7375525049170728		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.7375525049170728 | validation: 0.618213645821846]
	TIME [epoch: 27.7 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5983265740968176		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.5983265740968176 | validation: 0.6038884676656244]
	TIME [epoch: 27.7 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5859260990872954		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.5859260990872954 | validation: 0.6246582685325072]
	TIME [epoch: 27.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6311661124503505		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.6311661124503505 | validation: 0.5831375751958965]
	TIME [epoch: 27.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5541927478157873		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.5541927478157873 | validation: 0.5631537553570048]
	TIME [epoch: 27.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5396087262150266		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.5396087262150266 | validation: 0.594470255032042]
	TIME [epoch: 27.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5852971438011729		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.5852971438011729 | validation: 0.5443386113012201]
	TIME [epoch: 27.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49544084146426415		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.49544084146426415 | validation: 0.558095257995237]
	TIME [epoch: 27.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5643583463737216		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.5643583463737216 | validation: 0.9737594440403341]
	TIME [epoch: 27.7 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4583805826926335		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.4583805826926335 | validation: 1.5286252930035007]
	TIME [epoch: 27.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.180996657543853		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.180996657543853 | validation: 0.5889782799247069]
	TIME [epoch: 27.7 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5602064444452931		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.5602064444452931 | validation: 0.5252977121559866]
	TIME [epoch: 27.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5245693337965062		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.5245693337965062 | validation: 0.5112509138028838]
	TIME [epoch: 27.7 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5357669303568733		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.5357669303568733 | validation: 0.562202809343027]
	TIME [epoch: 27.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6708792112571547		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.6708792112571547 | validation: 0.8390378806985694]
	TIME [epoch: 27.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9903697619351163		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.9903697619351163 | validation: 0.6847176999826634]
	TIME [epoch: 27.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9998640764565045		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.9998640764565045 | validation: 0.8951021677469426]
	TIME [epoch: 27.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6571990271053796		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.6571990271053796 | validation: 0.48513447679344224]
	TIME [epoch: 27.7 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.647905427948404		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.647905427948404 | validation: 1.8236949098483586]
	TIME [epoch: 27.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4310169179522352		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.4310169179522352 | validation: 0.6267066404631728]
	TIME [epoch: 27.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5804397635124912		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.5804397635124912 | validation: 0.45691675218416833]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43996713811060656		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.43996713811060656 | validation: 0.48639055315404944]
	TIME [epoch: 27.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5690996615254136		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.5690996615254136 | validation: 0.6102060919932448]
	TIME [epoch: 27.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5418985802128652		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.5418985802128652 | validation: 0.5194217781594549]
	TIME [epoch: 27.7 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.557870747804831		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.557870747804831 | validation: 0.5352658945367326]
	TIME [epoch: 27.7 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5290068735762796		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.5290068735762796 | validation: 0.5791071601683625]
	TIME [epoch: 27.7 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4951945452374866		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.4951945452374866 | validation: 0.43074614372609865]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_310.pth
	Model improved!!!
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4402984361368632		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.4402984361368632 | validation: 0.48967048910918437]
	TIME [epoch: 27.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5328365953149102		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.5328365953149102 | validation: 0.5322903105190945]
	TIME [epoch: 27.7 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7670957300538837		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.7670957300538837 | validation: 1.0715865381700584]
	TIME [epoch: 27.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7506368149438011		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.7506368149438011 | validation: 0.5672389993886613]
	TIME [epoch: 27.7 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5178638953113796		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.5178638953113796 | validation: 0.4654623385260552]
	TIME [epoch: 27.7 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5344708276436054		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.5344708276436054 | validation: 0.9746469933151876]
	TIME [epoch: 27.7 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7268314905244638		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.7268314905244638 | validation: 0.5413192990984892]
	TIME [epoch: 27.7 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5808844413208125		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.5808844413208125 | validation: 0.5697571839302699]
	TIME [epoch: 27.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5228462744419471		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.5228462744419471 | validation: 0.46474990130471067]
	TIME [epoch: 27.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.482352785437426		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.482352785437426 | validation: 0.5242431430204527]
	TIME [epoch: 27.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4879689849331987		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.4879689849331987 | validation: 0.5342212493981292]
	TIME [epoch: 27.7 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5396139898764889		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.5396139898764889 | validation: 0.48325200197242907]
	TIME [epoch: 27.7 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.572247598851969		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.572247598851969 | validation: 0.5376217341646167]
	TIME [epoch: 27.7 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5102714270393821		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.5102714270393821 | validation: 0.6031322351198916]
	TIME [epoch: 27.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6367707262387454		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.6367707262387454 | validation: 0.43502254303629573]
	TIME [epoch: 27.7 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5082349352841284		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.5082349352841284 | validation: 0.6423951620765789]
	TIME [epoch: 27.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5720888259423083		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.5720888259423083 | validation: 0.5050153893913927]
	TIME [epoch: 27.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6064011750078575		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.6064011750078575 | validation: 0.6407578396441101]
	TIME [epoch: 27.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6699682454773364		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.6699682454773364 | validation: 0.7918103327199885]
	TIME [epoch: 27.7 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6369259897112		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.6369259897112 | validation: 0.5738370631938717]
	TIME [epoch: 27.7 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5205588856562112		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.5205588856562112 | validation: 0.5212989018766264]
	TIME [epoch: 27.7 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.532424458300742		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.532424458300742 | validation: 0.5929657253934804]
	TIME [epoch: 27.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.576674659106444		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.576674659106444 | validation: 0.5395606199585712]
	TIME [epoch: 27.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5153060613311069		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.5153060613311069 | validation: 0.456492661991209]
	TIME [epoch: 27.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.504149765710775		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.504149765710775 | validation: 0.5556099662190824]
	TIME [epoch: 27.7 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5428058390701762		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.5428058390701762 | validation: 0.5338796940530698]
	TIME [epoch: 27.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5280040523329752		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.5280040523329752 | validation: 0.6107867274211509]
	TIME [epoch: 27.7 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6092933444917683		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.6092933444917683 | validation: 0.6390240557008525]
	TIME [epoch: 27.7 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.602669128989509		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.602669128989509 | validation: 0.4990908515738447]
	TIME [epoch: 27.7 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49635496530790807		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.49635496530790807 | validation: 0.5111996012785545]
	TIME [epoch: 27.7 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5020825482621336		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.5020825482621336 | validation: 0.5024860816109109]
	TIME [epoch: 27.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5657895792940536		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.5657895792940536 | validation: 0.5958844771562927]
	TIME [epoch: 27.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209076777596998		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.7209076777596998 | validation: 0.887085171228682]
	TIME [epoch: 27.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.089747350768401		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.089747350768401 | validation: 0.8238398198747303]
	TIME [epoch: 27.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7883009546385255		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.7883009546385255 | validation: 0.546963843228601]
	TIME [epoch: 27.7 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5559054750982312		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.5559054750982312 | validation: 0.4759547402671385]
	TIME [epoch: 27.7 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47838791957485866		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.47838791957485866 | validation: 0.5890079458302404]
	TIME [epoch: 27.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7101637962474469		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.7101637962474469 | validation: 0.5589977571074676]
	TIME [epoch: 27.7 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5131947297420456		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.5131947297420456 | validation: 0.5974053368804585]
	TIME [epoch: 27.7 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5785716921337896		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.5785716921337896 | validation: 0.6475396754599829]
	TIME [epoch: 27.7 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6512924177082214		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.6512924177082214 | validation: 0.8526034799976343]
	TIME [epoch: 27.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8928306881581032		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.8928306881581032 | validation: 0.7974053713982582]
	TIME [epoch: 27.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7105215411012418		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.7105215411012418 | validation: 0.5217682473123505]
	TIME [epoch: 27.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5533530672664371		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.5533530672664371 | validation: 0.5235082571295822]
	TIME [epoch: 27.7 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6267717425329707		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.6267717425329707 | validation: 0.8501925751201551]
	TIME [epoch: 27.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8143221999207024		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.8143221999207024 | validation: 0.7384555520912451]
	TIME [epoch: 27.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5805268811215409		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.5805268811215409 | validation: 0.48769037018343453]
	TIME [epoch: 27.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5235334229405554		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.5235334229405554 | validation: 0.7309930810145775]
	TIME [epoch: 27.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.789413388437146		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.789413388437146 | validation: 0.7554478666726365]
	TIME [epoch: 27.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6482363771924942		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.6482363771924942 | validation: 0.6035687089644662]
	TIME [epoch: 27.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6665817560160581		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.6665817560160581 | validation: 0.6033255911288785]
	TIME [epoch: 27.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.580627460513002		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.580627460513002 | validation: 0.6078269462881669]
	TIME [epoch: 27.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5960087832254723		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.5960087832254723 | validation: 0.5559586840871396]
	TIME [epoch: 27.7 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5453659964855243		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.5453659964855243 | validation: 0.551199015271082]
	TIME [epoch: 27.7 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.59943957274013		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.59943957274013 | validation: 0.6375448405505675]
	TIME [epoch: 27.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7353829474094384		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.7353829474094384 | validation: 0.8554466821963496]
	TIME [epoch: 27.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7387794555524572		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.7387794555524572 | validation: 0.5042104054340683]
	TIME [epoch: 27.7 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5490501917414653		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.5490501917414653 | validation: 0.47998944680693184]
	TIME [epoch: 27.7 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49154346518951253		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.49154346518951253 | validation: 0.4486382092782278]
	TIME [epoch: 27.7 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5617970571993678		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.5617970571993678 | validation: 0.4600643823238842]
	TIME [epoch: 27.7 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5820415585751354		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.5820415585751354 | validation: 0.5842940703369365]
	TIME [epoch: 27.7 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7917406639622107		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.7917406639622107 | validation: 0.6564106211355519]
	TIME [epoch: 27.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7357957699123355		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.7357957699123355 | validation: 0.9568499296003193]
	TIME [epoch: 27.7 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.106857543695486		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.106857543695486 | validation: 0.9405608856255896]
	TIME [epoch: 27.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9902666362840203		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.9902666362840203 | validation: 0.7861148967170349]
	TIME [epoch: 27.7 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6411818996505176		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.6411818996505176 | validation: 0.5218875689586129]
	TIME [epoch: 27.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5667498203561645		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.5667498203561645 | validation: 0.6084128821094075]
	TIME [epoch: 27.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5983540053155946		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.5983540053155946 | validation: 0.48559407797603177]
	TIME [epoch: 27.7 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4953131215916054		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.4953131215916054 | validation: 0.48871720216715253]
	TIME [epoch: 27.7 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.518464073728554		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.518464073728554 | validation: 0.5111743678416012]
	TIME [epoch: 27.8 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5694717801967858		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.5694717801967858 | validation: 0.5988247584259009]
	TIME [epoch: 27.7 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5943220346851584		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.5943220346851584 | validation: 0.5937695869101105]
	TIME [epoch: 27.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5875361430694278		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.5875361430694278 | validation: 0.5262085535432701]
	TIME [epoch: 27.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6702727368627195		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.6702727368627195 | validation: 0.6031170535849499]
	TIME [epoch: 27.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5738974420134015		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.5738974420134015 | validation: 0.5024407868096035]
	TIME [epoch: 27.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5106668449954548		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.5106668449954548 | validation: 0.49881984617831315]
	TIME [epoch: 27.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5995901717725961		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.5995901717725961 | validation: 0.6438375179771056]
	TIME [epoch: 27.7 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6149750831665787		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.6149750831665787 | validation: 0.4759077130345352]
	TIME [epoch: 27.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5195336009678693		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.5195336009678693 | validation: 0.5113123632971648]
	TIME [epoch: 27.7 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5208615419654349		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.5208615419654349 | validation: 0.5421991506366919]
	TIME [epoch: 27.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5186757613987983		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.5186757613987983 | validation: 0.528209046277327]
	TIME [epoch: 27.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6053771264473521		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.6053771264473521 | validation: 0.6249202155457096]
	TIME [epoch: 27.7 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5961372535190284		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.5961372535190284 | validation: 0.4856348727775921]
	TIME [epoch: 27.7 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5133942204907087		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.5133942204907087 | validation: 0.45912973955740327]
	TIME [epoch: 27.7 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5098070405810129		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.5098070405810129 | validation: 0.48764937040938394]
	TIME [epoch: 27.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.537393197179193		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.537393197179193 | validation: 0.5592476952509849]
	TIME [epoch: 27.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5937010693578028		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.5937010693578028 | validation: 0.6122437420977931]
	TIME [epoch: 27.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6611930492125115		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.6611930492125115 | validation: 0.5725010501451604]
	TIME [epoch: 27.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5121081253735247		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.5121081253735247 | validation: 0.46479415728080303]
	TIME [epoch: 27.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5376178593726181		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.5376178593726181 | validation: 0.7480634171703645]
	TIME [epoch: 27.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7343993475513831		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.7343993475513831 | validation: 0.6639558229824892]
	TIME [epoch: 27.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7061282016740213		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.7061282016740213 | validation: 0.6228452444929072]
	TIME [epoch: 27.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5998144705727902		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.5998144705727902 | validation: 0.6262512874223487]
	TIME [epoch: 27.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7252004189563863		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.7252004189563863 | validation: 0.736149428447745]
	TIME [epoch: 27.7 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7553285142575421		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.7553285142575421 | validation: 0.6536808971421219]
	TIME [epoch: 27.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6239890512719495		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.6239890512719495 | validation: 0.517069974830968]
	TIME [epoch: 27.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.526977299375332		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.526977299375332 | validation: 0.5360544029154088]
	TIME [epoch: 27.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5528299093675398		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.5528299093675398 | validation: 0.47127440847431235]
	TIME [epoch: 27.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4895572631249662		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.4895572631249662 | validation: 0.5059577669660987]
	TIME [epoch: 27.7 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5263249016707585		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.5263249016707585 | validation: 0.46900978947434313]
	TIME [epoch: 27.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5343357666170154		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.5343357666170154 | validation: 0.5488586100373469]
	TIME [epoch: 27.6 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5411815715139375		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.5411815715139375 | validation: 0.4848981367447754]
	TIME [epoch: 27.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.595656493549787		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.595656493549787 | validation: 0.9905419194561114]
	TIME [epoch: 27.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8368647363091882		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.8368647363091882 | validation: 0.5547778212660707]
	TIME [epoch: 27.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46524376398895373		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.46524376398895373 | validation: 0.38940041965924815]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_415.pth
	Model improved!!!
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42651223466279675		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.42651223466279675 | validation: 0.4634066084436886]
	TIME [epoch: 27.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4980685007629269		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.4980685007629269 | validation: 0.42758935018296335]
	TIME [epoch: 27.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4602098461062295		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.4602098461062295 | validation: 0.4375470328772926]
	TIME [epoch: 27.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43845471780988543		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.43845471780988543 | validation: 0.4838780461202542]
	TIME [epoch: 27.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5272480473585206		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.5272480473585206 | validation: 0.5241849283642921]
	TIME [epoch: 27.7 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5225050650222799		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.5225050650222799 | validation: 0.49853422658113333]
	TIME [epoch: 27.7 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46110709995051635		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.46110709995051635 | validation: 0.47273409178222836]
	TIME [epoch: 27.7 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4413689543961695		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.4413689543961695 | validation: 0.38899364147863913]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_423.pth
	Model improved!!!
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.535278491655715		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.535278491655715 | validation: 0.8895309477341256]
	TIME [epoch: 27.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7874071182614344		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.7874071182614344 | validation: 0.5506917903141301]
	TIME [epoch: 27.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5233894910405847		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.5233894910405847 | validation: 0.7798405777193734]
	TIME [epoch: 27.7 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.655004238986114		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.655004238986114 | validation: 0.4777574816008795]
	TIME [epoch: 27.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45512257168468756		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.45512257168468756 | validation: 0.45554727510004955]
	TIME [epoch: 27.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4729498560618177		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.4729498560618177 | validation: 0.502342819050992]
	TIME [epoch: 27.7 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5217371217161416		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.5217371217161416 | validation: 0.5144747640643323]
	TIME [epoch: 27.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49042125255248564		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.49042125255248564 | validation: 0.40642817299898737]
	TIME [epoch: 27.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42450125430141317		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.42450125430141317 | validation: 0.4136147612839633]
	TIME [epoch: 27.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43797378833444267		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.43797378833444267 | validation: 0.40213865962597184]
	TIME [epoch: 27.7 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4534507943752634		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.4534507943752634 | validation: 0.3971013685314639]
	TIME [epoch: 27.7 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41870367288010335		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.41870367288010335 | validation: 0.44399031024686336]
	TIME [epoch: 27.7 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45031847122350543		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.45031847122350543 | validation: 0.41035304707872494]
	TIME [epoch: 27.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4893573819716349		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.4893573819716349 | validation: 0.723113207181859]
	TIME [epoch: 27.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6429668352059226		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.6429668352059226 | validation: 0.6005025849067755]
	TIME [epoch: 27.7 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5080477664562753		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.5080477664562753 | validation: 0.45529359406892267]
	TIME [epoch: 27.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4801657808677755		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.4801657808677755 | validation: 0.5620157970023434]
	TIME [epoch: 27.7 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7615505624999088		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.7615505624999088 | validation: 0.7374314668388736]
	TIME [epoch: 27.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5931014565669568		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.5931014565669568 | validation: 0.47914309163045177]
	TIME [epoch: 27.7 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46528913876658484		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.46528913876658484 | validation: 0.4627341755195946]
	TIME [epoch: 27.7 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44680987540506845		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.44680987540506845 | validation: 0.4661809746966479]
	TIME [epoch: 27.7 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5305883221519814		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.5305883221519814 | validation: 0.568333435126602]
	TIME [epoch: 27.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5381299956608634		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.5381299956608634 | validation: 0.495299264837482]
	TIME [epoch: 27.7 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5396457573080921		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.5396457573080921 | validation: 0.49977996976588496]
	TIME [epoch: 27.7 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5071389237120176		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.5071389237120176 | validation: 0.4589868582118834]
	TIME [epoch: 27.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46786041178050325		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.46786041178050325 | validation: 0.46189324178410945]
	TIME [epoch: 27.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4553588722649486		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.4553588722649486 | validation: 0.43950405692903716]
	TIME [epoch: 27.7 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5016379229142798		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.5016379229142798 | validation: 0.6099360155159113]
	TIME [epoch: 27.7 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8689945966945747		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.8689945966945747 | validation: 1.0537461990845527]
	TIME [epoch: 27.7 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8820145370508038		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.8820145370508038 | validation: 0.7293980692470813]
	TIME [epoch: 27.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7015349391200072		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.7015349391200072 | validation: 0.6362545765494579]
	TIME [epoch: 27.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5818223708397435		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.5818223708397435 | validation: 0.49156020198447464]
	TIME [epoch: 27.7 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5066917797938679		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.5066917797938679 | validation: 0.5070762859203102]
	TIME [epoch: 27.7 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4826154092623772		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.4826154092623772 | validation: 0.4445489373807277]
	TIME [epoch: 27.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5371149030057238		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.5371149030057238 | validation: 0.5051645689144416]
	TIME [epoch: 27.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43128219191215555		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.43128219191215555 | validation: 0.40952511989850676]
	TIME [epoch: 27.7 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4352372675165488		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.4352372675165488 | validation: 0.4063667690721651]
	TIME [epoch: 27.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.454314362032775		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.454314362032775 | validation: 0.5810738894273554]
	TIME [epoch: 27.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5080485490852633		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.5080485490852633 | validation: 0.5052328892091609]
	TIME [epoch: 27.7 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5957754294319866		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.5957754294319866 | validation: 0.8211900521378505]
	TIME [epoch: 27.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7472488442628845		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.7472488442628845 | validation: 0.6443932567171891]
	TIME [epoch: 27.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5780669124992092		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.5780669124992092 | validation: 0.6119141653674787]
	TIME [epoch: 27.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5778418440596848		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.5778418440596848 | validation: 0.6238400339642773]
	TIME [epoch: 27.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6446228140463223		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.6446228140463223 | validation: 0.5645253395790455]
	TIME [epoch: 27.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.643387085868298		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.643387085868298 | validation: 0.6644729526844222]
	TIME [epoch: 27.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6023795515261875		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.6023795515261875 | validation: 0.6052851206520642]
	TIME [epoch: 27.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5480462649787343		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.5480462649787343 | validation: 0.5322606220043066]
	TIME [epoch: 27.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5168020770571022		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.5168020770571022 | validation: 0.5867337079631706]
	TIME [epoch: 27.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6560405347271794		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.6560405347271794 | validation: 0.8471737872773148]
	TIME [epoch: 27.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6763700025595802		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.6763700025595802 | validation: 0.6482143947416341]
	TIME [epoch: 27.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5650473209516266		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.5650473209516266 | validation: 0.49991882048637637]
	TIME [epoch: 27.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48589153815691605		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.48589153815691605 | validation: 0.5815760231029782]
	TIME [epoch: 27.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.611758998319399		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.611758998319399 | validation: 0.7900790262817579]
	TIME [epoch: 27.6 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7518843799017954		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.7518843799017954 | validation: 0.6397405374869239]
	TIME [epoch: 27.7 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5357631802715362		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.5357631802715362 | validation: 0.5178316952721362]
	TIME [epoch: 27.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4829152849651934		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.4829152849651934 | validation: 0.4989965607238518]
	TIME [epoch: 27.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5095368283924743		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.5095368283924743 | validation: 0.5954089816754368]
	TIME [epoch: 27.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6723400004243278		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.6723400004243278 | validation: 0.7544090140258487]
	TIME [epoch: 27.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6255802155831839		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.6255802155831839 | validation: 0.5119310229109745]
	TIME [epoch: 27.7 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5201362558731845		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.5201362558731845 | validation: 0.8220866885424174]
	TIME [epoch: 27.6 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7884728182061129		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.7884728182061129 | validation: 0.6732802380678746]
	TIME [epoch: 27.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.661511475856394		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.661511475856394 | validation: 0.6023819454990325]
	TIME [epoch: 27.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5304791891111156		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.5304791891111156 | validation: 0.5391885562026021]
	TIME [epoch: 27.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5363356109917883		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.5363356109917883 | validation: 0.5150497974080308]
	TIME [epoch: 27.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5032749310037538		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.5032749310037538 | validation: 0.5760864077239343]
	TIME [epoch: 27.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5369224777207214		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.5369224777207214 | validation: 0.5230567725485841]
	TIME [epoch: 27.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5141210674741539		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.5141210674741539 | validation: 0.4735812381498317]
	TIME [epoch: 27.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44174431392540414		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.44174431392540414 | validation: 0.4421460321158462]
	TIME [epoch: 27.7 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4500635351016136		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.4500635351016136 | validation: 0.47265802654675526]
	TIME [epoch: 27.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45836017776529625		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.45836017776529625 | validation: 0.4069855268310386]
	TIME [epoch: 27.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.427964527039881		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.427964527039881 | validation: 0.46501356909701375]
	TIME [epoch: 27.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4745467955711584		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.4745467955711584 | validation: 0.5332046592400806]
	TIME [epoch: 27.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5366512906159822		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.5366512906159822 | validation: 0.5884881783321758]
	TIME [epoch: 27.7 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5607063363688805		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.5607063363688805 | validation: 0.6086536235566352]
	TIME [epoch: 27.7 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5576769863079556		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.5576769863079556 | validation: 0.6906780500393822]
	TIME [epoch: 27.7 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8673292325674883		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.8673292325674883 | validation: 0.8960784688244008]
	TIME [epoch: 27.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7510308098615022		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.7510308098615022 | validation: 0.767091853120003]
	TIME [epoch: 27.7 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6135824968685893		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.6135824968685893 | validation: 0.5564526230173145]
	TIME [epoch: 27.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47912989397132955		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.47912989397132955 | validation: 0.4782043187378123]
	TIME [epoch: 27.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4593996982752871		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.4593996982752871 | validation: 0.4499368257668798]
	TIME [epoch: 27.7 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45081525978508846		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.45081525978508846 | validation: 0.4367400661559334]
	TIME [epoch: 27.7 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4548289333716601		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.4548289333716601 | validation: 0.4639436792000611]
	TIME [epoch: 27.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4827659425089422		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.4827659425089422 | validation: 0.49044200013429695]
	TIME [epoch: 27.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4923449574640033		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.4923449574640033 | validation: 0.5292659434090254]
	TIME [epoch: 27.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5387732884813309		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.5387732884813309 | validation: 0.7651279543267029]
	TIME [epoch: 27.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8089943434494088		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.8089943434494088 | validation: 1.0831016270140439]
	TIME [epoch: 27.6 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.868968570167161		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.868968570167161 | validation: 0.6681036814072061]
	TIME [epoch: 27.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5777636936160653		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.5777636936160653 | validation: 0.563692360901563]
	TIME [epoch: 27.7 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5224939073628105		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.5224939073628105 | validation: 0.4420995248571131]
	TIME [epoch: 27.7 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47240905775520253		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.47240905775520253 | validation: 0.44807426971673486]
	TIME [epoch: 27.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45980391486567185		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.45980391486567185 | validation: 0.4613390808960706]
	TIME [epoch: 27.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45003180031078727		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.45003180031078727 | validation: 0.4190206618186603]
	TIME [epoch: 27.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44369630529975757		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.44369630529975757 | validation: 0.43523472385517]
	TIME [epoch: 27.7 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5527379721539483		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.5527379721539483 | validation: 0.7561050965309614]
	TIME [epoch: 27.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7281797084454681		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.7281797084454681 | validation: 0.6042800254646983]
	TIME [epoch: 27.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5424776766644939		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.5424776766644939 | validation: 0.4821452856028968]
	TIME [epoch: 27.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49243702220194957		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.49243702220194957 | validation: 0.5793172936447949]
	TIME [epoch: 27.7 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239894927804692		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.7239894927804692 | validation: 0.7577764834806229]
	TIME [epoch: 27.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6957784938814773		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.6957784938814773 | validation: 0.5108322980602983]
	TIME [epoch: 27.7 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4739944667885396		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.4739944667885396 | validation: 0.4611553889697078]
	TIME [epoch: 27.7 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4887999150841668		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.4887999150841668 | validation: 0.5861942216137956]
	TIME [epoch: 27.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5631444414974272		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.5631444414974272 | validation: 0.4660852434543078]
	TIME [epoch: 27.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.431123510869707		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.431123510869707 | validation: 0.40815933854285674]
	TIME [epoch: 27.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4154226597554934		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.4154226597554934 | validation: 0.4167002527731063]
	TIME [epoch: 27.7 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41529932457171814		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.41529932457171814 | validation: 0.4191489242746935]
	TIME [epoch: 27.7 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43636262283434735		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.43636262283434735 | validation: 0.41694250349923495]
	TIME [epoch: 27.7 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46272074013882597		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.46272074013882597 | validation: 0.4275934467221619]
	TIME [epoch: 27.7 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46142922728519586		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.46142922728519586 | validation: 0.4950262663351332]
	TIME [epoch: 27.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46687495674603263		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.46687495674603263 | validation: 0.4472661095870765]
	TIME [epoch: 27.7 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5105963758417547		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.5105963758417547 | validation: 0.5448757520053582]
	TIME [epoch: 27.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4954363546049543		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.4954363546049543 | validation: 0.5274796296349856]
	TIME [epoch: 27.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47251417939630314		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.47251417939630314 | validation: 0.4700381354475893]
	TIME [epoch: 27.7 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4693531861003199		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.4693531861003199 | validation: 0.4927025278987304]
	TIME [epoch: 27.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.468445870082249		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.468445870082249 | validation: 0.6527361451258077]
	TIME [epoch: 27.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6639803293323197		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.6639803293323197 | validation: 0.6029866908102143]
	TIME [epoch: 27.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.585607732945038		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.585607732945038 | validation: 0.5268522166533859]
	TIME [epoch: 27.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5085672779743889		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.5085672779743889 | validation: 0.5045005925942128]
	TIME [epoch: 27.6 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4690141252759301		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.4690141252759301 | validation: 0.419904157222424]
	TIME [epoch: 27.6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4361901033642233		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.4361901033642233 | validation: 0.6382689450707147]
	TIME [epoch: 27.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5969820059599463		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.5969820059599463 | validation: 0.4788272186066307]
	TIME [epoch: 27.7 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46314283976444093		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.46314283976444093 | validation: 0.45861966028937856]
	TIME [epoch: 27.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45275984167596994		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.45275984167596994 | validation: 0.38408678065988766]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_545.pth
	Model improved!!!
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4293845312167325		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.4293845312167325 | validation: 0.5466083532484259]
	TIME [epoch: 27.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5131468747587705		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.5131468747587705 | validation: 0.42680340212704515]
	TIME [epoch: 27.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3957613963745824		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.3957613963745824 | validation: 0.3760398576895624]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_548.pth
	Model improved!!!
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3771540562626782		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.3771540562626782 | validation: 0.36014137581952993]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_549.pth
	Model improved!!!
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3814162072810659		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.3814162072810659 | validation: 0.33395138128615437]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_550.pth
	Model improved!!!
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3928485274134182		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.3928485274134182 | validation: 0.36133040802909494]
	TIME [epoch: 27.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3943056511449172		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.3943056511449172 | validation: 0.3763250621772467]
	TIME [epoch: 27.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38513501626764574		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.38513501626764574 | validation: 0.40642530368137797]
	TIME [epoch: 27.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3960323369708112		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.3960323369708112 | validation: 0.46686506379552806]
	TIME [epoch: 27.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4280863323848448		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.4280863323848448 | validation: 0.37493182746899356]
	TIME [epoch: 27.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37522675186657806		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.37522675186657806 | validation: 0.34979353264753427]
	TIME [epoch: 27.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3817712465262739		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.3817712465262739 | validation: 0.3426179883366988]
	TIME [epoch: 27.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3656627981281213		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.3656627981281213 | validation: 0.4026198386402485]
	TIME [epoch: 27.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4897902241132133		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.4897902241132133 | validation: 0.44516689702870194]
	TIME [epoch: 27.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4058787419330633		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.4058787419330633 | validation: 0.42230935316711543]
	TIME [epoch: 27.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4228044826521907		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.4228044826521907 | validation: 0.46452091921242417]
	TIME [epoch: 27.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4713885111586942		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.4713885111586942 | validation: 0.4257403866027126]
	TIME [epoch: 27.7 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40821095051944234		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.40821095051944234 | validation: 0.4133102891893169]
	TIME [epoch: 27.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42666290584994854		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.42666290584994854 | validation: 0.5339645484845725]
	TIME [epoch: 27.7 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48331080595804154		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.48331080595804154 | validation: 0.4608586882628606]
	TIME [epoch: 27.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4457505390013119		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.4457505390013119 | validation: 0.36373761168079866]
	TIME [epoch: 27.7 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3810656259300009		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.3810656259300009 | validation: 0.39658396317080646]
	TIME [epoch: 27.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38513025250052874		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.38513025250052874 | validation: 0.3751587804077073]
	TIME [epoch: 27.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.388955282325209		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.388955282325209 | validation: 0.38291030292958156]
	TIME [epoch: 27.7 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40598646797223403		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.40598646797223403 | validation: 0.38923304862487074]
	TIME [epoch: 27.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3673069246893351		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.3673069246893351 | validation: 0.32156386391143715]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_571.pth
	Model improved!!!
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32910254098999847		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.32910254098999847 | validation: 0.3684022717567487]
	TIME [epoch: 27.8 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37279771313287446		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.37279771313287446 | validation: 0.4031491767202935]
	TIME [epoch: 27.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42495492463032		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.42495492463032 | validation: 0.49974875143997993]
	TIME [epoch: 27.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5063856635218422		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.5063856635218422 | validation: 0.393254859491715]
	TIME [epoch: 27.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4820763637143386		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.4820763637143386 | validation: 0.5808274530727919]
	TIME [epoch: 27.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5212166939229804		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.5212166939229804 | validation: 0.441575819764087]
	TIME [epoch: 27.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4518332206913281		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.4518332206913281 | validation: 0.42827515089811335]
	TIME [epoch: 27.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4134751435173001		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.4134751435173001 | validation: 0.4194465196973954]
	TIME [epoch: 27.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3761715552212672		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.3761715552212672 | validation: 0.315071117901343]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_580.pth
	Model improved!!!
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33733825465528344		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.33733825465528344 | validation: 0.31890898772598375]
	TIME [epoch: 27.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33210247200320614		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.33210247200320614 | validation: 0.33023841763170764]
	TIME [epoch: 27.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3875637148034332		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.3875637148034332 | validation: 0.4528597360039037]
	TIME [epoch: 27.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4110045670892666		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.4110045670892666 | validation: 0.3241413330611966]
	TIME [epoch: 27.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34194159847435224		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.34194159847435224 | validation: 0.3420863835429093]
	TIME [epoch: 27.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31864124278417016		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.31864124278417016 | validation: 0.3283151619897005]
	TIME [epoch: 27.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4232270459694766		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.4232270459694766 | validation: 0.4996502394213662]
	TIME [epoch: 27.7 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4703644218601779		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.4703644218601779 | validation: 0.5290913697178945]
	TIME [epoch: 27.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45928517707018657		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.45928517707018657 | validation: 0.40560059250552327]
	TIME [epoch: 27.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45909553564865885		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.45909553564865885 | validation: 0.410286635520262]
	TIME [epoch: 27.7 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41368142734390306		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.41368142734390306 | validation: 0.35933131680225094]
	TIME [epoch: 27.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32594260542477865		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.32594260542477865 | validation: 0.3498314549676888]
	TIME [epoch: 27.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41482188255447183		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.41482188255447183 | validation: 0.3743001333791194]
	TIME [epoch: 27.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3620080936840778		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.3620080936840778 | validation: 0.30769415614927226]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_594.pth
	Model improved!!!
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3155601259195426		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.3155601259195426 | validation: 0.3184090145356295]
	TIME [epoch: 27.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3255898894754737		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.3255898894754737 | validation: 0.31899103554862196]
	TIME [epoch: 27.7 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3236581874342746		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.3236581874342746 | validation: 0.3035316142235314]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_597.pth
	Model improved!!!
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32914024331911224		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.32914024331911224 | validation: 0.35971737793140385]
	TIME [epoch: 27.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33304764044610113		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.33304764044610113 | validation: 0.3341144435797236]
	TIME [epoch: 27.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3475605297772671		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.3475605297772671 | validation: 0.35998014740003553]
	TIME [epoch: 27.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3326119871976271		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.3326119871976271 | validation: 0.3051468342647273]
	TIME [epoch: 27.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34938789402461046		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.34938789402461046 | validation: 0.4002620971985796]
	TIME [epoch: 27.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4365601350959409		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.4365601350959409 | validation: 0.35472138773423434]
	TIME [epoch: 27.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4168674493988711		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.4168674493988711 | validation: 0.45574944636620035]
	TIME [epoch: 27.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.471895085261403		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.471895085261403 | validation: 0.4603293892870751]
	TIME [epoch: 27.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4132632646287614		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.4132632646287614 | validation: 0.35208712021622646]
	TIME [epoch: 27.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3420214243251324		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.3420214243251324 | validation: 0.31578834816679363]
	TIME [epoch: 27.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34129938131295817		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.34129938131295817 | validation: 0.37719343689255747]
	TIME [epoch: 27.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43962173317654724		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.43962173317654724 | validation: 0.532265191161913]
	TIME [epoch: 27.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47772623316702784		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.47772623316702784 | validation: 0.3944439238875904]
	TIME [epoch: 27.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3802430220703823		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.3802430220703823 | validation: 0.4083152288437075]
	TIME [epoch: 27.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41469297804446587		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.41469297804446587 | validation: 0.4681440759701539]
	TIME [epoch: 27.7 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46706974524023964		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.46706974524023964 | validation: 0.5650598273314144]
	TIME [epoch: 27.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5009567629367376		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.5009567629367376 | validation: 0.5197820034129633]
	TIME [epoch: 27.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45243906847160675		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.45243906847160675 | validation: 0.45868144854024806]
	TIME [epoch: 27.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4719840667533507		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.4719840667533507 | validation: 0.49055317807606535]
	TIME [epoch: 27.7 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47445555607326756		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.47445555607326756 | validation: 0.5416148751752624]
	TIME [epoch: 27.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5635937291991258		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.5635937291991258 | validation: 0.7436121258250864]
	TIME [epoch: 27.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6983312729303434		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.6983312729303434 | validation: 0.7459065303656705]
	TIME [epoch: 27.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.654108619622679		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.654108619622679 | validation: 0.5345822004625517]
	TIME [epoch: 27.7 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47755682777640457		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.47755682777640457 | validation: 0.3779500425542221]
	TIME [epoch: 27.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3766363759991569		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.3766363759991569 | validation: 0.37895492077878895]
	TIME [epoch: 27.7 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.394387683808315		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.394387683808315 | validation: 0.4345993832575434]
	TIME [epoch: 27.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45750593043696164		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.45750593043696164 | validation: 0.41601357414120954]
	TIME [epoch: 27.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41825728325376604		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.41825728325376604 | validation: 0.4287122071556986]
	TIME [epoch: 27.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4935289265300743		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.4935289265300743 | validation: 0.5090395382788157]
	TIME [epoch: 27.7 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5521533550149452		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.5521533550149452 | validation: 0.5698880188570413]
	TIME [epoch: 27.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6045954119756647		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.6045954119756647 | validation: 0.552949234737793]
	TIME [epoch: 27.7 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5175177449148405		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.5175177449148405 | validation: 0.49032269837954034]
	TIME [epoch: 27.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44113778576437757		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.44113778576437757 | validation: 0.40629476021041366]
	TIME [epoch: 27.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40280963906071177		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.40280963906071177 | validation: 0.38191631513535884]
	TIME [epoch: 27.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3768795431246065		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.3768795431246065 | validation: 0.32754633895681395]
	TIME [epoch: 27.7 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31126509666699875		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.31126509666699875 | validation: 0.30672468465354924]
	TIME [epoch: 27.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3140550826781482		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.3140550826781482 | validation: 0.30765821900567936]
	TIME [epoch: 27.7 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3260054695686598		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.3260054695686598 | validation: 0.347075172798382]
	TIME [epoch: 27.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3556306591821045		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.3556306591821045 | validation: 0.42182468494182523]
	TIME [epoch: 27.7 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38888200853407323		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.38888200853407323 | validation: 0.38561587699123595]
	TIME [epoch: 27.7 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3726704705395698		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.3726704705395698 | validation: 0.41986211229709486]
	TIME [epoch: 27.7 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3889548805026367		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.3889548805026367 | validation: 0.4180384950804214]
	TIME [epoch: 27.7 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3867155171947806		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.3867155171947806 | validation: 0.3969430435816886]
	TIME [epoch: 27.7 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36281149135986135		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.36281149135986135 | validation: 0.3554578450360043]
	TIME [epoch: 27.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39117532173560315		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.39117532173560315 | validation: 0.5316248823950744]
	TIME [epoch: 27.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5582860443266564		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.5582860443266564 | validation: 0.5643857160493312]
	TIME [epoch: 27.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7606559567338222		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.7606559567338222 | validation: 0.9192332228834462]
	TIME [epoch: 27.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8663774656524674		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.8663774656524674 | validation: 0.7432193096735273]
	TIME [epoch: 27.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6039689421433907		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.6039689421433907 | validation: 0.4969822320907567]
	TIME [epoch: 27.7 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48805686651903185		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.48805686651903185 | validation: 0.42956606810066206]
	TIME [epoch: 27.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4694295268360861		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.4694295268360861 | validation: 0.5612921746762022]
	TIME [epoch: 27.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45567565110056274		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.45567565110056274 | validation: 0.40793412645811566]
	TIME [epoch: 27.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4694634949767703		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.4694634949767703 | validation: 0.5352242386767453]
	TIME [epoch: 27.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5231283076693788		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.5231283076693788 | validation: 0.437048486765885]
	TIME [epoch: 27.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.360729934609523		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.360729934609523 | validation: 0.32141507888706194]
	TIME [epoch: 27.7 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3177344808264558		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.3177344808264558 | validation: 0.3170497625622273]
	TIME [epoch: 27.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29941365826375044		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.29941365826375044 | validation: 0.31080750711527716]
	TIME [epoch: 27.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3279187346927519		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.3279187346927519 | validation: 0.3674280391262954]
	TIME [epoch: 27.7 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3857396926306694		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.3857396926306694 | validation: 0.46148264481638257]
	TIME [epoch: 27.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4424801437065158		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.4424801437065158 | validation: 0.38775184823506936]
	TIME [epoch: 27.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35854872755552053		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.35854872755552053 | validation: 0.3509502203904956]
	TIME [epoch: 27.7 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3596499103801975		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.3596499103801975 | validation: 0.3186216291934318]
	TIME [epoch: 27.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3275544726938261		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.3275544726938261 | validation: 0.31890219375814083]
	TIME [epoch: 27.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3356051561691514		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.3356051561691514 | validation: 0.3690549703523831]
	TIME [epoch: 27.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3586188039997925		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.3586188039997925 | validation: 0.31893232188799625]
	TIME [epoch: 27.7 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3116554559920801		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.3116554559920801 | validation: 0.297273682649039]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_663.pth
	Model improved!!!
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2908867435085739		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.2908867435085739 | validation: 0.29027962658501383]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_664.pth
	Model improved!!!
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28617248094153214		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.28617248094153214 | validation: 0.3192225017045007]
	TIME [epoch: 27.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3392815776064624		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.3392815776064624 | validation: 0.30617415207183485]
	TIME [epoch: 27.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30476970417039256		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.30476970417039256 | validation: 0.27463844953394906]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_667.pth
	Model improved!!!
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2878857070460844		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.2878857070460844 | validation: 0.33349407110977863]
	TIME [epoch: 27.7 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3046311555076478		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.3046311555076478 | validation: 0.2978415813410281]
	TIME [epoch: 27.7 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2868556040581715		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.2868556040581715 | validation: 0.28262523959602204]
	TIME [epoch: 27.7 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2721508432741318		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.2721508432741318 | validation: 0.2699713952710357]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_671.pth
	Model improved!!!
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28240816256261625		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.28240816256261625 | validation: 0.3071122258608662]
	TIME [epoch: 27.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3478319359840065		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.3478319359840065 | validation: 0.37746787829094447]
	TIME [epoch: 27.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.381729157427398		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.381729157427398 | validation: 0.4983487590179235]
	TIME [epoch: 27.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5002184993132396		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.5002184993132396 | validation: 0.3972881609156656]
	TIME [epoch: 27.7 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38028729940087286		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.38028729940087286 | validation: 0.38142341472991]
	TIME [epoch: 27.7 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3376438213594561		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.3376438213594561 | validation: 0.2900110375510871]
	TIME [epoch: 27.7 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32558844454054275		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.32558844454054275 | validation: 0.32513895207727544]
	TIME [epoch: 27.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3232577172937886		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.3232577172937886 | validation: 0.27678206585222015]
	TIME [epoch: 27.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785214152268628		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.2785214152268628 | validation: 0.26867605197315714]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_680.pth
	Model improved!!!
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2933399806782924		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.2933399806782924 | validation: 0.3485114156557141]
	TIME [epoch: 27.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32386654285455985		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.32386654285455985 | validation: 0.28977555254767895]
	TIME [epoch: 27.7 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3164245892723371		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.3164245892723371 | validation: 0.30670198531324366]
	TIME [epoch: 27.7 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3171523742714064		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.3171523742714064 | validation: 0.36761872677530116]
	TIME [epoch: 27.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48429920525037473		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.48429920525037473 | validation: 0.6982088446170391]
	TIME [epoch: 27.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6158701510058243		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.6158701510058243 | validation: 0.46711013582697347]
	TIME [epoch: 27.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44009877964104893		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.44009877964104893 | validation: 0.3996563131652413]
	TIME [epoch: 27.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4097326351372482		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.4097326351372482 | validation: 0.3777058816517675]
	TIME [epoch: 27.7 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3561510468431821		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.3561510468431821 | validation: 0.3228307467239192]
	TIME [epoch: 27.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31250243125961363		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.31250243125961363 | validation: 0.3012476590892315]
	TIME [epoch: 27.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3160364938318384		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.3160364938318384 | validation: 0.27979949583158387]
	TIME [epoch: 27.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30147649533006743		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.30147649533006743 | validation: 0.28588293197889203]
	TIME [epoch: 27.7 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29247746560516374		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.29247746560516374 | validation: 0.27965899328991894]
	TIME [epoch: 27.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29032635773032295		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.29032635773032295 | validation: 0.26090841370506296]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_694.pth
	Model improved!!!
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2781032293176394		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.2781032293176394 | validation: 0.2787453805357607]
	TIME [epoch: 27.7 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3185534140656857		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.3185534140656857 | validation: 0.31371164088373027]
	TIME [epoch: 27.7 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3490943104745746		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.3490943104745746 | validation: 0.3827812545187756]
	TIME [epoch: 27.7 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39472263392586177		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.39472263392586177 | validation: 0.3914767061517298]
	TIME [epoch: 27.7 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3969258720250129		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.3969258720250129 | validation: 0.42075186325835057]
	TIME [epoch: 27.6 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45201189053998925		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.45201189053998925 | validation: 0.3743038691364602]
	TIME [epoch: 27.7 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3434359504130737		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.3434359504130737 | validation: 0.28178490781960364]
	TIME [epoch: 27.7 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3174322304206375		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.3174322304206375 | validation: 0.2940791573179579]
	TIME [epoch: 27.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3422403548132854		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.3422403548132854 | validation: 0.3457095504515869]
	TIME [epoch: 27.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3560930780393132		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.3560930780393132 | validation: 0.34280105920623355]
	TIME [epoch: 27.7 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35332461067706006		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.35332461067706006 | validation: 0.3505790271140218]
	TIME [epoch: 27.7 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35751341270830306		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.35751341270830306 | validation: 0.3221748208516602]
	TIME [epoch: 27.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34668723554811387		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.34668723554811387 | validation: 0.35885550163909585]
	TIME [epoch: 27.7 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.439068290875006		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.439068290875006 | validation: 0.4567856426272675]
	TIME [epoch: 27.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41743754398156924		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.41743754398156924 | validation: 0.3697165017078757]
	TIME [epoch: 27.7 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37307738978835403		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.37307738978835403 | validation: 0.36068447652226665]
	TIME [epoch: 27.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3545424817481938		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.3545424817481938 | validation: 0.3312978631497025]
	TIME [epoch: 27.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32002218244674097		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.32002218244674097 | validation: 0.35270843720538736]
	TIME [epoch: 27.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36735007719652274		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.36735007719652274 | validation: 0.3258413023158351]
	TIME [epoch: 27.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32265423790855136		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.32265423790855136 | validation: 0.2901559849473409]
	TIME [epoch: 27.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.339185886080863		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.339185886080863 | validation: 0.37143956577523457]
	TIME [epoch: 27.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39590190779731904		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.39590190779731904 | validation: 0.43293378204963306]
	TIME [epoch: 27.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.397943873444956		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.397943873444956 | validation: 0.30804585929795375]
	TIME [epoch: 27.7 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30435281484992216		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.30435281484992216 | validation: 0.28866361941635793]
	TIME [epoch: 27.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.320452574559779		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.320452574559779 | validation: 0.3188979278405513]
	TIME [epoch: 27.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31875072380756325		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.31875072380756325 | validation: 0.3241173293062621]
	TIME [epoch: 27.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3380450813407716		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.3380450813407716 | validation: 0.3232086572055483]
	TIME [epoch: 27.7 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34550990578502544		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.34550990578502544 | validation: 0.34402076330811243]
	TIME [epoch: 27.7 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32372856078882134		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.32372856078882134 | validation: 0.27804951664590566]
	TIME [epoch: 27.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2905921695652045		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.2905921695652045 | validation: 0.2914530253795537]
	TIME [epoch: 27.8 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34146728522683084		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.34146728522683084 | validation: 0.3151199873417977]
	TIME [epoch: 27.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30121242257410513		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.30121242257410513 | validation: 0.25689444152240176]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_726.pth
	Model improved!!!
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27945722213618296		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.27945722213618296 | validation: 0.29578538982979297]
	TIME [epoch: 27.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2933306331885757		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.2933306331885757 | validation: 0.2703207958516909]
	TIME [epoch: 27.7 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3189479097760217		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.3189479097760217 | validation: 0.3017414997369419]
	TIME [epoch: 27.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3054084219167723		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.3054084219167723 | validation: 0.29108625646618186]
	TIME [epoch: 27.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2865347881833944		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.2865347881833944 | validation: 0.2682772045747311]
	TIME [epoch: 27.7 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28322098690614494		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.28322098690614494 | validation: 0.30873056219567024]
	TIME [epoch: 27.7 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36105313186103155		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.36105313186103155 | validation: 0.4417827424725405]
	TIME [epoch: 27.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49995343783589086		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.49995343783589086 | validation: 0.4388813956559352]
	TIME [epoch: 27.7 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38043898643387525		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.38043898643387525 | validation: 0.3275514900539925]
	TIME [epoch: 27.7 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3562316222050127		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.3562316222050127 | validation: 0.3818776615427684]
	TIME [epoch: 27.7 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3671229515207482		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.3671229515207482 | validation: 0.33135373684471037]
	TIME [epoch: 27.7 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35556601022813344		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.35556601022813344 | validation: 0.3273226090685725]
	TIME [epoch: 27.7 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31603744141219786		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.31603744141219786 | validation: 0.2722488823749535]
	TIME [epoch: 27.7 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29159334845014545		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.29159334845014545 | validation: 0.269928580770617]
	TIME [epoch: 27.7 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27261653625109084		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.27261653625109084 | validation: 0.2642584413190686]
	TIME [epoch: 27.7 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2949980174855675		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.2949980174855675 | validation: 0.3035436919583343]
	TIME [epoch: 27.7 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3603981878705009		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.3603981878705009 | validation: 0.36598685451732865]
	TIME [epoch: 27.7 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3449258246251678		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.3449258246251678 | validation: 0.2921970609714423]
	TIME [epoch: 27.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32492945801128803		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.32492945801128803 | validation: 0.3206737664902608]
	TIME [epoch: 27.7 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3056459208208393		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.3056459208208393 | validation: 0.29186099130545345]
	TIME [epoch: 27.7 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3075394525525712		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.3075394525525712 | validation: 0.277309464464804]
	TIME [epoch: 27.7 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2888606698278104		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.2888606698278104 | validation: 0.3015424204977382]
	TIME [epoch: 27.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28982986786190856		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.28982986786190856 | validation: 0.31179063582277666]
	TIME [epoch: 27.7 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34295428222525975		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.34295428222525975 | validation: 0.3450616340378126]
	TIME [epoch: 27.7 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46008204264086694		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.46008204264086694 | validation: 0.572801993851312]
	TIME [epoch: 27.7 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5034575741906606		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.5034575741906606 | validation: 0.4305921919203901]
	TIME [epoch: 27.7 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.424577778180964		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.424577778180964 | validation: 0.4106323756196794]
	TIME [epoch: 27.7 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42713057879735766		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.42713057879735766 | validation: 0.38202932323388333]
	TIME [epoch: 27.7 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36983031112759246		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.36983031112759246 | validation: 0.3249924377618048]
	TIME [epoch: 27.7 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30738544750525654		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.30738544750525654 | validation: 0.26880953143918634]
	TIME [epoch: 27.7 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27807433655491576		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.27807433655491576 | validation: 0.2617333773273563]
	TIME [epoch: 27.7 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27062179841356077		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.27062179841356077 | validation: 0.2672743099771836]
	TIME [epoch: 27.7 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28406556131521765		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.28406556131521765 | validation: 0.25868712095693136]
	TIME [epoch: 27.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2809329792909372		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.2809329792909372 | validation: 0.29728368561002094]
	TIME [epoch: 27.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29136503492051774		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.29136503492051774 | validation: 0.27722909272026514]
	TIME [epoch: 27.7 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27630516614454953		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.27630516614454953 | validation: 0.2861313577158598]
	TIME [epoch: 27.7 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2881719199607923		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.2881719199607923 | validation: 0.3125728685028497]
	TIME [epoch: 27.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30432279314456906		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.30432279314456906 | validation: 0.28091594053920865]
	TIME [epoch: 27.8 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31025316063977504		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.31025316063977504 | validation: 0.3445975349447719]
	TIME [epoch: 27.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33383590012922937		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.33383590012922937 | validation: 0.341030450619864]
	TIME [epoch: 27.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3573711936176646		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.3573711936176646 | validation: 0.3794369363706461]
	TIME [epoch: 27.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39256017222612527		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.39256017222612527 | validation: 0.4070438406722312]
	TIME [epoch: 27.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3795398706692348		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.3795398706692348 | validation: 0.34254053492191394]
	TIME [epoch: 27.7 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3053089840865803		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.3053089840865803 | validation: 0.26910155240026984]
	TIME [epoch: 27.7 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27155793868046285		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.27155793868046285 | validation: 0.2853992751162608]
	TIME [epoch: 27.8 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27234888655936285		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.27234888655936285 | validation: 0.29946688043686825]
	TIME [epoch: 27.7 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2899184678213709		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.2899184678213709 | validation: 0.29673178810851203]
	TIME [epoch: 27.7 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29710521677038404		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.29710521677038404 | validation: 0.31236119186767064]
	TIME [epoch: 27.7 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28578067598116597		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.28578067598116597 | validation: 0.2642906600400146]
	TIME [epoch: 27.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26095609816983645		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.26095609816983645 | validation: 0.25803416849733796]
	TIME [epoch: 27.7 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27616488391924526		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.27616488391924526 | validation: 0.30037340729717055]
	TIME [epoch: 27.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2851087477844461		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.2851087477844461 | validation: 0.28176799708556494]
	TIME [epoch: 27.7 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26603056913858286		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.26603056913858286 | validation: 0.25555755230983185]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_779.pth
	Model improved!!!
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2625954104455849		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.2625954104455849 | validation: 0.2663526459854404]
	TIME [epoch: 27.7 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2580514885574974		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.2580514885574974 | validation: 0.24991046704761055]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_781.pth
	Model improved!!!
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26466696779805576		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.26466696779805576 | validation: 0.29003048844477136]
	TIME [epoch: 27.7 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27655334063012793		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.27655334063012793 | validation: 0.25801362986086784]
	TIME [epoch: 27.7 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2803623174343396		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.2803623174343396 | validation: 0.29276428154417244]
	TIME [epoch: 27.7 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30727713025131564		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.30727713025131564 | validation: 0.3266742194944186]
	TIME [epoch: 27.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29282342280771434		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.29282342280771434 | validation: 0.25553350804714897]
	TIME [epoch: 27.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2681059721706824		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.2681059721706824 | validation: 0.26878650727691045]
	TIME [epoch: 27.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26052884614327027		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.26052884614327027 | validation: 0.2513242757453573]
	TIME [epoch: 27.7 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.259251794564448		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.259251794564448 | validation: 0.2631927120247511]
	TIME [epoch: 27.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2935156400809735		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.2935156400809735 | validation: 0.3115808721080127]
	TIME [epoch: 27.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28239793024900745		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.28239793024900745 | validation: 0.27758392548348987]
	TIME [epoch: 27.7 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2586083181149052		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.2586083181149052 | validation: 0.2560055203981252]
	TIME [epoch: 27.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25762118747527063		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.25762118747527063 | validation: 0.3050513746101875]
	TIME [epoch: 27.8 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30648385462829353		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.30648385462829353 | validation: 0.30610636031559796]
	TIME [epoch: 27.7 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3144201675421161		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.3144201675421161 | validation: 0.34625977558912147]
	TIME [epoch: 27.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3270561490079497		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.3270561490079497 | validation: 0.30416240217275176]
	TIME [epoch: 27.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3352306669114901		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.3352306669114901 | validation: 0.3205732231068344]
	TIME [epoch: 27.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2856524336726559		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.2856524336726559 | validation: 0.25730695370077283]
	TIME [epoch: 27.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2628158572812564		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.2628158572812564 | validation: 0.2619963507166524]
	TIME [epoch: 27.7 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2555764241330609		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.2555764241330609 | validation: 0.24516084521982323]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_800.pth
	Model improved!!!
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2469571103889327		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.2469571103889327 | validation: 0.256249075355642]
	TIME [epoch: 27.7 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2862465698828273		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.2862465698828273 | validation: 0.2709597399892854]
	TIME [epoch: 27.6 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26496061968424445		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.26496061968424445 | validation: 0.2889962225692068]
	TIME [epoch: 27.7 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3050153548357505		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.3050153548357505 | validation: 0.30154817239251386]
	TIME [epoch: 27.7 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3261285187541019		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.3261285187541019 | validation: 0.41609584098763636]
	TIME [epoch: 27.7 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3718086235352088		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.3718086235352088 | validation: 0.27539020778978385]
	TIME [epoch: 27.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27329833386651387		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.27329833386651387 | validation: 0.27022969074687725]
	TIME [epoch: 27.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2686656518278583		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.2686656518278583 | validation: 0.2544710969420548]
	TIME [epoch: 27.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2655045973754388		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.2655045973754388 | validation: 0.2982542330766322]
	TIME [epoch: 27.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32544046001021737		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.32544046001021737 | validation: 0.2893989850883079]
	TIME [epoch: 27.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27564182973793017		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.27564182973793017 | validation: 0.2415668584614247]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_811.pth
	Model improved!!!
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24649508808909976		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.24649508808909976 | validation: 0.2521220525093569]
	TIME [epoch: 27.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2531934564900573		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.2531934564900573 | validation: 0.2522056160970428]
	TIME [epoch: 27.7 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26464675809636945		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.26464675809636945 | validation: 0.2701359388392555]
	TIME [epoch: 27.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29823820891800873		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.29823820891800873 | validation: 0.33039003324867977]
	TIME [epoch: 27.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3637749062177821		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.3637749062177821 | validation: 0.3746079026673296]
	TIME [epoch: 27.7 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3365500465034025		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.3365500465034025 | validation: 0.29003446056906046]
	TIME [epoch: 27.7 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2727322444132647		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.2727322444132647 | validation: 0.2773834116250598]
	TIME [epoch: 27.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2794247976004134		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.2794247976004134 | validation: 0.2599934629795384]
	TIME [epoch: 27.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25375913035133824		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.25375913035133824 | validation: 0.2628954557458881]
	TIME [epoch: 27.7 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2601094593108652		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.2601094593108652 | validation: 0.2686634898738277]
	TIME [epoch: 27.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.271829049447226		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.271829049447226 | validation: 0.265249783026126]
	TIME [epoch: 27.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.278545174081087		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.278545174081087 | validation: 0.29461688012462167]
	TIME [epoch: 27.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27421779555500514		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.27421779555500514 | validation: 0.2633532618806882]
	TIME [epoch: 27.8 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26106759498624627		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.26106759498624627 | validation: 0.2621586943356345]
	TIME [epoch: 27.7 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2530785764717196		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.2530785764717196 | validation: 0.2571695310626804]
	TIME [epoch: 27.7 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25219236598771627		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.25219236598771627 | validation: 0.23812379044097387]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_827.pth
	Model improved!!!
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24836072337346493		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.24836072337346493 | validation: 0.25104885311878467]
	TIME [epoch: 27.7 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26753300593018076		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.26753300593018076 | validation: 0.264515396517326]
	TIME [epoch: 27.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25893965089255067		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.25893965089255067 | validation: 0.2349289849197793]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_830.pth
	Model improved!!!
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2414989840370722		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.2414989840370722 | validation: 0.24467443261321578]
	TIME [epoch: 27.7 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.241579887278696		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.241579887278696 | validation: 0.23187384925938154]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_832.pth
	Model improved!!!
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2603075378901191		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.2603075378901191 | validation: 0.24775194450363766]
	TIME [epoch: 27.7 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24430913646513971		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.24430913646513971 | validation: 0.24327903923043565]
	TIME [epoch: 27.7 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2347833682393357		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.2347833682393357 | validation: 0.23079252524810887]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_835.pth
	Model improved!!!
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2510220831603342		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.2510220831603342 | validation: 0.2781652202515745]
	TIME [epoch: 27.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30677083196457355		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.30677083196457355 | validation: 0.3046796715870545]
	TIME [epoch: 27.6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3221228612891477		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.3221228612891477 | validation: 0.3432718016339854]
	TIME [epoch: 27.7 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35583897777217566		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.35583897777217566 | validation: 0.35985421981099025]
	TIME [epoch: 27.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34779015685790565		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.34779015685790565 | validation: 0.3416000536734895]
	TIME [epoch: 27.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3281737678219711		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.3281737678219711 | validation: 0.32337536962701713]
	TIME [epoch: 27.7 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33979810673256294		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.33979810673256294 | validation: 0.33439810470329767]
	TIME [epoch: 27.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32656657787623505		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.32656657787623505 | validation: 0.3735881744627821]
	TIME [epoch: 27.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41238569246506473		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.41238569246506473 | validation: 0.44571018914819077]
	TIME [epoch: 27.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44195371319735277		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.44195371319735277 | validation: 0.3917075795831255]
	TIME [epoch: 27.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38396067279719515		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.38396067279719515 | validation: 0.35638089705639814]
	TIME [epoch: 27.7 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3316753635346559		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.3316753635346559 | validation: 0.2945633751346102]
	TIME [epoch: 27.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2884781914795863		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.2884781914795863 | validation: 0.27066988511298895]
	TIME [epoch: 27.7 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28379308429216754		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.28379308429216754 | validation: 0.2776004790130032]
	TIME [epoch: 27.7 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28314017674843517		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.28314017674843517 | validation: 0.32157672898427897]
	TIME [epoch: 27.7 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.347318617651076		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.347318617651076 | validation: 0.3201359648735364]
	TIME [epoch: 27.7 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3063848876806746		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.3063848876806746 | validation: 0.3006786859207534]
	TIME [epoch: 27.7 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2940106421792612		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.2940106421792612 | validation: 0.25967648112358893]
	TIME [epoch: 27.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28915865361648385		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.28915865361648385 | validation: 0.28786651672908364]
	TIME [epoch: 27.7 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29345985123458485		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.29345985123458485 | validation: 0.292677522621158]
	TIME [epoch: 27.7 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.293019953102665		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.293019953102665 | validation: 0.3189872464885121]
	TIME [epoch: 27.7 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2976176596450401		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.2976176596450401 | validation: 0.27731312380283163]
	TIME [epoch: 27.7 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2689304622816516		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.2689304622816516 | validation: 0.255307716015025]
	TIME [epoch: 27.7 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26723920074139806		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.26723920074139806 | validation: 0.26329511276055395]
	TIME [epoch: 27.7 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2666270331831018		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.2666270331831018 | validation: 0.2673323112581008]
	TIME [epoch: 27.7 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26517805084903595		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.26517805084903595 | validation: 0.24660815917234225]
	TIME [epoch: 27.7 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27131080913673544		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.27131080913673544 | validation: 0.2946504373646786]
	TIME [epoch: 27.7 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27909696381329596		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.27909696381329596 | validation: 0.24076137619837973]
	TIME [epoch: 27.7 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2400730910408228		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.2400730910408228 | validation: 0.2274899216497314]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_864.pth
	Model improved!!!
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2265495017546905		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.2265495017546905 | validation: 0.2350834656033999]
	TIME [epoch: 27.7 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2412128653598328		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.2412128653598328 | validation: 0.24715012376735426]
	TIME [epoch: 27.7 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2281269046508658		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.2281269046508658 | validation: 0.2428480433120619]
	TIME [epoch: 27.7 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2319041628014835		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.2319041628014835 | validation: 0.2526491803922415]
	TIME [epoch: 27.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23964769432515817		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.23964769432515817 | validation: 0.23102441968261542]
	TIME [epoch: 27.7 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23624632235911855		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.23624632235911855 | validation: 0.2607517861894412]
	TIME [epoch: 27.7 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26497058177830546		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.26497058177830546 | validation: 0.23704471240655078]
	TIME [epoch: 27.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2583812761725983		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.2583812761725983 | validation: 0.25086436377807236]
	TIME [epoch: 27.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24322250629951206		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.24322250629951206 | validation: 0.2260735153259369]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_873.pth
	Model improved!!!
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23635346036357888		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.23635346036357888 | validation: 0.22162037914602262]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_874.pth
	Model improved!!!
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23253251445019177		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.23253251445019177 | validation: 0.2408466528223245]
	TIME [epoch: 27.7 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23771513250913062		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.23771513250913062 | validation: 0.2263635981806236]
	TIME [epoch: 27.8 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2368494006322234		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.2368494006322234 | validation: 0.23232634821734832]
	TIME [epoch: 27.7 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2332379797948283		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.2332379797948283 | validation: 0.2520484194426477]
	TIME [epoch: 27.6 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23052894448591055		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.23052894448591055 | validation: 0.21077181770047557]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_879.pth
	Model improved!!!
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2155414679881931		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.2155414679881931 | validation: 0.22441847840183804]
	TIME [epoch: 27.7 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2246999786904082		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.2246999786904082 | validation: 0.22712855570335475]
	TIME [epoch: 27.7 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23005738460293276		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.23005738460293276 | validation: 0.23424756558790813]
	TIME [epoch: 27.8 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24401045770290622		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.24401045770290622 | validation: 0.24460600980552893]
	TIME [epoch: 27.8 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2369527790296299		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.2369527790296299 | validation: 0.2133990973249135]
	TIME [epoch: 27.7 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22107895988343595		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.22107895988343595 | validation: 0.2391190254606429]
	TIME [epoch: 27.7 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24880903153378386		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.24880903153378386 | validation: 0.25314705795379977]
	TIME [epoch: 27.7 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24555009819016727		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.24555009819016727 | validation: 0.24278152104387596]
	TIME [epoch: 27.8 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.240390433746486		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.240390433746486 | validation: 0.24370657662316386]
	TIME [epoch: 27.8 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23944021832832502		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.23944021832832502 | validation: 0.23313578298369866]
	TIME [epoch: 27.8 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24330155878244386		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.24330155878244386 | validation: 0.24585457098412425]
	TIME [epoch: 27.7 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27927050286633376		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.27927050286633376 | validation: 0.2944745567935652]
	TIME [epoch: 27.8 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26246569535114916		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.26246569535114916 | validation: 0.2284504798287635]
	TIME [epoch: 27.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22245386052056648		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.22245386052056648 | validation: 0.2287214727099499]
	TIME [epoch: 27.7 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22645552000634353		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.22645552000634353 | validation: 0.22137704207813008]
	TIME [epoch: 27.8 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2225862300007217		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.2225862300007217 | validation: 0.21717323493006294]
	TIME [epoch: 27.6 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22992306574486068		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.22992306574486068 | validation: 0.23682080333339478]
	TIME [epoch: 27.7 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22866651858086523		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.22866651858086523 | validation: 0.20968998353523055]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_897.pth
	Model improved!!!
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21769559498912083		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.21769559498912083 | validation: 0.21722885147013146]
	TIME [epoch: 27.7 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2198071236398014		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.2198071236398014 | validation: 0.2109576421973654]
	TIME [epoch: 27.8 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22543093889098834		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.22543093889098834 | validation: 0.23450222080667218]
	TIME [epoch: 27.8 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2577298271917906		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.2577298271917906 | validation: 0.26259598616369817]
	TIME [epoch: 27.8 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2545902957245685		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.2545902957245685 | validation: 0.23718594488018702]
	TIME [epoch: 27.8 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2293258306316648		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.2293258306316648 | validation: 0.21505358112736261]
	TIME [epoch: 27.8 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22494847621186048		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.22494847621186048 | validation: 0.23617811460871238]
	TIME [epoch: 27.7 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.226183666484291		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.226183666484291 | validation: 0.2392284878779249]
	TIME [epoch: 27.8 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23133354338432735		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.23133354338432735 | validation: 0.23351919417279796]
	TIME [epoch: 27.8 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23235012268896693		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.23235012268896693 | validation: 0.2418013693803117]
	TIME [epoch: 27.8 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22802120862189346		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.22802120862189346 | validation: 0.22415424884597143]
	TIME [epoch: 27.8 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2243497245601671		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.2243497245601671 | validation: 0.21971116513863506]
	TIME [epoch: 27.8 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2272152906366579		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.2272152906366579 | validation: 0.2263935299019555]
	TIME [epoch: 27.7 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22287261819604695		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.22287261819604695 | validation: 0.2321580288042715]
	TIME [epoch: 27.8 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22089139592015983		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.22089139592015983 | validation: 0.22210469572950886]
	TIME [epoch: 27.7 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2311662044988584		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.2311662044988584 | validation: 0.24738258023495227]
	TIME [epoch: 27.8 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23582570827723495		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.23582570827723495 | validation: 0.23083161816006495]
	TIME [epoch: 27.8 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22727091164098873		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.22727091164098873 | validation: 0.23134055427946745]
	TIME [epoch: 27.8 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22243310889751594		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.22243310889751594 | validation: 0.20847847736724295]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_916.pth
	Model improved!!!
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21182293443093653		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.21182293443093653 | validation: 0.20792600229376404]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_917.pth
	Model improved!!!
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21337127827822028		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.21337127827822028 | validation: 0.21351042139080348]
	TIME [epoch: 27.7 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2114728682814546		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.2114728682814546 | validation: 0.2113727119714492]
	TIME [epoch: 27.7 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20915384084028532		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.20915384084028532 | validation: 0.19911928895854783]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_920.pth
	Model improved!!!
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2107794903003845		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.2107794903003845 | validation: 0.22004308860509036]
	TIME [epoch: 27.8 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2202812214402532		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.2202812214402532 | validation: 0.22211555104397895]
	TIME [epoch: 27.7 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21834388046348394		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.21834388046348394 | validation: 0.22249544718565534]
	TIME [epoch: 27.7 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2219091706721248		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.2219091706721248 | validation: 0.20867472935085832]
	TIME [epoch: 27.7 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20923722447066276		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.20923722447066276 | validation: 0.2190988243506245]
	TIME [epoch: 27.7 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.220878040929997		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.220878040929997 | validation: 0.21217875831065583]
	TIME [epoch: 27.7 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2075291733272005		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.2075291733272005 | validation: 0.2084401378329119]
	TIME [epoch: 27.7 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.219779113392442		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.219779113392442 | validation: 0.2368759673183747]
	TIME [epoch: 27.7 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25586988298010827		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.25586988298010827 | validation: 0.28718034942403037]
	TIME [epoch: 27.7 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2685134752989313		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.2685134752989313 | validation: 0.2506517064736415]
	TIME [epoch: 27.7 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2671217498205487		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.2671217498205487 | validation: 0.30887840186715004]
	TIME [epoch: 27.7 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3216741243306761		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.3216741243306761 | validation: 0.3166542810801476]
	TIME [epoch: 27.7 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3195244208033088		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.3195244208033088 | validation: 0.2919689402628251]
	TIME [epoch: 27.6 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2829220334471309		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.2829220334471309 | validation: 0.28163833579738234]
	TIME [epoch: 27.7 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3059515238734053		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.3059515238734053 | validation: 0.3491746567453899]
	TIME [epoch: 27.7 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3808624086099245		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.3808624086099245 | validation: 0.3566091047826042]
	TIME [epoch: 27.7 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3431487095462878		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.3431487095462878 | validation: 0.3230672535783647]
	TIME [epoch: 27.7 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3041474347536414		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.3041474347536414 | validation: 0.28115764595297466]
	TIME [epoch: 27.7 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27212946875052046		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.27212946875052046 | validation: 0.2504045788680914]
	TIME [epoch: 27.7 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2457418359681182		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.2457418359681182 | validation: 0.23245002016255034]
	TIME [epoch: 27.7 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2276068902972403		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.2276068902972403 | validation: 0.24174801051240485]
	TIME [epoch: 27.7 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23101164227911908		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.23101164227911908 | validation: 0.2208137510157571]
	TIME [epoch: 27.7 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2211152719740127		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.2211152719740127 | validation: 0.2137585183304846]
	TIME [epoch: 27.7 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21818714466018863		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.21818714466018863 | validation: 0.20396544311950382]
	TIME [epoch: 27.7 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20688106258288547		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.20688106258288547 | validation: 0.20950431846039358]
	TIME [epoch: 27.7 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2095219201534462		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.2095219201534462 | validation: 0.22584366542903148]
	TIME [epoch: 27.7 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2056693533439881		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.2056693533439881 | validation: 0.2090095305705628]
	TIME [epoch: 27.7 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2039597002924588		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.2039597002924588 | validation: 0.19909899351878546]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_948.pth
	Model improved!!!
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20080867137602532		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.20080867137602532 | validation: 0.19700382016238396]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_949.pth
	Model improved!!!
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20347816068235167		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.20347816068235167 | validation: 0.20375544561728196]
	TIME [epoch: 27.7 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21580405695808674		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.21580405695808674 | validation: 0.22865914194393916]
	TIME [epoch: 27.7 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21684990507428742		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.21684990507428742 | validation: 0.20897497287261912]
	TIME [epoch: 27.7 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20695277128963271		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.20695277128963271 | validation: 0.20834616347752133]
	TIME [epoch: 27.7 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20535777540326852		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.20535777540326852 | validation: 0.20520101219673506]
	TIME [epoch: 27.7 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21735656470323036		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.21735656470323036 | validation: 0.23681205068006045]
	TIME [epoch: 27.7 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2466076388495591		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.2466076388495591 | validation: 0.2746920675398915]
	TIME [epoch: 27.7 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2716977049684345		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.2716977049684345 | validation: 0.2490442200750814]
	TIME [epoch: 27.7 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24096262754898573		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.24096262754898573 | validation: 0.2281027529646654]
	TIME [epoch: 27.7 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23423508349759714		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.23423508349759714 | validation: 0.2553136078052457]
	TIME [epoch: 27.7 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24884441908055938		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.24884441908055938 | validation: 0.2490714773880404]
	TIME [epoch: 27.7 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25868787016389316		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.25868787016389316 | validation: 0.2949021526140194]
	TIME [epoch: 27.7 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2736791054475968		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.2736791054475968 | validation: 0.24851829263953273]
	TIME [epoch: 27.7 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24047567598721425		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.24047567598721425 | validation: 0.24412498980718997]
	TIME [epoch: 27.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25023149850725174		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.25023149850725174 | validation: 0.2677158381234872]
	TIME [epoch: 27.7 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2830550071240281		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.2830550071240281 | validation: 0.29526060716363683]
	TIME [epoch: 27.7 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29323441413588036		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.29323441413588036 | validation: 0.26907535105908503]
	TIME [epoch: 27.7 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2774673530848868		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.2774673530848868 | validation: 0.2547150056022058]
	TIME [epoch: 27.7 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24547567413067087		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.24547567413067087 | validation: 0.2270633791272081]
	TIME [epoch: 27.7 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23320274945550087		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.23320274945550087 | validation: 0.23894219786174553]
	TIME [epoch: 27.7 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22509423689481284		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.22509423689481284 | validation: 0.20634365688752987]
	TIME [epoch: 27.7 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2151136668448887		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.2151136668448887 | validation: 0.22173592986444304]
	TIME [epoch: 27.7 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2267250218022888		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.2267250218022888 | validation: 0.24149635341542425]
	TIME [epoch: 27.8 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2248785502581868		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.2248785502581868 | validation: 0.22206045584293893]
	TIME [epoch: 27.7 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2224907349309182		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.2224907349309182 | validation: 0.22489071750079326]
	TIME [epoch: 27.7 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21457229007937892		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.21457229007937892 | validation: 0.23171670767744354]
	TIME [epoch: 27.7 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22251298446501283		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.22251298446501283 | validation: 0.23724671325849783]
	TIME [epoch: 27.8 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22889348582468486		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.22889348582468486 | validation: 0.2277696843372167]
	TIME [epoch: 27.8 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23705304370309377		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.23705304370309377 | validation: 0.2454127034838337]
	TIME [epoch: 27.7 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24443772473289072		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.24443772473289072 | validation: 0.2572844621107059]
	TIME [epoch: 27.7 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2352425317220619		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.2352425317220619 | validation: 0.21440698441656977]
	TIME [epoch: 27.8 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21828601464669142		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.21828601464669142 | validation: 0.2103556857787879]
	TIME [epoch: 27.7 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22069091406653177		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.22069091406653177 | validation: 0.2383819071767534]
	TIME [epoch: 27.7 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22794168473342363		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.22794168473342363 | validation: 0.23414401721612485]
	TIME [epoch: 27.7 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22306936299803887		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.22306936299803887 | validation: 0.24051504981705385]
	TIME [epoch: 27.7 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24696523240824267		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.24696523240824267 | validation: 0.25528740315603893]
	TIME [epoch: 27.8 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24131792881140757		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.24131792881140757 | validation: 0.24184920204100413]
	TIME [epoch: 27.7 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2541270289391509		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.2541270289391509 | validation: 0.25788155027029624]
	TIME [epoch: 27.7 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26801923881175643		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.26801923881175643 | validation: 0.2701140726028395]
	TIME [epoch: 27.7 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2676343635603142		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.2676343635603142 | validation: 0.2727361372603507]
	TIME [epoch: 27.7 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28660255924844585		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.28660255924844585 | validation: 0.3012830506942217]
	TIME [epoch: 27.7 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29334302640825266		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.29334302640825266 | validation: 0.2505345187968395]
	TIME [epoch: 27.7 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25481118187443774		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.25481118187443774 | validation: 0.2405163416724328]
	TIME [epoch: 27.7 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22940710045443719		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.22940710045443719 | validation: 0.22180138984024783]
	TIME [epoch: 27.8 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21813538850681258		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.21813538850681258 | validation: 0.22904164020958384]
	TIME [epoch: 27.7 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25125652732994097		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.25125652732994097 | validation: 0.24669856235245355]
	TIME [epoch: 27.7 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2706416984361635		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.2706416984361635 | validation: 0.26666444297455405]
	TIME [epoch: 27.7 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2789791149431695		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.2789791149431695 | validation: 0.2521370475744242]
	TIME [epoch: 27.7 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2575744679562702		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.2575744679562702 | validation: 0.22809647699237035]
	TIME [epoch: 27.8 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22198598639707998		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.22198598639707998 | validation: 0.20316696363590184]
	TIME [epoch: 27.7 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21485571839376483		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.21485571839376483 | validation: 0.2187590042458315]
	TIME [epoch: 27.7 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2169385250010225		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.2169385250010225 | validation: 0.20502446177664638]
	TIME [epoch: 27.7 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20119747544742145		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.20119747544742145 | validation: 0.19867397969695005]
	TIME [epoch: 27.7 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20220801598126342		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.20220801598126342 | validation: 0.1965021675412509]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_1003.pth
	Model improved!!!
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1983812227885497		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.1983812227885497 | validation: 0.19956144434307518]
	TIME [epoch: 27.7 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19969030196561013		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.19969030196561013 | validation: 0.19840451202005713]
	TIME [epoch: 27.8 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20172421750530464		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.20172421750530464 | validation: 0.21037718470886232]
	TIME [epoch: 27.8 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2412318990702086		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.2412318990702086 | validation: 0.2443784493769288]
	TIME [epoch: 27.8 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2787350896128531		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.2787350896128531 | validation: 0.33965699952905143]
	TIME [epoch: 27.8 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301549666286827		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.3301549666286827 | validation: 0.27389205317084797]
	TIME [epoch: 27.7 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2677616631014851		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.2677616631014851 | validation: 0.26011428854082064]
	TIME [epoch: 27.7 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2559403364414632		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.2559403364414632 | validation: 0.24921677252208]
	TIME [epoch: 27.7 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.260225020029213		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.260225020029213 | validation: 0.2626191950074082]
	TIME [epoch: 27.8 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26442736869599703		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.26442736869599703 | validation: 0.24850996664268862]
	TIME [epoch: 27.8 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23117448301769583		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.23117448301769583 | validation: 0.23486724718168853]
	TIME [epoch: 27.8 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23154915080541144		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.23154915080541144 | validation: 0.22022081106482155]
	TIME [epoch: 27.8 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21025340599091014		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.21025340599091014 | validation: 0.22498343000588808]
	TIME [epoch: 27.8 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20372875309425403		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.20372875309425403 | validation: 0.1942198696844862]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_1017.pth
	Model improved!!!
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20755931313757722		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.20755931313757722 | validation: 0.21192180931427795]
	TIME [epoch: 27.8 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22126876931681116		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.22126876931681116 | validation: 0.21750913150650747]
	TIME [epoch: 27.7 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22107569074507066		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.22107569074507066 | validation: 0.2171234052224505]
	TIME [epoch: 27.8 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21413065841040524		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.21413065841040524 | validation: 0.191504294768519]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_1021.pth
	Model improved!!!
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2045857560403641		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.2045857560403641 | validation: 0.20678505070838923]
	TIME [epoch: 27.7 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22012866330477543		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.22012866330477543 | validation: 0.21944582796654413]
	TIME [epoch: 27.6 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22008509317307334		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.22008509317307334 | validation: 0.2120259470820636]
	TIME [epoch: 27.6 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2151458322118895		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.2151458322118895 | validation: 0.21769271864451997]
	TIME [epoch: 27.6 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21570159433853756		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.21570159433853756 | validation: 0.21526903906249398]
	TIME [epoch: 27.7 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2288268987711248		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.2288268987711248 | validation: 0.2195057141188866]
	TIME [epoch: 27.8 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21881264072287188		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.21881264072287188 | validation: 0.2122941216516444]
	TIME [epoch: 27.7 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2188163394575495		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.2188163394575495 | validation: 0.2154766212563341]
	TIME [epoch: 27.8 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21459612650712148		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.21459612650712148 | validation: 0.21630197444764845]
	TIME [epoch: 27.8 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22820966017054067		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.22820966017054067 | validation: 0.21633815291932848]
	TIME [epoch: 27.7 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2156233211342815		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.2156233211342815 | validation: 0.19943910473507787]
	TIME [epoch: 27.7 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2200878678249148		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.2200878678249148 | validation: 0.21084802801315083]
	TIME [epoch: 27.7 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21544808887988975		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.21544808887988975 | validation: 0.19239257601124105]
	TIME [epoch: 27.8 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2007804388656985		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.2007804388656985 | validation: 0.19364821420687658]
	TIME [epoch: 27.7 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20701157117289787		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.20701157117289787 | validation: 0.20111977988365137]
	TIME [epoch: 27.7 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21598642292720294		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.21598642292720294 | validation: 0.2200185221474893]
	TIME [epoch: 27.7 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2339233764832226		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.2339233764832226 | validation: 0.22695130726002163]
	TIME [epoch: 27.7 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23332363591618316		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.23332363591618316 | validation: 0.21306183577533552]
	TIME [epoch: 27.8 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2138947728536758		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.2138947728536758 | validation: 0.19894178118678527]
	TIME [epoch: 27.7 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20255163850056393		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.20255163850056393 | validation: 0.19773638194589566]
	TIME [epoch: 27.7 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20371782560005902		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.20371782560005902 | validation: 0.2047669079338641]
	TIME [epoch: 27.7 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20735464246468083		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.20735464246468083 | validation: 0.18725811873603873]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_1043.pth
	Model improved!!!
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20002053115969623		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.20002053115969623 | validation: 0.18835065097106848]
	TIME [epoch: 27.7 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19336677003751263		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.19336677003751263 | validation: 0.1975075471773991]
	TIME [epoch: 27.7 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19273609657403076		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.19273609657403076 | validation: 0.19529806580874032]
	TIME [epoch: 27.7 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1917569125973772		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.1917569125973772 | validation: 0.19989563366823043]
	TIME [epoch: 27.7 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20325510845702582		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.20325510845702582 | validation: 0.20926278488209676]
	TIME [epoch: 27.7 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22432719261164025		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.22432719261164025 | validation: 0.2654423446630459]
	TIME [epoch: 27.7 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2726571290264441		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.2726571290264441 | validation: 0.25748128627910705]
	TIME [epoch: 27.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23762762438563384		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.23762762438563384 | validation: 0.20598216976863795]
	TIME [epoch: 27.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23080749241138954		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.23080749241138954 | validation: 0.24198227095888628]
	TIME [epoch: 27.7 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23673869297942962		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.23673869297942962 | validation: 0.2260143994556281]
	TIME [epoch: 27.7 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2530681431364722		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.2530681431364722 | validation: 0.2947121238591262]
	TIME [epoch: 27.7 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30052486013579555		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.30052486013579555 | validation: 0.31213155755349525]
	TIME [epoch: 27.7 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32333818829099037		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.32333818829099037 | validation: 0.3359437770706839]
	TIME [epoch: 27.7 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33670027409259884		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.33670027409259884 | validation: 0.3196398094944489]
	TIME [epoch: 27.7 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3062751888631593		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.3062751888631593 | validation: 0.26583163976597995]
	TIME [epoch: 27.8 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2527031327757583		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.2527031327757583 | validation: 0.2284146394923517]
	TIME [epoch: 27.8 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22573321965131632		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.22573321965131632 | validation: 0.21360710445295744]
	TIME [epoch: 27.7 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.209578108229909		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.209578108229909 | validation: 0.19713682030633137]
	TIME [epoch: 27.7 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20017349418247982		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.20017349418247982 | validation: 0.20406785745525752]
	TIME [epoch: 27.7 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21242647835091913		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.21242647835091913 | validation: 0.22121228592719774]
	TIME [epoch: 27.8 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21845070595512533		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.21845070595512533 | validation: 0.23012358605834654]
	TIME [epoch: 27.7 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21909414103722552		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.21909414103722552 | validation: 0.20897155148049243]
	TIME [epoch: 27.8 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2192339885436493		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.2192339885436493 | validation: 0.22935226638479114]
	TIME [epoch: 27.7 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24326514789884557		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.24326514789884557 | validation: 0.23393396234336616]
	TIME [epoch: 27.7 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22711634680112003		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.22711634680112003 | validation: 0.22276448416016942]
	TIME [epoch: 27.7 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22032755822214406		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.22032755822214406 | validation: 0.24283625718539717]
	TIME [epoch: 27.7 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2291420850111466		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.2291420850111466 | validation: 0.21633386082446365]
	TIME [epoch: 27.8 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2134311353948079		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.2134311353948079 | validation: 0.20768926807850743]
	TIME [epoch: 27.7 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20841596029924464		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.20841596029924464 | validation: 0.20377464146802848]
	TIME [epoch: 27.8 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19791350345815958		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.19791350345815958 | validation: 0.19982621114510707]
	TIME [epoch: 27.7 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2047674710370938		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.2047674710370938 | validation: 0.21326425255680806]
	TIME [epoch: 27.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21021401041723559		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.21021401041723559 | validation: 0.22254342495497345]
	TIME [epoch: 27.8 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21923948106170787		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.21923948106170787 | validation: 0.22985105713117013]
	TIME [epoch: 27.6 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2173350256303691		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.2173350256303691 | validation: 0.22071623936650395]
	TIME [epoch: 27.8 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2126539498823598		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.2126539498823598 | validation: 0.211427451858833]
	TIME [epoch: 27.8 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21005621598046928		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.21005621598046928 | validation: 0.20054498824800798]
	TIME [epoch: 27.7 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1995323184295122		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.1995323184295122 | validation: 0.20385784919643066]
	TIME [epoch: 27.7 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21435060056339608		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.21435060056339608 | validation: 0.22432321570371805]
	TIME [epoch: 27.7 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21950569776824064		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.21950569776824064 | validation: 0.22639654360311476]
	TIME [epoch: 27.8 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22432319421811295		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.22432319421811295 | validation: 0.23033413217503623]
	TIME [epoch: 27.8 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2311850708046434		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.2311850708046434 | validation: 0.2420548275985096]
	TIME [epoch: 27.7 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23102415868610107		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.23102415868610107 | validation: 0.22704310727939608]
	TIME [epoch: 27.8 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2197189886062476		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.2197189886062476 | validation: 0.22001160652177545]
	TIME [epoch: 27.7 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22270809216703574		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.22270809216703574 | validation: 0.2368313625133917]
	TIME [epoch: 27.8 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2356460167036249		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.2356460167036249 | validation: 0.2349262687891025]
	TIME [epoch: 27.7 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23538975736715131		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.23538975736715131 | validation: 0.2506463261199565]
	TIME [epoch: 27.6 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23880271141285395		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.23880271141285395 | validation: 0.24028112725663966]
	TIME [epoch: 27.7 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23712651590165898		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.23712651590165898 | validation: 0.2635373192992688]
	TIME [epoch: 27.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26280050549000705		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.26280050549000705 | validation: 0.25592261383090653]
	TIME [epoch: 27.7 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24579127295037864		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.24579127295037864 | validation: 0.25294527885511003]
	TIME [epoch: 27.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23817086804279614		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.23817086804279614 | validation: 0.23914549363085782]
	TIME [epoch: 27.8 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22501267614176254		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.22501267614176254 | validation: 0.22716121883876803]
	TIME [epoch: 27.8 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2250687543006209		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.2250687543006209 | validation: 0.2253448617430584]
	TIME [epoch: 27.8 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22647010075647248		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.22647010075647248 | validation: 0.22706813160867598]
	TIME [epoch: 27.8 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22115402291678826		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.22115402291678826 | validation: 0.23531612292639179]
	TIME [epoch: 27.8 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24225057026202973		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.24225057026202973 | validation: 0.2623570571689021]
	TIME [epoch: 27.7 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2541796174447708		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.2541796174447708 | validation: 0.23212257023690108]
	TIME [epoch: 27.7 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2289643635593189		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.2289643635593189 | validation: 0.2092818099373689]
	TIME [epoch: 27.6 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21424031870037316		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.21424031870037316 | validation: 0.2169030282287867]
	TIME [epoch: 27.7 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2225066101206946		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.2225066101206946 | validation: 0.21980312189199075]
	TIME [epoch: 27.7 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2211765714039741		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.2211765714039741 | validation: 0.22761584726181125]
	TIME [epoch: 27.7 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22764825533860256		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.22764825533860256 | validation: 0.23754900062153955]
	TIME [epoch: 27.8 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23612569160794122		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.23612569160794122 | validation: 0.24474330146375292]
	TIME [epoch: 27.7 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25439528627662017		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.25439528627662017 | validation: 0.2649025922671191]
	TIME [epoch: 27.7 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26918883406712013		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.26918883406712013 | validation: 0.27343543304775864]
	TIME [epoch: 27.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27252546132381233		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.27252546132381233 | validation: 0.2810540442319836]
	TIME [epoch: 27.7 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27202051353321066		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.27202051353321066 | validation: 0.24781985793303385]
	TIME [epoch: 27.7 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24262715949077918		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.24262715949077918 | validation: 0.22145808068240985]
	TIME [epoch: 27.7 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23085743888047658		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.23085743888047658 | validation: 0.22501498786159516]
	TIME [epoch: 27.7 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22224271938543022		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.22224271938543022 | validation: 0.2146804248520133]
	TIME [epoch: 27.8 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2267752532499371		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.2267752532499371 | validation: 0.22024283532019084]
	TIME [epoch: 27.7 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2317718906537061		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.2317718906537061 | validation: 0.2524615197315139]
	TIME [epoch: 27.8 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2388871772313543		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.2388871772313543 | validation: 0.220459290795271]
	TIME [epoch: 27.7 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22643360180609		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.22643360180609 | validation: 0.23227724070055134]
	TIME [epoch: 27.7 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23017546682411172		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.23017546682411172 | validation: 0.235625764304157]
	TIME [epoch: 27.8 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22207613462705475		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.22207613462705475 | validation: 0.20271417895023894]
	TIME [epoch: 27.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2041290122084129		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.2041290122084129 | validation: 0.2075118763985857]
	TIME [epoch: 27.8 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2044112609654659		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.2044112609654659 | validation: 0.21605967467473297]
	TIME [epoch: 27.7 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2098250791973856		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.2098250791973856 | validation: 0.21754456058816884]
	TIME [epoch: 27.7 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2274852935905622		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.2274852935905622 | validation: 0.23014372064764207]
	TIME [epoch: 27.7 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22544265915498965		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.22544265915498965 | validation: 0.21787228803593806]
	TIME [epoch: 27.6 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2204334034950409		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.2204334034950409 | validation: 0.22347900401734377]
	TIME [epoch: 27.7 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21404910756098344		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.21404910756098344 | validation: 0.19884231785036377]
	TIME [epoch: 27.6 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2076127392455632		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.2076127392455632 | validation: 0.20814153127012475]
	TIME [epoch: 27.8 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20863532448527802		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.20863532448527802 | validation: 0.20191664686701388]
	TIME [epoch: 27.8 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20687768025958925		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.20687768025958925 | validation: 0.21417590854940763]
	TIME [epoch: 27.8 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2052922793037673		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.2052922793037673 | validation: 0.2169539742991963]
	TIME [epoch: 27.8 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2163130092931215		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.2163130092931215 | validation: 0.2191460146551079]
	TIME [epoch: 27.8 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20890805509096938		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.20890805509096938 | validation: 0.2089129998185018]
	TIME [epoch: 27.8 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19934250045918622		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.19934250045918622 | validation: 0.19995988119332755]
	TIME [epoch: 27.8 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19769564428586406		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.19769564428586406 | validation: 0.19007486534990847]
	TIME [epoch: 27.8 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19241243678580872		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.19241243678580872 | validation: 0.20011873732833593]
	TIME [epoch: 27.8 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1938290833504455		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.1938290833504455 | validation: 0.1979412894403376]
	TIME [epoch: 27.7 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1954241096435207		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.1954241096435207 | validation: 0.19777237190729685]
	TIME [epoch: 27.7 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1931604143283306		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.1931604143283306 | validation: 0.1919851796524331]
	TIME [epoch: 27.8 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19205231793981536		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.19205231793981536 | validation: 0.18694664308029418]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_1139.pth
	Model improved!!!
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19257969143398795		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.19257969143398795 | validation: 0.19411040805667754]
	TIME [epoch: 27.7 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18653913256629115		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.18653913256629115 | validation: 0.18159236031689396]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240310_003042/states/model_tr_study6_1141.pth
	Model improved!!!
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18776049531722422		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.18776049531722422 | validation: 0.18539311491719906]
	TIME [epoch: 27.7 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1900504138510986		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.1900504138510986 | validation: 0.18629313116661045]
	TIME [epoch: 27.7 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1908185282027111		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.1908185282027111 | validation: 0.1996164222003546]
	TIME [epoch: 27.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19989869182848793		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.19989869182848793 | validation: 0.2082897842958268]
	TIME [epoch: 27.8 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2072402590719967		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.2072402590719967 | validation: 0.21237427728169528]
	TIME [epoch: 27.7 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19932644469777594		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.19932644469777594 | validation: 0.2052895786463811]
	TIME [epoch: 27.7 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20263988019125428		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.20263988019125428 | validation: 0.2116251335731089]
	TIME [epoch: 27.8 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20306455734579332		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.20306455734579332 | validation: 0.2025762718494628]
	TIME [epoch: 27.8 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2021502373146628		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.2021502373146628 | validation: 0.2038815926414281]
	TIME [epoch: 27.8 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19232090562505844		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.19232090562505844 | validation: 0.19506353755300715]
	TIME [epoch: 27.7 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2007628035991798		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.2007628035991798 | validation: 0.19768921207944645]
	TIME [epoch: 27.8 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.198975870419071		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.198975870419071 | validation: 0.18262402588178492]
	TIME [epoch: 27.8 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19306576330024755		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.19306576330024755 | validation: 0.20535161906535362]
	TIME [epoch: 27.8 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20671417729431252		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.20671417729431252 | validation: 0.20966769341762284]
	TIME [epoch: 27.9 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20458348207705518		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.20458348207705518 | validation: 0.1929381523532233]
	TIME [epoch: 27.8 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19623181043511173		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.19623181043511173 | validation: 0.18898441533691576]
	TIME [epoch: 27.8 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20012446657257948		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.20012446657257948 | validation: 0.18905422586932602]
	TIME [epoch: 27.8 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19744377120149575		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.19744377120149575 | validation: 0.21215269139856865]
	TIME [epoch: 27.7 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20292914052957028		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.20292914052957028 | validation: 0.1949660939750455]
	TIME [epoch: 27.7 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19685924726917345		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.19685924726917345 | validation: 0.20100660770920922]
	TIME [epoch: 27.6 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2090617051647456		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.2090617051647456 | validation: 0.21318576531464395]
	TIME [epoch: 27.6 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21041170551447208		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.21041170551447208 | validation: 0.20474590063548895]
	TIME [epoch: 27.6 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20243256875943286		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.20243256875943286 | validation: 0.19257153221662918]
	TIME [epoch: 27.6 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19111126951976962		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.19111126951976962 | validation: 0.18668956594483352]
	TIME [epoch: 27.7 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19465296058730822		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.19465296058730822 | validation: 0.2052914159634204]
	TIME [epoch: 27.8 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20259215977608797		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.20259215977608797 | validation: 0.20943135149201259]
	TIME [epoch: 27.8 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20667417036008517		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.20667417036008517 | validation: 0.20972283400364553]
	TIME [epoch: 27.7 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21682265613879248		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.21682265613879248 | validation: 0.24255597122576114]
	TIME [epoch: 27.6 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22867753662721033		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.22867753662721033 | validation: 0.23880606656665854]
	TIME [epoch: 27.7 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22651210502190683		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.22651210502190683 | validation: 0.22289492942471584]
	TIME [epoch: 27.6 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22624620813478574		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.22624620813478574 | validation: 0.2212699239956556]
	TIME [epoch: 27.7 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.218615754829915		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.218615754829915 | validation: 0.2067086757613643]
	TIME [epoch: 27.8 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20409195340926323		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.20409195340926323 | validation: 0.20366135623480547]
	TIME [epoch: 27.8 sec]
EPOCH 1175/2000:
	Training over batches...
