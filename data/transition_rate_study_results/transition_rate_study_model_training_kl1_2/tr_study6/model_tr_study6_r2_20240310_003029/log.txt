Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r2', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1621016976

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.269080283428824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.269080283428824 | validation: 7.108501153936266]
	TIME [epoch: 105 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.664173001083216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.664173001083216 | validation: 5.486832106399472]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.424776174461532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.424776174461532 | validation: 5.274518218870642]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.120607310937502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.120607310937502 | validation: 4.783475286937312]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7703709672498915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7703709672498915 | validation: 4.321028306503242]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.414161271280715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.414161271280715 | validation: 4.2109333008059515]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8512787981087255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8512787981087255 | validation: 5.059717077353181]
	TIME [epoch: 27.6 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7702613360895745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7702613360895745 | validation: 4.314733612012913]
	TIME [epoch: 27.6 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.405612069496835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.405612069496835 | validation: 5.1857235352895374]
	TIME [epoch: 27.6 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.959996024211783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.959996024211783 | validation: 4.202286156908699]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9833628308141193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9833628308141193 | validation: 3.845931507038891]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8071334790010374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8071334790010374 | validation: 4.523784775502253]
	TIME [epoch: 27.7 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8942636439241527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8942636439241527 | validation: 3.6707439136495648]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5037100532127377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5037100532127377 | validation: 3.4239221488667875]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.26670221607988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.26670221607988 | validation: 3.9741936505541657]
	TIME [epoch: 27.6 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5685423500029874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5685423500029874 | validation: 3.721374093178848]
	TIME [epoch: 27.7 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.488514482599585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.488514482599585 | validation: 3.341566369387988]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2441029805510606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2441029805510606 | validation: 3.2671901238947054]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.155578828189756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.155578828189756 | validation: 3.2128552907349475]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0701445808492416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0701445808492416 | validation: 3.4686847913465146]
	TIME [epoch: 27.7 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1294325429304934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1294325429304934 | validation: 3.3287798986353336]
	TIME [epoch: 27.6 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1143377023242604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1143377023242604 | validation: 3.1514264459243635]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.103128793832491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.103128793832491 | validation: 3.5138330882868876]
	TIME [epoch: 27.6 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.324509958903429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.324509958903429 | validation: 4.211698430177473]
	TIME [epoch: 27.6 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8124484566163765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8124484566163765 | validation: 2.824692086942791]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9712617504589582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9712617504589582 | validation: 3.119156866206801]
	TIME [epoch: 27.6 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9585705901098454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9585705901098454 | validation: 2.761319683676274]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.884023927476439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.884023927476439 | validation: 2.607131989714019]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.668527403409935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.668527403409935 | validation: 2.5607746207877664]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.768519986287606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.768519986287606 | validation: 3.72611003719926]
	TIME [epoch: 27.7 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.87808279507888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.87808279507888 | validation: 5.122512104247549]
	TIME [epoch: 27.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.638734672628668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.638734672628668 | validation: 2.9210992556194175]
	TIME [epoch: 27.6 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0950467355340785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0950467355340785 | validation: 3.484617829413854]
	TIME [epoch: 27.6 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.542665057985018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.542665057985018 | validation: 4.3354663207412605]
	TIME [epoch: 27.6 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5908980706630667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5908980706630667 | validation: 2.8525738040544537]
	TIME [epoch: 27.6 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2056032749501977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2056032749501977 | validation: 4.5428933506195195]
	TIME [epoch: 27.6 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.771171070617608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.771171070617608 | validation: 2.929682141058965]
	TIME [epoch: 27.6 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.192609296512971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.192609296512971 | validation: 4.281427929837508]
	TIME [epoch: 27.7 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.468143674248455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.468143674248455 | validation: 2.854182812950568]
	TIME [epoch: 27.6 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.124449350281294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.124449350281294 | validation: 3.4606262565899004]
	TIME [epoch: 27.6 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.667528887342776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.667528887342776 | validation: 4.164596978222234]
	TIME [epoch: 27.6 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.521632788800909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.521632788800909 | validation: 3.0623313815640927]
	TIME [epoch: 27.6 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.116486199309711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.116486199309711 | validation: 2.9197925183010187]
	TIME [epoch: 27.6 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9958729500801615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9958729500801615 | validation: 3.057167994799642]
	TIME [epoch: 27.6 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.223539399388347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.223539399388347 | validation: 2.8046369743921953]
	TIME [epoch: 27.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.507613142458825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.507613142458825 | validation: 3.955986540783405]
	TIME [epoch: 27.7 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.795620141771992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.795620141771992 | validation: 5.316849649640745]
	TIME [epoch: 27.7 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.555148281000014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.555148281000014 | validation: 4.027206581597379]
	TIME [epoch: 27.6 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.536283985654793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.536283985654793 | validation: 3.425220574171461]
	TIME [epoch: 27.6 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4097944499194615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4097944499194615 | validation: 5.667648531081918]
	TIME [epoch: 27.6 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476177442119855		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.476177442119855 | validation: 3.570224298972774]
	TIME [epoch: 27.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.180221661418856		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.180221661418856 | validation: 2.9563837650083236]
	TIME [epoch: 27.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1978708507639158		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.1978708507639158 | validation: 3.2384140859190245]
	TIME [epoch: 27.6 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3526198047085494		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.3526198047085494 | validation: 3.386904023931117]
	TIME [epoch: 27.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.295435748185632		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.295435748185632 | validation: 2.8730736860999286]
	TIME [epoch: 27.7 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.97806665037874		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.97806665037874 | validation: 2.8313966399909383]
	TIME [epoch: 27.6 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.205579596354826		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.205579596354826 | validation: 4.034532026515564]
	TIME [epoch: 27.6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.257427328457568		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.257427328457568 | validation: 4.6151165286832905]
	TIME [epoch: 27.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2503381563721865		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.2503381563721865 | validation: 3.838127454590518]
	TIME [epoch: 27.6 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.230031420622262		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.230031420622262 | validation: 2.8868173843261684]
	TIME [epoch: 27.7 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8159196449392203		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.8159196449392203 | validation: 2.996408900790948]
	TIME [epoch: 27.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1163818803391266		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.1163818803391266 | validation: 3.0792180614052422]
	TIME [epoch: 27.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.439340495452954		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.439340495452954 | validation: 2.779409450282202]
	TIME [epoch: 27.6 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0268061710918746		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.0268061710918746 | validation: 2.6837570747930437]
	TIME [epoch: 27.6 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0465415865131504		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.0465415865131504 | validation: 3.3231659531081053]
	TIME [epoch: 27.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0631838858819105		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.0631838858819105 | validation: 2.8337855982805293]
	TIME [epoch: 27.6 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8486519647659008		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.8486519647659008 | validation: 2.586776977654292]
	TIME [epoch: 27.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8904705521751555		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.8904705521751555 | validation: 2.5883391152964537]
	TIME [epoch: 27.7 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.699460989546007		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.699460989546007 | validation: 3.2828324849850845]
	TIME [epoch: 27.6 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9150816985849484		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.9150816985849484 | validation: 4.054838525732489]
	TIME [epoch: 27.6 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2291080083723696		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 4.2291080083723696 | validation: 4.18795305299031]
	TIME [epoch: 27.6 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9527219900824995		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.9527219900824995 | validation: 3.331011173612899]
	TIME [epoch: 27.6 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.209388756181855		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 4.209388756181855 | validation: 4.091566080822693]
	TIME [epoch: 27.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6402036397329534		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.6402036397329534 | validation: 3.0246785680764616]
	TIME [epoch: 27.6 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.009046741662027		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.009046741662027 | validation: 2.973713931675619]
	TIME [epoch: 27.6 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1112912532394605		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.1112912532394605 | validation: 2.7180701681035804]
	TIME [epoch: 27.6 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.07381005405652		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.07381005405652 | validation: 2.729752696694286]
	TIME [epoch: 27.6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7695525591433148		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.7695525591433148 | validation: 2.614118615578345]
	TIME [epoch: 27.6 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5789609357350987		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.5789609357350987 | validation: 2.5075274675093913]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210428494211217		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.210428494211217 | validation: 3.1992380979022608]
	TIME [epoch: 27.6 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0650297737905454		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.0650297737905454 | validation: 2.834354015857526]
	TIME [epoch: 27.6 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6985947806348225		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.6985947806348225 | validation: 2.964835870888762]
	TIME [epoch: 27.7 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.948462356492792		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.948462356492792 | validation: 2.881986771978636]
	TIME [epoch: 27.6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5233996090458186		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.5233996090458186 | validation: 2.7497914586618766]
	TIME [epoch: 27.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.384267914509967		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.384267914509967 | validation: 3.295810566360952]
	TIME [epoch: 27.7 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8238751960702615		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.8238751960702615 | validation: 4.6753156875967]
	TIME [epoch: 27.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.286750760996039		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 4.286750760996039 | validation: 2.830038569599833]
	TIME [epoch: 27.6 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9012515698975907		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.9012515698975907 | validation: 2.737023051353887]
	TIME [epoch: 27.7 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2011751343624386		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.2011751343624386 | validation: 3.423435894947819]
	TIME [epoch: 27.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.853592379849501		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.853592379849501 | validation: 3.0728632020221993]
	TIME [epoch: 27.6 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.978687521791591		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.978687521791591 | validation: 2.922302302756392]
	TIME [epoch: 27.6 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0415218782772353		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.0415218782772353 | validation: 2.820433034615926]
	TIME [epoch: 27.6 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.818255858714439		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.818255858714439 | validation: 2.7794965458332377]
	TIME [epoch: 27.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9897001888616517		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.9897001888616517 | validation: 2.615709040932349]
	TIME [epoch: 27.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7463941828091696		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.7463941828091696 | validation: 2.9254212076115618]
	TIME [epoch: 27.7 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6698393939174143		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.6698393939174143 | validation: 2.480920782334196]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5020193936070156		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.5020193936070156 | validation: 2.313115384257201]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5948192770026814		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.5948192770026814 | validation: 2.347581502121843]
	TIME [epoch: 27.6 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.58158579317816		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.58158579317816 | validation: 3.363340321837601]
	TIME [epoch: 27.6 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9448868262119894		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.9448868262119894 | validation: 2.2596924905000724]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.454782982435735		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.454782982435735 | validation: 2.169190747364547]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.316617758188083		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.316617758188083 | validation: 1.9362870645678232]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.129387037355689		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.129387037355689 | validation: 2.0766119851011267]
	TIME [epoch: 27.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1221129440074913		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.1221129440074913 | validation: 1.7863730507955788]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9149952275388262		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.9149952275388262 | validation: 1.9914781169337687]
	TIME [epoch: 27.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2780737016416914		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.2780737016416914 | validation: 2.8551101443985596]
	TIME [epoch: 27.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.321995212663373		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.321995212663373 | validation: 2.6525443967414755]
	TIME [epoch: 27.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.808302929051344		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.808302929051344 | validation: 2.149287039161016]
	TIME [epoch: 27.7 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.03802924981515		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.03802924981515 | validation: 2.494893255768717]
	TIME [epoch: 27.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1023335696219925		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.1023335696219925 | validation: 1.9535289480468734]
	TIME [epoch: 27.7 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9981021689510652		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.9981021689510652 | validation: 1.7944311442144547]
	TIME [epoch: 27.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8286243233958068		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.8286243233958068 | validation: 2.9101318247171175]
	TIME [epoch: 27.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.178591139961191		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.178591139961191 | validation: 3.343030808311005]
	TIME [epoch: 27.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.610452046410469		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.610452046410469 | validation: 1.7404805968214454]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.780459102573766		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.780459102573766 | validation: 1.6649305384145694]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6484342046146563		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.6484342046146563 | validation: 1.575353651559775]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9829757554519494		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.9829757554519494 | validation: 2.3303212116842325]
	TIME [epoch: 27.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7894302851784285		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.7894302851784285 | validation: 1.5034068023182772]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0103483851616715		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.0103483851616715 | validation: 1.9049858925769685]
	TIME [epoch: 27.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6422764964005983		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.6422764964005983 | validation: 1.3611516384644962]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3697386494599382		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.3697386494599382 | validation: 1.3083307070754302]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0174967672508344		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.0174967672508344 | validation: 1.806290839699809]
	TIME [epoch: 27.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.672210150741209		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.672210150741209 | validation: 1.4423707660230864]
	TIME [epoch: 27.6 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4540519449629175		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.4540519449629175 | validation: 1.17407173712824]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2707058092190677		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.2707058092190677 | validation: 2.4491840183067253]
	TIME [epoch: 27.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5628122390607437		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.5628122390607437 | validation: 1.628352803177139]
	TIME [epoch: 27.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2831043027594236		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.2831043027594236 | validation: 1.6002229652722972]
	TIME [epoch: 27.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5226202998471936		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.5226202998471936 | validation: 1.1482460018975658]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0329511360571098		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.0329511360571098 | validation: 1.342787185034899]
	TIME [epoch: 27.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0205675691510279		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.0205675691510279 | validation: 1.2937292573302637]
	TIME [epoch: 27.7 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9637808892747822		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.9637808892747822 | validation: 0.9011001406785062]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.983248819745337		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.983248819745337 | validation: 0.8175980524082772]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8272792428752149		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.8272792428752149 | validation: 0.7569032506588639]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.855563920650636		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.855563920650636 | validation: 1.4578486575254823]
	TIME [epoch: 27.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0967668180722194		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.0967668180722194 | validation: 0.9350141933714443]
	TIME [epoch: 27.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9406353613294567		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.9406353613294567 | validation: 0.8353069647451434]
	TIME [epoch: 27.7 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1308626396467973		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.1308626396467973 | validation: 1.3198483514918582]
	TIME [epoch: 27.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9863074743932498		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.9863074743932498 | validation: 0.7339399062707114]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9596501546309634		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.9596501546309634 | validation: 0.7314947722417946]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0046851700356887		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.0046851700356887 | validation: 2.650481292722337]
	TIME [epoch: 27.7 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4851738610814724		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.4851738610814724 | validation: 0.9934886042788017]
	TIME [epoch: 27.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9548982285196947		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.9548982285196947 | validation: 0.9390028487004318]
	TIME [epoch: 27.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.826594848891359		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.826594848891359 | validation: 0.7026492816725762]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9545240769169472		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.9545240769169472 | validation: 1.9963598788158867]
	TIME [epoch: 27.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7855102654572106		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.7855102654572106 | validation: 1.2144443799983469]
	TIME [epoch: 27.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.175909062186474		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.175909062186474 | validation: 0.7871462602876386]
	TIME [epoch: 27.7 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9445133545914869		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.9445133545914869 | validation: 1.1260750478671036]
	TIME [epoch: 27.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9395102032124105		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.9395102032124105 | validation: 1.2640212980109664]
	TIME [epoch: 27.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0628511798841038		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.0628511798841038 | validation: 0.9698672925019781]
	TIME [epoch: 27.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.945864937866516		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.945864937866516 | validation: 0.8822898061480683]
	TIME [epoch: 27.7 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.00447502186598		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.00447502186598 | validation: 1.4134313375593845]
	TIME [epoch: 27.7 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3086991314127119		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.3086991314127119 | validation: 1.2673294787951646]
	TIME [epoch: 27.7 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9948306546709137		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.9948306546709137 | validation: 1.4087390623069354]
	TIME [epoch: 27.7 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1128389905325264		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.1128389905325264 | validation: 1.149706324254274]
	TIME [epoch: 27.7 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0264774959487935		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.0264774959487935 | validation: 0.9583018786161518]
	TIME [epoch: 27.7 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9890692942907469		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.9890692942907469 | validation: 0.8659896768640909]
	TIME [epoch: 27.7 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6246146934607704		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.6246146934607704 | validation: 1.1905436535962397]
	TIME [epoch: 27.6 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9890997727036629		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.9890997727036629 | validation: 0.851365301578721]
	TIME [epoch: 27.7 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6929119603444548		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.6929119603444548 | validation: 1.4788941529432915]
	TIME [epoch: 27.7 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1299691335302187		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.1299691335302187 | validation: 0.7553016045605289]
	TIME [epoch: 27.7 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0845184537419061		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.0845184537419061 | validation: 1.2285802665452787]
	TIME [epoch: 27.7 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0101833328591807		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.0101833328591807 | validation: 0.8664502930781697]
	TIME [epoch: 27.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022620061626732		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.022620061626732 | validation: 0.8335204171861199]
	TIME [epoch: 27.7 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9717693410443764		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.9717693410443764 | validation: 1.25055096031529]
	TIME [epoch: 27.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1016398969646173		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.1016398969646173 | validation: 1.1332089033111306]
	TIME [epoch: 27.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0462491880774347		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.0462491880774347 | validation: 0.8954043480216707]
	TIME [epoch: 27.7 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4014582100692716		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.4014582100692716 | validation: 1.4266003375860512]
	TIME [epoch: 27.7 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.009283375238676		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.009283375238676 | validation: 0.7480715724743416]
	TIME [epoch: 27.7 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9188052402896086		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.9188052402896086 | validation: 0.6701613985693077]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1158160149027003		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.1158160149027003 | validation: 0.8400063687183493]
	TIME [epoch: 27.7 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7259776567903808		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.7259776567903808 | validation: 1.0517654241271823]
	TIME [epoch: 27.7 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8632798116313818		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.8632798116313818 | validation: 0.979284198635418]
	TIME [epoch: 27.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.051176243160187		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.051176243160187 | validation: 0.7603657081775289]
	TIME [epoch: 27.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9725723877281459		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.9725723877281459 | validation: 0.7300725578041878]
	TIME [epoch: 27.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4760967364772708		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.4760967364772708 | validation: 1.0589293124254666]
	TIME [epoch: 27.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4238422356982663		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.4238422356982663 | validation: 1.3738966531067882]
	TIME [epoch: 27.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0410353437839241		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.0410353437839241 | validation: 0.6559133752408808]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7526747527637971		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.7526747527637971 | validation: 0.7575587258912811]
	TIME [epoch: 27.7 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7584240782628247		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.7584240782628247 | validation: 0.790412736677437]
	TIME [epoch: 27.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0576741923528774		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.0576741923528774 | validation: 0.6120606479307391]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9379009189660372		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.9379009189660372 | validation: 1.0153292596746544]
	TIME [epoch: 27.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9287971971665014		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.9287971971665014 | validation: 1.3240353807975356]
	TIME [epoch: 27.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0577584098267898		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.0577584098267898 | validation: 0.6109147796510662]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8196465762539026		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.8196465762539026 | validation: 0.8728082749068625]
	TIME [epoch: 27.7 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9336813601757936		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.9336813601757936 | validation: 0.87413362592168]
	TIME [epoch: 27.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.098090415710496		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.098090415710496 | validation: 0.9764281115418146]
	TIME [epoch: 27.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.844481573127279		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.844481573127279 | validation: 1.4147832270716163]
	TIME [epoch: 27.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7093448403622418		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.7093448403622418 | validation: 1.9231681643128413]
	TIME [epoch: 27.7 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.498969559431781		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.498969559431781 | validation: 1.1794005913599943]
	TIME [epoch: 27.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9892672494864634		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.9892672494864634 | validation: 0.8976250699127326]
	TIME [epoch: 27.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0367569076962664		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.0367569076962664 | validation: 2.9580171378850935]
	TIME [epoch: 27.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3141740945526923		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 3.3141740945526923 | validation: 2.767910921957935]
	TIME [epoch: 27.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.043816659107369		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 3.043816659107369 | validation: 3.330930963885277]
	TIME [epoch: 27.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.559552210815486		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 3.559552210815486 | validation: 4.30834116616569]
	TIME [epoch: 27.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.906157537035355		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 3.906157537035355 | validation: 3.0596729042725634]
	TIME [epoch: 27.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.324643287806328		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 3.324643287806328 | validation: 3.013437225778896]
	TIME [epoch: 27.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0594594315355006		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 3.0594594315355006 | validation: 3.0118082186893718]
	TIME [epoch: 27.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.269282786673817		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 3.269282786673817 | validation: 4.126394396217217]
	TIME [epoch: 27.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6060811635891366		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 3.6060811635891366 | validation: 2.64530532623206]
	TIME [epoch: 27.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6806023283922635		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 2.6806023283922635 | validation: 2.297013523809692]
	TIME [epoch: 27.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2653257481102855		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.2653257481102855 | validation: 1.5304952464786612]
	TIME [epoch: 27.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4453711801442033		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.4453711801442033 | validation: 1.1106242615292576]
	TIME [epoch: 27.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1420522242432145		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.1420522242432145 | validation: 0.9851281213631439]
	TIME [epoch: 27.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0623336615953374		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.0623336615953374 | validation: 0.894568250585738]
	TIME [epoch: 27.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.07003295730635		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.07003295730635 | validation: 0.9387000332317413]
	TIME [epoch: 27.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1223872419430478		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.1223872419430478 | validation: 1.4637317900094626]
	TIME [epoch: 27.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.063279931072355		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.063279931072355 | validation: 1.2190044677079825]
	TIME [epoch: 27.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0171918169564167		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.0171918169564167 | validation: 0.949439293277874]
	TIME [epoch: 27.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1837280937798833		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.1837280937798833 | validation: 1.3824105785642338]
	TIME [epoch: 27.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1508453330089652		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.1508453330089652 | validation: 0.9145210665094416]
	TIME [epoch: 27.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9867444617946985		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.9867444617946985 | validation: 0.7993535850079059]
	TIME [epoch: 27.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9796708720693965		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.9796708720693965 | validation: 1.0509518323950016]
	TIME [epoch: 27.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9136087389619385		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.9136087389619385 | validation: 0.8001050090216864]
	TIME [epoch: 27.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7862277363019592		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.7862277363019592 | validation: 0.7583482554915765]
	TIME [epoch: 27.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5702639317423737		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.5702639317423737 | validation: 2.5640080692842226]
	TIME [epoch: 27.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7833115283756653		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 2.7833115283756653 | validation: 2.6812231962791397]
	TIME [epoch: 27.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0935768765255003		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 3.0935768765255003 | validation: 2.746703042404238]
	TIME [epoch: 27.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.327419897934139		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 3.327419897934139 | validation: 2.9989020384918685]
	TIME [epoch: 27.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1505688144460082		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 3.1505688144460082 | validation: 2.898538776046319]
	TIME [epoch: 27.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.455013835814264		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 3.455013835814264 | validation: 3.4433416215514474]
	TIME [epoch: 27.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.447788581541035		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 3.447788581541035 | validation: 3.014909996229602]
	TIME [epoch: 27.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3715409745454084		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 3.3715409745454084 | validation: 2.973656265820822]
	TIME [epoch: 27.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5542656644450386		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 3.5542656644450386 | validation: 3.2753145634049203]
	TIME [epoch: 27.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.478191836791178		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 3.478191836791178 | validation: 2.7385769303707095]
	TIME [epoch: 27.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5127588923326627		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 2.5127588923326627 | validation: 1.6611627712617951]
	TIME [epoch: 27.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3445104974600277		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.3445104974600277 | validation: 0.8875826308056084]
	TIME [epoch: 27.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9439203937211789		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.9439203937211789 | validation: 0.7666896377974063]
	TIME [epoch: 27.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9700080385989709		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.9700080385989709 | validation: 0.7994515231734639]
	TIME [epoch: 27.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8217992294579491		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.8217992294579491 | validation: 0.905838182805078]
	TIME [epoch: 27.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8656000793824785		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.8656000793824785 | validation: 0.7446562447307078]
	TIME [epoch: 27.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8436636129190823		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.8436636129190823 | validation: 0.8817785380648715]
	TIME [epoch: 27.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9119607762955362		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.9119607762955362 | validation: 0.8537096356535847]
	TIME [epoch: 27.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7447531041852788		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.7447531041852788 | validation: 0.8303119760875102]
	TIME [epoch: 27.7 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8464081413105735		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.8464081413105735 | validation: 0.7333461662470893]
	TIME [epoch: 27.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6613190690775768		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.6613190690775768 | validation: 1.3660182665671985]
	TIME [epoch: 27.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0097686610195367		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.0097686610195367 | validation: 0.9064187229598037]
	TIME [epoch: 27.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9976638792552899		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.9976638792552899 | validation: 1.0834534561663092]
	TIME [epoch: 27.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9573267264769921		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.9573267264769921 | validation: 0.9722976630873044]
	TIME [epoch: 27.7 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8751612799817666		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.8751612799817666 | validation: 0.8436713316201033]
	TIME [epoch: 27.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8228363255542948		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.8228363255542948 | validation: 0.7842392840506394]
	TIME [epoch: 27.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7660106281058718		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.7660106281058718 | validation: 0.8619782545460322]
	TIME [epoch: 27.7 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7896186450322009		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.7896186450322009 | validation: 0.9731024636788324]
	TIME [epoch: 27.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5793299680965482		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.5793299680965482 | validation: 2.827337855749886]
	TIME [epoch: 27.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.453665698253539		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.453665698253539 | validation: 0.7492916197698074]
	TIME [epoch: 27.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8794334364423178		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.8794334364423178 | validation: 1.0928897536010036]
	TIME [epoch: 27.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3568353197632592		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.3568353197632592 | validation: 0.8176856743718395]
	TIME [epoch: 27.6 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.979658510654122		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.979658510654122 | validation: 1.1252917908180387]
	TIME [epoch: 27.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8247264290146011		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.8247264290146011 | validation: 1.4461730952405893]
	TIME [epoch: 27.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1694185313357248		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.1694185313357248 | validation: 1.169282578583999]
	TIME [epoch: 27.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8273945683037245		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.8273945683037245 | validation: 0.8677561454969905]
	TIME [epoch: 27.7 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8584828587711131		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.8584828587711131 | validation: 0.7481466708722505]
	TIME [epoch: 27.7 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6978795147055539		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.6978795147055539 | validation: 0.7414596230920659]
	TIME [epoch: 27.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7161866192466918		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.7161866192466918 | validation: 0.8941396592749805]
	TIME [epoch: 27.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7876756356378842		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.7876756356378842 | validation: 0.7710868259721957]
	TIME [epoch: 27.7 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2166775490366912		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.2166775490366912 | validation: 0.6792790089240437]
	TIME [epoch: 27.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7594281064787004		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.7594281064787004 | validation: 1.0880579552911067]
	TIME [epoch: 27.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8627581926170022		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.8627581926170022 | validation: 0.7891761498321712]
	TIME [epoch: 27.7 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7999638159456467		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.7999638159456467 | validation: 0.6948544562336523]
	TIME [epoch: 27.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8914443922741152		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.8914443922741152 | validation: 0.6591093975000237]
	TIME [epoch: 27.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8578436860862138		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.8578436860862138 | validation: 0.6578384661900162]
	TIME [epoch: 27.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7137334983095835		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.7137334983095835 | validation: 1.3871788023466893]
	TIME [epoch: 27.7 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2360296494680012		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.2360296494680012 | validation: 0.8905610163331019]
	TIME [epoch: 27.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8907282095082347		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.8907282095082347 | validation: 0.9733984510560468]
	TIME [epoch: 27.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8179086880655021		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.8179086880655021 | validation: 0.9173946843881364]
	TIME [epoch: 27.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8154334632909572		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.8154334632909572 | validation: 0.7030667625336914]
	TIME [epoch: 27.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7797604022800483		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.7797604022800483 | validation: 0.7906487970688408]
	TIME [epoch: 27.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7186480276671343		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.7186480276671343 | validation: 1.2177443734135145]
	TIME [epoch: 27.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8233114044905532		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.8233114044905532 | validation: 1.1668592538577764]
	TIME [epoch: 27.7 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9472841520832499		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.9472841520832499 | validation: 0.7433306856955315]
	TIME [epoch: 27.7 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7197832971501971		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.7197832971501971 | validation: 0.7369339654947649]
	TIME [epoch: 27.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7184421676321155		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.7184421676321155 | validation: 1.2472202867250304]
	TIME [epoch: 27.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0057251784241392		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.0057251784241392 | validation: 0.7080511786123972]
	TIME [epoch: 27.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6987169189316818		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.6987169189316818 | validation: 1.1715365432270752]
	TIME [epoch: 27.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.971877097649656		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.971877097649656 | validation: 0.703603102463083]
	TIME [epoch: 27.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833185634006147		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.6833185634006147 | validation: 0.7308706333320205]
	TIME [epoch: 27.7 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.985637097038529		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.985637097038529 | validation: 0.7753884104638423]
	TIME [epoch: 27.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7806673107795654		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.7806673107795654 | validation: 0.7150507876242194]
	TIME [epoch: 27.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.891161623041507		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.891161623041507 | validation: 0.8654939306849991]
	TIME [epoch: 27.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8390705462241218		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.8390705462241218 | validation: 0.8780020467212305]
	TIME [epoch: 27.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8201297943621941		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.8201297943621941 | validation: 0.9279702834549051]
	TIME [epoch: 27.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0381083989628117		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.0381083989628117 | validation: 0.8716293007066088]
	TIME [epoch: 27.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7966289267206808		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.7966289267206808 | validation: 0.9247397742290471]
	TIME [epoch: 27.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.008936493906663		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.008936493906663 | validation: 1.651776330210666]
	TIME [epoch: 27.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0408233325230734		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.0408233325230734 | validation: 0.9375696195718763]
	TIME [epoch: 27.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7547380942629027		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.7547380942629027 | validation: 0.8761626936321497]
	TIME [epoch: 27.7 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6983709857445868		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.6983709857445868 | validation: 0.6176575987970211]
	TIME [epoch: 27.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6264637567349431		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.6264637567349431 | validation: 3.076043028963447]
	TIME [epoch: 27.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.626354700378022		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 3.626354700378022 | validation: 2.98464383927026]
	TIME [epoch: 27.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7174354896018458		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 2.7174354896018458 | validation: 1.7497429514470166]
	TIME [epoch: 27.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6147399056795875		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.6147399056795875 | validation: 0.850222732109896]
	TIME [epoch: 27.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7289995093684061		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.7289995093684061 | validation: 0.9751674178111928]
	TIME [epoch: 27.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9647413033096158		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.9647413033096158 | validation: 0.9793873580172173]
	TIME [epoch: 27.7 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.869560893285061		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.869560893285061 | validation: 0.9939216416307477]
	TIME [epoch: 27.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9410867491940165		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.9410867491940165 | validation: 1.2660067155921062]
	TIME [epoch: 27.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8212086290751778		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.8212086290751778 | validation: 0.9674349328875533]
	TIME [epoch: 27.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4198649676813515		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.4198649676813515 | validation: 1.028751984469411]
	TIME [epoch: 27.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9286615669097571		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.9286615669097571 | validation: 0.6536809130352343]
	TIME [epoch: 27.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.771820195014588		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.771820195014588 | validation: 0.9656066119340458]
	TIME [epoch: 27.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7761268397577679		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.7761268397577679 | validation: 0.7460873293455038]
	TIME [epoch: 27.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7159814049475952		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.7159814049475952 | validation: 0.7400364321622587]
	TIME [epoch: 27.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7843733878413788		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.7843733878413788 | validation: 0.8257010648153873]
	TIME [epoch: 27.7 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8050056865338442		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.8050056865338442 | validation: 0.6664508917689781]
	TIME [epoch: 27.7 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3477115620438642		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.3477115620438642 | validation: 2.1720829477321724]
	TIME [epoch: 27.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7506542898964599		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.7506542898964599 | validation: 1.3434811055831193]
	TIME [epoch: 27.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0360891035558148		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.0360891035558148 | validation: 0.8336438231653369]
	TIME [epoch: 27.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.09505298590357		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.09505298590357 | validation: 0.8807125778076204]
	TIME [epoch: 27.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8065645513245614		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.8065645513245614 | validation: 1.474266058331741]
	TIME [epoch: 27.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064803471771686		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.064803471771686 | validation: 0.7534187432947872]
	TIME [epoch: 27.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7070478646915624		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.7070478646915624 | validation: 0.6138690456733119]
	TIME [epoch: 27.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830060537984717		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.6830060537984717 | validation: 0.6453753378859299]
	TIME [epoch: 27.7 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854697413632188		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.6854697413632188 | validation: 0.708871997725987]
	TIME [epoch: 27.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7817206729252428		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.7817206729252428 | validation: 0.9587049294696572]
	TIME [epoch: 27.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.805498040844967		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.805498040844967 | validation: 2.1631061721796416]
	TIME [epoch: 27.7 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6612064981531214		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.6612064981531214 | validation: 0.870800083385314]
	TIME [epoch: 27.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7800710172676224		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.7800710172676224 | validation: 0.9764630525540142]
	TIME [epoch: 27.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8113903111637066		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.8113903111637066 | validation: 0.8864088530421035]
	TIME [epoch: 27.7 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7996376972714041		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.7996376972714041 | validation: 0.6593661045717428]
	TIME [epoch: 27.7 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6978889382487701		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.6978889382487701 | validation: 0.6811230248018546]
	TIME [epoch: 27.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2121347084529845		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.2121347084529845 | validation: 1.457820054694007]
	TIME [epoch: 27.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2227979313971526		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.2227979313971526 | validation: 0.6708166354417583]
	TIME [epoch: 27.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6579973247557185		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.6579973247557185 | validation: 0.6601492388673411]
	TIME [epoch: 27.7 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6067656939470648		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.6067656939470648 | validation: 0.56959423829141]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_322.pth
	Model improved!!!
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8064794777063605		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.8064794777063605 | validation: 0.6347069828417783]
	TIME [epoch: 27.7 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5881573759876084		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.5881573759876084 | validation: 0.818586521779221]
	TIME [epoch: 27.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6474752307040276		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.6474752307040276 | validation: 0.8031769262257293]
	TIME [epoch: 27.7 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9576451295760318		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.9576451295760318 | validation: 1.0074759973952887]
	TIME [epoch: 27.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.859925522019405		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.859925522019405 | validation: 1.5956056948106685]
	TIME [epoch: 27.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235306494675501		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.235306494675501 | validation: 0.7248789186809198]
	TIME [epoch: 27.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6984471027636299		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.6984471027636299 | validation: 0.7628533815020205]
	TIME [epoch: 27.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.655496160845805		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.655496160845805 | validation: 0.8634111182105436]
	TIME [epoch: 27.7 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8849948502641188		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.8849948502641188 | validation: 0.9277180576411668]
	TIME [epoch: 27.7 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8333431028419591		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.8333431028419591 | validation: 0.9366941772028349]
	TIME [epoch: 27.7 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.712727909279425		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.712727909279425 | validation: 0.8302731625006691]
	TIME [epoch: 27.7 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7978973340470432		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.7978973340470432 | validation: 0.9373110851903314]
	TIME [epoch: 27.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8230374488416083		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.8230374488416083 | validation: 0.6983992979587919]
	TIME [epoch: 27.7 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0282099817773471		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.0282099817773471 | validation: 1.1669705382319766]
	TIME [epoch: 27.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8191742971820377		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.8191742971820377 | validation: 0.6271235044232126]
	TIME [epoch: 27.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7580609077687824		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.7580609077687824 | validation: 1.3959907348783258]
	TIME [epoch: 27.7 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2666209641699988		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.2666209641699988 | validation: 0.6960415011988078]
	TIME [epoch: 27.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8239253922567815		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.8239253922567815 | validation: 0.9801763148262771]
	TIME [epoch: 27.7 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.962438030546531		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.962438030546531 | validation: 1.0853978481548572]
	TIME [epoch: 27.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8511491483745719		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.8511491483745719 | validation: 0.7829708019160362]
	TIME [epoch: 27.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8609969158142342		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.8609969158142342 | validation: 0.6523497416868489]
	TIME [epoch: 27.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7730533441612848		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.7730533441612848 | validation: 0.6534989775915148]
	TIME [epoch: 27.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7670759252228219		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.7670759252228219 | validation: 0.6823974830177885]
	TIME [epoch: 27.7 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4649008744624683		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.4649008744624683 | validation: 1.3380733853975177]
	TIME [epoch: 27.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8827334858541469		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.8827334858541469 | validation: 0.6930560372614591]
	TIME [epoch: 27.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0085283160333423		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.0085283160333423 | validation: 0.7409460193498449]
	TIME [epoch: 27.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7401731509520015		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.7401731509520015 | validation: 1.5924879160350498]
	TIME [epoch: 27.7 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.395799117668755		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.395799117668755 | validation: 1.0895097295039182]
	TIME [epoch: 27.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8069670097917717		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.8069670097917717 | validation: 0.9803585728423648]
	TIME [epoch: 27.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8877762805376871		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.8877762805376871 | validation: 0.7301199695635517]
	TIME [epoch: 27.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6923227928367115		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.6923227928367115 | validation: 0.796386236155362]
	TIME [epoch: 27.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6738942614875919		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.6738942614875919 | validation: 0.7750883937915717]
	TIME [epoch: 27.7 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7019566758768659		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.7019566758768659 | validation: 0.596192010074075]
	TIME [epoch: 27.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7730044724255472		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.7730044724255472 | validation: 0.6575875155019709]
	TIME [epoch: 27.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5082291759043533		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.5082291759043533 | validation: 1.447943204888013]
	TIME [epoch: 27.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.258581324170317		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.258581324170317 | validation: 0.9268204362658636]
	TIME [epoch: 27.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0218248995788297		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.0218248995788297 | validation: 1.08063989552549]
	TIME [epoch: 27.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7977328548523734		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.7977328548523734 | validation: 0.6245960271279724]
	TIME [epoch: 27.7 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6685613534277202		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.6685613534277202 | validation: 0.7017738538252999]
	TIME [epoch: 27.7 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7923389073239895		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.7923389073239895 | validation: 0.8778106040555403]
	TIME [epoch: 27.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7363654986006396		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.7363654986006396 | validation: 0.7428639148846624]
	TIME [epoch: 27.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237251231789359		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.7237251231789359 | validation: 1.843097949626379]
	TIME [epoch: 27.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.020273878605694		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 2.020273878605694 | validation: 1.15621173204923]
	TIME [epoch: 27.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.953841382159852		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.953841382159852 | validation: 0.7102092720573369]
	TIME [epoch: 27.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8326159843804244		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.8326159843804244 | validation: 0.6629377897615352]
	TIME [epoch: 27.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8957998566188874		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.8957998566188874 | validation: 0.9987835787758366]
	TIME [epoch: 27.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7998196712527453		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.7998196712527453 | validation: 0.8093189108627116]
	TIME [epoch: 27.7 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8224176240396261		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.8224176240396261 | validation: 0.8869046222330806]
	TIME [epoch: 27.7 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8448638790575612		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.8448638790575612 | validation: 0.759149150876631]
	TIME [epoch: 27.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8823387705196934		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.8823387705196934 | validation: 1.169590371796188]
	TIME [epoch: 27.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0324813290833037		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.0324813290833037 | validation: 0.8727681215721824]
	TIME [epoch: 27.6 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8277757019584524		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.8277757019584524 | validation: 0.8136867781137929]
	TIME [epoch: 27.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7545654473304039		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.7545654473304039 | validation: 0.7727240861341347]
	TIME [epoch: 27.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7875727023041479		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.7875727023041479 | validation: 0.7420329955052657]
	TIME [epoch: 27.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7701103583883419		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.7701103583883419 | validation: 0.8065235037277353]
	TIME [epoch: 27.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7752523761364277		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.7752523761364277 | validation: 0.7405275974309299]
	TIME [epoch: 27.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2371974973584994		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.2371974973584994 | validation: 0.7942192157660733]
	TIME [epoch: 27.6 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7561931941243168		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.7561931941243168 | validation: 0.9678527005890405]
	TIME [epoch: 27.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8154269849169115		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.8154269849169115 | validation: 0.636488625561269]
	TIME [epoch: 27.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7908987227171878		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.7908987227171878 | validation: 0.9684938891490944]
	TIME [epoch: 27.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.864413391270314		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.864413391270314 | validation: 0.8269126815047783]
	TIME [epoch: 27.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8172830685152209		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.8172830685152209 | validation: 0.8447113674212671]
	TIME [epoch: 27.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8823596300805093		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.8823596300805093 | validation: 0.8938298311516727]
	TIME [epoch: 27.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.630942990966306		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.630942990966306 | validation: 1.6460939721787669]
	TIME [epoch: 27.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0721895776077341		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.0721895776077341 | validation: 0.8740217704764126]
	TIME [epoch: 27.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7542314000576853		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.7542314000576853 | validation: 0.8346042168790273]
	TIME [epoch: 27.7 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7779110463677694		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.7779110463677694 | validation: 0.7414960217241426]
	TIME [epoch: 27.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7674634336622466		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.7674634336622466 | validation: 0.7970071721548432]
	TIME [epoch: 27.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7997969440492921		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.7997969440492921 | validation: 0.6424139939683992]
	TIME [epoch: 27.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7639231545324849		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.7639231545324849 | validation: 1.10932907318676]
	TIME [epoch: 27.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8611672793030959		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.8611672793030959 | validation: 0.7833494810314567]
	TIME [epoch: 27.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7524441386953861		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.7524441386953861 | validation: 0.7845910724543064]
	TIME [epoch: 27.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7164356442308331		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.7164356442308331 | validation: 0.6926793163638544]
	TIME [epoch: 27.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6815967865584848		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.6815967865584848 | validation: 0.8344850763456337]
	TIME [epoch: 27.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8399715111856085		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.8399715111856085 | validation: 0.8093433283389044]
	TIME [epoch: 27.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7428757005334605		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.7428757005334605 | validation: 0.7470123376174483]
	TIME [epoch: 27.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6671898446319436		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.6671898446319436 | validation: 0.6026788826808717]
	TIME [epoch: 27.7 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6677160464130518		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.6677160464130518 | validation: 0.6604471065324572]
	TIME [epoch: 27.6 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6321204097087216		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.6321204097087216 | validation: 0.8840561644669771]
	TIME [epoch: 27.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7591385453045475		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.7591385453045475 | validation: 0.8469169668659339]
	TIME [epoch: 27.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7438363485332052		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.7438363485332052 | validation: 0.8029155622634636]
	TIME [epoch: 27.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.682184683365558		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.682184683365558 | validation: 0.6611599103812481]
	TIME [epoch: 27.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6640775947089569		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.6640775947089569 | validation: 0.7018528321280353]
	TIME [epoch: 27.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7075326178739514		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.7075326178739514 | validation: 0.8015671261561144]
	TIME [epoch: 27.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860232905139887		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.6860232905139887 | validation: 0.6525586338319438]
	TIME [epoch: 27.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6386970720248504		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.6386970720248504 | validation: 0.6754844896883503]
	TIME [epoch: 27.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.755920396511667		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.755920396511667 | validation: 0.7538156370570716]
	TIME [epoch: 27.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7750180178455991		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.7750180178455991 | validation: 0.5721523309318437]
	TIME [epoch: 27.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5513941240449297		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.5513941240449297 | validation: 0.6931276688152775]
	TIME [epoch: 27.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6243306416087537		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.6243306416087537 | validation: 0.604403534896868]
	TIME [epoch: 27.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6730326827508071		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.6730326827508071 | validation: 0.6526173630402116]
	TIME [epoch: 27.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6338490588747427		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.6338490588747427 | validation: 0.7519257672913747]
	TIME [epoch: 27.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6672970272925696		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.6672970272925696 | validation: 0.5847781116496751]
	TIME [epoch: 27.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6596449166035586		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.6596449166035586 | validation: 0.7136018293904107]
	TIME [epoch: 27.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7255820796397245		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.7255820796397245 | validation: 0.6482283815706316]
	TIME [epoch: 27.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6100392741060412		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.6100392741060412 | validation: 0.6096199508390913]
	TIME [epoch: 27.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5847380421477559		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.5847380421477559 | validation: 0.5951834328854948]
	TIME [epoch: 27.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6132223242573251		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.6132223242573251 | validation: 0.6257235793483337]
	TIME [epoch: 27.7 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7838109204418227		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.7838109204418227 | validation: 0.6343187157900251]
	TIME [epoch: 27.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6334128090403196		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.6334128090403196 | validation: 0.8164449415291347]
	TIME [epoch: 27.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7061503354221979		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.7061503354221979 | validation: 1.1283293204066405]
	TIME [epoch: 27.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8594536857350477		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.8594536857350477 | validation: 0.7778659101334663]
	TIME [epoch: 27.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7416262838924441		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.7416262838924441 | validation: 0.75582277682513]
	TIME [epoch: 27.6 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6719908704173311		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.6719908704173311 | validation: 0.6029863312647121]
	TIME [epoch: 27.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7138485488022084		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.7138485488022084 | validation: 0.8400420074225247]
	TIME [epoch: 27.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7091311220317404		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.7091311220317404 | validation: 0.6492583304190825]
	TIME [epoch: 27.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6264340837325433		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.6264340837325433 | validation: 0.5996790745018852]
	TIME [epoch: 27.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6098777335993553		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.6098777335993553 | validation: 0.6940822584184823]
	TIME [epoch: 27.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8468029120289327		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.8468029120289327 | validation: 0.7979655143009019]
	TIME [epoch: 27.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210558279144147		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.7210558279144147 | validation: 0.6468055151225189]
	TIME [epoch: 27.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6033693899386139		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.6033693899386139 | validation: 0.577113514391078]
	TIME [epoch: 27.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.574055089460891		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.574055089460891 | validation: 0.6098203880918808]
	TIME [epoch: 27.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6711353496772126		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.6711353496772126 | validation: 0.61796588232072]
	TIME [epoch: 27.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6278519029946149		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.6278519029946149 | validation: 0.7262824424164123]
	TIME [epoch: 27.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.67800937143329		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.67800937143329 | validation: 0.7404954220367488]
	TIME [epoch: 27.6 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6384399800395621		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.6384399800395621 | validation: 0.6554631402297596]
	TIME [epoch: 27.6 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6733602118209809		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.6733602118209809 | validation: 0.7417533848411592]
	TIME [epoch: 27.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6008824011547397		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.6008824011547397 | validation: 0.6535311782234311]
	TIME [epoch: 27.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.71317696447157		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.71317696447157 | validation: 0.6948077547396736]
	TIME [epoch: 27.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5972327381261314		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.5972327381261314 | validation: 0.5539312096602395]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_442.pth
	Model improved!!!
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5403419322939014		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.5403419322939014 | validation: 0.6903850175816264]
	TIME [epoch: 27.7 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6373108955877288		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.6373108955877288 | validation: 0.753545367277448]
	TIME [epoch: 27.7 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7137767472670067		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.7137767472670067 | validation: 0.6292954897286317]
	TIME [epoch: 27.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.718383032507491		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.718383032507491 | validation: 0.8343043586342003]
	TIME [epoch: 27.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6570479445827423		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.6570479445827423 | validation: 0.627737652164691]
	TIME [epoch: 27.7 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9131260293760028		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.9131260293760028 | validation: 0.6153723489308977]
	TIME [epoch: 27.6 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.573704231727483		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.573704231727483 | validation: 1.3200212800202935]
	TIME [epoch: 27.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3030501593299189		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.3030501593299189 | validation: 1.2713326048520481]
	TIME [epoch: 27.6 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8446543984320452		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.8446543984320452 | validation: 0.6918780687440415]
	TIME [epoch: 27.6 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6721045994033524		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.6721045994033524 | validation: 0.6554712630491761]
	TIME [epoch: 27.6 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6596913366318113		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.6596913366318113 | validation: 0.7820475284351415]
	TIME [epoch: 27.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6343759727361793		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.6343759727361793 | validation: 0.5208512254865905]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_454.pth
	Model improved!!!
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5870926102389808		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.5870926102389808 | validation: 0.6099960744978795]
	TIME [epoch: 27.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.605532970556994		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.605532970556994 | validation: 0.6136052784801944]
	TIME [epoch: 27.6 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6063175207460378		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.6063175207460378 | validation: 0.6037890675003602]
	TIME [epoch: 27.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5888851067343117		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.5888851067343117 | validation: 0.6680769112243695]
	TIME [epoch: 27.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6564500879210716		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.6564500879210716 | validation: 0.677064421518837]
	TIME [epoch: 27.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6368191397895926		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.6368191397895926 | validation: 0.5751117440868863]
	TIME [epoch: 27.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.568042047229468		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.568042047229468 | validation: 0.695785659174605]
	TIME [epoch: 27.6 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5894941150300221		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.5894941150300221 | validation: 0.757143038126019]
	TIME [epoch: 27.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7716802302084944		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.7716802302084944 | validation: 0.7568535130888756]
	TIME [epoch: 27.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7535160566410936		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.7535160566410936 | validation: 0.7590329216097657]
	TIME [epoch: 27.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.661928252445591		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.661928252445591 | validation: 0.6218381297596504]
	TIME [epoch: 27.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5602686673335129		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.5602686673335129 | validation: 0.6538522318046139]
	TIME [epoch: 27.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.567428339430432		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.567428339430432 | validation: 0.5457530584283675]
	TIME [epoch: 27.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5449152799714945		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.5449152799714945 | validation: 0.66234224937437]
	TIME [epoch: 27.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5740536315912047		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.5740536315912047 | validation: 0.5458168332427826]
	TIME [epoch: 27.6 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.51985613253868		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.51985613253868 | validation: 0.5224864494121321]
	TIME [epoch: 27.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5035129516156105		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.5035129516156105 | validation: 0.5404787549679183]
	TIME [epoch: 27.6 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5180010537176368		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.5180010537176368 | validation: 0.5238818784208324]
	TIME [epoch: 27.6 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7391751534632531		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.7391751534632531 | validation: 0.6585076682619717]
	TIME [epoch: 27.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5889399714868145		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.5889399714868145 | validation: 0.5413266958453056]
	TIME [epoch: 27.6 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.509009569445247		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.509009569445247 | validation: 0.5524369766073923]
	TIME [epoch: 27.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4839950767466101		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.4839950767466101 | validation: 0.5330662180772965]
	TIME [epoch: 27.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5943577333980985		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.5943577333980985 | validation: 0.7892392570387843]
	TIME [epoch: 27.7 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6663443174255089		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.6663443174255089 | validation: 0.6618345677874745]
	TIME [epoch: 27.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5323983658001665		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.5323983658001665 | validation: 0.618594021048168]
	TIME [epoch: 27.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5883500571369715		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.5883500571369715 | validation: 0.5160978930976413]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_480.pth
	Model improved!!!
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5231547133668273		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.5231547133668273 | validation: 0.5332849900494314]
	TIME [epoch: 27.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5505846741491104		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.5505846741491104 | validation: 0.514211260947052]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_482.pth
	Model improved!!!
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.612700537224708		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.612700537224708 | validation: 0.6398832682673422]
	TIME [epoch: 27.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5858482954943944		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.5858482954943944 | validation: 0.5446421981007843]
	TIME [epoch: 27.7 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8448660960489559		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.8448660960489559 | validation: 0.9584066847701985]
	TIME [epoch: 27.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8067281230073797		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.8067281230073797 | validation: 0.8774322294771537]
	TIME [epoch: 27.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8099546091835066		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.8099546091835066 | validation: 0.7538946231882955]
	TIME [epoch: 27.6 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7173054351854398		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.7173054351854398 | validation: 0.7522568195940197]
	TIME [epoch: 27.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6287149608732732		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.6287149608732732 | validation: 0.5774309915895439]
	TIME [epoch: 27.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5477769513048216		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.5477769513048216 | validation: 0.8439246794331666]
	TIME [epoch: 27.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6098704307999473		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.6098704307999473 | validation: 0.6552397082200635]
	TIME [epoch: 27.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7943109250361194		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.7943109250361194 | validation: 0.6334457939909222]
	TIME [epoch: 27.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6206583980796139		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.6206583980796139 | validation: 0.8035265573563252]
	TIME [epoch: 27.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7963431190808549		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.7963431190808549 | validation: 0.6683271150484719]
	TIME [epoch: 27.6 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7044231349304444		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.7044231349304444 | validation: 0.5386148222393433]
	TIME [epoch: 27.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7820513868738379		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.7820513868738379 | validation: 0.9368946362726538]
	TIME [epoch: 27.7 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7429830659459826		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.7429830659459826 | validation: 0.7162823261704572]
	TIME [epoch: 27.7 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6693034550634533		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.6693034550634533 | validation: 0.6594487132679933]
	TIME [epoch: 27.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.571584389120387		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.571584389120387 | validation: 0.5754671266262319]
	TIME [epoch: 27.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6267606125387892		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.6267606125387892 | validation: 0.6110687905486707]
	TIME [epoch: 27.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5513675826665084		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.5513675826665084 | validation: 0.622242637266758]
	TIME [epoch: 27.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5747114047756385		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.5747114047756385 | validation: 0.6750657589284816]
	TIME [epoch: 27.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5761688066149191		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.5761688066149191 | validation: 0.5867397923644687]
	TIME [epoch: 27.7 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6235972799834918		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.6235972799834918 | validation: 0.6593875165734358]
	TIME [epoch: 27.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5387705002591824		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.5387705002591824 | validation: 0.5868816845704538]
	TIME [epoch: 27.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5534635141522877		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.5534635141522877 | validation: 0.6203429300427822]
	TIME [epoch: 27.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5874277881391393		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.5874277881391393 | validation: 0.6313298433196286]
	TIME [epoch: 27.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5884576885297729		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.5884576885297729 | validation: 0.5317051576440407]
	TIME [epoch: 27.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5478109913861117		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.5478109913861117 | validation: 0.6917787973516875]
	TIME [epoch: 27.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5789159658634438		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.5789159658634438 | validation: 0.5983856145025996]
	TIME [epoch: 27.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5414027157671866		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.5414027157671866 | validation: 0.5016121618882294]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_511.pth
	Model improved!!!
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48331292224628286		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.48331292224628286 | validation: 0.5900816443921609]
	TIME [epoch: 27.7 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5615824837450214		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.5615824837450214 | validation: 0.6706893837891349]
	TIME [epoch: 27.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5877091436303427		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.5877091436303427 | validation: 0.5071745965976524]
	TIME [epoch: 27.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5348445907078229		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.5348445907078229 | validation: 0.5675552813486499]
	TIME [epoch: 27.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.516984820232963		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.516984820232963 | validation: 0.482982929530173]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_516.pth
	Model improved!!!
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5341118173953703		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.5341118173953703 | validation: 0.49187088698386644]
	TIME [epoch: 27.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5143600592572163		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.5143600592572163 | validation: 0.5075043412632511]
	TIME [epoch: 27.7 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6540154169226197		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.6540154169226197 | validation: 0.6231445966078455]
	TIME [epoch: 27.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5548514817043584		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.5548514817043584 | validation: 0.5164596892118162]
	TIME [epoch: 27.7 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5350743566572754		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.5350743566572754 | validation: 0.5248502551061164]
	TIME [epoch: 27.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4772328490291566		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.4772328490291566 | validation: 0.4893569290165392]
	TIME [epoch: 27.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5756182066384669		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.5756182066384669 | validation: 0.504790598445595]
	TIME [epoch: 27.7 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4906902350197929		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.4906902350197929 | validation: 0.49929345954404236]
	TIME [epoch: 27.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4973477328572532		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.4973477328572532 | validation: 0.5858487947127803]
	TIME [epoch: 27.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.810274780673802		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.810274780673802 | validation: 0.8627106132282434]
	TIME [epoch: 27.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8116707157864541		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.8116707157864541 | validation: 0.5877461262312788]
	TIME [epoch: 27.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5922910136699988		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.5922910136699988 | validation: 0.515181394166616]
	TIME [epoch: 27.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4785014007041482		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.4785014007041482 | validation: 0.5110078387770421]
	TIME [epoch: 27.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.478862847360259		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.478862847360259 | validation: 1.1018326572501005]
	TIME [epoch: 27.7 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0548737150538166		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 1.0548737150538166 | validation: 0.6027108599230224]
	TIME [epoch: 27.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5422311776550726		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.5422311776550726 | validation: 0.6638928927627867]
	TIME [epoch: 27.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5219998290627255		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.5219998290627255 | validation: 0.5777728421927023]
	TIME [epoch: 27.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.505368364880334		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.505368364880334 | validation: 0.492540787227974]
	TIME [epoch: 27.6 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6709516598002442		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.6709516598002442 | validation: 0.8114817265155488]
	TIME [epoch: 27.7 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6296973533038986		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.6296973533038986 | validation: 0.6423487829781627]
	TIME [epoch: 27.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5881195926155405		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.5881195926155405 | validation: 0.6996142053697306]
	TIME [epoch: 27.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5993120919966702		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.5993120919966702 | validation: 0.5662109719803933]
	TIME [epoch: 27.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49299259914084403		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.49299259914084403 | validation: 0.5201485212722101]
	TIME [epoch: 27.7 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5822747940226747		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.5822747940226747 | validation: 0.49200986692896326]
	TIME [epoch: 27.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48322746644214765		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.48322746644214765 | validation: 0.5385116161050164]
	TIME [epoch: 27.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5925451783112302		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.5925451783112302 | validation: 0.49316114059021415]
	TIME [epoch: 27.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47813580056130167		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.47813580056130167 | validation: 0.5041083576988851]
	TIME [epoch: 27.7 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4783851431491435		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.4783851431491435 | validation: 0.5677099517817378]
	TIME [epoch: 27.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5043935130646154		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.5043935130646154 | validation: 0.4870870345346465]
	TIME [epoch: 27.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45665597066473756		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.45665597066473756 | validation: 0.495817494632564]
	TIME [epoch: 27.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5125267039229027		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.5125267039229027 | validation: 0.6935465513341859]
	TIME [epoch: 27.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.65712811549484		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.65712811549484 | validation: 0.7798739760949636]
	TIME [epoch: 27.7 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5817261940963895		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.5817261940963895 | validation: 0.5265377861434434]
	TIME [epoch: 27.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4809701515202653		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.4809701515202653 | validation: 0.5164753236656603]
	TIME [epoch: 27.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5377926711947332		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.5377926711947332 | validation: 0.6778613412291195]
	TIME [epoch: 27.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5604024381568397		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.5604024381568397 | validation: 0.4730914328896956]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_552.pth
	Model improved!!!
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47080106056542237		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.47080106056542237 | validation: 0.7650554895603773]
	TIME [epoch: 27.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0278027852247782		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 1.0278027852247782 | validation: 0.7005044092536781]
	TIME [epoch: 27.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5467925414688042		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.5467925414688042 | validation: 0.5662912750229484]
	TIME [epoch: 27.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6734050470025932		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.6734050470025932 | validation: 0.6971621101188638]
	TIME [epoch: 27.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6299716556740647		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.6299716556740647 | validation: 0.5569897403930605]
	TIME [epoch: 27.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5256834741855644		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.5256834741855644 | validation: 0.5757768778024628]
	TIME [epoch: 27.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47748948329495355		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.47748948329495355 | validation: 0.4647362402389741]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_559.pth
	Model improved!!!
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47450663976145957		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.47450663976145957 | validation: 0.5229851488103081]
	TIME [epoch: 27.7 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5529365161388262		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.5529365161388262 | validation: 0.513663611767512]
	TIME [epoch: 27.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5190101721148439		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.5190101721148439 | validation: 0.46388337778087746]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_562.pth
	Model improved!!!
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46244797393491904		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.46244797393491904 | validation: 0.5141678594330932]
	TIME [epoch: 27.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4789964215417115		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.4789964215417115 | validation: 0.6246145449549355]
	TIME [epoch: 27.7 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5915684625333634		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.5915684625333634 | validation: 1.0142901428610511]
	TIME [epoch: 27.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8727891412376424		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.8727891412376424 | validation: 0.6367476173036296]
	TIME [epoch: 27.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5685662213344247		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.5685662213344247 | validation: 0.5293459233809656]
	TIME [epoch: 27.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.584894962782124		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.584894962782124 | validation: 0.5346707916937958]
	TIME [epoch: 27.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5102946310584923		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.5102946310584923 | validation: 0.4905190602941683]
	TIME [epoch: 27.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45182095020604074		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.45182095020604074 | validation: 0.5424536148601282]
	TIME [epoch: 27.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5065002541547468		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.5065002541547468 | validation: 0.46763411283558726]
	TIME [epoch: 27.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49770884007866073		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.49770884007866073 | validation: 0.4904842597764019]
	TIME [epoch: 27.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48491538203364937		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.48491538203364937 | validation: 0.48257392827450957]
	TIME [epoch: 27.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4543960124388766		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.4543960124388766 | validation: 0.4748584826398181]
	TIME [epoch: 27.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4345683076376795		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.4345683076376795 | validation: 0.7005904128734625]
	TIME [epoch: 27.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6677504631777403		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.6677504631777403 | validation: 0.460471631518025]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_576.pth
	Model improved!!!
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42932489097032944		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.42932489097032944 | validation: 0.5129529457873906]
	TIME [epoch: 27.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4743807502368624		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.4743807502368624 | validation: 0.5163572743657147]
	TIME [epoch: 27.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4963175587288253		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.4963175587288253 | validation: 0.5425574992746008]
	TIME [epoch: 27.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4754556008436104		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.4754556008436104 | validation: 0.50126373255666]
	TIME [epoch: 27.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5004179167557277		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.5004179167557277 | validation: 0.5835035874619142]
	TIME [epoch: 27.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5470787834103983		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.5470787834103983 | validation: 0.4873774958174265]
	TIME [epoch: 27.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6605095624483124		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.6605095624483124 | validation: 0.6975092199617997]
	TIME [epoch: 27.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.592446618213401		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.592446618213401 | validation: 0.6071151201413731]
	TIME [epoch: 27.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5592110375713698		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.5592110375713698 | validation: 0.5148435361398042]
	TIME [epoch: 27.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6743492610273758		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.6743492610273758 | validation: 0.5900682166153367]
	TIME [epoch: 27.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.516932569866722		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.516932569866722 | validation: 0.5351945500965131]
	TIME [epoch: 27.7 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4678702211873527		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.4678702211873527 | validation: 0.47833359288685834]
	TIME [epoch: 27.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44911996857140557		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.44911996857140557 | validation: 0.4981552536022841]
	TIME [epoch: 27.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44086424241751043		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.44086424241751043 | validation: 0.4617720176629226]
	TIME [epoch: 27.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45183519841510683		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.45183519841510683 | validation: 0.6278118442093242]
	TIME [epoch: 27.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5830825912074169		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.5830825912074169 | validation: 0.5346555560288837]
	TIME [epoch: 27.7 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4827973725373461		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.4827973725373461 | validation: 0.654320094942289]
	TIME [epoch: 27.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.518775691832253		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.518775691832253 | validation: 0.5404698946755467]
	TIME [epoch: 27.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5046824602749995		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.5046824602749995 | validation: 0.5136235234170385]
	TIME [epoch: 27.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4704171266778732		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.4704171266778732 | validation: 0.5696170125808101]
	TIME [epoch: 27.7 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49216895821629936		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.49216895821629936 | validation: 0.5459720799147328]
	TIME [epoch: 27.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4794175663574255		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.4794175663574255 | validation: 0.7046791818297078]
	TIME [epoch: 27.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5606344814150812		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.5606344814150812 | validation: 0.5065877896816228]
	TIME [epoch: 27.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49824379652916806		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.49824379652916806 | validation: 0.6160919232926242]
	TIME [epoch: 27.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4992167959227586		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.4992167959227586 | validation: 0.548166040758665]
	TIME [epoch: 27.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4772926458246989		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.4772926458246989 | validation: 0.6012918110069738]
	TIME [epoch: 27.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.615331765074079		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.615331765074079 | validation: 0.7736490770421918]
	TIME [epoch: 27.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6031803176587139		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.6031803176587139 | validation: 0.6127515083232116]
	TIME [epoch: 27.7 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5716271361162893		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.5716271361162893 | validation: 0.7463873598162769]
	TIME [epoch: 27.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6269422970558622		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.6269422970558622 | validation: 0.7656897565909148]
	TIME [epoch: 27.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6588647680895566		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.6588647680895566 | validation: 0.6716190382707388]
	TIME [epoch: 27.7 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6028731883265156		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.6028731883265156 | validation: 0.5742816151321887]
	TIME [epoch: 27.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5047303182750488		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.5047303182750488 | validation: 0.5646282151904065]
	TIME [epoch: 27.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5067077394609076		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.5067077394609076 | validation: 0.5451133323505717]
	TIME [epoch: 27.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48175023214372		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.48175023214372 | validation: 0.5648033100875595]
	TIME [epoch: 27.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5037200816209211		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.5037200816209211 | validation: 0.5366160095294734]
	TIME [epoch: 27.7 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5245416041396693		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.5245416041396693 | validation: 0.6319310227730179]
	TIME [epoch: 27.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5170829963176131		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.5170829963176131 | validation: 0.6468844738613757]
	TIME [epoch: 27.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5322012516911616		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.5322012516911616 | validation: 0.5951757238471769]
	TIME [epoch: 27.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5323351695789496		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.5323351695789496 | validation: 0.5868916289875196]
	TIME [epoch: 27.7 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.525458373151142		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.525458373151142 | validation: 0.6572705581292874]
	TIME [epoch: 27.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.582098267768997		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.582098267768997 | validation: 0.6163899216753127]
	TIME [epoch: 27.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5910480297718088		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.5910480297718088 | validation: 0.7135995460703481]
	TIME [epoch: 27.7 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6044920209650182		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.6044920209650182 | validation: 0.6227307940995014]
	TIME [epoch: 27.7 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5814806997784439		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.5814806997784439 | validation: 0.6855507143684213]
	TIME [epoch: 27.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6089309026900545		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.6089309026900545 | validation: 0.6495883045031576]
	TIME [epoch: 27.7 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5945586795101852		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.5945586795101852 | validation: 0.5214076537962697]
	TIME [epoch: 27.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5137481044563463		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.5137481044563463 | validation: 0.6561713336719798]
	TIME [epoch: 27.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8618019916303319		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.8618019916303319 | validation: 0.7187488241018885]
	TIME [epoch: 27.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6206809162768516		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.6206809162768516 | validation: 0.5555747239426915]
	TIME [epoch: 27.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5760889753548867		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.5760889753548867 | validation: 0.6574038604354969]
	TIME [epoch: 27.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.552710204000439		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.552710204000439 | validation: 0.5495661459906829]
	TIME [epoch: 27.7 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5247239176811613		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.5247239176811613 | validation: 0.7010040178572002]
	TIME [epoch: 27.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5686869605758311		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.5686869605758311 | validation: 0.5012970475001884]
	TIME [epoch: 27.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4723945560180207		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.4723945560180207 | validation: 0.5002765430795015]
	TIME [epoch: 27.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43952205636273034		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.43952205636273034 | validation: 0.5137573204596906]
	TIME [epoch: 27.7 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47669625526857934		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.47669625526857934 | validation: 0.5784926378322435]
	TIME [epoch: 27.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6512932982106251		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.6512932982106251 | validation: 0.5036640975096178]
	TIME [epoch: 27.7 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4936855551904966		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.4936855551904966 | validation: 0.5009736040975628]
	TIME [epoch: 27.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45783409996413327		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.45783409996413327 | validation: 0.4768549031784849]
	TIME [epoch: 27.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5826436870668019		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.5826436870668019 | validation: 0.45413422377424456]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_637.pth
	Model improved!!!
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46307359003581083		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.46307359003581083 | validation: 0.49135539678726065]
	TIME [epoch: 27.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4738117188376082		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.4738117188376082 | validation: 0.5149519778577181]
	TIME [epoch: 27.7 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46533659161812224		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.46533659161812224 | validation: 0.49995679656459646]
	TIME [epoch: 27.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43329329394389315		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.43329329394389315 | validation: 0.43899379962382507]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_641.pth
	Model improved!!!
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4444896864922758		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.4444896864922758 | validation: 0.42905525878766027]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_642.pth
	Model improved!!!
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4148892973197664		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.4148892973197664 | validation: 0.4606871621452189]
	TIME [epoch: 27.6 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43719068817525786		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.43719068817525786 | validation: 0.46685514290514535]
	TIME [epoch: 27.6 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5132816185497072		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.5132816185497072 | validation: 0.5227783360143263]
	TIME [epoch: 27.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5115625530370789		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.5115625530370789 | validation: 0.7438248790372408]
	TIME [epoch: 27.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5419657829362846		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.5419657829362846 | validation: 0.4429718730026802]
	TIME [epoch: 27.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4122790506864978		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.4122790506864978 | validation: 0.4715019579216703]
	TIME [epoch: 27.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4215695775547924		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.4215695775547924 | validation: 0.46176226880237736]
	TIME [epoch: 27.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4059928916836993		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.4059928916836993 | validation: 0.6136066021318797]
	TIME [epoch: 27.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5138285851430636		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.5138285851430636 | validation: 0.42769258337473276]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_651.pth
	Model improved!!!
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4073178128271013		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.4073178128271013 | validation: 0.4725797294722975]
	TIME [epoch: 27.7 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4701156597675098		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.4701156597675098 | validation: 0.5716801496860379]
	TIME [epoch: 27.7 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48070196237463814		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.48070196237463814 | validation: 0.5070097289732641]
	TIME [epoch: 27.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5072811367177452		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.5072811367177452 | validation: 0.46888302880470406]
	TIME [epoch: 27.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4419492385046118		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.4419492385046118 | validation: 0.4663925062272358]
	TIME [epoch: 27.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.485797600052955		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.485797600052955 | validation: 0.44799052563195213]
	TIME [epoch: 27.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46002358242220726		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.46002358242220726 | validation: 0.4703686587863966]
	TIME [epoch: 27.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4300077709288397		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.4300077709288397 | validation: 0.5350521292155493]
	TIME [epoch: 27.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44532495251374893		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.44532495251374893 | validation: 0.5515864741441048]
	TIME [epoch: 27.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5547086128533114		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.5547086128533114 | validation: 0.6119956991461358]
	TIME [epoch: 27.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5315536502282495		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.5315536502282495 | validation: 0.4501294163376733]
	TIME [epoch: 27.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40353348164518327		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.40353348164518327 | validation: 0.49029081386463985]
	TIME [epoch: 27.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44455090443003603		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.44455090443003603 | validation: 0.447300633680058]
	TIME [epoch: 27.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4184774766930055		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.4184774766930055 | validation: 0.41747899774394376]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_665.pth
	Model improved!!!
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3999916472277737		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.3999916472277737 | validation: 0.44123983027241354]
	TIME [epoch: 27.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42232883616673156		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.42232883616673156 | validation: 0.43390526224371223]
	TIME [epoch: 27.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40005200660244133		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.40005200660244133 | validation: 0.5619436271465181]
	TIME [epoch: 27.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44502752981565746		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.44502752981565746 | validation: 0.4499443970462841]
	TIME [epoch: 27.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4360920349570459		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.4360920349570459 | validation: 0.539065120316265]
	TIME [epoch: 27.7 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5971106625138717		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.5971106625138717 | validation: 0.6538460414347431]
	TIME [epoch: 27.7 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6056851884907228		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.6056851884907228 | validation: 0.7463286926731937]
	TIME [epoch: 27.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5678452767715644		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.5678452767715644 | validation: 0.4564450761989567]
	TIME [epoch: 27.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4282332645904062		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.4282332645904062 | validation: 0.4489469384459357]
	TIME [epoch: 27.7 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40642744799699604		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.40642744799699604 | validation: 0.4449074827558055]
	TIME [epoch: 27.7 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43064169605392455		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.43064169605392455 | validation: 0.49897848997750144]
	TIME [epoch: 27.7 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44375251607755406		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.44375251607755406 | validation: 0.5111981781035599]
	TIME [epoch: 27.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46681474019797886		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.46681474019797886 | validation: 0.6440548479583649]
	TIME [epoch: 27.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5191774908095811		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.5191774908095811 | validation: 0.5269217081890782]
	TIME [epoch: 27.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4722409289697363		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.4722409289697363 | validation: 0.4511342828969426]
	TIME [epoch: 27.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4687521661130733		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.4687521661130733 | validation: 0.48245209047444954]
	TIME [epoch: 27.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4200292533130773		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.4200292533130773 | validation: 0.4412766096144358]
	TIME [epoch: 27.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42958414353503627		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.42958414353503627 | validation: 0.4987020950550643]
	TIME [epoch: 27.7 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45534685007431974		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.45534685007431974 | validation: 0.6143255951916572]
	TIME [epoch: 27.7 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49531727735775777		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.49531727735775777 | validation: 0.4573497809206529]
	TIME [epoch: 27.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4241245062531275		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.4241245062531275 | validation: 0.5110068804027302]
	TIME [epoch: 27.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48989268932841096		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.48989268932841096 | validation: 0.5423192466637421]
	TIME [epoch: 27.7 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6169456996841136		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.6169456996841136 | validation: 0.6044218047049633]
	TIME [epoch: 27.7 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5440167057308553		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.5440167057308553 | validation: 0.45503805552228926]
	TIME [epoch: 27.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42837986716814563		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.42837986716814563 | validation: 0.42325196123111897]
	TIME [epoch: 27.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41884467584857266		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.41884467584857266 | validation: 0.4264862257902102]
	TIME [epoch: 27.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4114092574102335		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.4114092574102335 | validation: 0.4213909918473608]
	TIME [epoch: 27.7 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40803316907043813		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.40803316907043813 | validation: 0.4136578923095408]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_693.pth
	Model improved!!!
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4082562257627573		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.4082562257627573 | validation: 0.4167269511934062]
	TIME [epoch: 27.7 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3942072064210963		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.3942072064210963 | validation: 0.42994197995288574]
	TIME [epoch: 27.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42510095137107656		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.42510095137107656 | validation: 0.5197599935934261]
	TIME [epoch: 27.7 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45904484504723897		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.45904484504723897 | validation: 0.44339999021230225]
	TIME [epoch: 27.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.398823540297777		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.398823540297777 | validation: 0.43339981503951064]
	TIME [epoch: 27.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4283570466570479		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.4283570466570479 | validation: 0.5369210788423717]
	TIME [epoch: 27.7 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43481383779631877		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.43481383779631877 | validation: 0.4427045935639891]
	TIME [epoch: 27.7 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3942805535479954		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.3942805535479954 | validation: 0.436448302100058]
	TIME [epoch: 27.7 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4086153497344019		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.4086153497344019 | validation: 0.5343057206202171]
	TIME [epoch: 27.7 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43450491504403205		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.43450491504403205 | validation: 0.5519040229452842]
	TIME [epoch: 27.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49692954780505966		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.49692954780505966 | validation: 0.4537681195066249]
	TIME [epoch: 27.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.410959777240661		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.410959777240661 | validation: 0.44573668397691235]
	TIME [epoch: 27.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43777191000979065		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.43777191000979065 | validation: 0.5327036948286791]
	TIME [epoch: 27.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47470013652973864		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.47470013652973864 | validation: 0.5021243894456167]
	TIME [epoch: 27.7 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4291389285356477		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.4291389285356477 | validation: 0.44403847130929264]
	TIME [epoch: 27.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3854182462988332		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.3854182462988332 | validation: 0.42090705965872344]
	TIME [epoch: 27.7 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40554367766608623		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.40554367766608623 | validation: 0.4937358870971936]
	TIME [epoch: 27.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4067915694929947		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.4067915694929947 | validation: 0.47090629269434403]
	TIME [epoch: 27.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4462217009445949		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.4462217009445949 | validation: 0.43427386951928015]
	TIME [epoch: 27.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3945374978611984		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.3945374978611984 | validation: 0.4538382476598857]
	TIME [epoch: 27.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42391240061291435		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.42391240061291435 | validation: 0.6465982917580116]
	TIME [epoch: 27.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49397921578950166		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.49397921578950166 | validation: 0.46365393166240737]
	TIME [epoch: 27.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4064636644289156		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.4064636644289156 | validation: 0.49901255866630095]
	TIME [epoch: 27.8 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44882123064419766		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.44882123064419766 | validation: 0.653037460453573]
	TIME [epoch: 27.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6623439649939411		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.6623439649939411 | validation: 0.43751571416873575]
	TIME [epoch: 27.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3957661623530567		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.3957661623530567 | validation: 0.45095410339883657]
	TIME [epoch: 27.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42449258770160503		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.42449258770160503 | validation: 0.4385227322281376]
	TIME [epoch: 27.7 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38357152138564155		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.38357152138564155 | validation: 0.43178129437996937]
	TIME [epoch: 27.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49982246698050453		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.49982246698050453 | validation: 0.5033021699768555]
	TIME [epoch: 27.7 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4305023699807822		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.4305023699807822 | validation: 0.45862631850724145]
	TIME [epoch: 27.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42978474318838233		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.42978474318838233 | validation: 0.5012414562488148]
	TIME [epoch: 27.8 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4677028448732903		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.4677028448732903 | validation: 0.4784924737948215]
	TIME [epoch: 27.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4442977120489304		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.4442977120489304 | validation: 0.5071492674384299]
	TIME [epoch: 27.8 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4873554412242357		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.4873554412242357 | validation: 0.5052191188311885]
	TIME [epoch: 27.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4614171762509864		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.4614171762509864 | validation: 0.49460973299826366]
	TIME [epoch: 27.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5030975445605246		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.5030975445605246 | validation: 0.6020747809836914]
	TIME [epoch: 27.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.448608295645214		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.448608295645214 | validation: 0.49708175090253726]
	TIME [epoch: 27.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49717386866682806		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.49717386866682806 | validation: 0.5176112038533812]
	TIME [epoch: 27.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43247948386064405		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.43247948386064405 | validation: 0.45551641711045593]
	TIME [epoch: 27.8 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4234171694019597		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.4234171694019597 | validation: 0.5119287426895992]
	TIME [epoch: 27.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5421530579564201		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.5421530579564201 | validation: 0.6280767648350566]
	TIME [epoch: 27.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.648498530765588		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.648498530765588 | validation: 0.7350354412183286]
	TIME [epoch: 27.7 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6138194888224182		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.6138194888224182 | validation: 0.5714781023737814]
	TIME [epoch: 27.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.51639368685698		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.51639368685698 | validation: 0.5015304996823143]
	TIME [epoch: 27.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4812332856977477		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.4812332856977477 | validation: 0.468590515809384]
	TIME [epoch: 27.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41409191341699064		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.41409191341699064 | validation: 0.4931684519641149]
	TIME [epoch: 27.7 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46138695885478154		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.46138695885478154 | validation: 0.4437145684236121]
	TIME [epoch: 27.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40091093624161334		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.40091093624161334 | validation: 0.4652010755483128]
	TIME [epoch: 27.7 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5054295949975716		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.5054295949975716 | validation: 0.4916802827223037]
	TIME [epoch: 27.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43773782316702664		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.43773782316702664 | validation: 0.5328282868224348]
	TIME [epoch: 27.7 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4737168599041385		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.4737168599041385 | validation: 0.5512330060416454]
	TIME [epoch: 27.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5082355974658961		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.5082355974658961 | validation: 0.41489502593986416]
	TIME [epoch: 27.7 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44104676002109844		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.44104676002109844 | validation: 0.5264922534559267]
	TIME [epoch: 27.7 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46134955338666905		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.46134955338666905 | validation: 0.4661399012517522]
	TIME [epoch: 27.7 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4432294994052483		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.4432294994052483 | validation: 0.4945813614316275]
	TIME [epoch: 27.7 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4464594917456726		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.4464594917456726 | validation: 0.47269949166297587]
	TIME [epoch: 27.7 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48704272754294814		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.48704272754294814 | validation: 0.4290443687017034]
	TIME [epoch: 27.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3930981431428532		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.3930981431428532 | validation: 0.46882973130815847]
	TIME [epoch: 27.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4212423346752484		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.4212423346752484 | validation: 0.43099223881599663]
	TIME [epoch: 27.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40311427594788535		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.40311427594788535 | validation: 0.441588504681519]
	TIME [epoch: 27.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4461002835472198		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.4461002835472198 | validation: 0.6254020144327131]
	TIME [epoch: 27.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5343510648496365		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.5343510648496365 | validation: 0.4512946798740254]
	TIME [epoch: 27.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3910180147329145		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.3910180147329145 | validation: 0.45255464856485533]
	TIME [epoch: 27.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47878979867116256		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.47878979867116256 | validation: 0.5399467208399706]
	TIME [epoch: 27.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4164360792123919		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.4164360792123919 | validation: 0.4877819586477641]
	TIME [epoch: 27.8 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4524004513252298		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.4524004513252298 | validation: 0.4518995869754797]
	TIME [epoch: 27.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5162734047871972		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.5162734047871972 | validation: 0.5789478385333495]
	TIME [epoch: 27.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48865250388503734		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.48865250388503734 | validation: 0.50449667277942]
	TIME [epoch: 27.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5499434912136874		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.5499434912136874 | validation: 0.6351072575866128]
	TIME [epoch: 27.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49402339225774844		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.49402339225774844 | validation: 0.4519477591932328]
	TIME [epoch: 27.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4011258208139448		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.4011258208139448 | validation: 0.461169350618572]
	TIME [epoch: 27.8 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4053741820546728		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.4053741820546728 | validation: 0.42275619480864096]
	TIME [epoch: 27.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3923520183459289		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.3923520183459289 | validation: 0.41210588937839165]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_766.pth
	Model improved!!!
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37701323678212334		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.37701323678212334 | validation: 0.39949903967199846]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_767.pth
	Model improved!!!
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3843039890838116		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.3843039890838116 | validation: 0.48219685512643323]
	TIME [epoch: 27.7 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43772265020643436		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.43772265020643436 | validation: 0.4327953059989663]
	TIME [epoch: 27.7 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40452759143228334		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.40452759143228334 | validation: 0.4660202722797975]
	TIME [epoch: 27.7 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40737077020617096		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.40737077020617096 | validation: 0.49620197741684885]
	TIME [epoch: 27.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4415127119837694		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.4415127119837694 | validation: 0.46243002949290574]
	TIME [epoch: 27.7 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40703509844416896		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.40703509844416896 | validation: 0.4404297609635478]
	TIME [epoch: 27.7 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4150392604638389		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.4150392604638389 | validation: 0.41703293752500464]
	TIME [epoch: 27.7 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3856695940335433		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.3856695940335433 | validation: 0.46310201928914607]
	TIME [epoch: 27.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5228746587878398		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.5228746587878398 | validation: 0.5968663976217998]
	TIME [epoch: 27.7 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4471180164766715		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.4471180164766715 | validation: 0.4108326681366151]
	TIME [epoch: 27.7 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3848772273958053		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.3848772273958053 | validation: 0.4706630280359278]
	TIME [epoch: 27.7 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41048044360915925		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.41048044360915925 | validation: 0.4332007721343708]
	TIME [epoch: 27.7 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39017308700482245		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.39017308700482245 | validation: 0.43371178597582344]
	TIME [epoch: 27.7 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42588215531767426		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.42588215531767426 | validation: 0.49994814333635107]
	TIME [epoch: 27.7 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48753683281416826		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.48753683281416826 | validation: 0.5194609460426429]
	TIME [epoch: 27.7 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42900108113815827		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.42900108113815827 | validation: 0.4518633048478974]
	TIME [epoch: 27.7 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4387093634793127		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.4387093634793127 | validation: 0.4440189266039515]
	TIME [epoch: 27.8 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4688575941409652		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.4688575941409652 | validation: 0.5362646784963867]
	TIME [epoch: 27.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5172676411168295		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.5172676411168295 | validation: 0.43122957124168865]
	TIME [epoch: 27.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3966116632519091		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.3966116632519091 | validation: 0.41683604722951617]
	TIME [epoch: 27.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38300703880161907		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.38300703880161907 | validation: 0.4373492330668198]
	TIME [epoch: 27.7 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5155428168602735		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.5155428168602735 | validation: 0.5177964996471813]
	TIME [epoch: 27.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5068951801938474		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.5068951801938474 | validation: 0.44399555186645134]
	TIME [epoch: 27.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3969918035333462		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.3969918035333462 | validation: 0.40277208305345036]
	TIME [epoch: 27.7 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42774287517905635		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.42774287517905635 | validation: 0.5483646956222777]
	TIME [epoch: 27.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4553416427778932		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.4553416427778932 | validation: 0.4533039488707614]
	TIME [epoch: 27.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4515080756381791		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.4515080756381791 | validation: 0.5387172164970666]
	TIME [epoch: 27.7 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47813691394466373		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.47813691394466373 | validation: 0.4100426185314411]
	TIME [epoch: 27.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40917586440441356		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.40917586440441356 | validation: 0.534430368054429]
	TIME [epoch: 27.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5112060989370782		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.5112060989370782 | validation: 0.4084139090802724]
	TIME [epoch: 27.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40491294452044313		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.40491294452044313 | validation: 0.510595374415367]
	TIME [epoch: 27.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4165628182725566		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.4165628182725566 | validation: 0.3890916017144388]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_799.pth
	Model improved!!!
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3701423867610018		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.3701423867610018 | validation: 0.387770886630983]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_800.pth
	Model improved!!!
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36736332599685345		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.36736332599685345 | validation: 0.3951615129910377]
	TIME [epoch: 27.7 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36447226445218384		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.36447226445218384 | validation: 0.4487991831729714]
	TIME [epoch: 27.7 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41111649920269866		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.41111649920269866 | validation: 0.4257136957263618]
	TIME [epoch: 27.7 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3899070401181009		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.3899070401181009 | validation: 0.38671287224218265]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_804.pth
	Model improved!!!
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38993467062976217		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.38993467062976217 | validation: 0.43605769881609246]
	TIME [epoch: 28.1 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41214835398793337		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.41214835398793337 | validation: 0.4200736698997702]
	TIME [epoch: 27.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3754135127494656		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.3754135127494656 | validation: 0.46170674114099913]
	TIME [epoch: 27.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41201459706903626		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.41201459706903626 | validation: 0.4889354554304818]
	TIME [epoch: 27.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46815840273177506		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.46815840273177506 | validation: 0.5322350335806846]
	TIME [epoch: 27.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4341508763323171		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.4341508763323171 | validation: 0.4506666388908893]
	TIME [epoch: 27.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46061511017721984		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.46061511017721984 | validation: 0.47947316940665635]
	TIME [epoch: 27.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42953066936609896		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.42953066936609896 | validation: 0.420866148331295]
	TIME [epoch: 27.7 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3795603005561924		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.3795603005561924 | validation: 0.42530277786252113]
	TIME [epoch: 27.7 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36835041122076334		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.36835041122076334 | validation: 0.42867756691605]
	TIME [epoch: 27.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3741703535080424		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.3741703535080424 | validation: 0.39412283093554534]
	TIME [epoch: 27.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3778395335893988		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.3778395335893988 | validation: 0.4675047927668983]
	TIME [epoch: 27.8 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5110523776348618		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.5110523776348618 | validation: 0.5271801729860394]
	TIME [epoch: 27.8 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4108081560016624		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.4108081560016624 | validation: 0.43071591079535965]
	TIME [epoch: 27.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37408344492177154		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.37408344492177154 | validation: 0.4543036147597448]
	TIME [epoch: 27.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41835119889926664		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.41835119889926664 | validation: 0.4589939904273365]
	TIME [epoch: 27.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3877722310810821		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.3877722310810821 | validation: 0.39665235713261576]
	TIME [epoch: 27.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3727521576048217		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.3727521576048217 | validation: 0.41239690414111635]
	TIME [epoch: 27.7 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37430732092473085		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.37430732092473085 | validation: 0.3939280624087088]
	TIME [epoch: 27.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36335791363268455		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.36335791363268455 | validation: 0.4136308728603567]
	TIME [epoch: 27.7 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39154837423167155		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.39154837423167155 | validation: 0.4853127634680628]
	TIME [epoch: 27.7 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4779404017793974		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.4779404017793974 | validation: 0.5216083487585239]
	TIME [epoch: 27.8 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5224161890453225		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.5224161890453225 | validation: 0.5826091443392616]
	TIME [epoch: 27.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4679297200221487		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.4679297200221487 | validation: 0.5104403953439753]
	TIME [epoch: 27.7 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.437647686553007		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.437647686553007 | validation: 0.4345731966839794]
	TIME [epoch: 27.8 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39166626730751064		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.39166626730751064 | validation: 0.45659533979156874]
	TIME [epoch: 27.7 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4061560627604063		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.4061560627604063 | validation: 0.4431856227007917]
	TIME [epoch: 27.8 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37927069992745766		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.37927069992745766 | validation: 0.40526491509964474]
	TIME [epoch: 27.8 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3640404630674164		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.3640404630674164 | validation: 0.4179785484434742]
	TIME [epoch: 27.7 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3795017705312571		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.3795017705312571 | validation: 0.4328437936172481]
	TIME [epoch: 27.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38836033402302683		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.38836033402302683 | validation: 0.43549054405909604]
	TIME [epoch: 27.7 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39569502178510035		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.39569502178510035 | validation: 0.47319342098484796]
	TIME [epoch: 27.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4158779694375548		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.4158779694375548 | validation: 0.3998283428372349]
	TIME [epoch: 27.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3861700100969885		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.3861700100969885 | validation: 0.43721055125585145]
	TIME [epoch: 27.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3728751502046626		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.3728751502046626 | validation: 0.40759747943976143]
	TIME [epoch: 27.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3849940114556888		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.3849940114556888 | validation: 0.4042185072655002]
	TIME [epoch: 27.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.363343724644688		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.363343724644688 | validation: 0.3917696299948637]
	TIME [epoch: 27.7 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.367260799985047		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.367260799985047 | validation: 0.40338270541625276]
	TIME [epoch: 27.7 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3612642756454617		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.3612642756454617 | validation: 0.38468446328836964]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_843.pth
	Model improved!!!
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3879992752576331		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.3879992752576331 | validation: 0.4021232636923773]
	TIME [epoch: 27.7 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37533505365610287		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.37533505365610287 | validation: 0.44329700963377805]
	TIME [epoch: 27.7 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41231098795445775		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.41231098795445775 | validation: 0.400521972900989]
	TIME [epoch: 27.7 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4241098273108051		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.4241098273108051 | validation: 0.5688240615853516]
	TIME [epoch: 27.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4633299154579399		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.4633299154579399 | validation: 0.43512048622998684]
	TIME [epoch: 27.7 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41274861443285643		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.41274861443285643 | validation: 0.4459656458070832]
	TIME [epoch: 27.7 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4137868446589461		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.4137868446589461 | validation: 0.4809351137472379]
	TIME [epoch: 27.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42028673587469717		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.42028673587469717 | validation: 0.48011401262310827]
	TIME [epoch: 27.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4014737743513925		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.4014737743513925 | validation: 0.434759674708956]
	TIME [epoch: 27.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4069940798121539		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.4069940798121539 | validation: 0.4255691204589479]
	TIME [epoch: 27.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3764342639855002		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.3764342639855002 | validation: 0.442425571303814]
	TIME [epoch: 27.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3837391779092471		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.3837391779092471 | validation: 0.4131357116746548]
	TIME [epoch: 27.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3736759951133732		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.3736759951133732 | validation: 0.43579488306700087]
	TIME [epoch: 27.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3850274914091102		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.3850274914091102 | validation: 0.39333705137493824]
	TIME [epoch: 27.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39337522373243605		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.39337522373243605 | validation: 0.4033997821725208]
	TIME [epoch: 27.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37311465857421033		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.37311465857421033 | validation: 0.42122097171987977]
	TIME [epoch: 27.8 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.377978395856604		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.377978395856604 | validation: 0.4142025941867118]
	TIME [epoch: 27.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3785197007969596		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.3785197007969596 | validation: 0.4201325803749923]
	TIME [epoch: 27.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36716734284398533		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.36716734284398533 | validation: 0.4173722221008083]
	TIME [epoch: 27.8 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39815466646420267		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.39815466646420267 | validation: 0.46035718417630905]
	TIME [epoch: 27.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41263600941785844		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.41263600941785844 | validation: 0.3930430545217665]
	TIME [epoch: 27.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35838815802388707		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.35838815802388707 | validation: 0.3951876681469696]
	TIME [epoch: 27.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3619532560672204		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.3619532560672204 | validation: 0.3917264799665129]
	TIME [epoch: 27.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3819428805193438		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.3819428805193438 | validation: 0.45298505930285304]
	TIME [epoch: 27.8 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3970664791793596		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.3970664791793596 | validation: 0.44904315751060936]
	TIME [epoch: 27.8 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40337675521446226		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.40337675521446226 | validation: 0.4364940327713914]
	TIME [epoch: 27.7 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39672940610145985		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.39672940610145985 | validation: 0.48099015067258977]
	TIME [epoch: 27.7 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4574014895419268		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.4574014895419268 | validation: 0.4576506663106567]
	TIME [epoch: 27.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39122192567066755		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.39122192567066755 | validation: 0.42890408409953706]
	TIME [epoch: 27.7 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3945801987286088		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.3945801987286088 | validation: 0.4621682419514482]
	TIME [epoch: 27.7 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4060559506041759		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.4060559506041759 | validation: 0.4072915316866391]
	TIME [epoch: 27.7 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38070414091209165		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.38070414091209165 | validation: 0.43634646781393216]
	TIME [epoch: 27.7 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.390914796819647		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.390914796819647 | validation: 0.40099208573447004]
	TIME [epoch: 27.7 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38779990019109256		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.38779990019109256 | validation: 0.4315525269320517]
	TIME [epoch: 27.8 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3957535044240315		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.3957535044240315 | validation: 0.4330331430522121]
	TIME [epoch: 27.8 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38403793793769825		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.38403793793769825 | validation: 0.4122628831359127]
	TIME [epoch: 27.8 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3724343117097793		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.3724343117097793 | validation: 0.4123798419541794]
	TIME [epoch: 27.7 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4257520644907286		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.4257520644907286 | validation: 0.46282292285566884]
	TIME [epoch: 27.8 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44619322044663395		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.44619322044663395 | validation: 0.42939451142688934]
	TIME [epoch: 27.7 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42232480836386926		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.42232480836386926 | validation: 0.42295144773116383]
	TIME [epoch: 27.7 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39386753749840914		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.39386753749840914 | validation: 0.4192606476733369]
	TIME [epoch: 27.7 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.405756270483414		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.405756270483414 | validation: 0.44313468231099296]
	TIME [epoch: 27.7 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46073683465940246		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.46073683465940246 | validation: 0.44825844317229535]
	TIME [epoch: 27.7 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4002284823964008		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.4002284823964008 | validation: 0.4611260083043547]
	TIME [epoch: 27.7 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41556810528316757		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.41556810528316757 | validation: 0.4325363539100489]
	TIME [epoch: 27.7 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37966579938451733		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.37966579938451733 | validation: 0.4110633205165189]
	TIME [epoch: 27.7 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3883911216934812		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.3883911216934812 | validation: 0.39742893446135763]
	TIME [epoch: 27.7 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40284588084686873		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.40284588084686873 | validation: 0.41278620580516695]
	TIME [epoch: 27.7 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39121423048093196		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.39121423048093196 | validation: 0.4202130736272996]
	TIME [epoch: 27.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3845585592021633		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.3845585592021633 | validation: 0.40156533840367603]
	TIME [epoch: 27.7 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36251531754876837		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.36251531754876837 | validation: 0.4092573313453036]
	TIME [epoch: 27.8 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4093595699683526		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.4093595699683526 | validation: 0.5700352086005928]
	TIME [epoch: 27.7 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5005744512819705		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.5005744512819705 | validation: 0.4398224482398705]
	TIME [epoch: 27.7 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3804801779058699		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.3804801779058699 | validation: 0.41057529953065525]
	TIME [epoch: 27.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36945104669510503		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.36945104669510503 | validation: 0.40007670289196157]
	TIME [epoch: 27.8 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4232214395144424		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.4232214395144424 | validation: 0.41755188435062246]
	TIME [epoch: 27.7 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3709160533778957		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.3709160533778957 | validation: 0.40411837721165117]
	TIME [epoch: 27.7 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4350203854194179		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.4350203854194179 | validation: 0.6530228492672242]
	TIME [epoch: 27.7 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5320833866658147		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.5320833866658147 | validation: 0.4464033408265162]
	TIME [epoch: 27.7 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39125493555735025		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.39125493555735025 | validation: 0.4422783044389109]
	TIME [epoch: 27.7 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4125580139101416		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.4125580139101416 | validation: 0.4133975692560381]
	TIME [epoch: 27.8 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37225649568851227		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.37225649568851227 | validation: 0.5138674110357548]
	TIME [epoch: 27.7 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5879484857860275		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.5879484857860275 | validation: 0.5603209229337516]
	TIME [epoch: 27.7 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5121529637188542		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.5121529637188542 | validation: 0.49731221214807336]
	TIME [epoch: 27.7 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39414567439021264		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.39414567439021264 | validation: 0.40115466830117485]
	TIME [epoch: 27.8 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3586098098454066		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.3586098098454066 | validation: 0.4079813538061236]
	TIME [epoch: 27.7 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3648005372944595		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.3648005372944595 | validation: 0.39205502778649026]
	TIME [epoch: 27.8 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39055166284985443		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.39055166284985443 | validation: 0.41296937202471945]
	TIME [epoch: 27.8 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3814935413725852		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.3814935413725852 | validation: 0.4241173078694533]
	TIME [epoch: 27.7 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3757711096067657		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.3757711096067657 | validation: 0.40009521611287285]
	TIME [epoch: 27.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36257094945641744		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.36257094945641744 | validation: 0.42326016548919493]
	TIME [epoch: 27.8 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.378405860574205		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.378405860574205 | validation: 0.41392783564630575]
	TIME [epoch: 27.7 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38812131044776393		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.38812131044776393 | validation: 0.40372005201710304]
	TIME [epoch: 27.7 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.362219103307754		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.362219103307754 | validation: 0.401309224381413]
	TIME [epoch: 27.8 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3639346034712531		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.3639346034712531 | validation: 0.4075749474665662]
	TIME [epoch: 27.7 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38425836788582934		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.38425836788582934 | validation: 0.3999683498338529]
	TIME [epoch: 27.7 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3648439882386887		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.3648439882386887 | validation: 0.4236893778824954]
	TIME [epoch: 27.8 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3973196953076107		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.3973196953076107 | validation: 0.38289561547344814]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_921.pth
	Model improved!!!
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36155133293415065		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.36155133293415065 | validation: 0.40514713507424754]
	TIME [epoch: 27.7 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3812579237885607		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.3812579237885607 | validation: 0.42212253664939914]
	TIME [epoch: 27.8 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4127004844013578		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.4127004844013578 | validation: 0.4640150750302996]
	TIME [epoch: 27.8 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3769766006789843		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.3769766006789843 | validation: 0.3997000950604345]
	TIME [epoch: 27.8 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3675029022412548		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.3675029022412548 | validation: 0.4154569740989632]
	TIME [epoch: 27.8 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37586912875444073		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.37586912875444073 | validation: 0.40622418108451974]
	TIME [epoch: 27.8 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3718910310369624		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.3718910310369624 | validation: 0.3932044045323645]
	TIME [epoch: 27.8 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38967064951945796		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.38967064951945796 | validation: 0.46352308000060904]
	TIME [epoch: 27.8 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4293763996317982		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.4293763996317982 | validation: 0.5122937013380112]
	TIME [epoch: 27.8 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43206401684204215		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.43206401684204215 | validation: 0.44695321955397804]
	TIME [epoch: 27.7 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38692187988371496		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.38692187988371496 | validation: 0.4128918946873371]
	TIME [epoch: 27.8 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36780061349639137		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.36780061349639137 | validation: 0.39853191386293135]
	TIME [epoch: 27.8 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3696656766584884		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.3696656766584884 | validation: 0.46410879265609417]
	TIME [epoch: 27.7 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4299847380490507		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.4299847380490507 | validation: 0.48185278536186515]
	TIME [epoch: 27.7 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4130755443649815		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.4130755443649815 | validation: 0.4031828928303372]
	TIME [epoch: 27.7 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37736091306196096		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.37736091306196096 | validation: 0.40593026721390446]
	TIME [epoch: 27.7 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.380710141119018		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.380710141119018 | validation: 0.40628310588669153]
	TIME [epoch: 27.7 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3583815098206815		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.3583815098206815 | validation: 0.38603173574611915]
	TIME [epoch: 27.7 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35987341999040967		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.35987341999040967 | validation: 0.3913885817742159]
	TIME [epoch: 27.7 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35582243634321953		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.35582243634321953 | validation: 0.38822324999777]
	TIME [epoch: 27.7 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36157783964661444		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.36157783964661444 | validation: 0.404752381935443]
	TIME [epoch: 27.8 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3618754766338984		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.3618754766338984 | validation: 0.3850734644979808]
	TIME [epoch: 27.7 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3555209105748681		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.3555209105748681 | validation: 0.41011388160916723]
	TIME [epoch: 27.7 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37137598262033866		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.37137598262033866 | validation: 0.38930666491102645]
	TIME [epoch: 27.8 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3508283284435278		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.3508283284435278 | validation: 0.3789821068702326]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_946.pth
	Model improved!!!
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3789423503164706		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.3789423503164706 | validation: 0.39809500365909756]
	TIME [epoch: 27.7 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3702334454924072		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.3702334454924072 | validation: 0.4121953609328915]
	TIME [epoch: 27.8 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4388539559394451		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.4388539559394451 | validation: 0.42618162780856095]
	TIME [epoch: 27.7 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42632865787053265		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.42632865787053265 | validation: 0.4180906090149202]
	TIME [epoch: 27.7 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38254753829651966		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.38254753829651966 | validation: 0.39784822690737687]
	TIME [epoch: 27.7 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37519689727880084		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.37519689727880084 | validation: 0.4257792768530974]
	TIME [epoch: 27.8 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.364490446229867		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.364490446229867 | validation: 0.3824741765030216]
	TIME [epoch: 27.8 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3576660820766446		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.3576660820766446 | validation: 0.3819492842274914]
	TIME [epoch: 27.7 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3640967741251446		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.3640967741251446 | validation: 0.4115330431630014]
	TIME [epoch: 27.8 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.389987681619707		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.389987681619707 | validation: 0.4232930651588323]
	TIME [epoch: 27.7 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37775609245374087		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.37775609245374087 | validation: 0.39369857018211046]
	TIME [epoch: 27.7 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3651326961760202		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.3651326961760202 | validation: 0.4517070081741655]
	TIME [epoch: 27.8 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4512220773625102		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.4512220773625102 | validation: 0.5086681264506965]
	TIME [epoch: 27.8 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41635689353636857		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.41635689353636857 | validation: 0.4310030991835994]
	TIME [epoch: 27.8 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38312191912626953		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.38312191912626953 | validation: 0.42659800822330257]
	TIME [epoch: 27.7 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3621992526524869		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.3621992526524869 | validation: 0.3896529823903464]
	TIME [epoch: 27.7 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3518567214268796		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.3518567214268796 | validation: 0.4083085704198652]
	TIME [epoch: 27.8 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41398973852583165		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.41398973852583165 | validation: 0.4466757263345202]
	TIME [epoch: 27.7 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4076406483812511		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.4076406483812511 | validation: 0.38981149423242545]
	TIME [epoch: 27.8 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37008458481803075		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.37008458481803075 | validation: 0.381860031484361]
	TIME [epoch: 27.8 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.359458749635048		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.359458749635048 | validation: 0.3857555944238497]
	TIME [epoch: 27.8 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38047508701871097		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.38047508701871097 | validation: 0.424319199774808]
	TIME [epoch: 27.8 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44483371940183686		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.44483371940183686 | validation: 0.49037114505788365]
	TIME [epoch: 27.8 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5079749127305674		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.5079749127305674 | validation: 0.4791726925891753]
	TIME [epoch: 27.7 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4314192680944936		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.4314192680944936 | validation: 0.4228319362440906]
	TIME [epoch: 27.6 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3745078811443866		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.3745078811443866 | validation: 0.3774205913753367]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_972.pth
	Model improved!!!
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37256959893280367		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.37256959893280367 | validation: 0.46157599353809803]
	TIME [epoch: 27.7 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5144209878921234		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.5144209878921234 | validation: 0.6199871293337227]
	TIME [epoch: 27.7 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5862385453069783		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.5862385453069783 | validation: 0.5885339652117615]
	TIME [epoch: 27.7 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.516665417967334		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.516665417967334 | validation: 0.5936042506990868]
	TIME [epoch: 27.8 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5697652994990807		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.5697652994990807 | validation: 0.5024693415283472]
	TIME [epoch: 27.8 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41068267821923554		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.41068267821923554 | validation: 0.414176620697068]
	TIME [epoch: 27.8 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3705993974662412		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.3705993974662412 | validation: 0.39961409606848736]
	TIME [epoch: 27.7 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36880976891213746		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.36880976891213746 | validation: 0.4114890156996248]
	TIME [epoch: 27.8 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38547087955083015		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.38547087955083015 | validation: 0.4274614763969484]
	TIME [epoch: 27.7 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3940939748342658		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.3940939748342658 | validation: 0.456784834205696]
	TIME [epoch: 27.8 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3915922045443436		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.3915922045443436 | validation: 0.4312318029862175]
	TIME [epoch: 27.8 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4097374909960926		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.4097374909960926 | validation: 0.4563086221280833]
	TIME [epoch: 27.8 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38132642839739456		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.38132642839739456 | validation: 0.41004338681465746]
	TIME [epoch: 27.9 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36014576037952317		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.36014576037952317 | validation: 0.4049819942308876]
	TIME [epoch: 27.8 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3762880734249651		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.3762880734249651 | validation: 0.39234523402820953]
	TIME [epoch: 27.8 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3587341479867212		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.3587341479867212 | validation: 0.3931882780378709]
	TIME [epoch: 27.8 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36082628602001604		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.36082628602001604 | validation: 0.4064844657524301]
	TIME [epoch: 27.8 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.377129402427527		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.377129402427527 | validation: 0.38828951104633547]
	TIME [epoch: 27.8 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3560327139579978		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.3560327139579978 | validation: 0.38564850442490467]
	TIME [epoch: 27.8 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36080345428230887		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.36080345428230887 | validation: 0.3963203052678835]
	TIME [epoch: 27.9 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3763152041105468		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.3763152041105468 | validation: 0.4313818043362867]
	TIME [epoch: 27.8 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42834828416536297		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.42834828416536297 | validation: 0.4722877800135937]
	TIME [epoch: 27.8 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44579451039806217		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.44579451039806217 | validation: 0.4479997613092412]
	TIME [epoch: 27.7 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3723931613442651		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.3723931613442651 | validation: 0.38128662917169776]
	TIME [epoch: 27.8 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43619060131465587		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.43619060131465587 | validation: 0.48445181052820907]
	TIME [epoch: 27.8 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5145019719669297		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.5145019719669297 | validation: 0.4087397818651839]
	TIME [epoch: 27.8 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39450420378479945		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.39450420378479945 | validation: 0.3617566746880731]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_999.pth
	Model improved!!!
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35615028874610277		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.35615028874610277 | validation: 0.38429498354021235]
	TIME [epoch: 27.8 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3510546050087429		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.3510546050087429 | validation: 0.3863363312084857]
	TIME [epoch: 27.7 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34455215689097113		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.34455215689097113 | validation: 0.3863927246975884]
	TIME [epoch: 27.8 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42243060032295976		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.42243060032295976 | validation: 0.4347597782095865]
	TIME [epoch: 27.8 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4707778578486673		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.4707778578486673 | validation: 0.4018254278894245]
	TIME [epoch: 27.8 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3989430261787605		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.3989430261787605 | validation: 0.39881110586412183]
	TIME [epoch: 27.8 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37668431302901745		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.37668431302901745 | validation: 0.3654807259656102]
	TIME [epoch: 27.8 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3574867081587066		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.3574867081587066 | validation: 0.3761709163549196]
	TIME [epoch: 27.8 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3594139949181074		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.3594139949181074 | validation: 0.39659446872606363]
	TIME [epoch: 27.9 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39277142913226903		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.39277142913226903 | validation: 0.41510865517510603]
	TIME [epoch: 27.7 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3793887485316383		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.3793887485316383 | validation: 0.4212130844290578]
	TIME [epoch: 27.7 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38181662901542945		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.38181662901542945 | validation: 0.41605136878600635]
	TIME [epoch: 27.8 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3725415535654406		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.3725415535654406 | validation: 0.39200796176864894]
	TIME [epoch: 27.8 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3576417586839632		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.3576417586839632 | validation: 0.3885597962892653]
	TIME [epoch: 27.8 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3871288232477656		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.3871288232477656 | validation: 0.3979313776418181]
	TIME [epoch: 27.8 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38554279014410436		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.38554279014410436 | validation: 0.4111423113113064]
	TIME [epoch: 27.7 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3694390653976145		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.3694390653976145 | validation: 0.40080704309214443]
	TIME [epoch: 27.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3854315970233476		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.3854315970233476 | validation: 0.41629236649048224]
	TIME [epoch: 27.6 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38660479647324575		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.38660479647324575 | validation: 0.42009441080061494]
	TIME [epoch: 27.7 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38048097361726785		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.38048097361726785 | validation: 0.3802252506767216]
	TIME [epoch: 27.7 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3540204294625725		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.3540204294625725 | validation: 0.4218113570639772]
	TIME [epoch: 27.8 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3709396621746854		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.3709396621746854 | validation: 0.3714331495915271]
	TIME [epoch: 27.8 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3617354332071618		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.3617354332071618 | validation: 0.38319148130985]
	TIME [epoch: 27.7 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3509336770554797		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.3509336770554797 | validation: 0.3828991298246976]
	TIME [epoch: 27.7 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3494173653867464		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.3494173653867464 | validation: 0.38411210347968683]
	TIME [epoch: 27.7 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35206181285391197		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.35206181285391197 | validation: 0.3883391451505921]
	TIME [epoch: 27.8 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36143019671413035		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.36143019671413035 | validation: 0.36672739657318076]
	TIME [epoch: 27.7 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35709690905483144		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.35709690905483144 | validation: 0.391507874196345]
	TIME [epoch: 27.6 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3490166941965819		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.3490166941965819 | validation: 0.38284861523830727]
	TIME [epoch: 27.7 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36769361218477753		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.36769361218477753 | validation: 0.3932901001638144]
	TIME [epoch: 27.6 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36427990746567174		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.36427990746567174 | validation: 0.4138947057504545]
	TIME [epoch: 27.6 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42139477716680157		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.42139477716680157 | validation: 0.39897296849692465]
	TIME [epoch: 27.6 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3742517480945291		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.3742517480945291 | validation: 0.3858119665277263]
	TIME [epoch: 27.7 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3677367870363376		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.3677367870363376 | validation: 0.39680094971391666]
	TIME [epoch: 27.8 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37952699174552995		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.37952699174552995 | validation: 0.3877263109368997]
	TIME [epoch: 27.7 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3593658282155321		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.3593658282155321 | validation: 0.3791709148741498]
	TIME [epoch: 27.7 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3731265072770576		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.3731265072770576 | validation: 0.4271440392088865]
	TIME [epoch: 27.7 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3683822522702949		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.3683822522702949 | validation: 0.40368277347113435]
	TIME [epoch: 27.7 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36738050899783214		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.36738050899783214 | validation: 0.39418447429298953]
	TIME [epoch: 27.7 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34875295891739855		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.34875295891739855 | validation: 0.39322278978017017]
	TIME [epoch: 27.7 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3662945371971169		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.3662945371971169 | validation: 0.3801323662074853]
	TIME [epoch: 27.8 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34691132842593997		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.34691132842593997 | validation: 0.3771435423204452]
	TIME [epoch: 27.7 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34978424312995254		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.34978424312995254 | validation: 0.36839727030256103]
	TIME [epoch: 27.7 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3867552590997235		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.3867552590997235 | validation: 0.4169419327275832]
	TIME [epoch: 27.8 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39996464302720025		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.39996464302720025 | validation: 0.40935557150164564]
	TIME [epoch: 27.8 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3936698703733542		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.3936698703733542 | validation: 0.42962187739483254]
	TIME [epoch: 27.7 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.418583641464529		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.418583641464529 | validation: 0.41503577556116256]
	TIME [epoch: 27.7 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40427583168892006		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.40427583168892006 | validation: 0.3816444942573051]
	TIME [epoch: 27.7 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3600083407625189		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.3600083407625189 | validation: 0.3858501670058181]
	TIME [epoch: 27.8 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3542497742284498		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.3542497742284498 | validation: 0.3767193658319572]
	TIME [epoch: 27.7 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35089041073343386		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.35089041073343386 | validation: 0.373852293525285]
	TIME [epoch: 27.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3740444250741939		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.3740444250741939 | validation: 0.3861608052653698]
	TIME [epoch: 27.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3622996926441101		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.3622996926441101 | validation: 0.37566001574942326]
	TIME [epoch: 27.7 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34697191594108245		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.34697191594108245 | validation: 0.3754116228998084]
	TIME [epoch: 27.7 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3463281982255114		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.3463281982255114 | validation: 0.377676318283831]
	TIME [epoch: 27.8 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35000550029662647		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.35000550029662647 | validation: 0.3833420718249578]
	TIME [epoch: 27.8 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34496687077847615		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.34496687077847615 | validation: 0.3835084522619135]
	TIME [epoch: 27.8 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37529359009064545		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.37529359009064545 | validation: 0.3939386073091164]
	TIME [epoch: 27.8 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36143103183063396		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.36143103183063396 | validation: 0.38772509468686855]
	TIME [epoch: 27.8 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3723441665123707		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.3723441665123707 | validation: 0.4322120113972189]
	TIME [epoch: 27.8 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3813229432175197		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.3813229432175197 | validation: 0.3785640134865026]
	TIME [epoch: 27.8 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35253508450242954		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.35253508450242954 | validation: 0.38204406544436254]
	TIME [epoch: 27.8 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3475061423827016		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.3475061423827016 | validation: 0.38123931684708384]
	TIME [epoch: 27.7 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3488439209504623		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.3488439209504623 | validation: 0.3704311376730379]
	TIME [epoch: 27.7 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34761496804209197		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.34761496804209197 | validation: 0.3741362748423482]
	TIME [epoch: 27.7 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3490756828195325		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.3490756828195325 | validation: 0.38424373396653755]
	TIME [epoch: 27.6 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3568444206358209		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.3568444206358209 | validation: 0.3894480319190787]
	TIME [epoch: 27.7 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3542855887065943		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.3542855887065943 | validation: 0.37097923689827356]
	TIME [epoch: 27.8 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3468266645527356		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.3468266645527356 | validation: 0.36906380149887413]
	TIME [epoch: 27.8 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35307425265229203		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.35307425265229203 | validation: 0.37644585894026267]
	TIME [epoch: 27.7 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3569817753124206		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.3569817753124206 | validation: 0.37138681220407505]
	TIME [epoch: 27.8 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35235402504907637		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.35235402504907637 | validation: 0.39469579301545155]
	TIME [epoch: 27.8 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35554388887101807		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.35554388887101807 | validation: 0.36936328918469863]
	TIME [epoch: 27.8 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3532401960311951		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.3532401960311951 | validation: 0.41797948613279984]
	TIME [epoch: 27.8 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39683912527887943		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.39683912527887943 | validation: 0.4479250834219329]
	TIME [epoch: 27.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4060060551468977		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.4060060551468977 | validation: 0.4120070359678583]
	TIME [epoch: 27.8 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35961191048310537		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.35961191048310537 | validation: 0.40116864577159816]
	TIME [epoch: 27.7 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37383969990370425		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.37383969990370425 | validation: 0.4604773208955101]
	TIME [epoch: 27.8 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39807921404870916		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.39807921404870916 | validation: 0.41830741987993575]
	TIME [epoch: 27.8 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.363677789527164		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.363677789527164 | validation: 0.39212420404669757]
	TIME [epoch: 27.8 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.366989508346671		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.366989508346671 | validation: 0.38846141556901165]
	TIME [epoch: 27.8 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35653503489748173		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.35653503489748173 | validation: 0.37536089265773004]
	TIME [epoch: 27.7 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3495385023835095		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.3495385023835095 | validation: 0.3741699414533882]
	TIME [epoch: 27.7 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3607262772590716		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.3607262772590716 | validation: 0.3779206241589427]
	TIME [epoch: 27.8 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35395455670673265		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.35395455670673265 | validation: 0.39043445443669716]
	TIME [epoch: 27.7 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3651547227139255		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.3651547227139255 | validation: 0.37359462900299556]
	TIME [epoch: 27.7 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35219766372785216		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.35219766372785216 | validation: 0.380446461610547]
	TIME [epoch: 27.7 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.351019399893098		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.351019399893098 | validation: 0.3750012975757959]
	TIME [epoch: 27.7 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34908715957384795		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.34908715957384795 | validation: 0.40120341723096803]
	TIME [epoch: 27.8 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.379676913530692		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.379676913530692 | validation: 0.38809694061180205]
	TIME [epoch: 27.7 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36062311146561027		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.36062311146561027 | validation: 0.37240490874815974]
	TIME [epoch: 27.7 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3543011656692928		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.3543011656692928 | validation: 0.37794269077094994]
	TIME [epoch: 27.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34951166861668775		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.34951166861668775 | validation: 0.3866223076212678]
	TIME [epoch: 27.6 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3566926274085708		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.3566926274085708 | validation: 0.3912216076902266]
	TIME [epoch: 27.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3824913328867365		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.3824913328867365 | validation: 0.4520933977171116]
	TIME [epoch: 27.6 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4173190214346354		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.4173190214346354 | validation: 0.4547086382610603]
	TIME [epoch: 27.7 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3970876770371006		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.3970876770371006 | validation: 0.42233172833928306]
	TIME [epoch: 27.7 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38250476640252884		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.38250476640252884 | validation: 0.4249875350016472]
	TIME [epoch: 27.8 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39449238034724643		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.39449238034724643 | validation: 0.43276998558594815]
	TIME [epoch: 27.8 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.398950242891092		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.398950242891092 | validation: 0.44632793574955487]
	TIME [epoch: 27.8 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40260209877761854		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.40260209877761854 | validation: 0.40938520434400716]
	TIME [epoch: 27.8 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3631616908114917		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.3631616908114917 | validation: 0.3932567776999943]
	TIME [epoch: 27.9 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35810385884180995		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.35810385884180995 | validation: 0.3947229980097548]
	TIME [epoch: 27.7 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35906042099111024		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.35906042099111024 | validation: 0.3986111261381043]
	TIME [epoch: 27.8 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3679513648517567		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.3679513648517567 | validation: 0.3836107261755407]
	TIME [epoch: 27.8 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36232734087359814		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.36232734087359814 | validation: 0.4067084657173055]
	TIME [epoch: 27.8 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38495810446641354		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.38495810446641354 | validation: 0.4321465999229658]
	TIME [epoch: 27.8 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4423917282545199		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.4423917282545199 | validation: 0.5140428627973985]
	TIME [epoch: 27.8 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4582382289174547		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.4582382289174547 | validation: 0.44448435781662454]
	TIME [epoch: 27.8 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4199217027648153		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.4199217027648153 | validation: 0.436891156828999]
	TIME [epoch: 27.8 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39866781436731735		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.39866781436731735 | validation: 0.4021907973211198]
	TIME [epoch: 27.7 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3686817350649654		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.3686817350649654 | validation: 0.38661606015091865]
	TIME [epoch: 27.8 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34999026739101335		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.34999026739101335 | validation: 0.39384656546842806]
	TIME [epoch: 27.7 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3716322095775344		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.3716322095775344 | validation: 0.4284129430815978]
	TIME [epoch: 27.7 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38818847807923174		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.38818847807923174 | validation: 0.39670969699210185]
	TIME [epoch: 27.7 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3611524321820097		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.3611524321820097 | validation: 0.39305674470753404]
	TIME [epoch: 27.7 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3478682534977361		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.3478682534977361 | validation: 0.3814514691873476]
	TIME [epoch: 27.7 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35747616311369346		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.35747616311369346 | validation: 0.38470561870605935]
	TIME [epoch: 27.7 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3515545887921002		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.3515545887921002 | validation: 0.38987705028570996]
	TIME [epoch: 27.7 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3559588934457205		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.3559588934457205 | validation: 0.38071786715369416]
	TIME [epoch: 27.8 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3554379231119114		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.3554379231119114 | validation: 0.39218723007764555]
	TIME [epoch: 27.8 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35664754745403426		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.35664754745403426 | validation: 0.3993808225276375]
	TIME [epoch: 27.7 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3610990279827588		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.3610990279827588 | validation: 0.39117182453736377]
	TIME [epoch: 27.7 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.364083894204927		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.364083894204927 | validation: 0.40245485918355883]
	TIME [epoch: 27.7 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.390354390376792		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.390354390376792 | validation: 0.4023356877006532]
	TIME [epoch: 27.7 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36255503474648165		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.36255503474648165 | validation: 0.38817355758890915]
	TIME [epoch: 27.7 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3595258914185293		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.3595258914185293 | validation: 0.39358030562854013]
	TIME [epoch: 27.7 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3551298725766073		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.3551298725766073 | validation: 0.3874703273882726]
	TIME [epoch: 27.7 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3645111257420719		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.3645111257420719 | validation: 0.37982158792813253]
	TIME [epoch: 27.8 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3513684837451357		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.3513684837451357 | validation: 0.3781075264517628]
	TIME [epoch: 27.8 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35555844036556067		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.35555844036556067 | validation: 0.37183357763620556]
	TIME [epoch: 27.8 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3465201536872614		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.3465201536872614 | validation: 0.3778956113000922]
	TIME [epoch: 27.8 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35021331183241233		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.35021331183241233 | validation: 0.37679772792935895]
	TIME [epoch: 27.7 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34464768015262165		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.34464768015262165 | validation: 0.3799472524548668]
	TIME [epoch: 27.8 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3430015826690131		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.3430015826690131 | validation: 0.37215896509574464]
	TIME [epoch: 27.7 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34558009732552475		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.34558009732552475 | validation: 0.38228079822641725]
	TIME [epoch: 27.8 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3418082508660293		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.3418082508660293 | validation: 0.3774307238878015]
	TIME [epoch: 27.8 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33683702720586317		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.33683702720586317 | validation: 0.3669418866018547]
	TIME [epoch: 27.8 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34163517620991957		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.34163517620991957 | validation: 0.36269496301774307]
	TIME [epoch: 27.8 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3466184031014518		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.3466184031014518 | validation: 0.39147446899281435]
	TIME [epoch: 27.8 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38541679737807066		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.38541679737807066 | validation: 0.4165746568243617]
	TIME [epoch: 27.8 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3785517338914342		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.3785517338914342 | validation: 0.39440606345363294]
	TIME [epoch: 27.8 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34822322593538996		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.34822322593538996 | validation: 0.37219636669624906]
	TIME [epoch: 27.7 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3342738591551744		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.3342738591551744 | validation: 0.3757134425635719]
	TIME [epoch: 27.8 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33959311579363416		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.33959311579363416 | validation: 0.3710919300218919]
	TIME [epoch: 27.7 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3398700536377802		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.3398700536377802 | validation: 0.3749403114783689]
	TIME [epoch: 27.8 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33741314277112544		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.33741314277112544 | validation: 0.37929319493342756]
	TIME [epoch: 27.8 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34813834342949657		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.34813834342949657 | validation: 0.37638689122278307]
	TIME [epoch: 27.7 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33962575551242014		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.33962575551242014 | validation: 0.3717029649510829]
	TIME [epoch: 27.8 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34660486726115125		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.34660486726115125 | validation: 0.37230832987196494]
	TIME [epoch: 27.8 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34677002609716884		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.34677002609716884 | validation: 0.40553318337041205]
	TIME [epoch: 27.7 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3701584718839442		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.3701584718839442 | validation: 0.3881945250075215]
	TIME [epoch: 27.8 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3499077130935272		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.3499077130935272 | validation: 0.3872386971010022]
	TIME [epoch: 27.8 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3444383567326519		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.3444383567326519 | validation: 0.3766893783420852]
	TIME [epoch: 27.8 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34868555520272637		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.34868555520272637 | validation: 0.38966407576528783]
	TIME [epoch: 27.7 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3379566316326645		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.3379566316326645 | validation: 0.3698404585388947]
	TIME [epoch: 27.8 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3377611213566917		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.3377611213566917 | validation: 0.3762456067297628]
	TIME [epoch: 27.7 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34976346379759465		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.34976346379759465 | validation: 0.39267212701216003]
	TIME [epoch: 27.7 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3554848337124991		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.3554848337124991 | validation: 0.4206046152467504]
	TIME [epoch: 27.7 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37427019025573244		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.37427019025573244 | validation: 0.40299071133156544]
	TIME [epoch: 27.8 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35721502668324884		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.35721502668324884 | validation: 0.38165481822828456]
	TIME [epoch: 27.7 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36213918213995183		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.36213918213995183 | validation: 0.4106797036499778]
	TIME [epoch: 27.8 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3643510107443394		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.3643510107443394 | validation: 0.4050666994273638]
	TIME [epoch: 27.8 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35935285970926467		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.35935285970926467 | validation: 0.38578986088661615]
	TIME [epoch: 27.8 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34622756756849754		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.34622756756849754 | validation: 0.38861382615815987]
	TIME [epoch: 27.8 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34697934043061585		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.34697934043061585 | validation: 0.37929622774635663]
	TIME [epoch: 27.7 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3454814046253389		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.3454814046253389 | validation: 0.3878337712481148]
	TIME [epoch: 27.8 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3370706969355542		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.3370706969355542 | validation: 0.3601270185957134]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240310_003029/states/model_tr_study6_1167.pth
	Model improved!!!
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34180554437775523		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.34180554437775523 | validation: 0.37003221370356665]
	TIME [epoch: 27.8 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3405604251402068		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.3405604251402068 | validation: 0.3735096882783914]
	TIME [epoch: 27.8 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34448341591439674		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.34448341591439674 | validation: 0.3765090217412792]
	TIME [epoch: 27.8 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34732201611057484		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.34732201611057484 | validation: 0.3814244026231478]
	TIME [epoch: 27.8 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36833464008108885		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.36833464008108885 | validation: 0.4065446604690282]
	TIME [epoch: 27.7 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3787869427519662		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.3787869427519662 | validation: 0.3746275368262845]
	TIME [epoch: 27.7 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3654719756590746		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.3654719756590746 | validation: 0.39083709527154353]
	TIME [epoch: 27.8 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37384244127015304		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.37384244127015304 | validation: 0.405658378824223]
	TIME [epoch: 27.8 sec]
EPOCH 1176/2000:
	Training over batches...
