Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r1', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1215820107

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.130103448822192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.130103448822192 | validation: 6.857394620125035]
	TIME [epoch: 94.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.117461838027188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.117461838027188 | validation: 5.822553456604985]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6637428158151435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6637428158151435 | validation: 2.8063536967808207]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8137292847142543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8137292847142543 | validation: 2.812087116484722]
	TIME [epoch: 5.73 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.002446243554944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.002446243554944 | validation: 3.109503263189076]
	TIME [epoch: 5.72 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2107483947113202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2107483947113202 | validation: 2.7547899642772724]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9525584600326042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9525584600326042 | validation: 2.6367248342075538]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6990965158213296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6990965158213296 | validation: 2.7621757749629934]
	TIME [epoch: 5.76 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7551505546510553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7551505546510553 | validation: 2.541349576383976]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.623261419210741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.623261419210741 | validation: 2.3039968596426412]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.430505622556688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.430505622556688 | validation: 2.9586218283596306]
	TIME [epoch: 5.72 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7259381185749345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7259381185749345 | validation: 2.4381137960248043]
	TIME [epoch: 5.72 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4103520438610024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4103520438610024 | validation: 2.202470540556028]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2575866693081457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2575866693081457 | validation: 2.2929759924111726]
	TIME [epoch: 5.71 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3884165525258143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3884165525258143 | validation: 1.96093404028294]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.197801570068574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.197801570068574 | validation: 1.7574124740800687]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1336908597007893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1336908597007893 | validation: 2.023389800214154]
	TIME [epoch: 5.73 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.180299142017421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.180299142017421 | validation: 2.0721516358991714]
	TIME [epoch: 5.72 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.882380910074366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.882380910074366 | validation: 1.9469339452568826]
	TIME [epoch: 5.72 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.14567991336135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.14567991336135 | validation: 1.856094439454593]
	TIME [epoch: 5.73 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8430926922116797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8430926922116797 | validation: 1.8091898112230427]
	TIME [epoch: 5.76 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0563167802135567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0563167802135567 | validation: 1.5326974133976985]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9013559935060838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9013559935060838 | validation: 1.8652100448244289]
	TIME [epoch: 5.73 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9163495401343484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9163495401343484 | validation: 1.639964016462713]
	TIME [epoch: 5.73 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7465435872046076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7465435872046076 | validation: 1.7583931926534562]
	TIME [epoch: 5.73 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9587001706608325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9587001706608325 | validation: 1.528053870174836]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4794948876850789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4794948876850789 | validation: 1.7080844689726378]
	TIME [epoch: 5.73 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9743710405418082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9743710405418082 | validation: 1.3352398398135603]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4758214981796214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4758214981796214 | validation: 1.6495679106726828]
	TIME [epoch: 5.74 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7762465253442237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7762465253442237 | validation: 1.6113780150558226]
	TIME [epoch: 5.73 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.789282639524584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.789282639524584 | validation: 1.7238121216828461]
	TIME [epoch: 5.73 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5090252025950688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5090252025950688 | validation: 1.1569809444584127]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3680661514285624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3680661514285624 | validation: 4.623738074076723]
	TIME [epoch: 5.72 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.304683929258468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.304683929258468 | validation: 3.127673322986327]
	TIME [epoch: 5.73 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2147582311769916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2147582311769916 | validation: 1.8454578053535402]
	TIME [epoch: 5.77 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6348627379749794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6348627379749794 | validation: 1.344677794419169]
	TIME [epoch: 5.73 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5145581145663363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5145581145663363 | validation: 1.2323595394344753]
	TIME [epoch: 5.72 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2805633963323926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2805633963323926 | validation: 1.4578586786377528]
	TIME [epoch: 5.73 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6534369750251074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6534369750251074 | validation: 1.9984529878382227]
	TIME [epoch: 5.71 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.609425318448285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.609425318448285 | validation: 1.2455367303540448]
	TIME [epoch: 5.72 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4062432142571006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4062432142571006 | validation: 1.919396063280998]
	TIME [epoch: 5.74 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6225003405138607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6225003405138607 | validation: 1.425255170075448]
	TIME [epoch: 5.76 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4197011784940252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4197011784940252 | validation: 1.625480144804729]
	TIME [epoch: 5.73 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.613829976926779		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.613829976926779 | validation: 1.1218339175045544]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3466839010393183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3466839010393183 | validation: 1.3857175840381468]
	TIME [epoch: 5.72 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4407798869242119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4407798869242119 | validation: 1.5282004079107099]
	TIME [epoch: 5.71 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2888767754367487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2888767754367487 | validation: 1.1009891746442195]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4465346103022745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4465346103022745 | validation: 0.9781701724026519]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1296154090150095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1296154090150095 | validation: 1.3411684238091033]
	TIME [epoch: 5.74 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1789037955876083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1789037955876083 | validation: 1.951335288334037]
	TIME [epoch: 5.71 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7029521972084534		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.7029521972084534 | validation: 0.9057123028074002]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023968511678397		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.023968511678397 | validation: 2.327920768790585]
	TIME [epoch: 5.72 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.681940375246439		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.681940375246439 | validation: 0.9403391619616991]
	TIME [epoch: 5.71 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0936398365893472		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.0936398365893472 | validation: 1.0269677588615886]
	TIME [epoch: 5.71 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3539329716187154		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.3539329716187154 | validation: 0.8307495477254706]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1009458695367211		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.1009458695367211 | validation: 1.3572377627438255]
	TIME [epoch: 5.71 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0425484418670585		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.0425484418670585 | validation: 1.2874385945912976]
	TIME [epoch: 5.71 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0733490675366673		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.0733490675366673 | validation: 1.6100397669514916]
	TIME [epoch: 5.71 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.257979098973257		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.257979098973257 | validation: 0.8518151715626486]
	TIME [epoch: 5.71 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8773093355738188		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.8773093355738188 | validation: 0.6040503805487046]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2028109091488783		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.2028109091488783 | validation: 0.82770259811904]
	TIME [epoch: 5.71 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9664478749920166		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.9664478749920166 | validation: 1.7916753088887498]
	TIME [epoch: 5.75 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0481504395945223		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.0481504395945223 | validation: 0.6382009139353063]
	TIME [epoch: 5.71 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9287157404176781		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.9287157404176781 | validation: 1.3274300992416026]
	TIME [epoch: 5.71 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9926057447554916		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.9926057447554916 | validation: 1.3613929926603434]
	TIME [epoch: 5.71 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0193238160553666		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.0193238160553666 | validation: 0.8257361151345157]
	TIME [epoch: 5.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.343212525250845		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.343212525250845 | validation: 1.228922899973471]
	TIME [epoch: 5.71 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0580537273708672		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.0580537273708672 | validation: 0.7397641594306387]
	TIME [epoch: 5.73 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7426088098613384		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.7426088098613384 | validation: 0.8955524286375696]
	TIME [epoch: 5.73 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9315161906689542		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.9315161906689542 | validation: 0.4679665139520759]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.975048450653736		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.975048450653736 | validation: 0.9150743358080959]
	TIME [epoch: 5.71 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8439030785725075		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.8439030785725075 | validation: 0.7613342534272316]
	TIME [epoch: 5.71 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7881918843826222		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.7881918843826222 | validation: 0.7775593877706859]
	TIME [epoch: 5.71 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7724402736571103		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.7724402736571103 | validation: 0.6992402014127093]
	TIME [epoch: 5.71 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6216987682731505		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.6216987682731505 | validation: 0.7572386144246588]
	TIME [epoch: 5.75 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6578598899813701		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.6578598899813701 | validation: 2.0992562797135643]
	TIME [epoch: 5.71 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9843066517548233		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.9843066517548233 | validation: 0.8830195952641295]
	TIME [epoch: 5.71 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9448296481287811		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.9448296481287811 | validation: 1.103443436199714]
	TIME [epoch: 5.71 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1832532779866958		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.1832532779866958 | validation: 1.2542411304829546]
	TIME [epoch: 5.71 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7066032564963113		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.7066032564963113 | validation: 0.3948381424851128]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5075506448906237		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.5075506448906237 | validation: 3.856586942166268]
	TIME [epoch: 5.73 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6590902318142713		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.6590902318142713 | validation: 0.5094626668540413]
	TIME [epoch: 5.73 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.529416733786492		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.529416733786492 | validation: 1.1415514842105916]
	TIME [epoch: 5.71 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6526304018053293		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.6526304018053293 | validation: 0.8053428505170408]
	TIME [epoch: 5.72 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.702998657834471		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.702998657834471 | validation: 0.6673086815820016]
	TIME [epoch: 5.71 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6804798827730731		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.6804798827730731 | validation: 0.974213554687273]
	TIME [epoch: 5.71 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8091813453179908		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.8091813453179908 | validation: 0.36523542904932227]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5607954552642229		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.5607954552642229 | validation: 0.6870874318635138]
	TIME [epoch: 5.76 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8075792812022604		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.8075792812022604 | validation: 0.4100928060547628]
	TIME [epoch: 5.71 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5607750840334336		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.5607750840334336 | validation: 0.6127156138745419]
	TIME [epoch: 5.71 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6466375429014978		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.6466375429014978 | validation: 0.6637728601721464]
	TIME [epoch: 5.71 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.635590656163194		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.635590656163194 | validation: 0.4541561524467126]
	TIME [epoch: 5.71 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5124440559225273		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.5124440559225273 | validation: 0.34897524773241884]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43450617383188905		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.43450617383188905 | validation: 0.7600942530693917]
	TIME [epoch: 5.74 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9079314301569883		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.9079314301569883 | validation: 0.7687180300258681]
	TIME [epoch: 5.73 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6344582560183315		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.6344582560183315 | validation: 0.3532246937904435]
	TIME [epoch: 5.71 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7387960319687208		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.7387960319687208 | validation: 0.5212081334971058]
	TIME [epoch: 5.72 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5691027056357754		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.5691027056357754 | validation: 0.4759651298495209]
	TIME [epoch: 5.71 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5710567202974888		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.5710567202974888 | validation: 0.5076652769638256]
	TIME [epoch: 5.71 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6086002157430342		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.6086002157430342 | validation: 0.4201173954211204]
	TIME [epoch: 5.71 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5002389706214081		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.5002389706214081 | validation: 0.48800338854317865]
	TIME [epoch: 5.75 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4918390874141244		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.4918390874141244 | validation: 0.37870915689300916]
	TIME [epoch: 5.72 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6642638817235376		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.6642638817235376 | validation: 0.45980060805303213]
	TIME [epoch: 5.71 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6140850229194641		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.6140850229194641 | validation: 0.5019553349549739]
	TIME [epoch: 5.71 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.512322296262277		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.512322296262277 | validation: 0.3797699369064018]
	TIME [epoch: 5.71 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5247052521927332		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.5247052521927332 | validation: 0.5769158997015288]
	TIME [epoch: 5.71 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6137228126702178		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.6137228126702178 | validation: 0.7157495070210397]
	TIME [epoch: 5.75 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5808588195625205		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.5808588195625205 | validation: 0.43849284443214886]
	TIME [epoch: 5.73 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4555860581816767		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.4555860581816767 | validation: 0.6905999242647426]
	TIME [epoch: 5.72 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4589634035796704		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.4589634035796704 | validation: 0.40193394174241137]
	TIME [epoch: 5.72 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.603912044882869		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.603912044882869 | validation: 0.5141483072169115]
	TIME [epoch: 5.72 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5886759255321761		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.5886759255321761 | validation: 0.520727613791988]
	TIME [epoch: 5.72 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45292244903088313		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.45292244903088313 | validation: 0.597905939233171]
	TIME [epoch: 5.71 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0876511720228903		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.0876511720228903 | validation: 0.7985015247289923]
	TIME [epoch: 5.77 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5349416343653377		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.5349416343653377 | validation: 0.8501459450756466]
	TIME [epoch: 5.72 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6062869748979605		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.6062869748979605 | validation: 0.4739454352814023]
	TIME [epoch: 5.72 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38150938114586597		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.38150938114586597 | validation: 0.31535473366537636]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7431020302876712		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.7431020302876712 | validation: 0.6531404304280604]
	TIME [epoch: 5.72 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.658761175102499		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.658761175102499 | validation: 0.2770787457956049]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4593440017136302		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.4593440017136302 | validation: 0.6000262151816378]
	TIME [epoch: 5.74 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5878559622820707		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.5878559622820707 | validation: 0.3464477212890048]
	TIME [epoch: 5.73 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.428947717764684		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.428947717764684 | validation: 0.39974737989827336]
	TIME [epoch: 5.71 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4640911769353939		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.4640911769353939 | validation: 0.498194073058896]
	TIME [epoch: 5.72 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44817144500603256		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.44817144500603256 | validation: 0.38438558353239416]
	TIME [epoch: 5.71 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4928994781607079		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.4928994781607079 | validation: 0.563285781696156]
	TIME [epoch: 5.72 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42628080505487426		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.42628080505487426 | validation: 0.4662483681199911]
	TIME [epoch: 5.72 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4162321818010428		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.4162321818010428 | validation: 0.25110699041007245]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4732871649641931		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.4732871649641931 | validation: 0.511855750209923]
	TIME [epoch: 5.72 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5734746230419157		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.5734746230419157 | validation: 0.3959570180584165]
	TIME [epoch: 5.72 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4687863902631922		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.4687863902631922 | validation: 0.24761140824764327]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5059192852317206		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.5059192852317206 | validation: 0.30990136096360343]
	TIME [epoch: 5.7 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47820617213609623		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.47820617213609623 | validation: 0.28625179236680276]
	TIME [epoch: 5.7 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3691602127493195		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.3691602127493195 | validation: 0.30689796561882565]
	TIME [epoch: 5.75 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3534476571468639		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.3534476571468639 | validation: 0.7204077417924546]
	TIME [epoch: 5.72 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46051361833190174		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.46051361833190174 | validation: 0.8808189893327579]
	TIME [epoch: 5.71 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6433324248813969		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.6433324248813969 | validation: 0.45865852490836817]
	TIME [epoch: 5.72 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4174267738215665		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.4174267738215665 | validation: 0.4357828125607253]
	TIME [epoch: 5.71 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4581586813478986		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.4581586813478986 | validation: 0.3321146932726594]
	TIME [epoch: 5.71 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5844390108503393		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.5844390108503393 | validation: 0.38106092327535296]
	TIME [epoch: 5.72 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5411216662477429		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.5411216662477429 | validation: 0.790422346581948]
	TIME [epoch: 5.75 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4085491760858176		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.4085491760858176 | validation: 0.23220764518959933]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3928580777045879		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.3928580777045879 | validation: 0.658010883964428]
	TIME [epoch: 5.71 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4657974123845287		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.4657974123845287 | validation: 0.5496678005006125]
	TIME [epoch: 5.71 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37190039983302653		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.37190039983302653 | validation: 0.7980906227667661]
	TIME [epoch: 5.71 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5772509449662169		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.5772509449662169 | validation: 0.3119117503474713]
	TIME [epoch: 5.71 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5244590535692579		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.5244590535692579 | validation: 0.4426373855031406]
	TIME [epoch: 5.76 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3125312808405591		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.3125312808405591 | validation: 0.5408206690375923]
	TIME [epoch: 5.72 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4225518056928861		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.4225518056928861 | validation: 0.2860576545690552]
	TIME [epoch: 5.72 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5149618501607911		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.5149618501607911 | validation: 0.4124645519893271]
	TIME [epoch: 5.71 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37821547166892633		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.37821547166892633 | validation: 0.49141262233213157]
	TIME [epoch: 5.72 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44606594616158646		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.44606594616158646 | validation: 0.303193715454083]
	TIME [epoch: 5.71 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3802683430743618		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.3802683430743618 | validation: 0.5053754672016282]
	TIME [epoch: 5.73 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5785191246151399		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.5785191246151399 | validation: 0.3907578551357117]
	TIME [epoch: 5.74 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39064430369491354		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.39064430369491354 | validation: 0.3605786988678908]
	TIME [epoch: 5.72 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5203890636758399		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.5203890636758399 | validation: 0.4129757714303915]
	TIME [epoch: 5.71 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3234631426947351		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.3234631426947351 | validation: 0.6150212208412066]
	TIME [epoch: 5.71 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5258149200652302		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.5258149200652302 | validation: 0.2723769771598289]
	TIME [epoch: 5.71 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38940244041167354		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.38940244041167354 | validation: 0.2653524631383416]
	TIME [epoch: 5.72 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42293314777669505		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.42293314777669505 | validation: 0.2826299596225963]
	TIME [epoch: 5.75 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46158805769453215		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.46158805769453215 | validation: 0.5958000330148352]
	TIME [epoch: 5.75 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5461875361587102		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.5461875361587102 | validation: 0.32795291558716366]
	TIME [epoch: 5.71 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5997477494769067		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.5997477494769067 | validation: 0.4578240917865388]
	TIME [epoch: 5.73 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40761999493992873		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.40761999493992873 | validation: 0.3006479076593851]
	TIME [epoch: 5.71 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42377732947713587		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.42377732947713587 | validation: 0.3917995347168109]
	TIME [epoch: 5.72 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34159099531932974		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.34159099531932974 | validation: 0.4399645774659989]
	TIME [epoch: 5.72 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35713630407405267		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.35713630407405267 | validation: 0.25974336353640765]
	TIME [epoch: 5.77 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39770691299310595		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.39770691299310595 | validation: 0.3137696521787273]
	TIME [epoch: 5.71 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4302148759203418		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.4302148759203418 | validation: 0.2810333058655043]
	TIME [epoch: 5.71 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3681688140579838		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.3681688140579838 | validation: 0.4324378581420102]
	TIME [epoch: 5.71 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34532840676967413		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.34532840676967413 | validation: 0.3056162059630646]
	TIME [epoch: 5.71 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4636569419788146		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.4636569419788146 | validation: 0.6801279731978093]
	TIME [epoch: 5.71 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3665684649571426		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.3665684649571426 | validation: 0.4055940602268393]
	TIME [epoch: 5.74 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43337133393419613		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.43337133393419613 | validation: 0.2620352069121179]
	TIME [epoch: 5.73 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2897791089073894		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.2897791089073894 | validation: 0.26471125113905586]
	TIME [epoch: 5.71 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2997671878371263		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.2997671878371263 | validation: 0.3677339709510252]
	TIME [epoch: 5.7 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3128906326418118		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.3128906326418118 | validation: 0.3492117168401454]
	TIME [epoch: 5.71 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43092900769772857		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.43092900769772857 | validation: 0.30894204412924525]
	TIME [epoch: 5.71 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2692604871670581		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.2692604871670581 | validation: 0.26896932418098013]
	TIME [epoch: 5.72 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2723364717987259		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.2723364717987259 | validation: 0.23346083843520468]
	TIME [epoch: 5.76 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44560584133412573		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.44560584133412573 | validation: 0.2471785472557189]
	TIME [epoch: 5.71 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.255005501787981		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.255005501787981 | validation: 0.23843896058545602]
	TIME [epoch: 5.72 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3112600164646657		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.3112600164646657 | validation: 0.214762226958648]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40098031346849744		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.40098031346849744 | validation: 0.23631326788479454]
	TIME [epoch: 5.71 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2933716493343575		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.2933716493343575 | validation: 0.2834357470618258]
	TIME [epoch: 5.73 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3131295402498944		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.3131295402498944 | validation: 0.30135100221544925]
	TIME [epoch: 5.76 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.345596355536981		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.345596355536981 | validation: 0.2675324895465617]
	TIME [epoch: 5.75 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3092376864247925		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.3092376864247925 | validation: 0.30069048050441666]
	TIME [epoch: 5.73 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3322244093453353		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.3322244093453353 | validation: 0.5336133382161959]
	TIME [epoch: 5.73 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34010962661289856		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.34010962661289856 | validation: 0.22377049488001025]
	TIME [epoch: 5.73 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3703077400997251		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.3703077400997251 | validation: 0.30204880074069373]
	TIME [epoch: 5.73 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32178687858891425		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.32178687858891425 | validation: 0.6470648145545537]
	TIME [epoch: 5.73 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3467689992479865		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.3467689992479865 | validation: 0.28405375104455394]
	TIME [epoch: 5.77 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40735740704202505		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.40735740704202505 | validation: 0.39406664047768347]
	TIME [epoch: 5.73 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2918148685870955		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.2918148685870955 | validation: 0.593864502188354]
	TIME [epoch: 5.73 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41569208000373364		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.41569208000373364 | validation: 0.9674617106631591]
	TIME [epoch: 5.73 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8285191940876077		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.8285191940876077 | validation: 1.4843323839996436]
	TIME [epoch: 5.73 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7225953377369964		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.7225953377369964 | validation: 0.6372647881892233]
	TIME [epoch: 5.73 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38637536332473743		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.38637536332473743 | validation: 0.25262571094741104]
	TIME [epoch: 5.75 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32152984191105605		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.32152984191105605 | validation: 0.21603280051711024]
	TIME [epoch: 5.75 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.330401115416776		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.330401115416776 | validation: 0.34621956782967345]
	TIME [epoch: 5.73 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27849132245022995		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.27849132245022995 | validation: 0.2184335511260018]
	TIME [epoch: 5.73 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29647831087837895		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.29647831087837895 | validation: 0.2828222667568231]
	TIME [epoch: 5.72 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34481861587113805		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.34481861587113805 | validation: 0.6672550101494495]
	TIME [epoch: 5.73 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46714705877939067		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.46714705877939067 | validation: 0.3411497240987266]
	TIME [epoch: 5.73 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4199257454046863		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.4199257454046863 | validation: 0.23548931107117915]
	TIME [epoch: 5.77 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2862255353276541		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.2862255353276541 | validation: 0.22547141598941595]
	TIME [epoch: 5.73 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25206460058985836		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.25206460058985836 | validation: 0.23406201294077064]
	TIME [epoch: 5.73 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2787838104758268		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.2787838104758268 | validation: 0.2595236731513759]
	TIME [epoch: 5.73 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2528624848246124		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.2528624848246124 | validation: 0.2727999834941199]
	TIME [epoch: 5.73 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3289115356465071		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.3289115356465071 | validation: 0.2844593893659411]
	TIME [epoch: 5.73 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3063166976650127		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.3063166976650127 | validation: 0.2428578720003114]
	TIME [epoch: 5.75 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31575959474925974		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.31575959474925974 | validation: 0.3485852429684836]
	TIME [epoch: 5.74 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31812054763542674		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.31812054763542674 | validation: 0.26017554882574323]
	TIME [epoch: 5.73 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2544013712401128		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.2544013712401128 | validation: 0.195234612541772]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19820530522016		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.19820530522016 | validation: 0.3786388618397314]
	TIME [epoch: 5.72 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24715791014808128		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.24715791014808128 | validation: 0.16315301921751077]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2578619765848998		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.2578619765848998 | validation: 0.2562167016768104]
	TIME [epoch: 5.73 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2593962579614246		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.2593962579614246 | validation: 0.16881766429208028]
	TIME [epoch: 5.77 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22205962662948828		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.22205962662948828 | validation: 0.20669761849724996]
	TIME [epoch: 5.73 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18712450547690246		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.18712450547690246 | validation: 0.2718184289219176]
	TIME [epoch: 5.72 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21163345198985528		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.21163345198985528 | validation: 0.1694213206837821]
	TIME [epoch: 5.72 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20801185188277077		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.20801185188277077 | validation: 0.6395860675167915]
	TIME [epoch: 5.72 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3775752747594947		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.3775752747594947 | validation: 0.22383059306107314]
	TIME [epoch: 5.72 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28978015145434943		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.28978015145434943 | validation: 0.22086417872617767]
	TIME [epoch: 5.75 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32070179858181463		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.32070179858181463 | validation: 0.1941879112052326]
	TIME [epoch: 5.74 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2031615015414597		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.2031615015414597 | validation: 0.19091214460694303]
	TIME [epoch: 5.73 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2182007871958777		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.2182007871958777 | validation: 0.17911117347118954]
	TIME [epoch: 5.72 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1640162903143037		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.1640162903143037 | validation: 0.3216126348822748]
	TIME [epoch: 5.71 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23213990730038403		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.23213990730038403 | validation: 0.22747493294799775]
	TIME [epoch: 5.72 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21848695374587718		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.21848695374587718 | validation: 0.23853718775563323]
	TIME [epoch: 5.72 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29871981341722215		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.29871981341722215 | validation: 0.24266577420084376]
	TIME [epoch: 5.77 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25517431415865605		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.25517431415865605 | validation: 0.2214411183495446]
	TIME [epoch: 5.72 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2923206692169594		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.2923206692169594 | validation: 0.28712771673165816]
	TIME [epoch: 5.72 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.318616365782185		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.318616365782185 | validation: 0.15420225654502104]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24452743581531972		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.24452743581531972 | validation: 0.2694816018013058]
	TIME [epoch: 5.72 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19564973773390115		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.19564973773390115 | validation: 0.12601173235001598]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24399127755569852		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.24399127755569852 | validation: 0.11281388307693807]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14269781746403626		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.14269781746403626 | validation: 0.15664990945682875]
	TIME [epoch: 5.72 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.272556957332875		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.272556957332875 | validation: 0.3620172135992833]
	TIME [epoch: 5.71 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2128442372700743		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.2128442372700743 | validation: 0.30031104536661135]
	TIME [epoch: 5.71 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2547212673256848		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.2547212673256848 | validation: 0.32102366404188376]
	TIME [epoch: 5.71 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30997566535390925		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.30997566535390925 | validation: 0.23399819593942803]
	TIME [epoch: 5.71 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1672201234991805		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.1672201234991805 | validation: 0.18393290636489737]
	TIME [epoch: 5.74 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2024477577005273		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.2024477577005273 | validation: 0.1833881812364713]
	TIME [epoch: 5.76 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4437990872014986		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.4437990872014986 | validation: 0.21234377534826648]
	TIME [epoch: 5.73 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22048902385636335		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.22048902385636335 | validation: 0.12552517183132345]
	TIME [epoch: 5.72 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29477741009428127		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.29477741009428127 | validation: 0.18523232967471384]
	TIME [epoch: 5.72 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17714622480806944		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.17714622480806944 | validation: 0.13114479680011315]
	TIME [epoch: 5.72 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19209985041995842		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.19209985041995842 | validation: 0.19917608321758842]
	TIME [epoch: 5.72 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20508837117074447		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.20508837117074447 | validation: 0.23346477505466237]
	TIME [epoch: 5.75 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2282127745034087		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.2282127745034087 | validation: 0.13956005514093633]
	TIME [epoch: 5.73 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2028034784811587		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.2028034784811587 | validation: 0.1411284018241969]
	TIME [epoch: 5.72 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2329003010491319		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.2329003010491319 | validation: 0.1666082305899055]
	TIME [epoch: 5.71 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26687143175868167		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.26687143175868167 | validation: 0.21987537877032914]
	TIME [epoch: 5.71 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21161180677113664		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.21161180677113664 | validation: 0.18218391855540744]
	TIME [epoch: 5.72 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19578889848327996		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.19578889848327996 | validation: 0.15561354624098195]
	TIME [epoch: 5.72 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20195940868229148		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.20195940868229148 | validation: 0.25414608165926533]
	TIME [epoch: 5.75 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19594135582839733		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.19594135582839733 | validation: 0.10067972538054512]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_258.pth
	Model improved!!!
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15043742873464344		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.15043742873464344 | validation: 0.11235885098293903]
	TIME [epoch: 5.71 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.162298935934969		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.162298935934969 | validation: 0.13897802817617275]
	TIME [epoch: 5.72 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16123914590104532		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.16123914590104532 | validation: 0.1603163627227614]
	TIME [epoch: 5.71 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1465529090548612		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.1465529090548612 | validation: 0.13797457762019522]
	TIME [epoch: 5.72 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16285617770534544		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.16285617770534544 | validation: 0.2605753887571578]
	TIME [epoch: 5.76 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1635736569042119		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.1635736569042119 | validation: 0.37372924659288187]
	TIME [epoch: 5.71 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2234033623173278		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.2234033623173278 | validation: 0.14549592183840107]
	TIME [epoch: 5.71 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1912122822037763		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.1912122822037763 | validation: 0.39025449065460666]
	TIME [epoch: 5.71 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2519429553700779		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.2519429553700779 | validation: 0.2710355996320162]
	TIME [epoch: 5.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1995422936868873		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.1995422936868873 | validation: 0.1337598981900519]
	TIME [epoch: 5.72 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1980586528200751		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.1980586528200751 | validation: 0.0987335231108395]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17047086777722917		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.17047086777722917 | validation: 0.13993898804205793]
	TIME [epoch: 5.75 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23346377007129174		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.23346377007129174 | validation: 0.17496666416494414]
	TIME [epoch: 5.71 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12710175780798963		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.12710175780798963 | validation: 0.330564533279031]
	TIME [epoch: 5.73 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18009877068235106		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.18009877068235106 | validation: 0.3258700728510964]
	TIME [epoch: 5.72 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21109859983203477		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.21109859983203477 | validation: 0.31069322938389343]
	TIME [epoch: 5.71 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1676258179864849		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.1676258179864849 | validation: 0.17569756815653637]
	TIME [epoch: 5.72 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13346408656499617		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.13346408656499617 | validation: 0.10255186659862359]
	TIME [epoch: 5.75 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18728102469006258		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.18728102469006258 | validation: 0.23099357617902663]
	TIME [epoch: 5.73 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2542759906689395		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.2542759906689395 | validation: 0.14900137479270972]
	TIME [epoch: 5.73 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15446121188038964		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.15446121188038964 | validation: 0.39140888130697377]
	TIME [epoch: 5.73 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21446556595278243		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.21446556595278243 | validation: 0.24469403368242582]
	TIME [epoch: 5.71 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20874524811758347		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.20874524811758347 | validation: 0.2317836782761831]
	TIME [epoch: 5.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15025568476696044		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.15025568476696044 | validation: 0.1477405385234707]
	TIME [epoch: 5.72 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14247169677535454		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.14247169677535454 | validation: 0.24672241803056216]
	TIME [epoch: 5.75 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15087797627433772		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.15087797627433772 | validation: 0.1890363373943513]
	TIME [epoch: 5.72 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22434590907077231		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.22434590907077231 | validation: 0.1323347633039153]
	TIME [epoch: 5.72 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19449911887888996		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.19449911887888996 | validation: 0.27146654654160557]
	TIME [epoch: 5.71 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2388477340863931		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.2388477340863931 | validation: 0.2827263303413993]
	TIME [epoch: 5.71 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18180732775991748		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.18180732775991748 | validation: 0.11291271337350357]
	TIME [epoch: 5.71 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14942811287335114		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.14942811287335114 | validation: 0.14887158154486696]
	TIME [epoch: 5.76 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17089471309888235		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.17089471309888235 | validation: 0.18442748610332516]
	TIME [epoch: 5.72 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17548083925726415		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.17548083925726415 | validation: 0.19024661572058157]
	TIME [epoch: 5.72 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21092222114648293		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.21092222114648293 | validation: 0.09501354786379523]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1650440699500614		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.1650440699500614 | validation: 0.2336301565218696]
	TIME [epoch: 5.72 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15383494298624478		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.15383494298624478 | validation: 0.09260135322128585]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10596892578172523		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.10596892578172523 | validation: 0.2629860072412177]
	TIME [epoch: 5.72 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2040850519878956		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.2040850519878956 | validation: 0.1179501378715593]
	TIME [epoch: 5.75 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25445004740595084		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.25445004740595084 | validation: 0.12255816390844082]
	TIME [epoch: 5.73 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1950076942774568		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.1950076942774568 | validation: 0.21348180508535997]
	TIME [epoch: 5.71 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16487679534282568		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.16487679534282568 | validation: 0.19536308886904918]
	TIME [epoch: 5.71 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18918417304087803		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.18918417304087803 | validation: 0.17150337452131006]
	TIME [epoch: 5.71 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1798311831492972		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.1798311831492972 | validation: 0.1449916956498418]
	TIME [epoch: 5.71 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14794744323364964		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.14794744323364964 | validation: 0.11983992167514018]
	TIME [epoch: 5.75 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12846361048615873		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.12846361048615873 | validation: 0.2540645804268298]
	TIME [epoch: 5.72 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19293444376792998		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.19293444376792998 | validation: 0.12509240622202214]
	TIME [epoch: 5.71 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33527550322424643		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.33527550322424643 | validation: 0.2790785598120149]
	TIME [epoch: 5.72 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38497790074325006		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.38497790074325006 | validation: 0.3787682045522038]
	TIME [epoch: 5.71 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1938118712714058		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.1938118712714058 | validation: 0.26864549729101384]
	TIME [epoch: 5.73 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20369941710823797		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.20369941710823797 | validation: 0.12460083779012689]
	TIME [epoch: 5.74 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16156564806433482		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.16156564806433482 | validation: 0.16308862946239583]
	TIME [epoch: 5.74 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15622857784477018		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.15622857784477018 | validation: 0.13825199335205254]
	TIME [epoch: 5.72 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14469750639283882		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.14469750639283882 | validation: 0.1626354016370371]
	TIME [epoch: 5.72 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17173545920539407		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.17173545920539407 | validation: 0.11337639344281343]
	TIME [epoch: 5.71 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1593055873008029		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.1593055873008029 | validation: 0.115338505920831]
	TIME [epoch: 5.72 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1720105467334606		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.1720105467334606 | validation: 0.12700475818425289]
	TIME [epoch: 5.71 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1576633463674018		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.1576633463674018 | validation: 0.14379005322933158]
	TIME [epoch: 5.76 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14106540282240101		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.14106540282240101 | validation: 0.1427573388754397]
	TIME [epoch: 5.72 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1627288309898541		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.1627288309898541 | validation: 0.16774126393486838]
	TIME [epoch: 5.72 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17480432954057434		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.17480432954057434 | validation: 0.12518336793454413]
	TIME [epoch: 5.72 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17959271680880937		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.17959271680880937 | validation: 0.2072293272020513]
	TIME [epoch: 5.72 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23357142091318955		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.23357142091318955 | validation: 0.12835591258525977]
	TIME [epoch: 5.71 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2540930356663396		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.2540930356663396 | validation: 0.14882336219955905]
	TIME [epoch: 5.73 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13336957784369047		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.13336957784369047 | validation: 0.14755376384981772]
	TIME [epoch: 5.74 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15666659770668123		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.15666659770668123 | validation: 0.24109072828167627]
	TIME [epoch: 5.71 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19181246469931074		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.19181246469931074 | validation: 0.3831603805586427]
	TIME [epoch: 5.72 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2471786906981745		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.2471786906981745 | validation: 0.13653433085823075]
	TIME [epoch: 5.71 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16097351598137688		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.16097351598137688 | validation: 0.11606546877394061]
	TIME [epoch: 5.71 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11879374968370685		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.11879374968370685 | validation: 0.47599019602602355]
	TIME [epoch: 5.72 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19357406307560093		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.19357406307560093 | validation: 0.19275632673949097]
	TIME [epoch: 5.74 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1437088100262183		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.1437088100262183 | validation: 0.20587193671241127]
	TIME [epoch: 5.75 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3860338247129824		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.3860338247129824 | validation: 0.29526219971867046]
	TIME [epoch: 5.72 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2759603806368284		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.2759603806368284 | validation: 0.19596779435463652]
	TIME [epoch: 5.71 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17371523811973624		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.17371523811973624 | validation: 0.15236740778025518]
	TIME [epoch: 5.71 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18550638161595842		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.18550638161595842 | validation: 0.18858793953170452]
	TIME [epoch: 5.71 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16617450588489627		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.16617450588489627 | validation: 0.19126184487651465]
	TIME [epoch: 5.71 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27006972013769465		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.27006972013769465 | validation: 0.2027990743524628]
	TIME [epoch: 5.75 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17137847454184546		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.17137847454184546 | validation: 0.1119520078800161]
	TIME [epoch: 5.71 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12612799349883078		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.12612799349883078 | validation: 0.0860980701486319]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_337.pth
	Model improved!!!
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1339287186042084		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.1339287186042084 | validation: 0.24069692423703898]
	TIME [epoch: 5.71 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20018032096618585		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.20018032096618585 | validation: 0.14363444561553596]
	TIME [epoch: 5.7 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12611523970043786		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.12611523970043786 | validation: 0.11302103675620537]
	TIME [epoch: 5.7 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2205273988384251		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.2205273988384251 | validation: 0.2100759821831777]
	TIME [epoch: 5.73 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1647576896097928		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.1647576896097928 | validation: 0.1123257561374254]
	TIME [epoch: 5.72 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1506815942548262		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.1506815942548262 | validation: 0.11214306405809314]
	TIME [epoch: 5.71 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24429358799155293		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.24429358799155293 | validation: 0.32994088905963637]
	TIME [epoch: 5.71 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22816437896198005		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.22816437896198005 | validation: 0.07644861438913711]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10820223469302989		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.10820223469302989 | validation: 0.08623924689131174]
	TIME [epoch: 5.71 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15348833858304692		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.15348833858304692 | validation: 0.11882529316115563]
	TIME [epoch: 5.72 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15300000207248154		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.15300000207248154 | validation: 0.09291988249686199]
	TIME [epoch: 5.75 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14973478377038177		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.14973478377038177 | validation: 0.2707666007526971]
	TIME [epoch: 5.71 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17960143585830435		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.17960143585830435 | validation: 0.09986964533341532]
	TIME [epoch: 5.71 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10981375739841666		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.10981375739841666 | validation: 0.100898974414512]
	TIME [epoch: 5.71 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14075116397888443		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.14075116397888443 | validation: 0.13944693461875118]
	TIME [epoch: 5.71 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16040620358512483		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.16040620358512483 | validation: 0.13603428513866464]
	TIME [epoch: 5.71 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12967324660604118		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.12967324660604118 | validation: 0.19192508831087543]
	TIME [epoch: 5.75 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17912081052683135		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.17912081052683135 | validation: 0.18369393642925866]
	TIME [epoch: 5.72 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1503636331340143		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.1503636331340143 | validation: 0.13612568046703152]
	TIME [epoch: 5.71 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15434702927324312		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.15434702927324312 | validation: 0.11924914053712868]
	TIME [epoch: 5.71 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10311401272812702		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.10311401272812702 | validation: 0.08838031239071871]
	TIME [epoch: 5.71 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14507926343874325		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.14507926343874325 | validation: 0.10388546385008984]
	TIME [epoch: 5.71 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11610735953214815		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.11610735953214815 | validation: 0.08555047304890795]
	TIME [epoch: 5.71 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17568725356271683		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.17568725356271683 | validation: 0.11752192276224413]
	TIME [epoch: 5.75 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16678793627670394		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.16678793627670394 | validation: 0.11261146359191526]
	TIME [epoch: 5.71 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353403213466833		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.1353403213466833 | validation: 0.09977724859309348]
	TIME [epoch: 5.71 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10204203797553232		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.10204203797553232 | validation: 0.28115092132309516]
	TIME [epoch: 5.71 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14460720256544354		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.14460720256544354 | validation: 0.15667139243223602]
	TIME [epoch: 5.71 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1246280378898949		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.1246280378898949 | validation: 0.07869776365271916]
	TIME [epoch: 5.71 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12416451863073898		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.12416451863073898 | validation: 0.11353127538956727]
	TIME [epoch: 5.74 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15022371509803306		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.15022371509803306 | validation: 0.22099176288502267]
	TIME [epoch: 5.73 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346270647910596		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.1346270647910596 | validation: 0.08601583798176993]
	TIME [epoch: 5.71 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18069855264162166		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.18069855264162166 | validation: 0.10813159590334309]
	TIME [epoch: 5.71 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12926282227741173		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.12926282227741173 | validation: 0.07897564032529779]
	TIME [epoch: 5.71 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1788278149567162		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.1788278149567162 | validation: 0.36050636072608006]
	TIME [epoch: 5.71 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27539756487478895		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.27539756487478895 | validation: 0.15726260186689217]
	TIME [epoch: 5.71 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13986805103514707		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.13986805103514707 | validation: 0.08231026793435958]
	TIME [epoch: 5.75 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22486038425157584		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.22486038425157584 | validation: 0.19562946989275534]
	TIME [epoch: 5.71 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14548703390764156		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.14548703390764156 | validation: 0.18175222751396564]
	TIME [epoch: 5.71 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11902104494452886		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.11902104494452886 | validation: 0.09665327683676517]
	TIME [epoch: 5.71 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11794195260273685		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.11794195260273685 | validation: 0.13297570649478022]
	TIME [epoch: 5.71 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1234051733749298		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.1234051733749298 | validation: 0.245456399955265]
	TIME [epoch: 5.71 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14994117313222827		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.14994117313222827 | validation: 0.10958203414392856]
	TIME [epoch: 5.74 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1300058305563299		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.1300058305563299 | validation: 0.1505385015760964]
	TIME [epoch: 5.73 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20507551943359192		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.20507551943359192 | validation: 0.09645518434166156]
	TIME [epoch: 5.71 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1182456524694588		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.1182456524694588 | validation: 0.07981678968200097]
	TIME [epoch: 5.71 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09805397402418989		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.09805397402418989 | validation: 0.18244443884384914]
	TIME [epoch: 5.71 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13440233641993765		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.13440233641993765 | validation: 0.11139903812115183]
	TIME [epoch: 5.71 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09223786409176554		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.09223786409176554 | validation: 0.181838481573221]
	TIME [epoch: 5.74 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14401308097618215		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.14401308097618215 | validation: 0.21057712830543004]
	TIME [epoch: 5.75 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12779836628687102		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.12779836628687102 | validation: 0.20792082062750822]
	TIME [epoch: 5.71 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13710007842108546		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.13710007842108546 | validation: 0.1143632224841853]
	TIME [epoch: 5.71 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11456879945375814		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.11456879945375814 | validation: 0.0766002552682084]
	TIME [epoch: 5.71 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08705288584654786		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.08705288584654786 | validation: 0.15353628615698006]
	TIME [epoch: 5.71 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12697049051294257		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.12697049051294257 | validation: 0.10318372518492577]
	TIME [epoch: 5.71 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13330636404375606		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.13330636404375606 | validation: 0.16519249629698035]
	TIME [epoch: 5.72 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1194162456398643		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.1194162456398643 | validation: 0.1426608559175471]
	TIME [epoch: 5.74 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12293347974069273		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.12293347974069273 | validation: 0.07437633704669161]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_395.pth
	Model improved!!!
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15849606708448208		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.15849606708448208 | validation: 0.10111369662256683]
	TIME [epoch: 5.71 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15411950910761377		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.15411950910761377 | validation: 0.09311599877346642]
	TIME [epoch: 5.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0956796836950789		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.0956796836950789 | validation: 0.07141913622508217]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_398.pth
	Model improved!!!
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09386602844266304		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.09386602844266304 | validation: 0.12194579508440825]
	TIME [epoch: 5.71 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15079957729597587		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.15079957729597587 | validation: 0.07010804161007568]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09846642347330578		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.09846642347330578 | validation: 0.16551712994651266]
	TIME [epoch: 5.71 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12487629893572968		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.12487629893572968 | validation: 0.11951988439156638]
	TIME [epoch: 5.71 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10388944542217926		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.10388944542217926 | validation: 0.07085780926014457]
	TIME [epoch: 5.71 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06584002060645368		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.06584002060645368 | validation: 0.09953078312882845]
	TIME [epoch: 5.71 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10661244956686865		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.10661244956686865 | validation: 0.2522248293778022]
	TIME [epoch: 5.71 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23658747557343493		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.23658747557343493 | validation: 0.27693925114076784]
	TIME [epoch: 5.73 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19705805802414061		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.19705805802414061 | validation: 0.09467457562457547]
	TIME [epoch: 5.73 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1504408655610892		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.1504408655610892 | validation: 0.09888309169357008]
	TIME [epoch: 5.71 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10003997961372077		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.10003997961372077 | validation: 0.149020192369971]
	TIME [epoch: 5.71 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1378927860554055		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.1378927860554055 | validation: 0.11373138665742871]
	TIME [epoch: 5.71 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09808113003321098		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.09808113003321098 | validation: 0.13539055184613802]
	TIME [epoch: 5.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1364230242915063		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.1364230242915063 | validation: 0.18651866596258387]
	TIME [epoch: 5.71 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1477486332519347		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.1477486332519347 | validation: 0.0825121551066286]
	TIME [epoch: 5.75 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0905920495250869		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.0905920495250869 | validation: 0.09165891876216345]
	TIME [epoch: 5.71 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16762420027390684		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.16762420027390684 | validation: 0.25835210323758395]
	TIME [epoch: 5.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14809349943898809		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.14809349943898809 | validation: 0.09373078158537956]
	TIME [epoch: 5.71 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11416420582201858		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.11416420582201858 | validation: 0.12034965037529319]
	TIME [epoch: 5.71 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1112234111369038		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.1112234111369038 | validation: 0.12056538311216258]
	TIME [epoch: 5.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11683415199819121		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.11683415199819121 | validation: 0.2184836140420229]
	TIME [epoch: 5.73 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12452490986187222		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.12452490986187222 | validation: 0.1305761541087058]
	TIME [epoch: 5.72 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11255242482611316		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.11255242482611316 | validation: 0.09161215527707546]
	TIME [epoch: 5.71 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08927569986449947		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.08927569986449947 | validation: 0.08559165198970992]
	TIME [epoch: 5.71 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10392825192952859		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.10392825192952859 | validation: 0.13457040983804694]
	TIME [epoch: 5.71 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10830384066880955		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.10830384066880955 | validation: 0.08940862184883225]
	TIME [epoch: 5.71 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09656814498615247		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.09656814498615247 | validation: 0.13108981733993724]
	TIME [epoch: 5.71 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12548345422396465		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.12548345422396465 | validation: 0.1120966257297148]
	TIME [epoch: 5.75 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11917268900099164		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.11917268900099164 | validation: 0.16059788563853417]
	TIME [epoch: 5.71 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1197987850547227		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.1197987850547227 | validation: 0.2049478243865466]
	TIME [epoch: 5.71 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1558302308672571		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.1558302308672571 | validation: 0.09071255536862868]
	TIME [epoch: 5.71 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10402334205767823		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.10402334205767823 | validation: 0.09381171537073428]
	TIME [epoch: 5.71 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10567099078466066		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.10567099078466066 | validation: 0.09146163631447213]
	TIME [epoch: 5.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10683301960359526		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.10683301960359526 | validation: 0.1416436926994207]
	TIME [epoch: 5.72 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10146110077225717		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.10146110077225717 | validation: 0.09273961972347998]
	TIME [epoch: 5.74 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10558981234213552		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.10558981234213552 | validation: 0.16114795150644476]
	TIME [epoch: 5.71 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1334712841263871		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.1334712841263871 | validation: 0.08326977800685947]
	TIME [epoch: 5.71 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10520492898776951		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.10520492898776951 | validation: 0.11845077512701782]
	TIME [epoch: 5.71 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09547960711326996		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.09547960711326996 | validation: 0.17121135022942902]
	TIME [epoch: 5.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1315637940360258		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.1315637940360258 | validation: 0.1198447932744411]
	TIME [epoch: 5.7 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12285694165779282		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.12285694165779282 | validation: 0.06738135927583581]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_439.pth
	Model improved!!!
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09641803839666799		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.09641803839666799 | validation: 0.0645970242320522]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_440.pth
	Model improved!!!
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09233567746549368		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.09233567746549368 | validation: 0.11255245793104703]
	TIME [epoch: 5.71 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1145780172379171		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.1145780172379171 | validation: 0.10829001195643688]
	TIME [epoch: 5.71 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08118044788551321		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.08118044788551321 | validation: 0.1402571374651445]
	TIME [epoch: 5.71 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12992478248527495		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.12992478248527495 | validation: 0.0910605464406277]
	TIME [epoch: 5.7 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08500691601518107		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.08500691601518107 | validation: 0.10863624557648814]
	TIME [epoch: 5.73 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09187383932297274		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.09187383932297274 | validation: 0.1487295919609891]
	TIME [epoch: 5.72 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10943942231818488		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.10943942231818488 | validation: 0.0708072321662632]
	TIME [epoch: 5.71 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08164656544774682		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.08164656544774682 | validation: 0.1107511808991579]
	TIME [epoch: 5.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09722224068725734		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.09722224068725734 | validation: 0.09136823828241174]
	TIME [epoch: 5.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09688841520888497		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.09688841520888497 | validation: 0.10329514562646828]
	TIME [epoch: 5.7 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13139205577128316		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.13139205577128316 | validation: 0.08729164544348095]
	TIME [epoch: 5.71 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08947092954040811		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.08947092954040811 | validation: 0.12265270808099006]
	TIME [epoch: 5.75 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1544149925404843		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.1544149925404843 | validation: 0.14092797261502696]
	TIME [epoch: 5.71 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12104811733002287		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.12104811733002287 | validation: 0.1296517532333612]
	TIME [epoch: 5.71 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08650067944597639		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.08650067944597639 | validation: 0.0618731254646243]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_455.pth
	Model improved!!!
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08450066363297024		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.08450066363297024 | validation: 0.05858572911040231]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_456.pth
	Model improved!!!
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10114346350255586		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.10114346350255586 | validation: 0.11796659269294493]
	TIME [epoch: 5.71 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10445359873376636		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.10445359873376636 | validation: 0.1525467799303274]
	TIME [epoch: 5.73 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1315435701716628		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.1315435701716628 | validation: 0.13861476473485254]
	TIME [epoch: 5.72 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10948695491619931		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.10948695491619931 | validation: 0.0878672285816647]
	TIME [epoch: 5.71 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16260606171966474		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.16260606171966474 | validation: 0.13689429958797603]
	TIME [epoch: 5.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14052652844739344		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.14052652844739344 | validation: 0.11664562041098914]
	TIME [epoch: 5.71 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10413532783933777		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.10413532783933777 | validation: 0.08839866263670892]
	TIME [epoch: 5.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07984542603750132		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.07984542603750132 | validation: 0.0841104063486852]
	TIME [epoch: 5.71 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17014198847183845		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.17014198847183845 | validation: 0.137982574307686]
	TIME [epoch: 5.75 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279115806161037		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.1279115806161037 | validation: 0.08552972434221083]
	TIME [epoch: 5.71 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11366450584323445		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.11366450584323445 | validation: 0.11310110599452297]
	TIME [epoch: 5.71 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10351689681726131		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.10351689681726131 | validation: 0.09595302786251608]
	TIME [epoch: 5.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10167036795567047		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.10167036795567047 | validation: 0.07012272221944037]
	TIME [epoch: 5.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18441972998303685		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.18441972998303685 | validation: 0.13672096737614378]
	TIME [epoch: 5.71 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09700366496098332		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.09700366496098332 | validation: 0.061812004077207126]
	TIME [epoch: 5.73 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07822744703220261		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.07822744703220261 | validation: 0.13553529491110006]
	TIME [epoch: 5.72 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07616957147940288		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.07616957147940288 | validation: 0.07338554099471326]
	TIME [epoch: 5.71 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08711228295144442		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.08711228295144442 | validation: 0.16683074019506022]
	TIME [epoch: 5.71 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12774145141682697		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.12774145141682697 | validation: 0.21591604176383716]
	TIME [epoch: 5.71 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15549942498913288		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.15549942498913288 | validation: 0.10977494311505584]
	TIME [epoch: 5.71 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11595221829579166		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.11595221829579166 | validation: 0.1054417882615776]
	TIME [epoch: 5.71 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15040103778709552		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.15040103778709552 | validation: 0.13756038192933207]
	TIME [epoch: 5.75 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11295196449110806		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.11295196449110806 | validation: 0.09607554414321003]
	TIME [epoch: 5.71 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10381335192176049		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.10381335192176049 | validation: 0.11697126222174997]
	TIME [epoch: 5.71 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10590058094667122		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.10590058094667122 | validation: 0.10328088710398751]
	TIME [epoch: 5.71 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09372914706017979		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.09372914706017979 | validation: 0.0953021815054488]
	TIME [epoch: 5.71 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07595098501868144		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.07595098501868144 | validation: 0.09896711708592072]
	TIME [epoch: 5.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08437548876998248		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.08437548876998248 | validation: 0.08410797487265036]
	TIME [epoch: 5.73 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07738675990006319		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.07738675990006319 | validation: 0.10725363551764229]
	TIME [epoch: 5.73 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07778031801730018		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.07778031801730018 | validation: 0.15799793853206293]
	TIME [epoch: 5.71 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11038874490011276		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.11038874490011276 | validation: 0.07867103615545325]
	TIME [epoch: 5.71 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10474802757692235		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.10474802757692235 | validation: 0.08230376735669326]
	TIME [epoch: 5.71 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07553101068828968		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.07553101068828968 | validation: 0.06038005038579639]
	TIME [epoch: 5.71 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07703712034628524		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.07703712034628524 | validation: 0.12335576679498822]
	TIME [epoch: 5.71 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08978541854741574		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.08978541854741574 | validation: 0.09157428711158992]
	TIME [epoch: 5.75 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06581151964754084		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.06581151964754084 | validation: 0.060414404252118435]
	TIME [epoch: 5.71 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07391700531550185		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.07391700531550185 | validation: 0.07704856255358845]
	TIME [epoch: 5.71 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0810760670153311		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.0810760670153311 | validation: 0.07559794801302468]
	TIME [epoch: 5.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07887557652787561		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.07887557652787561 | validation: 0.09374539685205484]
	TIME [epoch: 5.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09114488620131389		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.09114488620131389 | validation: 0.09077396723510583]
	TIME [epoch: 5.7 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10095548480335675		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.10095548480335675 | validation: 0.11055370588100011]
	TIME [epoch: 5.71 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11826066167358604		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.11826066167358604 | validation: 0.08200813081078417]
	TIME [epoch: 5.74 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09711338683883149		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.09711338683883149 | validation: 0.2503013021240039]
	TIME [epoch: 5.71 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1395904452103077		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.1395904452103077 | validation: 0.08156857572786085]
	TIME [epoch: 5.71 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07710897890637229		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.07710897890637229 | validation: 0.09684654449938691]
	TIME [epoch: 5.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07806259044164682		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.07806259044164682 | validation: 0.07713060741201955]
	TIME [epoch: 5.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07240768637859434		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.07240768637859434 | validation: 0.08662995454541722]
	TIME [epoch: 5.7 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10219453933827016		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.10219453933827016 | validation: 0.1345608599559346]
	TIME [epoch: 5.74 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.089260603094057		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.089260603094057 | validation: 0.06663191773327666]
	TIME [epoch: 5.71 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0639581773467863		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.0639581773467863 | validation: 0.09948177650848447]
	TIME [epoch: 5.71 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09610960253961556		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.09610960253961556 | validation: 0.07166536982862551]
	TIME [epoch: 5.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08342758211046825		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.08342758211046825 | validation: 0.07715668444181192]
	TIME [epoch: 5.71 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0885734219503459		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.0885734219503459 | validation: 0.11719220274965934]
	TIME [epoch: 5.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12464872465528123		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.12464872465528123 | validation: 0.17103838207598163]
	TIME [epoch: 5.72 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11108207357748845		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.11108207357748845 | validation: 0.09935741432962664]
	TIME [epoch: 5.74 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0902263666105979		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.0902263666105979 | validation: 0.1168396313318199]
	TIME [epoch: 5.71 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08439321575604482		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.08439321575604482 | validation: 0.10051276013721662]
	TIME [epoch: 5.71 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09700672755716976		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.09700672755716976 | validation: 0.08529282385323285]
	TIME [epoch: 5.71 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09225961037683404		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.09225961037683404 | validation: 0.08895316539279727]
	TIME [epoch: 5.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0733320154321329		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.0733320154321329 | validation: 0.05328439220652996]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_516.pth
	Model improved!!!
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06861147215396864		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.06861147215396864 | validation: 0.14263185337288517]
	TIME [epoch: 5.75 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1509591433804647		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.1509591433804647 | validation: 0.06831695885586564]
	TIME [epoch: 5.71 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06675566060707952		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.06675566060707952 | validation: 0.12589657863582196]
	TIME [epoch: 5.71 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10330222104744854		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.10330222104744854 | validation: 0.09168566843404655]
	TIME [epoch: 5.71 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13801990577005244		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.13801990577005244 | validation: 0.0853611614695661]
	TIME [epoch: 5.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08175280510066103		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.08175280510066103 | validation: 0.06948467085381353]
	TIME [epoch: 5.7 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0616172171894451		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.0616172171894451 | validation: 0.08893730275815372]
	TIME [epoch: 5.71 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060569060847209304		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.060569060847209304 | validation: 0.0967313150792107]
	TIME [epoch: 5.74 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09931483630757473		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.09931483630757473 | validation: 0.1117687321711]
	TIME [epoch: 5.71 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09751254506415723		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.09751254506415723 | validation: 0.0836747445438816]
	TIME [epoch: 5.71 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08423746386286132		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.08423746386286132 | validation: 0.06965662236580096]
	TIME [epoch: 5.7 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060752060217226005		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.060752060217226005 | validation: 0.060776499804475144]
	TIME [epoch: 5.7 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07390358923285646		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.07390358923285646 | validation: 0.11705326467712379]
	TIME [epoch: 5.7 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17042680337433153		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.17042680337433153 | validation: 0.11314178911965092]
	TIME [epoch: 5.73 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06836417651010676		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.06836417651010676 | validation: 0.05713825684325899]
	TIME [epoch: 5.72 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06481352486343137		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.06481352486343137 | validation: 0.07726000684543693]
	TIME [epoch: 5.71 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06611650880428128		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.06611650880428128 | validation: 0.06236193059280756]
	TIME [epoch: 5.71 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07698683842546994		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.07698683842546994 | validation: 0.0854682213698504]
	TIME [epoch: 5.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10113677792828081		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.10113677792828081 | validation: 0.09056507403601248]
	TIME [epoch: 5.7 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06278293195205284		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.06278293195205284 | validation: 0.07548695590475787]
	TIME [epoch: 5.71 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09047661390683234		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.09047661390683234 | validation: 0.1571378388228108]
	TIME [epoch: 5.75 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11636380477906143		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.11636380477906143 | validation: 0.08941313281470127]
	TIME [epoch: 5.71 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05707547554460334		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.05707547554460334 | validation: 0.0743817887418092]
	TIME [epoch: 5.71 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09288240081374009		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.09288240081374009 | validation: 0.08373957812518501]
	TIME [epoch: 5.71 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0823051943656984		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.0823051943656984 | validation: 0.06368100377372304]
	TIME [epoch: 5.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06081400006483176		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.06081400006483176 | validation: 0.07938763031066706]
	TIME [epoch: 5.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08332958367843774		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.08332958367843774 | validation: 0.09195243468980892]
	TIME [epoch: 5.73 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07739305804892635		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.07739305804892635 | validation: 0.06600685122674652]
	TIME [epoch: 5.72 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06842022046937313		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.06842022046937313 | validation: 0.06894112491017478]
	TIME [epoch: 5.71 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08677020643509975		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.08677020643509975 | validation: 0.05195844771223323]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_546.pth
	Model improved!!!
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06894633240593104		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.06894633240593104 | validation: 0.0813876005380887]
	TIME [epoch: 5.71 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10767148228720132		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.10767148228720132 | validation: 0.05871420010568453]
	TIME [epoch: 5.7 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08525665264613827		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.08525665264613827 | validation: 0.08348246221983734]
	TIME [epoch: 5.71 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06498443852251584		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.06498443852251584 | validation: 0.1367352152533907]
	TIME [epoch: 5.75 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0996672331851501		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.0996672331851501 | validation: 0.07405494586029714]
	TIME [epoch: 5.71 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07355596083139057		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.07355596083139057 | validation: 0.071968078693377]
	TIME [epoch: 5.71 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07176387290348141		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.07176387290348141 | validation: 0.08596269957152342]
	TIME [epoch: 5.71 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05873394300428505		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.05873394300428505 | validation: 0.09789351486275541]
	TIME [epoch: 5.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07718911145668972		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.07718911145668972 | validation: 0.09695068403461594]
	TIME [epoch: 5.71 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07317006078276386		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.07317006078276386 | validation: 0.11536117320875029]
	TIME [epoch: 5.73 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08340491785794765		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.08340491785794765 | validation: 0.09722890434259811]
	TIME [epoch: 5.73 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14042279116393766		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.14042279116393766 | validation: 0.11065844776694322]
	TIME [epoch: 5.71 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09049519776564353		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.09049519776564353 | validation: 0.08849620778285659]
	TIME [epoch: 5.71 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06140144268205428		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.06140144268205428 | validation: 0.053516557290775854]
	TIME [epoch: 5.71 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06877372369115024		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.06877372369115024 | validation: 0.062013020070405725]
	TIME [epoch: 5.71 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058440726193793424		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.058440726193793424 | validation: 0.11871024028571173]
	TIME [epoch: 5.71 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08769774018055781		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.08769774018055781 | validation: 0.08923564072477984]
	TIME [epoch: 5.75 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07745567599096653		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.07745567599096653 | validation: 0.07062312156436715]
	TIME [epoch: 5.71 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1305453448092786		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.1305453448092786 | validation: 0.07035866631183745]
	TIME [epoch: 5.71 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06786530759379385		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.06786530759379385 | validation: 0.14380881616009808]
	TIME [epoch: 5.71 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11635939470909837		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.11635939470909837 | validation: 0.18999823537376717]
	TIME [epoch: 5.71 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11634808204663222		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.11634808204663222 | validation: 0.10931346530876646]
	TIME [epoch: 5.71 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0843086684582574		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.0843086684582574 | validation: 0.04595179741689764]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_569.pth
	Model improved!!!
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05511526358415221		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.05511526358415221 | validation: 0.07009094852975704]
	TIME [epoch: 5.73 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10847510182474841		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.10847510182474841 | validation: 0.0781536549832473]
	TIME [epoch: 5.71 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06409652472651757		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.06409652472651757 | validation: 0.08887627892774315]
	TIME [epoch: 5.71 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08176179098189625		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.08176179098189625 | validation: 0.0635630384151198]
	TIME [epoch: 5.71 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056259545569588884		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.056259545569588884 | validation: 0.07039467686888055]
	TIME [epoch: 5.71 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08702739374558803		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.08702739374558803 | validation: 0.053113520498129944]
	TIME [epoch: 5.71 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059763390651753165		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.059763390651753165 | validation: 0.04734929807517757]
	TIME [epoch: 5.76 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05817863339719736		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.05817863339719736 | validation: 0.15476423947690077]
	TIME [epoch: 5.72 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11132688852105012		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.11132688852105012 | validation: 0.09162724067534328]
	TIME [epoch: 5.71 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0931704814122443		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.0931704814122443 | validation: 0.07251235278734203]
	TIME [epoch: 5.71 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06796753188800697		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.06796753188800697 | validation: 0.08892293773134752]
	TIME [epoch: 5.71 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05851626230622686		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.05851626230622686 | validation: 0.05731098606141808]
	TIME [epoch: 5.71 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07270878562993224		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.07270878562993224 | validation: 0.06292653274618103]
	TIME [epoch: 5.74 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06212256700097389		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.06212256700097389 | validation: 0.08262744566634651]
	TIME [epoch: 5.73 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08970439468532247		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.08970439468532247 | validation: 0.0848127799325724]
	TIME [epoch: 5.72 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06119972440481329		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.06119972440481329 | validation: 0.05059737110595682]
	TIME [epoch: 5.71 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06817218516274684		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.06817218516274684 | validation: 0.0695507206862641]
	TIME [epoch: 5.71 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07479738044560696		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.07479738044560696 | validation: 0.052232336237473004]
	TIME [epoch: 5.71 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06777223889547708		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.06777223889547708 | validation: 0.12515335809688882]
	TIME [epoch: 5.71 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06878405222459048		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.06878405222459048 | validation: 0.057075504707802864]
	TIME [epoch: 5.76 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07020654420764452		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.07020654420764452 | validation: 0.0776236863594725]
	TIME [epoch: 5.71 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07715327239167469		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.07715327239167469 | validation: 0.07376783233790447]
	TIME [epoch: 5.71 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06563017687940621		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.06563017687940621 | validation: 0.0636224912096072]
	TIME [epoch: 5.71 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09613675463057461		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.09613675463057461 | validation: 0.11986127711531104]
	TIME [epoch: 5.71 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09245160624639205		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.09245160624639205 | validation: 0.0738748475245057]
	TIME [epoch: 5.71 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08700523168188909		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.08700523168188909 | validation: 0.08708815115222145]
	TIME [epoch: 5.74 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07546234574445587		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.07546234574445587 | validation: 0.09033679809681594]
	TIME [epoch: 5.73 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08501503750206074		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.08501503750206074 | validation: 0.06437623744727314]
	TIME [epoch: 5.71 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055916582440551144		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.055916582440551144 | validation: 0.09374290347714993]
	TIME [epoch: 5.71 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07492922088681814		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.07492922088681814 | validation: 0.0827336977478792]
	TIME [epoch: 5.71 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07452519448077541		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.07452519448077541 | validation: 0.08097879477558972]
	TIME [epoch: 5.71 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10508221346700088		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.10508221346700088 | validation: 0.11923035534309044]
	TIME [epoch: 5.71 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10188921771175827		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.10188921771175827 | validation: 0.10733331436963099]
	TIME [epoch: 5.76 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08169230449446724		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.08169230449446724 | validation: 0.1081005428436098]
	TIME [epoch: 5.71 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09902036715184143		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.09902036715184143 | validation: 0.09071362765409514]
	TIME [epoch: 5.71 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06348216030422531		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.06348216030422531 | validation: 0.13132878921716856]
	TIME [epoch: 5.71 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08441107025158666		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.08441107025158666 | validation: 0.07714297285473802]
	TIME [epoch: 5.71 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06946212596056911		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.06946212596056911 | validation: 0.049390032295290175]
	TIME [epoch: 5.71 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07438604780211294		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.07438604780211294 | validation: 0.07070446280606005]
	TIME [epoch: 5.72 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06748605997216359		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.06748605997216359 | validation: 0.08112536163863833]
	TIME [epoch: 5.74 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08740467281790139		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.08740467281790139 | validation: 0.1093877843646792]
	TIME [epoch: 5.71 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07950698071809398		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.07950698071809398 | validation: 0.06855268552093323]
	TIME [epoch: 5.71 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052195481423945686		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.052195481423945686 | validation: 0.06722481284003051]
	TIME [epoch: 5.71 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06075993773413416		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.06075993773413416 | validation: 0.08511135707306108]
	TIME [epoch: 5.71 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09222052578295761		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.09222052578295761 | validation: 0.1206948413698607]
	TIME [epoch: 5.71 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1078869330289578		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.1078869330289578 | validation: 0.05808102282949495]
	TIME [epoch: 5.75 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05945548176334946		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.05945548176334946 | validation: 0.0593758396217363]
	TIME [epoch: 5.72 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06306493593751072		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.06306493593751072 | validation: 0.046876368980970175]
	TIME [epoch: 5.71 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0684108760558518		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.0684108760558518 | validation: 0.09233381002479492]
	TIME [epoch: 5.71 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06961802532588218		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.06961802532588218 | validation: 0.25039340204138893]
	TIME [epoch: 5.71 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18856400683388308		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.18856400683388308 | validation: 0.0620388694733062]
	TIME [epoch: 5.71 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06778842767400753		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.06778842767400753 | validation: 0.1099327551678039]
	TIME [epoch: 5.72 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09418450641283044		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.09418450641283044 | validation: 0.08000604895580513]
	TIME [epoch: 5.75 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08361068446493919		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.08361068446493919 | validation: 0.10878583625033648]
	TIME [epoch: 5.71 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06496217340876209		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.06496217340876209 | validation: 0.057979867126361884]
	TIME [epoch: 5.71 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04941287767707085		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.04941287767707085 | validation: 0.07948669249753765]
	TIME [epoch: 5.71 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07933660287166756		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.07933660287166756 | validation: 0.06858687778121934]
	TIME [epoch: 5.71 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05768827031372821		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.05768827031372821 | validation: 0.05199269032408349]
	TIME [epoch: 5.72 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046388016812474564		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.046388016812474564 | validation: 0.06272840778213604]
	TIME [epoch: 5.75 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055974132929078504		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.055974132929078504 | validation: 0.20674635105756053]
	TIME [epoch: 5.72 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16491001386048332		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.16491001386048332 | validation: 0.05812657177022057]
	TIME [epoch: 5.71 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0562279808869976		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.0562279808869976 | validation: 0.07114740641178592]
	TIME [epoch: 5.71 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049465545271976594		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.049465545271976594 | validation: 0.05544589995369356]
	TIME [epoch: 5.71 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056725066471009236		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.056725066471009236 | validation: 0.06919351474231421]
	TIME [epoch: 5.71 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05722066041751951		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.05722066041751951 | validation: 0.058422109203298475]
	TIME [epoch: 5.72 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06138892202412492		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.06138892202412492 | validation: 0.05725162279072347]
	TIME [epoch: 5.74 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05386578224121501		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.05386578224121501 | validation: 0.06840707929066964]
	TIME [epoch: 5.71 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07055093106063669		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.07055093106063669 | validation: 0.08448215938221006]
	TIME [epoch: 5.71 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08824662018220189		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.08824662018220189 | validation: 0.0945935488716567]
	TIME [epoch: 5.71 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07578808087534515		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.07578808087534515 | validation: 0.0720983742187084]
	TIME [epoch: 5.71 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07763351506261429		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.07763351506261429 | validation: 0.057168087739098664]
	TIME [epoch: 5.71 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07441703570313074		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.07441703570313074 | validation: 0.10635280156726368]
	TIME [epoch: 5.75 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09162967434553049		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.09162967434553049 | validation: 0.04872304118080148]
	TIME [epoch: 5.72 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06836698134199164		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.06836698134199164 | validation: 0.0758166165296799]
	TIME [epoch: 5.71 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05875856917930877		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.05875856917930877 | validation: 0.08521980908421646]
	TIME [epoch: 5.71 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0673876667034933		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.0673876667034933 | validation: 0.08396770070904978]
	TIME [epoch: 5.71 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07639419551124092		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.07639419551124092 | validation: 0.055148089823453976]
	TIME [epoch: 5.71 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06276470198074044		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.06276470198074044 | validation: 0.061483458680843074]
	TIME [epoch: 5.71 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05706285615367958		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.05706285615367958 | validation: 0.09774410043224119]
	TIME [epoch: 5.75 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06389797985587649		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.06389797985587649 | validation: 0.06986069826805102]
	TIME [epoch: 5.71 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06339104125111908		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.06339104125111908 | validation: 0.06879147656060564]
	TIME [epoch: 5.71 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06475110430121735		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.06475110430121735 | validation: 0.0663988007532802]
	TIME [epoch: 5.71 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06518956926479397		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.06518956926479397 | validation: 0.06196990350436927]
	TIME [epoch: 5.71 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08095959530297868		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.08095959530297868 | validation: 0.0937794645647029]
	TIME [epoch: 5.71 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1419034924671496		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.1419034924671496 | validation: 0.15037072298880727]
	TIME [epoch: 5.74 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0657002486639339		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.0657002486639339 | validation: 0.10529931624112882]
	TIME [epoch: 5.73 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08733124766413847		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.08733124766413847 | validation: 0.04156934734744445]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_656.pth
	Model improved!!!
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05729217240610584		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.05729217240610584 | validation: 0.05459928882545685]
	TIME [epoch: 5.71 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05048645258239209		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.05048645258239209 | validation: 0.06458939140930862]
	TIME [epoch: 5.71 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09601977074806846		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.09601977074806846 | validation: 0.07667065597026836]
	TIME [epoch: 5.71 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06903538195389632		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.06903538195389632 | validation: 0.05482287910642858]
	TIME [epoch: 5.72 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06355501283684692		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.06355501283684692 | validation: 0.06333236528843024]
	TIME [epoch: 5.74 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07164578223570163		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.07164578223570163 | validation: 0.08183346891482855]
	TIME [epoch: 5.71 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07065790159185793		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.07065790159185793 | validation: 0.06241774211039292]
	TIME [epoch: 5.71 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06133402191646293		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.06133402191646293 | validation: 0.05605458520067298]
	TIME [epoch: 5.71 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05448681465256888		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.05448681465256888 | validation: 0.11867363109096608]
	TIME [epoch: 5.71 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07270186338967849		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.07270186338967849 | validation: 0.05392557440659559]
	TIME [epoch: 5.71 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05262326319417208		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.05262326319417208 | validation: 0.058512559577322154]
	TIME [epoch: 5.73 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0547063596866723		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.0547063596866723 | validation: 0.0701834378626047]
	TIME [epoch: 5.72 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05054461179781089		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.05054461179781089 | validation: 0.06959832969517407]
	TIME [epoch: 5.71 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06064883573373581		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.06064883573373581 | validation: 0.05098994417396166]
	TIME [epoch: 5.71 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06247005753196058		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.06247005753196058 | validation: 0.11249437049824247]
	TIME [epoch: 5.71 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06927919726575672		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.06927919726575672 | validation: 0.06177186460093864]
	TIME [epoch: 5.71 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06141646156295624		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.06141646156295624 | validation: 0.053070211461309455]
	TIME [epoch: 5.71 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06750925651644354		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.06750925651644354 | validation: 0.10155756320262156]
	TIME [epoch: 5.75 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06739400856784143		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.06739400856784143 | validation: 0.05007493487067793]
	TIME [epoch: 5.71 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04888363310303327		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.04888363310303327 | validation: 0.05282726444534872]
	TIME [epoch: 5.71 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0583813186183333		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.0583813186183333 | validation: 0.04871193386726325]
	TIME [epoch: 5.71 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05001362483973123		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.05001362483973123 | validation: 0.05916898000672852]
	TIME [epoch: 5.71 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06138918955123864		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.06138918955123864 | validation: 0.042449048608035195]
	TIME [epoch: 5.71 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049969929416465345		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.049969929416465345 | validation: 0.05634176944193838]
	TIME [epoch: 5.73 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048990404327984315		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.048990404327984315 | validation: 0.05224232873730508]
	TIME [epoch: 5.73 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04467808266817742		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.04467808266817742 | validation: 0.04314692765686454]
	TIME [epoch: 5.71 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04823551095771849		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.04823551095771849 | validation: 0.05002709171310757]
	TIME [epoch: 5.71 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060434144455307		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.060434144455307 | validation: 0.140366546826295]
	TIME [epoch: 5.71 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11156828575562197		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.11156828575562197 | validation: 0.06506648713299214]
	TIME [epoch: 5.71 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053564295521874576		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.053564295521874576 | validation: 0.08209491147857591]
	TIME [epoch: 5.71 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06419613535223277		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.06419613535223277 | validation: 0.08855259391615414]
	TIME [epoch: 5.75 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06011202236337478		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.06011202236337478 | validation: 0.041611715219439474]
	TIME [epoch: 5.71 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04695791111694436		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.04695791111694436 | validation: 0.042049133545335564]
	TIME [epoch: 5.71 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05112280274189364		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.05112280274189364 | validation: 0.0644923043564647]
	TIME [epoch: 5.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05742296258461983		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.05742296258461983 | validation: 0.06882266564989527]
	TIME [epoch: 5.71 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050767690928928216		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.050767690928928216 | validation: 0.07887976514462863]
	TIME [epoch: 5.71 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05989471821995029		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.05989471821995029 | validation: 0.04158703316367229]
	TIME [epoch: 5.73 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04820458216558784		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.04820458216558784 | validation: 0.08444072840191261]
	TIME [epoch: 5.73 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07597858993312967		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.07597858993312967 | validation: 0.07240141479197383]
	TIME [epoch: 5.71 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06725831842494652		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.06725831842494652 | validation: 0.07787567713377352]
	TIME [epoch: 5.71 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07017005384692883		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.07017005384692883 | validation: 0.06001499281039113]
	TIME [epoch: 5.71 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05607325178143237		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.05607325178143237 | validation: 0.07500087934323857]
	TIME [epoch: 5.71 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06214965076832142		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.06214965076832142 | validation: 0.06083006909747736]
	TIME [epoch: 5.71 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05736620908524456		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.05736620908524456 | validation: 0.07034884285369715]
	TIME [epoch: 5.75 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05819750697814118		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.05819750697814118 | validation: 0.052368638530393065]
	TIME [epoch: 5.71 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05818596486090074		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.05818596486090074 | validation: 0.05030991579593451]
	TIME [epoch: 5.71 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05372281729901457		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.05372281729901457 | validation: 0.0661378839692293]
	TIME [epoch: 5.71 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06087126173883118		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.06087126173883118 | validation: 0.04992229332638545]
	TIME [epoch: 5.71 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05126752506266695		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.05126752506266695 | validation: 0.05199334053403079]
	TIME [epoch: 5.71 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05162587900105796		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.05162587900105796 | validation: 0.06188942346242465]
	TIME [epoch: 5.72 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052449310079116976		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.052449310079116976 | validation: 0.047984774516037075]
	TIME [epoch: 5.74 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04099812326703138		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.04099812326703138 | validation: 0.04943768050175982]
	TIME [epoch: 5.71 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054152563129458035		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.054152563129458035 | validation: 0.058212948523593745]
	TIME [epoch: 5.71 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05060017972188511		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.05060017972188511 | validation: 0.036687765736165306]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_710.pth
	Model improved!!!
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04815993565435488		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.04815993565435488 | validation: 0.05613907953298242]
	TIME [epoch: 5.71 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0495058700349487		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.0495058700349487 | validation: 0.052168301689895245]
	TIME [epoch: 5.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04074011501704919		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.04074011501704919 | validation: 0.04741648702447629]
	TIME [epoch: 5.75 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056467054599763165		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.056467054599763165 | validation: 0.05218173236233958]
	TIME [epoch: 5.71 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06076937415639406		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.06076937415639406 | validation: 0.06700295935464036]
	TIME [epoch: 5.71 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04705158603332893		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.04705158603332893 | validation: 0.05838772194691913]
	TIME [epoch: 5.71 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043105514414354965		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.043105514414354965 | validation: 0.0432784607276078]
	TIME [epoch: 5.71 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04403314744069866		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.04403314744069866 | validation: 0.06462501954051789]
	TIME [epoch: 5.71 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061969369671301955		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.061969369671301955 | validation: 0.05885829851212055]
	TIME [epoch: 5.73 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06476343340894697		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.06476343340894697 | validation: 0.056404312092573045]
	TIME [epoch: 5.73 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05442011275952619		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.05442011275952619 | validation: 0.05133270005164328]
	TIME [epoch: 5.71 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045158650410243986		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.045158650410243986 | validation: 0.04914021174656265]
	TIME [epoch: 5.71 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05492878571217805		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.05492878571217805 | validation: 0.08283642128789113]
	TIME [epoch: 5.71 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05236545468457944		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.05236545468457944 | validation: 0.05886894698804378]
	TIME [epoch: 5.71 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06739477540219244		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.06739477540219244 | validation: 0.0659131862986665]
	TIME [epoch: 5.71 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048258000010631824		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.048258000010631824 | validation: 0.07835307990723182]
	TIME [epoch: 5.75 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07265530072212888		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.07265530072212888 | validation: 0.07861484032409082]
	TIME [epoch: 5.71 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05810058687474609		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.05810058687474609 | validation: 0.05232097378007694]
	TIME [epoch: 5.71 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05027055890955653		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.05027055890955653 | validation: 0.07231228202242064]
	TIME [epoch: 5.71 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05622924726727399		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.05622924726727399 | validation: 0.08145809179156728]
	TIME [epoch: 5.71 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052636445060486814		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.052636445060486814 | validation: 0.05030086679789422]
	TIME [epoch: 5.71 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04618069433091733		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.04618069433091733 | validation: 0.06761959444533437]
	TIME [epoch: 5.71 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06072582244708532		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.06072582244708532 | validation: 0.06496128645159917]
	TIME [epoch: 5.74 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04516719198753259		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.04516719198753259 | validation: 0.05952917484070255]
	TIME [epoch: 5.71 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043490259478964725		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.043490259478964725 | validation: 0.06166474885757908]
	TIME [epoch: 5.71 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07263750063702648		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.07263750063702648 | validation: 0.07883397000007733]
	TIME [epoch: 5.7 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053532309381232844		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.053532309381232844 | validation: 0.05611694455636828]
	TIME [epoch: 5.7 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05833616979626632		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.05833616979626632 | validation: 0.04927213402825334]
	TIME [epoch: 5.71 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058203960902001334		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.058203960902001334 | validation: 0.09892874447915175]
	TIME [epoch: 5.74 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0793557532282672		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.0793557532282672 | validation: 0.055094646878465665]
	TIME [epoch: 5.71 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04930824905364353		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.04930824905364353 | validation: 0.08273689880254842]
	TIME [epoch: 5.71 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06474077044914811		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.06474077044914811 | validation: 0.0697035353409242]
	TIME [epoch: 5.7 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044794305205913744		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.044794305205913744 | validation: 0.052555759433708236]
	TIME [epoch: 5.71 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07357625188182852		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.07357625188182852 | validation: 0.06662348333281337]
	TIME [epoch: 5.71 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05008512097169767		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.05008512097169767 | validation: 0.0425089384390431]
	TIME [epoch: 5.72 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04562517628053926		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.04562517628053926 | validation: 0.042226699032406695]
	TIME [epoch: 5.74 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05308959196272564		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.05308959196272564 | validation: 0.06554375502262896]
	TIME [epoch: 5.71 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05251865626062044		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.05251865626062044 | validation: 0.042620363122179955]
	TIME [epoch: 5.71 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03712846393896606		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.03712846393896606 | validation: 0.06269383229267458]
	TIME [epoch: 5.71 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05784989573889801		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.05784989573889801 | validation: 0.10386350992918039]
	TIME [epoch: 5.71 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08242493170156899		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.08242493170156899 | validation: 0.08262042894663228]
	TIME [epoch: 5.71 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07488404850036688		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.07488404850036688 | validation: 0.08529357111843343]
	TIME [epoch: 5.74 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0549899566018595		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.0549899566018595 | validation: 0.08829032164010102]
	TIME [epoch: 5.71 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05005231003983818		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.05005231003983818 | validation: 0.03577607871560743]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_754.pth
	Model improved!!!
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04647629428851494		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.04647629428851494 | validation: 0.038230881272336856]
	TIME [epoch: 5.71 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04134332330451687		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.04134332330451687 | validation: 0.04275389899484628]
	TIME [epoch: 5.7 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046481858875579186		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.046481858875579186 | validation: 0.0698692902514529]
	TIME [epoch: 5.7 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06497578833305588		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.06497578833305588 | validation: 0.04589187465893089]
	TIME [epoch: 5.72 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04156971303036964		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.04156971303036964 | validation: 0.03912040495543179]
	TIME [epoch: 5.74 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04915199614273401		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.04915199614273401 | validation: 0.04407398207020598]
	TIME [epoch: 5.71 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038434893300201056		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.038434893300201056 | validation: 0.07701890953821625]
	TIME [epoch: 5.71 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053327358965853014		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.053327358965853014 | validation: 0.05084294232807721]
	TIME [epoch: 5.71 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0404604526330452		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.0404604526330452 | validation: 0.04636117656098019]
	TIME [epoch: 5.7 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04005710415019771		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.04005710415019771 | validation: 0.042050926087197855]
	TIME [epoch: 5.71 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06470788761708843		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.06470788761708843 | validation: 0.07902503462412522]
	TIME [epoch: 5.74 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04788515028855378		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.04788515028855378 | validation: 0.0448814695722227]
	TIME [epoch: 5.71 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05407314884351655		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.05407314884351655 | validation: 0.10410625904405443]
	TIME [epoch: 5.71 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10127400805346988		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.10127400805346988 | validation: 0.07955627710539125]
	TIME [epoch: 5.71 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06620380483729105		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.06620380483729105 | validation: 0.06359400888242965]
	TIME [epoch: 5.71 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054777944446912336		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.054777944446912336 | validation: 0.08435940038604432]
	TIME [epoch: 5.7 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057227141279771104		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.057227141279771104 | validation: 0.04803592077548753]
	TIME [epoch: 5.72 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043068788252442716		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.043068788252442716 | validation: 0.0892700090443096]
	TIME [epoch: 5.74 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06724520763364022		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.06724520763364022 | validation: 0.07482280992510361]
	TIME [epoch: 5.71 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0468994304345501		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.0468994304345501 | validation: 0.04291556028886884]
	TIME [epoch: 5.71 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03751177511143808		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.03751177511143808 | validation: 0.054201866323706195]
	TIME [epoch: 5.71 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0494118155492746		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.0494118155492746 | validation: 0.05902468541262824]
	TIME [epoch: 5.7 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059844345496508654		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.059844345496508654 | validation: 0.0642489563274709]
	TIME [epoch: 5.71 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047620636420273914		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.047620636420273914 | validation: 0.04733627589730835]
	TIME [epoch: 5.73 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044488613215322374		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.044488613215322374 | validation: 0.057659932296452276]
	TIME [epoch: 5.72 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061046868098562634		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.061046868098562634 | validation: 0.057372656262389445]
	TIME [epoch: 5.7 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056869976694133184		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.056869976694133184 | validation: 0.06686953226087848]
	TIME [epoch: 5.71 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04827037614045582		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.04827037614045582 | validation: 0.045545545176103576]
	TIME [epoch: 5.71 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03886093328087951		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.03886093328087951 | validation: 0.05052001033782574]
	TIME [epoch: 5.71 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052231654306121526		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.052231654306121526 | validation: 0.05154254437693074]
	TIME [epoch: 5.71 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040338380415607035		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.040338380415607035 | validation: 0.03811238719836275]
	TIME [epoch: 5.75 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0408766023981436		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.0408766023981436 | validation: 0.057939410239984175]
	TIME [epoch: 5.71 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04243594558826615		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.04243594558826615 | validation: 0.051174890029597984]
	TIME [epoch: 5.71 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03519804149891742		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.03519804149891742 | validation: 0.042841288920194794]
	TIME [epoch: 5.71 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03559926387137342		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.03559926387137342 | validation: 0.041496649864942815]
	TIME [epoch: 5.71 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034121428324803804		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.034121428324803804 | validation: 0.053791641949515814]
	TIME [epoch: 5.71 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04242916659656505		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.04242916659656505 | validation: 0.05280431158521893]
	TIME [epoch: 5.73 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05774533959782397		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.05774533959782397 | validation: 0.03187579596110115]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_792.pth
	Model improved!!!
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041971778059993595		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.041971778059993595 | validation: 0.05162545772759103]
	TIME [epoch: 5.71 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042327422190434866		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.042327422190434866 | validation: 0.04369894696280561]
	TIME [epoch: 5.71 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04605073915886167		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.04605073915886167 | validation: 0.05298588255372369]
	TIME [epoch: 5.71 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033836044664982634		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.033836044664982634 | validation: 0.04251687775104222]
	TIME [epoch: 5.71 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04478673447840284		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.04478673447840284 | validation: 0.06278090718157583]
	TIME [epoch: 5.71 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04582669412730449		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.04582669412730449 | validation: 0.03965670311520191]
	TIME [epoch: 5.75 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042944053475428276		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.042944053475428276 | validation: 0.03903433367952846]
	TIME [epoch: 5.71 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038311535268917445		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.038311535268917445 | validation: 0.05174921664031791]
	TIME [epoch: 5.71 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04224793492779494		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.04224793492779494 | validation: 0.03466726035910206]
	TIME [epoch: 5.71 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04773644343381571		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.04773644343381571 | validation: 0.08285958387787265]
	TIME [epoch: 5.71 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06622707140969943		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.06622707140969943 | validation: 0.05815108345096329]
	TIME [epoch: 5.71 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04379588078765437		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.04379588078765437 | validation: 0.052561633292713496]
	TIME [epoch: 5.73 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035266498510526365		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.035266498510526365 | validation: 0.052947905629382945]
	TIME [epoch: 5.72 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04189119360863685		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.04189119360863685 | validation: 0.08851737279587368]
	TIME [epoch: 5.71 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056513773930218975		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.056513773930218975 | validation: 0.06273048267563786]
	TIME [epoch: 5.71 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05106583794309897		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.05106583794309897 | validation: 0.057940062944411716]
	TIME [epoch: 5.71 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04856691479217204		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.04856691479217204 | validation: 0.05799821862120783]
	TIME [epoch: 5.71 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05694610582499087		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.05694610582499087 | validation: 0.06315965350094045]
	TIME [epoch: 5.71 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045072861135167085		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.045072861135167085 | validation: 0.04328654439459357]
	TIME [epoch: 5.75 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03544088338979593		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.03544088338979593 | validation: 0.05308746993682176]
	TIME [epoch: 5.71 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04280978271433741		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.04280978271433741 | validation: 0.06563448757271478]
	TIME [epoch: 5.71 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039544350719320484		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.039544350719320484 | validation: 0.04433954535455577]
	TIME [epoch: 5.71 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05159673529375418		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.05159673529375418 | validation: 0.10661907433500342]
	TIME [epoch: 5.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07468550477518733		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.07468550477518733 | validation: 0.05488074542904192]
	TIME [epoch: 5.71 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038343717259453194		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.038343717259453194 | validation: 0.04487209886262802]
	TIME [epoch: 5.73 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05952868606660717		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.05952868606660717 | validation: 0.06144248515827603]
	TIME [epoch: 5.72 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0362938728324297		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.0362938728324297 | validation: 0.0417744820392337]
	TIME [epoch: 5.71 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034205498288442035		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.034205498288442035 | validation: 0.06819692822384445]
	TIME [epoch: 5.71 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05031767571730439		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.05031767571730439 | validation: 0.048822821757628726]
	TIME [epoch: 5.71 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04810645186843552		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.04810645186843552 | validation: 0.060239264480452255]
	TIME [epoch: 5.71 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0470796473894267		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.0470796473894267 | validation: 0.048915989399951114]
	TIME [epoch: 5.71 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04356175528192796		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.04356175528192796 | validation: 0.06640718207176534]
	TIME [epoch: 5.75 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049187211304104		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.049187211304104 | validation: 0.044222846588041584]
	TIME [epoch: 5.71 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03834313425740083		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.03834313425740083 | validation: 0.055984265911960984]
	TIME [epoch: 5.71 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060602600500946666		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.060602600500946666 | validation: 0.05082760801766011]
	TIME [epoch: 5.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03772911668229164		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.03772911668229164 | validation: 0.034778962084092244]
	TIME [epoch: 5.71 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04284418904726825		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.04284418904726825 | validation: 0.0707447904236141]
	TIME [epoch: 5.71 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05223440641964913		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.05223440641964913 | validation: 0.0604423247359931]
	TIME [epoch: 5.73 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043205669535151175		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.043205669535151175 | validation: 0.050808469444694644]
	TIME [epoch: 5.72 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05626261564814593		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.05626261564814593 | validation: 0.04079808237305944]
	TIME [epoch: 5.71 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044095696012030415		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.044095696012030415 | validation: 0.06893012767045774]
	TIME [epoch: 5.7 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04673316016658978		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.04673316016658978 | validation: 0.07053307213491199]
	TIME [epoch: 5.7 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03502143648720742		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.03502143648720742 | validation: 0.04323660030623341]
	TIME [epoch: 5.71 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03670182911102769		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.03670182911102769 | validation: 0.05477207435570881]
	TIME [epoch: 5.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03863797084231813		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.03863797084231813 | validation: 0.04743592060926799]
	TIME [epoch: 5.75 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05168497399478668		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.05168497399478668 | validation: 0.06308554122688852]
	TIME [epoch: 5.71 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039333726006506906		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.039333726006506906 | validation: 0.042028104552594564]
	TIME [epoch: 5.71 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034198778704678655		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.034198778704678655 | validation: 0.07002224097640496]
	TIME [epoch: 5.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03903104273854734		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.03903104273854734 | validation: 0.05819696205078529]
	TIME [epoch: 5.71 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04096772608968648		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.04096772608968648 | validation: 0.055626724587782096]
	TIME [epoch: 5.7 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07147153342538295		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.07147153342538295 | validation: 0.08807432962202368]
	TIME [epoch: 5.72 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06292023894183343		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.06292023894183343 | validation: 0.061463517899025606]
	TIME [epoch: 5.74 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03826764761253345		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.03826764761253345 | validation: 0.02915303500760416]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_845.pth
	Model improved!!!
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035343466308041124		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.035343466308041124 | validation: 0.039558615575449756]
	TIME [epoch: 5.71 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0485281787872974		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.0485281787872974 | validation: 0.07883725499963525]
	TIME [epoch: 5.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06969544455133951		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.06969544455133951 | validation: 0.0533345645484442]
	TIME [epoch: 5.7 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038336871342511375		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.038336871342511375 | validation: 0.051961137542466694]
	TIME [epoch: 5.71 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03697159169326492		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.03697159169326492 | validation: 0.041427888142142155]
	TIME [epoch: 5.75 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041637105690606135		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.041637105690606135 | validation: 0.05931051828500952]
	TIME [epoch: 5.71 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05659752543071257		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.05659752543071257 | validation: 0.06516850961745976]
	TIME [epoch: 5.7 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05156695626180948		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.05156695626180948 | validation: 0.041444506301344414]
	TIME [epoch: 5.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03694749564938443		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.03694749564938443 | validation: 0.058224986736172185]
	TIME [epoch: 5.7 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044340511523766335		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.044340511523766335 | validation: 0.04084614649293482]
	TIME [epoch: 5.7 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042957652419620844		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.042957652419620844 | validation: 0.061689564380651554]
	TIME [epoch: 5.72 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0459781858100101		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.0459781858100101 | validation: 0.04624488233559092]
	TIME [epoch: 5.74 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04075568471140423		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.04075568471140423 | validation: 0.05107855541081339]
	TIME [epoch: 5.71 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040509161646456626		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.040509161646456626 | validation: 0.04586713923019473]
	TIME [epoch: 5.7 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04048381283803715		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.04048381283803715 | validation: 0.05945668880412396]
	TIME [epoch: 5.71 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045174517198889465		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.045174517198889465 | validation: 0.04900589875393593]
	TIME [epoch: 5.7 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03978301454463882		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.03978301454463882 | validation: 0.03450890161872846]
	TIME [epoch: 5.71 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036897036787308726		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.036897036787308726 | validation: 0.04864834657127215]
	TIME [epoch: 5.74 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038695313202830234		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.038695313202830234 | validation: 0.04466416163066786]
	TIME [epoch: 5.71 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035516381560091584		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.035516381560091584 | validation: 0.042391716819718595]
	TIME [epoch: 5.7 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03510974433166556		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.03510974433166556 | validation: 0.05009874006283768]
	TIME [epoch: 5.7 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04245914313307346		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.04245914313307346 | validation: 0.0636009244267904]
	TIME [epoch: 5.7 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05050337308402481		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.05050337308402481 | validation: 0.059634616229472734]
	TIME [epoch: 5.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058354639641295655		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.058354639641295655 | validation: 0.046763984731496226]
	TIME [epoch: 5.71 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03640796649937644		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.03640796649937644 | validation: 0.041144452977077146]
	TIME [epoch: 5.73 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034580629599262114		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.034580629599262114 | validation: 0.04594500418156905]
	TIME [epoch: 5.71 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0546704431087286		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.0546704431087286 | validation: 0.03977074904377796]
	TIME [epoch: 5.7 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0384171670675547		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.0384171670675547 | validation: 0.05213237515079348]
	TIME [epoch: 5.7 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03517389803964158		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.03517389803964158 | validation: 0.045555885677523215]
	TIME [epoch: 5.7 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05291247401534356		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.05291247401534356 | validation: 0.07504584478850242]
	TIME [epoch: 5.7 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0439256908287122		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.0439256908287122 | validation: 0.041082162710692]
	TIME [epoch: 5.74 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03816326665539789		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.03816326665539789 | validation: 0.03422830751509871]
	TIME [epoch: 5.71 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03932373508937384		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.03932373508937384 | validation: 0.041099545215812903]
	TIME [epoch: 5.7 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03940224035620446		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.03940224035620446 | validation: 0.05808437986848828]
	TIME [epoch: 5.7 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03509054039338754		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.03509054039338754 | validation: 0.04170640905515659]
	TIME [epoch: 5.7 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0316710807933995		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.0316710807933995 | validation: 0.05077870047018095]
	TIME [epoch: 5.71 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03778811282291788		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.03778811282291788 | validation: 0.059437554024365014]
	TIME [epoch: 5.71 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0438162153948084		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.0438162153948084 | validation: 0.0352372984426074]
	TIME [epoch: 5.74 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037751392567448305		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.037751392567448305 | validation: 0.05254713442485311]
	TIME [epoch: 5.7 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0532598745465728		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.0532598745465728 | validation: 0.0686063542543426]
	TIME [epoch: 5.71 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038527244222838736		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.038527244222838736 | validation: 0.041341108564032045]
	TIME [epoch: 5.7 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031077020339269054		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.031077020339269054 | validation: 0.0429893292668743]
	TIME [epoch: 5.7 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028163052605436528		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.028163052605436528 | validation: 0.05833476848682205]
	TIME [epoch: 5.7 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05716871114468057		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.05716871114468057 | validation: 0.057109914307042785]
	TIME [epoch: 5.74 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047572681636989106		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.047572681636989106 | validation: 0.05238013438617317]
	TIME [epoch: 5.71 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05328782427367211		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.05328782427367211 | validation: 0.05493933140912831]
	TIME [epoch: 5.7 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04731932742603763		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.04731932742603763 | validation: 0.04981089286991536]
	TIME [epoch: 5.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04302602435466732		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.04302602435466732 | validation: 0.04227889182309438]
	TIME [epoch: 5.7 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046421675039470804		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.046421675039470804 | validation: 0.07384704314614583]
	TIME [epoch: 5.7 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07579478621941665		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.07579478621941665 | validation: 0.03872694595005902]
	TIME [epoch: 5.71 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03432358831996524		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.03432358831996524 | validation: 0.04781752609081298]
	TIME [epoch: 5.74 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039458976150158996		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.039458976150158996 | validation: 0.055454814547500425]
	TIME [epoch: 5.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03974904577526982		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.03974904577526982 | validation: 0.041376342923947484]
	TIME [epoch: 5.71 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03670955223624337		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.03670955223624337 | validation: 0.048794590111270325]
	TIME [epoch: 5.7 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042870495881787644		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.042870495881787644 | validation: 0.06894622010592442]
	TIME [epoch: 5.7 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0447205984253839		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.0447205984253839 | validation: 0.053535109556280165]
	TIME [epoch: 5.7 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041285036048787055		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.041285036048787055 | validation: 0.04505751836459886]
	TIME [epoch: 5.73 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03422744474567892		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.03422744474567892 | validation: 0.04664132720375549]
	TIME [epoch: 5.72 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04224303764265211		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.04224303764265211 | validation: 0.03978211247718493]
	TIME [epoch: 5.7 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05176968848627865		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.05176968848627865 | validation: 0.04694420936638515]
	TIME [epoch: 5.71 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03761462749892224		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.03761462749892224 | validation: 0.04810003135599259]
	TIME [epoch: 5.7 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051061535244347825		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.051061535244347825 | validation: 0.06022696957780422]
	TIME [epoch: 5.7 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044301614532343346		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.044301614532343346 | validation: 0.04953744199681335]
	TIME [epoch: 5.7 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04505883373665916		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.04505883373665916 | validation: 0.053893835975109265]
	TIME [epoch: 5.74 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04087316402148092		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.04087316402148092 | validation: 0.055769383232903584]
	TIME [epoch: 5.71 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03860788961011717		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.03860788961011717 | validation: 0.050322165417906656]
	TIME [epoch: 5.7 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043006194989413944		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.043006194989413944 | validation: 0.04980206592975046]
	TIME [epoch: 5.7 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0452006298907021		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.0452006298907021 | validation: 0.05037757669248065]
	TIME [epoch: 5.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042974230621656485		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.042974230621656485 | validation: 0.048325878132825906]
	TIME [epoch: 5.7 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039071464048441		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.039071464048441 | validation: 0.07241576405606603]
	TIME [epoch: 5.73 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051633126869357546		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.051633126869357546 | validation: 0.04487122684858926]
	TIME [epoch: 5.72 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04649274886394604		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.04649274886394604 | validation: 0.08823229319408853]
	TIME [epoch: 5.71 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07100203355292144		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.07100203355292144 | validation: 0.059350975804099405]
	TIME [epoch: 5.7 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05009441730635187		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.05009441730635187 | validation: 0.05903315341204934]
	TIME [epoch: 5.7 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049210975341186056		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.049210975341186056 | validation: 0.049755101350546456]
	TIME [epoch: 5.7 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0442016687957192		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.0442016687957192 | validation: 0.041415660924693766]
	TIME [epoch: 5.7 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037005904777853565		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.037005904777853565 | validation: 0.042948486670305944]
	TIME [epoch: 5.75 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036229773798787696		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.036229773798787696 | validation: 0.0475999180938199]
	TIME [epoch: 5.71 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032491663790006384		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.032491663790006384 | validation: 0.04158342600656319]
	TIME [epoch: 5.7 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03474544749064186		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.03474544749064186 | validation: 0.05024610306120064]
	TIME [epoch: 5.7 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034628460051940604		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.034628460051940604 | validation: 0.043068096294381145]
	TIME [epoch: 5.7 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036027374443166844		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.036027374443166844 | validation: 0.04628539186186289]
	TIME [epoch: 5.7 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03939774912847897		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.03939774912847897 | validation: 0.037904844796873796]
	TIME [epoch: 5.73 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03841590477335362		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.03841590477335362 | validation: 0.049547508689946715]
	TIME [epoch: 5.72 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04763915094211119		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.04763915094211119 | validation: 0.030573677305602575]
	TIME [epoch: 5.71 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028334823084431065		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.028334823084431065 | validation: 0.03796412074928235]
	TIME [epoch: 5.7 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036779418659796365		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.036779418659796365 | validation: 0.04303608564117294]
	TIME [epoch: 5.7 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04024406334962443		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.04024406334962443 | validation: 0.054960880952858705]
	TIME [epoch: 5.7 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04274890416578603		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.04274890416578603 | validation: 0.044214840781950024]
	TIME [epoch: 5.7 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043006831207596505		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.043006831207596505 | validation: 0.056474865739977106]
	TIME [epoch: 5.74 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04914207898993481		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.04914207898993481 | validation: 0.05062600923723608]
	TIME [epoch: 5.7 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03534315919900671		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.03534315919900671 | validation: 0.04782174092301244]
	TIME [epoch: 5.7 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03250011549372379		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.03250011549372379 | validation: 0.040351640573168236]
	TIME [epoch: 5.7 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04018774539993274		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.04018774539993274 | validation: 0.03770027321793584]
	TIME [epoch: 5.7 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03470660917332775		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.03470660917332775 | validation: 0.031768439091953225]
	TIME [epoch: 5.7 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0322714002597813		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.0322714002597813 | validation: 0.05523985879267967]
	TIME [epoch: 5.71 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04614352202283725		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.04614352202283725 | validation: 0.036302966207820545]
	TIME [epoch: 5.74 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03235576641506906		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.03235576641506906 | validation: 0.03629952511300998]
	TIME [epoch: 5.7 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03281507658041425		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.03281507658041425 | validation: 0.04186685629810903]
	TIME [epoch: 5.7 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03405979284965166		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.03405979284965166 | validation: 0.04399756637475059]
	TIME [epoch: 5.7 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0355247216302431		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.0355247216302431 | validation: 0.03913674821319323]
	TIME [epoch: 5.7 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031629361903172434		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.031629361903172434 | validation: 0.04534877950632566]
	TIME [epoch: 5.7 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03082989660550848		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.03082989660550848 | validation: 0.04596448363166717]
	TIME [epoch: 5.74 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032549163567272735		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.032549163567272735 | validation: 0.03696809175295355]
	TIME [epoch: 5.71 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03093632526277334		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.03093632526277334 | validation: 0.0475571820929839]
	TIME [epoch: 5.7 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0330593067917555		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.0330593067917555 | validation: 0.04348503230315804]
	TIME [epoch: 5.7 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042759596247456774		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.042759596247456774 | validation: 0.040557656113087585]
	TIME [epoch: 5.7 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03310651848045094		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.03310651848045094 | validation: 0.046538970152921015]
	TIME [epoch: 5.7 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03614731961351387		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.03614731961351387 | validation: 0.03849420260145284]
	TIME [epoch: 5.71 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03148215497392618		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.03148215497392618 | validation: 0.04269400531975457]
	TIME [epoch: 5.73 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03181707650976674		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.03181707650976674 | validation: 0.04408765727731794]
	TIME [epoch: 5.7 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02986423016924887		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.02986423016924887 | validation: 0.03363071510705602]
	TIME [epoch: 5.7 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02466581306356564		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.02466581306356564 | validation: 0.03994455030884657]
	TIME [epoch: 5.7 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030851304252176744		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.030851304252176744 | validation: 0.044407778192338654]
	TIME [epoch: 5.7 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03658859794870374		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.03658859794870374 | validation: 0.045695318658165236]
	TIME [epoch: 5.7 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03286382697074774		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.03286382697074774 | validation: 0.029249720248961806]
	TIME [epoch: 5.74 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03010329815899948		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.03010329815899948 | validation: 0.03772060715535246]
	TIME [epoch: 5.71 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031172737020847153		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.031172737020847153 | validation: 0.05774004833691357]
	TIME [epoch: 5.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04510170158427188		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.04510170158427188 | validation: 0.039845614021681616]
	TIME [epoch: 5.7 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03417225577636853		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.03417225577636853 | validation: 0.04878622779118402]
	TIME [epoch: 5.7 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03558819701871099		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.03558819701871099 | validation: 0.038343734821924866]
	TIME [epoch: 5.7 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026302709883789903		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.026302709883789903 | validation: 0.043497011341180336]
	TIME [epoch: 5.71 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0339409785550797		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.0339409785550797 | validation: 0.04353578483907928]
	TIME [epoch: 5.73 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03766088824556521		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.03766088824556521 | validation: 0.07196013144514572]
	TIME [epoch: 5.7 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06365757426207867		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.06365757426207867 | validation: 0.04705555395488666]
	TIME [epoch: 5.7 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040060505192121676		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.040060505192121676 | validation: 0.04675112534031246]
	TIME [epoch: 5.7 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028359853564051914		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.028359853564051914 | validation: 0.048247499651811396]
	TIME [epoch: 5.7 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03509764934186162		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.03509764934186162 | validation: 0.05556052806780345]
	TIME [epoch: 5.7 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036169127914892456		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.036169127914892456 | validation: 0.04016861354010206]
	TIME [epoch: 5.74 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028345634510850204		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.028345634510850204 | validation: 0.03599352312205439]
	TIME [epoch: 5.71 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03750853229214809		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.03750853229214809 | validation: 0.03930081577928982]
	TIME [epoch: 5.7 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038743614518018714		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.038743614518018714 | validation: 0.04352946988037521]
	TIME [epoch: 5.7 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043362346515330843		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.043362346515330843 | validation: 0.057690847014354174]
	TIME [epoch: 5.7 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048470123111030355		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.048470123111030355 | validation: 0.04615860005908323]
	TIME [epoch: 5.7 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03977523497961048		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.03977523497961048 | validation: 0.045054326359039]
	TIME [epoch: 5.71 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03609644079221092		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.03609644079221092 | validation: 0.044531163557379516]
	TIME [epoch: 5.74 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04358923228591256		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.04358923228591256 | validation: 0.047454525903902686]
	TIME [epoch: 5.71 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03713916293626566		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.03713916293626566 | validation: 0.0651578658474547]
	TIME [epoch: 5.71 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04227243232151481		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.04227243232151481 | validation: 0.049515810309121236]
	TIME [epoch: 5.7 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028297943082269753		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.028297943082269753 | validation: 0.03800843561330471]
	TIME [epoch: 5.7 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030093331368952033		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.030093331368952033 | validation: 0.037580592448333984]
	TIME [epoch: 5.71 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03188601784363352		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.03188601784363352 | validation: 0.042442269455409375]
	TIME [epoch: 5.73 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028362079443102345		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.028362079443102345 | validation: 0.04129039803472203]
	TIME [epoch: 5.72 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03359085531695271		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.03359085531695271 | validation: 0.04471008535905628]
	TIME [epoch: 5.71 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03664194842736922		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.03664194842736922 | validation: 0.04766410038000126]
	TIME [epoch: 5.71 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04206981468433513		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.04206981468433513 | validation: 0.04404076308023948]
	TIME [epoch: 5.7 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036549616460513384		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.036549616460513384 | validation: 0.0519410708317067]
	TIME [epoch: 5.7 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043324206306072865		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.043324206306072865 | validation: 0.03827926746051736]
	TIME [epoch: 5.7 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037787855178918583		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.037787855178918583 | validation: 0.04785902632232927]
	TIME [epoch: 5.75 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035602454086861524		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.035602454086861524 | validation: 0.04014094972928737]
	TIME [epoch: 5.71 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0370288667333411		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.0370288667333411 | validation: 0.05009656895350817]
	TIME [epoch: 5.7 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04287490996493232		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.04287490996493232 | validation: 0.05419429940232525]
	TIME [epoch: 5.7 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05049636169284575		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.05049636169284575 | validation: 0.03842234806071849]
	TIME [epoch: 5.7 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032302170836999294		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.032302170836999294 | validation: 0.034571466850539675]
	TIME [epoch: 5.7 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04202393116707655		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.04202393116707655 | validation: 0.06774655362826851]
	TIME [epoch: 5.73 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038475808101987696		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.038475808101987696 | validation: 0.03677166717462229]
	TIME [epoch: 5.72 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029291512841064196		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.029291512841064196 | validation: 0.03310640927875436]
	TIME [epoch: 5.71 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02975603582518877		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.02975603582518877 | validation: 0.048281415242868685]
	TIME [epoch: 5.71 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040300256190903445		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.040300256190903445 | validation: 0.04874677476004043]
	TIME [epoch: 5.7 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04717302340168776		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.04717302340168776 | validation: 0.04787655664668769]
	TIME [epoch: 5.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039443928827799644		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.039443928827799644 | validation: 0.04484554636856597]
	TIME [epoch: 5.7 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03441881445546993		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.03441881445546993 | validation: 0.0610172239442824]
	TIME [epoch: 5.75 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03802937809821376		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.03802937809821376 | validation: 0.0428563906530506]
	TIME [epoch: 5.71 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041171173984841686		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.041171173984841686 | validation: 0.03866904773828719]
	TIME [epoch: 5.7 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03638756531344412		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.03638756531344412 | validation: 0.0579127450326537]
	TIME [epoch: 5.7 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0460180899029289		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.0460180899029289 | validation: 0.043216362978692885]
	TIME [epoch: 5.7 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04283934752835614		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.04283934752835614 | validation: 0.054424589501772744]
	TIME [epoch: 5.7 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047080830213249054		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.047080830213249054 | validation: 0.04318800079272924]
	TIME [epoch: 5.73 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04660010795337893		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.04660010795337893 | validation: 0.05955058586453793]
	TIME [epoch: 5.72 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03731251500308415		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.03731251500308415 | validation: 0.03413849326214963]
	TIME [epoch: 5.71 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0353247418829928		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.0353247418829928 | validation: 0.044884442844667624]
	TIME [epoch: 5.7 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03484804814237506		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.03484804814237506 | validation: 0.03932113491289103]
	TIME [epoch: 5.7 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02861415187758368		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.02861415187758368 | validation: 0.03622466677279382]
	TIME [epoch: 5.7 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02847586238778321		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.02847586238778321 | validation: 0.04429733655999526]
	TIME [epoch: 5.7 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032748920388909836		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.032748920388909836 | validation: 0.04053491623752027]
	TIME [epoch: 5.75 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03474785548342446		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.03474785548342446 | validation: 0.04976589678917298]
	TIME [epoch: 5.7 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03281824249347323		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.03281824249347323 | validation: 0.03732678646455003]
	TIME [epoch: 5.7 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03620927355393792		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.03620927355393792 | validation: 0.0496477498375944]
	TIME [epoch: 5.7 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02995423550412518		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.02995423550412518 | validation: 0.03498155561097626]
	TIME [epoch: 5.7 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027239371529426668		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.027239371529426668 | validation: 0.04095932244442556]
	TIME [epoch: 5.7 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031133012351935233		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.031133012351935233 | validation: 0.02731284198718264]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_1026.pth
	Model improved!!!
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027849647875826007		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.027849647875826007 | validation: 0.03430135337066838]
	TIME [epoch: 5.72 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03115445230546228		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.03115445230546228 | validation: 0.041372964710706235]
	TIME [epoch: 5.7 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029849874061298402		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.029849874061298402 | validation: 0.03318533435437112]
	TIME [epoch: 5.7 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03331267292491918		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.03331267292491918 | validation: 0.03812206535996542]
	TIME [epoch: 5.7 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030255031919802652		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.030255031919802652 | validation: 0.03522556227176972]
	TIME [epoch: 5.7 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02812445957561066		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.02812445957561066 | validation: 0.042171676266252435]
	TIME [epoch: 5.7 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05299584018913989		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.05299584018913989 | validation: 0.05712648201555829]
	TIME [epoch: 5.74 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043685877845709896		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.043685877845709896 | validation: 0.04513929571815042]
	TIME [epoch: 5.71 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02851501620855989		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.02851501620855989 | validation: 0.030541319305449986]
	TIME [epoch: 5.7 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03625377677866624		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.03625377677866624 | validation: 0.04400350883890135]
	TIME [epoch: 5.7 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025333424881977658		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.025333424881977658 | validation: 0.03656168674860656]
	TIME [epoch: 5.7 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02879286258997205		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.02879286258997205 | validation: 0.04626532734885647]
	TIME [epoch: 5.7 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03787026090968608		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.03787026090968608 | validation: 0.044288525688690863]
	TIME [epoch: 5.73 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032902901338436145		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.032902901338436145 | validation: 0.03422561257839704]
	TIME [epoch: 5.72 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027145152858733597		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.027145152858733597 | validation: 0.03370775171857468]
	TIME [epoch: 5.7 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026569568887011834		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.026569568887011834 | validation: 0.03542104952119865]
	TIME [epoch: 5.7 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031199912348062284		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.031199912348062284 | validation: 0.03934407880455269]
	TIME [epoch: 5.7 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024213927658597735		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.024213927658597735 | validation: 0.04287893040673806]
	TIME [epoch: 5.7 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028428351796640175		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.028428351796640175 | validation: 0.03609971889599369]
	TIME [epoch: 5.7 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04231436631237773		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.04231436631237773 | validation: 0.05245336491867377]
	TIME [epoch: 5.74 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0499984139667961		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.0499984139667961 | validation: 0.0524035710904935]
	TIME [epoch: 5.71 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037868749452752225		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.037868749452752225 | validation: 0.044598447928241934]
	TIME [epoch: 5.7 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03060296412077528		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.03060296412077528 | validation: 0.03966947304015688]
	TIME [epoch: 5.7 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02834473633983519		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.02834473633983519 | validation: 0.031186996063664464]
	TIME [epoch: 5.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03104462374383805		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.03104462374383805 | validation: 0.03682618770650188]
	TIME [epoch: 5.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033155167859815905		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.033155167859815905 | validation: 0.03717793300377142]
	TIME [epoch: 5.71 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027183133974452277		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.027183133974452277 | validation: 0.035622106818519614]
	TIME [epoch: 5.73 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027070177168878513		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.027070177168878513 | validation: 0.03389580846081645]
	TIME [epoch: 5.7 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028203655520482623		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.028203655520482623 | validation: 0.04031259960896017]
	TIME [epoch: 5.7 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028846216832077783		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.028846216832077783 | validation: 0.03559154323818158]
	TIME [epoch: 5.7 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03196160512574253		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.03196160512574253 | validation: 0.04758158295593867]
	TIME [epoch: 5.7 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03676367716584961		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.03676367716584961 | validation: 0.03694819484682431]
	TIME [epoch: 5.7 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033143954850459734		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.033143954850459734 | validation: 0.03800386542345247]
	TIME [epoch: 5.74 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03316776319528644		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.03316776319528644 | validation: 0.04556962575498246]
	TIME [epoch: 5.71 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03676014260209792		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.03676014260209792 | validation: 0.06595589768358194]
	TIME [epoch: 5.7 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05905916688381082		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.05905916688381082 | validation: 0.03964265460951267]
	TIME [epoch: 5.7 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032586182122011885		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.032586182122011885 | validation: 0.0387638102924585]
	TIME [epoch: 5.7 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036622999557390366		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.036622999557390366 | validation: 0.03755190548508074]
	TIME [epoch: 5.7 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027782702556891158		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.027782702556891158 | validation: 0.0384384916838134]
	TIME [epoch: 5.71 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026584364220888744		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.026584364220888744 | validation: 0.03710460693861297]
	TIME [epoch: 5.73 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02789574926109522		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.02789574926109522 | validation: 0.04107224424094658]
	TIME [epoch: 5.7 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027732620261046892		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.027732620261046892 | validation: 0.036790768362385866]
	TIME [epoch: 5.7 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02646130778115518		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.02646130778115518 | validation: 0.032329096079258414]
	TIME [epoch: 5.7 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0357087433958732		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.0357087433958732 | validation: 0.03461841793769927]
	TIME [epoch: 5.7 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03385740532474957		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.03385740532474957 | validation: 0.04960585781971753]
	TIME [epoch: 5.7 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03240404443528547		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.03240404443528547 | validation: 0.04329290715302786]
	TIME [epoch: 5.74 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027738004105786484		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.027738004105786484 | validation: 0.03816268751613317]
	TIME [epoch: 5.7 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025812532894786022		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.025812532894786022 | validation: 0.039057900673651794]
	TIME [epoch: 5.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025540090105926484		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.025540090105926484 | validation: 0.036438879790872]
	TIME [epoch: 5.7 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024592208441796725		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.024592208441796725 | validation: 0.03536207964177679]
	TIME [epoch: 5.7 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02766891818542569		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.02766891818542569 | validation: 0.04887967828329421]
	TIME [epoch: 5.7 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03214469699012155		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.03214469699012155 | validation: 0.03734608675402712]
	TIME [epoch: 5.71 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02613004266046203		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.02613004266046203 | validation: 0.03562972927945715]
	TIME [epoch: 5.73 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029190013355784337		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.029190013355784337 | validation: 0.03811786908458822]
	TIME [epoch: 5.7 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02979813830859556		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.02979813830859556 | validation: 0.052952459898130286]
	TIME [epoch: 5.7 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03973499058977745		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.03973499058977745 | validation: 0.047591938266126864]
	TIME [epoch: 5.7 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039155007332675115		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.039155007332675115 | validation: 0.04506887554215705]
	TIME [epoch: 5.7 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03271680224387567		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.03271680224387567 | validation: 0.050024682065960065]
	TIME [epoch: 5.7 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03566751504038437		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.03566751504038437 | validation: 0.0408549828483614]
	TIME [epoch: 5.74 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03288074276533741		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.03288074276533741 | validation: 0.04310187963740163]
	TIME [epoch: 5.71 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03217067544698301		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.03217067544698301 | validation: 0.04174201145110198]
	TIME [epoch: 5.7 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03175033462538246		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.03175033462538246 | validation: 0.0397311353691887]
	TIME [epoch: 5.7 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029842838847530334		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.029842838847530334 | validation: 0.03566196949111721]
	TIME [epoch: 5.7 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032134983852035955		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.032134983852035955 | validation: 0.0402320445013588]
	TIME [epoch: 5.7 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032992633187498205		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.032992633187498205 | validation: 0.05070934211280423]
	TIME [epoch: 5.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0357846064037143		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.0357846064037143 | validation: 0.040794214605630694]
	TIME [epoch: 5.74 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03283026268603824		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.03283026268603824 | validation: 0.03653453081541949]
	TIME [epoch: 5.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028492500487928386		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.028492500487928386 | validation: 0.040413762216718475]
	TIME [epoch: 5.7 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029252582870580635		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.029252582870580635 | validation: 0.0472868255883124]
	TIME [epoch: 5.7 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05850808289134467		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.05850808289134467 | validation: 0.07051819249006852]
	TIME [epoch: 5.7 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06300601637990202		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.06300601637990202 | validation: 0.04107588514175692]
	TIME [epoch: 5.7 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03747702011906706		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.03747702011906706 | validation: 0.03630710648390271]
	TIME [epoch: 5.73 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029955838086378955		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.029955838086378955 | validation: 0.04163671872653257]
	TIME [epoch: 5.72 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032024320652958675		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.032024320652958675 | validation: 0.043688725658117974]
	TIME [epoch: 5.7 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031683130756517186		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.031683130756517186 | validation: 0.032088559073182844]
	TIME [epoch: 5.7 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02680507556767294		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.02680507556767294 | validation: 0.03606305747512625]
	TIME [epoch: 5.7 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025428102115554612		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.025428102115554612 | validation: 0.04139457503067178]
	TIME [epoch: 5.7 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03340979555799281		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.03340979555799281 | validation: 0.035494120403798436]
	TIME [epoch: 5.7 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033774580865423016		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.033774580865423016 | validation: 0.04259037594839924]
	TIME [epoch: 5.74 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032905208528751416		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.032905208528751416 | validation: 0.040222738733526275]
	TIME [epoch: 5.7 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03290874931315412		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.03290874931315412 | validation: 0.046904841787994866]
	TIME [epoch: 5.7 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02854894195049246		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.02854894195049246 | validation: 0.03347770889761634]
	TIME [epoch: 5.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023038174674789552		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.023038174674789552 | validation: 0.03526446000788203]
	TIME [epoch: 5.7 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031982607331659835		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.031982607331659835 | validation: 0.04265805251771981]
	TIME [epoch: 5.7 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029658440932954257		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.029658440932954257 | validation: 0.040347793448044664]
	TIME [epoch: 5.73 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03180416061475922		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.03180416061475922 | validation: 0.03614137829495357]
	TIME [epoch: 5.72 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023880900015081266		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.023880900015081266 | validation: 0.03425530340884591]
	TIME [epoch: 5.7 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029081571640993512		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.029081571640993512 | validation: 0.03804026485996156]
	TIME [epoch: 5.7 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02862383827299249		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.02862383827299249 | validation: 0.035035264227416145]
	TIME [epoch: 5.7 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028918606794107574		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.028918606794107574 | validation: 0.03525013338205127]
	TIME [epoch: 5.7 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03038730745351078		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.03038730745351078 | validation: 0.03810616733639151]
	TIME [epoch: 5.7 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030942379801437304		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.030942379801437304 | validation: 0.03414036598276256]
	TIME [epoch: 5.74 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024884161090319566		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.024884161090319566 | validation: 0.03168407563934572]
	TIME [epoch: 5.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03256652116913023		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.03256652116913023 | validation: 0.05117322192408965]
	TIME [epoch: 5.7 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04224397656219134		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.04224397656219134 | validation: 0.05803760514208282]
	TIME [epoch: 5.7 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04402929089613852		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.04402929089613852 | validation: 0.035184833818033986]
	TIME [epoch: 5.7 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030245331378666515		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.030245331378666515 | validation: 0.046146926898965386]
	TIME [epoch: 5.7 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03499251867391327		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.03499251867391327 | validation: 0.03778568338461134]
	TIME [epoch: 5.73 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029626769745777888		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.029626769745777888 | validation: 0.038447290917462705]
	TIME [epoch: 5.72 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03370364649603854		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.03370364649603854 | validation: 0.03632713261954092]
	TIME [epoch: 5.7 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03255555202807077		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.03255555202807077 | validation: 0.042777453612408964]
	TIME [epoch: 5.7 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02447310869082808		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.02447310869082808 | validation: 0.039087501171310664]
	TIME [epoch: 5.7 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027005589495055264		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.027005589495055264 | validation: 0.02362594807541754]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_1129.pth
	Model improved!!!
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024004649470652208		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.024004649470652208 | validation: 0.03968791364486667]
	TIME [epoch: 5.7 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026778794155903278		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.026778794155903278 | validation: 0.04409917795765358]
	TIME [epoch: 5.74 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025650749309269912		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.025650749309269912 | validation: 0.03772911725229161]
	TIME [epoch: 5.7 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032661260849173035		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.032661260849173035 | validation: 0.03934294381741279]
	TIME [epoch: 5.7 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025651099728262756		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.025651099728262756 | validation: 0.030611283085099028]
	TIME [epoch: 5.7 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02685946117011406		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.02685946117011406 | validation: 0.034540361553582456]
	TIME [epoch: 5.7 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027516908038380736		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.027516908038380736 | validation: 0.035899040625929274]
	TIME [epoch: 5.7 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031047025657046673		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.031047025657046673 | validation: 0.03773198379510388]
	TIME [epoch: 5.72 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0288862309881326		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.0288862309881326 | validation: 0.031104794093532413]
	TIME [epoch: 5.72 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027903159773518142		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.027903159773518142 | validation: 0.04366522446253935]
	TIME [epoch: 5.7 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028970484125680394		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.028970484125680394 | validation: 0.03423760436383344]
	TIME [epoch: 5.7 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029726717421383282		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.029726717421383282 | validation: 0.03868459007193911]
	TIME [epoch: 5.7 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03639550022056756		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.03639550022056756 | validation: 0.040620462361346046]
	TIME [epoch: 5.7 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03322367152963178		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.03322367152963178 | validation: 0.034883986618522135]
	TIME [epoch: 5.7 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03633060421810231		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.03633060421810231 | validation: 0.0482496176928776]
	TIME [epoch: 5.74 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050485183203272166		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.050485183203272166 | validation: 0.05923634846229203]
	TIME [epoch: 5.7 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04811359063459329		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.04811359063459329 | validation: 0.04191348412708109]
	TIME [epoch: 5.7 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03157687922824679		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.03157687922824679 | validation: 0.05076735993892905]
	TIME [epoch: 5.7 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03391885596243734		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.03391885596243734 | validation: 0.04369911545785736]
	TIME [epoch: 5.7 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025826197479921244		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.025826197479921244 | validation: 0.028894322669640315]
	TIME [epoch: 5.7 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02807571120183495		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.02807571120183495 | validation: 0.035798450640440856]
	TIME [epoch: 5.72 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027210319153808726		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.027210319153808726 | validation: 0.034451446502490816]
	TIME [epoch: 5.72 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025797883973001763		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.025797883973001763 | validation: 0.029475278544233756]
	TIME [epoch: 5.7 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02524737553908864		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.02524737553908864 | validation: 0.03213956421917443]
	TIME [epoch: 5.7 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02856078782660601		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.02856078782660601 | validation: 0.04075255192095767]
	TIME [epoch: 5.7 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028364831730649024		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.028364831730649024 | validation: 0.034618321767115684]
	TIME [epoch: 5.7 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028510482940287987		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.028510482940287987 | validation: 0.03466450509918296]
	TIME [epoch: 5.7 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033455203668594446		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.033455203668594446 | validation: 0.05427486127872839]
	TIME [epoch: 5.74 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03899380499551968		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.03899380499551968 | validation: 0.05805414642245214]
	TIME [epoch: 5.7 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03877732941073669		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.03877732941073669 | validation: 0.03457113678677775]
	TIME [epoch: 5.7 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028938695416961684		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.028938695416961684 | validation: 0.03937045627293772]
	TIME [epoch: 5.7 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03167911469653752		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.03167911469653752 | validation: 0.04314735332335433]
	TIME [epoch: 5.7 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034872105411580756		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.034872105411580756 | validation: 0.03730591557081411]
	TIME [epoch: 5.7 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026920832534397882		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.026920832534397882 | validation: 0.03625912170258506]
	TIME [epoch: 5.71 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030624417690660474		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.030624417690660474 | validation: 0.04211447218281011]
	TIME [epoch: 5.73 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03285673018976736		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.03285673018976736 | validation: 0.04213653478534665]
	TIME [epoch: 5.7 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03087809715189676		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.03087809715189676 | validation: 0.035411795415008905]
	TIME [epoch: 5.7 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022605920575497315		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.022605920575497315 | validation: 0.036382151176672074]
	TIME [epoch: 5.7 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024513339757750194		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.024513339757750194 | validation: 0.03927996001107786]
	TIME [epoch: 5.7 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027649524165821074		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.027649524165821074 | validation: 0.034510001210629034]
	TIME [epoch: 5.7 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03319619852793887		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.03319619852793887 | validation: 0.03115457230495232]
	TIME [epoch: 5.74 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02336809298565367		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.02336809298565367 | validation: 0.039108625093960694]
	TIME [epoch: 5.71 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02777941313431326		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.02777941313431326 | validation: 0.02539650290526241]
	TIME [epoch: 5.7 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02704887867255821		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.02704887867255821 | validation: 0.041010729742219816]
	TIME [epoch: 5.7 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03532804446395893		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.03532804446395893 | validation: 0.03848295882054251]
	TIME [epoch: 5.7 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03235689796417905		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.03235689796417905 | validation: 0.040923696847015016]
	TIME [epoch: 5.7 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028451351795491124		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.028451351795491124 | validation: 0.03569465525669632]
	TIME [epoch: 5.71 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030950142991979804		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.030950142991979804 | validation: 0.03737965683539478]
	TIME [epoch: 5.73 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02938660061853053		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.02938660061853053 | validation: 0.03465307910893708]
	TIME [epoch: 5.7 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02344774637256296		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.02344774637256296 | validation: 0.03860725458859495]
	TIME [epoch: 5.7 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030802744668443127		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.030802744668443127 | validation: 0.04652744695146389]
	TIME [epoch: 5.7 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03747980073458229		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.03747980073458229 | validation: 0.04348276582320302]
	TIME [epoch: 5.7 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027726091113747842		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.027726091113747842 | validation: 0.039713877333208004]
	TIME [epoch: 5.7 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02764427812341281		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.02764427812341281 | validation: 0.04453844328864105]
	TIME [epoch: 5.74 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03259520410570986		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.03259520410570986 | validation: 0.03365319591126535]
	TIME [epoch: 5.7 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0303942046667684		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.0303942046667684 | validation: 0.031441794063140696]
	TIME [epoch: 5.7 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028134221622607918		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.028134221622607918 | validation: 0.03592805691790078]
	TIME [epoch: 5.7 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032719240238129894		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.032719240238129894 | validation: 0.04062905175936408]
	TIME [epoch: 5.7 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031010259592537802		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.031010259592537802 | validation: 0.04122946400784531]
	TIME [epoch: 5.7 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02993163683936273		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.02993163683936273 | validation: 0.03828226098922832]
	TIME [epoch: 5.71 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028693910381218414		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.028693910381218414 | validation: 0.0339895172240082]
	TIME [epoch: 5.73 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029296489771485027		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.029296489771485027 | validation: 0.04543010669154333]
	TIME [epoch: 5.7 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030582775348642368		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.030582775348642368 | validation: 0.03147598890997493]
	TIME [epoch: 5.7 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029117832364484772		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.029117832364484772 | validation: 0.05328293836278018]
	TIME [epoch: 5.7 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03260906575953669		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.03260906575953669 | validation: 0.032249995754754845]
	TIME [epoch: 5.7 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02633609264062213		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.02633609264062213 | validation: 0.03922072654966803]
	TIME [epoch: 5.7 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024235549290170497		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.024235549290170497 | validation: 0.03229202772153554]
	TIME [epoch: 5.74 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027011608018872372		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.027011608018872372 | validation: 0.053932021317189716]
	TIME [epoch: 5.7 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027241109920141813		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.027241109920141813 | validation: 0.03749789704593918]
	TIME [epoch: 5.7 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028784048139028757		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.028784048139028757 | validation: 0.0324482445531526]
	TIME [epoch: 5.7 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034165489202438955		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.034165489202438955 | validation: 0.039157023540090846]
	TIME [epoch: 5.7 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02716149102061119		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.02716149102061119 | validation: 0.03896714357026306]
	TIME [epoch: 5.7 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024133929736309023		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.024133929736309023 | validation: 0.032440334412180284]
	TIME [epoch: 5.71 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02789294653850101		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.02789294653850101 | validation: 0.03612818186814627]
	TIME [epoch: 5.73 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026536493313930737		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.026536493313930737 | validation: 0.030746641765366577]
	TIME [epoch: 5.7 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02756763210490029		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.02756763210490029 | validation: 0.03093181157760875]
	TIME [epoch: 5.7 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03663448073172224		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.03663448073172224 | validation: 0.042696249159308676]
	TIME [epoch: 5.7 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03357581398776052		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.03357581398776052 | validation: 0.037956320839570956]
	TIME [epoch: 5.7 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03329808331057009		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.03329808331057009 | validation: 0.03938792190396234]
	TIME [epoch: 5.7 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036764557090682395		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.036764557090682395 | validation: 0.036510225947041036]
	TIME [epoch: 5.74 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025638504853989195		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.025638504853989195 | validation: 0.0322939309586414]
	TIME [epoch: 5.71 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026720176516490474		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.026720176516490474 | validation: 0.03199042614279231]
	TIME [epoch: 5.7 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022518146830544324		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.022518146830544324 | validation: 0.03522925443343069]
	TIME [epoch: 5.7 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024926441225723045		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.024926441225723045 | validation: 0.043884775263963]
	TIME [epoch: 5.7 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020224515298710867		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.020224515298710867 | validation: 0.044044535041014236]
	TIME [epoch: 5.7 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02784085695655995		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.02784085695655995 | validation: 0.0211513601831005]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240310_003030/states/model_tr_study2_1215.pth
	Model improved!!!
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02598058304469648		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.02598058304469648 | validation: 0.033146014524434435]
	TIME [epoch: 5.73 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032598733767807614		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.032598733767807614 | validation: 0.036949589410923814]
	TIME [epoch: 5.7 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03192059208225766		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.03192059208225766 | validation: 0.04199038207879892]
	TIME [epoch: 5.7 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027126248053475275		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.027126248053475275 | validation: 0.037580068760745]
	TIME [epoch: 5.7 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027335878849942586		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.027335878849942586 | validation: 0.03920350167119027]
	TIME [epoch: 5.7 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03064138285264467		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.03064138285264467 | validation: 0.029180145536956657]
	TIME [epoch: 5.7 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02698409915165214		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.02698409915165214 | validation: 0.03828421398883238]
	TIME [epoch: 5.74 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02466083543718077		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.02466083543718077 | validation: 0.03339087626185124]
	TIME [epoch: 5.71 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02531496456286315		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.02531496456286315 | validation: 0.04418322993194562]
	TIME [epoch: 5.7 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029680206323383203		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.029680206323383203 | validation: 0.03898009805720866]
	TIME [epoch: 5.7 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02630327950092652		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.02630327950092652 | validation: 0.04405330049267158]
	TIME [epoch: 5.7 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02772371451761952		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.02772371451761952 | validation: 0.03885920616934348]
	TIME [epoch: 5.7 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026185151997023204		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.026185151997023204 | validation: 0.035293282150368026]
	TIME [epoch: 5.71 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032202184970442985		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.032202184970442985 | validation: 0.04029110183994803]
	TIME [epoch: 5.73 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029541649322066346		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.029541649322066346 | validation: 0.03365898520562143]
	TIME [epoch: 5.7 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02375906182368792		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.02375906182368792 | validation: 0.03635931573607548]
	TIME [epoch: 5.7 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02821304326187505		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.02821304326187505 | validation: 0.04124674290600696]
	TIME [epoch: 5.7 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030312720067055016		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.030312720067055016 | validation: 0.04050147951018845]
	TIME [epoch: 5.7 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029446010705334334		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.029446010705334334 | validation: 0.029951086788492853]
	TIME [epoch: 5.7 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02886528928488321		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.02886528928488321 | validation: 0.033298820137912]
	TIME [epoch: 5.74 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026349659984502234		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.026349659984502234 | validation: 0.03297551492578672]
	TIME [epoch: 5.7 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028631440213707587		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.028631440213707587 | validation: 0.035766339273472586]
	TIME [epoch: 5.7 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023736805310843746		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.023736805310843746 | validation: 0.037367036805794264]
	TIME [epoch: 5.7 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029619747597596734		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.029619747597596734 | validation: 0.03500189052091941]
	TIME [epoch: 5.7 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026036172878748317		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.026036172878748317 | validation: 0.02809777395955253]
	TIME [epoch: 5.7 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024410511888905667		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.024410511888905667 | validation: 0.027962263827789526]
	TIME [epoch: 5.71 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02922087030943626		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.02922087030943626 | validation: 0.026436635996773195]
	TIME [epoch: 5.73 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030963089186031918		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.030963089186031918 | validation: 0.030093667102954528]
	TIME [epoch: 5.7 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024094480493831328		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.024094480493831328 | validation: 0.034971205621450036]
	TIME [epoch: 5.7 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023663543047514245		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.023663543047514245 | validation: 0.025796639741840082]
	TIME [epoch: 5.7 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024979810513637644		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.024979810513637644 | validation: 0.036162766812612254]
	TIME [epoch: 5.7 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026939790075014756		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.026939790075014756 | validation: 0.033301148440519554]
	TIME [epoch: 5.7 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027080657077752417		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.027080657077752417 | validation: 0.03783807033689173]
	TIME [epoch: 5.73 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023955009359118346		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.023955009359118346 | validation: 0.03746775679062319]
	TIME [epoch: 5.71 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023262962061870177		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.023262962061870177 | validation: 0.0321999163577246]
	TIME [epoch: 5.7 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026155331178620816		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.026155331178620816 | validation: 0.04094044289695628]
	TIME [epoch: 5.7 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025397483547907		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.025397483547907 | validation: 0.034948317698635344]
	TIME [epoch: 5.7 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02851382263906363		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.02851382263906363 | validation: 0.03670535926338995]
	TIME [epoch: 5.7 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027159404415731694		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.027159404415731694 | validation: 0.03183916042658378]
	TIME [epoch: 5.7 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026569599884597683		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.026569599884597683 | validation: 0.04351400961879412]
	TIME [epoch: 5.74 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029839460975929884		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.029839460975929884 | validation: 0.03587905786374066]
	TIME [epoch: 5.7 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022374471046316922		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.022374471046316922 | validation: 0.0345906819024231]
	TIME [epoch: 5.7 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02327931814453511		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.02327931814453511 | validation: 0.0372428085702993]
	TIME [epoch: 5.7 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020971320246259056		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.020971320246259056 | validation: 0.03265997228467317]
	TIME [epoch: 5.7 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028916070720175237		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.028916070720175237 | validation: 0.03705804047317798]
	TIME [epoch: 5.7 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02604525798596681		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.02604525798596681 | validation: 0.036396952213759194]
	TIME [epoch: 5.72 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02657585706869694		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.02657585706869694 | validation: 0.034126927810836385]
	TIME [epoch: 5.72 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02601555771913744		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.02601555771913744 | validation: 0.036139419919808076]
	TIME [epoch: 5.7 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027213318865621474		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.027213318865621474 | validation: 0.03357097816295631]
	TIME [epoch: 5.7 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029396695398765018		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.029396695398765018 | validation: 0.04149828948267073]
	TIME [epoch: 5.7 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026559568874620607		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.026559568874620607 | validation: 0.04149562586266186]
	TIME [epoch: 5.7 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02642813150655087		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.02642813150655087 | validation: 0.03235140373955184]
	TIME [epoch: 5.7 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02509442847272436		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.02509442847272436 | validation: 0.03014331425936857]
	TIME [epoch: 5.74 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026304553374382235		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.026304553374382235 | validation: 0.0304083140929154]
	TIME [epoch: 5.7 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02883646066503744		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.02883646066503744 | validation: 0.030159501666565208]
	TIME [epoch: 5.7 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030444787073308187		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.030444787073308187 | validation: 0.03162297138795434]
	TIME [epoch: 5.7 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027443252670467707		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.027443252670467707 | validation: 0.033713415445248536]
	TIME [epoch: 5.7 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027145051127944297		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.027145051127944297 | validation: 0.036787198887039047]
	TIME [epoch: 5.7 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024415813068206168		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.024415813068206168 | validation: 0.03646089248567659]
	TIME [epoch: 5.73 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02734454729883884		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.02734454729883884 | validation: 0.02815020174712532]
	TIME [epoch: 5.71 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023753412394238685		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.023753412394238685 | validation: 0.0360323559151077]
	TIME [epoch: 5.7 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027237027668368437		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.027237027668368437 | validation: 0.04194459203714189]
	TIME [epoch: 5.7 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02822271620312164		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.02822271620312164 | validation: 0.035892815560456225]
	TIME [epoch: 5.7 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028494281735289968		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.028494281735289968 | validation: 0.029901921535664736]
	TIME [epoch: 5.7 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02785194702821727		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.02785194702821727 | validation: 0.04633364434375066]
	TIME [epoch: 5.7 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027170430547742902		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.027170430547742902 | validation: 0.034598409457406006]
	TIME [epoch: 5.74 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028139328917187182		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.028139328917187182 | validation: 0.03540490362892967]
	TIME [epoch: 5.7 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02689921338031659		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.02689921338031659 | validation: 0.047438894963089895]
	TIME [epoch: 5.7 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027261593101633994		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.027261593101633994 | validation: 0.02825233006865461]
	TIME [epoch: 5.7 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024728527210206148		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.024728527210206148 | validation: 0.0381211330780316]
	TIME [epoch: 5.7 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022105992308290766		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.022105992308290766 | validation: 0.030724742221766813]
	TIME [epoch: 5.7 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024321683609399705		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.024321683609399705 | validation: 0.028509130977243932]
	TIME [epoch: 5.72 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02520962445170739		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.02520962445170739 | validation: 0.035666852136773945]
	TIME [epoch: 5.72 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023843239637237643		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.023843239637237643 | validation: 0.03296134356700519]
	TIME [epoch: 5.7 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02290009001706995		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.02290009001706995 | validation: 0.03733007943547207]
	TIME [epoch: 5.7 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025693777812223165		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.025693777812223165 | validation: 0.03383897243721065]
	TIME [epoch: 5.7 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021422694944906756		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.021422694944906756 | validation: 0.03509444117697556]
	TIME [epoch: 5.7 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029576396319877553		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.029576396319877553 | validation: 0.034884669751226706]
	TIME [epoch: 5.7 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02317062781619915		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.02317062781619915 | validation: 0.03361980844451705]
	TIME [epoch: 5.74 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027778583558550517		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.027778583558550517 | validation: 0.03653766589091482]
	TIME [epoch: 5.7 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025449844937726736		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.025449844937726736 | validation: 0.03026277131760656]
	TIME [epoch: 5.7 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023956838451950187		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.023956838451950187 | validation: 0.03753957623023916]
	TIME [epoch: 5.7 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029088185587791783		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.029088185587791783 | validation: 0.034475412138726104]
	TIME [epoch: 5.7 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02330481639696353		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.02330481639696353 | validation: 0.0416462399037328]
	TIME [epoch: 5.7 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025318229378643687		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.025318229378643687 | validation: 0.0368315495113762]
	TIME [epoch: 5.73 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027841581827436106		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.027841581827436106 | validation: 0.028251173232742812]
	TIME [epoch: 5.72 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025598982910768786		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.025598982910768786 | validation: 0.030140510190267457]
	TIME [epoch: 5.7 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025549658658034685		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.025549658658034685 | validation: 0.02801124620420317]
	TIME [epoch: 5.7 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025488409803949102		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.025488409803949102 | validation: 0.0393962555925995]
	TIME [epoch: 5.7 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029665291897536056		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.029665291897536056 | validation: 0.033095183392899206]
	TIME [epoch: 5.7 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02657048140498007		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.02657048140498007 | validation: 0.03979140534502125]
	TIME [epoch: 5.7 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02881285316240299		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.02881285316240299 | validation: 0.03533932394812417]
	TIME [epoch: 5.74 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029238965552592762		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.029238965552592762 | validation: 0.03810239230234808]
	TIME [epoch: 5.7 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025026803899120785		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.025026803899120785 | validation: 0.03098432651080729]
	TIME [epoch: 5.7 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026223477944291446		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.026223477944291446 | validation: 0.03843074669605365]
	TIME [epoch: 5.7 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027582057977280132		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.027582057977280132 | validation: 0.039524618388673605]
	TIME [epoch: 5.7 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02579880120348097		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.02579880120348097 | validation: 0.03862463221445179]
	TIME [epoch: 5.7 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0266928084313909		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.0266928084313909 | validation: 0.04275742034200365]
	TIME [epoch: 5.71 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025397910747901226		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.025397910747901226 | validation: 0.03611794863342073]
	TIME [epoch: 5.73 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027643886651687412		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.027643886651687412 | validation: 0.03170938310478208]
	TIME [epoch: 5.7 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030856706639902993		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.030856706639902993 | validation: 0.04215479931781566]
	TIME [epoch: 5.7 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029632535622362757		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.029632535622362757 | validation: 0.037064379861165495]
	TIME [epoch: 5.7 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030062821397495672		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.030062821397495672 | validation: 0.046072385424214136]
	TIME [epoch: 5.7 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026890429142953427		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.026890429142953427 | validation: 0.03826628952377375]
	TIME [epoch: 5.7 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029720868341552614		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.029720868341552614 | validation: 0.04248780702535141]
	TIME [epoch: 5.74 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02896309504557686		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.02896309504557686 | validation: 0.04363304908298006]
	TIME [epoch: 5.71 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027375543556058576		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.027375543556058576 | validation: 0.03613403509052378]
	TIME [epoch: 5.7 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02469390232939573		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.02469390232939573 | validation: 0.03731090458342034]
	TIME [epoch: 5.7 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02921393991005843		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.02921393991005843 | validation: 0.043667149739539016]
	TIME [epoch: 5.7 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0299042160529307		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.0299042160529307 | validation: 0.02771885770035354]
	TIME [epoch: 5.7 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026507297850931415		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.026507297850931415 | validation: 0.022961775905090423]
	TIME [epoch: 5.71 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02441363365012631		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.02441363365012631 | validation: 0.03575619203847563]
	TIME [epoch: 5.73 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028038272960006664		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.028038272960006664 | validation: 0.03765566266033044]
	TIME [epoch: 5.7 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028124927542790595		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.028124927542790595 | validation: 0.047142619388458526]
	TIME [epoch: 5.7 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035916948636972035		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.035916948636972035 | validation: 0.042700776635719306]
	TIME [epoch: 5.7 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03512961431667682		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.03512961431667682 | validation: 0.04641938837412056]
	TIME [epoch: 5.7 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03794429681671638		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.03794429681671638 | validation: 0.04940195272822383]
	TIME [epoch: 5.7 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04447369335685231		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.04447369335685231 | validation: 0.04823781165702768]
	TIME [epoch: 5.74 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03736857177135222		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.03736857177135222 | validation: 0.04094884820425744]
	TIME [epoch: 5.71 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032823023261092016		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.032823023261092016 | validation: 0.036368735259435216]
	TIME [epoch: 5.7 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026631546759203588		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.026631546759203588 | validation: 0.02324555699508865]
	TIME [epoch: 5.7 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02353386519009263		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.02353386519009263 | validation: 0.029680975502598708]
	TIME [epoch: 5.7 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023650940125748796		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.023650940125748796 | validation: 0.03612943419784185]
	TIME [epoch: 5.7 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024343673292382816		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.024343673292382816 | validation: 0.030968478732333084]
	TIME [epoch: 5.71 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024941988635309387		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.024941988635309387 | validation: 0.028802941676228083]
	TIME [epoch: 5.73 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02414481221944134		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.02414481221944134 | validation: 0.03579476966362069]
	TIME [epoch: 5.7 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02435787263953095		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.02435787263953095 | validation: 0.03977896818755713]
	TIME [epoch: 5.7 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027967953456476884		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.027967953456476884 | validation: 0.03005478725059776]
	TIME [epoch: 5.7 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024533977988705272		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.024533977988705272 | validation: 0.030777841692794298]
	TIME [epoch: 5.7 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028772080452203603		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.028772080452203603 | validation: 0.04618458994734123]
	TIME [epoch: 5.7 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027925679270820274		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.027925679270820274 | validation: 0.0347829643275105]
	TIME [epoch: 5.74 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02756727497566342		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.02756727497566342 | validation: 0.03392420451674761]
	TIME [epoch: 5.7 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025699050500854845		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.025699050500854845 | validation: 0.03410332282203005]
	TIME [epoch: 5.7 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03154646464843221		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.03154646464843221 | validation: 0.04020951399137616]
	TIME [epoch: 5.7 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027638898498705263		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.027638898498705263 | validation: 0.041956480794399856]
	TIME [epoch: 5.7 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01981206082020732		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.01981206082020732 | validation: 0.02856989690243306]
	TIME [epoch: 5.7 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025435925173537845		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.025435925173537845 | validation: 0.03630734855736901]
	TIME [epoch: 5.71 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02333423936008199		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.02333423936008199 | validation: 0.02994357303038305]
	TIME [epoch: 5.73 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023124924287903692		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.023124924287903692 | validation: 0.035590673377294636]
	TIME [epoch: 5.7 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023860754939853943		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.023860754939853943 | validation: 0.03366149280019054]
	TIME [epoch: 5.7 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027159413935768026		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.027159413935768026 | validation: 0.03221366525222783]
	TIME [epoch: 5.7 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0233986614868475		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.0233986614868475 | validation: 0.03554373249657074]
	TIME [epoch: 5.7 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027768281909795835		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.027768281909795835 | validation: 0.03542639066825488]
	TIME [epoch: 5.7 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026488284666513408		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.026488284666513408 | validation: 0.03577883473631312]
	TIME [epoch: 5.74 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026349173110196588		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.026349173110196588 | validation: 0.030127254374364584]
	TIME [epoch: 5.7 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030404114641296925		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.030404114641296925 | validation: 0.03956035142173303]
	TIME [epoch: 5.7 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026177079441145036		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.026177079441145036 | validation: 0.04245255763747514]
	TIME [epoch: 5.7 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024259960581977026		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.024259960581977026 | validation: 0.0426705942955359]
	TIME [epoch: 5.7 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022590025033258188		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.022590025033258188 | validation: 0.03544015352857712]
	TIME [epoch: 5.7 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02751623371322407		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.02751623371322407 | validation: 0.02926259463871407]
	TIME [epoch: 5.7 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026629802829331844		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.026629802829331844 | validation: 0.03730416252111207]
	TIME [epoch: 5.74 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02950402971929636		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.02950402971929636 | validation: 0.035203893258726984]
	TIME [epoch: 5.7 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024367312211872837		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.024367312211872837 | validation: 0.03697044883246003]
	TIME [epoch: 5.7 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02701400913584078		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.02701400913584078 | validation: 0.033576141947608176]
	TIME [epoch: 5.7 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025677868121315		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.025677868121315 | validation: 0.029109602933529884]
	TIME [epoch: 5.7 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03048087595576042		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.03048087595576042 | validation: 0.03679778382002403]
	TIME [epoch: 5.7 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029084036352186628		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.029084036352186628 | validation: 0.04461931379016638]
	TIME [epoch: 5.73 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022942119361083188		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.022942119361083188 | validation: 0.027140259871841498]
	TIME [epoch: 5.72 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02571171483102607		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.02571171483102607 | validation: 0.03395693308473916]
	TIME [epoch: 5.7 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02665122057746808		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.02665122057746808 | validation: 0.03163825910942025]
	TIME [epoch: 5.7 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022931884513126895		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.022931884513126895 | validation: 0.03472869190634066]
	TIME [epoch: 5.7 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028739802616978602		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.028739802616978602 | validation: 0.033793929950811166]
	TIME [epoch: 5.7 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0248993691639182		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.0248993691639182 | validation: 0.046669393673343454]
	TIME [epoch: 5.7 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024456517866171965		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.024456517866171965 | validation: 0.03416639991520821]
	TIME [epoch: 5.74 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028729225442068754		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.028729225442068754 | validation: 0.030529114240383824]
	TIME [epoch: 5.7 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028390237527153465		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.028390237527153465 | validation: 0.028562201001296313]
	TIME [epoch: 5.7 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026686930046220088		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.026686930046220088 | validation: 0.030247831636269523]
	TIME [epoch: 5.7 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022861704868619468		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.022861704868619468 | validation: 0.030852613229223447]
	TIME [epoch: 5.7 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024982613969104676		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.024982613969104676 | validation: 0.03419684834668685]
	TIME [epoch: 5.7 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026533911855699435		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.026533911855699435 | validation: 0.04392085845969621]
	TIME [epoch: 5.73 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024464206328973125		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.024464206328973125 | validation: 0.0334110050791754]
	TIME [epoch: 5.72 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026802109851699646		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.026802109851699646 | validation: 0.02908302334451049]
	TIME [epoch: 5.7 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023508431552446685		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.023508431552446685 | validation: 0.04356031674210005]
	TIME [epoch: 5.7 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026006122291054114		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.026006122291054114 | validation: 0.03834567706815892]
	TIME [epoch: 5.7 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02418137939930667		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.02418137939930667 | validation: 0.039334097064281294]
	TIME [epoch: 5.7 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02515412658621623		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.02515412658621623 | validation: 0.04161884209638004]
	TIME [epoch: 5.7 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025585027134720592		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.025585027134720592 | validation: 0.033869373596979196]
	TIME [epoch: 5.74 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02241150207459207		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.02241150207459207 | validation: 0.040164769394979614]
	TIME [epoch: 5.7 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024535132676238317		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.024535132676238317 | validation: 0.03498964178513475]
	TIME [epoch: 5.7 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023641058274943616		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.023641058274943616 | validation: 0.030535000365532933]
	TIME [epoch: 5.7 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02536785015123358		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.02536785015123358 | validation: 0.04092807763182752]
	TIME [epoch: 5.7 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02708048550530017		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.02708048550530017 | validation: 0.03368979527935583]
	TIME [epoch: 5.7 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025227285695773163		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.025227285695773163 | validation: 0.0384422778852462]
	TIME [epoch: 5.73 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026039473892507256		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.026039473892507256 | validation: 0.027993666096676795]
	TIME [epoch: 5.72 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025654377784200332		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.025654377784200332 | validation: 0.0336084406396821]
	TIME [epoch: 5.7 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01813015852858346		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.01813015852858346 | validation: 0.03166736960818579]
	TIME [epoch: 5.7 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02360939834284724		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.02360939834284724 | validation: 0.031844849340849475]
	TIME [epoch: 5.7 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023645793829889097		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.023645793829889097 | validation: 0.03242818188438026]
	TIME [epoch: 5.7 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026148748619934055		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.026148748619934055 | validation: 0.03489800284658372]
	TIME [epoch: 5.7 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024171691312702824		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.024171691312702824 | validation: 0.03236798581060462]
	TIME [epoch: 5.74 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025234602844687423		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.025234602844687423 | validation: 0.035209591060170395]
	TIME [epoch: 5.7 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021521590709532284		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.021521590709532284 | validation: 0.02671641113329805]
	TIME [epoch: 5.7 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02916229334500022		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.02916229334500022 | validation: 0.03302296948060424]
	TIME [epoch: 5.7 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025608395740428072		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.025608395740428072 | validation: 0.033811959412516045]
	TIME [epoch: 5.7 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023963807849392872		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.023963807849392872 | validation: 0.037760397791897264]
	TIME [epoch: 5.7 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022726106746132416		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.022726106746132416 | validation: 0.03942877442406327]
	TIME [epoch: 5.72 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025343820879732238		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.025343820879732238 | validation: 0.03179824849663535]
	TIME [epoch: 5.71 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02554881846707934		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.02554881846707934 | validation: 0.03229700352180474]
	TIME [epoch: 5.7 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022826460999092545		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.022826460999092545 | validation: 0.03306718696919174]
	TIME [epoch: 5.7 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025526699996382393		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.025526699996382393 | validation: 0.029240001063043943]
	TIME [epoch: 5.7 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025533382754563735		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.025533382754563735 | validation: 0.027249070572068348]
	TIME [epoch: 5.7 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024783116976513742		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.024783116976513742 | validation: 0.03525929308483664]
	TIME [epoch: 5.7 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026873691160522357		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.026873691160522357 | validation: 0.03160340862041903]
	TIME [epoch: 5.74 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023386942072225442		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.023386942072225442 | validation: 0.03246764096412251]
	TIME [epoch: 5.7 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024510909246198306		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.024510909246198306 | validation: 0.02322385468171503]
	TIME [epoch: 5.7 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021785108115777316		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.021785108115777316 | validation: 0.032410183278477646]
	TIME [epoch: 5.7 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026121899999534584		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.026121899999534584 | validation: 0.03340735818351649]
	TIME [epoch: 5.7 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024474720322796954		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.024474720322796954 | validation: 0.04015032766357157]
	TIME [epoch: 5.7 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028466184739356297		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.028466184739356297 | validation: 0.03253352991194971]
	TIME [epoch: 5.73 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025572310190944428		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.025572310190944428 | validation: 0.04255688806128899]
	TIME [epoch: 5.72 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02365689716393059		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.02365689716393059 | validation: 0.02596149821879058]
	TIME [epoch: 5.7 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022241772437203298		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.022241772437203298 | validation: 0.03545604629621684]
	TIME [epoch: 5.7 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02301720810351371		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.02301720810351371 | validation: 0.03992780702591611]
	TIME [epoch: 5.7 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025951325756610046		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.025951325756610046 | validation: 0.03657637827366744]
	TIME [epoch: 5.7 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024019755585617197		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.024019755585617197 | validation: 0.02629903955348638]
	TIME [epoch: 5.7 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0219290066750312		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.0219290066750312 | validation: 0.028240165558649596]
	TIME [epoch: 5.74 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02439239281228349		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.02439239281228349 | validation: 0.02949416089593111]
	TIME [epoch: 5.7 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024079924108476293		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.024079924108476293 | validation: 0.02862453759469066]
	TIME [epoch: 5.7 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023215167805176858		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.023215167805176858 | validation: 0.033645137580543764]
	TIME [epoch: 5.7 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02541090925751766		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.02541090925751766 | validation: 0.03673966537185858]
	TIME [epoch: 5.7 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028823136342023412		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.028823136342023412 | validation: 0.033877218227243]
	TIME [epoch: 5.7 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02646466154756327		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.02646466154756327 | validation: 0.03424540537972209]
	TIME [epoch: 5.71 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026112486556810748		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.026112486556810748 | validation: 0.02909296756496024]
	TIME [epoch: 5.73 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025111145642598073		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.025111145642598073 | validation: 0.03125764784531912]
	TIME [epoch: 5.7 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026174931405127812		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.026174931405127812 | validation: 0.030557371367200162]
	TIME [epoch: 5.7 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02407699245295269		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.02407699245295269 | validation: 0.043243844124997606]
	TIME [epoch: 5.7 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023550519194256957		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.023550519194256957 | validation: 0.03361262961261926]
	TIME [epoch: 5.7 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026603946467238997		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.026603946467238997 | validation: 0.034614089236183386]
	TIME [epoch: 5.7 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025188546921865968		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.025188546921865968 | validation: 0.03923176814307574]
	TIME [epoch: 5.74 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026662657496594886		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.026662657496594886 | validation: 0.03507554734302767]
	TIME [epoch: 5.71 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03166043421215466		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.03166043421215466 | validation: 0.04258228010399961]
	TIME [epoch: 5.7 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02790844492190913		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.02790844492190913 | validation: 0.033645295742147245]
	TIME [epoch: 5.7 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024628216027461167		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.024628216027461167 | validation: 0.04207606868711893]
	TIME [epoch: 5.7 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022293590632139766		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.022293590632139766 | validation: 0.04066346165018636]
	TIME [epoch: 5.7 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025570548750485735		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.025570548750485735 | validation: 0.0328078316885486]
	TIME [epoch: 5.71 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025078424638729613		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.025078424638729613 | validation: 0.03567955538765368]
	TIME [epoch: 5.73 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02588078067604933		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.02588078067604933 | validation: 0.04010199782970096]
	TIME [epoch: 5.7 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03003382954851405		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.03003382954851405 | validation: 0.03279828252043839]
	TIME [epoch: 5.7 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020833354541987734		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.020833354541987734 | validation: 0.03318006392889895]
	TIME [epoch: 5.7 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022987037966347167		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.022987037966347167 | validation: 0.03146326668402054]
	TIME [epoch: 5.7 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027056726367543648		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.027056726367543648 | validation: 0.033884471627008486]
	TIME [epoch: 5.7 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02587862389602301		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.02587862389602301 | validation: 0.03936554396962758]
	TIME [epoch: 5.74 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025833528605420236		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.025833528605420236 | validation: 0.02952244930909414]
	TIME [epoch: 5.71 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026680192640509602		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.026680192640509602 | validation: 0.033108008924912065]
	TIME [epoch: 5.7 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0278911149356937		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.0278911149356937 | validation: 0.03335276448985273]
	TIME [epoch: 5.7 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02730655583830966		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.02730655583830966 | validation: 0.03846988378436131]
	TIME [epoch: 5.7 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02331606513664968		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.02331606513664968 | validation: 0.044143090933908884]
	TIME [epoch: 5.7 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02999834617174327		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.02999834617174327 | validation: 0.04758950524917994]
	TIME [epoch: 5.71 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0283776549327983		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.0283776549327983 | validation: 0.04014910267946086]
	TIME [epoch: 5.72 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027588425925828823		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.027588425925828823 | validation: 0.03388717727952047]
	TIME [epoch: 5.7 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026764174863722918		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.026764174863722918 | validation: 0.037721616144115386]
	TIME [epoch: 5.7 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033713172708332045		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.033713172708332045 | validation: 0.041566941330322946]
	TIME [epoch: 5.7 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027566689795447533		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.027566689795447533 | validation: 0.032028289728089916]
	TIME [epoch: 5.7 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030809715049809464		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.030809715049809464 | validation: 0.03974641863959604]
	TIME [epoch: 5.69 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02514367455816696		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.02514367455816696 | validation: 0.033099008500631376]
	TIME [epoch: 5.73 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027281719446997775		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.027281719446997775 | validation: 0.038008029606851255]
	TIME [epoch: 5.7 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02661472039083391		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.02661472039083391 | validation: 0.025964640096133508]
	TIME [epoch: 5.7 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028815711842654714		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.028815711842654714 | validation: 0.0322540716167507]
	TIME [epoch: 5.7 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02881361520610199		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.02881361520610199 | validation: 0.0435397457848905]
	TIME [epoch: 5.69 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023515147227562462		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.023515147227562462 | validation: 0.033953357512292295]
	TIME [epoch: 5.7 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027649120781021375		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.027649120781021375 | validation: 0.04204585727094803]
	TIME [epoch: 5.71 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02570017870775251		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.02570017870775251 | validation: 0.03324397662996631]
	TIME [epoch: 5.72 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0303675761963513		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.0303675761963513 | validation: 0.04001755255846809]
	TIME [epoch: 5.7 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02774406071339696		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.02774406071339696 | validation: 0.03140867856030034]
	TIME [epoch: 5.7 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0240901912165269		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.0240901912165269 | validation: 0.03203053787156764]
	TIME [epoch: 5.7 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02367560370835231		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.02367560370835231 | validation: 0.03173483364968403]
	TIME [epoch: 5.7 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026129524540352098		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.026129524540352098 | validation: 0.025733591296528517]
	TIME [epoch: 5.7 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026484364629665053		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.026484364629665053 | validation: 0.028921276277072968]
	TIME [epoch: 5.73 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027721809549728173		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.027721809549728173 | validation: 0.03673361406685261]
	TIME [epoch: 5.7 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026977263054306432		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.026977263054306432 | validation: 0.04063734223669748]
	TIME [epoch: 5.7 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02744130071172699		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.02744130071172699 | validation: 0.03931874108522136]
	TIME [epoch: 5.7 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024643238239731118		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.024643238239731118 | validation: 0.035286822837295444]
	TIME [epoch: 5.7 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023746159037104298		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.023746159037104298 | validation: 0.0406552362504244]
	TIME [epoch: 5.7 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02559301804688246		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.02559301804688246 | validation: 0.036147050542030226]
	TIME [epoch: 5.7 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03041739232862599		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.03041739232862599 | validation: 0.04342694570279541]
	TIME [epoch: 5.72 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027864539801239194		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.027864539801239194 | validation: 0.03217772200538078]
	TIME [epoch: 5.7 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027161940128059364		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.027161940128059364 | validation: 0.0402767015701974]
	TIME [epoch: 5.7 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023997960677621298		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.023997960677621298 | validation: 0.032997467496932324]
	TIME [epoch: 5.7 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025572840217898254		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.025572840217898254 | validation: 0.02815682484223625]
	TIME [epoch: 5.7 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02505667497265985		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.02505667497265985 | validation: 0.03531836434755383]
	TIME [epoch: 5.7 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023705547281945606		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.023705547281945606 | validation: 0.03720506661038228]
	TIME [epoch: 5.74 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023433126530527523		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.023433126530527523 | validation: 0.03839058335988618]
	TIME [epoch: 5.71 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023544806298216266		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.023544806298216266 | validation: 0.03367030616663603]
	TIME [epoch: 5.7 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01986585256735607		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.01986585256735607 | validation: 0.04150797879364266]
	TIME [epoch: 5.7 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02376666331156315		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.02376666331156315 | validation: 0.03073669202739777]
	TIME [epoch: 5.7 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023791874784994838		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.023791874784994838 | validation: 0.031979164760478546]
	TIME [epoch: 5.7 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024562452502317624		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.024562452502317624 | validation: 0.03454951237488933]
	TIME [epoch: 5.71 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02627737216934442		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.02627737216934442 | validation: 0.033946793038455506]
	TIME [epoch: 5.73 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024517294059210656		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.024517294059210656 | validation: 0.03520391904524124]
	TIME [epoch: 5.7 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025948823451526215		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.025948823451526215 | validation: 0.032371054106440804]
	TIME [epoch: 5.7 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023217005326664715		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.023217005326664715 | validation: 0.03879696743500182]
	TIME [epoch: 5.7 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021429470816800883		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.021429470816800883 | validation: 0.03186517388692598]
	TIME [epoch: 5.7 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020603163926259993		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.020603163926259993 | validation: 0.03820756710357641]
	TIME [epoch: 5.7 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02709168554140735		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.02709168554140735 | validation: 0.03256268213901449]
	TIME [epoch: 5.72 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025732653945592543		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.025732653945592543 | validation: 0.03976936513483171]
	TIME [epoch: 5.71 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02452484582040881		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.02452484582040881 | validation: 0.03360148282038851]
	TIME [epoch: 5.7 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026707854681385323		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.026707854681385323 | validation: 0.04130093888697116]
	TIME [epoch: 5.7 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027584784155681576		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.027584784155681576 | validation: 0.03852824244846057]
	TIME [epoch: 5.7 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023582376074587595		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.023582376074587595 | validation: 0.03528534096410298]
	TIME [epoch: 5.7 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0250911215425811		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.0250911215425811 | validation: 0.042118062215397704]
	TIME [epoch: 5.7 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026349804489906585		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.026349804489906585 | validation: 0.027446301423018876]
	TIME [epoch: 5.73 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02377309967081159		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.02377309967081159 | validation: 0.029823320576890806]
	TIME [epoch: 5.7 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026378640974109347		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.026378640974109347 | validation: 0.03345903010958802]
	TIME [epoch: 5.7 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023195541319828917		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.023195541319828917 | validation: 0.03067042806155074]
	TIME [epoch: 5.7 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022057759727999372		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.022057759727999372 | validation: 0.03963484682676791]
	TIME [epoch: 5.7 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02291275001591461		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.02291275001591461 | validation: 0.035351314106524055]
	TIME [epoch: 5.7 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031160042777656306		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.031160042777656306 | validation: 0.03456285097832854]
	TIME [epoch: 5.72 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026451854468619248		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.026451854468619248 | validation: 0.04603543077496454]
	TIME [epoch: 5.71 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03095974155162317		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.03095974155162317 | validation: 0.026576360528748236]
	TIME [epoch: 5.7 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02525516919755515		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.02525516919755515 | validation: 0.045886107299521015]
	TIME [epoch: 5.7 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02308448934164359		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.02308448934164359 | validation: 0.03647610892338556]
	TIME [epoch: 5.7 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025350143969190733		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.025350143969190733 | validation: 0.03645157348288314]
	TIME [epoch: 5.7 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026118510180839404		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.026118510180839404 | validation: 0.03369053224623486]
	TIME [epoch: 5.7 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0293428063144855		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.0293428063144855 | validation: 0.033403710305187045]
	TIME [epoch: 5.73 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02531107378307447		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.02531107378307447 | validation: 0.040012420775733304]
	TIME [epoch: 5.7 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02788430837726205		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.02788430837726205 | validation: 0.03378848460070041]
	TIME [epoch: 5.7 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026707507390810466		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.026707507390810466 | validation: 0.0394433045729202]
	TIME [epoch: 5.7 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026378194857363754		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.026378194857363754 | validation: 0.04159312810176621]
	TIME [epoch: 5.7 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02250477234926543		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.02250477234926543 | validation: 0.036310868583250215]
	TIME [epoch: 5.7 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026483652626850433		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.026483652626850433 | validation: 0.038023967886527454]
	TIME [epoch: 5.72 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02143684686397004		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.02143684686397004 | validation: 0.024416444937231635]
	TIME [epoch: 5.71 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025150350496739797		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.025150350496739797 | validation: 0.03304070291980726]
	TIME [epoch: 5.7 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026084719868261635		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.026084719868261635 | validation: 0.03434344755379263]
	TIME [epoch: 5.7 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026431083677301948		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.026431083677301948 | validation: 0.03554999003944042]
	TIME [epoch: 5.7 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023873644966531445		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.023873644966531445 | validation: 0.02414077613041259]
	TIME [epoch: 5.7 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025426405278373827		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.025426405278373827 | validation: 0.03208728895076706]
	TIME [epoch: 5.7 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027543282699920416		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.027543282699920416 | validation: 0.03966166561151498]
	TIME [epoch: 5.73 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026706530531780705		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.026706530531780705 | validation: 0.032005632991840706]
	TIME [epoch: 5.7 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024632631460513622		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.024632631460513622 | validation: 0.03157801876051451]
	TIME [epoch: 5.7 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024953009606400095		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.024953009606400095 | validation: 0.04100125446362123]
	TIME [epoch: 5.7 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02279280677400801		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.02279280677400801 | validation: 0.022523589774910376]
	TIME [epoch: 5.7 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021550582841696378		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.021550582841696378 | validation: 0.035567851731571475]
	TIME [epoch: 5.7 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023392697950117607		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.023392697950117607 | validation: 0.03353646268740618]
	TIME [epoch: 5.72 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02257422809208301		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.02257422809208301 | validation: 0.03624870066514381]
	TIME [epoch: 5.71 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023776331380440833		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.023776331380440833 | validation: 0.04640637495707617]
	TIME [epoch: 5.7 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026715612862810996		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.026715612862810996 | validation: 0.03314199142068823]
	TIME [epoch: 5.7 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025876107375558788		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.025876107375558788 | validation: 0.03009696039412095]
	TIME [epoch: 5.7 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024546086103929898		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.024546086103929898 | validation: 0.03503555701183931]
	TIME [epoch: 5.7 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024214366246810545		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.024214366246810545 | validation: 0.03580676961738724]
	TIME [epoch: 5.7 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02176289106739428		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.02176289106739428 | validation: 0.03547880463277932]
	TIME [epoch: 5.74 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02245403269640157		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.02245403269640157 | validation: 0.03889922220586246]
	TIME [epoch: 5.7 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024886515352898618		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.024886515352898618 | validation: 0.03291744242864868]
	TIME [epoch: 5.7 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02247662734540612		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.02247662734540612 | validation: 0.034989121560621186]
	TIME [epoch: 5.7 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0234346219577345		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.0234346219577345 | validation: 0.03064863929394744]
	TIME [epoch: 5.7 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022159298835011974		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.022159298835011974 | validation: 0.03514719725499162]
	TIME [epoch: 5.7 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023811707593019305		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.023811707593019305 | validation: 0.03665226279445004]
	TIME [epoch: 5.72 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02348691907711615		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.02348691907711615 | validation: 0.03334108762966656]
	TIME [epoch: 5.71 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022010196251341697		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.022010196251341697 | validation: 0.0374088748087923]
	TIME [epoch: 5.7 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026151600782843586		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.026151600782843586 | validation: 0.02687695312192349]
	TIME [epoch: 5.7 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02176719878917964		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.02176719878917964 | validation: 0.037073935564025995]
	TIME [epoch: 5.7 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022917500761860995		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.022917500761860995 | validation: 0.026696670702064416]
	TIME [epoch: 5.7 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02219166145175383		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.02219166145175383 | validation: 0.033735270171778436]
	TIME [epoch: 5.7 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02449836732452608		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.02449836732452608 | validation: 0.03201696769485583]
	TIME [epoch: 5.73 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02520308923229049		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.02520308923229049 | validation: 0.035786130137216474]
	TIME [epoch: 5.7 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025969445647109804		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.025969445647109804 | validation: 0.03696341663523159]
	TIME [epoch: 5.7 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026284669507349662		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.026284669507349662 | validation: 0.041039103065958385]
	TIME [epoch: 5.7 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020668616968955403		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.020668616968955403 | validation: 0.033657451367933765]
	TIME [epoch: 5.7 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022668013990976517		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.022668013990976517 | validation: 0.025260195664759278]
	TIME [epoch: 5.69 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024239668571704245		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.024239668571704245 | validation: 0.029607711761822843]
	TIME [epoch: 5.72 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025959938694372787		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.025959938694372787 | validation: 0.034931858089463245]
	TIME [epoch: 5.71 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021506593995631717		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.021506593995631717 | validation: 0.02836879452950206]
	TIME [epoch: 5.7 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02593479423301493		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.02593479423301493 | validation: 0.03742150600167664]
	TIME [epoch: 5.7 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020732503134778563		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.020732503134778563 | validation: 0.030955180244839595]
	TIME [epoch: 5.7 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021038529960324973		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.021038529960324973 | validation: 0.031786739376834044]
	TIME [epoch: 5.7 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024034428496462652		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.024034428496462652 | validation: 0.031155858123546876]
	TIME [epoch: 5.7 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02061240432906295		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.02061240432906295 | validation: 0.03772586578097231]
	TIME [epoch: 5.73 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022223715186586553		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.022223715186586553 | validation: 0.03323091315650885]
	TIME [epoch: 5.7 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02338626448227937		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.02338626448227937 | validation: 0.030193337162617448]
	TIME [epoch: 5.7 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024912683591883245		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.024912683591883245 | validation: 0.031164978133334707]
	TIME [epoch: 5.7 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022653582008338786		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.022653582008338786 | validation: 0.02746715928585043]
	TIME [epoch: 5.7 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025084991086236234		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.025084991086236234 | validation: 0.03536520415945608]
	TIME [epoch: 5.7 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021894280695784953		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.021894280695784953 | validation: 0.030057761765384283]
	TIME [epoch: 5.71 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026573959517002907		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.026573959517002907 | validation: 0.037699000422977524]
	TIME [epoch: 5.73 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02291531495990767		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.02291531495990767 | validation: 0.03407968117470333]
	TIME [epoch: 5.7 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021281871356094707		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.021281871356094707 | validation: 0.03442247098120207]
	TIME [epoch: 5.7 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021746725849698126		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.021746725849698126 | validation: 0.029893336452454455]
	TIME [epoch: 5.7 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023086684214029568		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.023086684214029568 | validation: 0.0322445249103327]
	TIME [epoch: 5.7 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02510805218051599		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.02510805218051599 | validation: 0.03155987712119032]
	TIME [epoch: 5.7 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0254999041222008		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.0254999041222008 | validation: 0.039607437540349795]
	TIME [epoch: 5.73 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0211523962887922		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.0211523962887922 | validation: 0.0343732987562111]
	TIME [epoch: 5.7 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024880282766467372		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.024880282766467372 | validation: 0.0415250163207578]
	TIME [epoch: 5.7 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024454507508871237		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.024454507508871237 | validation: 0.03533595365220184]
	TIME [epoch: 5.7 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028070369957598006		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.028070369957598006 | validation: 0.030314271880229973]
	TIME [epoch: 5.7 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025621008862205013		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.025621008862205013 | validation: 0.027640117353713]
	TIME [epoch: 5.7 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024589621071368847		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.024589621071368847 | validation: 0.030553165876052946]
	TIME [epoch: 5.71 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020962203720941625		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.020962203720941625 | validation: 0.03773655368396034]
	TIME [epoch: 5.73 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023181278005091732		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.023181278005091732 | validation: 0.03793534869241998]
	TIME [epoch: 5.7 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023755149783488742		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.023755149783488742 | validation: 0.0293115511556657]
	TIME [epoch: 5.7 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025492604688000603		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.025492604688000603 | validation: 0.034877357344470304]
	TIME [epoch: 5.7 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0259940586975207		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.0259940586975207 | validation: 0.03434409547653867]
	TIME [epoch: 5.7 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025794706489276904		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.025794706489276904 | validation: 0.03910115130815888]
	TIME [epoch: 5.7 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024798879785849288		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.024798879785849288 | validation: 0.03188260007194144]
	TIME [epoch: 5.73 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024132814380412437		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.024132814380412437 | validation: 0.03319781431112171]
	TIME [epoch: 5.7 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026513388447044144		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.026513388447044144 | validation: 0.03704042871815887]
	TIME [epoch: 5.7 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02148970674325793		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.02148970674325793 | validation: 0.02605424647460823]
	TIME [epoch: 5.7 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023893833326475423		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.023893833326475423 | validation: 0.03721738099554174]
	TIME [epoch: 5.7 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025659342938339238		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.025659342938339238 | validation: 0.026893505291803014]
	TIME [epoch: 5.7 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02267718220958303		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.02267718220958303 | validation: 0.03295524349548866]
	TIME [epoch: 5.71 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02457210870724555		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.02457210870724555 | validation: 0.030969721833612986]
	TIME [epoch: 5.73 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021554130416410425		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.021554130416410425 | validation: 0.036911271114618414]
	TIME [epoch: 5.7 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025951802052865965		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.025951802052865965 | validation: 0.03235399526507034]
	TIME [epoch: 5.7 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026883026303369237		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.026883026303369237 | validation: 0.025728794046110507]
	TIME [epoch: 5.7 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023677238329441762		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.023677238329441762 | validation: 0.035122527788194524]
	TIME [epoch: 5.7 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02331342423224531		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.02331342423224531 | validation: 0.03803743703232549]
	TIME [epoch: 5.7 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025666411110122633		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.025666411110122633 | validation: 0.031706633962472544]
	TIME [epoch: 5.73 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023826463721862434		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.023826463721862434 | validation: 0.03453810374235857]
	TIME [epoch: 5.7 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02061479444804571		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.02061479444804571 | validation: 0.030569915261290638]
	TIME [epoch: 5.7 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02287250884147431		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.02287250884147431 | validation: 0.03529548348040581]
	TIME [epoch: 5.7 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022360739002074356		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.022360739002074356 | validation: 0.024037908145639587]
	TIME [epoch: 5.7 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02414896895963288		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.02414896895963288 | validation: 0.02810832645539721]
	TIME [epoch: 5.7 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023155719640795158		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.023155719640795158 | validation: 0.030584984086134873]
	TIME [epoch: 5.71 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024721265419289776		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.024721265419289776 | validation: 0.032645321186338463]
	TIME [epoch: 5.73 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02392881088845362		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.02392881088845362 | validation: 0.02858775605895123]
	TIME [epoch: 5.7 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022154463979229193		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.022154463979229193 | validation: 0.0259252098232923]
	TIME [epoch: 5.7 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024772062719732153		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.024772062719732153 | validation: 0.02726759553765114]
	TIME [epoch: 5.7 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023928456370697033		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.023928456370697033 | validation: 0.03671092809876396]
	TIME [epoch: 5.7 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02593883401916982		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.02593883401916982 | validation: 0.03593783448520275]
	TIME [epoch: 5.7 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022701659627993684		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.022701659627993684 | validation: 0.032421524767396806]
	TIME [epoch: 5.73 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022501146288456328		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.022501146288456328 | validation: 0.03175187971826815]
	TIME [epoch: 5.7 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028266511202079226		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.028266511202079226 | validation: 0.035439241453883455]
	TIME [epoch: 5.7 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025095514618854255		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.025095514618854255 | validation: 0.03169456920310695]
	TIME [epoch: 5.7 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024523354298252552		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.024523354298252552 | validation: 0.03192414392606636]
	TIME [epoch: 5.7 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02198213471957232		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.02198213471957232 | validation: 0.039533853047156786]
	TIME [epoch: 5.7 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02233752998715001		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.02233752998715001 | validation: 0.03845159003232471]
	TIME [epoch: 5.7 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022140776676103396		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.022140776676103396 | validation: 0.027853851678866132]
	TIME [epoch: 5.73 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024162607776686315		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.024162607776686315 | validation: 0.02717630474601216]
	TIME [epoch: 5.7 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021015213282538612		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.021015213282538612 | validation: 0.036414472354347326]
	TIME [epoch: 5.7 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02221507667267366		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.02221507667267366 | validation: 0.03161937857739527]
	TIME [epoch: 5.7 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023745190384135178		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.023745190384135178 | validation: 0.04263461639434609]
	TIME [epoch: 5.7 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024312102530689914		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.024312102530689914 | validation: 0.033435659370934734]
	TIME [epoch: 5.7 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022975466633403375		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.022975466633403375 | validation: 0.033231338668158555]
	TIME [epoch: 5.73 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021737994140748552		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.021737994140748552 | validation: 0.03813012241949309]
	TIME [epoch: 5.7 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025540104504742152		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.025540104504742152 | validation: 0.027843713917916332]
	TIME [epoch: 5.7 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02214802318205799		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.02214802318205799 | validation: 0.030661350433352778]
	TIME [epoch: 5.7 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02448656407463915		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.02448656407463915 | validation: 0.03409095074374999]
	TIME [epoch: 5.7 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020861568794702398		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.020861568794702398 | validation: 0.032405461178377656]
	TIME [epoch: 5.7 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020549158157339854		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.020549158157339854 | validation: 0.032579902692619345]
	TIME [epoch: 5.71 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024050373559669335		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.024050373559669335 | validation: 0.03464996117100708]
	TIME [epoch: 5.73 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023504512692143285		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.023504512692143285 | validation: 0.02697948264681311]
	TIME [epoch: 5.7 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022339940003834248		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.022339940003834248 | validation: 0.028896351916110983]
	TIME [epoch: 5.7 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02399343482918269		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.02399343482918269 | validation: 0.034037189237774886]
	TIME [epoch: 5.7 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022316722833169326		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.022316722833169326 | validation: 0.027779714744039702]
	TIME [epoch: 5.7 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023330850510294085		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.023330850510294085 | validation: 0.0482172931635198]
	TIME [epoch: 5.7 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022625832792160634		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.022625832792160634 | validation: 0.03633260297460934]
	TIME [epoch: 5.72 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02357224912842073		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.02357224912842073 | validation: 0.03316261294935492]
	TIME [epoch: 5.71 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024233281278767456		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.024233281278767456 | validation: 0.032202548109806765]
	TIME [epoch: 5.7 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023982924658729757		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.023982924658729757 | validation: 0.030925720076051384]
	TIME [epoch: 5.7 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020320118806695646		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.020320118806695646 | validation: 0.03143087588067816]
	TIME [epoch: 5.7 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021840656257104844		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.021840656257104844 | validation: 0.03522786399786078]
	TIME [epoch: 5.7 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021259618005428225		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.021259618005428225 | validation: 0.04313837162796372]
	TIME [epoch: 5.7 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02149170563622637		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.02149170563622637 | validation: 0.030875840247446284]
	TIME [epoch: 5.73 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023259451448774338		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.023259451448774338 | validation: 0.03294832952154812]
	TIME [epoch: 5.7 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024805875987307085		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.024805875987307085 | validation: 0.0400578694808409]
	TIME [epoch: 5.7 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022743262002762454		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.022743262002762454 | validation: 0.03319469530917695]
	TIME [epoch: 5.7 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02219426090791924		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.02219426090791924 | validation: 0.038113410600354045]
	TIME [epoch: 5.7 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023938079061096306		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.023938079061096306 | validation: 0.023804500602237787]
	TIME [epoch: 5.7 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02547410004608169		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.02547410004608169 | validation: 0.02328856600867421]
	TIME [epoch: 5.72 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025198966295145824		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.025198966295145824 | validation: 0.03845154518423273]
	TIME [epoch: 5.71 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02616266239915505		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.02616266239915505 | validation: 0.030880578945772643]
	TIME [epoch: 5.7 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025563939353187543		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.025563939353187543 | validation: 0.02402403855290726]
	TIME [epoch: 5.7 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021057905680708297		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.021057905680708297 | validation: 0.03355683929087799]
	TIME [epoch: 5.7 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02199198624236694		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.02199198624236694 | validation: 0.03808391189473022]
	TIME [epoch: 5.7 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021234554944498583		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.021234554944498583 | validation: 0.03458196313198813]
	TIME [epoch: 5.7 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021581890729141216		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.021581890729141216 | validation: 0.03481107298581927]
	TIME [epoch: 5.74 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020449451143895035		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.020449451143895035 | validation: 0.036852905802854434]
	TIME [epoch: 5.7 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022488230174384304		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.022488230174384304 | validation: 0.03499259450994901]
	TIME [epoch: 5.7 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022322686955813582		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.022322686955813582 | validation: 0.027353602331497175]
	TIME [epoch: 5.7 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02592407590828468		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.02592407590828468 | validation: 0.02838986444032779]
	TIME [epoch: 5.7 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023568597216618012		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.023568597216618012 | validation: 0.03503042674014042]
	TIME [epoch: 5.7 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02323421715593051		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.02323421715593051 | validation: 0.026886735736167698]
	TIME [epoch: 5.72 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025027202406650118		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.025027202406650118 | validation: 0.030576062145736504]
	TIME [epoch: 5.71 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020313390538538742		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.020313390538538742 | validation: 0.03022034398468536]
	TIME [epoch: 5.7 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025400778580417067		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.025400778580417067 | validation: 0.03216481865931581]
	TIME [epoch: 5.7 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024700779795280417		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.024700779795280417 | validation: 0.03964772440401372]
	TIME [epoch: 5.7 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021711879995916117		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.021711879995916117 | validation: 0.024157124228612645]
	TIME [epoch: 5.7 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022840057191547584		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.022840057191547584 | validation: 0.0362848393585579]
	TIME [epoch: 5.7 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027488574539266338		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.027488574539266338 | validation: 0.032632340584125404]
	TIME [epoch: 5.74 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024460337194838984		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.024460337194838984 | validation: 0.0344849556899761]
	TIME [epoch: 5.7 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024848947228443254		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.024848947228443254 | validation: 0.031451324985245756]
	TIME [epoch: 5.7 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021562570998476038		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.021562570998476038 | validation: 0.0352851800648623]
	TIME [epoch: 5.7 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022637857039037215		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.022637857039037215 | validation: 0.0311242198710917]
	TIME [epoch: 5.7 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02403537451908116		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.02403537451908116 | validation: 0.030995891870040163]
	TIME [epoch: 5.7 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021559260160824566		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.021559260160824566 | validation: 0.03705002959176]
	TIME [epoch: 5.72 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02261580388048911		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.02261580388048911 | validation: 0.03213920845668194]
	TIME [epoch: 5.71 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021162512428014205		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.021162512428014205 | validation: 0.038403805048686575]
	TIME [epoch: 5.7 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023692451682694706		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.023692451682694706 | validation: 0.03910657134038722]
	TIME [epoch: 5.7 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01899159997938777		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.01899159997938777 | validation: 0.033671508734757216]
	TIME [epoch: 5.7 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02327557249952173		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.02327557249952173 | validation: 0.03820109800685419]
	TIME [epoch: 5.7 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0241717760493064		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.0241717760493064 | validation: 0.027650204460135535]
	TIME [epoch: 5.7 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022946857452207356		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.022946857452207356 | validation: 0.03719094006928985]
	TIME [epoch: 5.73 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02610823788238894		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.02610823788238894 | validation: 0.0272135533489975]
	TIME [epoch: 5.7 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021375233170906366		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.021375233170906366 | validation: 0.028338435143576906]
	TIME [epoch: 5.7 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023743133630760863		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.023743133630760863 | validation: 0.025303420023985296]
	TIME [epoch: 5.7 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024741955382835266		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.024741955382835266 | validation: 0.02849769320347371]
	TIME [epoch: 5.7 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023396520800766707		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.023396520800766707 | validation: 0.036066924182521796]
	TIME [epoch: 5.7 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023051888220633115		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.023051888220633115 | validation: 0.03350776711639628]
	TIME [epoch: 5.72 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0246704690719322		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.0246704690719322 | validation: 0.029269788102976514]
	TIME [epoch: 5.71 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023322432508013614		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.023322432508013614 | validation: 0.02920891042559927]
	TIME [epoch: 5.7 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026887809135147964		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.026887809135147964 | validation: 0.03251830432765411]
	TIME [epoch: 5.7 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02215327458683198		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.02215327458683198 | validation: 0.04044289986814147]
	TIME [epoch: 5.7 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022679288221802554		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.022679288221802554 | validation: 0.027100704284696134]
	TIME [epoch: 5.7 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025243524933992546		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.025243524933992546 | validation: 0.04324235787160439]
	TIME [epoch: 5.7 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02383325505868279		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.02383325505868279 | validation: 0.04196250198314643]
	TIME [epoch: 5.74 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022533404776237973		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.022533404776237973 | validation: 0.0391547178377324]
	TIME [epoch: 5.7 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02258482149412383		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.02258482149412383 | validation: 0.03679270840768783]
	TIME [epoch: 5.7 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025699328750691225		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.025699328750691225 | validation: 0.03994009802505524]
	TIME [epoch: 5.7 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020497469377155398		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.020497469377155398 | validation: 0.0340339920169883]
	TIME [epoch: 5.7 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025612969878935247		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.025612969878935247 | validation: 0.032651513128681746]
	TIME [epoch: 5.7 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02060758674587481		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.02060758674587481 | validation: 0.03159496542811304]
	TIME [epoch: 5.72 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026915012064574147		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.026915012064574147 | validation: 0.041217609414286635]
	TIME [epoch: 5.71 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022978137308242427		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.022978137308242427 | validation: 0.034902025390069466]
	TIME [epoch: 5.7 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02834599872055893		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.02834599872055893 | validation: 0.0402924486842438]
	TIME [epoch: 5.7 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024159482204280304		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.024159482204280304 | validation: 0.038193881165995085]
	TIME [epoch: 5.7 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02534369086087156		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.02534369086087156 | validation: 0.03109066852586519]
	TIME [epoch: 5.7 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026489978508892204		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.026489978508892204 | validation: 0.028224952805372832]
	TIME [epoch: 5.7 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022727901515286978		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.022727901515286978 | validation: 0.03320855529896213]
	TIME [epoch: 5.73 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021487982652216315		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.021487982652216315 | validation: 0.038002660425575804]
	TIME [epoch: 5.7 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021926631147079732		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.021926631147079732 | validation: 0.03585053341224754]
	TIME [epoch: 5.7 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027762329485490636		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.027762329485490636 | validation: 0.038954975517100594]
	TIME [epoch: 5.7 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029148041657125277		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.029148041657125277 | validation: 0.03310466950982456]
	TIME [epoch: 5.7 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021184686179803628		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.021184686179803628 | validation: 0.0325240278883585]
	TIME [epoch: 5.7 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021301110876960492		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.021301110876960492 | validation: 0.031826506454200695]
	TIME [epoch: 5.72 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024186638764446825		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.024186638764446825 | validation: 0.03294800944623105]
	TIME [epoch: 5.71 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024261280931761345		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.024261280931761345 | validation: 0.035468011196068135]
	TIME [epoch: 5.7 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020897263449889063		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.020897263449889063 | validation: 0.040126031370443564]
	TIME [epoch: 5.7 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02150989330194418		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.02150989330194418 | validation: 0.03393163038764649]
	TIME [epoch: 5.7 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02420732585161438		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.02420732585161438 | validation: 0.038832912131285736]
	TIME [epoch: 5.7 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025218942391868178		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.025218942391868178 | validation: 0.030257562781900126]
	TIME [epoch: 5.7 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026234361688977522		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.026234361688977522 | validation: 0.036157991171168684]
	TIME [epoch: 5.74 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021807967345499397		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.021807967345499397 | validation: 0.029860122359670647]
	TIME [epoch: 5.7 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023892216227712534		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.023892216227712534 | validation: 0.046488849515376456]
	TIME [epoch: 5.7 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026481550741225046		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.026481550741225046 | validation: 0.04192021083821512]
	TIME [epoch: 5.7 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026148908063417305		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.026148908063417305 | validation: 0.026540998987264565]
	TIME [epoch: 5.7 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02322454123837474		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.02322454123837474 | validation: 0.028752259359976048]
	TIME [epoch: 5.7 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022413986597260453		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.022413986597260453 | validation: 0.032812619329761664]
	TIME [epoch: 5.71 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02365315377359317		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.02365315377359317 | validation: 0.03539952570617774]
	TIME [epoch: 5.72 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019319645194193075		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.019319645194193075 | validation: 0.03484776384410279]
	TIME [epoch: 5.7 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022497797980068502		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.022497797980068502 | validation: 0.030448716500337127]
	TIME [epoch: 5.7 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024647598595895416		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.024647598595895416 | validation: 0.03590352299900929]
	TIME [epoch: 5.7 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024943618955533535		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.024943618955533535 | validation: 0.03604560580803234]
	TIME [epoch: 5.7 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023202528957049013		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.023202528957049013 | validation: 0.03087890146575385]
	TIME [epoch: 5.7 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02224318416182067		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.02224318416182067 | validation: 0.04013809996775065]
	TIME [epoch: 5.73 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02583788730014331		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.02583788730014331 | validation: 0.0246973032980538]
	TIME [epoch: 5.7 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0236679288432878		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.0236679288432878 | validation: 0.034194692212563715]
	TIME [epoch: 5.7 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0258782906145982		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.0258782906145982 | validation: 0.03473581315301162]
	TIME [epoch: 5.7 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025370552120158554		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.025370552120158554 | validation: 0.029013906761819256]
	TIME [epoch: 5.7 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0229503056859213		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.0229503056859213 | validation: 0.03359304253457152]
	TIME [epoch: 5.7 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02232764051316135		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.02232764051316135 | validation: 0.03135157962755209]
	TIME [epoch: 5.71 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02789147948938809		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.02789147948938809 | validation: 0.03335802847285193]
	TIME [epoch: 5.73 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022393065816463945		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.022393065816463945 | validation: 0.03807158073774965]
	TIME [epoch: 5.7 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022991875399097868		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.022991875399097868 | validation: 0.03775363592648197]
	TIME [epoch: 5.7 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024275248457593317		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.024275248457593317 | validation: 0.039540550882737585]
	TIME [epoch: 5.7 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024907224459310793		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.024907224459310793 | validation: 0.02941418706685498]
	TIME [epoch: 5.7 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02680358179303014		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.02680358179303014 | validation: 0.02822956496186893]
	TIME [epoch: 5.7 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022863853983279635		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.022863853983279635 | validation: 0.03659137405538435]
	TIME [epoch: 5.73 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022854031377319263		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.022854031377319263 | validation: 0.033943560677084476]
	TIME [epoch: 5.7 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02589989875741167		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.02589989875741167 | validation: 0.029897887088526948]
	TIME [epoch: 5.7 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0267419837639894		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.0267419837639894 | validation: 0.03160000965652056]
	TIME [epoch: 5.7 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019555299724960194		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.019555299724960194 | validation: 0.03031854359203231]
	TIME [epoch: 5.7 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02202072905368359		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.02202072905368359 | validation: 0.04760922998484016]
	TIME [epoch: 5.7 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023585822387361118		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.023585822387361118 | validation: 0.03019360107990073]
	TIME [epoch: 5.71 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02454165878572622		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.02454165878572622 | validation: 0.03229894347027185]
	TIME [epoch: 5.72 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027920946451661897		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.027920946451661897 | validation: 0.030837808605088696]
	TIME [epoch: 5.7 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02340476922505515		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.02340476922505515 | validation: 0.03483692022266672]
	TIME [epoch: 5.7 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023439740293971653		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.023439740293971653 | validation: 0.03288101493954319]
	TIME [epoch: 5.7 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028063129978239832		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.028063129978239832 | validation: 0.035699018929952885]
	TIME [epoch: 5.7 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025471331435568782		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.025471331435568782 | validation: 0.036272255235364245]
	TIME [epoch: 5.7 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02583180400519429		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.02583180400519429 | validation: 0.032104885246773684]
	TIME [epoch: 5.73 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0247717203640272		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.0247717203640272 | validation: 0.02921564775188961]
	TIME [epoch: 5.7 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02252452222449508		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.02252452222449508 | validation: 0.027255584935797304]
	TIME [epoch: 5.7 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024860682515391475		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.024860682515391475 | validation: 0.03326748138922013]
	TIME [epoch: 5.7 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019398760067631585		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.019398760067631585 | validation: 0.041582716323691864]
	TIME [epoch: 5.7 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026273689540435137		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.026273689540435137 | validation: 0.03809999547117881]
	TIME [epoch: 5.7 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024854216226420235		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.024854216226420235 | validation: 0.032123386397569724]
	TIME [epoch: 5.71 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021936118922546426		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.021936118922546426 | validation: 0.03232637201608186]
	TIME [epoch: 5.72 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024641700370729692		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.024641700370729692 | validation: 0.030633540373009416]
	TIME [epoch: 5.7 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025184968912991337		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.025184968912991337 | validation: 0.043363815474271726]
	TIME [epoch: 5.7 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01979581671437203		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.01979581671437203 | validation: 0.02625667808881477]
	TIME [epoch: 5.7 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02167701187063497		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.02167701187063497 | validation: 0.036399675031510155]
	TIME [epoch: 5.7 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024587763088375555		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.024587763088375555 | validation: 0.02865080992688475]
	TIME [epoch: 5.7 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020480236805711056		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.020480236805711056 | validation: 0.035818694155457534]
	TIME [epoch: 6 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02295941673061848		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.02295941673061848 | validation: 0.0356928016440782]
	TIME [epoch: 5.71 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023849673777787107		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.023849673777787107 | validation: 0.034098817755744845]
	TIME [epoch: 5.7 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024494161457378035		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.024494161457378035 | validation: 0.031601742517758144]
	TIME [epoch: 5.7 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021570772158842295		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.021570772158842295 | validation: 0.03405680694013967]
	TIME [epoch: 5.7 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024323345438828622		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.024323345438828622 | validation: 0.03549920692543519]
	TIME [epoch: 5.7 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02591634498470409		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.02591634498470409 | validation: 0.033918764249243186]
	TIME [epoch: 5.71 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02110300068965898		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.02110300068965898 | validation: 0.036091554908408645]
	TIME [epoch: 5.73 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021224716321300692		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.021224716321300692 | validation: 0.026102350448818614]
	TIME [epoch: 5.7 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024962031692800205		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.024962031692800205 | validation: 0.03749350294876884]
	TIME [epoch: 5.7 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024713607063577704		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.024713607063577704 | validation: 0.03530929576083773]
	TIME [epoch: 5.7 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02213125704010091		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.02213125704010091 | validation: 0.03881477025865662]
	TIME [epoch: 5.7 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025903594306979614		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.025903594306979614 | validation: 0.032950190698089625]
	TIME [epoch: 5.7 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024733752331132904		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.024733752331132904 | validation: 0.03904042716104632]
	TIME [epoch: 5.74 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02357641703335289		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.02357641703335289 | validation: 0.0374442156396613]
	TIME [epoch: 5.71 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021245645330108368		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.021245645330108368 | validation: 0.027563144605196887]
	TIME [epoch: 5.7 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02281541668020845		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.02281541668020845 | validation: 0.032038514911319406]
	TIME [epoch: 5.7 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023908449841744964		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.023908449841744964 | validation: 0.029181400695345083]
	TIME [epoch: 5.7 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023504070603799644		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.023504070603799644 | validation: 0.029240310490919814]
	TIME [epoch: 5.7 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023661046444556775		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.023661046444556775 | validation: 0.03135035149557711]
	TIME [epoch: 5.71 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02124744182976686		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.02124744182976686 | validation: 0.029340478857935177]
	TIME [epoch: 5.73 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025530654779286177		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.025530654779286177 | validation: 0.03020361471885977]
	TIME [epoch: 5.7 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027225148613051846		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.027225148613051846 | validation: 0.03126924209589888]
	TIME [epoch: 5.7 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024718701783764032		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.024718701783764032 | validation: 0.03753533471183177]
	TIME [epoch: 5.7 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01967342866114372		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.01967342866114372 | validation: 0.03438013893150699]
	TIME [epoch: 5.7 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02408107413204219		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.02408107413204219 | validation: 0.03639954153131322]
	TIME [epoch: 5.7 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023366167763673104		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.023366167763673104 | validation: 0.03660854288042713]
	TIME [epoch: 5.73 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023036285501285586		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.023036285501285586 | validation: 0.02950760688424614]
	TIME [epoch: 5.7 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022466468562056387		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.022466468562056387 | validation: 0.034620393053474245]
	TIME [epoch: 5.7 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021669024454430887		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.021669024454430887 | validation: 0.03592083120096858]
	TIME [epoch: 5.7 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020125932545340404		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.020125932545340404 | validation: 0.028810407881855182]
	TIME [epoch: 5.7 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02414391600264025		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.02414391600264025 | validation: 0.03936176491886901]
	TIME [epoch: 5.7 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023399001445040722		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.023399001445040722 | validation: 0.027754139178312546]
	TIME [epoch: 5.71 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021147743156367523		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.021147743156367523 | validation: 0.03047256221807651]
	TIME [epoch: 5.73 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02301933449822599		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.02301933449822599 | validation: 0.03028483098623271]
	TIME [epoch: 5.7 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025310443777712348		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.025310443777712348 | validation: 0.03353593676011001]
	TIME [epoch: 5.7 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022310970980588585		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.022310970980588585 | validation: 0.03669567198489193]
	TIME [epoch: 5.7 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02415719361004776		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.02415719361004776 | validation: 0.029657623713264903]
	TIME [epoch: 5.7 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023713790818590826		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.023713790818590826 | validation: 0.028866724895547053]
	TIME [epoch: 5.7 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024247329647089172		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.024247329647089172 | validation: 0.029792342602523378]
	TIME [epoch: 5.74 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022218943894648402		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.022218943894648402 | validation: 0.027982864673443197]
	TIME [epoch: 5.71 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0199080394525959		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.0199080394525959 | validation: 0.029508602292580368]
	TIME [epoch: 5.7 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020546621156740556		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.020546621156740556 | validation: 0.03057880754803628]
	TIME [epoch: 5.7 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021493871224428484		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.021493871224428484 | validation: 0.025328593508659705]
	TIME [epoch: 5.7 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021560966287361708		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.021560966287361708 | validation: 0.029964210915326483]
	TIME [epoch: 5.7 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022618531796216337		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.022618531796216337 | validation: 0.030147478035169657]
	TIME [epoch: 5.71 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021348484317061857		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.021348484317061857 | validation: 0.0316851205602031]
	TIME [epoch: 5.73 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022163874204970423		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.022163874204970423 | validation: 0.02583399185566334]
	TIME [epoch: 5.7 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02443222137949331		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.02443222137949331 | validation: 0.027605296202092594]
	TIME [epoch: 5.7 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0235890121727975		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.0235890121727975 | validation: 0.034584345939062885]
	TIME [epoch: 5.7 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018658807572667552		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.018658807572667552 | validation: 0.03928332177398576]
	TIME [epoch: 5.7 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02618940017557149		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.02618940017557149 | validation: 0.03184030587966441]
	TIME [epoch: 5.7 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021862725457516406		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.021862725457516406 | validation: 0.03506745997877093]
	TIME [epoch: 5.74 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021986368569674775		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.021986368569674775 | validation: 0.034547637154395065]
	TIME [epoch: 5.71 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02008113225595263		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.02008113225595263 | validation: 0.03493401137994855]
	TIME [epoch: 5.7 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024735685448906614		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.024735685448906614 | validation: 0.03067371693931017]
	TIME [epoch: 5.7 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021195200476226493		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.021195200476226493 | validation: 0.030244601136532632]
	TIME [epoch: 5.7 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02146044866293038		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.02146044866293038 | validation: 0.030428225475769042]
	TIME [epoch: 5.7 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023312774629952206		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.023312774629952206 | validation: 0.030896826098271477]
	TIME [epoch: 5.72 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024436543650284255		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.024436543650284255 | validation: 0.039486889253210075]
	TIME [epoch: 5.73 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02545406722251886		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.02545406722251886 | validation: 0.02988683276844058]
	TIME [epoch: 5.71 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022516451687182144		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.022516451687182144 | validation: 0.022812848788820922]
	TIME [epoch: 5.7 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02234085969828357		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.02234085969828357 | validation: 0.03530163993942176]
	TIME [epoch: 5.7 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02213521150107193		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.02213521150107193 | validation: 0.029909885187315535]
	TIME [epoch: 5.71 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021641447734624123		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.021641447734624123 | validation: 0.037013189348995265]
	TIME [epoch: 5.7 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022063200494817248		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.022063200494817248 | validation: 0.036134411739276166]
	TIME [epoch: 5.74 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023710091441794555		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.023710091441794555 | validation: 0.026453412894723246]
	TIME [epoch: 5.71 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022340406436502355		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.022340406436502355 | validation: 0.0282963653661052]
	TIME [epoch: 5.71 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02331795187854052		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.02331795187854052 | validation: 0.029996437301038403]
	TIME [epoch: 5.71 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0226202139016711		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.0226202139016711 | validation: 0.028085905771267128]
	TIME [epoch: 5.7 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020764123407515836		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.020764123407515836 | validation: 0.03186564618766033]
	TIME [epoch: 5.7 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022641779584932575		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.022641779584932575 | validation: 0.03018978523326909]
	TIME [epoch: 5.71 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020695947761276083		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.020695947761276083 | validation: 0.030525746246232215]
	TIME [epoch: 5.73 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02348296772560703		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.02348296772560703 | validation: 0.03138378457637959]
	TIME [epoch: 5.71 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023785297814854944		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.023785297814854944 | validation: 0.04181804324241374]
	TIME [epoch: 5.7 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027384283983947797		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.027384283983947797 | validation: 0.030043498703163897]
	TIME [epoch: 5.71 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022089914920892663		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.022089914920892663 | validation: 0.03196040911644746]
	TIME [epoch: 5.7 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024151526622498757		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.024151526622498757 | validation: 0.032726726799341264]
	TIME [epoch: 5.71 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02511597548736378		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.02511597548736378 | validation: 0.032477765509509156]
	TIME [epoch: 5.74 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022563603024037746		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.022563603024037746 | validation: 0.027472770175301166]
	TIME [epoch: 5.71 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022024741468685844		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.022024741468685844 | validation: 0.03579815837660967]
	TIME [epoch: 5.7 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024485592371070786		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.024485592371070786 | validation: 0.029084666000446627]
	TIME [epoch: 5.7 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02198962121334792		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.02198962121334792 | validation: 0.02179742193852054]
	TIME [epoch: 5.7 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023692115002693845		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.023692115002693845 | validation: 0.028167083452218415]
	TIME [epoch: 5.7 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027685842050706403		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.027685842050706403 | validation: 0.03454282521783654]
	TIME [epoch: 5.71 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021037259488827877		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.021037259488827877 | validation: 0.027316426755171687]
	TIME [epoch: 5.73 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02370952158799052		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.02370952158799052 | validation: 0.03080070692465173]
	TIME [epoch: 5.71 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021401045914513417		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.021401045914513417 | validation: 0.03195026899717792]
	TIME [epoch: 5.71 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023840949593016664		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.023840949593016664 | validation: 0.037763167908288126]
	TIME [epoch: 5.7 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026105476239607066		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.026105476239607066 | validation: 0.03348091324664225]
	TIME [epoch: 5.71 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020898932816655363		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.020898932816655363 | validation: 0.03793625818890296]
	TIME [epoch: 5.7 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02384178378838749		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.02384178378838749 | validation: 0.03340665073741006]
	TIME [epoch: 5.74 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023685715402990495		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.023685715402990495 | validation: 0.03316054804589168]
	TIME [epoch: 5.71 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026536213170271362		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.026536213170271362 | validation: 0.03203440402559282]
	TIME [epoch: 5.7 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023258910756286572		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.023258910756286572 | validation: 0.03672736971870513]
	TIME [epoch: 5.7 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026163926588122145		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.026163926588122145 | validation: 0.03808110553630833]
	TIME [epoch: 5.7 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023932538880059317		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.023932538880059317 | validation: 0.035248990790927186]
	TIME [epoch: 5.7 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02173900018660075		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.02173900018660075 | validation: 0.0308921456545085]
	TIME [epoch: 5.72 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02373687710212549		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.02373687710212549 | validation: 0.027701659420085928]
	TIME [epoch: 5.73 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024748096303851278		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.024748096303851278 | validation: 0.031491148575810736]
	TIME [epoch: 5.7 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026898241618660914		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.026898241618660914 | validation: 0.028892251640299703]
	TIME [epoch: 5.7 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02478428528943783		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.02478428528943783 | validation: 0.029989200199299557]
	TIME [epoch: 5.7 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023307082685447678		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.023307082685447678 | validation: 0.032524887740588565]
	TIME [epoch: 5.7 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020806778562882315		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.020806778562882315 | validation: 0.031017750283084348]
	TIME [epoch: 5.7 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02313944198806784		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.02313944198806784 | validation: 0.03253763377726706]
	TIME [epoch: 5.74 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025777954379547805		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.025777954379547805 | validation: 0.03113210634364803]
	TIME [epoch: 5.71 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01831955266787807		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.01831955266787807 | validation: 0.030221019246497238]
	TIME [epoch: 5.7 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025524040143241826		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.025524040143241826 | validation: 0.032780342401105375]
	TIME [epoch: 5.7 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019076834830762696		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.019076834830762696 | validation: 0.033452368373623115]
	TIME [epoch: 5.7 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023087545291697445		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.023087545291697445 | validation: 0.038398847048358914]
	TIME [epoch: 5.7 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022600584916459623		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.022600584916459623 | validation: 0.02791304821101754]
	TIME [epoch: 5.71 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024454862631607482		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.024454862631607482 | validation: 0.0348044346057139]
	TIME [epoch: 5.73 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02189683346811508		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.02189683346811508 | validation: 0.04163290591438378]
	TIME [epoch: 5.71 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023817302405830503		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.023817302405830503 | validation: 0.028459447405484728]
	TIME [epoch: 5.7 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02390603336754501		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.02390603336754501 | validation: 0.025866964364008982]
	TIME [epoch: 5.7 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020309460222502726		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.020309460222502726 | validation: 0.02997250342039684]
	TIME [epoch: 5.7 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025549022633276082		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.025549022633276082 | validation: 0.033929296720747015]
	TIME [epoch: 5.7 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02114019190963901		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.02114019190963901 | validation: 0.029365843391890183]
	TIME [epoch: 5.74 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0226192859882269		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.0226192859882269 | validation: 0.02839838163130163]
	TIME [epoch: 5.71 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02397129658699028		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.02397129658699028 | validation: 0.032529486032173004]
	TIME [epoch: 5.7 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02094911843275902		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.02094911843275902 | validation: 0.03314230366164469]
	TIME [epoch: 5.71 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026394181581297905		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.026394181581297905 | validation: 0.032606633958773674]
	TIME [epoch: 5.7 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02481988593061343		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.02481988593061343 | validation: 0.0407694689148663]
	TIME [epoch: 5.7 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028452309977898424		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.028452309977898424 | validation: 0.031006696062039225]
	TIME [epoch: 5.71 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022940908081881442		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.022940908081881442 | validation: 0.03598116359578977]
	TIME [epoch: 5.73 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02272943359547016		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.02272943359547016 | validation: 0.03018176554782618]
	TIME [epoch: 5.71 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024595203670249758		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.024595203670249758 | validation: 0.03196984652964456]
	TIME [epoch: 5.7 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02460046478373859		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.02460046478373859 | validation: 0.028962211783918824]
	TIME [epoch: 5.7 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025283455617938322		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.025283455617938322 | validation: 0.03206116571234078]
	TIME [epoch: 5.7 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024588677808661766		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.024588677808661766 | validation: 0.03751370981563002]
	TIME [epoch: 5.7 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02279994307438473		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.02279994307438473 | validation: 0.0324524178925164]
	TIME [epoch: 5.74 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022444884927287707		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.022444884927287707 | validation: 0.031614093891315004]
	TIME [epoch: 5.71 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02049053790652399		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.02049053790652399 | validation: 0.026132791416963112]
	TIME [epoch: 5.7 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024000472152926517		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.024000472152926517 | validation: 0.030171348888928317]
	TIME [epoch: 5.7 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026439524637428068		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.026439524637428068 | validation: 0.030841238117757186]
	TIME [epoch: 5.7 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02253763947897075		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.02253763947897075 | validation: 0.03603831266955039]
	TIME [epoch: 5.7 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01977808017042198		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.01977808017042198 | validation: 0.031433238150627416]
	TIME [epoch: 5.71 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02098003108193268		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.02098003108193268 | validation: 0.031441055899382245]
	TIME [epoch: 5.73 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02236179568724987		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.02236179568724987 | validation: 0.034896722386920286]
	TIME [epoch: 5.71 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023581302104340448		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.023581302104340448 | validation: 0.030091003505378237]
	TIME [epoch: 5.7 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023549768319923847		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.023549768319923847 | validation: 0.027734869361560034]
	TIME [epoch: 5.7 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022232348744174662		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.022232348744174662 | validation: 0.03258043954395884]
	TIME [epoch: 5.7 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020772572829524966		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.020772572829524966 | validation: 0.02734999610871256]
	TIME [epoch: 5.7 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022950684155551515		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.022950684155551515 | validation: 0.03146628123052661]
	TIME [epoch: 5.74 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024419523343357983		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.024419523343357983 | validation: 0.032629187634759124]
	TIME [epoch: 5.71 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022311472877230582		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.022311472877230582 | validation: 0.03425845051843919]
	TIME [epoch: 5.71 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023255537467764563		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.023255537467764563 | validation: 0.032610633543021]
	TIME [epoch: 5.71 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024907550043588425		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.024907550043588425 | validation: 0.02749807493941158]
	TIME [epoch: 5.7 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025294744454356755		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.025294744454356755 | validation: 0.02663432149157474]
	TIME [epoch: 5.7 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023253945196992604		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.023253945196992604 | validation: 0.03810656476101619]
	TIME [epoch: 5.71 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019505641452195653		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.019505641452195653 | validation: 0.037351156638716826]
	TIME [epoch: 5.73 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022087877313932466		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.022087877313932466 | validation: 0.027272169400935714]
	TIME [epoch: 5.71 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020974693135467074		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.020974693135467074 | validation: 0.031211043430859117]
	TIME [epoch: 5.71 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02275908058783892		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.02275908058783892 | validation: 0.0323483755951963]
	TIME [epoch: 5.7 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02465536312316349		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.02465536312316349 | validation: 0.031741008892839755]
	TIME [epoch: 5.7 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02413121730522262		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.02413121730522262 | validation: 0.033623521252755445]
	TIME [epoch: 5.7 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02360885834733464		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.02360885834733464 | validation: 0.0312379927023463]
	TIME [epoch: 5.74 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023017572353009486		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.023017572353009486 | validation: 0.02763642365862651]
	TIME [epoch: 5.71 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02345901674682936		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.02345901674682936 | validation: 0.03395676127033399]
	TIME [epoch: 5.71 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025709745252222332		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.025709745252222332 | validation: 0.03593256187627831]
	TIME [epoch: 5.71 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02707302477905586		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.02707302477905586 | validation: 0.03250896033046501]
	TIME [epoch: 5.7 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02425808336761196		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.02425808336761196 | validation: 0.031007830762880804]
	TIME [epoch: 5.7 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027037724473380927		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.027037724473380927 | validation: 0.0354492458050649]
	TIME [epoch: 5.71 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0203825626666387		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.0203825626666387 | validation: 0.025580806733608012]
	TIME [epoch: 5.73 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02431181132865267		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.02431181132865267 | validation: 0.03080317565348195]
	TIME [epoch: 5.71 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0238002474533046		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.0238002474533046 | validation: 0.028605105626028783]
	TIME [epoch: 5.71 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023145352186717684		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.023145352186717684 | validation: 0.0410811293907816]
	TIME [epoch: 5.71 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02308636180330539		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.02308636180330539 | validation: 0.02689106362762922]
	TIME [epoch: 5.7 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02038206512506998		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.02038206512506998 | validation: 0.03272860869265564]
	TIME [epoch: 5.7 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022498433558931094		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.022498433558931094 | validation: 0.03716362477938337]
	TIME [epoch: 5.73 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022954894675614516		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.022954894675614516 | validation: 0.035291609760280965]
	TIME [epoch: 5.72 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02264772212921328		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.02264772212921328 | validation: 0.037203375824523696]
	TIME [epoch: 5.71 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02551963087128189		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.02551963087128189 | validation: 0.021356099356344287]
	TIME [epoch: 5.71 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021647730239618804		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.021647730239618804 | validation: 0.02668001782641438]
	TIME [epoch: 5.7 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022318701391560402		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.022318701391560402 | validation: 0.03386690070911571]
	TIME [epoch: 5.7 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023470715788554586		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.023470715788554586 | validation: 0.03197893801910244]
	TIME [epoch: 5.71 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025736430435287155		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.025736430435287155 | validation: 0.036531393685368264]
	TIME [epoch: 5.74 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02555575026802473		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.02555575026802473 | validation: 0.03697548478211618]
	TIME [epoch: 5.71 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021229172433648403		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.021229172433648403 | validation: 0.027934052949404212]
	TIME [epoch: 5.7 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02466080274386271		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.02466080274386271 | validation: 0.03657067669052754]
	TIME [epoch: 5.7 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022112455940732707		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.022112455940732707 | validation: 0.027482413186611057]
	TIME [epoch: 5.71 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020491168912144968		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.020491168912144968 | validation: 0.03181981998591194]
	TIME [epoch: 5.7 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02409947463912539		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.02409947463912539 | validation: 0.03613548397111422]
	TIME [epoch: 5.73 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023349448229578493		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.023349448229578493 | validation: 0.037746741713343634]
	TIME [epoch: 5.71 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020469097927643443		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.020469097927643443 | validation: 0.026527969992324495]
	TIME [epoch: 5.7 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025470761475379283		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.025470761475379283 | validation: 0.032093261047236095]
	TIME [epoch: 5.7 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022046635657121044		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.022046635657121044 | validation: 0.033164212202741315]
	TIME [epoch: 5.7 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02316247144071539		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.02316247144071539 | validation: 0.029561007206270747]
	TIME [epoch: 5.7 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02117006157806557		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.02117006157806557 | validation: 0.03688799688115781]
	TIME [epoch: 5.71 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02351001206299723		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.02351001206299723 | validation: 0.035872991294336354]
	TIME [epoch: 5.74 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02319588615649844		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.02319588615649844 | validation: 0.031480863380528155]
	TIME [epoch: 5.71 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025245550291997675		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.025245550291997675 | validation: 0.033061823334332635]
	TIME [epoch: 5.71 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02464756454577155		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.02464756454577155 | validation: 0.026421942174344046]
	TIME [epoch: 5.7 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02201953634084388		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.02201953634084388 | validation: 0.03491631495361934]
	TIME [epoch: 5.7 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023514110755260345		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.023514110755260345 | validation: 0.028998568569594544]
	TIME [epoch: 5.7 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0210328996545674		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.0210328996545674 | validation: 0.02706287698721129]
	TIME [epoch: 5.73 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022821828310300184		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.022821828310300184 | validation: 0.03552512280176424]
	TIME [epoch: 5.71 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02246023885482286		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.02246023885482286 | validation: 0.036624382746172586]
	TIME [epoch: 5.7 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02047111798656147		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.02047111798656147 | validation: 0.030022684141749866]
	TIME [epoch: 5.7 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022619310343113833		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.022619310343113833 | validation: 0.030063911784752106]
	TIME [epoch: 5.7 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0228624916098471		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.0228624916098471 | validation: 0.0233860484214062]
	TIME [epoch: 5.7 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02503532686072276		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.02503532686072276 | validation: 0.0344617730364992]
	TIME [epoch: 5.71 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023791255173889622		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.023791255173889622 | validation: 0.03181995418226209]
	TIME [epoch: 5.74 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02259269034607409		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.02259269034607409 | validation: 0.034748043415003246]
	TIME [epoch: 5.71 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024410483918112052		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.024410483918112052 | validation: 0.03876373322354748]
	TIME [epoch: 5.7 sec]
Finished training in 11617.471 seconds.
