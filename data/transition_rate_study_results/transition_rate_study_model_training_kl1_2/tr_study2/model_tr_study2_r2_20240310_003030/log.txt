Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r2', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2689659260

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.094084878397824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.094084878397824 | validation: 7.223626163876402]
	TIME [epoch: 94 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6222821311152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6222821311152 | validation: 5.501390653944818]
	TIME [epoch: 5.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.442175377710732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.442175377710732 | validation: 4.446798270977378]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.782837698950376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.782837698950376 | validation: 4.101671587525605]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.541921004977635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.541921004977635 | validation: 4.091480726970335]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.219474758396801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.219474758396801 | validation: 3.4081038294534483]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6593301410600043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6593301410600043 | validation: 3.1018444312581757]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.304621465123749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.304621465123749 | validation: 3.526772751099586]
	TIME [epoch: 5.78 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.23605799962346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.23605799962346 | validation: 3.013323339034447]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0644586023639593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0644586023639593 | validation: 2.703155348303353]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8905430226449793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8905430226449793 | validation: 2.925800589047173]
	TIME [epoch: 5.75 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.913359491084834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.913359491084834 | validation: 2.4308306443353205]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1193152171127845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1193152171127845 | validation: 3.3204603816297857]
	TIME [epoch: 5.76 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7481942711323115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7481942711323115 | validation: 2.455415876017579]
	TIME [epoch: 5.78 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3499645117415193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3499645117415193 | validation: 2.147100184516473]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4793780878151255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4793780878151255 | validation: 2.757686926738784]
	TIME [epoch: 5.75 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.279243398692577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.279243398692577 | validation: 1.9522859222889708]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9824387362457516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9824387362457516 | validation: 2.1011753598341216]
	TIME [epoch: 5.74 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9652417049199278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9652417049199278 | validation: 1.9215751688774259]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0264095006063503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0264095006063503 | validation: 1.8605135850931387]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6693239824194928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6693239824194928 | validation: 2.3031930273897117]
	TIME [epoch: 5.76 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8522427754533877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8522427754533877 | validation: 1.7205317696177278]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.856030780807043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.856030780807043 | validation: 1.4502668697069414]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6153417794254572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6153417794254572 | validation: 1.5672199632091082]
	TIME [epoch: 5.75 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4634142607897491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4634142607897491 | validation: 1.277841667673722]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4160316756317841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4160316756317841 | validation: 1.684824660440614]
	TIME [epoch: 5.79 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4588566183255207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4588566183255207 | validation: 1.639939988203061]
	TIME [epoch: 5.74 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6266169923653107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6266169923653107 | validation: 1.1797037181119114]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2848240916522795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2848240916522795 | validation: 1.3403665307176547]
	TIME [epoch: 5.75 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3179776233688982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3179776233688982 | validation: 1.0503718294367437]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3324239632371728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3324239632371728 | validation: 1.0193391971404788]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.123522909259323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.123522909259323 | validation: 0.9444374689318349]
	TIME [epoch: 5.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1886695193205834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1886695193205834 | validation: 0.9735345400523496]
	TIME [epoch: 5.76 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.073835535562755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.073835535562755 | validation: 1.219409122181507]
	TIME [epoch: 5.75 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1408753550356474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1408753550356474 | validation: 0.9221556445762241]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2718424259749634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2718424259749634 | validation: 1.099043392464568]
	TIME [epoch: 5.75 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3617445882737582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3617445882737582 | validation: 1.07623736441628]
	TIME [epoch: 5.75 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1386984469089074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1386984469089074 | validation: 1.5987521555016082]
	TIME [epoch: 5.78 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2286264394439463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2286264394439463 | validation: 0.9828412856911893]
	TIME [epoch: 5.77 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0472251756886897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0472251756886897 | validation: 0.9662050671022206]
	TIME [epoch: 5.75 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0359393202721385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0359393202721385 | validation: 1.1279308204316931]
	TIME [epoch: 5.75 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1905989487988364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1905989487988364 | validation: 1.2654749841382245]
	TIME [epoch: 5.75 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1610242065513894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1610242065513894 | validation: 0.8917867145945115]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0209961517269792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0209961517269792 | validation: 1.0137634551119212]
	TIME [epoch: 5.79 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9880103417055041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9880103417055041 | validation: 0.8890206294982512]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9389604665869925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9389604665869925 | validation: 0.9052623578064005]
	TIME [epoch: 5.75 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0669847200746678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0669847200746678 | validation: 1.4182952146790513]
	TIME [epoch: 5.74 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1789121571718526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1789121571718526 | validation: 1.0267080165230713]
	TIME [epoch: 5.74 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9657662945479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9657662945479 | validation: 0.7430273634186209]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.087944251470634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.087944251470634 | validation: 0.8617941068354135]
	TIME [epoch: 5.85 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9048270359962514		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.9048270359962514 | validation: 1.0816598786797262]
	TIME [epoch: 5.75 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8971372348196199		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.8971372348196199 | validation: 2.252851504264911]
	TIME [epoch: 5.74 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2373260821911387		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.2373260821911387 | validation: 1.0602229534550087]
	TIME [epoch: 5.74 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9467686071789284		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.9467686071789284 | validation: 0.7961522470412303]
	TIME [epoch: 5.74 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.958898003148775		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.958898003148775 | validation: 0.8819942832225786]
	TIME [epoch: 5.74 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1454503902654511		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.1454503902654511 | validation: 0.8461701180011043]
	TIME [epoch: 5.79 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.837234875906998		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.837234875906998 | validation: 0.8088966168497846]
	TIME [epoch: 5.75 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9932596048920392		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.9932596048920392 | validation: 0.7366467485953417]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8554662290943739		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.8554662290943739 | validation: 1.2546193906301712]
	TIME [epoch: 5.75 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1191332381311747		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.1191332381311747 | validation: 0.7219428727150003]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1192199858507874		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.1192199858507874 | validation: 1.190022055163454]
	TIME [epoch: 5.75 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7816989565843379		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.7816989565843379 | validation: 0.8745764071792522]
	TIME [epoch: 5.78 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9692128475595603		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.9692128475595603 | validation: 0.7650505424536398]
	TIME [epoch: 5.75 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7810084385219668		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.7810084385219668 | validation: 0.6835068400582764]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7016673544277914		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.7016673544277914 | validation: 0.8774251490909575]
	TIME [epoch: 5.74 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8173038266100603		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.8173038266100603 | validation: 1.15940293943916]
	TIME [epoch: 5.74 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.876482420200341		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.876482420200341 | validation: 1.5688521827629738]
	TIME [epoch: 5.74 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9622627700156117		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.9622627700156117 | validation: 1.682893678344609]
	TIME [epoch: 5.79 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.86373472385251		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.86373472385251 | validation: 0.8977249270572312]
	TIME [epoch: 5.75 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8777310985907131		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.8777310985907131 | validation: 1.3764017603579768]
	TIME [epoch: 5.74 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.919172524093111		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.919172524093111 | validation: 1.084694400774779]
	TIME [epoch: 5.74 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8206181484026074		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.8206181484026074 | validation: 0.711843607996151]
	TIME [epoch: 5.75 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5918287179393681		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.5918287179393681 | validation: 0.583314347355925]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8534455954723092		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.8534455954723092 | validation: 1.1577958799635588]
	TIME [epoch: 5.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6790291088398591		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.6790291088398591 | validation: 1.127624387466201]
	TIME [epoch: 5.73 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8385793948961884		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.8385793948961884 | validation: 0.5169463051675013]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5597428505575615		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.5597428505575615 | validation: 1.0046980524797855]
	TIME [epoch: 6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7109808703486951		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.7109808703486951 | validation: 0.42179469644718737]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.502940208898029		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.502940208898029 | validation: 0.47005790324165364]
	TIME [epoch: 5.77 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5636059866064036		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.5636059866064036 | validation: 0.9279563892514309]
	TIME [epoch: 5.79 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6078337111482033		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.6078337111482033 | validation: 0.5856283079413734]
	TIME [epoch: 5.76 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6392481515704505		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.6392481515704505 | validation: 0.8743731067676999]
	TIME [epoch: 5.75 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7076055717439846		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.7076055717439846 | validation: 0.5508039028429204]
	TIME [epoch: 5.75 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5961744159865009		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.5961744159865009 | validation: 0.4733783549193397]
	TIME [epoch: 5.75 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4961059837127082		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.4961059837127082 | validation: 0.5485173810092971]
	TIME [epoch: 5.77 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6459264858009324		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.6459264858009324 | validation: 0.5177995867088703]
	TIME [epoch: 5.78 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5113535763864911		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.5113535763864911 | validation: 0.5092212862489568]
	TIME [epoch: 5.76 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5676184527958652		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.5676184527958652 | validation: 0.4258844032433548]
	TIME [epoch: 5.75 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6385080063183487		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.6385080063183487 | validation: 0.6358746594432575]
	TIME [epoch: 5.75 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.604865330236466		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.604865330236466 | validation: 0.5001435125544359]
	TIME [epoch: 5.75 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6043408376783632		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.6043408376783632 | validation: 0.47583310896899683]
	TIME [epoch: 5.77 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5623470268410173		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.5623470268410173 | validation: 0.7005011605540625]
	TIME [epoch: 5.79 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6306199248320044		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.6306199248320044 | validation: 0.40108839480776626]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5434263947194962		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.5434263947194962 | validation: 0.5377249848879079]
	TIME [epoch: 5.75 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6162884565210218		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.6162884565210218 | validation: 0.583143639152676]
	TIME [epoch: 5.75 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5004370332309137		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.5004370332309137 | validation: 0.6474101854227119]
	TIME [epoch: 5.75 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6108176443897948		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.6108176443897948 | validation: 0.34043454797002765]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7912437835759638		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.7912437835759638 | validation: 0.5742726731735265]
	TIME [epoch: 5.76 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5544693830478833		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.5544693830478833 | validation: 0.40102788457470795]
	TIME [epoch: 5.74 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4473935568785707		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.4473935568785707 | validation: 0.39586648083547105]
	TIME [epoch: 5.74 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5329337257212851		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.5329337257212851 | validation: 0.4148902095408842]
	TIME [epoch: 5.74 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4627268411621174		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.4627268411621174 | validation: 0.30797392206934926]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3672241892864139		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.3672241892864139 | validation: 0.42377623046944546]
	TIME [epoch: 5.77 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7653283176692285		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.7653283176692285 | validation: 0.5931632367669799]
	TIME [epoch: 5.76 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.595912985325039		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.595912985325039 | validation: 0.38501324606574844]
	TIME [epoch: 5.74 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5140899816372788		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.5140899816372788 | validation: 0.3718412801053227]
	TIME [epoch: 5.74 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6101422397795178		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.6101422397795178 | validation: 0.5524522217698603]
	TIME [epoch: 5.74 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46978106398798525		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.46978106398798525 | validation: 0.37431027244155174]
	TIME [epoch: 5.74 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6949526889713971		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.6949526889713971 | validation: 0.46586404092564965]
	TIME [epoch: 5.77 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5949852087349986		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.5949852087349986 | validation: 0.3912338377093289]
	TIME [epoch: 5.76 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47946592251535497		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.47946592251535497 | validation: 0.5287555330335859]
	TIME [epoch: 5.74 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44556249996375785		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.44556249996375785 | validation: 0.44528607349791754]
	TIME [epoch: 5.74 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49246401872646245		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.49246401872646245 | validation: 0.3273759341078681]
	TIME [epoch: 5.74 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5965252782078472		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.5965252782078472 | validation: 0.435980570862451]
	TIME [epoch: 5.74 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5013825345480698		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.5013825345480698 | validation: 0.39750034023639713]
	TIME [epoch: 5.77 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3950422048931118		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.3950422048931118 | validation: 0.9197815676992238]
	TIME [epoch: 5.76 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47819176765295934		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.47819176765295934 | validation: 0.6496019426315875]
	TIME [epoch: 5.74 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5542352575329154		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.5542352575329154 | validation: 0.45141133063407246]
	TIME [epoch: 5.74 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4335023429873011		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.4335023429873011 | validation: 0.8580556983917066]
	TIME [epoch: 5.74 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4949049026390393		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.4949049026390393 | validation: 0.36879939733045974]
	TIME [epoch: 5.74 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40377984112401943		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.40377984112401943 | validation: 0.38268963192265404]
	TIME [epoch: 5.77 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4088962540667763		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.4088962540667763 | validation: 0.6040634558447798]
	TIME [epoch: 5.76 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3992836312121168		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.3992836312121168 | validation: 0.29496105523755395]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37230159099192395		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.37230159099192395 | validation: 0.481554121785098]
	TIME [epoch: 5.74 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.919840116178617		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.919840116178617 | validation: 0.6072025275151259]
	TIME [epoch: 5.74 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42788687834286454		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.42788687834286454 | validation: 0.368786072135486]
	TIME [epoch: 5.74 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43753276035559024		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.43753276035559024 | validation: 0.38715447269321956]
	TIME [epoch: 5.77 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3799720698080568		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.3799720698080568 | validation: 0.4111864635542803]
	TIME [epoch: 5.75 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4056615357622201		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.4056615357622201 | validation: 0.34722477471468816]
	TIME [epoch: 5.74 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2733478059906306		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.2733478059906306 | validation: 0.5949055283936552]
	TIME [epoch: 5.74 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.54752316442269		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.54752316442269 | validation: 0.3067686932978731]
	TIME [epoch: 5.74 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5098442834857181		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.5098442834857181 | validation: 0.3690979589195389]
	TIME [epoch: 5.74 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.341698246035348		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.341698246035348 | validation: 0.3834480045827523]
	TIME [epoch: 5.77 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.491098923117512		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.491098923117512 | validation: 0.5053282455907626]
	TIME [epoch: 5.76 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46205277042200615		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.46205277042200615 | validation: 0.3370493138329128]
	TIME [epoch: 5.74 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3478734993259392		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.3478734993259392 | validation: 0.5984544827686192]
	TIME [epoch: 5.74 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39767429412739097		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.39767429412739097 | validation: 0.4170491807652914]
	TIME [epoch: 5.74 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37148053857885777		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.37148053857885777 | validation: 0.3775375355005193]
	TIME [epoch: 5.74 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3335045328893716		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.3335045328893716 | validation: 0.3067493136147697]
	TIME [epoch: 5.77 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3852323329150379		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.3852323329150379 | validation: 0.5144593507300856]
	TIME [epoch: 5.76 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.393944276170175		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.393944276170175 | validation: 0.305359806513567]
	TIME [epoch: 5.74 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5648440674499227		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.5648440674499227 | validation: 0.5343765202212043]
	TIME [epoch: 5.74 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37319423789827166		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.37319423789827166 | validation: 0.308771142844219]
	TIME [epoch: 5.74 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45808137201079935		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.45808137201079935 | validation: 0.5385727040010807]
	TIME [epoch: 5.74 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3382175193221013		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.3382175193221013 | validation: 0.2607276131625617]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30378356481818986		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.30378356481818986 | validation: 0.36445139870470167]
	TIME [epoch: 5.76 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36538919487089777		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.36538919487089777 | validation: 0.43152075344000096]
	TIME [epoch: 5.74 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.336125819177927		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.336125819177927 | validation: 0.9343851217233768]
	TIME [epoch: 5.74 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47732510432214437		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.47732510432214437 | validation: 0.5752341784690528]
	TIME [epoch: 5.74 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3958929598099711		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.3958929598099711 | validation: 0.2512007251166083]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2904229229658023		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.2904229229658023 | validation: 0.29166372412197983]
	TIME [epoch: 5.78 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4193046560407265		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.4193046560407265 | validation: 0.3026291820831586]
	TIME [epoch: 5.75 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3643775810244051		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.3643775810244051 | validation: 0.31081396768736846]
	TIME [epoch: 5.74 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34197185773003563		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.34197185773003563 | validation: 0.40612585254994465]
	TIME [epoch: 5.73 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3287804577686698		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.3287804577686698 | validation: 0.46246564565860854]
	TIME [epoch: 5.74 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3618470505688629		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.3618470505688629 | validation: 0.2737377305173078]
	TIME [epoch: 5.74 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27990107750371856		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.27990107750371856 | validation: 0.497326559168017]
	TIME [epoch: 5.78 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42070395979900793		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.42070395979900793 | validation: 0.2996725762551985]
	TIME [epoch: 5.75 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3757940877831981		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.3757940877831981 | validation: 0.23653271921337382]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3217783377447313		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.3217783377447313 | validation: 0.2612050585289361]
	TIME [epoch: 5.75 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2860132364230079		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.2860132364230079 | validation: 0.3205181348445331]
	TIME [epoch: 5.74 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32001227159572476		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.32001227159572476 | validation: 0.23864567883834284]
	TIME [epoch: 5.73 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32034384564829965		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.32034384564829965 | validation: 0.3744430451930105]
	TIME [epoch: 5.79 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38667049228510003		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.38667049228510003 | validation: 0.3321539611037294]
	TIME [epoch: 5.76 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.488197624969927		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.488197624969927 | validation: 0.44500651199347924]
	TIME [epoch: 5.75 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3668783429671555		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.3668783429671555 | validation: 0.41440719611092536]
	TIME [epoch: 5.74 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39166953089368217		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.39166953089368217 | validation: 0.2671426558220836]
	TIME [epoch: 5.75 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23428306808731114		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.23428306808731114 | validation: 0.2514923045049546]
	TIME [epoch: 5.74 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3463331686191134		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.3463331686191134 | validation: 0.295334298936307]
	TIME [epoch: 5.78 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34713753023831634		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.34713753023831634 | validation: 0.4389628893340089]
	TIME [epoch: 5.75 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42938075291730404		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.42938075291730404 | validation: 0.4318490851587767]
	TIME [epoch: 5.74 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.414101597698387		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.414101597698387 | validation: 0.4070320616193025]
	TIME [epoch: 5.74 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3017037959841269		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.3017037959841269 | validation: 0.39860286867106726]
	TIME [epoch: 5.74 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3787611037859895		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.3787611037859895 | validation: 0.25175120007559565]
	TIME [epoch: 5.74 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3346573748317629		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.3346573748317629 | validation: 0.3064912612877779]
	TIME [epoch: 5.79 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3935975612336745		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.3935975612336745 | validation: 0.3000874216778788]
	TIME [epoch: 5.76 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2962811279140191		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.2962811279140191 | validation: 0.3590167395511425]
	TIME [epoch: 5.74 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3076009282280334		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.3076009282280334 | validation: 0.264299804383184]
	TIME [epoch: 5.74 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24301464362309255		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.24301464362309255 | validation: 0.2983015842463134]
	TIME [epoch: 5.74 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36074915581383815		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.36074915581383815 | validation: 0.3138450137820299]
	TIME [epoch: 5.74 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.282064397259327		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.282064397259327 | validation: 0.3832253313348041]
	TIME [epoch: 5.78 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30886868698309444		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.30886868698309444 | validation: 0.2741952364200756]
	TIME [epoch: 5.75 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2999986111131433		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.2999986111131433 | validation: 0.44430756488556833]
	TIME [epoch: 5.74 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31633074493088115		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.31633074493088115 | validation: 0.29322690657280204]
	TIME [epoch: 5.74 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28022424613580665		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.28022424613580665 | validation: 0.39598030699721337]
	TIME [epoch: 5.74 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31290991900451814		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.31290991900451814 | validation: 0.21396493218399287]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3383627928498645		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.3383627928498645 | validation: 0.5521812860583845]
	TIME [epoch: 5.78 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3749952752179805		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.3749952752179805 | validation: 0.7264430268993377]
	TIME [epoch: 5.75 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39712169874558995		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.39712169874558995 | validation: 0.2911411919670588]
	TIME [epoch: 5.74 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.251617303930253		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.251617303930253 | validation: 0.26697214780243017]
	TIME [epoch: 5.74 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22903831683663053		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.22903831683663053 | validation: 0.24015372436622034]
	TIME [epoch: 5.74 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.262354418200758		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.262354418200758 | validation: 0.5599039507354935]
	TIME [epoch: 5.74 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4930432892422594		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.4930432892422594 | validation: 0.24261037871937519]
	TIME [epoch: 5.78 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29710781879326875		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.29710781879326875 | validation: 0.26337217589689027]
	TIME [epoch: 5.75 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30189290011506453		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.30189290011506453 | validation: 0.3450927508753452]
	TIME [epoch: 5.74 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44269920888284814		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.44269920888284814 | validation: 0.4922942703185342]
	TIME [epoch: 5.74 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31104201905603307		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.31104201905603307 | validation: 0.24469185503186403]
	TIME [epoch: 5.74 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2508476736275273		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.2508476736275273 | validation: 0.39214415843793005]
	TIME [epoch: 5.74 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30490791233453823		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.30490791233453823 | validation: 0.28402865290848]
	TIME [epoch: 5.78 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27717133264254545		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.27717133264254545 | validation: 0.25746192031601234]
	TIME [epoch: 5.75 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2430905475138641		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.2430905475138641 | validation: 0.30651602058243643]
	TIME [epoch: 5.74 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32138272746420293		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.32138272746420293 | validation: 0.2426815955185716]
	TIME [epoch: 5.74 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33788315518225165		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.33788315518225165 | validation: 0.3898738530735861]
	TIME [epoch: 5.74 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4018904500998492		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.4018904500998492 | validation: 0.22291385277810455]
	TIME [epoch: 5.74 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24803631360678757		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.24803631360678757 | validation: 0.3683989499265962]
	TIME [epoch: 5.78 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2823161470625214		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.2823161470625214 | validation: 0.23295670801487728]
	TIME [epoch: 5.75 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27170234150904493		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.27170234150904493 | validation: 0.8529847008914874]
	TIME [epoch: 5.74 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44859535151359564		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.44859535151359564 | validation: 0.37816745214323105]
	TIME [epoch: 5.74 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3256333853437262		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.3256333853437262 | validation: 0.2945831328474365]
	TIME [epoch: 5.74 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24147034179242224		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.24147034179242224 | validation: 0.3065400487454706]
	TIME [epoch: 5.74 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27656916611558857		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.27656916611558857 | validation: 0.3688476371208526]
	TIME [epoch: 5.78 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.278036221929094		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.278036221929094 | validation: 0.3372118420473845]
	TIME [epoch: 5.75 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24035618385709234		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.24035618385709234 | validation: 0.3042295018968811]
	TIME [epoch: 5.74 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2466146146775492		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.2466146146775492 | validation: 0.5317934639819475]
	TIME [epoch: 5.74 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31469860134777866		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.31469860134777866 | validation: 0.26816915393492546]
	TIME [epoch: 5.74 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2967379030605889		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.2967379030605889 | validation: 0.4451427058203061]
	TIME [epoch: 5.74 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2555954026656004		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.2555954026656004 | validation: 0.26057035891022606]
	TIME [epoch: 5.78 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2541440928846764		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.2541440928846764 | validation: 0.2184126479883083]
	TIME [epoch: 5.75 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27951312444645726		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.27951312444645726 | validation: 0.21330568382713488]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19473095029144494		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.19473095029144494 | validation: 0.40379353881987073]
	TIME [epoch: 5.74 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26411491480521293		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.26411491480521293 | validation: 0.45132845676094113]
	TIME [epoch: 5.74 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3277050720950019		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.3277050720950019 | validation: 0.2780494130998676]
	TIME [epoch: 5.74 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2561063319849304		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.2561063319849304 | validation: 0.2609481581421327]
	TIME [epoch: 5.78 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27184318013301695		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.27184318013301695 | validation: 0.3711784557450459]
	TIME [epoch: 5.75 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24007653278005336		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.24007653278005336 | validation: 0.32969677669294]
	TIME [epoch: 5.74 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23565847469015688		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.23565847469015688 | validation: 0.32542571701186196]
	TIME [epoch: 5.74 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2611798715657094		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.2611798715657094 | validation: 0.25348676714286783]
	TIME [epoch: 5.74 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3182862404304393		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.3182862404304393 | validation: 0.2571311720785278]
	TIME [epoch: 5.74 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21497412848583458		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.21497412848583458 | validation: 0.2276901490717605]
	TIME [epoch: 5.78 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5159317575467247		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.5159317575467247 | validation: 0.5161424068151841]
	TIME [epoch: 5.75 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3488718426202535		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.3488718426202535 | validation: 0.23426935147642677]
	TIME [epoch: 5.74 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24156212201204813		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.24156212201204813 | validation: 0.2517180636539867]
	TIME [epoch: 5.74 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21731839411761464		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.21731839411761464 | validation: 0.3076665585188797]
	TIME [epoch: 5.74 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2880263360471597		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.2880263360471597 | validation: 0.24469152228716948]
	TIME [epoch: 5.74 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2040818540344469		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.2040818540344469 | validation: 0.24832385966949422]
	TIME [epoch: 5.78 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21958903986324188		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.21958903986324188 | validation: 0.4355243472885141]
	TIME [epoch: 5.75 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3107186202859299		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.3107186202859299 | validation: 0.3262122254234893]
	TIME [epoch: 5.74 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3342284160170545		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.3342284160170545 | validation: 0.22043971564410092]
	TIME [epoch: 5.74 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21082850614878818		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.21082850614878818 | validation: 0.29728370765468]
	TIME [epoch: 5.74 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24084663100030643		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.24084663100030643 | validation: 0.22188292299634774]
	TIME [epoch: 5.74 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2006854531152785		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.2006854531152785 | validation: 0.30005512134746876]
	TIME [epoch: 5.78 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2274953179786367		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.2274953179786367 | validation: 0.17913946697158906]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1709938898803865		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.1709938898803865 | validation: 0.3581497053448434]
	TIME [epoch: 5.75 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2646409193951159		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.2646409193951159 | validation: 0.2086793908192109]
	TIME [epoch: 5.75 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2966491845035726		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.2966491845035726 | validation: 0.27844000866707475]
	TIME [epoch: 5.75 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27731384966737016		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.27731384966737016 | validation: 0.24377935112882781]
	TIME [epoch: 5.75 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28237194641361213		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.28237194641361213 | validation: 0.25070555285327517]
	TIME [epoch: 5.79 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2834382343015606		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.2834382343015606 | validation: 0.2585953288698309]
	TIME [epoch: 5.76 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2333270093145265		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.2333270093145265 | validation: 0.2885020103050619]
	TIME [epoch: 5.75 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21346546980661102		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.21346546980661102 | validation: 0.2725838424443363]
	TIME [epoch: 5.74 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32840704148072675		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.32840704148072675 | validation: 0.424587802934873]
	TIME [epoch: 5.75 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3386663765002315		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.3386663765002315 | validation: 0.29530918497923214]
	TIME [epoch: 5.75 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26727892935615055		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.26727892935615055 | validation: 0.23756942770214526]
	TIME [epoch: 5.79 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23133098314461986		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.23133098314461986 | validation: 0.18730786819351786]
	TIME [epoch: 5.76 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22972896851135055		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.22972896851135055 | validation: 0.4152404997411867]
	TIME [epoch: 5.74 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23862208017809805		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.23862208017809805 | validation: 0.2073708828269721]
	TIME [epoch: 5.75 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22663438992633075		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.22663438992633075 | validation: 0.20034824473389481]
	TIME [epoch: 5.75 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19481324115838974		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.19481324115838974 | validation: 0.21538197667165485]
	TIME [epoch: 5.75 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1975997160085488		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.1975997160085488 | validation: 0.23356453858819126]
	TIME [epoch: 5.78 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18894225048652868		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.18894225048652868 | validation: 0.312996960561555]
	TIME [epoch: 5.76 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23509728887397482		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.23509728887397482 | validation: 0.31509785560272724]
	TIME [epoch: 5.75 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22895423379712732		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.22895423379712732 | validation: 0.34436228018416]
	TIME [epoch: 5.75 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.257315744011422		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.257315744011422 | validation: 0.35336283923302114]
	TIME [epoch: 5.75 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23904448739832457		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.23904448739832457 | validation: 0.22683346292304965]
	TIME [epoch: 5.74 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23407645692504359		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.23407645692504359 | validation: 0.19649301124347687]
	TIME [epoch: 5.79 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19397022146120557		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.19397022146120557 | validation: 0.30716641877658163]
	TIME [epoch: 5.76 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2496186144454098		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.2496186144454098 | validation: 0.3304723766538012]
	TIME [epoch: 5.75 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1909589808572258		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.1909589808572258 | validation: 0.1907943453846558]
	TIME [epoch: 5.75 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22201572052826882		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.22201572052826882 | validation: 0.18688825159745368]
	TIME [epoch: 5.74 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18637335238504663		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.18637335238504663 | validation: 0.2726914502203524]
	TIME [epoch: 5.75 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2160777809931651		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.2160777809931651 | validation: 0.2870685999602634]
	TIME [epoch: 5.78 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23332699711345783		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.23332699711345783 | validation: 0.2058802625993949]
	TIME [epoch: 5.76 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18490105042296		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.18490105042296 | validation: 0.1881805355821013]
	TIME [epoch: 5.75 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28395766125531996		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.28395766125531996 | validation: 0.3856836114934346]
	TIME [epoch: 5.74 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25054224716461576		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.25054224716461576 | validation: 0.24463608654877686]
	TIME [epoch: 5.75 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20350993358791347		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.20350993358791347 | validation: 0.1844721362773035]
	TIME [epoch: 5.75 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19005777331522275		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.19005777331522275 | validation: 0.1807718757886186]
	TIME [epoch: 5.78 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3623858735801047		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.3623858735801047 | validation: 0.25711538531261235]
	TIME [epoch: 5.75 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21014273059586808		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.21014273059586808 | validation: 0.42205626714770506]
	TIME [epoch: 5.74 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2520411394777146		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.2520411394777146 | validation: 0.19571450837334736]
	TIME [epoch: 5.75 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.188763116687664		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.188763116687664 | validation: 0.33646105107563273]
	TIME [epoch: 5.74 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25052395569602687		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.25052395569602687 | validation: 0.25850763846361846]
	TIME [epoch: 5.74 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23233697951231022		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.23233697951231022 | validation: 0.18363655619995975]
	TIME [epoch: 5.78 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17031131160582713		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.17031131160582713 | validation: 0.20407243850381626]
	TIME [epoch: 5.75 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25519845881122893		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.25519845881122893 | validation: 0.2874398221257244]
	TIME [epoch: 5.75 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18255952749701962		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.18255952749701962 | validation: 0.16233280350443619]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23334273061535232		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.23334273061535232 | validation: 0.37653519609458375]
	TIME [epoch: 5.75 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26083263974453613		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.26083263974453613 | validation: 0.30865803322478874]
	TIME [epoch: 5.74 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27172383165677816		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.27172383165677816 | validation: 0.34429942715018]
	TIME [epoch: 5.78 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22980163972063783		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.22980163972063783 | validation: 0.2876863369470204]
	TIME [epoch: 5.75 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21788248248151443		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.21788248248151443 | validation: 0.21268434871140338]
	TIME [epoch: 5.74 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1826298187125216		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.1826298187125216 | validation: 0.18548805433432766]
	TIME [epoch: 5.74 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2073428273292524		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.2073428273292524 | validation: 0.27402825386927143]
	TIME [epoch: 5.74 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17570838223238638		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.17570838223238638 | validation: 0.17012127865297477]
	TIME [epoch: 5.74 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2106237519424275		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.2106237519424275 | validation: 0.15931430969424734]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_295.pth
	Model improved!!!
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17296718135264647		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.17296718135264647 | validation: 0.16496528590081946]
	TIME [epoch: 5.75 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17371588809821284		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.17371588809821284 | validation: 0.2616269441360151]
	TIME [epoch: 5.74 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2214443776408386		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.2214443776408386 | validation: 0.22702763585650992]
	TIME [epoch: 5.74 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21091152678280925		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.21091152678280925 | validation: 0.23502017471314665]
	TIME [epoch: 5.74 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16831238211489297		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.16831238211489297 | validation: 0.3388797686330189]
	TIME [epoch: 5.74 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2020995977654139		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.2020995977654139 | validation: 0.17575541778796763]
	TIME [epoch: 5.78 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18059841792968784		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.18059841792968784 | validation: 0.17937934469492398]
	TIME [epoch: 5.75 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13412533710259428		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.13412533710259428 | validation: 0.19297040716472155]
	TIME [epoch: 5.74 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17933061768832234		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.17933061768832234 | validation: 0.332203503082234]
	TIME [epoch: 5.74 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17773204925975147		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.17773204925975147 | validation: 0.23236459073232762]
	TIME [epoch: 5.74 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20489146437007308		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.20489146437007308 | validation: 0.26027464581077675]
	TIME [epoch: 5.74 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1681223212551598		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.1681223212551598 | validation: 0.18358294369185071]
	TIME [epoch: 5.78 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20599934976002163		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.20599934976002163 | validation: 0.2506015930793622]
	TIME [epoch: 5.75 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22402411922443533		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.22402411922443533 | validation: 0.21412659796227393]
	TIME [epoch: 5.74 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18040445476771097		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.18040445476771097 | validation: 0.27050197601178466]
	TIME [epoch: 5.74 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17887059629221552		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.17887059629221552 | validation: 0.1628848468439059]
	TIME [epoch: 5.74 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20605491497719908		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.20605491497719908 | validation: 0.29665375537637456]
	TIME [epoch: 5.74 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26532464494835883		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.26532464494835883 | validation: 0.31958482143745903]
	TIME [epoch: 5.78 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23018315835324998		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.23018315835324998 | validation: 0.26602439665447636]
	TIME [epoch: 5.75 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20766953489792747		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.20766953489792747 | validation: 0.17610709403016628]
	TIME [epoch: 5.74 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1592074632073181		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.1592074632073181 | validation: 0.2961642399830614]
	TIME [epoch: 5.74 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2040602574399579		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.2040602574399579 | validation: 0.31028078100093337]
	TIME [epoch: 5.74 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20333692495881353		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.20333692495881353 | validation: 0.22640099134179756]
	TIME [epoch: 5.74 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17227144871815114		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.17227144871815114 | validation: 0.19917519907547196]
	TIME [epoch: 5.78 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1588964316253618		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.1588964316253618 | validation: 0.24215889286333322]
	TIME [epoch: 5.75 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22295278750841774		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.22295278750841774 | validation: 0.3202864570026435]
	TIME [epoch: 5.74 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2239614809640631		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.2239614809640631 | validation: 0.2549456533410756]
	TIME [epoch: 5.74 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19277965777272218		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.19277965777272218 | validation: 0.1966578550840024]
	TIME [epoch: 5.74 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15599906186337734		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.15599906186337734 | validation: 0.18318788906217948]
	TIME [epoch: 5.74 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19259559802704213		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.19259559802704213 | validation: 0.22712731745494677]
	TIME [epoch: 5.78 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17071614775927277		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.17071614775927277 | validation: 0.16135348801078692]
	TIME [epoch: 5.75 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1437331800550403		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.1437331800550403 | validation: 0.26987734507801303]
	TIME [epoch: 5.74 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19038870958877785		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.19038870958877785 | validation: 0.18149926992974016]
	TIME [epoch: 5.74 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16693575111022024		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.16693575111022024 | validation: 0.21967832069318383]
	TIME [epoch: 5.74 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20793908134152478		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.20793908134152478 | validation: 0.2509966553758588]
	TIME [epoch: 5.74 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17078838545378247		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.17078838545378247 | validation: 0.28697457838084367]
	TIME [epoch: 5.78 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1829453541786898		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.1829453541786898 | validation: 0.1642290144118575]
	TIME [epoch: 5.75 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19768009543529738		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.19768009543529738 | validation: 0.3036468522793645]
	TIME [epoch: 5.74 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20290394360620678		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.20290394360620678 | validation: 0.3041169769021205]
	TIME [epoch: 5.74 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22242315309711658		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.22242315309711658 | validation: 0.2927131399364801]
	TIME [epoch: 5.74 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25191542556467383		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.25191542556467383 | validation: 0.2281527544850013]
	TIME [epoch: 5.74 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15711471711660482		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.15711471711660482 | validation: 0.2205887682413756]
	TIME [epoch: 5.78 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19767327970798837		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.19767327970798837 | validation: 0.1465109076111405]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_338.pth
	Model improved!!!
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1652803327558263		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.1652803327558263 | validation: 0.2080623733963882]
	TIME [epoch: 5.74 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20308059401126644		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.20308059401126644 | validation: 0.22398039565733277]
	TIME [epoch: 5.74 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1869984188289771		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.1869984188289771 | validation: 0.2591758110398743]
	TIME [epoch: 5.74 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2101616280831075		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.2101616280831075 | validation: 0.38051379016595105]
	TIME [epoch: 5.74 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23698180469723673		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.23698180469723673 | validation: 0.15392154333520863]
	TIME [epoch: 5.78 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16761122094053194		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.16761122094053194 | validation: 0.15418050983689197]
	TIME [epoch: 5.75 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16049302222479106		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.16049302222479106 | validation: 0.2294024884006317]
	TIME [epoch: 5.74 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15947399716064495		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.15947399716064495 | validation: 0.22925547511583358]
	TIME [epoch: 5.74 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18033510317938767		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.18033510317938767 | validation: 0.19000143177904782]
	TIME [epoch: 5.74 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14401094195034983		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.14401094195034983 | validation: 0.23105495383635524]
	TIME [epoch: 5.74 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1954497448539564		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.1954497448539564 | validation: 0.23514796195774842]
	TIME [epoch: 5.78 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17385750222450222		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.17385750222450222 | validation: 0.28150745298713575]
	TIME [epoch: 5.75 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16328527720583497		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.16328527720583497 | validation: 0.15739282785899752]
	TIME [epoch: 5.74 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15097467178826116		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.15097467178826116 | validation: 0.29910902156220476]
	TIME [epoch: 5.74 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2616355596036424		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.2616355596036424 | validation: 0.34092347283250735]
	TIME [epoch: 5.74 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2589007855180821		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.2589007855180821 | validation: 0.20939771284006456]
	TIME [epoch: 5.74 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15581499574672825		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.15581499574672825 | validation: 0.3415494142544674]
	TIME [epoch: 5.78 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2195074840454332		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.2195074840454332 | validation: 0.17948971668721084]
	TIME [epoch: 5.75 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16399138103543695		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.16399138103543695 | validation: 0.16491091285834855]
	TIME [epoch: 5.74 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15773880687581637		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.15773880687581637 | validation: 0.169886822928002]
	TIME [epoch: 5.74 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16960224920650097		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.16960224920650097 | validation: 0.1661617456065916]
	TIME [epoch: 5.74 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19245030217488612		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.19245030217488612 | validation: 0.15749226732575397]
	TIME [epoch: 5.74 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15210717649250444		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.15210717649250444 | validation: 0.20780942837159008]
	TIME [epoch: 5.78 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14987541211407138		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.14987541211407138 | validation: 0.18326181971171404]
	TIME [epoch: 5.75 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1683239470738724		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.1683239470738724 | validation: 0.26775328984334373]
	TIME [epoch: 5.74 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1771490454695265		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.1771490454695265 | validation: 0.17767086729966658]
	TIME [epoch: 5.74 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1878203421031511		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.1878203421031511 | validation: 0.27029884769270185]
	TIME [epoch: 5.74 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17476793512674504		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.17476793512674504 | validation: 0.15326470482245003]
	TIME [epoch: 5.74 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1345885376758619		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.1345885376758619 | validation: 0.13603881551898128]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_367.pth
	Model improved!!!
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15121107447352833		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.15121107447352833 | validation: 0.26639130412117096]
	TIME [epoch: 5.76 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2027801449841705		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.2027801449841705 | validation: 0.2347927957365755]
	TIME [epoch: 5.74 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15712132543449867		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.15712132543449867 | validation: 0.1782382024099246]
	TIME [epoch: 5.74 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15418552643203065		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.15418552643203065 | validation: 0.16619971020783872]
	TIME [epoch: 5.74 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19823513733239084		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.19823513733239084 | validation: 0.17284740942643034]
	TIME [epoch: 5.74 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289296225467349		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.1289296225467349 | validation: 0.1471035490128502]
	TIME [epoch: 5.78 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19007656408974702		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.19007656408974702 | validation: 0.2728660686143852]
	TIME [epoch: 5.75 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19013114719044646		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.19013114719044646 | validation: 0.1927222740695803]
	TIME [epoch: 5.74 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14278516707879527		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.14278516707879527 | validation: 0.39846516278695904]
	TIME [epoch: 5.74 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2830255946332225		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.2830255946332225 | validation: 0.16340980805341918]
	TIME [epoch: 5.74 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14965732758527914		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.14965732758527914 | validation: 0.15589892810708197]
	TIME [epoch: 5.74 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1451703282312521		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.1451703282312521 | validation: 0.13746167745227034]
	TIME [epoch: 5.78 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14913746118606025		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.14913746118606025 | validation: 0.2503672467133493]
	TIME [epoch: 5.75 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1434393100213972		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.1434393100213972 | validation: 0.17487122604968966]
	TIME [epoch: 5.74 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17125204993366244		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.17125204993366244 | validation: 0.33453733240535144]
	TIME [epoch: 5.74 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25674157908775525		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.25674157908775525 | validation: 0.1281282179451297]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_383.pth
	Model improved!!!
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15259894474560623		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.15259894474560623 | validation: 0.1638263053238255]
	TIME [epoch: 5.74 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12527985312729387		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.12527985312729387 | validation: 0.21911466996972448]
	TIME [epoch: 5.78 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.147935849236576		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.147935849236576 | validation: 0.13011043451086596]
	TIME [epoch: 5.75 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10430802483752107		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.10430802483752107 | validation: 0.28051846641778855]
	TIME [epoch: 5.74 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16666986232531256		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.16666986232531256 | validation: 0.1953503850158839]
	TIME [epoch: 5.74 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14098666389192066		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.14098666389192066 | validation: 0.2165204583275806]
	TIME [epoch: 5.74 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1478138630607206		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.1478138630607206 | validation: 0.2640739166204616]
	TIME [epoch: 5.74 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15938457536055645		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.15938457536055645 | validation: 0.17464654735828664]
	TIME [epoch: 5.78 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16193111971655136		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.16193111971655136 | validation: 0.17670795299627326]
	TIME [epoch: 5.75 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12711835010399666		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.12711835010399666 | validation: 0.2174909384539784]
	TIME [epoch: 5.74 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14784560029328386		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.14784560029328386 | validation: 0.16344521221042932]
	TIME [epoch: 5.74 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12570975443956645		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.12570975443956645 | validation: 0.3195421903777498]
	TIME [epoch: 5.74 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.170731335520102		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.170731335520102 | validation: 0.11445505477679774]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10982003159323948		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.10982003159323948 | validation: 0.1534289012418656]
	TIME [epoch: 5.79 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1601701702157575		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.1601701702157575 | validation: 0.1921569927321265]
	TIME [epoch: 5.75 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11899207676949844		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.11899207676949844 | validation: 0.14341531042638742]
	TIME [epoch: 5.74 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13807247839144143		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.13807247839144143 | validation: 0.3261149649796317]
	TIME [epoch: 5.74 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1775614966814844		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.1775614966814844 | validation: 0.13877039860204193]
	TIME [epoch: 5.74 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13656763540043015		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.13656763540043015 | validation: 0.12115919328959092]
	TIME [epoch: 5.75 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12640752476457084		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.12640752476457084 | validation: 0.16349124029886217]
	TIME [epoch: 5.79 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22325452696884937		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.22325452696884937 | validation: 0.3469036474079858]
	TIME [epoch: 5.75 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28496364648633576		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.28496364648633576 | validation: 0.404453206875597]
	TIME [epoch: 5.74 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20010993808688693		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.20010993808688693 | validation: 0.1418327433498467]
	TIME [epoch: 5.74 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11786760765896846		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.11786760765896846 | validation: 0.12750113826177614]
	TIME [epoch: 5.74 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11891141018921708		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.11891141018921708 | validation: 0.1170456761631867]
	TIME [epoch: 5.75 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1551560876423287		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.1551560876423287 | validation: 0.16512297970751802]
	TIME [epoch: 5.78 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.191243894408411		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.191243894408411 | validation: 0.17448437600142364]
	TIME [epoch: 5.74 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11788078627300352		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.11788078627300352 | validation: 0.15283104012135715]
	TIME [epoch: 5.74 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259576790577099		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.1259576790577099 | validation: 0.267180952491674]
	TIME [epoch: 5.74 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25840692469933424		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.25840692469933424 | validation: 0.21551240907308433]
	TIME [epoch: 5.74 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14118486935641456		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.14118486935641456 | validation: 0.13305362153190234]
	TIME [epoch: 5.74 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1181678389494078		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.1181678389494078 | validation: 0.2166283539858206]
	TIME [epoch: 5.78 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16136259906110537		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.16136259906110537 | validation: 0.19583344920594806]
	TIME [epoch: 5.75 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18096309433672925		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.18096309433672925 | validation: 0.14401686563134108]
	TIME [epoch: 5.74 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11427840213579074		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.11427840213579074 | validation: 0.11995653866274424]
	TIME [epoch: 5.74 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13600562675145766		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.13600562675145766 | validation: 0.1863120528415274]
	TIME [epoch: 5.74 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13851964589491475		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.13851964589491475 | validation: 0.12121468986479965]
	TIME [epoch: 5.74 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15159897575938644		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.15159897575938644 | validation: 0.13376921989509133]
	TIME [epoch: 5.78 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12410065898968776		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.12410065898968776 | validation: 0.10342617463195915]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_422.pth
	Model improved!!!
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1073683663857541		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.1073683663857541 | validation: 0.22065842177949846]
	TIME [epoch: 5.74 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14606083362591535		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.14606083362591535 | validation: 0.14085277084408693]
	TIME [epoch: 5.74 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1275134558831883		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.1275134558831883 | validation: 0.13389512746345422]
	TIME [epoch: 5.74 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12839197637609168		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.12839197637609168 | validation: 0.15966413825578074]
	TIME [epoch: 5.74 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16113986866865415		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.16113986866865415 | validation: 0.170380918713969]
	TIME [epoch: 5.78 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26633299653893405		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.26633299653893405 | validation: 0.34796190779903924]
	TIME [epoch: 5.74 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24105508290941652		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.24105508290941652 | validation: 0.1623682231252702]
	TIME [epoch: 5.74 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11618170691866742		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.11618170691866742 | validation: 0.16758842714917724]
	TIME [epoch: 5.74 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1942039778969467		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.1942039778969467 | validation: 0.1496607747279923]
	TIME [epoch: 5.74 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14271333256983285		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.14271333256983285 | validation: 0.13180257044125182]
	TIME [epoch: 5.74 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11539576440624319		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.11539576440624319 | validation: 0.1355657652554452]
	TIME [epoch: 5.78 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11810366871250325		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.11810366871250325 | validation: 0.11527065882437847]
	TIME [epoch: 5.74 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10335112104012828		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.10335112104012828 | validation: 0.1305230627930019]
	TIME [epoch: 5.74 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12465670668694688		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.12465670668694688 | validation: 0.1273813619364148]
	TIME [epoch: 5.74 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14293506856369365		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.14293506856369365 | validation: 0.11647608600922704]
	TIME [epoch: 5.74 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1219789864248057		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.1219789864248057 | validation: 0.16832148715931408]
	TIME [epoch: 5.75 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1516177724838903		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.1516177724838903 | validation: 0.13834796664466875]
	TIME [epoch: 5.78 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13584629853953237		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.13584629853953237 | validation: 0.1639092726596116]
	TIME [epoch: 5.75 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25187686452658203		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.25187686452658203 | validation: 0.14220257967678604]
	TIME [epoch: 5.74 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09883875870554948		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.09883875870554948 | validation: 0.3627914795616107]
	TIME [epoch: 5.74 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40486696047874676		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.40486696047874676 | validation: 0.1393384244541164]
	TIME [epoch: 5.74 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15716160602072127		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.15716160602072127 | validation: 0.3084376673226001]
	TIME [epoch: 5.74 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1562936344783346		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.1562936344783346 | validation: 0.1817847437569142]
	TIME [epoch: 5.78 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15433571230596427		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.15433571230596427 | validation: 0.12632278852197515]
	TIME [epoch: 5.74 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11788004215207333		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.11788004215207333 | validation: 0.11589495318834286]
	TIME [epoch: 5.74 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09721650749926539		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.09721650749926539 | validation: 0.16947185484994307]
	TIME [epoch: 5.74 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16993405999619468		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.16993405999619468 | validation: 0.15421650563973227]
	TIME [epoch: 5.74 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15222668656349655		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.15222668656349655 | validation: 0.1659095547939991]
	TIME [epoch: 5.74 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14988483035577435		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.14988483035577435 | validation: 0.158472773268832]
	TIME [epoch: 5.78 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2113395390592016		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.2113395390592016 | validation: 0.38859000836901253]
	TIME [epoch: 5.75 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20607905589342881		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.20607905589342881 | validation: 0.13403203106547068]
	TIME [epoch: 5.74 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12927027084967166		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.12927027084967166 | validation: 0.1279422566043654]
	TIME [epoch: 5.74 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10515968659546426		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.10515968659546426 | validation: 0.1365180389530539]
	TIME [epoch: 5.74 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11461578281229018		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.11461578281229018 | validation: 0.19580268185880684]
	TIME [epoch: 5.74 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13682963593380446		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.13682963593380446 | validation: 0.1566050387925834]
	TIME [epoch: 5.78 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12662035930619053		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.12662035930619053 | validation: 0.16981215908937955]
	TIME [epoch: 5.75 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11251710084390953		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.11251710084390953 | validation: 0.14561018036347462]
	TIME [epoch: 5.74 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10163333374259825		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.10163333374259825 | validation: 0.13699529071788072]
	TIME [epoch: 5.74 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13525757695463944		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.13525757695463944 | validation: 0.15404658841050792]
	TIME [epoch: 5.74 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1306238696108982		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.1306238696108982 | validation: 0.1380011469824634]
	TIME [epoch: 5.74 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1092297022710017		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.1092297022710017 | validation: 0.10737241595133812]
	TIME [epoch: 5.78 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09447371939634261		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.09447371939634261 | validation: 0.1329201972476516]
	TIME [epoch: 5.75 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10185337080102508		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.10185337080102508 | validation: 0.12379325201233439]
	TIME [epoch: 5.74 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12032700366286211		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.12032700366286211 | validation: 0.3152403710907196]
	TIME [epoch: 5.74 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17526353655273835		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.17526353655273835 | validation: 0.14640823332313857]
	TIME [epoch: 5.74 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11866917112575076		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.11866917112575076 | validation: 0.20739772366209663]
	TIME [epoch: 5.74 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11805118826642949		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.11805118826642949 | validation: 0.15457357728392193]
	TIME [epoch: 5.78 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11855900449453918		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.11855900449453918 | validation: 0.13908701111456043]
	TIME [epoch: 5.75 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289715470363459		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.1289715470363459 | validation: 0.1713468715059851]
	TIME [epoch: 5.74 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14413925941998482		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.14413925941998482 | validation: 0.17383894893068402]
	TIME [epoch: 5.74 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13193528524092415		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.13193528524092415 | validation: 0.12280976966768582]
	TIME [epoch: 5.74 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10708971660772205		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.10708971660772205 | validation: 0.15893086318535418]
	TIME [epoch: 5.74 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13332165976864224		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.13332165976864224 | validation: 0.1235964936325168]
	TIME [epoch: 5.78 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09915258849892764		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.09915258849892764 | validation: 0.14460233881832463]
	TIME [epoch: 5.75 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10769802533487327		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.10769802533487327 | validation: 0.1489895864748907]
	TIME [epoch: 5.74 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13575468737797494		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.13575468737797494 | validation: 0.1001326887115506]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_478.pth
	Model improved!!!
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10756598273676982		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.10756598273676982 | validation: 0.16243724301391468]
	TIME [epoch: 5.74 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1300185898019286		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.1300185898019286 | validation: 0.1444158367238432]
	TIME [epoch: 5.74 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1033347853117017		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.1033347853117017 | validation: 0.11049027875402916]
	TIME [epoch: 5.78 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0955939571206249		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.0955939571206249 | validation: 0.12018788066831733]
	TIME [epoch: 5.74 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14883954172346944		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.14883954172346944 | validation: 0.18091989122106886]
	TIME [epoch: 5.74 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13783032617432603		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.13783032617432603 | validation: 0.15458075137997548]
	TIME [epoch: 5.74 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1525305516541763		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.1525305516541763 | validation: 0.15065627710324817]
	TIME [epoch: 5.74 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13463940370756255		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.13463940370756255 | validation: 0.12818029904256253]
	TIME [epoch: 5.74 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10821716176571616		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.10821716176571616 | validation: 0.11762180839619749]
	TIME [epoch: 5.78 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13689329109882986		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.13689329109882986 | validation: 0.10921983673084718]
	TIME [epoch: 5.75 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11466457731809049		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.11466457731809049 | validation: 0.14155552124905232]
	TIME [epoch: 5.74 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13509041512683947		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.13509041512683947 | validation: 0.18313439215408578]
	TIME [epoch: 5.74 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2356148308739252		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.2356148308739252 | validation: 0.15336587065599772]
	TIME [epoch: 5.74 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2021922347916129		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.2021922347916129 | validation: 0.12369191472142185]
	TIME [epoch: 5.74 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1113428455959938		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.1113428455959938 | validation: 0.10734283286194807]
	TIME [epoch: 5.78 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10291014653590105		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.10291014653590105 | validation: 0.16406829729585848]
	TIME [epoch: 5.75 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1324179515351513		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.1324179515351513 | validation: 0.11180395047340079]
	TIME [epoch: 5.74 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13121573845813786		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.13121573845813786 | validation: 0.18931804770816185]
	TIME [epoch: 5.74 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15895185687273275		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.15895185687273275 | validation: 0.16374891388081111]
	TIME [epoch: 5.74 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09631684940730345		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.09631684940730345 | validation: 0.13401515449762713]
	TIME [epoch: 5.74 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13506305190786028		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.13506305190786028 | validation: 0.15503759277559462]
	TIME [epoch: 5.78 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12337897498783822		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.12337897498783822 | validation: 0.13507865521305953]
	TIME [epoch: 5.75 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11714150052574812		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.11714150052574812 | validation: 0.14599972861792104]
	TIME [epoch: 5.74 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1179094101176617		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.1179094101176617 | validation: 0.16478103864278432]
	TIME [epoch: 5.74 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11533018530914292		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.11533018530914292 | validation: 0.2632352145601284]
	TIME [epoch: 5.74 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2136055926820607		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.2136055926820607 | validation: 0.1206331037650598]
	TIME [epoch: 5.74 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08407262333521781		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.08407262333521781 | validation: 0.14871960362590794]
	TIME [epoch: 5.78 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16128010217999258		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.16128010217999258 | validation: 0.12212921373847817]
	TIME [epoch: 5.75 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10330016713970097		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.10330016713970097 | validation: 0.13513546301249768]
	TIME [epoch: 5.74 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13901054821674638		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.13901054821674638 | validation: 0.11914829792660894]
	TIME [epoch: 5.74 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12924303825838915		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.12924303825838915 | validation: 0.14816677529782207]
	TIME [epoch: 5.74 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08883367982124139		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.08883367982124139 | validation: 0.10261990997701609]
	TIME [epoch: 5.74 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08012411952897051		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.08012411952897051 | validation: 0.11305259231309872]
	TIME [epoch: 5.78 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09779455968113539		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.09779455968113539 | validation: 0.13148392171848217]
	TIME [epoch: 5.75 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10780956554492488		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.10780956554492488 | validation: 0.14788349640804727]
	TIME [epoch: 5.74 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12367687935063926		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.12367687935063926 | validation: 0.12703750095426405]
	TIME [epoch: 5.74 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10361515504502988		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.10361515504502988 | validation: 0.18895478013075587]
	TIME [epoch: 5.74 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12434400169355775		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.12434400169355775 | validation: 0.1103885959201476]
	TIME [epoch: 5.74 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10545609712126225		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.10545609712126225 | validation: 0.1864021835718411]
	TIME [epoch: 5.78 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1417085746649806		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.1417085746649806 | validation: 0.1565340396069066]
	TIME [epoch: 5.75 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14516005142788124		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.14516005142788124 | validation: 0.16207154437695487]
	TIME [epoch: 5.74 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12893929602471535		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.12893929602471535 | validation: 0.19433048414632467]
	TIME [epoch: 5.74 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20997460531790313		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.20997460531790313 | validation: 0.15480581371910637]
	TIME [epoch: 5.74 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12318304611987785		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.12318304611987785 | validation: 0.16473849398511142]
	TIME [epoch: 5.74 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10301212259622335		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.10301212259622335 | validation: 0.12292075382298992]
	TIME [epoch: 5.78 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11044166711167375		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.11044166711167375 | validation: 0.1633388397781544]
	TIME [epoch: 5.75 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09333902653128273		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.09333902653128273 | validation: 0.11205877858438874]
	TIME [epoch: 5.74 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14718361578260197		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.14718361578260197 | validation: 0.15741604386605687]
	TIME [epoch: 5.74 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1138359947202409		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.1138359947202409 | validation: 0.11112822238096243]
	TIME [epoch: 5.74 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08399409747678789		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.08399409747678789 | validation: 0.1549074991161488]
	TIME [epoch: 5.74 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11366815408596323		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.11366815408596323 | validation: 0.09311045007459817]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_529.pth
	Model improved!!!
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09172772651236988		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.09172772651236988 | validation: 0.1372101528526732]
	TIME [epoch: 5.75 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09369433831618634		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.09369433831618634 | validation: 0.12941536391683]
	TIME [epoch: 5.74 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08953199900288727		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.08953199900288727 | validation: 0.14473459353988444]
	TIME [epoch: 5.74 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09537432844171503		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.09537432844171503 | validation: 0.16055359254054055]
	TIME [epoch: 5.74 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307077691739604		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.1307077691739604 | validation: 0.17139797988811328]
	TIME [epoch: 5.74 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13143252822837867		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.13143252822837867 | validation: 0.10628663593266048]
	TIME [epoch: 5.78 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15136203650354368		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.15136203650354368 | validation: 0.1438184751289433]
	TIME [epoch: 5.74 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1033971867102563		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.1033971867102563 | validation: 0.1294904971423048]
	TIME [epoch: 5.74 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13296249086138776		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.13296249086138776 | validation: 0.12365350599670107]
	TIME [epoch: 5.74 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10473150197687624		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.10473150197687624 | validation: 0.16280515222410546]
	TIME [epoch: 5.74 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09099673833122277		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.09099673833122277 | validation: 0.1069932002247884]
	TIME [epoch: 5.74 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09233211266609982		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.09233211266609982 | validation: 0.0982692640416737]
	TIME [epoch: 5.78 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11018058007517037		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.11018058007517037 | validation: 0.23332762441862742]
	TIME [epoch: 5.75 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14324814926262286		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.14324814926262286 | validation: 0.1610470313703715]
	TIME [epoch: 5.74 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19713676809946093		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.19713676809946093 | validation: 0.18024547108734573]
	TIME [epoch: 5.74 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1034702397301248		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.1034702397301248 | validation: 0.1086286310819602]
	TIME [epoch: 5.74 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08767395215798685		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.08767395215798685 | validation: 0.1190281452950153]
	TIME [epoch: 5.74 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08831062953947695		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.08831062953947695 | validation: 0.09748369263244067]
	TIME [epoch: 5.78 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08479574005683291		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.08479574005683291 | validation: 0.14558751771741538]
	TIME [epoch: 5.75 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11719849419745035		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.11719849419745035 | validation: 0.1345082363110209]
	TIME [epoch: 5.74 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09114500103876538		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.09114500103876538 | validation: 0.11584313909837356]
	TIME [epoch: 5.74 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08825992508775085		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.08825992508775085 | validation: 0.12746185191855489]
	TIME [epoch: 5.74 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07379520547374527		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.07379520547374527 | validation: 0.08916108919264018]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_552.pth
	Model improved!!!
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09251941288941509		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.09251941288941509 | validation: 0.28400177061825543]
	TIME [epoch: 5.79 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1852776924465327		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.1852776924465327 | validation: 0.10414779103245372]
	TIME [epoch: 5.74 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12579594198970082		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.12579594198970082 | validation: 0.10579547089820271]
	TIME [epoch: 5.74 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08313775924478063		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.08313775924478063 | validation: 0.147875035662723]
	TIME [epoch: 5.74 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10359638733535616		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.10359638733535616 | validation: 0.11854436931841981]
	TIME [epoch: 5.74 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0828633939421828		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.0828633939421828 | validation: 0.11128011849285376]
	TIME [epoch: 5.74 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10776858972340889		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.10776858972340889 | validation: 0.12059460217754095]
	TIME [epoch: 5.78 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08644876824855897		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.08644876824855897 | validation: 0.11005433400156314]
	TIME [epoch: 5.75 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12508499814240326		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.12508499814240326 | validation: 0.18710626352278298]
	TIME [epoch: 5.74 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14516641646360823		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.14516641646360823 | validation: 0.13659480765739979]
	TIME [epoch: 5.74 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10278100936547388		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.10278100936547388 | validation: 0.21212278043963118]
	TIME [epoch: 5.74 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12810911614205123		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.12810911614205123 | validation: 0.18615359427568842]
	TIME [epoch: 5.75 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1629332306461052		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.1629332306461052 | validation: 0.1645264252812514]
	TIME [epoch: 5.78 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14912357313962785		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.14912357313962785 | validation: 0.0959376680151209]
	TIME [epoch: 5.75 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10002254367922353		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.10002254367922353 | validation: 0.12191577550065016]
	TIME [epoch: 5.74 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08282706436419958		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.08282706436419958 | validation: 0.11255955540846911]
	TIME [epoch: 5.74 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08443406608441706		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.08443406608441706 | validation: 0.13476819153859104]
	TIME [epoch: 5.74 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08600188584348173		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.08600188584348173 | validation: 0.15619935741777954]
	TIME [epoch: 5.75 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08864452833284542		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.08864452833284542 | validation: 0.18665448878647126]
	TIME [epoch: 5.78 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19919437898569856		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.19919437898569856 | validation: 0.18184150676408836]
	TIME [epoch: 5.75 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11832314619116421		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.11832314619116421 | validation: 0.11523885330353138]
	TIME [epoch: 5.74 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12027928378553632		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.12027928378553632 | validation: 0.16738326897844416]
	TIME [epoch: 5.74 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09769515072012769		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.09769515072012769 | validation: 0.1202399572841274]
	TIME [epoch: 5.74 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0786401872328392		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.0786401872328392 | validation: 0.1144474440235106]
	TIME [epoch: 5.75 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07637513852313861		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.07637513852313861 | validation: 0.09299832101320499]
	TIME [epoch: 5.78 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07861084038182896		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.07861084038182896 | validation: 0.10801850343176694]
	TIME [epoch: 5.75 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07956846485318614		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.07956846485318614 | validation: 0.09186456436665981]
	TIME [epoch: 5.74 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08321369448082666		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.08321369448082666 | validation: 0.08121762976223205]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_580.pth
	Model improved!!!
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07173901433864838		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.07173901433864838 | validation: 0.09328416152048577]
	TIME [epoch: 5.74 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06662449214926336		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.06662449214926336 | validation: 0.0869538466413817]
	TIME [epoch: 5.74 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11468364202939554		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.11468364202939554 | validation: 0.09643035887656144]
	TIME [epoch: 5.78 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11392193129786968		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.11392193129786968 | validation: 0.15584888274506997]
	TIME [epoch: 5.74 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11326022873403865		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.11326022873403865 | validation: 0.08900738942522711]
	TIME [epoch: 5.74 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10247250963912262		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.10247250963912262 | validation: 0.08079594072668879]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_586.pth
	Model improved!!!
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08186412780457356		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.08186412780457356 | validation: 0.08485021871389609]
	TIME [epoch: 5.74 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08626853608760496		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.08626853608760496 | validation: 0.1392476522169335]
	TIME [epoch: 5.75 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0858020682448045		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.0858020682448045 | validation: 0.1161848257867112]
	TIME [epoch: 5.77 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10374080422198823		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.10374080422198823 | validation: 0.1870888452450833]
	TIME [epoch: 5.74 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09076279702801032		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.09076279702801032 | validation: 0.08948758962621493]
	TIME [epoch: 5.74 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07643411588977944		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.07643411588977944 | validation: 0.12682608267583045]
	TIME [epoch: 5.73 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08130469568687808		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.08130469568687808 | validation: 0.167538516946072]
	TIME [epoch: 5.73 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11581357957360479		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.11581357957360479 | validation: 0.15892094423333133]
	TIME [epoch: 5.74 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09281679720316638		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.09281679720316638 | validation: 0.09581145815901336]
	TIME [epoch: 5.78 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07376469299616023		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.07376469299616023 | validation: 0.10017636915976447]
	TIME [epoch: 5.74 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0788252965579295		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.0788252965579295 | validation: 0.13419697464919922]
	TIME [epoch: 5.74 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10862095854330697		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.10862095854330697 | validation: 0.14139774423551368]
	TIME [epoch: 5.74 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08600896614128624		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.08600896614128624 | validation: 0.11886859130802577]
	TIME [epoch: 5.74 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10980702119402788		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.10980702119402788 | validation: 0.10856886908165443]
	TIME [epoch: 5.74 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10074970673964036		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.10074970673964036 | validation: 0.09369405757444291]
	TIME [epoch: 5.78 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09628631513656767		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.09628631513656767 | validation: 0.10514349032944928]
	TIME [epoch: 5.75 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08926281867364078		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.08926281867364078 | validation: 0.10284223061092415]
	TIME [epoch: 5.74 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08340455160454333		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.08340455160454333 | validation: 0.11148686616220214]
	TIME [epoch: 5.74 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06453817885198303		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.06453817885198303 | validation: 0.11325577415607618]
	TIME [epoch: 5.74 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07865772493333052		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.07865772493333052 | validation: 0.10630871692761246]
	TIME [epoch: 5.74 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10275207999674905		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.10275207999674905 | validation: 0.09008562228742548]
	TIME [epoch: 5.78 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08669651027749527		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.08669651027749527 | validation: 0.12514968087905953]
	TIME [epoch: 5.75 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09673615648852477		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.09673615648852477 | validation: 0.08988025931924895]
	TIME [epoch: 5.74 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07868379152160766		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.07868379152160766 | validation: 0.08185236803186845]
	TIME [epoch: 5.74 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1330143449315426		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.1330143449315426 | validation: 0.13432487214811845]
	TIME [epoch: 5.74 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08234229376967223		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.08234229376967223 | validation: 0.1369932984644715]
	TIME [epoch: 5.74 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10050876417661461		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.10050876417661461 | validation: 0.12403620190096944]
	TIME [epoch: 5.78 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08385610938709423		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.08385610938709423 | validation: 0.12236759699182004]
	TIME [epoch: 5.75 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0915714523480994		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.0915714523480994 | validation: 0.10133915744291055]
	TIME [epoch: 5.74 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10400299023629393		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.10400299023629393 | validation: 0.1178211094279434]
	TIME [epoch: 5.74 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07410926721356015		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.07410926721356015 | validation: 0.0895960718030834]
	TIME [epoch: 5.74 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07521859467252581		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.07521859467252581 | validation: 0.15091891773358543]
	TIME [epoch: 5.74 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11247014258878067		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.11247014258878067 | validation: 0.11725965818694416]
	TIME [epoch: 5.78 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0837516480654713		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.0837516480654713 | validation: 0.10865125605153855]
	TIME [epoch: 5.75 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08585991193060005		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.08585991193060005 | validation: 0.11348505796319913]
	TIME [epoch: 5.74 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08086121588172174		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.08086121588172174 | validation: 0.10421990269222871]
	TIME [epoch: 5.74 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08987372147476355		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.08987372147476355 | validation: 0.11124311880261827]
	TIME [epoch: 5.74 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07473238374972546		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.07473238374972546 | validation: 0.10017449203203752]
	TIME [epoch: 5.74 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07511347923502913		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.07511347923502913 | validation: 0.17598195907684308]
	TIME [epoch: 5.78 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10442970702950537		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.10442970702950537 | validation: 0.1591778947214448]
	TIME [epoch: 5.74 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08922702747124002		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.08922702747124002 | validation: 0.08250583906446035]
	TIME [epoch: 5.74 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07591763681525153		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.07591763681525153 | validation: 0.08603552149550649]
	TIME [epoch: 5.74 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07178415744719882		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.07178415744719882 | validation: 0.08419853407089203]
	TIME [epoch: 5.74 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07968484611322683		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.07968484611322683 | validation: 0.08737244045724517]
	TIME [epoch: 5.74 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07549747286760478		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.07549747286760478 | validation: 0.13205239861710977]
	TIME [epoch: 5.78 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09355989269904344		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.09355989269904344 | validation: 0.105389570599331]
	TIME [epoch: 5.75 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07865074077519647		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.07865074077519647 | validation: 0.10137656058748767]
	TIME [epoch: 5.74 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08593137808098224		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.08593137808098224 | validation: 0.12926981360920414]
	TIME [epoch: 5.74 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08965871311680006		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.08965871311680006 | validation: 0.10305117490490216]
	TIME [epoch: 5.74 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08257409752488305		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.08257409752488305 | validation: 0.09156101868744732]
	TIME [epoch: 5.75 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06862798943038523		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.06862798943038523 | validation: 0.1048243327777375]
	TIME [epoch: 5.78 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09257488561908103		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.09257488561908103 | validation: 0.0831703644136448]
	TIME [epoch: 5.75 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06281826798142627		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.06281826798142627 | validation: 0.08432665528079011]
	TIME [epoch: 5.74 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08427712845345103		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.08427712845345103 | validation: 0.0835815194596723]
	TIME [epoch: 5.74 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08440526961685815		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.08440526961685815 | validation: 0.10849088386680618]
	TIME [epoch: 5.74 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07420938661132184		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.07420938661132184 | validation: 0.10290539563349352]
	TIME [epoch: 5.74 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07922734279028161		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.07922734279028161 | validation: 0.12591060543818328]
	TIME [epoch: 5.78 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09491793824603681		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.09491793824603681 | validation: 0.11410446806714138]
	TIME [epoch: 5.75 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08654999676591615		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.08654999676591615 | validation: 0.10278614894109411]
	TIME [epoch: 5.74 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1197106017025574		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.1197106017025574 | validation: 0.0896009087520367]
	TIME [epoch: 5.74 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08818782780691155		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.08818782780691155 | validation: 0.09855876804413174]
	TIME [epoch: 5.74 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07891068704628915		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.07891068704628915 | validation: 0.10113979189819457]
	TIME [epoch: 5.74 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0756985692612136		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.0756985692612136 | validation: 0.11701557677737746]
	TIME [epoch: 5.78 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1119502361303081		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.1119502361303081 | validation: 0.1468502348145311]
	TIME [epoch: 5.74 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11274133840409986		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.11274133840409986 | validation: 0.19302666817507194]
	TIME [epoch: 5.74 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2483879672626829		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.2483879672626829 | validation: 0.1474893985038212]
	TIME [epoch: 5.74 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0933841860870241		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.0933841860870241 | validation: 0.12502875050717482]
	TIME [epoch: 5.74 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11623980607620024		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.11623980607620024 | validation: 0.10212978251185828]
	TIME [epoch: 5.74 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0720006923180414		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.0720006923180414 | validation: 0.12619898980584737]
	TIME [epoch: 5.78 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07694639662235138		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.07694639662235138 | validation: 0.10079506830435218]
	TIME [epoch: 5.75 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06983003320535244		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.06983003320535244 | validation: 0.08877681329243316]
	TIME [epoch: 5.74 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06027566287416361		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.06027566287416361 | validation: 0.09097284835323129]
	TIME [epoch: 5.74 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07511095700183595		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.07511095700183595 | validation: 0.10175956581953063]
	TIME [epoch: 5.74 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07202349866457206		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.07202349866457206 | validation: 0.08714902992265433]
	TIME [epoch: 5.74 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07640666487870003		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.07640666487870003 | validation: 0.1017111612141412]
	TIME [epoch: 5.78 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07519611613029337		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.07519611613029337 | validation: 0.16580788522885642]
	TIME [epoch: 5.74 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09653784579276127		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.09653784579276127 | validation: 0.08157568095768629]
	TIME [epoch: 5.74 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06153776293401447		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.06153776293401447 | validation: 0.08710114480149059]
	TIME [epoch: 5.74 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06854334414034871		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.06854334414034871 | validation: 0.11206652101537173]
	TIME [epoch: 5.74 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07394399966596946		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.07394399966596946 | validation: 0.16898073684521342]
	TIME [epoch: 5.74 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11969271030387404		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.11969271030387404 | validation: 0.1164265774629374]
	TIME [epoch: 5.78 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07289428592341354		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.07289428592341354 | validation: 0.141054746145987]
	TIME [epoch: 5.74 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08127963500222024		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.08127963500222024 | validation: 0.08534922761695457]
	TIME [epoch: 5.74 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08042620051536795		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.08042620051536795 | validation: 0.09956097565011257]
	TIME [epoch: 5.74 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06395708476905285		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.06395708476905285 | validation: 0.07825512898069273]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_671.pth
	Model improved!!!
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07126139148423752		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.07126139148423752 | validation: 0.12192223337098126]
	TIME [epoch: 5.74 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09827458822789717		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.09827458822789717 | validation: 0.09055360933492942]
	TIME [epoch: 5.78 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05414434762445846		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.05414434762445846 | validation: 0.10471338576895883]
	TIME [epoch: 5.74 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11175852426383787		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.11175852426383787 | validation: 0.15681964351596378]
	TIME [epoch: 5.74 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0973691779677025		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.0973691779677025 | validation: 0.10732477497084573]
	TIME [epoch: 5.74 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06419773453798566		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.06419773453798566 | validation: 0.1717315464223669]
	TIME [epoch: 5.74 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1141611589039748		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.1141611589039748 | validation: 0.10991695872770266]
	TIME [epoch: 5.74 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0847179355540061		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.0847179355540061 | validation: 0.10290042455342543]
	TIME [epoch: 5.78 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07418366122630803		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.07418366122630803 | validation: 0.08079794846401385]
	TIME [epoch: 5.74 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07684529056946013		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.07684529056946013 | validation: 0.09844224641577796]
	TIME [epoch: 5.73 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08667055669174363		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.08667055669174363 | validation: 0.07577670826905265]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_682.pth
	Model improved!!!
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06138656056730347		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.06138656056730347 | validation: 0.0838969618832398]
	TIME [epoch: 5.73 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06402945178608309		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.06402945178608309 | validation: 0.09942416200472773]
	TIME [epoch: 5.75 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0888509369962069		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.0888509369962069 | validation: 0.08470246221100801]
	TIME [epoch: 5.77 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06924626184910043		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.06924626184910043 | validation: 0.08130036876324441]
	TIME [epoch: 5.74 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056377644797419635		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.056377644797419635 | validation: 0.08473715414875291]
	TIME [epoch: 5.74 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06256989829323786		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.06256989829323786 | validation: 0.07918912097822194]
	TIME [epoch: 5.74 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05998616351933288		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.05998616351933288 | validation: 0.0769506240008884]
	TIME [epoch: 5.74 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07505078267168072		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.07505078267168072 | validation: 0.14264042312455555]
	TIME [epoch: 5.75 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09575379090278958		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.09575379090278958 | validation: 0.1214361509609744]
	TIME [epoch: 5.77 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07495232674843247		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.07495232674843247 | validation: 0.09248360547644494]
	TIME [epoch: 5.74 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0749942680544589		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.0749942680544589 | validation: 0.12061436729543275]
	TIME [epoch: 5.73 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08697657272472592		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.08697657272472592 | validation: 0.09320718233603426]
	TIME [epoch: 5.74 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06884572535538977		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.06884572535538977 | validation: 0.08465998523879882]
	TIME [epoch: 5.74 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07329943356967249		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.07329943356967249 | validation: 0.09076786750486011]
	TIME [epoch: 5.74 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0686207641854073		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.0686207641854073 | validation: 0.13759783879007403]
	TIME [epoch: 5.77 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11300075946194216		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.11300075946194216 | validation: 0.09837515951021576]
	TIME [epoch: 5.74 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07685288703076071		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.07685288703076071 | validation: 0.0875601305132936]
	TIME [epoch: 5.74 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07807012403449987		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.07807012403449987 | validation: 0.08635826080810635]
	TIME [epoch: 5.74 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.064873900584727		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.064873900584727 | validation: 0.09843719099444441]
	TIME [epoch: 5.73 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06105538014167207		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.06105538014167207 | validation: 0.08363520782283004]
	TIME [epoch: 5.74 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06533242695827773		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.06533242695827773 | validation: 0.07817274327816473]
	TIME [epoch: 5.78 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06069158960919059		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.06069158960919059 | validation: 0.07871273906972022]
	TIME [epoch: 5.74 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061298947063152885		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.061298947063152885 | validation: 0.10094787184962442]
	TIME [epoch: 5.74 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06623651109642079		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.06623651109642079 | validation: 0.08113749892929732]
	TIME [epoch: 5.74 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0708471980090647		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.0708471980090647 | validation: 0.09053836136788236]
	TIME [epoch: 5.74 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06416294023424535		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.06416294023424535 | validation: 0.0757567129345199]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_708.pth
	Model improved!!!
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0605464637646512		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.0605464637646512 | validation: 0.08786468221813568]
	TIME [epoch: 5.78 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06708551302578533		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.06708551302578533 | validation: 0.12231169697748935]
	TIME [epoch: 5.74 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08231468319605333		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.08231468319605333 | validation: 0.11074927831538728]
	TIME [epoch: 5.74 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09452364379878246		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.09452364379878246 | validation: 0.08038358800550752]
	TIME [epoch: 5.74 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06298987236927195		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.06298987236927195 | validation: 0.12488290179724114]
	TIME [epoch: 5.73 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08379620043535901		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.08379620043535901 | validation: 0.06962345754624687]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_714.pth
	Model improved!!!
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08748275259196467		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.08748275259196467 | validation: 0.14280345769379815]
	TIME [epoch: 5.77 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09130742919588139		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.09130742919588139 | validation: 0.09085259290955108]
	TIME [epoch: 5.74 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06375052573786992		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.06375052573786992 | validation: 0.07625559077670226]
	TIME [epoch: 5.73 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05397807664925978		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.05397807664925978 | validation: 0.10039930774506192]
	TIME [epoch: 5.73 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08543360159366836		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.08543360159366836 | validation: 0.08385694652524965]
	TIME [epoch: 5.73 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058385548613682475		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.058385548613682475 | validation: 0.08547798780801462]
	TIME [epoch: 5.75 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05716374692678851		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.05716374692678851 | validation: 0.08620594528162073]
	TIME [epoch: 5.77 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0625393687978983		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.0625393687978983 | validation: 0.09334413491960593]
	TIME [epoch: 5.74 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07029027283020077		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.07029027283020077 | validation: 0.06330450792858434]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_723.pth
	Model improved!!!
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07346218674826101		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.07346218674826101 | validation: 0.08795757155467132]
	TIME [epoch: 5.74 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060475697832181895		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.060475697832181895 | validation: 0.11142462983890376]
	TIME [epoch: 5.74 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06352885774213513		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.06352885774213513 | validation: 0.08024971768042466]
	TIME [epoch: 5.75 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06523511281701952		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.06523511281701952 | validation: 0.07191383885029622]
	TIME [epoch: 5.76 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04909342737396985		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.04909342737396985 | validation: 0.08674334251817438]
	TIME [epoch: 5.73 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06396170716064573		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.06396170716064573 | validation: 0.06919091169376712]
	TIME [epoch: 5.73 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05640558443818006		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.05640558443818006 | validation: 0.07944437432644895]
	TIME [epoch: 5.73 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057811570288212794		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.057811570288212794 | validation: 0.09024631772808121]
	TIME [epoch: 5.73 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05785528391475849		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.05785528391475849 | validation: 0.07701674610592725]
	TIME [epoch: 5.75 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06440089033175903		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.06440089033175903 | validation: 0.13447258317981903]
	TIME [epoch: 5.76 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07212452692702892		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.07212452692702892 | validation: 0.08699669356821613]
	TIME [epoch: 5.74 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06353175587615821		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.06353175587615821 | validation: 0.08714012039695186]
	TIME [epoch: 5.73 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06112154249510992		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.06112154249510992 | validation: 0.08831976005456416]
	TIME [epoch: 5.73 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055376045085409886		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.055376045085409886 | validation: 0.09045224370184052]
	TIME [epoch: 5.73 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05916856580472915		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.05916856580472915 | validation: 0.0698071785317877]
	TIME [epoch: 5.74 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051469550625677034		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.051469550625677034 | validation: 0.0900292090226811]
	TIME [epoch: 5.77 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06419468111774072		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.06419468111774072 | validation: 0.06954155303481001]
	TIME [epoch: 5.74 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.063262520535623		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.063262520535623 | validation: 0.15258846759466843]
	TIME [epoch: 5.73 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08018591151522649		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.08018591151522649 | validation: 0.08795991854381584]
	TIME [epoch: 5.73 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06179495946971775		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.06179495946971775 | validation: 0.10394338127125607]
	TIME [epoch: 5.74 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07263453583576722		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.07263453583576722 | validation: 0.07191672875841626]
	TIME [epoch: 5.75 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05166858225380985		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.05166858225380985 | validation: 0.08757766878342402]
	TIME [epoch: 5.77 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05503575329383242		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.05503575329383242 | validation: 0.06394658730829358]
	TIME [epoch: 5.74 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06103946604905868		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.06103946604905868 | validation: 0.07237574843806201]
	TIME [epoch: 5.74 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05129890833315511		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.05129890833315511 | validation: 0.10022104955182172]
	TIME [epoch: 5.73 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05960993840120366		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.05960993840120366 | validation: 0.08049702433574296]
	TIME [epoch: 5.73 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052467100311331845		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.052467100311331845 | validation: 0.06466467803367229]
	TIME [epoch: 5.75 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050053768603914695		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.050053768603914695 | validation: 0.07194878769965513]
	TIME [epoch: 5.76 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05523634590379359		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.05523634590379359 | validation: 0.0653049273914244]
	TIME [epoch: 5.74 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049367076158676575		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.049367076158676575 | validation: 0.071556405453194]
	TIME [epoch: 5.73 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058586762317502525		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.058586762317502525 | validation: 0.07795830171104695]
	TIME [epoch: 5.73 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12352612268511436		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.12352612268511436 | validation: 0.18196051658882198]
	TIME [epoch: 5.73 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10277987594451427		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.10277987594451427 | validation: 0.07073048218499488]
	TIME [epoch: 5.75 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05196663974650656		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.05196663974650656 | validation: 0.08199573207266485]
	TIME [epoch: 5.77 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05900780122522559		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.05900780122522559 | validation: 0.12783970591921062]
	TIME [epoch: 5.74 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0902447971377352		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.0902447971377352 | validation: 0.07121262122172084]
	TIME [epoch: 5.73 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0626026909544348		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.0626026909544348 | validation: 0.08281091982682874]
	TIME [epoch: 5.74 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07836084669769879		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.07836084669769879 | validation: 0.08990602729646054]
	TIME [epoch: 5.73 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06160562681608735		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.06160562681608735 | validation: 0.09451706408327383]
	TIME [epoch: 5.75 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04928047638963813		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.04928047638963813 | validation: 0.08107549484768821]
	TIME [epoch: 5.78 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04977795743943958		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.04977795743943958 | validation: 0.07355795255610408]
	TIME [epoch: 5.74 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08764318138691075		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.08764318138691075 | validation: 0.0959546228293595]
	TIME [epoch: 5.74 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06449931520152355		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.06449931520152355 | validation: 0.06512599622926753]
	TIME [epoch: 5.73 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04858975213885233		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.04858975213885233 | validation: 0.08796795354573163]
	TIME [epoch: 5.74 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0589852096959829		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.0589852096959829 | validation: 0.09357775445313075]
	TIME [epoch: 5.75 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060985988738833104		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.060985988738833104 | validation: 0.06967548228894506]
	TIME [epoch: 5.77 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07238612925271809		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.07238612925271809 | validation: 0.1655238032416412]
	TIME [epoch: 5.74 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13853689354925808		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.13853689354925808 | validation: 0.1520358565456686]
	TIME [epoch: 5.73 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10486430546306019		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.10486430546306019 | validation: 0.09435876160593008]
	TIME [epoch: 5.73 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061995615531163596		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.061995615531163596 | validation: 0.06984088408656933]
	TIME [epoch: 5.74 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042873245952947836		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.042873245952947836 | validation: 0.06408168025489035]
	TIME [epoch: 5.75 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06253871881500567		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.06253871881500567 | validation: 0.10995873708366577]
	TIME [epoch: 5.77 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05904109537099764		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.05904109537099764 | validation: 0.07282266231462281]
	TIME [epoch: 5.74 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05683698622869662		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.05683698622869662 | validation: 0.1374809071539888]
	TIME [epoch: 5.74 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08265836799831071		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.08265836799831071 | validation: 0.06850360866496046]
	TIME [epoch: 5.73 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04935445973066792		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.04935445973066792 | validation: 0.09729392749094366]
	TIME [epoch: 5.73 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05941757493982697		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.05941757493982697 | validation: 0.07893628682355733]
	TIME [epoch: 5.75 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058213136092540786		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.058213136092540786 | validation: 0.08741421596723352]
	TIME [epoch: 5.77 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05952942732221803		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.05952942732221803 | validation: 0.07069449848982144]
	TIME [epoch: 5.74 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07235094750566408		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.07235094750566408 | validation: 0.10241735880954149]
	TIME [epoch: 5.73 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08235223795846379		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.08235223795846379 | validation: 0.06892398435325421]
	TIME [epoch: 5.73 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05284670731727512		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.05284670731727512 | validation: 0.07867669402344715]
	TIME [epoch: 5.73 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05298395269235172		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.05298395269235172 | validation: 0.09652467601611121]
	TIME [epoch: 5.75 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06933595474732308		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.06933595474732308 | validation: 0.08473342669387054]
	TIME [epoch: 5.76 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0641678483036699		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.0641678483036699 | validation: 0.09791695708877426]
	TIME [epoch: 5.74 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0560944247313053		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.0560944247313053 | validation: 0.09570369696695741]
	TIME [epoch: 5.73 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054473113755994056		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.054473113755994056 | validation: 0.07415423561057423]
	TIME [epoch: 5.74 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062400400211350765		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.062400400211350765 | validation: 0.06620820171737556]
	TIME [epoch: 5.73 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05054637744648714		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.05054637744648714 | validation: 0.10682590465558976]
	TIME [epoch: 5.75 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05317938151642012		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.05317938151642012 | validation: 0.06907101817175725]
	TIME [epoch: 5.77 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05391064870438868		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.05391064870438868 | validation: 0.06999179475096204]
	TIME [epoch: 5.74 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055239115479853225		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.055239115479853225 | validation: 0.10707646917817965]
	TIME [epoch: 5.73 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06983196029111191		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.06983196029111191 | validation: 0.08172216625691293]
	TIME [epoch: 5.73 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055681685319661604		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.055681685319661604 | validation: 0.06538954408547083]
	TIME [epoch: 5.73 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046564374682185355		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.046564374682185355 | validation: 0.06716657913440138]
	TIME [epoch: 5.75 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05251830609878245		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.05251830609878245 | validation: 0.08829325453242308]
	TIME [epoch: 5.76 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07323547363644482		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.07323547363644482 | validation: 0.06872169955767234]
	TIME [epoch: 5.74 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0576733163073377		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.0576733163073377 | validation: 0.0798441996903405]
	TIME [epoch: 5.73 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07231523401942304		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.07231523401942304 | validation: 0.0856736647144772]
	TIME [epoch: 5.73 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06031916811878179		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.06031916811878179 | validation: 0.09903690896949847]
	TIME [epoch: 5.73 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0695826678989343		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.0695826678989343 | validation: 0.14043625494166495]
	TIME [epoch: 5.75 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0822258347292437		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.0822258347292437 | validation: 0.11106066752207568]
	TIME [epoch: 5.77 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062106801323811016		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.062106801323811016 | validation: 0.08469498056691852]
	TIME [epoch: 5.74 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053689519370169865		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.053689519370169865 | validation: 0.06604675304733275]
	TIME [epoch: 5.73 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05784557656570399		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.05784557656570399 | validation: 0.07421706388659843]
	TIME [epoch: 5.73 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053833768375968996		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.053833768375968996 | validation: 0.0861203450208779]
	TIME [epoch: 5.73 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05538120112142094		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.05538120112142094 | validation: 0.08418959238922216]
	TIME [epoch: 5.75 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058679582814530694		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.058679582814530694 | validation: 0.09704617300130679]
	TIME [epoch: 5.76 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06917149746861508		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.06917149746861508 | validation: 0.07115423747672699]
	TIME [epoch: 5.73 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048283154930172184		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.048283154930172184 | validation: 0.08006066399424987]
	TIME [epoch: 5.73 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05512507065534745		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.05512507065534745 | validation: 0.08646333893741985]
	TIME [epoch: 5.73 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061192403243512765		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.061192403243512765 | validation: 0.09201119788470315]
	TIME [epoch: 5.73 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05491390754213575		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.05491390754213575 | validation: 0.08284685475358745]
	TIME [epoch: 5.75 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06331822707262709		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.06331822707262709 | validation: 0.07607360644951747]
	TIME [epoch: 5.76 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05495751557544182		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.05495751557544182 | validation: 0.07903679114828509]
	TIME [epoch: 5.74 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06004184182680822		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.06004184182680822 | validation: 0.0846788551588061]
	TIME [epoch: 5.73 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06332197782682106		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.06332197782682106 | validation: 0.12453610216445203]
	TIME [epoch: 5.73 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0872798370290946		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.0872798370290946 | validation: 0.10966650654143376]
	TIME [epoch: 5.73 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07568403145672097		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.07568403145672097 | validation: 0.07078007981301966]
	TIME [epoch: 5.75 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04940279493986936		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.04940279493986936 | validation: 0.07323933282430621]
	TIME [epoch: 5.76 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04979906774465842		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.04979906774465842 | validation: 0.07695147536481628]
	TIME [epoch: 5.74 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08689000954297335		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.08689000954297335 | validation: 0.12721114242498355]
	TIME [epoch: 5.73 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0984327296553169		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.0984327296553169 | validation: 0.09599886022333816]
	TIME [epoch: 5.73 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06843798323091399		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.06843798323091399 | validation: 0.06565013415974125]
	TIME [epoch: 5.73 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05140355101285849		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.05140355101285849 | validation: 0.06141484200450998]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_828.pth
	Model improved!!!
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039845844867484506		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.039845844867484506 | validation: 0.06355907147395853]
	TIME [epoch: 5.78 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04793436011008044		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.04793436011008044 | validation: 0.06719856438331764]
	TIME [epoch: 5.74 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051037534117420444		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.051037534117420444 | validation: 0.0747850997272016]
	TIME [epoch: 5.74 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0481913617554139		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.0481913617554139 | validation: 0.07071450602529838]
	TIME [epoch: 5.74 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06069905304688526		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.06069905304688526 | validation: 0.07219809466175942]
	TIME [epoch: 5.73 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05192352633414665		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.05192352633414665 | validation: 0.07968467485909836]
	TIME [epoch: 5.75 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0680598861014878		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.0680598861014878 | validation: 0.06556975944256539]
	TIME [epoch: 5.77 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0709827631763144		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.0709827631763144 | validation: 0.0834558108113703]
	TIME [epoch: 5.74 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052941547877029656		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.052941547877029656 | validation: 0.10823297894271633]
	TIME [epoch: 5.73 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0813924834154301		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.0813924834154301 | validation: 0.059037323497603496]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_838.pth
	Model improved!!!
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05061946995018919		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.05061946995018919 | validation: 0.07268848343700998]
	TIME [epoch: 5.73 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055405245567601014		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.055405245567601014 | validation: 0.06194175205542477]
	TIME [epoch: 5.75 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04550149297904589		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.04550149297904589 | validation: 0.05813472131718766]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_841.pth
	Model improved!!!
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050115752456281		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.050115752456281 | validation: 0.05993564989480478]
	TIME [epoch: 5.74 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04815014433206279		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.04815014433206279 | validation: 0.08542135437395901]
	TIME [epoch: 5.74 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08006178375685806		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.08006178375685806 | validation: 0.07340965453999733]
	TIME [epoch: 5.74 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054642004582337145		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.054642004582337145 | validation: 0.08474186149433745]
	TIME [epoch: 5.74 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05973308986491475		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.05973308986491475 | validation: 0.06283239039532676]
	TIME [epoch: 5.77 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049336165201759985		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.049336165201759985 | validation: 0.06008460391207235]
	TIME [epoch: 5.76 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05210165092155414		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.05210165092155414 | validation: 0.07968568963459573]
	TIME [epoch: 5.74 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051479360475177476		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.051479360475177476 | validation: 0.05800815967258718]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_849.pth
	Model improved!!!
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047848951892212395		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.047848951892212395 | validation: 0.0609264462563795]
	TIME [epoch: 5.74 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046759942207099024		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.046759942207099024 | validation: 0.05772302374124757]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_851.pth
	Model improved!!!
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04160165597884033		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.04160165597884033 | validation: 0.07159825102939482]
	TIME [epoch: 5.78 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05676003627933114		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.05676003627933114 | validation: 0.0629611304472554]
	TIME [epoch: 5.74 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05348478949122156		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.05348478949122156 | validation: 0.07049754456613622]
	TIME [epoch: 5.73 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058054421463284864		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.058054421463284864 | validation: 0.08908287969209402]
	TIME [epoch: 5.74 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06049259244911603		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.06049259244911603 | validation: 0.05202478797346546]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_856.pth
	Model improved!!!
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04538997934754482		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.04538997934754482 | validation: 0.08141914754382427]
	TIME [epoch: 5.74 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055735936631939036		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.055735936631939036 | validation: 0.057264992934218634]
	TIME [epoch: 5.77 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05345180935159021		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.05345180935159021 | validation: 0.06893111614938963]
	TIME [epoch: 5.75 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052320502506627835		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.052320502506627835 | validation: 0.07067317566861471]
	TIME [epoch: 5.74 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05535341191663525		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.05535341191663525 | validation: 0.058582920698817986]
	TIME [epoch: 5.73 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04118633537449549		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.04118633537449549 | validation: 0.0669404832195075]
	TIME [epoch: 5.73 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04804710911085562		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.04804710911085562 | validation: 0.0648851027942795]
	TIME [epoch: 5.73 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042150316939600904		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.042150316939600904 | validation: 0.07495515775853366]
	TIME [epoch: 5.77 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04445086331340347		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.04445086331340347 | validation: 0.05113651240953745]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_865.pth
	Model improved!!!
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04656528348456153		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.04656528348456153 | validation: 0.07749050047606278]
	TIME [epoch: 5.74 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05642694975061972		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.05642694975061972 | validation: 0.05484319329760475]
	TIME [epoch: 5.74 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0559421463723432		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.0559421463723432 | validation: 0.06187279545839739]
	TIME [epoch: 5.73 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053141944101368216		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.053141944101368216 | validation: 0.07058771556774547]
	TIME [epoch: 5.74 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05633848472540654		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.05633848472540654 | validation: 0.05844735762051245]
	TIME [epoch: 5.77 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03726294743077484		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.03726294743077484 | validation: 0.05754858358274506]
	TIME [epoch: 5.75 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05063768472934093		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.05063768472934093 | validation: 0.07230824378628894]
	TIME [epoch: 5.74 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057654559415784554		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.057654559415784554 | validation: 0.07084556659432444]
	TIME [epoch: 5.74 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053409640746623896		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.053409640746623896 | validation: 0.07106829664171616]
	TIME [epoch: 5.73 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07304790910908396		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.07304790910908396 | validation: 0.06503686228448036]
	TIME [epoch: 5.74 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05003212780355918		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.05003212780355918 | validation: 0.06267990654721808]
	TIME [epoch: 5.77 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04329373523118039		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.04329373523118039 | validation: 0.059126235007972386]
	TIME [epoch: 5.74 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04350202180726735		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.04350202180726735 | validation: 0.05718061941796826]
	TIME [epoch: 5.73 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0500160952970251		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.0500160952970251 | validation: 0.07821057368641672]
	TIME [epoch: 5.73 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049117322534532555		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.049117322534532555 | validation: 0.05533593189348685]
	TIME [epoch: 5.74 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04405068666278138		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.04405068666278138 | validation: 0.060528839490639134]
	TIME [epoch: 5.73 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04076467912005446		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.04076467912005446 | validation: 0.06871361198451863]
	TIME [epoch: 5.77 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04209516774868669		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.04209516774868669 | validation: 0.06243052207503211]
	TIME [epoch: 5.75 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04990524749157069		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.04990524749157069 | validation: 0.06270920390893157]
	TIME [epoch: 5.73 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04770754155084528		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.04770754155084528 | validation: 0.054860665522410715]
	TIME [epoch: 5.74 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04636735733217502		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.04636735733217502 | validation: 0.0773580824991142]
	TIME [epoch: 5.73 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044002845357035		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.044002845357035 | validation: 0.05094801816850035]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_887.pth
	Model improved!!!
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04077281647239034		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.04077281647239034 | validation: 0.06998797181031705]
	TIME [epoch: 5.78 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04495132577251615		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.04495132577251615 | validation: 0.09312114179705101]
	TIME [epoch: 5.74 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06710453574109856		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.06710453574109856 | validation: 0.09299516750557796]
	TIME [epoch: 5.73 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04999354472628674		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.04999354472628674 | validation: 0.07557000891248677]
	TIME [epoch: 5.73 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04632518222730126		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.04632518222730126 | validation: 0.0726483640894245]
	TIME [epoch: 5.73 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051170921197754585		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.051170921197754585 | validation: 0.057754758719301906]
	TIME [epoch: 5.74 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06661687929799504		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.06661687929799504 | validation: 0.06987436705645267]
	TIME [epoch: 5.77 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04177719602450284		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.04177719602450284 | validation: 0.05535606805108348]
	TIME [epoch: 5.74 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04067038021171835		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.04067038021171835 | validation: 0.06281882930410208]
	TIME [epoch: 5.73 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062061265514129424		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.062061265514129424 | validation: 0.07109217469557105]
	TIME [epoch: 5.73 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06978731247618145		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.06978731247618145 | validation: 0.08453046826500554]
	TIME [epoch: 5.73 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0566124547619818		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.0566124547619818 | validation: 0.05478709538027566]
	TIME [epoch: 5.73 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04290154783209322		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.04290154783209322 | validation: 0.0786974987600854]
	TIME [epoch: 5.77 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05753299982161321		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.05753299982161321 | validation: 0.09771951866971094]
	TIME [epoch: 5.74 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07850642217880378		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.07850642217880378 | validation: 0.06766046839723912]
	TIME [epoch: 5.73 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04033785597212768		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.04033785597212768 | validation: 0.06986943881801057]
	TIME [epoch: 5.73 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04555420797231291		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.04555420797231291 | validation: 0.05572713794751456]
	TIME [epoch: 5.74 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04591988292671294		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.04591988292671294 | validation: 0.06714628356797966]
	TIME [epoch: 5.73 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04823515435899298		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.04823515435899298 | validation: 0.06465564026904769]
	TIME [epoch: 5.77 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05052288009984873		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.05052288009984873 | validation: 0.09466263066073996]
	TIME [epoch: 5.74 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0726749679444634		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.0726749679444634 | validation: 0.06734144940532791]
	TIME [epoch: 5.73 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04854010194721778		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.04854010194721778 | validation: 0.0637308673723769]
	TIME [epoch: 5.73 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0418047129218706		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.0418047129218706 | validation: 0.066641882951011]
	TIME [epoch: 5.73 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050159383022444645		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.050159383022444645 | validation: 0.06465275828978237]
	TIME [epoch: 5.73 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04797240290734003		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.04797240290734003 | validation: 0.05645824014296373]
	TIME [epoch: 5.77 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04440622129291667		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.04440622129291667 | validation: 0.06651081131943729]
	TIME [epoch: 5.74 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04450899212373841		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.04450899212373841 | validation: 0.05960029069810277]
	TIME [epoch: 5.73 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04157834199741506		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.04157834199741506 | validation: 0.06099841158602388]
	TIME [epoch: 5.73 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047077808572858454		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.047077808572858454 | validation: 0.05814904543142051]
	TIME [epoch: 5.73 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043803929966850084		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.043803929966850084 | validation: 0.06484585015195572]
	TIME [epoch: 5.73 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052379963395310855		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.052379963395310855 | validation: 0.05373854180688531]
	TIME [epoch: 5.77 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04851038950666351		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.04851038950666351 | validation: 0.06999488021267831]
	TIME [epoch: 5.74 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07154923873811662		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.07154923873811662 | validation: 0.07667758078696092]
	TIME [epoch: 5.73 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044767780469437635		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.044767780469437635 | validation: 0.05890628135666268]
	TIME [epoch: 5.73 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04574418542494561		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.04574418542494561 | validation: 0.057325659806333404]
	TIME [epoch: 5.74 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04437307750142577		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.04437307750142577 | validation: 0.05851537479768066]
	TIME [epoch: 5.73 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052039208284390494		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.052039208284390494 | validation: 0.09251626342815245]
	TIME [epoch: 5.77 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06722254692235675		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.06722254692235675 | validation: 0.05456213396795673]
	TIME [epoch: 5.75 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047498292506260156		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.047498292506260156 | validation: 0.08076298391310044]
	TIME [epoch: 5.74 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054835176658990986		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.054835176658990986 | validation: 0.06013647570979579]
	TIME [epoch: 5.74 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03397534647533826		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.03397534647533826 | validation: 0.06304903025729656]
	TIME [epoch: 5.74 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037814068245770965		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.037814068245770965 | validation: 0.06676369844027016]
	TIME [epoch: 5.73 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041866208074922875		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.041866208074922875 | validation: 0.05523554163372394]
	TIME [epoch: 5.78 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038698069981512616		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.038698069981512616 | validation: 0.05675472905126865]
	TIME [epoch: 5.75 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047405052554120905		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.047405052554120905 | validation: 0.060498337748399286]
	TIME [epoch: 5.73 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038430935724524135		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.038430935724524135 | validation: 0.05405563279769293]
	TIME [epoch: 5.74 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04815480764142632		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.04815480764142632 | validation: 0.05530867657308498]
	TIME [epoch: 5.73 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04034800617355675		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.04034800617355675 | validation: 0.0670666964050559]
	TIME [epoch: 5.74 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04380710749736525		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.04380710749736525 | validation: 0.05447570647233341]
	TIME [epoch: 5.78 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05914762932466057		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.05914762932466057 | validation: 0.07367175381165468]
	TIME [epoch: 5.74 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045689866955231674		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.045689866955231674 | validation: 0.05202137654833282]
	TIME [epoch: 5.74 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04359365740653527		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.04359365740653527 | validation: 0.056859734598862344]
	TIME [epoch: 5.74 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036026826310753046		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.036026826310753046 | validation: 0.06000079978651034]
	TIME [epoch: 5.73 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045871485021722766		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.045871485021722766 | validation: 0.05665347105085003]
	TIME [epoch: 5.73 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03802166512525287		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.03802166512525287 | validation: 0.06576704527289608]
	TIME [epoch: 5.77 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04524563479549894		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.04524563479549894 | validation: 0.06797796882202621]
	TIME [epoch: 5.74 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04071359033407407		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.04071359033407407 | validation: 0.06463972555870065]
	TIME [epoch: 5.73 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04153292680383934		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.04153292680383934 | validation: 0.05367632463648416]
	TIME [epoch: 5.73 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036620325451968416		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.036620325451968416 | validation: 0.052220707118316174]
	TIME [epoch: 5.73 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04563454889616972		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.04563454889616972 | validation: 0.06083265402889865]
	TIME [epoch: 5.73 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04195341088400675		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.04195341088400675 | validation: 0.058731936349976074]
	TIME [epoch: 5.77 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036755582479856254		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.036755582479856254 | validation: 0.05175798397342163]
	TIME [epoch: 5.74 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041970792247577354		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.041970792247577354 | validation: 0.06502296170387445]
	TIME [epoch: 5.73 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04553959976801994		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.04553959976801994 | validation: 0.06875262041946231]
	TIME [epoch: 5.74 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05010590003933512		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.05010590003933512 | validation: 0.060067582733565814]
	TIME [epoch: 5.73 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040452867971366005		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.040452867971366005 | validation: 0.06107577331335059]
	TIME [epoch: 5.73 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04335696164940997		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.04335696164940997 | validation: 0.0589740528693411]
	TIME [epoch: 5.78 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0369027346738273		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.0369027346738273 | validation: 0.06747020114176218]
	TIME [epoch: 5.74 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043792545088729165		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.043792545088729165 | validation: 0.06533398714778382]
	TIME [epoch: 5.73 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04977756608660869		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.04977756608660869 | validation: 0.0686101844413975]
	TIME [epoch: 5.73 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04305422799405173		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.04305422799405173 | validation: 0.05560711725116175]
	TIME [epoch: 5.73 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045719537789772224		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.045719537789772224 | validation: 0.05548025513194201]
	TIME [epoch: 5.74 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04697049932189054		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.04697049932189054 | validation: 0.057002246553307184]
	TIME [epoch: 5.77 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04137645978279322		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.04137645978279322 | validation: 0.0780526923810422]
	TIME [epoch: 5.74 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04501659954081675		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.04501659954081675 | validation: 0.05783826451962929]
	TIME [epoch: 5.73 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03956760846807967		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.03956760846807967 | validation: 0.06888010208748323]
	TIME [epoch: 5.73 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05160669164420466		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.05160669164420466 | validation: 0.07213352617435095]
	TIME [epoch: 5.73 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04814502962131485		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.04814502962131485 | validation: 0.05626995850782557]
	TIME [epoch: 5.73 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04059825641040897		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.04059825641040897 | validation: 0.051990108120830686]
	TIME [epoch: 5.77 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04494682394969995		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.04494682394969995 | validation: 0.05772894988518072]
	TIME [epoch: 5.75 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042296465636701905		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.042296465636701905 | validation: 0.05803090426397502]
	TIME [epoch: 5.74 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04283144761947924		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.04283144761947924 | validation: 0.07109024050150321]
	TIME [epoch: 5.74 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03680624066248383		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.03680624066248383 | validation: 0.049754686802695486]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_970.pth
	Model improved!!!
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03970736874743619		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.03970736874743619 | validation: 0.05839661158397274]
	TIME [epoch: 5.74 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03747493115155549		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.03747493115155549 | validation: 0.05752218147901884]
	TIME [epoch: 5.77 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038971964001693414		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.038971964001693414 | validation: 0.050681217762702194]
	TIME [epoch: 5.74 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038966087724445174		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.038966087724445174 | validation: 0.05598677173442086]
	TIME [epoch: 5.74 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05784360696762825		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.05784360696762825 | validation: 0.07468230810307869]
	TIME [epoch: 5.73 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0499622408845652		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.0499622408845652 | validation: 0.070715302586335]
	TIME [epoch: 5.74 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05561720041624602		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.05561720041624602 | validation: 0.06604744484162924]
	TIME [epoch: 5.74 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0487618272123798		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.0487618272123798 | validation: 0.05026971023268818]
	TIME [epoch: 5.77 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03917553590906182		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.03917553590906182 | validation: 0.03935073394372363]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_979.pth
	Model improved!!!
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03437192276403716		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.03437192276403716 | validation: 0.05261311561277463]
	TIME [epoch: 5.74 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03690595400925007		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.03690595400925007 | validation: 0.05735308713642553]
	TIME [epoch: 5.73 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03762432639250747		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.03762432639250747 | validation: 0.05080160342908172]
	TIME [epoch: 5.73 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037148825051086645		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.037148825051086645 | validation: 0.053389934889982824]
	TIME [epoch: 5.74 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04262027422948442		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.04262027422948442 | validation: 0.059443176421004634]
	TIME [epoch: 5.77 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03970204940870724		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.03970204940870724 | validation: 0.055979789305110154]
	TIME [epoch: 5.74 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04276604088747671		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.04276604088747671 | validation: 0.05084822313278684]
	TIME [epoch: 5.73 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038754594650501316		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.038754594650501316 | validation: 0.05128637127396555]
	TIME [epoch: 5.74 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037091258405212955		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.037091258405212955 | validation: 0.06296638246539776]
	TIME [epoch: 5.73 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04850741663376798		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.04850741663376798 | validation: 0.05450841910797511]
	TIME [epoch: 5.74 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0437862553833057		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.0437862553833057 | validation: 0.07079390997675013]
	TIME [epoch: 5.77 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0406182935299198		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.0406182935299198 | validation: 0.0516226605843938]
	TIME [epoch: 5.74 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04151674543352658		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.04151674543352658 | validation: 0.0592328904076167]
	TIME [epoch: 5.74 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04323497774632382		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.04323497774632382 | validation: 0.06661185322337734]
	TIME [epoch: 5.73 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045781377380355565		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.045781377380355565 | validation: 0.06419377269053175]
	TIME [epoch: 5.73 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043272542306627575		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.043272542306627575 | validation: 0.06397639436673433]
	TIME [epoch: 5.74 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06352263389428851		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.06352263389428851 | validation: 0.1130074758968609]
	TIME [epoch: 5.77 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05680223249490137		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.05680223249490137 | validation: 0.0545813064638294]
	TIME [epoch: 5.74 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035622926320118826		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.035622926320118826 | validation: 0.052919224999801555]
	TIME [epoch: 5.73 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043506119096767555		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.043506119096767555 | validation: 0.05789715048137151]
	TIME [epoch: 5.73 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040795468496661845		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.040795468496661845 | validation: 0.06492183007333846]
	TIME [epoch: 5.73 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0576592631433824		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.0576592631433824 | validation: 0.07420764046468106]
	TIME [epoch: 5.74 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04899494951465604		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.04899494951465604 | validation: 0.06101991157993036]
	TIME [epoch: 5.77 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030874763547300905		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.030874763547300905 | validation: 0.05966552854913481]
	TIME [epoch: 5.74 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04865577047483015		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.04865577047483015 | validation: 0.06743529094186357]
	TIME [epoch: 5.73 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05804416441914358		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.05804416441914358 | validation: 0.06212219157884324]
	TIME [epoch: 5.73 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036099861339716974		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.036099861339716974 | validation: 0.05561887405008856]
	TIME [epoch: 5.73 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03358845465358438		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.03358845465358438 | validation: 0.06094040335101122]
	TIME [epoch: 5.74 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03113697108705757		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.03113697108705757 | validation: 0.05393050786207537]
	TIME [epoch: 5.77 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03836907484553712		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.03836907484553712 | validation: 0.060729703808480424]
	TIME [epoch: 5.74 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03997184833788949		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.03997184833788949 | validation: 0.05203218177258162]
	TIME [epoch: 5.73 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040644239930167574		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.040644239930167574 | validation: 0.055351033915880254]
	TIME [epoch: 5.73 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03858691597886608		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.03858691597886608 | validation: 0.04887247509695348]
	TIME [epoch: 5.73 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039111316126285656		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.039111316126285656 | validation: 0.05289840878348104]
	TIME [epoch: 5.74 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04129790314054737		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.04129790314054737 | validation: 0.06356166416314657]
	TIME [epoch: 5.77 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03945670044293422		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.03945670044293422 | validation: 0.06287100172812575]
	TIME [epoch: 5.74 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03924976668468022		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.03924976668468022 | validation: 0.05151672321594706]
	TIME [epoch: 5.73 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03818037218806783		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.03818037218806783 | validation: 0.0541517770982151]
	TIME [epoch: 5.74 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03972453239404389		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.03972453239404389 | validation: 0.053252938484291835]
	TIME [epoch: 5.73 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04284892986720505		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.04284892986720505 | validation: 0.0560377679173837]
	TIME [epoch: 5.74 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046588478485996905		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.046588478485996905 | validation: 0.07730817970172867]
	TIME [epoch: 5.77 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04398043555105582		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.04398043555105582 | validation: 0.049951629794214664]
	TIME [epoch: 5.74 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035438810173415165		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.035438810173415165 | validation: 0.053705637933711387]
	TIME [epoch: 5.73 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03398268261027681		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.03398268261027681 | validation: 0.052096401756578654]
	TIME [epoch: 5.73 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03897345142048589		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.03897345142048589 | validation: 0.048520344844242135]
	TIME [epoch: 5.73 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034743901299103805		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.034743901299103805 | validation: 0.058849449723538276]
	TIME [epoch: 5.74 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03380023344368888		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.03380023344368888 | validation: 0.03384327544080724]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_1026.pth
	Model improved!!!
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04158085446586919		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.04158085446586919 | validation: 0.06409127224406543]
	TIME [epoch: 5.74 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03907607053634733		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.03907607053634733 | validation: 0.057831572049399864]
	TIME [epoch: 5.73 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035619541604637976		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.035619541604637976 | validation: 0.059541424912017256]
	TIME [epoch: 5.73 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05031890657412631		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.05031890657412631 | validation: 0.056913088892370275]
	TIME [epoch: 5.73 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04559861308176294		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.04559861308176294 | validation: 0.05984062902890751]
	TIME [epoch: 5.74 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04131068107882778		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.04131068107882778 | validation: 0.049258736367493075]
	TIME [epoch: 5.77 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03734286926566764		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.03734286926566764 | validation: 0.0496990657072194]
	TIME [epoch: 5.74 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04096917249075187		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.04096917249075187 | validation: 0.05898652529882614]
	TIME [epoch: 5.73 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046349289784734224		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.046349289784734224 | validation: 0.0626414043721793]
	TIME [epoch: 5.73 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04664704752926112		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.04664704752926112 | validation: 0.052881895458951535]
	TIME [epoch: 5.73 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034837216115759136		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.034837216115759136 | validation: 0.06826275463012153]
	TIME [epoch: 5.74 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04993300871527351		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.04993300871527351 | validation: 0.05457757847293578]
	TIME [epoch: 5.77 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03674848140602605		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.03674848140602605 | validation: 0.0528392716308247]
	TIME [epoch: 5.74 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03338020231918383		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.03338020231918383 | validation: 0.05881241534032837]
	TIME [epoch: 5.73 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0356053367222147		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.0356053367222147 | validation: 0.04766309375592444]
	TIME [epoch: 5.74 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038287360822533006		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.038287360822533006 | validation: 0.05938900392542836]
	TIME [epoch: 5.73 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05157414318525355		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.05157414318525355 | validation: 0.05279766497450119]
	TIME [epoch: 5.74 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0403536207068866		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.0403536207068866 | validation: 0.04710781330175927]
	TIME [epoch: 5.77 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03525431977470049		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.03525431977470049 | validation: 0.053672509521226264]
	TIME [epoch: 5.74 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03502906515321484		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.03502906515321484 | validation: 0.046853457335386164]
	TIME [epoch: 5.73 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035044742739426954		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.035044742739426954 | validation: 0.04646108283384365]
	TIME [epoch: 5.73 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03486028057791267		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.03486028057791267 | validation: 0.05833970683459361]
	TIME [epoch: 5.73 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036032377791102105		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.036032377791102105 | validation: 0.04724859785501891]
	TIME [epoch: 5.74 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0405379141355903		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.0405379141355903 | validation: 0.04839330090236496]
	TIME [epoch: 5.77 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035203897641606495		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.035203897641606495 | validation: 0.04790585937227725]
	TIME [epoch: 5.74 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045959284517760934		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.045959284517760934 | validation: 0.05206719456533364]
	TIME [epoch: 5.73 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03630138023031139		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.03630138023031139 | validation: 0.04692478485210575]
	TIME [epoch: 5.73 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03268701074147914		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.03268701074147914 | validation: 0.04712627035667696]
	TIME [epoch: 5.73 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036469964071971825		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.036469964071971825 | validation: 0.05490118199028438]
	TIME [epoch: 5.74 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04463031291342374		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.04463031291342374 | validation: 0.0571301265967122]
	TIME [epoch: 5.77 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03222064409070134		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.03222064409070134 | validation: 0.052362717719326976]
	TIME [epoch: 5.74 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034271640727918946		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.034271640727918946 | validation: 0.04849129803192987]
	TIME [epoch: 5.73 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031249138528508757		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.031249138528508757 | validation: 0.05086165597166671]
	TIME [epoch: 5.73 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03800234170296224		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.03800234170296224 | validation: 0.04837972832894949]
	TIME [epoch: 5.73 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0343404405251101		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.0343404405251101 | validation: 0.052148538333025976]
	TIME [epoch: 5.73 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041321497436105074		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.041321497436105074 | validation: 0.050526251426074524]
	TIME [epoch: 5.77 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03654846891312151		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.03654846891312151 | validation: 0.04788264846760479]
	TIME [epoch: 5.74 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03796539388535441		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.03796539388535441 | validation: 0.06385489355974265]
	TIME [epoch: 5.73 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05794203752788655		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.05794203752788655 | validation: 0.08133577909809983]
	TIME [epoch: 5.73 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04721563230852716		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.04721563230852716 | validation: 0.06255376276468437]
	TIME [epoch: 5.73 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034096970635753406		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.034096970635753406 | validation: 0.04844544850560302]
	TIME [epoch: 5.73 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03660046911989305		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.03660046911989305 | validation: 0.050203836514206096]
	TIME [epoch: 5.77 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04333526983167277		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.04333526983167277 | validation: 0.0653826073354303]
	TIME [epoch: 5.73 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054791319615070944		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.054791319615070944 | validation: 0.0453607712467377]
	TIME [epoch: 5.73 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03651379131064262		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.03651379131064262 | validation: 0.04773619216426677]
	TIME [epoch: 5.73 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03617404911723412		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.03617404911723412 | validation: 0.051558546776167884]
	TIME [epoch: 5.73 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039552587102612384		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.039552587102612384 | validation: 0.04468195221448207]
	TIME [epoch: 5.73 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03856032994722215		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.03856032994722215 | validation: 0.04659491817956043]
	TIME [epoch: 5.77 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03753740906764595		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.03753740906764595 | validation: 0.0463842902070423]
	TIME [epoch: 5.74 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03136664565341345		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.03136664565341345 | validation: 0.05151014781805003]
	TIME [epoch: 5.73 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03412382358516625		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.03412382358516625 | validation: 0.04702493148183232]
	TIME [epoch: 5.73 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03150603655102528		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.03150603655102528 | validation: 0.07128259736014042]
	TIME [epoch: 5.73 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03935033684721277		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.03935033684721277 | validation: 0.04038073932821025]
	TIME [epoch: 5.73 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046040900274869075		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.046040900274869075 | validation: 0.06419580379298354]
	TIME [epoch: 5.77 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045053609266303224		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.045053609266303224 | validation: 0.060388917668342694]
	TIME [epoch: 5.74 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0402433289268413		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.0402433289268413 | validation: 0.053993490990812305]
	TIME [epoch: 5.73 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03509724979620592		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.03509724979620592 | validation: 0.04186217887719573]
	TIME [epoch: 5.73 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030731440337642118		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.030731440337642118 | validation: 0.04546048708337647]
	TIME [epoch: 5.73 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04376654082554397		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.04376654082554397 | validation: 0.05575578771739147]
	TIME [epoch: 5.73 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043006038404194945		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.043006038404194945 | validation: 0.04822058519549589]
	TIME [epoch: 5.77 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03722109184902599		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.03722109184902599 | validation: 0.05378115232625023]
	TIME [epoch: 5.74 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036428303960772755		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.036428303960772755 | validation: 0.05381401917866135]
	TIME [epoch: 5.73 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03581372675553036		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.03581372675553036 | validation: 0.04677609950038647]
	TIME [epoch: 5.73 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03461946428642082		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.03461946428642082 | validation: 0.06108164617208723]
	TIME [epoch: 5.73 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04031516731490119		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.04031516731490119 | validation: 0.06733790081160565]
	TIME [epoch: 5.73 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05227489710809921		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.05227489710809921 | validation: 0.06911967763484456]
	TIME [epoch: 5.77 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05457179185660509		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.05457179185660509 | validation: 0.07086400849211573]
	TIME [epoch: 5.74 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03876514981440392		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.03876514981440392 | validation: 0.03833964041465391]
	TIME [epoch: 5.73 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03164384871757153		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.03164384871757153 | validation: 0.04785853559201673]
	TIME [epoch: 5.73 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03722846579056492		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.03722846579056492 | validation: 0.042247455647051034]
	TIME [epoch: 5.73 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03706323673846026		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.03706323673846026 | validation: 0.039884855842387906]
	TIME [epoch: 5.73 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03834816399749042		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.03834816399749042 | validation: 0.0528726596127577]
	TIME [epoch: 5.77 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03700433532051302		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.03700433532051302 | validation: 0.04856036695340716]
	TIME [epoch: 5.74 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030740101155998525		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.030740101155998525 | validation: 0.04604888502950466]
	TIME [epoch: 5.73 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0314487505969702		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.0314487505969702 | validation: 0.05256150210041404]
	TIME [epoch: 5.73 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04386818475821854		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.04386818475821854 | validation: 0.06861748160432636]
	TIME [epoch: 5.73 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03430144087127981		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.03430144087127981 | validation: 0.04940012224111774]
	TIME [epoch: 5.73 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03123715039745081		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.03123715039745081 | validation: 0.05627603662005489]
	TIME [epoch: 5.77 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03475536345019405		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.03475536345019405 | validation: 0.04881298520098908]
	TIME [epoch: 5.74 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03264233615135134		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.03264233615135134 | validation: 0.05196863325366028]
	TIME [epoch: 5.73 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02709511370508248		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.02709511370508248 | validation: 0.04882584092297128]
	TIME [epoch: 5.73 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032310339234728966		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.032310339234728966 | validation: 0.06033164483053265]
	TIME [epoch: 5.73 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04103156599353523		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.04103156599353523 | validation: 0.05738001170977609]
	TIME [epoch: 5.73 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03280735539614925		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.03280735539614925 | validation: 0.06285580839035916]
	TIME [epoch: 5.77 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033714389524007404		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.033714389524007404 | validation: 0.05241143383975779]
	TIME [epoch: 5.74 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032565005238649816		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.032565005238649816 | validation: 0.049476448100005205]
	TIME [epoch: 5.73 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02864479444873098		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.02864479444873098 | validation: 0.053067317652995175]
	TIME [epoch: 5.73 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03608068752334109		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.03608068752334109 | validation: 0.04259431221355979]
	TIME [epoch: 5.73 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033749539546258325		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.033749539546258325 | validation: 0.049100014714390953]
	TIME [epoch: 5.73 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028150638636619863		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.028150638636619863 | validation: 0.052097374611565515]
	TIME [epoch: 5.77 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03367473569556992		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.03367473569556992 | validation: 0.05451427046321722]
	TIME [epoch: 5.74 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04217195370228722		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.04217195370228722 | validation: 0.05894363557140061]
	TIME [epoch: 5.73 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051442875022544944		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.051442875022544944 | validation: 0.07717934201582527]
	TIME [epoch: 5.73 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057688495695148466		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.057688495695148466 | validation: 0.05621568282052403]
	TIME [epoch: 5.73 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03558354208493497		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.03558354208493497 | validation: 0.05503503166968351]
	TIME [epoch: 5.73 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0330714367335557		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.0330714367335557 | validation: 0.0527767755765621]
	TIME [epoch: 5.77 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036886271528262536		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.036886271528262536 | validation: 0.060190354165678465]
	TIME [epoch: 5.74 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033899273919327434		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.033899273919327434 | validation: 0.05618032340192344]
	TIME [epoch: 5.73 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03916521463884637		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.03916521463884637 | validation: 0.06237766328496951]
	TIME [epoch: 5.73 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03419444797584974		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.03419444797584974 | validation: 0.05631339857233975]
	TIME [epoch: 5.73 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03729701423026913		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.03729701423026913 | validation: 0.06305490743875602]
	TIME [epoch: 5.73 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035088427399706634		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.035088427399706634 | validation: 0.05557446124501121]
	TIME [epoch: 5.77 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034776147605283504		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.034776147605283504 | validation: 0.046157476233646196]
	TIME [epoch: 5.74 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030615484746903142		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.030615484746903142 | validation: 0.045198577569589046]
	TIME [epoch: 5.73 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03578899387030015		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.03578899387030015 | validation: 0.058503990898060805]
	TIME [epoch: 5.73 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03727337933676225		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.03727337933676225 | validation: 0.05800660381785633]
	TIME [epoch: 5.73 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039294632306583255		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.039294632306583255 | validation: 0.05108110024887897]
	TIME [epoch: 5.73 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037614200809804536		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.037614200809804536 | validation: 0.0482977948329984]
	TIME [epoch: 5.77 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03570601090498357		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.03570601090498357 | validation: 0.05229843808074704]
	TIME [epoch: 5.74 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030010189511925297		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.030010189511925297 | validation: 0.04040534160609379]
	TIME [epoch: 5.73 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03216747533389848		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.03216747533389848 | validation: 0.052204171788695915]
	TIME [epoch: 5.73 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02859688517023552		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.02859688517023552 | validation: 0.05458472646137603]
	TIME [epoch: 5.73 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032844110808644945		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.032844110808644945 | validation: 0.05690437033991003]
	TIME [epoch: 5.73 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036404825921510967		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.036404825921510967 | validation: 0.05764123540786452]
	TIME [epoch: 5.77 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035735505710582774		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.035735505710582774 | validation: 0.07111369493219642]
	TIME [epoch: 5.74 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03332500316844181		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.03332500316844181 | validation: 0.0476363845114498]
	TIME [epoch: 5.73 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03582537855947459		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.03582537855947459 | validation: 0.05235795829706953]
	TIME [epoch: 5.73 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0330710661836783		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.0330710661836783 | validation: 0.06317869810309037]
	TIME [epoch: 5.73 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03978408949296122		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.03978408949296122 | validation: 0.06270010274999697]
	TIME [epoch: 5.73 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0354413524086823		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.0354413524086823 | validation: 0.050048975229354906]
	TIME [epoch: 5.77 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030649729145498593		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.030649729145498593 | validation: 0.050016356859594054]
	TIME [epoch: 5.74 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037695923916910054		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.037695923916910054 | validation: 0.056578055967141626]
	TIME [epoch: 5.73 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03695031903170558		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.03695031903170558 | validation: 0.052205193918993295]
	TIME [epoch: 5.73 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028335697129490904		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.028335697129490904 | validation: 0.04317583643820021]
	TIME [epoch: 5.73 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031839781281743355		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.031839781281743355 | validation: 0.041494634758140664]
	TIME [epoch: 5.73 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03193686625720103		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.03193686625720103 | validation: 0.043648320833571806]
	TIME [epoch: 5.77 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031957960226999566		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.031957960226999566 | validation: 0.04715753043985394]
	TIME [epoch: 5.74 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035543437306122375		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.035543437306122375 | validation: 0.049857555512600835]
	TIME [epoch: 5.73 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031299010666915185		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.031299010666915185 | validation: 0.04437308381949825]
	TIME [epoch: 5.73 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030233949758514		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.030233949758514 | validation: 0.05143166245878801]
	TIME [epoch: 5.73 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034501139484935106		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.034501139484935106 | validation: 0.05831024379188622]
	TIME [epoch: 5.73 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02953164406631987		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.02953164406631987 | validation: 0.05409427859777118]
	TIME [epoch: 5.77 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0351709822705793		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.0351709822705793 | validation: 0.04916306177937569]
	TIME [epoch: 5.74 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03129681527588274		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.03129681527588274 | validation: 0.04344619696488753]
	TIME [epoch: 5.73 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029432978249113655		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.029432978249113655 | validation: 0.060570159506624165]
	TIME [epoch: 5.73 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03441098973121806		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.03441098973121806 | validation: 0.05469139900849398]
	TIME [epoch: 5.73 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03172129073678348		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.03172129073678348 | validation: 0.05215177741573832]
	TIME [epoch: 5.73 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03183754553053937		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.03183754553053937 | validation: 0.03757786448416442]
	TIME [epoch: 5.77 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035460227817624514		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.035460227817624514 | validation: 0.051865661583592314]
	TIME [epoch: 5.74 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033433582265086345		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.033433582265086345 | validation: 0.04747143320465771]
	TIME [epoch: 5.73 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029330499222722274		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.029330499222722274 | validation: 0.04374808961336157]
	TIME [epoch: 5.73 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03553748294908308		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.03553748294908308 | validation: 0.060907889871245846]
	TIME [epoch: 5.73 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027068234771572407		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.027068234771572407 | validation: 0.04986842571448956]
	TIME [epoch: 5.73 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0351307783032261		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.0351307783032261 | validation: 0.05192936496958104]
	TIME [epoch: 5.77 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030307784129706666		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.030307784129706666 | validation: 0.04524301201067763]
	TIME [epoch: 5.74 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033799136155909716		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.033799136155909716 | validation: 0.05697501711697297]
	TIME [epoch: 5.73 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034601063022108504		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.034601063022108504 | validation: 0.059554773132608735]
	TIME [epoch: 5.73 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033415406736691966		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.033415406736691966 | validation: 0.053430611178536]
	TIME [epoch: 5.73 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029435440774493768		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.029435440774493768 | validation: 0.047003469128148505]
	TIME [epoch: 5.73 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0420235871197229		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.0420235871197229 | validation: 0.04357331748063527]
	TIME [epoch: 5.77 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029704532950770073		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.029704532950770073 | validation: 0.04480472310293405]
	TIME [epoch: 5.74 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033403770506456654		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.033403770506456654 | validation: 0.0434670814807578]
	TIME [epoch: 5.73 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03209006927711778		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.03209006927711778 | validation: 0.04786030748027999]
	TIME [epoch: 5.73 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03533746331687207		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.03533746331687207 | validation: 0.05345435918107995]
	TIME [epoch: 5.73 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03329790143525588		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.03329790143525588 | validation: 0.07307867271500328]
	TIME [epoch: 5.73 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041281774165841605		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.041281774165841605 | validation: 0.06017158222408388]
	TIME [epoch: 5.77 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04002144265269585		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.04002144265269585 | validation: 0.06114169812974965]
	TIME [epoch: 5.74 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04170225638876488		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.04170225638876488 | validation: 0.054625866786680195]
	TIME [epoch: 5.73 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034382390802277965		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.034382390802277965 | validation: 0.05643514705477296]
	TIME [epoch: 5.73 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03622884344729235		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.03622884344729235 | validation: 0.05301099863867827]
	TIME [epoch: 5.73 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041410524515847175		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.041410524515847175 | validation: 0.05297716646471878]
	TIME [epoch: 5.73 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03146948524372952		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.03146948524372952 | validation: 0.052113480590306425]
	TIME [epoch: 5.77 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0326983598530494		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.0326983598530494 | validation: 0.05386399551384169]
	TIME [epoch: 5.74 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03320153430216706		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.03320153430216706 | validation: 0.0536340469648225]
	TIME [epoch: 5.73 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03492208499464266		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.03492208499464266 | validation: 0.06646718376191818]
	TIME [epoch: 5.73 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03607486413603821		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.03607486413603821 | validation: 0.04188246971162154]
	TIME [epoch: 5.73 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03289242586374316		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.03289242586374316 | validation: 0.05024501340510486]
	TIME [epoch: 5.73 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026139515676270104		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.026139515676270104 | validation: 0.04714785871066239]
	TIME [epoch: 5.77 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034806705671405855		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.034806705671405855 | validation: 0.0487745545635014]
	TIME [epoch: 5.74 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030836921096009648		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.030836921096009648 | validation: 0.039173727164873544]
	TIME [epoch: 5.73 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02938290862493856		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.02938290862493856 | validation: 0.04784836816500345]
	TIME [epoch: 5.73 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03278957803772353		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.03278957803772353 | validation: 0.042420434840920083]
	TIME [epoch: 5.73 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02998722338188581		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.02998722338188581 | validation: 0.048779803874719606]
	TIME [epoch: 5.73 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032091013115754664		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.032091013115754664 | validation: 0.05414851917682935]
	TIME [epoch: 5.77 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03502050939370825		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.03502050939370825 | validation: 0.0581015737923429]
	TIME [epoch: 5.74 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03473343158397783		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.03473343158397783 | validation: 0.053782928290738864]
	TIME [epoch: 5.73 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0391756599723703		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.0391756599723703 | validation: 0.0545619019019167]
	TIME [epoch: 5.73 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035925584099143267		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.035925584099143267 | validation: 0.04755770673189906]
	TIME [epoch: 5.73 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034224226929974816		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.034224226929974816 | validation: 0.04582618617915979]
	TIME [epoch: 5.73 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03575614896940626		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.03575614896940626 | validation: 0.05047767532774383]
	TIME [epoch: 5.77 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03090575067396062		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.03090575067396062 | validation: 0.04804609986161533]
	TIME [epoch: 5.74 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03529133868842538		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.03529133868842538 | validation: 0.057511971553641635]
	TIME [epoch: 5.73 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036216133682563025		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.036216133682563025 | validation: 0.05040819569335026]
	TIME [epoch: 5.73 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0300162680289814		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.0300162680289814 | validation: 0.049724811147138476]
	TIME [epoch: 5.73 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032737377491338614		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.032737377491338614 | validation: 0.054390652587384285]
	TIME [epoch: 5.73 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03619612254438643		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.03619612254438643 | validation: 0.061127060908267035]
	TIME [epoch: 5.77 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037244052375213534		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.037244052375213534 | validation: 0.054243905285221196]
	TIME [epoch: 5.74 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030014770949668486		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.030014770949668486 | validation: 0.049524797813126256]
	TIME [epoch: 5.73 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028709961232852726		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.028709961232852726 | validation: 0.056070103957129434]
	TIME [epoch: 5.73 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028621742973886515		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.028621742973886515 | validation: 0.05188276112074748]
	TIME [epoch: 5.73 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029443164330697272		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.029443164330697272 | validation: 0.04489265863951816]
	TIME [epoch: 5.73 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027054111888507544		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.027054111888507544 | validation: 0.04718587918276593]
	TIME [epoch: 5.77 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03196430284047936		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.03196430284047936 | validation: 0.05267594321473869]
	TIME [epoch: 5.74 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0337109830263116		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.0337109830263116 | validation: 0.05062076334773167]
	TIME [epoch: 5.73 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03210886190718979		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.03210886190718979 | validation: 0.05587994277006944]
	TIME [epoch: 5.73 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034826121272625216		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.034826121272625216 | validation: 0.0612288851027861]
	TIME [epoch: 5.73 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03415975809840038		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.03415975809840038 | validation: 0.056913648188684926]
	TIME [epoch: 5.73 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031121728362813482		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.031121728362813482 | validation: 0.04913348065052164]
	TIME [epoch: 5.77 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03209410683234552		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.03209410683234552 | validation: 0.048799890360148875]
	TIME [epoch: 5.74 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031083560473553328		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.031083560473553328 | validation: 0.04805314012306387]
	TIME [epoch: 5.73 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035297109468201776		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.035297109468201776 | validation: 0.04946330310190089]
	TIME [epoch: 5.73 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03454159728585503		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.03454159728585503 | validation: 0.05154006038725262]
	TIME [epoch: 5.73 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03692892946038437		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.03692892946038437 | validation: 0.04726319698825281]
	TIME [epoch: 5.73 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0393911064216126		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.0393911064216126 | validation: 0.05086237203765223]
	TIME [epoch: 5.77 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033341070228025446		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.033341070228025446 | validation: 0.04737588254539127]
	TIME [epoch: 5.74 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040307804680820195		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.040307804680820195 | validation: 0.057285569784716384]
	TIME [epoch: 5.73 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04145853840360258		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.04145853840360258 | validation: 0.04930160242329791]
	TIME [epoch: 5.73 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033957182428232105		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.033957182428232105 | validation: 0.044532235756582876]
	TIME [epoch: 5.73 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02684440450694885		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.02684440450694885 | validation: 0.05069743601264107]
	TIME [epoch: 5.73 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030262400042806045		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.030262400042806045 | validation: 0.05486230789364011]
	TIME [epoch: 5.77 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04168989923150166		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.04168989923150166 | validation: 0.05956548396608124]
	TIME [epoch: 5.74 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044541011297386204		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.044541011297386204 | validation: 0.05159624184771037]
	TIME [epoch: 5.73 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04068027009949032		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.04068027009949032 | validation: 0.054166593939983944]
	TIME [epoch: 5.73 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039159222428541196		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.039159222428541196 | validation: 0.0456491934641609]
	TIME [epoch: 5.73 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03667900673845951		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.03667900673845951 | validation: 0.05036077964144235]
	TIME [epoch: 5.73 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03537674604208913		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.03537674604208913 | validation: 0.04736453923602532]
	TIME [epoch: 5.77 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03089753719097755		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.03089753719097755 | validation: 0.03780743004216516]
	TIME [epoch: 5.74 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031511200058467165		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.031511200058467165 | validation: 0.043622537954806355]
	TIME [epoch: 5.73 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030501783990219484		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.030501783990219484 | validation: 0.05451693965301576]
	TIME [epoch: 5.73 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029210072468678405		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.029210072468678405 | validation: 0.0440794819230196]
	TIME [epoch: 5.73 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034139617056210235		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.034139617056210235 | validation: 0.051920161415295624]
	TIME [epoch: 5.73 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03715043522482419		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.03715043522482419 | validation: 0.054185422937881554]
	TIME [epoch: 5.77 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039258389308954714		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.039258389308954714 | validation: 0.04236781707681486]
	TIME [epoch: 5.74 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037095648445223714		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.037095648445223714 | validation: 0.038668388936363124]
	TIME [epoch: 5.73 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034630702393791214		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.034630702393791214 | validation: 0.043953767416741986]
	TIME [epoch: 5.73 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030507957680003306		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.030507957680003306 | validation: 0.04225021789022097]
	TIME [epoch: 5.73 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031522117433448155		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.031522117433448155 | validation: 0.049648712319479246]
	TIME [epoch: 5.73 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03180234952772544		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.03180234952772544 | validation: 0.050468092571517395]
	TIME [epoch: 5.77 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029353289780552926		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.029353289780552926 | validation: 0.05296865799501644]
	TIME [epoch: 5.74 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02896416929622979		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.02896416929622979 | validation: 0.04659578853915276]
	TIME [epoch: 5.73 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028457917987856775		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.028457917987856775 | validation: 0.04761886240707417]
	TIME [epoch: 5.73 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03346408986626341		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.03346408986626341 | validation: 0.05904268451688864]
	TIME [epoch: 5.73 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039905806352250564		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.039905806352250564 | validation: 0.06270497798255105]
	TIME [epoch: 5.73 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038046827771194565		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.038046827771194565 | validation: 0.05291583423194104]
	TIME [epoch: 5.77 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03268853845080197		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.03268853845080197 | validation: 0.043538628927230885]
	TIME [epoch: 5.74 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027141346853931003		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.027141346853931003 | validation: 0.03967108458081336]
	TIME [epoch: 5.73 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03311023343090399		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.03311023343090399 | validation: 0.05025378426084934]
	TIME [epoch: 5.73 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030680777343340973		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.030680777343340973 | validation: 0.04431334654611966]
	TIME [epoch: 5.73 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03424729306394303		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.03424729306394303 | validation: 0.04925780846376758]
	TIME [epoch: 5.73 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033777722098322555		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.033777722098322555 | validation: 0.041937894127464834]
	TIME [epoch: 5.77 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0333784690209215		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.0333784690209215 | validation: 0.044771442435224164]
	TIME [epoch: 5.74 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033983236244712396		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.033983236244712396 | validation: 0.043215787587409786]
	TIME [epoch: 5.73 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03824300522970151		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.03824300522970151 | validation: 0.05447801992353779]
	TIME [epoch: 5.73 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035372868181664394		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.035372868181664394 | validation: 0.04924897383586569]
	TIME [epoch: 5.73 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028211172681968752		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.028211172681968752 | validation: 0.05577919566299699]
	TIME [epoch: 5.73 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03116645935300091		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.03116645935300091 | validation: 0.04686979899957797]
	TIME [epoch: 5.77 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0375037662974507		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.0375037662974507 | validation: 0.05645060578743427]
	TIME [epoch: 5.74 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028833104335646724		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.028833104335646724 | validation: 0.05202460662027455]
	TIME [epoch: 5.73 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031047462623628327		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.031047462623628327 | validation: 0.06076896220243622]
	TIME [epoch: 5.73 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03418685677535232		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.03418685677535232 | validation: 0.05289233226088956]
	TIME [epoch: 5.73 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026840022908573048		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.026840022908573048 | validation: 0.046817827525225016]
	TIME [epoch: 5.76 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030676331296610092		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.030676331296610092 | validation: 0.049697999226305536]
	TIME [epoch: 5.77 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03416868973395025		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.03416868973395025 | validation: 0.05178048686998267]
	TIME [epoch: 5.74 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03272091181487381		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.03272091181487381 | validation: 0.05091532305538048]
	TIME [epoch: 5.73 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03329200771620348		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.03329200771620348 | validation: 0.042365075711265375]
	TIME [epoch: 5.73 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025393103063607883		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.025393103063607883 | validation: 0.04489946307267093]
	TIME [epoch: 5.73 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03269224940417012		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.03269224940417012 | validation: 0.05819597292545665]
	TIME [epoch: 5.73 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03576553146531966		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.03576553146531966 | validation: 0.04750625788236425]
	TIME [epoch: 5.77 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03053716902648419		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.03053716902648419 | validation: 0.04966897669048276]
	TIME [epoch: 5.74 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03447911681448912		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.03447911681448912 | validation: 0.04999732799188303]
	TIME [epoch: 5.73 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02967222054722546		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.02967222054722546 | validation: 0.04133319014197274]
	TIME [epoch: 5.73 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03360285303317395		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.03360285303317395 | validation: 0.053506648310920786]
	TIME [epoch: 5.73 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035451200844139386		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.035451200844139386 | validation: 0.046228235806913744]
	TIME [epoch: 5.73 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029512063069491893		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.029512063069491893 | validation: 0.05080090606907428]
	TIME [epoch: 5.77 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03284453732708109		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.03284453732708109 | validation: 0.04402873957039503]
	TIME [epoch: 5.74 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02937980101371422		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.02937980101371422 | validation: 0.048480269285269516]
	TIME [epoch: 5.73 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03262697185849202		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.03262697185849202 | validation: 0.046365549132470214]
	TIME [epoch: 5.73 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032460933148493805		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.032460933148493805 | validation: 0.04046264372960241]
	TIME [epoch: 5.73 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032489603979768154		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.032489603979768154 | validation: 0.054451176056195115]
	TIME [epoch: 5.73 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034525880526236674		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.034525880526236674 | validation: 0.04683898432758975]
	TIME [epoch: 5.77 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035951069768692195		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.035951069768692195 | validation: 0.05742761374187893]
	TIME [epoch: 5.74 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03403422321408307		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.03403422321408307 | validation: 0.05141679933578711]
	TIME [epoch: 5.73 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03304535293980712		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.03304535293980712 | validation: 0.050057130029774514]
	TIME [epoch: 5.73 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032554623521929435		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.032554623521929435 | validation: 0.04525901837399113]
	TIME [epoch: 5.73 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02677097990973809		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.02677097990973809 | validation: 0.03710578684060023]
	TIME [epoch: 5.73 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03349501503082301		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.03349501503082301 | validation: 0.044413152961224237]
	TIME [epoch: 5.77 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029647275575422842		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.029647275575422842 | validation: 0.04408596470796319]
	TIME [epoch: 5.74 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030369576192548285		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.030369576192548285 | validation: 0.05112473000503925]
	TIME [epoch: 5.73 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03278262647923928		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.03278262647923928 | validation: 0.04488176340518695]
	TIME [epoch: 5.73 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03081645158614382		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.03081645158614382 | validation: 0.04181934995184989]
	TIME [epoch: 5.73 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02986483872167987		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.02986483872167987 | validation: 0.04851048970321884]
	TIME [epoch: 5.73 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03138065173986761		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.03138065173986761 | validation: 0.045996972009825936]
	TIME [epoch: 5.77 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02697959813673002		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.02697959813673002 | validation: 0.03965493135615033]
	TIME [epoch: 5.74 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030326404858003517		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.030326404858003517 | validation: 0.045116612511403205]
	TIME [epoch: 5.73 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028503663786231252		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.028503663786231252 | validation: 0.04642157119908969]
	TIME [epoch: 5.73 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03120985401848047		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.03120985401848047 | validation: 0.04682362255521465]
	TIME [epoch: 5.73 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027752431410740273		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.027752431410740273 | validation: 0.04337307308395061]
	TIME [epoch: 5.73 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02642087423566234		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.02642087423566234 | validation: 0.049309276233878596]
	TIME [epoch: 5.77 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03459810990979273		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.03459810990979273 | validation: 0.056310203027889506]
	TIME [epoch: 5.74 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03256286681467856		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.03256286681467856 | validation: 0.051652981750484654]
	TIME [epoch: 5.73 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03159832164865127		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.03159832164865127 | validation: 0.04192363215614935]
	TIME [epoch: 5.73 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033908060238202316		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.033908060238202316 | validation: 0.04836050269606543]
	TIME [epoch: 5.73 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02783356753047854		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.02783356753047854 | validation: 0.04315964645842546]
	TIME [epoch: 5.73 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027998330278870116		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.027998330278870116 | validation: 0.04496995148785663]
	TIME [epoch: 5.77 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02527423706103865		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.02527423706103865 | validation: 0.04803279671339108]
	TIME [epoch: 5.74 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03139501990503669		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.03139501990503669 | validation: 0.03971235137237103]
	TIME [epoch: 5.73 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031093679376181106		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.031093679376181106 | validation: 0.05004960839711822]
	TIME [epoch: 5.73 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0325824599479978		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.0325824599479978 | validation: 0.05037985158557671]
	TIME [epoch: 5.73 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024109842763151763		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.024109842763151763 | validation: 0.04438493224005796]
	TIME [epoch: 5.73 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025980829332576123		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.025980829332576123 | validation: 0.045091622233968405]
	TIME [epoch: 5.77 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02790036091271039		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.02790036091271039 | validation: 0.04864544918468066]
	TIME [epoch: 5.74 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027956371536152807		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.027956371536152807 | validation: 0.04407079453893751]
	TIME [epoch: 5.73 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033833776870559454		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.033833776870559454 | validation: 0.04430694721677238]
	TIME [epoch: 5.73 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03384154760792598		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.03384154760792598 | validation: 0.050860422420692115]
	TIME [epoch: 5.73 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031854655095399254		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.031854655095399254 | validation: 0.050771753438678964]
	TIME [epoch: 5.73 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028825708985787454		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.028825708985787454 | validation: 0.041861822448835184]
	TIME [epoch: 5.77 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02981879661116111		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.02981879661116111 | validation: 0.043266462504952176]
	TIME [epoch: 5.74 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030351051553965287		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.030351051553965287 | validation: 0.05507054517296295]
	TIME [epoch: 5.73 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031277596574703		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.031277596574703 | validation: 0.04340088326942654]
	TIME [epoch: 5.73 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026321850830163633		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.026321850830163633 | validation: 0.05362684979006163]
	TIME [epoch: 5.73 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03209609628815699		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.03209609628815699 | validation: 0.051621129854014125]
	TIME [epoch: 5.73 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0290301334108913		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.0290301334108913 | validation: 0.04373410356273718]
	TIME [epoch: 5.77 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03146467050544742		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.03146467050544742 | validation: 0.04947181560871926]
	TIME [epoch: 5.74 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02848466129435482		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.02848466129435482 | validation: 0.045617964596159494]
	TIME [epoch: 5.73 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028361165546870844		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.028361165546870844 | validation: 0.04305773358988006]
	TIME [epoch: 5.73 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030426398730609434		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.030426398730609434 | validation: 0.04435212001776604]
	TIME [epoch: 5.73 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02548325222503097		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.02548325222503097 | validation: 0.04558664240270659]
	TIME [epoch: 5.73 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030063930439103888		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.030063930439103888 | validation: 0.040179614012883835]
	TIME [epoch: 5.77 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028201493326389188		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.028201493326389188 | validation: 0.03999360246593408]
	TIME [epoch: 5.74 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02627493703405481		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.02627493703405481 | validation: 0.03827948522999248]
	TIME [epoch: 5.73 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026654445135912665		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.026654445135912665 | validation: 0.040079682817296396]
	TIME [epoch: 5.73 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025099329477850124		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.025099329477850124 | validation: 0.04028188250228551]
	TIME [epoch: 5.73 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028823013681352816		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.028823013681352816 | validation: 0.04837304785088934]
	TIME [epoch: 5.73 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028550278268574304		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.028550278268574304 | validation: 0.04693716889939813]
	TIME [epoch: 5.77 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029625527454164434		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.029625527454164434 | validation: 0.04368613291439987]
	TIME [epoch: 5.74 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03142952045074762		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.03142952045074762 | validation: 0.041305508013214406]
	TIME [epoch: 5.73 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02826084477728258		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.02826084477728258 | validation: 0.05456752646402606]
	TIME [epoch: 5.73 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029000474644831832		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.029000474644831832 | validation: 0.048535921696728615]
	TIME [epoch: 5.73 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029701372644010085		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.029701372644010085 | validation: 0.044922513230587297]
	TIME [epoch: 5.73 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02674468580695228		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.02674468580695228 | validation: 0.04433837432320766]
	TIME [epoch: 5.77 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026859455939273167		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.026859455939273167 | validation: 0.04032342971242603]
	TIME [epoch: 5.74 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03047769016870021		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.03047769016870021 | validation: 0.03926048139225244]
	TIME [epoch: 5.73 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03153196581214285		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.03153196581214285 | validation: 0.04060036133902643]
	TIME [epoch: 5.73 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030288440586773942		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.030288440586773942 | validation: 0.042090230898135496]
	TIME [epoch: 5.73 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03682271554190178		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.03682271554190178 | validation: 0.0426968120903431]
	TIME [epoch: 5.73 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0331327116013104		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.0331327116013104 | validation: 0.05561258608027154]
	TIME [epoch: 5.77 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03612032077795133		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.03612032077795133 | validation: 0.042026480985855326]
	TIME [epoch: 5.74 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028975270274046772		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.028975270274046772 | validation: 0.04637798477099785]
	TIME [epoch: 5.73 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02822088692745186		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.02822088692745186 | validation: 0.05270931566640904]
	TIME [epoch: 5.73 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03278077768771477		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.03278077768771477 | validation: 0.04577391558794456]
	TIME [epoch: 5.73 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032081377248290924		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.032081377248290924 | validation: 0.04463548191073269]
	TIME [epoch: 5.73 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02696148327332104		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.02696148327332104 | validation: 0.042389716129109536]
	TIME [epoch: 5.77 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030852442798355896		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.030852442798355896 | validation: 0.03735885029405908]
	TIME [epoch: 5.74 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02853979745304598		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.02853979745304598 | validation: 0.03785246594011477]
	TIME [epoch: 5.73 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030610169612782855		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.030610169612782855 | validation: 0.03727950227955007]
	TIME [epoch: 5.73 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02727623617613512		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.02727623617613512 | validation: 0.03518902304881874]
	TIME [epoch: 5.73 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027372853106549952		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.027372853106549952 | validation: 0.04526801348675112]
	TIME [epoch: 5.73 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02934800582027031		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.02934800582027031 | validation: 0.04301520240313653]
	TIME [epoch: 5.77 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027778012538070482		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.027778012538070482 | validation: 0.04131881159177959]
	TIME [epoch: 5.74 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030001668252860353		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.030001668252860353 | validation: 0.04614043478349267]
	TIME [epoch: 5.73 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029139116701091435		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.029139116701091435 | validation: 0.043175014829062074]
	TIME [epoch: 5.73 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03009558949030363		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.03009558949030363 | validation: 0.04108641592223087]
	TIME [epoch: 5.73 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03176913587342873		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.03176913587342873 | validation: 0.04869669320059341]
	TIME [epoch: 5.73 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029479171603594787		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.029479171603594787 | validation: 0.05636430573387257]
	TIME [epoch: 5.77 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031834577622678224		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.031834577622678224 | validation: 0.05174570735247217]
	TIME [epoch: 5.74 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03826020703993544		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.03826020703993544 | validation: 0.039003371786432525]
	TIME [epoch: 5.73 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02790426518876088		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.02790426518876088 | validation: 0.049489788978573625]
	TIME [epoch: 5.73 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026395133622353413		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.026395133622353413 | validation: 0.04240546458477767]
	TIME [epoch: 5.73 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029339200838731698		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.029339200838731698 | validation: 0.051072761893074754]
	TIME [epoch: 5.73 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03094705452817887		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.03094705452817887 | validation: 0.04694379153385866]
	TIME [epoch: 5.77 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030074777524515373		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.030074777524515373 | validation: 0.05795602765753678]
	TIME [epoch: 5.74 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030736316190298364		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.030736316190298364 | validation: 0.04437366203605004]
	TIME [epoch: 5.73 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034120147410028945		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.034120147410028945 | validation: 0.04880308866921992]
	TIME [epoch: 5.73 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031186097188422034		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.031186097188422034 | validation: 0.04638202787835624]
	TIME [epoch: 5.73 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02872763235468716		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.02872763235468716 | validation: 0.04912095590677435]
	TIME [epoch: 5.73 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02385171572643665		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.02385171572643665 | validation: 0.03622029021748326]
	TIME [epoch: 5.77 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03216533636565295		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.03216533636565295 | validation: 0.036737467150546495]
	TIME [epoch: 5.74 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03144534619618899		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.03144534619618899 | validation: 0.04288069679288675]
	TIME [epoch: 5.73 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02809492283050245		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.02809492283050245 | validation: 0.041388504725650734]
	TIME [epoch: 5.73 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027584680217737453		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.027584680217737453 | validation: 0.04774157122680215]
	TIME [epoch: 5.73 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025985258688939774		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.025985258688939774 | validation: 0.047126398512573324]
	TIME [epoch: 5.73 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030026635867863465		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.030026635867863465 | validation: 0.04693213737067521]
	TIME [epoch: 5.77 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028171927198313185		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.028171927198313185 | validation: 0.05055567237290143]
	TIME [epoch: 5.74 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032766857110500106		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.032766857110500106 | validation: 0.041582309808738234]
	TIME [epoch: 5.73 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02839712733718058		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.02839712733718058 | validation: 0.053231517495158524]
	TIME [epoch: 5.73 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024501979327203955		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.024501979327203955 | validation: 0.040959489905062284]
	TIME [epoch: 5.73 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030573676729908218		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.030573676729908218 | validation: 0.04171059746742996]
	TIME [epoch: 5.73 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030443562276442248		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.030443562276442248 | validation: 0.04352466295426654]
	TIME [epoch: 5.77 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02957776236609754		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.02957776236609754 | validation: 0.05089057367902271]
	TIME [epoch: 5.74 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028084692432098525		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.028084692432098525 | validation: 0.04374800040769739]
	TIME [epoch: 5.73 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02786193882143169		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.02786193882143169 | validation: 0.04170674155233384]
	TIME [epoch: 5.73 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027852555716946756		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.027852555716946756 | validation: 0.03875413302590095]
	TIME [epoch: 5.73 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027734451772534058		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.027734451772534058 | validation: 0.045379293985998555]
	TIME [epoch: 5.73 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02760061188478139		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.02760061188478139 | validation: 0.039971843112731754]
	TIME [epoch: 5.77 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0352974707079762		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.0352974707079762 | validation: 0.04418648328997723]
	TIME [epoch: 5.74 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029802976656276955		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.029802976656276955 | validation: 0.042678533160493026]
	TIME [epoch: 5.73 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02828746488544761		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.02828746488544761 | validation: 0.048965743433021666]
	TIME [epoch: 5.73 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02711458100832546		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.02711458100832546 | validation: 0.04589463300055144]
	TIME [epoch: 5.73 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02896287200290086		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.02896287200290086 | validation: 0.045850452377645394]
	TIME [epoch: 5.73 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026444196807816664		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.026444196807816664 | validation: 0.043564084502833875]
	TIME [epoch: 5.77 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0283365817958644		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.0283365817958644 | validation: 0.04500754245895127]
	TIME [epoch: 6.02 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028097359246241113		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.028097359246241113 | validation: 0.04330811085769013]
	TIME [epoch: 5.74 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02571213612348769		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.02571213612348769 | validation: 0.04925675494600755]
	TIME [epoch: 5.73 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02704217744741127		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.02704217744741127 | validation: 0.035177293135610056]
	TIME [epoch: 5.74 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027295404019256564		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.027295404019256564 | validation: 0.03726750645936482]
	TIME [epoch: 5.74 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0312007277392587		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.0312007277392587 | validation: 0.044537941816237485]
	TIME [epoch: 5.78 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03187144381072525		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.03187144381072525 | validation: 0.053999259445937746]
	TIME [epoch: 5.75 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0297747529528605		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.0297747529528605 | validation: 0.04931644833791934]
	TIME [epoch: 5.74 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02661662142686218		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.02661662142686218 | validation: 0.04989236964112035]
	TIME [epoch: 5.74 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025019415659525167		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.025019415659525167 | validation: 0.05777373908121847]
	TIME [epoch: 5.74 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029736454806158722		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.029736454806158722 | validation: 0.045650292247778994]
	TIME [epoch: 5.74 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029145851268818995		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.029145851268818995 | validation: 0.052860787699798094]
	TIME [epoch: 5.77 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02863826645565185		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.02863826645565185 | validation: 0.049200731049474644]
	TIME [epoch: 5.74 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026746458436692586		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.026746458436692586 | validation: 0.05177536696490742]
	TIME [epoch: 5.74 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030192936724273457		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.030192936724273457 | validation: 0.04723738668020046]
	TIME [epoch: 5.74 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02823204305327336		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.02823204305327336 | validation: 0.047434589180201436]
	TIME [epoch: 5.73 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030069425278321404		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.030069425278321404 | validation: 0.04829182385496836]
	TIME [epoch: 5.74 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02556066538526486		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.02556066538526486 | validation: 0.04980614485913761]
	TIME [epoch: 5.77 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0266789882774029		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.0266789882774029 | validation: 0.03609157311742611]
	TIME [epoch: 5.75 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02221838053078949		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.02221838053078949 | validation: 0.04131626696391032]
	TIME [epoch: 5.73 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0275557169792363		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.0275557169792363 | validation: 0.04055058940648367]
	TIME [epoch: 5.73 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02661753209751153		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.02661753209751153 | validation: 0.04837552721200792]
	TIME [epoch: 5.73 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02860906775405579		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.02860906775405579 | validation: 0.03270925324383537]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_1439.pth
	Model improved!!!
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025284326651151424		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.025284326651151424 | validation: 0.042098935574244496]
	TIME [epoch: 5.78 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03092411050200973		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.03092411050200973 | validation: 0.034312812084148894]
	TIME [epoch: 5.74 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027368575666100063		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.027368575666100063 | validation: 0.03972723726078515]
	TIME [epoch: 5.74 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026230920701780278		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.026230920701780278 | validation: 0.03982420387880975]
	TIME [epoch: 5.74 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030947088731927315		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.030947088731927315 | validation: 0.038850230045088294]
	TIME [epoch: 5.74 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02663221066748517		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.02663221066748517 | validation: 0.04160598019009331]
	TIME [epoch: 5.74 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02843238387437658		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.02843238387437658 | validation: 0.04350545546723554]
	TIME [epoch: 5.78 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028425877335918164		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.028425877335918164 | validation: 0.037567320511606675]
	TIME [epoch: 5.74 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02955093054351922		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.02955093054351922 | validation: 0.04211434908682953]
	TIME [epoch: 5.74 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029850171581413232		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.029850171581413232 | validation: 0.046854966311563474]
	TIME [epoch: 5.74 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03254259225237737		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.03254259225237737 | validation: 0.04295213823374527]
	TIME [epoch: 5.74 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027977201696362974		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.027977201696362974 | validation: 0.04353959538792358]
	TIME [epoch: 5.74 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029520315046658724		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.029520315046658724 | validation: 0.05029925751352915]
	TIME [epoch: 5.77 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027108934625128325		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.027108934625128325 | validation: 0.04568188977609483]
	TIME [epoch: 5.74 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0270589933986659		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.0270589933986659 | validation: 0.0484573179993426]
	TIME [epoch: 5.73 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029101542838654022		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.029101542838654022 | validation: 0.0446753560459575]
	TIME [epoch: 5.73 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027445119655533107		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.027445119655533107 | validation: 0.036264163783802296]
	TIME [epoch: 5.73 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03071849214478855		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.03071849214478855 | validation: 0.041739058720370315]
	TIME [epoch: 5.74 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025432879538927665		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.025432879538927665 | validation: 0.038678677925851196]
	TIME [epoch: 5.77 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026715382348987397		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.026715382348987397 | validation: 0.04862831996086692]
	TIME [epoch: 5.74 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03137760669394932		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.03137760669394932 | validation: 0.041440857753919945]
	TIME [epoch: 5.73 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026875587165129333		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.026875587165129333 | validation: 0.04303432778110173]
	TIME [epoch: 5.73 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029055723651757355		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.029055723651757355 | validation: 0.04740961148468213]
	TIME [epoch: 5.73 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028805378229877783		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.028805378229877783 | validation: 0.04405018154537471]
	TIME [epoch: 5.74 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026263609616772692		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.026263609616772692 | validation: 0.05393603400489697]
	TIME [epoch: 5.77 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03250853930646888		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.03250853930646888 | validation: 0.04685596475530794]
	TIME [epoch: 5.74 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030364488278441615		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.030364488278441615 | validation: 0.04888312287943551]
	TIME [epoch: 5.73 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03158773759207396		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.03158773759207396 | validation: 0.04484171709237507]
	TIME [epoch: 5.73 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026057554510818308		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.026057554510818308 | validation: 0.046052864666936186]
	TIME [epoch: 5.73 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03031304350193179		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.03031304350193179 | validation: 0.05945304391463826]
	TIME [epoch: 5.74 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030206632866531087		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.030206632866531087 | validation: 0.038540839683714974]
	TIME [epoch: 5.77 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03153968148805685		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.03153968148805685 | validation: 0.04794594605913179]
	TIME [epoch: 5.74 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03155242050676969		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.03155242050676969 | validation: 0.048180996525073835]
	TIME [epoch: 5.73 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028177341435580754		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.028177341435580754 | validation: 0.04956113856296204]
	TIME [epoch: 5.74 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03094025587044852		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.03094025587044852 | validation: 0.05170431201163164]
	TIME [epoch: 5.73 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03232641288167597		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.03232641288167597 | validation: 0.04156966329273132]
	TIME [epoch: 5.74 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03106479702171303		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.03106479702171303 | validation: 0.04705243616083823]
	TIME [epoch: 5.77 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03529833078532919		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.03529833078532919 | validation: 0.04731254086330772]
	TIME [epoch: 5.74 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029064347810918892		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.029064347810918892 | validation: 0.047870449026422984]
	TIME [epoch: 5.73 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032192494989822455		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.032192494989822455 | validation: 0.05315464780102376]
	TIME [epoch: 5.73 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03310135641993178		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.03310135641993178 | validation: 0.05410558828415876]
	TIME [epoch: 5.73 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026494487646929986		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.026494487646929986 | validation: 0.03673161126831793]
	TIME [epoch: 5.74 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026940358061344233		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.026940358061344233 | validation: 0.04303679418528188]
	TIME [epoch: 5.77 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034756740648381655		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.034756740648381655 | validation: 0.043058858066730814]
	TIME [epoch: 5.74 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03199334251986637		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.03199334251986637 | validation: 0.05201153528766697]
	TIME [epoch: 5.73 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027746562664772715		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.027746562664772715 | validation: 0.04815302072806835]
	TIME [epoch: 5.73 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029789859495265046		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.029789859495265046 | validation: 0.042895998005029176]
	TIME [epoch: 5.74 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030234869195686805		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.030234869195686805 | validation: 0.040430365824216254]
	TIME [epoch: 5.75 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030825021970162802		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.030825021970162802 | validation: 0.042332753822483776]
	TIME [epoch: 5.78 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02729054617597951		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.02729054617597951 | validation: 0.04509197847146666]
	TIME [epoch: 5.75 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030226209123054626		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.030226209123054626 | validation: 0.044759985058705834]
	TIME [epoch: 5.74 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03358105818109742		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.03358105818109742 | validation: 0.04324973042458025]
	TIME [epoch: 5.74 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027475679258689756		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.027475679258689756 | validation: 0.04573843902212858]
	TIME [epoch: 5.75 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027493547144076657		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.027493547144076657 | validation: 0.04516306392632563]
	TIME [epoch: 5.74 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02674953860579391		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.02674953860579391 | validation: 0.048033350189568294]
	TIME [epoch: 5.78 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029264366287244		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.029264366287244 | validation: 0.05047297781409231]
	TIME [epoch: 5.74 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024733329072055672		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.024733329072055672 | validation: 0.042861703367003796]
	TIME [epoch: 5.74 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026796130803479968		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.026796130803479968 | validation: 0.04054724807097004]
	TIME [epoch: 5.74 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029393744863908534		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.029393744863908534 | validation: 0.05170191570682489]
	TIME [epoch: 5.74 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030756724444486933		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.030756724444486933 | validation: 0.04754874971294841]
	TIME [epoch: 5.74 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02689516542654593		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.02689516542654593 | validation: 0.04644869485789197]
	TIME [epoch: 5.78 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030052722966859235		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.030052722966859235 | validation: 0.04447309990879852]
	TIME [epoch: 5.74 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02600099753874302		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.02600099753874302 | validation: 0.039319094476114015]
	TIME [epoch: 5.74 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02914724254818463		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.02914724254818463 | validation: 0.04640269851137271]
	TIME [epoch: 5.74 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027188051970720307		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.027188051970720307 | validation: 0.04589352547484901]
	TIME [epoch: 5.74 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024790942564555517		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.024790942564555517 | validation: 0.046492877963026855]
	TIME [epoch: 5.74 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026636336696342956		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.026636336696342956 | validation: 0.038722814033184824]
	TIME [epoch: 5.77 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024531714378723		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.024531714378723 | validation: 0.040454404528285026]
	TIME [epoch: 5.74 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028335474629288426		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.028335474629288426 | validation: 0.05298065047222787]
	TIME [epoch: 5.74 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030934564152380578		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.030934564152380578 | validation: 0.05242468980191009]
	TIME [epoch: 5.73 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027154383495211404		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.027154383495211404 | validation: 0.05021807014423077]
	TIME [epoch: 5.73 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029018546169143483		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.029018546169143483 | validation: 0.04753123942623364]
	TIME [epoch: 5.74 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026093687235673027		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.026093687235673027 | validation: 0.04530970880795516]
	TIME [epoch: 5.77 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028448469329404653		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.028448469329404653 | validation: 0.04021474872380953]
	TIME [epoch: 5.74 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026635059159296554		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.026635059159296554 | validation: 0.03872507504682818]
	TIME [epoch: 5.73 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02328104305245203		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.02328104305245203 | validation: 0.04793128643954121]
	TIME [epoch: 5.74 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026366686355631764		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.026366686355631764 | validation: 0.043683231284223585]
	TIME [epoch: 5.74 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024826019397296416		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.024826019397296416 | validation: 0.04594700162889125]
	TIME [epoch: 5.74 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030078337055480485		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.030078337055480485 | validation: 0.04345649620109418]
	TIME [epoch: 5.77 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02889986770982135		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.02889986770982135 | validation: 0.04586410345229151]
	TIME [epoch: 5.74 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028943394919387955		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.028943394919387955 | validation: 0.03773299484356207]
	TIME [epoch: 5.73 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030142701672187463		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.030142701672187463 | validation: 0.04308537876182385]
	TIME [epoch: 5.73 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028082669543846868		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.028082669543846868 | validation: 0.04585800528319727]
	TIME [epoch: 5.73 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022933710966611336		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.022933710966611336 | validation: 0.046182914309028926]
	TIME [epoch: 5.74 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02476358665491291		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.02476358665491291 | validation: 0.046565043436328286]
	TIME [epoch: 5.77 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02650680522121364		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.02650680522121364 | validation: 0.04239450628750193]
	TIME [epoch: 5.74 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028572451965123404		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.028572451965123404 | validation: 0.049932418045772343]
	TIME [epoch: 5.74 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03347604202790429		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.03347604202790429 | validation: 0.05320331567280036]
	TIME [epoch: 5.73 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033482842846339664		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.033482842846339664 | validation: 0.05086936265765087]
	TIME [epoch: 5.73 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029870394120367967		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.029870394120367967 | validation: 0.04297989078937269]
	TIME [epoch: 5.74 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027323483074413082		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.027323483074413082 | validation: 0.04807587590966998]
	TIME [epoch: 5.77 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02767340308393979		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.02767340308393979 | validation: 0.041685817543687574]
	TIME [epoch: 5.74 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03101946988177132		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.03101946988177132 | validation: 0.050010666874300995]
	TIME [epoch: 5.74 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027750242083065972		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.027750242083065972 | validation: 0.05676095761858134]
	TIME [epoch: 5.73 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03450166407931785		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.03450166407931785 | validation: 0.051609929035235445]
	TIME [epoch: 5.73 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028750586939013115		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.028750586939013115 | validation: 0.045453152471520965]
	TIME [epoch: 5.74 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026650761672797056		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.026650761672797056 | validation: 0.0500980783562033]
	TIME [epoch: 5.77 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026022924077993295		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.026022924077993295 | validation: 0.05261871930168131]
	TIME [epoch: 5.74 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02885614629213698		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.02885614629213698 | validation: 0.05893689155885306]
	TIME [epoch: 5.73 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02702875953847579		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.02702875953847579 | validation: 0.041223839653338]
	TIME [epoch: 5.74 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02547158351256306		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.02547158351256306 | validation: 0.036076595705753826]
	TIME [epoch: 5.73 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026035443253562364		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.026035443253562364 | validation: 0.04191205160458878]
	TIME [epoch: 5.74 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026832435159666386		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.026832435159666386 | validation: 0.03411872508888417]
	TIME [epoch: 5.77 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029440071910805134		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.029440071910805134 | validation: 0.048167143618780654]
	TIME [epoch: 5.74 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024906240147154042		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.024906240147154042 | validation: 0.04949958663422824]
	TIME [epoch: 5.73 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026320092058624185		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.026320092058624185 | validation: 0.04596657477258439]
	TIME [epoch: 5.73 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023305452477681267		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.023305452477681267 | validation: 0.04918375024626017]
	TIME [epoch: 5.73 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030227067274924094		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.030227067274924094 | validation: 0.043571164606424795]
	TIME [epoch: 5.74 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026563658471182697		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.026563658471182697 | validation: 0.045916295801057994]
	TIME [epoch: 5.77 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028300824208312095		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.028300824208312095 | validation: 0.04305927827602357]
	TIME [epoch: 5.74 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026382114026283106		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.026382114026283106 | validation: 0.0477957130365793]
	TIME [epoch: 5.74 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02872720112636918		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.02872720112636918 | validation: 0.04728403822123611]
	TIME [epoch: 5.73 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02995901769132715		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.02995901769132715 | validation: 0.04000770779845812]
	TIME [epoch: 5.73 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027094552492374132		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.027094552492374132 | validation: 0.036590495063889165]
	TIME [epoch: 5.74 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029725425297262676		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.029725425297262676 | validation: 0.05317119300368926]
	TIME [epoch: 5.77 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027536995033955618		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.027536995033955618 | validation: 0.04402509728147216]
	TIME [epoch: 5.74 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025438169149583897		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.025438169149583897 | validation: 0.04707838112533755]
	TIME [epoch: 5.73 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027648264886647775		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.027648264886647775 | validation: 0.04954013261084347]
	TIME [epoch: 5.73 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027717854489904128		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.027717854489904128 | validation: 0.04057996721357706]
	TIME [epoch: 5.73 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02998275323652859		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.02998275323652859 | validation: 0.033399557418223334]
	TIME [epoch: 5.74 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029012665584333547		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.029012665584333547 | validation: 0.04982652044845004]
	TIME [epoch: 5.77 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03012800451216362		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.03012800451216362 | validation: 0.04311190145874057]
	TIME [epoch: 5.74 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02339525346314751		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.02339525346314751 | validation: 0.041739537723712965]
	TIME [epoch: 5.73 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02868385244073464		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.02868385244073464 | validation: 0.042840937238278656]
	TIME [epoch: 5.73 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032069492401442565		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.032069492401442565 | validation: 0.050606929298252314]
	TIME [epoch: 5.73 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029009885391320295		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.029009885391320295 | validation: 0.03844337753456684]
	TIME [epoch: 5.74 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026246450572908704		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.026246450572908704 | validation: 0.04224315965227945]
	TIME [epoch: 5.77 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025224944962974217		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.025224944962974217 | validation: 0.04783911105595152]
	TIME [epoch: 5.74 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03107959723369405		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.03107959723369405 | validation: 0.04597319030000471]
	TIME [epoch: 5.73 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02641668046047554		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.02641668046047554 | validation: 0.04365174062911944]
	TIME [epoch: 5.74 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027497977274461096		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.027497977274461096 | validation: 0.036539969843496695]
	TIME [epoch: 5.73 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0282258931039982		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.0282258931039982 | validation: 0.0414385196634599]
	TIME [epoch: 5.74 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028772542093712335		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.028772542093712335 | validation: 0.048821561312997586]
	TIME [epoch: 5.77 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028180356541469657		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.028180356541469657 | validation: 0.04313447910291494]
	TIME [epoch: 5.74 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02712096565593898		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.02712096565593898 | validation: 0.04622431140389154]
	TIME [epoch: 5.73 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028443015346990695		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.028443015346990695 | validation: 0.04532680540220821]
	TIME [epoch: 5.73 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025552629989476112		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.025552629989476112 | validation: 0.050033068224509876]
	TIME [epoch: 5.73 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025983486596143666		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.025983486596143666 | validation: 0.04900950064965766]
	TIME [epoch: 5.73 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023698801719076946		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.023698801719076946 | validation: 0.04384148189679267]
	TIME [epoch: 5.77 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026217160802338952		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.026217160802338952 | validation: 0.04726973433813555]
	TIME [epoch: 5.74 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026995770408954026		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.026995770408954026 | validation: 0.04946136969262226]
	TIME [epoch: 5.73 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025141811115777676		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.025141811115777676 | validation: 0.040679611082286495]
	TIME [epoch: 5.73 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026161201016713393		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.026161201016713393 | validation: 0.04246836187644916]
	TIME [epoch: 5.73 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02932016117783361		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.02932016117783361 | validation: 0.03748280912391946]
	TIME [epoch: 5.74 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026276773095637723		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.026276773095637723 | validation: 0.03765642602784069]
	TIME [epoch: 5.77 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027466337356814002		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.027466337356814002 | validation: 0.0446449758596699]
	TIME [epoch: 5.74 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024809227337314978		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.024809227337314978 | validation: 0.0446116724807575]
	TIME [epoch: 5.73 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023758606195146605		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.023758606195146605 | validation: 0.04112499230251339]
	TIME [epoch: 5.73 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029427612184050614		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.029427612184050614 | validation: 0.047711313475669356]
	TIME [epoch: 5.73 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024863179331755324		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.024863179331755324 | validation: 0.0449623784495903]
	TIME [epoch: 5.74 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026303904034029196		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.026303904034029196 | validation: 0.048946077745368737]
	TIME [epoch: 5.77 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02527640991643457		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.02527640991643457 | validation: 0.037490653832356204]
	TIME [epoch: 5.74 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025693930459177828		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.025693930459177828 | validation: 0.04728132114449738]
	TIME [epoch: 5.73 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025951265909682785		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.025951265909682785 | validation: 0.046704997519917094]
	TIME [epoch: 5.73 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026011628428453976		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.026011628428453976 | validation: 0.04867907044295775]
	TIME [epoch: 5.73 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027428126735674022		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.027428126735674022 | validation: 0.03863170217127845]
	TIME [epoch: 5.74 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026618507630444176		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.026618507630444176 | validation: 0.05195179007856773]
	TIME [epoch: 5.77 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02698087277130095		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.02698087277130095 | validation: 0.043114599113437554]
	TIME [epoch: 5.74 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030714740151287723		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.030714740151287723 | validation: 0.04844660539628066]
	TIME [epoch: 5.73 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026524867703732732		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.026524867703732732 | validation: 0.04766306383420673]
	TIME [epoch: 5.73 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027736905219248938		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.027736905219248938 | validation: 0.037553916262172436]
	TIME [epoch: 5.73 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029141521594815502		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.029141521594815502 | validation: 0.046261836474058654]
	TIME [epoch: 5.74 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027107393809135304		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.027107393809135304 | validation: 0.042946894544480106]
	TIME [epoch: 5.77 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025250849310783387		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.025250849310783387 | validation: 0.04162496002127497]
	TIME [epoch: 5.74 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02714454407001744		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.02714454407001744 | validation: 0.04222789866426879]
	TIME [epoch: 5.73 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026642124272227834		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.026642124272227834 | validation: 0.04942178971675368]
	TIME [epoch: 5.74 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028620265874617103		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.028620265874617103 | validation: 0.039061428297826044]
	TIME [epoch: 5.73 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03181396286807292		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.03181396286807292 | validation: 0.036481997575476356]
	TIME [epoch: 5.74 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025943981964826522		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.025943981964826522 | validation: 0.04806975012304788]
	TIME [epoch: 5.77 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02884856185808603		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.02884856185808603 | validation: 0.0463175090406326]
	TIME [epoch: 5.73 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02479884616042621		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.02479884616042621 | validation: 0.040802839765726164]
	TIME [epoch: 5.73 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030420293025368514		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.030420293025368514 | validation: 0.04406029036483432]
	TIME [epoch: 5.73 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02700665590731672		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.02700665590731672 | validation: 0.037686256175621526]
	TIME [epoch: 5.73 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0258567011984495		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.0258567011984495 | validation: 0.05435248353124115]
	TIME [epoch: 5.73 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028924050249256265		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.028924050249256265 | validation: 0.04442342432152146]
	TIME [epoch: 5.77 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024961711894095653		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.024961711894095653 | validation: 0.04476350656477573]
	TIME [epoch: 5.74 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02699596577100076		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.02699596577100076 | validation: 0.04798983992998179]
	TIME [epoch: 5.73 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02316403549655409		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.02316403549655409 | validation: 0.041207197662749724]
	TIME [epoch: 5.73 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026127912648897085		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.026127912648897085 | validation: 0.041090637486642184]
	TIME [epoch: 5.73 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02659745752110042		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.02659745752110042 | validation: 0.051682695604731814]
	TIME [epoch: 5.74 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028411640756603046		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.028411640756603046 | validation: 0.048159859736085144]
	TIME [epoch: 5.77 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027403538930548442		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.027403538930548442 | validation: 0.04236049816531064]
	TIME [epoch: 5.74 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02801188667612564		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.02801188667612564 | validation: 0.04722737191660931]
	TIME [epoch: 5.73 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028011868593664623		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.028011868593664623 | validation: 0.041253035122692225]
	TIME [epoch: 5.73 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029313646020055845		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.029313646020055845 | validation: 0.04705653220490307]
	TIME [epoch: 5.73 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02654901593224683		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.02654901593224683 | validation: 0.039765127357607656]
	TIME [epoch: 5.74 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031086340300650966		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.031086340300650966 | validation: 0.045058100809271785]
	TIME [epoch: 5.76 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02995766037389004		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.02995766037389004 | validation: 0.03670560359865989]
	TIME [epoch: 5.74 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030092768996815546		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.030092768996815546 | validation: 0.04248840865247439]
	TIME [epoch: 5.73 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02837100002391864		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.02837100002391864 | validation: 0.03657646465976676]
	TIME [epoch: 5.73 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028385138504881214		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.028385138504881214 | validation: 0.04443714639053512]
	TIME [epoch: 5.73 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0282235185373617		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.0282235185373617 | validation: 0.04391839663421233]
	TIME [epoch: 5.73 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029082526729744294		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.029082526729744294 | validation: 0.04996529044241191]
	TIME [epoch: 5.76 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023873875158947535		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.023873875158947535 | validation: 0.04117972988769435]
	TIME [epoch: 5.74 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02401544231260019		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.02401544231260019 | validation: 0.04239656736731233]
	TIME [epoch: 5.73 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027041623991729682		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.027041623991729682 | validation: 0.038233979809924316]
	TIME [epoch: 5.73 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02742918777866816		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.02742918777866816 | validation: 0.0489719034442575]
	TIME [epoch: 5.73 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027555870630085178		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.027555870630085178 | validation: 0.04115474239264872]
	TIME [epoch: 5.73 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029706809727893635		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.029706809727893635 | validation: 0.040143500875230345]
	TIME [epoch: 5.76 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030713968249676447		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.030713968249676447 | validation: 0.04147132390230752]
	TIME [epoch: 5.73 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03263259876231511		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.03263259876231511 | validation: 0.03570926331187398]
	TIME [epoch: 5.73 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028171583165854178		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.028171583165854178 | validation: 0.05417835437777817]
	TIME [epoch: 5.73 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02427668615334919		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.02427668615334919 | validation: 0.04363698711706523]
	TIME [epoch: 5.73 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027400687477165474		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.027400687477165474 | validation: 0.04444609013901708]
	TIME [epoch: 5.74 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02688367659810679		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.02688367659810679 | validation: 0.04900710976547785]
	TIME [epoch: 5.76 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027288998715229783		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.027288998715229783 | validation: 0.04313525594190473]
	TIME [epoch: 5.73 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029271103323772186		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.029271103323772186 | validation: 0.04763016988458199]
	TIME [epoch: 5.73 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024720924328352045		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.024720924328352045 | validation: 0.04551084987277863]
	TIME [epoch: 5.73 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025178496937165368		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.025178496937165368 | validation: 0.04727612501622379]
	TIME [epoch: 5.73 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025797741123247682		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.025797741123247682 | validation: 0.04172229786555955]
	TIME [epoch: 5.74 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02524797502552392		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.02524797502552392 | validation: 0.040980722834560376]
	TIME [epoch: 5.76 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02592625356316328		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.02592625356316328 | validation: 0.0340087757056014]
	TIME [epoch: 5.73 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025860692307440102		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.025860692307440102 | validation: 0.042724492579720955]
	TIME [epoch: 5.73 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02720806511973875		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.02720806511973875 | validation: 0.03441035405991118]
	TIME [epoch: 5.73 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02483727193816116		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.02483727193816116 | validation: 0.04180038971084537]
	TIME [epoch: 5.73 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022797641036026085		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.022797641036026085 | validation: 0.047285341987645765]
	TIME [epoch: 5.74 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025388155018767983		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.025388155018767983 | validation: 0.039305718788174786]
	TIME [epoch: 5.76 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026741610566264236		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.026741610566264236 | validation: 0.04687281576602221]
	TIME [epoch: 5.73 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025094197017497735		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.025094197017497735 | validation: 0.04744036599754617]
	TIME [epoch: 5.73 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02557960279174564		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.02557960279174564 | validation: 0.04452334216657114]
	TIME [epoch: 5.73 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021633200144426552		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.021633200144426552 | validation: 0.03990582844515301]
	TIME [epoch: 5.73 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024278619462453768		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.024278619462453768 | validation: 0.039357741546164865]
	TIME [epoch: 5.74 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026173007799630554		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.026173007799630554 | validation: 0.040823974128797236]
	TIME [epoch: 5.76 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024804834501196048		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.024804834501196048 | validation: 0.04292056678783629]
	TIME [epoch: 5.73 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03161107048637757		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.03161107048637757 | validation: 0.04591120493998384]
	TIME [epoch: 5.73 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02500878920627326		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.02500878920627326 | validation: 0.040302217675827645]
	TIME [epoch: 5.73 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03098260288275627		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.03098260288275627 | validation: 0.04604014925417791]
	TIME [epoch: 5.73 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02933451581671018		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.02933451581671018 | validation: 0.05020213209025249]
	TIME [epoch: 5.74 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02730469499930422		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.02730469499930422 | validation: 0.04879507568231043]
	TIME [epoch: 5.76 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02665978462340254		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.02665978462340254 | validation: 0.04506614342176506]
	TIME [epoch: 5.74 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02533997152548853		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.02533997152548853 | validation: 0.043545344176345896]
	TIME [epoch: 5.73 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02226132377439645		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.02226132377439645 | validation: 0.04702272757855704]
	TIME [epoch: 5.73 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028348224386240857		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.028348224386240857 | validation: 0.04799294107738301]
	TIME [epoch: 5.73 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02685800051144423		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.02685800051144423 | validation: 0.040101605382420906]
	TIME [epoch: 5.74 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027132548778811556		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.027132548778811556 | validation: 0.04736319808803156]
	TIME [epoch: 5.76 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027715352414081747		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.027715352414081747 | validation: 0.04699394408156545]
	TIME [epoch: 5.73 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027977979766703968		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.027977979766703968 | validation: 0.04278285889602106]
	TIME [epoch: 5.73 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0285370060798135		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.0285370060798135 | validation: 0.0511706447946332]
	TIME [epoch: 5.73 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024748900495924625		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.024748900495924625 | validation: 0.05224181848601484]
	TIME [epoch: 5.73 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023574134333890728		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.023574134333890728 | validation: 0.04914275149073388]
	TIME [epoch: 5.74 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028343133374671387		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.028343133374671387 | validation: 0.0434237728025254]
	TIME [epoch: 5.76 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02340436186901055		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.02340436186901055 | validation: 0.04296770185441467]
	TIME [epoch: 5.73 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026835271721065035		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.026835271721065035 | validation: 0.037529629801573226]
	TIME [epoch: 5.73 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025514066234780163		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.025514066234780163 | validation: 0.03956053037730753]
	TIME [epoch: 5.73 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026234431886848996		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.026234431886848996 | validation: 0.044695342130788095]
	TIME [epoch: 5.73 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028226033593281227		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.028226033593281227 | validation: 0.04244236342186364]
	TIME [epoch: 5.74 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025899353805586573		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.025899353805586573 | validation: 0.03896567218384698]
	TIME [epoch: 5.76 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02489051105863186		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.02489051105863186 | validation: 0.050426767468920906]
	TIME [epoch: 5.73 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024488446288581947		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.024488446288581947 | validation: 0.04108468898175767]
	TIME [epoch: 5.73 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022998199783036046		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.022998199783036046 | validation: 0.040606948707496766]
	TIME [epoch: 5.73 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029248413130171326		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.029248413130171326 | validation: 0.04586921957879254]
	TIME [epoch: 5.73 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026044118846321088		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.026044118846321088 | validation: 0.04584438709867428]
	TIME [epoch: 5.74 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028056021358069613		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.028056021358069613 | validation: 0.03143751994726443]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_1692.pth
	Model improved!!!
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028046245335370062		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.028046245335370062 | validation: 0.04187021922023031]
	TIME [epoch: 5.73 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02810016477819703		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.02810016477819703 | validation: 0.04381024644630624]
	TIME [epoch: 5.73 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031010870068047442		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.031010870068047442 | validation: 0.051519169281838445]
	TIME [epoch: 5.73 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024890651787813807		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.024890651787813807 | validation: 0.042256169899945864]
	TIME [epoch: 5.73 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030697507083615638		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.030697507083615638 | validation: 0.04663915610235631]
	TIME [epoch: 5.74 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027082137158168006		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.027082137158168006 | validation: 0.032616662391790424]
	TIME [epoch: 5.75 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028229888783211504		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.028229888783211504 | validation: 0.032113876062069155]
	TIME [epoch: 5.73 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02634389202548361		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.02634389202548361 | validation: 0.04691818857486951]
	TIME [epoch: 5.73 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026704407603238202		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.026704407603238202 | validation: 0.042479337960270494]
	TIME [epoch: 5.73 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02725659823620025		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.02725659823620025 | validation: 0.04889704289732423]
	TIME [epoch: 5.73 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02823049001482819		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.02823049001482819 | validation: 0.03716053677654861]
	TIME [epoch: 5.74 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025684241683401474		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.025684241683401474 | validation: 0.04414745460983191]
	TIME [epoch: 5.75 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019572315030118068		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.019572315030118068 | validation: 0.048418662615569215]
	TIME [epoch: 5.73 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025758855165835343		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.025758855165835343 | validation: 0.04382991086936258]
	TIME [epoch: 5.73 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02607538117065279		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.02607538117065279 | validation: 0.04581681300016679]
	TIME [epoch: 5.73 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024633608901967242		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.024633608901967242 | validation: 0.0501621277414026]
	TIME [epoch: 5.73 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026547851850742453		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.026547851850742453 | validation: 0.04271923906829607]
	TIME [epoch: 5.74 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02853284530407995		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.02853284530407995 | validation: 0.043635396147068455]
	TIME [epoch: 5.75 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027474161127154145		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.027474161127154145 | validation: 0.0428727432654147]
	TIME [epoch: 5.73 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02375112196460413		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.02375112196460413 | validation: 0.03694743640613141]
	TIME [epoch: 5.73 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030370967433255396		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.030370967433255396 | validation: 0.040574493485802963]
	TIME [epoch: 5.73 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02593967888023328		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.02593967888023328 | validation: 0.04541128682069386]
	TIME [epoch: 5.73 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025778034661969332		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.025778034661969332 | validation: 0.05026495792889874]
	TIME [epoch: 5.74 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026320019759954665		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.026320019759954665 | validation: 0.03695751905435024]
	TIME [epoch: 5.75 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026060118655091037		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.026060118655091037 | validation: 0.051990707019307546]
	TIME [epoch: 5.73 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026676984367258		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.026676984367258 | validation: 0.03847166674709058]
	TIME [epoch: 5.73 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027034261462123656		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.027034261462123656 | validation: 0.04556567526305377]
	TIME [epoch: 5.73 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02787069599978885		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.02787069599978885 | validation: 0.04680694866931132]
	TIME [epoch: 5.73 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02575811886204458		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.02575811886204458 | validation: 0.04330009344246662]
	TIME [epoch: 5.74 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02207282825675166		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.02207282825675166 | validation: 0.04804371928594775]
	TIME [epoch: 5.75 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027352812864406863		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.027352812864406863 | validation: 0.0436986854581329]
	TIME [epoch: 5.73 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028244933866051432		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.028244933866051432 | validation: 0.04866530296862189]
	TIME [epoch: 5.73 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024067381085347134		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.024067381085347134 | validation: 0.0381711915902242]
	TIME [epoch: 5.73 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025932252955486283		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.025932252955486283 | validation: 0.04414763791538333]
	TIME [epoch: 5.73 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02739689202663207		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.02739689202663207 | validation: 0.04534867584849521]
	TIME [epoch: 5.74 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029662451804050492		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.029662451804050492 | validation: 0.04108697046921355]
	TIME [epoch: 5.75 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02525047216571928		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.02525047216571928 | validation: 0.05145243963827193]
	TIME [epoch: 5.73 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02586013365511551		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.02586013365511551 | validation: 0.03793220620849512]
	TIME [epoch: 5.73 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022790400555578152		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.022790400555578152 | validation: 0.04209298690128984]
	TIME [epoch: 5.73 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027105770896202093		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.027105770896202093 | validation: 0.041294540057092946]
	TIME [epoch: 5.73 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027307859125601658		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.027307859125601658 | validation: 0.040554385983494375]
	TIME [epoch: 5.74 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02851888719110744		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.02851888719110744 | validation: 0.03454273913696272]
	TIME [epoch: 5.75 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02682345181909136		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.02682345181909136 | validation: 0.039284059844290606]
	TIME [epoch: 5.73 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027477702960674727		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.027477702960674727 | validation: 0.0515633354169964]
	TIME [epoch: 5.73 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02867617292046578		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.02867617292046578 | validation: 0.04083460285055292]
	TIME [epoch: 5.73 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026866801568414964		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.026866801568414964 | validation: 0.04367670254184713]
	TIME [epoch: 5.73 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026069934998577585		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.026069934998577585 | validation: 0.03957408469460467]
	TIME [epoch: 5.74 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027034091094112395		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.027034091094112395 | validation: 0.046206470224044685]
	TIME [epoch: 5.75 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02884811581216514		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.02884811581216514 | validation: 0.04462228442640345]
	TIME [epoch: 5.73 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028126639340469436		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.028126639340469436 | validation: 0.0405472927754853]
	TIME [epoch: 5.73 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024094006310789565		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.024094006310789565 | validation: 0.0315958108164749]
	TIME [epoch: 5.73 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023056410504183115		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.023056410504183115 | validation: 0.047240649634088146]
	TIME [epoch: 5.73 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028153127532864704		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.028153127532864704 | validation: 0.04278412802266462]
	TIME [epoch: 5.74 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024368897791943036		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.024368897791943036 | validation: 0.04044946069133031]
	TIME [epoch: 5.75 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024515447476078693		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.024515447476078693 | validation: 0.04648998763543974]
	TIME [epoch: 5.73 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02178403183818448		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.02178403183818448 | validation: 0.04684375986250096]
	TIME [epoch: 5.73 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026603133905080983		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.026603133905080983 | validation: 0.042155460971482546]
	TIME [epoch: 5.73 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025102239688098504		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.025102239688098504 | validation: 0.0464875520581769]
	TIME [epoch: 5.73 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02678213349328539		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.02678213349328539 | validation: 0.042147131570240096]
	TIME [epoch: 5.74 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026273218717273887		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.026273218717273887 | validation: 0.049271128494931385]
	TIME [epoch: 5.75 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024561317068858342		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.024561317068858342 | validation: 0.046930813397866845]
	TIME [epoch: 5.73 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02857862921869153		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.02857862921869153 | validation: 0.04587662321522032]
	TIME [epoch: 5.73 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024870764109731998		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.024870764109731998 | validation: 0.056616631453201956]
	TIME [epoch: 5.73 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02663096011829088		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.02663096011829088 | validation: 0.04121291893139277]
	TIME [epoch: 5.73 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024006331682572282		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.024006331682572282 | validation: 0.047492305152175555]
	TIME [epoch: 5.74 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025560573237348602		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.025560573237348602 | validation: 0.036782426997065916]
	TIME [epoch: 5.75 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02791316658587284		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.02791316658587284 | validation: 0.041323811637829104]
	TIME [epoch: 5.73 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028125489598780452		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.028125489598780452 | validation: 0.04838383061499936]
	TIME [epoch: 5.73 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026511258757592214		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.026511258757592214 | validation: 0.03964174829805867]
	TIME [epoch: 5.73 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02749453257397081		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.02749453257397081 | validation: 0.04320575798983322]
	TIME [epoch: 5.73 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026410157370636653		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.026410157370636653 | validation: 0.04814250012547058]
	TIME [epoch: 5.74 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028475855485771192		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.028475855485771192 | validation: 0.03610405964573368]
	TIME [epoch: 5.75 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025529907415936588		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.025529907415936588 | validation: 0.04337671919994926]
	TIME [epoch: 5.73 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026123734016118002		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.026123734016118002 | validation: 0.0387792897169141]
	TIME [epoch: 5.73 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0278694185381037		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.0278694185381037 | validation: 0.04664993003186758]
	TIME [epoch: 5.73 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026132961707921905		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.026132961707921905 | validation: 0.046179999258655284]
	TIME [epoch: 5.73 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027549298649080952		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.027549298649080952 | validation: 0.04135596257252934]
	TIME [epoch: 5.74 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02465193373786777		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.02465193373786777 | validation: 0.041177952097469]
	TIME [epoch: 5.75 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028481923264809195		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.028481923264809195 | validation: 0.04831713541985892]
	TIME [epoch: 5.73 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029052044482233922		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.029052044482233922 | validation: 0.04105797090572743]
	TIME [epoch: 5.73 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028963348609446975		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.028963348609446975 | validation: 0.03607203379844529]
	TIME [epoch: 5.73 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025793205965088183		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.025793205965088183 | validation: 0.03990003165049499]
	TIME [epoch: 5.73 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024499336111149423		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.024499336111149423 | validation: 0.042141008780004735]
	TIME [epoch: 5.74 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027004824677223108		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.027004824677223108 | validation: 0.03638188896808928]
	TIME [epoch: 5.75 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028274408385612092		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.028274408385612092 | validation: 0.04475072184886091]
	TIME [epoch: 5.73 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025325907274907987		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.025325907274907987 | validation: 0.04103324543810615]
	TIME [epoch: 5.73 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02499258689198171		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.02499258689198171 | validation: 0.042080462795219806]
	TIME [epoch: 5.73 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02768337031652604		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.02768337031652604 | validation: 0.04156572040635437]
	TIME [epoch: 5.73 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02340699772014688		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.02340699772014688 | validation: 0.047516173928900396]
	TIME [epoch: 5.74 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024914813369215222		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.024914813369215222 | validation: 0.040198737417412964]
	TIME [epoch: 5.76 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026853495878498966		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.026853495878498966 | validation: 0.03808656888442358]
	TIME [epoch: 5.73 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025432874519529948		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.025432874519529948 | validation: 0.04957061438151497]
	TIME [epoch: 5.73 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02689069375808468		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.02689069375808468 | validation: 0.042912526768979026]
	TIME [epoch: 5.73 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026372490901281666		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.026372490901281666 | validation: 0.04199578182204194]
	TIME [epoch: 5.73 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026614647621198403		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.026614647621198403 | validation: 0.0406208736024095]
	TIME [epoch: 5.74 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025839474476593245		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.025839474476593245 | validation: 0.04292504115189167]
	TIME [epoch: 5.75 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028052199808144326		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.028052199808144326 | validation: 0.04238021999428039]
	TIME [epoch: 5.73 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026654774510031988		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.026654774510031988 | validation: 0.045697653208006575]
	TIME [epoch: 5.73 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028876917105624664		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.028876917105624664 | validation: 0.04783403694840784]
	TIME [epoch: 5.73 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02915538025639471		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.02915538025639471 | validation: 0.034792852261303374]
	TIME [epoch: 5.73 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026242374648965606		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.026242374648965606 | validation: 0.042565081413889656]
	TIME [epoch: 5.74 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024157849455793787		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.024157849455793787 | validation: 0.040179909553351635]
	TIME [epoch: 5.75 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025626041307682874		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.025626041307682874 | validation: 0.03781764516094638]
	TIME [epoch: 5.73 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026226535489702406		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.026226535489702406 | validation: 0.04114576409440848]
	TIME [epoch: 5.73 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02455664190259081		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.02455664190259081 | validation: 0.03990716683418703]
	TIME [epoch: 5.73 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020782933165225195		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.020782933165225195 | validation: 0.043883647144458006]
	TIME [epoch: 5.73 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030277347974607634		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.030277347974607634 | validation: 0.045934556977099174]
	TIME [epoch: 5.74 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027627594304338008		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.027627594304338008 | validation: 0.04586651827533557]
	TIME [epoch: 5.75 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026753478202300514		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.026753478202300514 | validation: 0.036371305258594215]
	TIME [epoch: 5.73 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0224311409801878		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.0224311409801878 | validation: 0.039784442957854]
	TIME [epoch: 5.73 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02730531091769494		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.02730531091769494 | validation: 0.04299910851688079]
	TIME [epoch: 5.73 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024353290549080548		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.024353290549080548 | validation: 0.04802074927826621]
	TIME [epoch: 5.73 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02582836632837455		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.02582836632837455 | validation: 0.05016971606328337]
	TIME [epoch: 5.74 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026504594719638876		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.026504594719638876 | validation: 0.04179970252071878]
	TIME [epoch: 5.75 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02426844032814697		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.02426844032814697 | validation: 0.04134655995593915]
	TIME [epoch: 5.73 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02482925303700268		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.02482925303700268 | validation: 0.04322774868709163]
	TIME [epoch: 5.73 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0262439870790256		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.0262439870790256 | validation: 0.0347906405443875]
	TIME [epoch: 5.73 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027853097750115234		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.027853097750115234 | validation: 0.03674040889457517]
	TIME [epoch: 5.73 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025474664173394487		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.025474664173394487 | validation: 0.04291520774286903]
	TIME [epoch: 5.74 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02796045339347513		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.02796045339347513 | validation: 0.049856936441903026]
	TIME [epoch: 5.75 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021007478134707668		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.021007478134707668 | validation: 0.04781837379449187]
	TIME [epoch: 5.73 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028548902332817046		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.028548902332817046 | validation: 0.04343385031357785]
	TIME [epoch: 5.73 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02193416890665987		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.02193416890665987 | validation: 0.04970735097840096]
	TIME [epoch: 5.73 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023145625195902828		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.023145625195902828 | validation: 0.03455018205665923]
	TIME [epoch: 5.74 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025768696687929627		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.025768696687929627 | validation: 0.042612241005799856]
	TIME [epoch: 5.74 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02870925918078136		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.02870925918078136 | validation: 0.040032882576171026]
	TIME [epoch: 5.75 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024789240724091874		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.024789240724091874 | validation: 0.0443872499888779]
	TIME [epoch: 5.73 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025812731760823018		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.025812731760823018 | validation: 0.043993166871798176]
	TIME [epoch: 5.73 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026038590861855056		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.026038590861855056 | validation: 0.031958586416269114]
	TIME [epoch: 5.73 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024843403655576107		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.024843403655576107 | validation: 0.034493390423106465]
	TIME [epoch: 5.73 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021873497168111683		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.021873497168111683 | validation: 0.04356046889222425]
	TIME [epoch: 5.75 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029496309132717266		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.029496309132717266 | validation: 0.04117230107143253]
	TIME [epoch: 5.74 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02967315098750988		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.02967315098750988 | validation: 0.03751937245572861]
	TIME [epoch: 5.73 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027150185390023143		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.027150185390023143 | validation: 0.04119362538584698]
	TIME [epoch: 5.73 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024273395824547166		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.024273395824547166 | validation: 0.035272741313735874]
	TIME [epoch: 5.73 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026684777407509075		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.026684777407509075 | validation: 0.03582913313348339]
	TIME [epoch: 5.73 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025317755160937573		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.025317755160937573 | validation: 0.04041212896612033]
	TIME [epoch: 5.75 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02697649168914985		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.02697649168914985 | validation: 0.045965661127952515]
	TIME [epoch: 5.74 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026966383338609394		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.026966383338609394 | validation: 0.044496191959534866]
	TIME [epoch: 5.73 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025927715240216767		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.025927715240216767 | validation: 0.042018103390735695]
	TIME [epoch: 5.73 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028078534556273807		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.028078534556273807 | validation: 0.049017623036073155]
	TIME [epoch: 5.73 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028035839881253733		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.028035839881253733 | validation: 0.03991424008113378]
	TIME [epoch: 5.73 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02484262903140526		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.02484262903140526 | validation: 0.04137076708782351]
	TIME [epoch: 5.75 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028270164398138467		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.028270164398138467 | validation: 0.043665862578476954]
	TIME [epoch: 5.74 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025003789477845696		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.025003789477845696 | validation: 0.04083060302891735]
	TIME [epoch: 5.73 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02575530982419612		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.02575530982419612 | validation: 0.032273725497210214]
	TIME [epoch: 5.73 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028196958450480567		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.028196958450480567 | validation: 0.044612428861046584]
	TIME [epoch: 5.73 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026848187857508657		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.026848187857508657 | validation: 0.04128575356096138]
	TIME [epoch: 5.73 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02574037966257459		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.02574037966257459 | validation: 0.03507259010822334]
	TIME [epoch: 5.75 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025367800864047857		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.025367800864047857 | validation: 0.04376525149577276]
	TIME [epoch: 5.74 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027373037740653614		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.027373037740653614 | validation: 0.04237516369744971]
	TIME [epoch: 5.73 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02791082654777016		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.02791082654777016 | validation: 0.04047045166651622]
	TIME [epoch: 5.73 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023145927611723113		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.023145927611723113 | validation: 0.05090635691479824]
	TIME [epoch: 5.73 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025039445514186447		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.025039445514186447 | validation: 0.03722263571126867]
	TIME [epoch: 5.73 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028758382278189935		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.028758382278189935 | validation: 0.054023890801521146]
	TIME [epoch: 5.75 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029822436059893865		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.029822436059893865 | validation: 0.03653979410626398]
	TIME [epoch: 5.74 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027340701575622108		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.027340701575622108 | validation: 0.03631105246057194]
	TIME [epoch: 5.73 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024499591544175157		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.024499591544175157 | validation: 0.043679399334840364]
	TIME [epoch: 5.73 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024336443973063192		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.024336443973063192 | validation: 0.04089822446385316]
	TIME [epoch: 5.73 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026135738526017593		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.026135738526017593 | validation: 0.033277394225314734]
	TIME [epoch: 5.73 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025371704023077507		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.025371704023077507 | validation: 0.0413129718363449]
	TIME [epoch: 5.75 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0264848161225294		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.0264848161225294 | validation: 0.040209831151969126]
	TIME [epoch: 5.74 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0244631890180992		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.0244631890180992 | validation: 0.047383324648911734]
	TIME [epoch: 5.73 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02253979532459307		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.02253979532459307 | validation: 0.041669009529188734]
	TIME [epoch: 5.73 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024575440086182863		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.024575440086182863 | validation: 0.03891716204241744]
	TIME [epoch: 5.73 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023836089027753683		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.023836089027753683 | validation: 0.04519911551896155]
	TIME [epoch: 5.73 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02420579515889422		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.02420579515889422 | validation: 0.03230387809111211]
	TIME [epoch: 5.75 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02545962368790154		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.02545962368790154 | validation: 0.04452653240985424]
	TIME [epoch: 5.74 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026691661189437922		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.026691661189437922 | validation: 0.04683799380510856]
	TIME [epoch: 5.73 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02726407491399397		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.02726407491399397 | validation: 0.044290490263439786]
	TIME [epoch: 5.73 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024675408104970768		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.024675408104970768 | validation: 0.045758942632211835]
	TIME [epoch: 5.73 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02793515904555638		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.02793515904555638 | validation: 0.038234776000593156]
	TIME [epoch: 5.73 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02636192160291725		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.02636192160291725 | validation: 0.04845093756010286]
	TIME [epoch: 5.75 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026496174600009886		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.026496174600009886 | validation: 0.039115766222836426]
	TIME [epoch: 5.74 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026131457794780308		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.026131457794780308 | validation: 0.03824154779242136]
	TIME [epoch: 5.73 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027746867574376936		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.027746867574376936 | validation: 0.04316612191759251]
	TIME [epoch: 5.73 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028990974855790122		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.028990974855790122 | validation: 0.040097541014025434]
	TIME [epoch: 5.73 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027218821686087573		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.027218821686087573 | validation: 0.04335398591978169]
	TIME [epoch: 5.73 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026993038631548567		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.026993038631548567 | validation: 0.04381466667284707]
	TIME [epoch: 5.75 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025643209184623598		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.025643209184623598 | validation: 0.04028197347514143]
	TIME [epoch: 5.74 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025604657287827376		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.025604657287827376 | validation: 0.05225391741825048]
	TIME [epoch: 5.73 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024009649334658455		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.024009649334658455 | validation: 0.03800080309135253]
	TIME [epoch: 5.73 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026170540459002165		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.026170540459002165 | validation: 0.0467122863110399]
	TIME [epoch: 5.73 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026088047560538456		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.026088047560538456 | validation: 0.043169444746978716]
	TIME [epoch: 5.73 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02875351193108155		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.02875351193108155 | validation: 0.042020688439270495]
	TIME [epoch: 5.75 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026054492312834854		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.026054492312834854 | validation: 0.04351857286849671]
	TIME [epoch: 5.74 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025306259445681198		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.025306259445681198 | validation: 0.03499052257418071]
	TIME [epoch: 5.73 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024746910119743438		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.024746910119743438 | validation: 0.04132057026533513]
	TIME [epoch: 5.73 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02527969813031467		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.02527969813031467 | validation: 0.05030672984409186]
	TIME [epoch: 5.73 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024234773956164767		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.024234773956164767 | validation: 0.044792679171677674]
	TIME [epoch: 5.73 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02633302054031795		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.02633302054031795 | validation: 0.04804792906173872]
	TIME [epoch: 5.75 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029297106819228803		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.029297106819228803 | validation: 0.04679319076022764]
	TIME [epoch: 5.74 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026261455991143705		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.026261455991143705 | validation: 0.0383977720490995]
	TIME [epoch: 5.73 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025390589796705294		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.025390589796705294 | validation: 0.04085587800625962]
	TIME [epoch: 5.73 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028285996224476032		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.028285996224476032 | validation: 0.04474453969718246]
	TIME [epoch: 5.73 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029705318723664526		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.029705318723664526 | validation: 0.039920684888851816]
	TIME [epoch: 5.73 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021158358079013694		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.021158358079013694 | validation: 0.04382951183475914]
	TIME [epoch: 5.75 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023614133650707202		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.023614133650707202 | validation: 0.04214339617408138]
	TIME [epoch: 5.74 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02580771081357942		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.02580771081357942 | validation: 0.052851309535134144]
	TIME [epoch: 5.73 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025184097787310344		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.025184097787310344 | validation: 0.04263070096256179]
	TIME [epoch: 5.73 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02768609143346439		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.02768609143346439 | validation: 0.04815620271158652]
	TIME [epoch: 5.73 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025549139321322988		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.025549139321322988 | validation: 0.04636761609956695]
	TIME [epoch: 5.72 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025037384221828503		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.025037384221828503 | validation: 0.04333791103296074]
	TIME [epoch: 5.75 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023802177935441836		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.023802177935441836 | validation: 0.045025174020510345]
	TIME [epoch: 5.74 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02509152664877226		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.02509152664877226 | validation: 0.04957882362247982]
	TIME [epoch: 5.73 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0269725041858655		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.0269725041858655 | validation: 0.04168821768381056]
	TIME [epoch: 5.73 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02759385409265165		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.02759385409265165 | validation: 0.04157716219033089]
	TIME [epoch: 5.73 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023116201856967448		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.023116201856967448 | validation: 0.03483633300877985]
	TIME [epoch: 5.72 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023492210825039106		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.023492210825039106 | validation: 0.03781813799069675]
	TIME [epoch: 5.75 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026927414213526343		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.026927414213526343 | validation: 0.03888888306424997]
	TIME [epoch: 5.74 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022033383471488862		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.022033383471488862 | validation: 0.04513660773530577]
	TIME [epoch: 5.73 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025016770547234987		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.025016770547234987 | validation: 0.048385586456717374]
	TIME [epoch: 5.73 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02363499702136484		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.02363499702136484 | validation: 0.04074245766110141]
	TIME [epoch: 5.73 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02775496506876144		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.02775496506876144 | validation: 0.04330397566029554]
	TIME [epoch: 5.73 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02710769739397528		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.02710769739397528 | validation: 0.039040756898744124]
	TIME [epoch: 5.75 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02446010724035015		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.02446010724035015 | validation: 0.036738514269274665]
	TIME [epoch: 5.74 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02723459755360806		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.02723459755360806 | validation: 0.03989927410223263]
	TIME [epoch: 5.73 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02590633846366876		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.02590633846366876 | validation: 0.03645385322047984]
	TIME [epoch: 5.73 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024021383648025495		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.024021383648025495 | validation: 0.04368312374348388]
	TIME [epoch: 5.73 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023287936950379513		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.023287936950379513 | validation: 0.04554681814990052]
	TIME [epoch: 5.73 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02512803350050004		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.02512803350050004 | validation: 0.038697147083938066]
	TIME [epoch: 5.76 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023369639885645947		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.023369639885645947 | validation: 0.041208377371397126]
	TIME [epoch: 5.74 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024914454848808405		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.024914454848808405 | validation: 0.04375035758784316]
	TIME [epoch: 5.75 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02530460395881091		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.02530460395881091 | validation: 0.03686380144966478]
	TIME [epoch: 5.73 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023232917853610223		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.023232917853610223 | validation: 0.03918270440113415]
	TIME [epoch: 5.73 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029087226433128752		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.029087226433128752 | validation: 0.043147384629172496]
	TIME [epoch: 5.73 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02505553968223121		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.02505553968223121 | validation: 0.046662661431184964]
	TIME [epoch: 5.76 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02543580408383527		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.02543580408383527 | validation: 0.047659464150201614]
	TIME [epoch: 5.74 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025520445878656133		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.025520445878656133 | validation: 0.04258224996025493]
	TIME [epoch: 5.73 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026506511004823055		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.026506511004823055 | validation: 0.038100498527027404]
	TIME [epoch: 5.73 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028659783960337568		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.028659783960337568 | validation: 0.0391179651752157]
	TIME [epoch: 5.73 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022772918782185618		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.022772918782185618 | validation: 0.042224568156162365]
	TIME [epoch: 5.73 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022082045086734184		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.022082045086734184 | validation: 0.04176793417814857]
	TIME [epoch: 5.75 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023025475819402112		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.023025475819402112 | validation: 0.04537180281405744]
	TIME [epoch: 5.74 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02636768227886802		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.02636768227886802 | validation: 0.041270544342521746]
	TIME [epoch: 5.73 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02674504671094912		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.02674504671094912 | validation: 0.03825244873991647]
	TIME [epoch: 5.73 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025510672387057204		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.025510672387057204 | validation: 0.03364593943821249]
	TIME [epoch: 5.73 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02798774622804607		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.02798774622804607 | validation: 0.04506460179943233]
	TIME [epoch: 5.73 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02777641369482292		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.02777641369482292 | validation: 0.04990619037711795]
	TIME [epoch: 5.76 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02426599277398192		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.02426599277398192 | validation: 0.044600039501422]
	TIME [epoch: 5.74 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025185054477070517		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.025185054477070517 | validation: 0.04428763759209099]
	TIME [epoch: 5.73 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02685901514497975		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.02685901514497975 | validation: 0.04222219315577116]
	TIME [epoch: 5.73 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023246725310767047		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.023246725310767047 | validation: 0.04376764592447703]
	TIME [epoch: 5.73 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02692509422742043		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.02692509422742043 | validation: 0.04095297564768037]
	TIME [epoch: 5.73 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027063907071923295		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.027063907071923295 | validation: 0.049164898296370184]
	TIME [epoch: 5.76 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025721798429647058		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.025721798429647058 | validation: 0.050079258517057794]
	TIME [epoch: 5.74 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025977377561619837		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.025977377561619837 | validation: 0.04095803245584713]
	TIME [epoch: 5.73 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026524992530085265		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.026524992530085265 | validation: 0.04335004439143598]
	TIME [epoch: 5.73 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025068354849811514		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.025068354849811514 | validation: 0.04430055301036461]
	TIME [epoch: 5.73 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02696102053020599		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.02696102053020599 | validation: 0.03987229432154937]
	TIME [epoch: 5.73 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02482999190954359		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.02482999190954359 | validation: 0.042988541154638224]
	TIME [epoch: 5.75 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025388568620425645		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.025388568620425645 | validation: 0.041351014876459063]
	TIME [epoch: 5.74 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026069036881607333		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.026069036881607333 | validation: 0.03885436703245248]
	TIME [epoch: 5.73 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024652114593446923		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.024652114593446923 | validation: 0.04112184548768708]
	TIME [epoch: 5.73 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028721092588536924		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.028721092588536924 | validation: 0.04668321641788983]
	TIME [epoch: 5.73 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028591719876835876		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.028591719876835876 | validation: 0.037450712843501224]
	TIME [epoch: 5.73 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027131437198629472		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.027131437198629472 | validation: 0.04741199658678737]
	TIME [epoch: 5.75 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02705712084418112		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.02705712084418112 | validation: 0.04912163170895062]
	TIME [epoch: 5.74 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028481418545606783		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.028481418545606783 | validation: 0.04424022412027865]
	TIME [epoch: 5.73 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027811637758257637		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.027811637758257637 | validation: 0.042143385725177715]
	TIME [epoch: 5.73 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025930298968588762		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.025930298968588762 | validation: 0.038759789861492304]
	TIME [epoch: 5.73 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02515030479744432		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.02515030479744432 | validation: 0.03756341347940191]
	TIME [epoch: 5.73 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02376558132952575		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.02376558132952575 | validation: 0.046192244826920865]
	TIME [epoch: 5.76 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02597343655680135		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.02597343655680135 | validation: 0.0422350260088095]
	TIME [epoch: 5.75 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028428506072484698		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.028428506072484698 | validation: 0.0419946704528761]
	TIME [epoch: 5.73 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02400221117752612		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.02400221117752612 | validation: 0.044426502785377034]
	TIME [epoch: 5.73 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024958657787611756		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.024958657787611756 | validation: 0.04240571163608493]
	TIME [epoch: 5.73 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024375042496252775		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.024375042496252775 | validation: 0.03466911784471635]
	TIME [epoch: 5.73 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026020756046086894		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.026020756046086894 | validation: 0.040798710400508365]
	TIME [epoch: 5.76 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027467579373176593		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.027467579373176593 | validation: 0.049089166443088306]
	TIME [epoch: 5.74 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021387995408719274		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.021387995408719274 | validation: 0.04435560420872755]
	TIME [epoch: 5.73 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026486316440876817		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.026486316440876817 | validation: 0.03628199630924577]
	TIME [epoch: 5.73 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02649981894483585		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.02649981894483585 | validation: 0.03688182280889342]
	TIME [epoch: 5.73 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026636143626185858		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.026636143626185858 | validation: 0.04198988272992451]
	TIME [epoch: 5.73 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0234571999516657		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.0234571999516657 | validation: 0.049238723062746424]
	TIME [epoch: 5.76 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022785896390197964		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.022785896390197964 | validation: 0.03519015754215458]
	TIME [epoch: 5.74 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024017827582964828		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.024017827582964828 | validation: 0.03615305175417523]
	TIME [epoch: 5.73 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02685110954957029		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.02685110954957029 | validation: 0.040758291972283305]
	TIME [epoch: 5.73 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024242707819577308		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.024242707819577308 | validation: 0.045797283010516505]
	TIME [epoch: 5.73 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02669533445998358		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.02669533445998358 | validation: 0.035116373134746366]
	TIME [epoch: 5.73 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025628347182897776		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.025628347182897776 | validation: 0.03792176451799929]
	TIME [epoch: 5.75 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02492419923356597		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.02492419923356597 | validation: 0.03897439929018945]
	TIME [epoch: 5.74 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028756259167418943		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.028756259167418943 | validation: 0.03991009305570724]
	TIME [epoch: 5.73 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025429041135252337		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.025429041135252337 | validation: 0.037431186862975564]
	TIME [epoch: 5.73 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026974018426525814		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.026974018426525814 | validation: 0.044950574355202395]
	TIME [epoch: 5.73 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02689095628943419		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.02689095628943419 | validation: 0.031356461538449086]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_1978.pth
	Model improved!!!
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02374018390215412		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.02374018390215412 | validation: 0.04580093294036642]
	TIME [epoch: 5.76 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02745549881467741		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.02745549881467741 | validation: 0.04808335566614383]
	TIME [epoch: 5.73 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024313673028855804		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.024313673028855804 | validation: 0.03709361586539562]
	TIME [epoch: 5.73 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02279281838354571		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.02279281838354571 | validation: 0.04779684751307448]
	TIME [epoch: 5.73 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02561160531633679		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.02561160531633679 | validation: 0.035980310584542124]
	TIME [epoch: 5.73 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026918729015654622		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.026918729015654622 | validation: 0.04401146885350322]
	TIME [epoch: 5.73 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02197131237955893		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.02197131237955893 | validation: 0.04840747915022355]
	TIME [epoch: 5.76 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025813404222141362		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.025813404222141362 | validation: 0.04496727924049971]
	TIME [epoch: 5.73 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025965001191604147		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.025965001191604147 | validation: 0.041226594797793295]
	TIME [epoch: 5.73 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026493751084010683		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.026493751084010683 | validation: 0.04776939079209028]
	TIME [epoch: 5.73 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02633983998123097		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.02633983998123097 | validation: 0.030727471723000745]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240310_003030/states/model_tr_study2_1989.pth
	Model improved!!!
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026713409885842615		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.026713409885842615 | validation: 0.03931060752024272]
	TIME [epoch: 5.73 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0243288482499593		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.0243288482499593 | validation: 0.03454028367136001]
	TIME [epoch: 5.75 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024244914874449165		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.024244914874449165 | validation: 0.03478054748835335]
	TIME [epoch: 5.73 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020656942579320946		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.020656942579320946 | validation: 0.043009513954852974]
	TIME [epoch: 5.72 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022830079504120058		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.022830079504120058 | validation: 0.04555861642199736]
	TIME [epoch: 5.72 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028500531074570616		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.028500531074570616 | validation: 0.046932819930078376]
	TIME [epoch: 5.72 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02438037275376641		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.02438037275376641 | validation: 0.0390372779748323]
	TIME [epoch: 5.72 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02377262245655069		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.02377262245655069 | validation: 0.044240358488351124]
	TIME [epoch: 5.75 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0303989706630026		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.0303989706630026 | validation: 0.04121479248710358]
	TIME [epoch: 5.73 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024472546760790942		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.024472546760790942 | validation: 0.042328748001203974]
	TIME [epoch: 5.72 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025427866639556474		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.025427866639556474 | validation: 0.04278801229048832]
	TIME [epoch: 5.72 sec]
Finished training in 11690.196 seconds.
