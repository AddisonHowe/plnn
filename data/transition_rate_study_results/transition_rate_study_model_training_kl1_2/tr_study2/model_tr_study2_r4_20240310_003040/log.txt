Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r4', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r4', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2983169117

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.558535616366163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.558535616366163 | validation: 8.459709995524156]
	TIME [epoch: 93.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.110721697307634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.110721697307634 | validation: 6.7058005227148385]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.038858234550581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.038858234550581 | validation: 5.742543463716967]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.166120659211828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.166120659211828 | validation: 5.067757442184833]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.636727727666291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.636727727666291 | validation: 4.768213723037571]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.29555332993403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.29555332993403 | validation: 4.771072161616108]
	TIME [epoch: 5.78 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.231931227154303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.231931227154303 | validation: 5.086698446198714]
	TIME [epoch: 5.75 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9763533593170655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9763533593170655 | validation: 3.4506398447238884]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.381644862557376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.381644862557376 | validation: 3.3333255622568174]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.373653204778972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.373653204778972 | validation: 3.017536980942001]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8789254713354095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8789254713354095 | validation: 2.792854269442123]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5758978215597423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5758978215597423 | validation: 2.679965320577602]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5225957617578363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5225957617578363 | validation: 2.2986646474995287]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.335148815322653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.335148815322653 | validation: 2.197197880847471]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1560816850437687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1560816850437687 | validation: 2.1639810350456874]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0312532702690707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0312532702690707 | validation: 1.7666390457461267]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.942309200181766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.942309200181766 | validation: 2.7042806721098605]
	TIME [epoch: 5.8 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.95552714161769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.95552714161769 | validation: 1.7938126588997096]
	TIME [epoch: 5.76 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9299447508087813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9299447508087813 | validation: 1.5343045480769448]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.585873137340618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.585873137340618 | validation: 1.4072777208515024]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4939535729510782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4939535729510782 | validation: 2.266941692580714]
	TIME [epoch: 5.74 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7437367260571042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7437367260571042 | validation: 1.5364545825000238]
	TIME [epoch: 5.74 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5723939598066168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5723939598066168 | validation: 1.142685911054158]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3166515040957045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3166515040957045 | validation: 1.3751099114064516]
	TIME [epoch: 5.78 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.174838946763721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.174838946763721 | validation: 1.2483149194142553]
	TIME [epoch: 5.75 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.348130112627334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.348130112627334 | validation: 1.196363770848735]
	TIME [epoch: 5.74 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1370472933564413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1370472933564413 | validation: 1.2233555528755702]
	TIME [epoch: 5.74 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2368767010679367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2368767010679367 | validation: 1.1263013125276902]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0643671395325163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0643671395325163 | validation: 1.0091779633269633]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2162985731133915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2162985731133915 | validation: 0.9438559078518955]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0120838348503485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0120838348503485 | validation: 0.8935158163858572]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8933596836544978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8933596836544978 | validation: 1.0374409432086649]
	TIME [epoch: 5.74 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4237892536128256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4237892536128256 | validation: 1.0505430031632204]
	TIME [epoch: 5.74 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.969680903080288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.969680903080288 | validation: 1.0224124802441772]
	TIME [epoch: 5.74 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9569526134987647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9569526134987647 | validation: 0.8205852956109376]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.082181606752394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.082181606752394 | validation: 0.6888425036444907]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8551262018459079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8551262018459079 | validation: 1.334558777914827]
	TIME [epoch: 5.76 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8887413753222635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8887413753222635 | validation: 0.5959765161842568]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9070715380498777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9070715380498777 | validation: 0.6232150482702792]
	TIME [epoch: 5.73 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.72001690494898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.72001690494898 | validation: 0.6428548177446877]
	TIME [epoch: 5.73 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9547411918587536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9547411918587536 | validation: 0.8799450673869664]
	TIME [epoch: 5.73 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0488948712148243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0488948712148243 | validation: 0.8097458307019076]
	TIME [epoch: 5.74 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.872434891136136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.872434891136136 | validation: 1.6732730524742585]
	TIME [epoch: 5.78 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9558192706000699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9558192706000699 | validation: 0.6969256040336549]
	TIME [epoch: 5.75 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7256593501065631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7256593501065631 | validation: 1.1605664474998687]
	TIME [epoch: 5.74 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8663736282416163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8663736282416163 | validation: 0.7719870030607692]
	TIME [epoch: 5.74 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.855181244741948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.855181244741948 | validation: 0.9421713767440087]
	TIME [epoch: 5.74 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7833230666980631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7833230666980631 | validation: 0.5513253530964457]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7597780343657139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7597780343657139 | validation: 0.83608985940177]
	TIME [epoch: 5.77 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7625674452955529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7625674452955529 | validation: 0.50372551878439]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5903779555717481		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.5903779555717481 | validation: 0.5451601400626688]
	TIME [epoch: 5.74 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8375184083964624		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.8375184083964624 | validation: 0.6745655589352925]
	TIME [epoch: 5.74 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.202916745142635		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.202916745142635 | validation: 0.8833314638873995]
	TIME [epoch: 5.75 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6914578592036216		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.6914578592036216 | validation: 0.7830503525953306]
	TIME [epoch: 5.75 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7609903557022144		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.7609903557022144 | validation: 0.5118758182103141]
	TIME [epoch: 5.74 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7066609434626052		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.7066609434626052 | validation: 0.9315500161369031]
	TIME [epoch: 5.78 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6883294922062351		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.6883294922062351 | validation: 1.003999497494312]
	TIME [epoch: 5.74 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7542649325661437		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.7542649325661437 | validation: 0.7315522111213982]
	TIME [epoch: 5.73 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860783974441109		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.6860783974441109 | validation: 1.001186301204356]
	TIME [epoch: 5.74 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834670233776197		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.6834670233776197 | validation: 0.49225804165489806]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042245273561252		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.7042245273561252 | validation: 0.5526224456962828]
	TIME [epoch: 5.74 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5753490300956638		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.5753490300956638 | validation: 0.6272367803037847]
	TIME [epoch: 5.79 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5290582579030756		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.5290582579030756 | validation: 0.4625120601677176]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5730675176268614		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.5730675176268614 | validation: 0.49757158647813937]
	TIME [epoch: 5.77 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.568365598635729		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.568365598635729 | validation: 1.7330780304713815]
	TIME [epoch: 5.76 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0039005220392898		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.0039005220392898 | validation: 0.4950904764991034]
	TIME [epoch: 5.76 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5533160199532612		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.5533160199532612 | validation: 0.5593425918345412]
	TIME [epoch: 5.75 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6227917219391219		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.6227917219391219 | validation: 0.38246252289105265]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4733559388160549		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.4733559388160549 | validation: 0.6579358835171084]
	TIME [epoch: 5.77 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.648155290496208		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.648155290496208 | validation: 0.4247427874860872]
	TIME [epoch: 5.75 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49065983850692985		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.49065983850692985 | validation: 0.41029836865121233]
	TIME [epoch: 5.74 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44539900938493576		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.44539900938493576 | validation: 0.4051297875212792]
	TIME [epoch: 5.75 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4953402991148515		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.4953402991148515 | validation: 0.6820958793861371]
	TIME [epoch: 5.75 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5286225634142587		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.5286225634142587 | validation: 0.4603692700204755]
	TIME [epoch: 5.74 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46667381171314315		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.46667381171314315 | validation: 0.4624957832840953]
	TIME [epoch: 5.78 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5628516494686492		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.5628516494686492 | validation: 0.5035008796251452]
	TIME [epoch: 5.74 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48648467685620145		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.48648467685620145 | validation: 0.8665767792150331]
	TIME [epoch: 5.75 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7185521839865945		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.7185521839865945 | validation: 0.3504165732152679]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4699911736160788		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.4699911736160788 | validation: 0.4573599406872964]
	TIME [epoch: 5.75 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4025014542283718		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.4025014542283718 | validation: 0.4029780894282186]
	TIME [epoch: 5.75 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45052153119723737		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.45052153119723737 | validation: 0.3904903932904148]
	TIME [epoch: 5.77 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4525924092836775		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.4525924092836775 | validation: 0.43439200476427603]
	TIME [epoch: 5.75 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5037911522751588		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.5037911522751588 | validation: 0.5012142068025651]
	TIME [epoch: 5.74 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46947416586983803		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.46947416586983803 | validation: 0.5099063876304673]
	TIME [epoch: 5.74 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46199714208697906		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.46199714208697906 | validation: 0.32974809073422223]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41938325837400275		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.41938325837400275 | validation: 0.3793038486192604]
	TIME [epoch: 5.74 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4496964768509735		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.4496964768509735 | validation: 0.37674640810311644]
	TIME [epoch: 5.74 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39288659290092354		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.39288659290092354 | validation: 0.24291817491667264]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49421297209028797		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.49421297209028797 | validation: 0.4389774011002974]
	TIME [epoch: 5.74 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5928565864620053		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.5928565864620053 | validation: 0.37969407129391214]
	TIME [epoch: 5.74 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4108663951968696		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.4108663951968696 | validation: 0.6883536034092318]
	TIME [epoch: 5.73 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5240204589876528		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.5240204589876528 | validation: 0.40324433180896335]
	TIME [epoch: 5.73 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40456690532620243		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.40456690532620243 | validation: 0.586996579601334]
	TIME [epoch: 5.73 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47388323448080816		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.47388323448080816 | validation: 0.2936576301327179]
	TIME [epoch: 5.78 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45643654707510606		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.45643654707510606 | validation: 0.3932424023968734]
	TIME [epoch: 5.75 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44370637969522786		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.44370637969522786 | validation: 0.3179852643938153]
	TIME [epoch: 5.74 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49916047875198866		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.49916047875198866 | validation: 0.47049440821772665]
	TIME [epoch: 5.74 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.527616935938644		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.527616935938644 | validation: 0.34719693856599115]
	TIME [epoch: 5.74 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5425538715452738		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.5425538715452738 | validation: 0.7173882782680521]
	TIME [epoch: 5.75 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47146135559691676		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.47146135559691676 | validation: 0.33048287417106564]
	TIME [epoch: 5.74 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3695305301730074		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.3695305301730074 | validation: 0.39057101822912116]
	TIME [epoch: 5.76 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3801252429152293		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.3801252429152293 | validation: 0.361201996786055]
	TIME [epoch: 5.74 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3652880409361051		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.3652880409361051 | validation: 0.4151214460666367]
	TIME [epoch: 5.74 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38484918682796243		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.38484918682796243 | validation: 0.31684697390283256]
	TIME [epoch: 5.74 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4159405379159504		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.4159405379159504 | validation: 0.268505342292831]
	TIME [epoch: 5.74 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44432735482020475		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.44432735482020475 | validation: 0.2788121402726563]
	TIME [epoch: 5.74 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.438254100314862		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.438254100314862 | validation: 0.34849456315767996]
	TIME [epoch: 5.77 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44517237761323936		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.44517237761323936 | validation: 0.4130239776771433]
	TIME [epoch: 5.74 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36531076031929954		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.36531076031929954 | validation: 0.2681288064731201]
	TIME [epoch: 5.73 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3743900021736858		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.3743900021736858 | validation: 0.3605732388124639]
	TIME [epoch: 5.73 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3784816475883014		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.3784816475883014 | validation: 0.44350608201984915]
	TIME [epoch: 5.73 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3839023445174068		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.3839023445174068 | validation: 0.3582905334984996]
	TIME [epoch: 5.74 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42831819842129804		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.42831819842129804 | validation: 0.2712539447651129]
	TIME [epoch: 5.74 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3695151629049459		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.3695151629049459 | validation: 0.2672418295767257]
	TIME [epoch: 5.78 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3751604342044095		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.3751604342044095 | validation: 0.5571659439812267]
	TIME [epoch: 5.75 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.439390917292369		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.439390917292369 | validation: 0.26400072548840636]
	TIME [epoch: 5.74 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3292444723301437		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.3292444723301437 | validation: 0.290235906056757]
	TIME [epoch: 5.74 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34101724912186004		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.34101724912186004 | validation: 0.3713066805807933]
	TIME [epoch: 5.73 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.58730217030895		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.58730217030895 | validation: 0.3384622768960429]
	TIME [epoch: 5.73 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34735869909353545		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.34735869909353545 | validation: 0.5737187850177095]
	TIME [epoch: 5.76 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42587405297219316		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.42587405297219316 | validation: 0.25184419179034917]
	TIME [epoch: 5.76 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3412037044145147		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.3412037044145147 | validation: 0.580456746332721]
	TIME [epoch: 5.74 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39467802790288514		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.39467802790288514 | validation: 0.32554593415339844]
	TIME [epoch: 5.74 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38785427566581454		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.38785427566581454 | validation: 0.2786612086388856]
	TIME [epoch: 5.74 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4356776180372144		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.4356776180372144 | validation: 0.2596419639022614]
	TIME [epoch: 5.73 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3524685077063216		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.3524685077063216 | validation: 0.32245478512146597]
	TIME [epoch: 5.73 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4873568754164449		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.4873568754164449 | validation: 0.6127302926048404]
	TIME [epoch: 5.77 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6447843586815422		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.6447843586815422 | validation: 0.4577727874223746]
	TIME [epoch: 5.74 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42117211881349087		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.42117211881349087 | validation: 0.253941901695634]
	TIME [epoch: 5.74 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3257562686851001		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.3257562686851001 | validation: 0.3086181111106036]
	TIME [epoch: 5.75 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.371961784189044		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.371961784189044 | validation: 0.26976794412473565]
	TIME [epoch: 5.74 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3477618595613544		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.3477618595613544 | validation: 0.2832672415964788]
	TIME [epoch: 5.74 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29478575971752496		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.29478575971752496 | validation: 0.2451436963961974]
	TIME [epoch: 5.77 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41021513999314124		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.41021513999314124 | validation: 0.3104118697629532]
	TIME [epoch: 5.75 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4191468359538708		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.4191468359538708 | validation: 0.46185185373957466]
	TIME [epoch: 5.74 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.407851839209377		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.407851839209377 | validation: 0.2267294947152819]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4448326359759526		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.4448326359759526 | validation: 0.2991382850984528]
	TIME [epoch: 5.74 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.402375107671988		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.402375107671988 | validation: 0.29487708014983743]
	TIME [epoch: 5.74 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3447239622518071		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.3447239622518071 | validation: 0.39012813872375984]
	TIME [epoch: 5.75 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3808142980871733		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.3808142980871733 | validation: 0.34267587435105235]
	TIME [epoch: 5.77 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30442809843914587		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.30442809843914587 | validation: 0.4637654232964888]
	TIME [epoch: 5.74 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40524985880440073		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.40524985880440073 | validation: 0.40793840287866523]
	TIME [epoch: 5.74 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4062577357068823		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.4062577357068823 | validation: 0.19703534977626733]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3425393852317965		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.3425393852317965 | validation: 0.3252224096882003]
	TIME [epoch: 5.73 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39217278167836805		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.39217278167836805 | validation: 0.40579037700772846]
	TIME [epoch: 5.74 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37545203775173464		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.37545203775173464 | validation: 0.230772029592057]
	TIME [epoch: 5.79 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2959429911023539		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.2959429911023539 | validation: 0.311724911416739]
	TIME [epoch: 5.75 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3372182283642772		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.3372182283642772 | validation: 0.32283450659637736]
	TIME [epoch: 5.75 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35365257280068485		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.35365257280068485 | validation: 0.2986846385911444]
	TIME [epoch: 5.73 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3548191426235222		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.3548191426235222 | validation: 0.3122455005328162]
	TIME [epoch: 5.76 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33870285124143484		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.33870285124143484 | validation: 0.2824932788619853]
	TIME [epoch: 5.74 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2875706270463637		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.2875706270463637 | validation: 0.4180510597867491]
	TIME [epoch: 5.76 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3515270703148845		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.3515270703148845 | validation: 0.26409145088678204]
	TIME [epoch: 5.76 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38663658000474105		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.38663658000474105 | validation: 0.3524161629461973]
	TIME [epoch: 5.75 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38525392750008386		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.38525392750008386 | validation: 0.3375134694932919]
	TIME [epoch: 5.74 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34356641095741464		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.34356641095741464 | validation: 0.9030862902605585]
	TIME [epoch: 5.74 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5150303218175085		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.5150303218175085 | validation: 0.25950706196317486]
	TIME [epoch: 5.74 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3113415008013951		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.3113415008013951 | validation: 0.819332732229728]
	TIME [epoch: 5.75 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6302437834499821		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.6302437834499821 | validation: 0.2716395982111429]
	TIME [epoch: 5.78 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28888393909767235		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.28888393909767235 | validation: 0.2513391476780679]
	TIME [epoch: 5.74 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3494929342910165		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.3494929342910165 | validation: 0.25894072423854936]
	TIME [epoch: 5.75 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3143236339407266		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.3143236339407266 | validation: 0.43077065639881285]
	TIME [epoch: 5.73 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43186310574433756		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.43186310574433756 | validation: 0.8495175100478705]
	TIME [epoch: 5.74 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49318772808727335		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.49318772808727335 | validation: 0.38504075242630975]
	TIME [epoch: 5.74 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37602171996499906		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.37602171996499906 | validation: 0.26355396714296575]
	TIME [epoch: 5.76 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30644472477992524		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.30644472477992524 | validation: 0.22605175722482615]
	TIME [epoch: 5.76 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3024031478666363		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.3024031478666363 | validation: 0.2012251290449984]
	TIME [epoch: 5.75 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3173393196880111		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.3173393196880111 | validation: 0.23523257374006484]
	TIME [epoch: 5.74 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36775096329365775		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.36775096329365775 | validation: 0.24912068683265742]
	TIME [epoch: 5.74 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.294836983551496		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.294836983551496 | validation: 0.19775358394962175]
	TIME [epoch: 5.75 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3108363451212425		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.3108363451212425 | validation: 0.32181022608317256]
	TIME [epoch: 5.73 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2790082182350737		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.2790082182350737 | validation: 0.20416714889371634]
	TIME [epoch: 5.78 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30648424547184994		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.30648424547184994 | validation: 0.21906369523003946]
	TIME [epoch: 5.75 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32191965760496144		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.32191965760496144 | validation: 0.2114863701308911]
	TIME [epoch: 5.73 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26790116788363544		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.26790116788363544 | validation: 0.21444842396260513]
	TIME [epoch: 5.74 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23350310262777785		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.23350310262777785 | validation: 0.28852016289409266]
	TIME [epoch: 5.75 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25102924256492065		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.25102924256492065 | validation: 0.2054460325437509]
	TIME [epoch: 5.74 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3037963243450053		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.3037963243450053 | validation: 0.1747959060298929]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2678125097670737		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.2678125097670737 | validation: 0.3297133110389887]
	TIME [epoch: 5.78 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3331640877127934		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.3331640877127934 | validation: 0.20318276232288202]
	TIME [epoch: 5.75 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27500791310754064		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.27500791310754064 | validation: 0.29703497015023195]
	TIME [epoch: 5.73 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3016927034254896		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.3016927034254896 | validation: 0.1897163479605434]
	TIME [epoch: 5.73 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27204279330945935		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.27204279330945935 | validation: 0.9887496009731106]
	TIME [epoch: 5.75 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5260597746345285		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.5260597746345285 | validation: 0.29131482857153695]
	TIME [epoch: 5.73 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2752612772347117		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.2752612772347117 | validation: 0.22510679634216568]
	TIME [epoch: 5.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2931354707767803		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.2931354707767803 | validation: 0.22107894048842844]
	TIME [epoch: 5.75 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26438142444215723		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.26438142444215723 | validation: 0.25774440076794286]
	TIME [epoch: 5.75 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2719669295248246		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.2719669295248246 | validation: 0.2717049181475741]
	TIME [epoch: 5.75 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24061237758059023		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.24061237758059023 | validation: 0.5365163911765445]
	TIME [epoch: 5.74 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5259475707779314		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.5259475707779314 | validation: 0.4885926054642769]
	TIME [epoch: 5.74 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42044608404816564		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.42044608404816564 | validation: 0.582222376883837]
	TIME [epoch: 5.75 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.377220744600993		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.377220744600993 | validation: 0.1957203325872608]
	TIME [epoch: 5.76 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24659205003858967		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.24659205003858967 | validation: 0.22419058484220342]
	TIME [epoch: 5.75 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.282710710534841		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.282710710534841 | validation: 0.2894127250759057]
	TIME [epoch: 5.75 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35861574452729766		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.35861574452729766 | validation: 0.20644156819986761]
	TIME [epoch: 5.75 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22929507278894892		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.22929507278894892 | validation: 0.22574983615262795]
	TIME [epoch: 5.74 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26410448008503873		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.26410448008503873 | validation: 0.40984324407475653]
	TIME [epoch: 5.76 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3101715490002474		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.3101715490002474 | validation: 0.23592614720382138]
	TIME [epoch: 5.78 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2597975213246983		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.2597975213246983 | validation: 0.3008928090253325]
	TIME [epoch: 5.76 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32489408139016424		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.32489408139016424 | validation: 0.25500632578495264]
	TIME [epoch: 5.75 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2597879305162976		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.2597879305162976 | validation: 0.2364493635018934]
	TIME [epoch: 5.75 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.282964220681584		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.282964220681584 | validation: 0.21904182903948902]
	TIME [epoch: 5.74 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24993554882574895		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.24993554882574895 | validation: 0.2097114673833384]
	TIME [epoch: 5.75 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3037122888821555		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.3037122888821555 | validation: 0.27834011008442655]
	TIME [epoch: 5.77 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.288301617866645		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.288301617866645 | validation: 0.20977147917631622]
	TIME [epoch: 5.78 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2941438723979167		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.2941438723979167 | validation: 0.18858731745059357]
	TIME [epoch: 5.75 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24282100318357602		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.24282100318357602 | validation: 0.2149987670263007]
	TIME [epoch: 5.76 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2618939290241595		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.2618939290241595 | validation: 0.17866417709152088]
	TIME [epoch: 5.75 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23201262063462685		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.23201262063462685 | validation: 0.24432627322958234]
	TIME [epoch: 5.74 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2588051264092702		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.2588051264092702 | validation: 0.21010941528671978]
	TIME [epoch: 5.74 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26670428533634527		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.26670428533634527 | validation: 0.20386091599626]
	TIME [epoch: 5.79 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27600516492121097		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.27600516492121097 | validation: 0.41785155603325297]
	TIME [epoch: 5.75 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44476824918774205		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.44476824918774205 | validation: 0.3603323097891811]
	TIME [epoch: 5.76 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2856800823408552		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.2856800823408552 | validation: 0.228072541736533]
	TIME [epoch: 5.75 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2354269018895514		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.2354269018895514 | validation: 0.19574429999565193]
	TIME [epoch: 5.74 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21483203066456177		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.21483203066456177 | validation: 0.16696269932674093]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2614498761859957		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.2614498761859957 | validation: 0.21872995038688714]
	TIME [epoch: 5.78 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2164871845921158		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.2164871845921158 | validation: 0.3892958839831998]
	TIME [epoch: 5.75 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2362194994110422		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.2362194994110422 | validation: 0.33401281395800647]
	TIME [epoch: 5.74 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2733805545986739		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.2733805545986739 | validation: 0.2507295221404381]
	TIME [epoch: 5.73 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21498646917089595		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.21498646917089595 | validation: 0.17420544841491165]
	TIME [epoch: 5.74 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20782882575382772		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.20782882575382772 | validation: 0.26209216064172336]
	TIME [epoch: 5.76 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19508309514997402		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.19508309514997402 | validation: 0.1546401564229228]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2571682774693433		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.2571682774693433 | validation: 0.17273767281440763]
	TIME [epoch: 5.78 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22201318555007926		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.22201318555007926 | validation: 0.30247242417931525]
	TIME [epoch: 5.74 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31441002901662246		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.31441002901662246 | validation: 0.154337456824739]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19653491216565847		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.19653491216565847 | validation: 0.19639034518679743]
	TIME [epoch: 5.75 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19015459422200068		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.19015459422200068 | validation: 0.18769450994909392]
	TIME [epoch: 5.73 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1905567421086819		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.1905567421086819 | validation: 0.18696257971175342]
	TIME [epoch: 5.74 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22207532699030297		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.22207532699030297 | validation: 0.30603862764156103]
	TIME [epoch: 5.77 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20596875057752637		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.20596875057752637 | validation: 0.2625001400415371]
	TIME [epoch: 5.76 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23711630328477878		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.23711630328477878 | validation: 0.3297420592620696]
	TIME [epoch: 5.73 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2532768949692571		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.2532768949692571 | validation: 0.1056330226140065]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_233.pth
	Model improved!!!
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17559834817780612		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.17559834817780612 | validation: 0.19749811830301262]
	TIME [epoch: 5.77 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17882138200573808		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.17882138200573808 | validation: 0.13024998081796296]
	TIME [epoch: 5.76 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18714634766082788		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.18714634766082788 | validation: 0.15202182714670193]
	TIME [epoch: 5.77 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22498394452567144		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.22498394452567144 | validation: 0.37897417236445186]
	TIME [epoch: 5.78 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33059773078997895		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.33059773078997895 | validation: 0.21287845282981438]
	TIME [epoch: 5.75 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24023971827589974		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.24023971827589974 | validation: 0.22055877503418442]
	TIME [epoch: 5.75 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23971903878172088		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.23971903878172088 | validation: 0.16352542278120738]
	TIME [epoch: 5.76 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.280566363592163		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.280566363592163 | validation: 0.18379549086958538]
	TIME [epoch: 5.77 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16371947909047443		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.16371947909047443 | validation: 0.1200596353526782]
	TIME [epoch: 5.75 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17128366643019102		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.17128366643019102 | validation: 0.12165930627639729]
	TIME [epoch: 5.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18531424034032143		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.18531424034032143 | validation: 0.19441028432588983]
	TIME [epoch: 5.77 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31090272582103884		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.31090272582103884 | validation: 0.41136780486520447]
	TIME [epoch: 5.76 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31455049196366586		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.31455049196366586 | validation: 0.24800943647048238]
	TIME [epoch: 5.76 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22110875235145735		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.22110875235145735 | validation: 0.18453015154277438]
	TIME [epoch: 5.76 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20838715451833426		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.20838715451833426 | validation: 0.18460553049942932]
	TIME [epoch: 5.76 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18586456628111178		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.18586456628111178 | validation: 0.1253283552343112]
	TIME [epoch: 5.77 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17244840751984428		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.17244840751984428 | validation: 0.15602403828536804]
	TIME [epoch: 5.79 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19426832145436		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.19426832145436 | validation: 0.1761068148786103]
	TIME [epoch: 5.77 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1506831241699234		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.1506831241699234 | validation: 0.1221606192191872]
	TIME [epoch: 5.76 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13576107177384833		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.13576107177384833 | validation: 0.19574935377006678]
	TIME [epoch: 5.76 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24807320455341186		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.24807320455341186 | validation: 0.10650475703488428]
	TIME [epoch: 5.77 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2364029203741315		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.2364029203741315 | validation: 0.153002386707683]
	TIME [epoch: 5.76 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.196806450965785		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.196806450965785 | validation: 0.0984667601516648]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17475486382486277		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.17475486382486277 | validation: 0.20981437772316583]
	TIME [epoch: 5.76 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2227057371484154		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.2227057371484154 | validation: 0.14699281739511047]
	TIME [epoch: 5.75 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17673645532751078		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.17673645532751078 | validation: 0.3697696900899141]
	TIME [epoch: 5.75 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3416766495458168		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.3416766495458168 | validation: 0.37024834933107736]
	TIME [epoch: 5.74 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26209505382356113		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.26209505382356113 | validation: 0.14443828056279906]
	TIME [epoch: 5.75 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17175525306654899		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.17175525306654899 | validation: 0.12139382322379141]
	TIME [epoch: 5.78 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.197108964950619		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.197108964950619 | validation: 0.12880713297452126]
	TIME [epoch: 5.77 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2010440885156549		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.2010440885156549 | validation: 0.12820952159057786]
	TIME [epoch: 5.74 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22534692662760838		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.22534692662760838 | validation: 0.1783483352439578]
	TIME [epoch: 5.73 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16348193727986393		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.16348193727986393 | validation: 0.4450442681202163]
	TIME [epoch: 5.75 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2962353380788506		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.2962353380788506 | validation: 0.2668364702532014]
	TIME [epoch: 5.74 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2517380220725502		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.2517380220725502 | validation: 0.12495222746023397]
	TIME [epoch: 5.76 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17411800842014313		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.17411800842014313 | validation: 0.10707967905163723]
	TIME [epoch: 5.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1540649351239671		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.1540649351239671 | validation: 0.2900018447870402]
	TIME [epoch: 5.76 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2551407329423779		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.2551407329423779 | validation: 0.7906380526826936]
	TIME [epoch: 5.74 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.525291492706192		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.525291492706192 | validation: 0.26224311062791905]
	TIME [epoch: 5.76 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22445467009793832		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.22445467009793832 | validation: 0.11202307606622376]
	TIME [epoch: 5.75 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15692553785333602		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.15692553785333602 | validation: 0.11378469073684251]
	TIME [epoch: 5.73 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1838453507615833		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.1838453507615833 | validation: 0.21844493207193963]
	TIME [epoch: 5.76 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17656258977773084		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.17656258977773084 | validation: 0.13225357423398115]
	TIME [epoch: 5.75 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2672574577896662		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.2672574577896662 | validation: 0.24098336905352924]
	TIME [epoch: 5.74 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21687332477078936		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.21687332477078936 | validation: 0.3608145078820815]
	TIME [epoch: 5.75 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2804810487216509		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.2804810487216509 | validation: 0.1672564615595642]
	TIME [epoch: 5.74 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18735034008547063		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.18735034008547063 | validation: 0.18036829605159824]
	TIME [epoch: 5.76 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18612588240761252		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.18612588240761252 | validation: 0.15084384743360243]
	TIME [epoch: 5.73 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21602691415851752		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.21602691415851752 | validation: 0.17464895425037688]
	TIME [epoch: 5.79 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17170136017136603		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.17170136017136603 | validation: 0.30929105565916265]
	TIME [epoch: 5.73 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23353405466338015		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.23353405466338015 | validation: 0.13521711866631533]
	TIME [epoch: 5.75 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1574496156186136		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.1574496156186136 | validation: 0.13041779076382626]
	TIME [epoch: 5.74 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18235199638477387		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.18235199638477387 | validation: 0.14123889227480194]
	TIME [epoch: 5.76 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17521552862643677		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.17521552862643677 | validation: 0.26160870489178956]
	TIME [epoch: 5.75 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1872342020311909		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.1872342020311909 | validation: 0.11704392984077941]
	TIME [epoch: 5.79 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15593227349084496		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.15593227349084496 | validation: 0.12816326716294943]
	TIME [epoch: 5.75 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14435859357985834		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.14435859357985834 | validation: 0.12172337312425315]
	TIME [epoch: 5.76 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2021720259463909		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.2021720259463909 | validation: 0.17478392662687844]
	TIME [epoch: 5.74 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18019643289445758		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.18019643289445758 | validation: 0.19153212384717358]
	TIME [epoch: 5.73 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19063706629066618		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.19063706629066618 | validation: 0.1791122138867005]
	TIME [epoch: 5.73 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1511687531316828		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.1511687531316828 | validation: 0.20723892249219372]
	TIME [epoch: 5.75 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20141209055329998		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.20141209055329998 | validation: 0.21213133301796916]
	TIME [epoch: 5.78 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23629152576865375		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.23629152576865375 | validation: 0.32301405778320885]
	TIME [epoch: 5.76 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18309001322040508		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.18309001322040508 | validation: 0.20556806412378842]
	TIME [epoch: 5.74 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19051000052513334		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.19051000052513334 | validation: 0.24629043936775874]
	TIME [epoch: 5.75 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14588430927318383		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.14588430927318383 | validation: 0.18544308561318582]
	TIME [epoch: 5.74 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21350392137945193		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.21350392137945193 | validation: 0.13164143102752643]
	TIME [epoch: 5.75 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1375003697265231		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.1375003697265231 | validation: 0.11929650232693818]
	TIME [epoch: 5.78 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12871573099483813		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.12871573099483813 | validation: 0.18408583985994142]
	TIME [epoch: 5.75 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13444039872561403		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.13444039872561403 | validation: 0.15883795454912408]
	TIME [epoch: 5.74 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15670324918154535		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.15670324918154535 | validation: 0.1784755004758044]
	TIME [epoch: 5.74 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24056402154291961		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.24056402154291961 | validation: 0.2417864858155673]
	TIME [epoch: 5.76 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22852848708549373		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.22852848708549373 | validation: 0.24373212193424257]
	TIME [epoch: 5.74 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2203013463271994		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.2203013463271994 | validation: 0.1014579619948575]
	TIME [epoch: 5.73 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1334585957651371		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.1334585957651371 | validation: 0.10751893768330131]
	TIME [epoch: 5.8 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10711953806689821		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.10711953806689821 | validation: 0.12267673660552636]
	TIME [epoch: 5.78 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12317002404648122		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.12317002404648122 | validation: 0.15357922229075713]
	TIME [epoch: 5.76 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16372724872405436		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.16372724872405436 | validation: 0.1616082832654427]
	TIME [epoch: 5.73 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1823943310416668		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.1823943310416668 | validation: 0.25181038742641804]
	TIME [epoch: 5.73 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18815773944018602		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.18815773944018602 | validation: 0.1372543301611452]
	TIME [epoch: 5.75 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1686027791685633		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.1686027791685633 | validation: 0.5243891928090686]
	TIME [epoch: 5.78 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2871051676958108		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.2871051676958108 | validation: 0.18462076330580987]
	TIME [epoch: 5.77 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23978979943245762		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.23978979943245762 | validation: 0.13119624296121535]
	TIME [epoch: 5.76 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.266503725568571		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.266503725568571 | validation: 0.33872276875005997]
	TIME [epoch: 5.75 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3119520036519502		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.3119520036519502 | validation: 0.13807109351195176]
	TIME [epoch: 5.75 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20737671954039497		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.20737671954039497 | validation: 0.1457176866152533]
	TIME [epoch: 5.74 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15296368752567593		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.15296368752567593 | validation: 0.20997102228769365]
	TIME [epoch: 5.74 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16420060723044674		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.16420060723044674 | validation: 0.12805096639395033]
	TIME [epoch: 5.78 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19126057659276027		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.19126057659276027 | validation: 0.2584865158998489]
	TIME [epoch: 5.74 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15648912243732288		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.15648912243732288 | validation: 0.07535540651163262]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_323.pth
	Model improved!!!
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1120393453736638		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.1120393453736638 | validation: 0.11244724333199134]
	TIME [epoch: 5.75 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268023041194574		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.1268023041194574 | validation: 0.15824204385264076]
	TIME [epoch: 5.75 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1398856366467174		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.1398856366467174 | validation: 0.1187914314306321]
	TIME [epoch: 5.75 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12880475829049934		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.12880475829049934 | validation: 0.11129318860383773]
	TIME [epoch: 5.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12310043933300668		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.12310043933300668 | validation: 0.1722080705127481]
	TIME [epoch: 5.76 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21432108941350425		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.21432108941350425 | validation: 0.10388627144822232]
	TIME [epoch: 5.75 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16735920593532994		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.16735920593532994 | validation: 0.27916639583769404]
	TIME [epoch: 5.75 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1929486273375706		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.1929486273375706 | validation: 0.13275662856629203]
	TIME [epoch: 5.76 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13967522933351784		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.13967522933351784 | validation: 0.11875441493104326]
	TIME [epoch: 5.75 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20936460013243385		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.20936460013243385 | validation: 0.11508118560862603]
	TIME [epoch: 5.75 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11768757103630598		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.11768757103630598 | validation: 0.1584472268609198]
	TIME [epoch: 5.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24810672568613154		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.24810672568613154 | validation: 0.1541746349158998]
	TIME [epoch: 5.76 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1706283444665871		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.1706283444665871 | validation: 0.19996444772849764]
	TIME [epoch: 5.76 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2209460605752885		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.2209460605752885 | validation: 0.10312057357538809]
	TIME [epoch: 5.75 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18515257241280136		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.18515257241280136 | validation: 0.41398946322370495]
	TIME [epoch: 5.74 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31038185659596507		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.31038185659596507 | validation: 0.1251590278977713]
	TIME [epoch: 5.74 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14865276844812314		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.14865276844812314 | validation: 0.14615950487042553]
	TIME [epoch: 5.77 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18593675204705934		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.18593675204705934 | validation: 0.15728853842930646]
	TIME [epoch: 5.76 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1868010046104885		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.1868010046104885 | validation: 0.11993622252494529]
	TIME [epoch: 5.75 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16852690675065768		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.16852690675065768 | validation: 0.17905504687217874]
	TIME [epoch: 5.74 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19694629833647323		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.19694629833647323 | validation: 0.21746294359816054]
	TIME [epoch: 5.74 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1609783543925471		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.1609783543925471 | validation: 0.10827587636808865]
	TIME [epoch: 5.74 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18643346853742704		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.18643346853742704 | validation: 0.2041613820192022]
	TIME [epoch: 5.76 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18572542211582738		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.18572542211582738 | validation: 0.500165515914414]
	TIME [epoch: 5.78 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3293505197091913		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.3293505197091913 | validation: 0.15125386841386446]
	TIME [epoch: 5.76 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16022784418704536		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.16022784418704536 | validation: 0.09028769524521554]
	TIME [epoch: 5.74 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21331189981895918		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.21331189981895918 | validation: 0.223808957355054]
	TIME [epoch: 5.74 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21832896992230552		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.21832896992230552 | validation: 0.1463095039668933]
	TIME [epoch: 5.75 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15283072095197492		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.15283072095197492 | validation: 0.15066522790370285]
	TIME [epoch: 5.73 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16774461598202606		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.16774461598202606 | validation: 0.09216501979821874]
	TIME [epoch: 5.78 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1376239597154885		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.1376239597154885 | validation: 0.1822292058928536]
	TIME [epoch: 5.75 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15286567505497187		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.15286567505497187 | validation: 0.10034222146788029]
	TIME [epoch: 5.75 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15270448201130157		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.15270448201130157 | validation: 0.1405071411095755]
	TIME [epoch: 5.73 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13945337677814412		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.13945337677814412 | validation: 0.08804282590367678]
	TIME [epoch: 5.75 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10062478131246813		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.10062478131246813 | validation: 0.16562708898652304]
	TIME [epoch: 5.75 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2200649735880472		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.2200649735880472 | validation: 0.18607697783990135]
	TIME [epoch: 5.74 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28794620523931536		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.28794620523931536 | validation: 0.1685984090185602]
	TIME [epoch: 5.79 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1685333704494486		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.1685333704494486 | validation: 0.1622693312787736]
	TIME [epoch: 5.74 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14463818593549121		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.14463818593549121 | validation: 0.14156703590759934]
	TIME [epoch: 5.75 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16288656660855366		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.16288656660855366 | validation: 0.18637318098276368]
	TIME [epoch: 5.74 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18246128082990512		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.18246128082990512 | validation: 0.16186357542953758]
	TIME [epoch: 5.74 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16442881576080975		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.16442881576080975 | validation: 0.11989759532448117]
	TIME [epoch: 5.74 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12100096039086458		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.12100096039086458 | validation: 0.10735676979896244]
	TIME [epoch: 5.78 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11670307397014536		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.11670307397014536 | validation: 0.08091590917185806]
	TIME [epoch: 5.75 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11190192470759511		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.11190192470759511 | validation: 0.0983442622300943]
	TIME [epoch: 5.76 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15997068007590984		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.15997068007590984 | validation: 0.10483063555205505]
	TIME [epoch: 5.74 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1372368350619859		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.1372368350619859 | validation: 0.36212859022395416]
	TIME [epoch: 5.74 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1955914898381123		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.1955914898381123 | validation: 0.1273099164971387]
	TIME [epoch: 5.74 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1317095930732437		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.1317095930732437 | validation: 0.07283440069694126]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_372.pth
	Model improved!!!
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13953323042156304		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.13953323042156304 | validation: 0.15921467500646325]
	TIME [epoch: 5.78 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21170116868529282		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.21170116868529282 | validation: 0.11750697613664551]
	TIME [epoch: 5.73 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13177399425321218		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.13177399425321218 | validation: 0.211927262881603]
	TIME [epoch: 5.75 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2497738123589257		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.2497738123589257 | validation: 0.09416518155694215]
	TIME [epoch: 5.74 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16252544259006815		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.16252544259006815 | validation: 0.10306091802871936]
	TIME [epoch: 5.75 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13320151237490718		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.13320151237490718 | validation: 0.08465522194809977]
	TIME [epoch: 5.75 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12379927133868188		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.12379927133868188 | validation: 0.10985836031658629]
	TIME [epoch: 5.78 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1329491221724659		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.1329491221724659 | validation: 0.1301736988444661]
	TIME [epoch: 5.74 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16693684084882754		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.16693684084882754 | validation: 0.12259824587569852]
	TIME [epoch: 5.76 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11543433424031874		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.11543433424031874 | validation: 0.08131966954264248]
	TIME [epoch: 5.75 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10757256291831868		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.10757256291831868 | validation: 0.0651174445010055]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_383.pth
	Model improved!!!
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08739859731617788		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.08739859731617788 | validation: 0.08737365421872266]
	TIME [epoch: 5.74 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10337349682439353		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.10337349682439353 | validation: 0.07925106623640649]
	TIME [epoch: 5.76 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20553476205440507		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.20553476205440507 | validation: 0.1498851659349695]
	TIME [epoch: 5.76 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.131520037794065		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.131520037794065 | validation: 0.06989850752689782]
	TIME [epoch: 5.74 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11777420131202862		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.11777420131202862 | validation: 0.08460331511853497]
	TIME [epoch: 5.74 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07887747780923417		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.07887747780923417 | validation: 0.07542859385846638]
	TIME [epoch: 5.75 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10237881375011826		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.10237881375011826 | validation: 0.10307344474234813]
	TIME [epoch: 5.74 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09240712402108794		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.09240712402108794 | validation: 0.068766669390502]
	TIME [epoch: 5.76 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11898151595904385		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.11898151595904385 | validation: 0.2411753506879748]
	TIME [epoch: 5.78 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32896365841601816		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.32896365841601816 | validation: 0.17130136351190792]
	TIME [epoch: 5.76 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1463540225060594		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.1463540225060594 | validation: 0.08535391479059472]
	TIME [epoch: 5.74 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09524589372857883		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.09524589372857883 | validation: 0.13098009176519348]
	TIME [epoch: 5.75 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1057343392092116		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.1057343392092116 | validation: 0.1441453419502309]
	TIME [epoch: 5.74 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12364296626538004		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.12364296626538004 | validation: 0.14746621964616322]
	TIME [epoch: 5.74 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11680541329205416		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.11680541329205416 | validation: 0.1450180427964858]
	TIME [epoch: 5.76 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363903244243107		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.1363903244243107 | validation: 0.16933821059113568]
	TIME [epoch: 5.77 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1503371055186717		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.1503371055186717 | validation: 0.08173284961095421]
	TIME [epoch: 5.74 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20048774956411466		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.20048774956411466 | validation: 0.10807561723570272]
	TIME [epoch: 5.74 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10291286337130003		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.10291286337130003 | validation: 0.08534093504412534]
	TIME [epoch: 5.74 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10274404430486019		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.10274404430486019 | validation: 0.0451669365680582]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_403.pth
	Model improved!!!
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1098089686097748		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.1098089686097748 | validation: 0.04728303241507946]
	TIME [epoch: 5.74 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07394953660327391		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.07394953660327391 | validation: 0.056939243657839124]
	TIME [epoch: 5.78 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1070910438625882		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.1070910438625882 | validation: 0.09942562363520757]
	TIME [epoch: 5.73 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08189051554146017		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.08189051554146017 | validation: 0.08960822877849829]
	TIME [epoch: 5.74 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12972536294674825		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.12972536294674825 | validation: 0.0766224285154751]
	TIME [epoch: 5.74 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17264581042952665		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.17264581042952665 | validation: 0.1934452764918714]
	TIME [epoch: 5.74 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1319377667829783		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.1319377667829783 | validation: 0.07036364631926068]
	TIME [epoch: 5.74 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12249676779605406		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.12249676779605406 | validation: 0.14800850003074748]
	TIME [epoch: 5.78 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09311873168798057		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.09311873168798057 | validation: 0.07320998950567977]
	TIME [epoch: 5.75 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1275157701116757		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.1275157701116757 | validation: 0.0801576057717683]
	TIME [epoch: 5.75 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09841658666210379		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.09841658666210379 | validation: 0.1789648510829045]
	TIME [epoch: 5.74 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17793863013496145		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.17793863013496145 | validation: 0.07798253153853897]
	TIME [epoch: 5.74 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11371925469333372		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.11371925469333372 | validation: 0.10894276268471252]
	TIME [epoch: 5.73 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12316203903382382		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.12316203903382382 | validation: 0.13966995011220498]
	TIME [epoch: 5.74 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10812720659688937		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.10812720659688937 | validation: 0.1581479472796514]
	TIME [epoch: 5.78 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15974511934168836		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.15974511934168836 | validation: 0.20633312020019864]
	TIME [epoch: 5.74 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12657760633265996		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.12657760633265996 | validation: 0.24238041081885667]
	TIME [epoch: 5.74 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16218614883800478		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.16218614883800478 | validation: 0.12349108690673387]
	TIME [epoch: 5.74 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10732810332947575		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.10732810332947575 | validation: 0.10574846276217766]
	TIME [epoch: 5.74 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12355454847899941		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.12355454847899941 | validation: 0.11771810885369628]
	TIME [epoch: 5.75 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10846956643788991		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.10846956643788991 | validation: 0.09063532156518504]
	TIME [epoch: 5.77 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11814380172927334		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.11814380172927334 | validation: 0.14254955660003105]
	TIME [epoch: 5.74 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10881401851535427		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.10881401851535427 | validation: 0.11613660997741583]
	TIME [epoch: 5.74 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11190771159138288		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.11190771159138288 | validation: 0.08970673222507738]
	TIME [epoch: 5.75 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11726920728752853		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.11726920728752853 | validation: 0.08374237996574048]
	TIME [epoch: 5.74 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09386119737869275		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.09386119737869275 | validation: 0.14694578592041374]
	TIME [epoch: 5.76 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1235320071899005		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.1235320071899005 | validation: 0.05840149883449417]
	TIME [epoch: 5.75 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12518507940721577		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.12518507940721577 | validation: 0.13310937810691426]
	TIME [epoch: 5.79 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12164760050961222		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.12164760050961222 | validation: 0.0891169643716891]
	TIME [epoch: 5.74 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09161529189076709		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.09161529189076709 | validation: 0.06218282560354286]
	TIME [epoch: 5.75 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08074340348029516		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.08074340348029516 | validation: 0.08109107927845997]
	TIME [epoch: 5.75 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0923477541038826		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.0923477541038826 | validation: 0.08988176260362778]
	TIME [epoch: 5.75 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11961627446820482		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.11961627446820482 | validation: 0.10743823585853042]
	TIME [epoch: 5.75 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07996956112801742		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.07996956112801742 | validation: 0.09741964818651529]
	TIME [epoch: 5.78 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08535603723747948		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.08535603723747948 | validation: 0.04751104756996805]
	TIME [epoch: 5.77 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0839563236558037		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.0839563236558037 | validation: 0.09303490332097854]
	TIME [epoch: 5.75 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14910901603788074		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.14910901603788074 | validation: 0.09832910969543711]
	TIME [epoch: 5.74 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08107568269543627		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.08107568269543627 | validation: 0.11727275897555753]
	TIME [epoch: 5.74 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11954551211020288		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.11954551211020288 | validation: 0.07116583034896923]
	TIME [epoch: 5.75 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10752921869388304		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.10752921869388304 | validation: 0.14353957075842924]
	TIME [epoch: 5.76 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1189899420270816		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.1189899420270816 | validation: 0.09677185636375796]
	TIME [epoch: 5.78 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08108577782964646		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.08108577782964646 | validation: 0.07666717812811358]
	TIME [epoch: 5.74 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10087584508355399		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.10087584508355399 | validation: 0.177261142916398]
	TIME [epoch: 5.75 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20961396984969066		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.20961396984969066 | validation: 0.11046107648151955]
	TIME [epoch: 5.74 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12526824418003651		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.12526824418003651 | validation: 0.11011820897486947]
	TIME [epoch: 5.74 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15487993670963712		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.15487993670963712 | validation: 0.16409642155415033]
	TIME [epoch: 5.74 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20089964530903962		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.20089964530903962 | validation: 0.14534778903324458]
	TIME [epoch: 5.78 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19024849944717512		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.19024849944717512 | validation: 0.16660392765084509]
	TIME [epoch: 5.76 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21607670375615787		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.21607670375615787 | validation: 0.20137342618609178]
	TIME [epoch: 5.76 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.168206743007146		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.168206743007146 | validation: 0.12427140668732012]
	TIME [epoch: 5.75 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21548312883898432		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.21548312883898432 | validation: 0.15136891629817487]
	TIME [epoch: 5.74 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11466291369345652		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.11466291369345652 | validation: 0.09182244801483286]
	TIME [epoch: 5.74 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11698827762100894		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.11698827762100894 | validation: 0.07359960827224954]
	TIME [epoch: 5.76 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07528355412860283		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.07528355412860283 | validation: 0.050661910021334404]
	TIME [epoch: 5.78 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10107374849910383		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.10107374849910383 | validation: 0.11231983637254934]
	TIME [epoch: 5.75 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13697418817567175		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.13697418817567175 | validation: 0.14504933458437264]
	TIME [epoch: 5.74 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1409544481974616		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.1409544481974616 | validation: 0.06775370648823868]
	TIME [epoch: 5.74 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07566138618554974		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.07566138618554974 | validation: 0.0688608826615568]
	TIME [epoch: 5.75 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10866025982269004		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.10866025982269004 | validation: 0.09602037966511585]
	TIME [epoch: 5.74 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323452445727546		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.1323452445727546 | validation: 0.15182904857668772]
	TIME [epoch: 5.77 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24583965082823012		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.24583965082823012 | validation: 0.18277243662172565]
	TIME [epoch: 5.77 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18110654185314373		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.18110654185314373 | validation: 0.10761630237395849]
	TIME [epoch: 5.74 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11505067056914325		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.11505067056914325 | validation: 0.15705242831090646]
	TIME [epoch: 5.76 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1341227683630937		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.1341227683630937 | validation: 0.10959637830437993]
	TIME [epoch: 5.74 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10377601648135593		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.10377601648135593 | validation: 0.1615640712588053]
	TIME [epoch: 5.75 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10718473343903884		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.10718473343903884 | validation: 0.06817397823392753]
	TIME [epoch: 5.75 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12360149710363122		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.12360149710363122 | validation: 0.15794243772194796]
	TIME [epoch: 5.78 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12280133258539211		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.12280133258539211 | validation: 0.0803348052078973]
	TIME [epoch: 5.74 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11774913315640254		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.11774913315640254 | validation: 0.10425325962211829]
	TIME [epoch: 5.76 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0984099815665827		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.0984099815665827 | validation: 0.07311763909707585]
	TIME [epoch: 5.75 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14646006619419968		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.14646006619419968 | validation: 0.17303288313534115]
	TIME [epoch: 5.75 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11782807434656145		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.11782807434656145 | validation: 0.11947450142824081]
	TIME [epoch: 5.75 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08851338319945468		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.08851338319945468 | validation: 0.08259972949010937]
	TIME [epoch: 5.77 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08484385093945031		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.08484385093945031 | validation: 0.04939332645683578]
	TIME [epoch: 5.75 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0863051666406751		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.0863051666406751 | validation: 0.12438569484070644]
	TIME [epoch: 5.74 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1593158499668744		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.1593158499668744 | validation: 0.07737336448173324]
	TIME [epoch: 5.74 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11865290122679609		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.11865290122679609 | validation: 0.12077203901779063]
	TIME [epoch: 5.75 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10313565326013906		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.10313565326013906 | validation: 0.06559600697519195]
	TIME [epoch: 5.75 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12712068714779715		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.12712068714779715 | validation: 0.13211375965339756]
	TIME [epoch: 5.75 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09569614972609902		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.09569614972609902 | validation: 0.10490164702597696]
	TIME [epoch: 5.79 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1733492564949269		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.1733492564949269 | validation: 0.30884451683208997]
	TIME [epoch: 5.74 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34168690846939975		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.34168690846939975 | validation: 0.08303513000796592]
	TIME [epoch: 5.75 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1059560700980785		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.1059560700980785 | validation: 0.06935785567283136]
	TIME [epoch: 5.74 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07642185997122174		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.07642185997122174 | validation: 0.06348251973628252]
	TIME [epoch: 5.74 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.109107524088185		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.109107524088185 | validation: 0.24885947601718536]
	TIME [epoch: 5.76 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1949157588922703		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.1949157588922703 | validation: 0.06391386938490587]
	TIME [epoch: 5.79 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11840988474671514		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.11840988474671514 | validation: 0.10997390453712212]
	TIME [epoch: 5.75 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10346382548926258		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.10346382548926258 | validation: 0.08574857795733337]
	TIME [epoch: 5.74 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10039348237618842		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.10039348237618842 | validation: 0.09162213067945711]
	TIME [epoch: 5.74 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09531721821868866		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.09531721821868866 | validation: 0.0913047611436615]
	TIME [epoch: 5.73 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07209618790136917		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.07209618790136917 | validation: 0.08613283244286414]
	TIME [epoch: 5.74 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11323891117673932		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.11323891117673932 | validation: 0.23817544517891967]
	TIME [epoch: 5.76 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14209243345760164		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.14209243345760164 | validation: 0.0783619672215245]
	TIME [epoch: 5.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10107359540203058		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.10107359540203058 | validation: 0.05949511251315709]
	TIME [epoch: 5.74 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08084901926539981		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.08084901926539981 | validation: 0.10287502475740418]
	TIME [epoch: 5.75 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10490410348084875		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.10490410348084875 | validation: 0.06868103753424849]
	TIME [epoch: 5.75 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08541060983071674		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.08541060983071674 | validation: 0.10612134741363596]
	TIME [epoch: 5.74 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12004135207896671		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.12004135207896671 | validation: 0.07197566920595788]
	TIME [epoch: 5.74 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07030484745364775		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.07030484745364775 | validation: 0.06131900224449771]
	TIME [epoch: 5.77 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07259091688995994		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.07259091688995994 | validation: 0.08547932344667186]
	TIME [epoch: 5.75 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07884646836564432		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.07884646836564432 | validation: 0.07665459653637674]
	TIME [epoch: 5.74 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09067603809059369		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.09067603809059369 | validation: 0.08431254290477756]
	TIME [epoch: 5.74 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08697319204649787		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.08697319204649787 | validation: 0.10237676537319373]
	TIME [epoch: 5.75 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10368060686659739		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.10368060686659739 | validation: 0.060852781618974054]
	TIME [epoch: 5.74 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07166514713062697		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.07166514713062697 | validation: 0.08306499788203281]
	TIME [epoch: 5.74 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08186364167710913		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.08186364167710913 | validation: 0.10422953905200241]
	TIME [epoch: 5.78 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09839484267001901		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.09839484267001901 | validation: 0.093846172045082]
	TIME [epoch: 5.74 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08872512621073633		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.08872512621073633 | validation: 0.0708680408728621]
	TIME [epoch: 5.75 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07087750655006868		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.07087750655006868 | validation: 0.06698680508997132]
	TIME [epoch: 5.76 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08592834340021324		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.08592834340021324 | validation: 0.07932092192273271]
	TIME [epoch: 5.75 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0838231571652667		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.0838231571652667 | validation: 0.06953044471150024]
	TIME [epoch: 5.74 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0888848420070806		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.0888848420070806 | validation: 0.10288789888920724]
	TIME [epoch: 5.79 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09961856825850028		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.09961856825850028 | validation: 0.08270893082826512]
	TIME [epoch: 5.77 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10547980906792737		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.10547980906792737 | validation: 0.13202842688803507]
	TIME [epoch: 5.76 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09134552913290275		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.09134552913290275 | validation: 0.052617628430957915]
	TIME [epoch: 5.76 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1070466475166148		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.1070466475166148 | validation: 0.065854732865537]
	TIME [epoch: 5.75 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08742890678016976		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.08742890678016976 | validation: 0.09092185930035566]
	TIME [epoch: 5.75 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11329642874439325		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.11329642874439325 | validation: 0.1821394074339129]
	TIME [epoch: 5.76 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16211169369708756		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.16211169369708756 | validation: 0.09110967575299786]
	TIME [epoch: 5.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12997404267647328		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.12997404267647328 | validation: 0.23653432162853782]
	TIME [epoch: 5.76 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42865136947500637		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.42865136947500637 | validation: 0.6773249988523392]
	TIME [epoch: 5.75 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37225232533026803		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.37225232533026803 | validation: 0.12346933533982295]
	TIME [epoch: 5.76 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14452506308793328		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.14452506308793328 | validation: 0.09790072367566932]
	TIME [epoch: 5.75 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10900995710898528		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.10900995710898528 | validation: 0.10400007186052385]
	TIME [epoch: 5.76 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15366827748604142		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.15366827748604142 | validation: 0.309875541489315]
	TIME [epoch: 5.79 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33865347725394934		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.33865347725394934 | validation: 0.24640338460387956]
	TIME [epoch: 5.77 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17123940666276716		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.17123940666276716 | validation: 0.10852272548582254]
	TIME [epoch: 5.73 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10933862773124713		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.10933862773124713 | validation: 0.09420880895792476]
	TIME [epoch: 5.74 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0905151845614846		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.0905151845614846 | validation: 0.06518932314522911]
	TIME [epoch: 5.74 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06564618122938669		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.06564618122938669 | validation: 0.08113746343463145]
	TIME [epoch: 5.76 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15124858768910113		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.15124858768910113 | validation: 0.07734868687025433]
	TIME [epoch: 5.76 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09741932442987021		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.09741932442987021 | validation: 0.12150285978807437]
	TIME [epoch: 5.78 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10962812192799824		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.10962812192799824 | validation: 0.09473863428206059]
	TIME [epoch: 5.76 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1022847405801315		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.1022847405801315 | validation: 0.05068437439813]
	TIME [epoch: 5.76 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1025182003216039		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.1025182003216039 | validation: 0.11232590529647186]
	TIME [epoch: 5.75 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09313103185399121		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.09313103185399121 | validation: 0.06626999864635376]
	TIME [epoch: 5.76 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08723604195612289		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.08723604195612289 | validation: 0.06590625323215443]
	TIME [epoch: 5.75 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08163959186391591		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.08163959186391591 | validation: 0.07024287639539371]
	TIME [epoch: 5.77 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10741830909521569		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.10741830909521569 | validation: 0.07831539293070555]
	TIME [epoch: 5.75 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07258854818065306		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.07258854818065306 | validation: 0.06915973439627796]
	TIME [epoch: 5.74 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06365916079071914		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.06365916079071914 | validation: 0.05571676003609987]
	TIME [epoch: 5.74 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09947281282769348		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.09947281282769348 | validation: 0.0992418694777816]
	TIME [epoch: 5.74 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09960364421776176		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.09960364421776176 | validation: 0.0702039258170597]
	TIME [epoch: 5.74 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07866535413100821		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.07866535413100821 | validation: 0.07444514588200452]
	TIME [epoch: 5.74 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09254576271535829		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.09254576271535829 | validation: 0.05617928519942748]
	TIME [epoch: 5.78 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05621659532050638		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.05621659532050638 | validation: 0.05401611130378574]
	TIME [epoch: 5.74 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06663959431572675		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.06663959431572675 | validation: 0.057934238630903856]
	TIME [epoch: 5.74 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13218198508123855		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.13218198508123855 | validation: 0.14381009467404313]
	TIME [epoch: 5.74 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1489299908481907		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.1489299908481907 | validation: 0.111460195991675]
	TIME [epoch: 5.74 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14918572269654784		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.14918572269654784 | validation: 0.07020219417614688]
	TIME [epoch: 5.74 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11877397763251837		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.11877397763251837 | validation: 0.1506861558433762]
	TIME [epoch: 5.77 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14742182266423023		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.14742182266423023 | validation: 0.1956389424070617]
	TIME [epoch: 5.74 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16826948849409398		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.16826948849409398 | validation: 0.1112990302577591]
	TIME [epoch: 5.74 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1117904027061053		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.1117904027061053 | validation: 0.08159631036658922]
	TIME [epoch: 5.73 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10581308904583435		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.10581308904583435 | validation: 0.08559654691640081]
	TIME [epoch: 5.74 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10909625087431213		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.10909625087431213 | validation: 0.07624832231225906]
	TIME [epoch: 5.74 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08960111529962624		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.08960111529962624 | validation: 0.06573545951679763]
	TIME [epoch: 5.74 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08221447168361723		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.08221447168361723 | validation: 0.057479439317697174]
	TIME [epoch: 5.78 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07294791533359732		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.07294791533359732 | validation: 0.12117970371600403]
	TIME [epoch: 5.74 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10835821520982308		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.10835821520982308 | validation: 0.06482747066598642]
	TIME [epoch: 5.74 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07605178355508067		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.07605178355508067 | validation: 0.08726172810946327]
	TIME [epoch: 5.76 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08323342407783159		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.08323342407783159 | validation: 0.05489450280963478]
	TIME [epoch: 5.76 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07633361647408188		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.07633361647408188 | validation: 0.0631606348989217]
	TIME [epoch: 5.74 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07839090104117695		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.07839090104117695 | validation: 0.040892653335682295]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_567.pth
	Model improved!!!
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06089650388259879		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.06089650388259879 | validation: 0.05897052515184802]
	TIME [epoch: 5.76 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059826609605785695		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.059826609605785695 | validation: 0.06281625509006838]
	TIME [epoch: 5.73 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08343703500767834		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.08343703500767834 | validation: 0.07657160588765727]
	TIME [epoch: 5.73 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08204497073346109		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.08204497073346109 | validation: 0.05052756334806945]
	TIME [epoch: 5.73 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07540594633972827		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.07540594633972827 | validation: 0.07139968278508409]
	TIME [epoch: 5.73 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08260564256158878		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.08260564256158878 | validation: 0.07099005356709116]
	TIME [epoch: 5.74 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07969857601880737		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.07969857601880737 | validation: 0.07628898033412769]
	TIME [epoch: 5.77 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10603749239339091		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.10603749239339091 | validation: 0.05102664427669591]
	TIME [epoch: 5.74 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10134139470457205		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.10134139470457205 | validation: 0.12956317168591283]
	TIME [epoch: 5.74 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17435985372425383		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.17435985372425383 | validation: 0.12570207884689935]
	TIME [epoch: 5.74 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12484498450536131		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.12484498450536131 | validation: 0.08682067032286049]
	TIME [epoch: 5.74 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12500390310892992		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.12500390310892992 | validation: 0.10246951727061258]
	TIME [epoch: 5.75 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10333851513726826		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.10333851513726826 | validation: 0.0863293458047474]
	TIME [epoch: 5.77 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09128693877733332		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.09128693877733332 | validation: 0.08580493894895737]
	TIME [epoch: 5.74 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08994649362728162		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.08994649362728162 | validation: 0.04755387259148614]
	TIME [epoch: 5.73 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06446932720917815		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.06446932720917815 | validation: 0.05023515992563025]
	TIME [epoch: 5.75 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0956730742292965		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.0956730742292965 | validation: 0.15307326908239918]
	TIME [epoch: 5.75 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14498150694913883		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.14498150694913883 | validation: 0.11436280549648985]
	TIME [epoch: 5.75 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09676704502560948		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.09676704502560948 | validation: 0.08083619186507747]
	TIME [epoch: 5.77 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10499888150986905		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.10499888150986905 | validation: 0.16345823698900686]
	TIME [epoch: 5.78 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1462944156239845		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.1462944156239845 | validation: 0.07389559710199166]
	TIME [epoch: 5.75 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08708588433345531		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.08708588433345531 | validation: 0.08043099025000287]
	TIME [epoch: 5.75 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06800357715838562		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.06800357715838562 | validation: 0.08141049763854252]
	TIME [epoch: 5.75 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1033402660850919		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.1033402660850919 | validation: 0.07122907860700757]
	TIME [epoch: 5.76 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.083398059112587		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.083398059112587 | validation: 0.0755667455327121]
	TIME [epoch: 5.75 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07392110410405983		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.07392110410405983 | validation: 0.07860830577221477]
	TIME [epoch: 5.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14919919336954435		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.14919919336954435 | validation: 0.19054896133198768]
	TIME [epoch: 5.76 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13361151101727758		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.13361151101727758 | validation: 0.10675734286700884]
	TIME [epoch: 5.75 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1344583169373712		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.1344583169373712 | validation: 0.1560592716306877]
	TIME [epoch: 5.75 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.145282383374771		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.145282383374771 | validation: 0.14507243939906533]
	TIME [epoch: 5.75 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09426734754576993		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.09426734754576993 | validation: 0.06099027028717988]
	TIME [epoch: 5.76 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0935041502759316		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.0935041502759316 | validation: 0.14878271683879915]
	TIME [epoch: 5.77 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0878289886311902		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.0878289886311902 | validation: 0.05780447320702381]
	TIME [epoch: 5.78 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10347710916729572		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.10347710916729572 | validation: 0.0957028170973925]
	TIME [epoch: 5.76 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07144224675883223		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.07144224675883223 | validation: 0.05638556317941974]
	TIME [epoch: 5.75 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05866325807555449		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.05866325807555449 | validation: 0.06409700429046866]
	TIME [epoch: 5.75 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08979629954264519		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.08979629954264519 | validation: 0.15148987682318735]
	TIME [epoch: 5.73 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1127829663342908		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.1127829663342908 | validation: 0.04985787215235538]
	TIME [epoch: 5.75 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12423686113667715		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.12423686113667715 | validation: 0.19978478412610517]
	TIME [epoch: 5.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14778317743815111		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.14778317743815111 | validation: 0.08225698104133371]
	TIME [epoch: 5.76 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08209109081009905		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.08209109081009905 | validation: 0.06160176301583782]
	TIME [epoch: 5.74 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06348761393802725		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.06348761393802725 | validation: 0.04333721781669968]
	TIME [epoch: 5.76 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061342773127245946		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.061342773127245946 | validation: 0.043656333240656625]
	TIME [epoch: 5.74 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0561460077676557		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.0561460077676557 | validation: 0.08020054602544507]
	TIME [epoch: 5.75 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09815349709023492		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.09815349709023492 | validation: 0.1460869283209467]
	TIME [epoch: 5.76 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14027598189640625		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.14027598189640625 | validation: 0.08824135281690948]
	TIME [epoch: 5.78 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09189598647358375		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.09189598647358375 | validation: 0.13240800438565756]
	TIME [epoch: 5.74 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10034192919621657		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.10034192919621657 | validation: 0.06905295763739364]
	TIME [epoch: 5.75 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0925871099557027		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.0925871099557027 | validation: 0.07100573714152623]
	TIME [epoch: 5.73 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08830816926925872		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.08830816926925872 | validation: 0.08062456914626802]
	TIME [epoch: 5.75 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06744468881351637		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.06744468881351637 | validation: 0.054559147756735954]
	TIME [epoch: 5.75 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07808208013449508		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.07808208013449508 | validation: 0.13986106685978153]
	TIME [epoch: 5.79 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1038017748184347		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.1038017748184347 | validation: 0.057080403592818525]
	TIME [epoch: 5.75 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057671484037230936		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.057671484037230936 | validation: 0.05354461015715899]
	TIME [epoch: 5.73 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06636727481827984		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.06636727481827984 | validation: 0.08157155275901573]
	TIME [epoch: 5.76 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07075431398357418		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.07075431398357418 | validation: 0.04274192399296132]
	TIME [epoch: 5.74 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0622605796816868		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.0622605796816868 | validation: 0.06591136811123074]
	TIME [epoch: 5.73 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07004595374600422		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.07004595374600422 | validation: 0.07520515321235768]
	TIME [epoch: 5.76 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08403481685120573		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.08403481685120573 | validation: 0.06849865967948475]
	TIME [epoch: 5.78 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07008639354153562		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.07008639354153562 | validation: 0.049584436586225904]
	TIME [epoch: 5.74 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0927266845298702		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.0927266845298702 | validation: 0.08989340176866666]
	TIME [epoch: 5.74 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09838418677289283		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.09838418677289283 | validation: 0.08522577063210783]
	TIME [epoch: 5.76 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08217221948664721		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.08217221948664721 | validation: 0.07795136907652289]
	TIME [epoch: 5.74 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08776091909580838		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.08776091909580838 | validation: 0.07683409073709607]
	TIME [epoch: 5.73 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0791214642477304		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.0791214642477304 | validation: 0.08008841171499025]
	TIME [epoch: 5.78 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0914161973638392		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.0914161973638392 | validation: 0.1006407396135381]
	TIME [epoch: 5.75 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07950065595468586		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.07950065595468586 | validation: 0.06575714270240438]
	TIME [epoch: 5.74 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07354869556527086		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.07354869556527086 | validation: 0.1502948483320599]
	TIME [epoch: 5.76 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12452491524468844		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.12452491524468844 | validation: 0.07711524951234767]
	TIME [epoch: 5.74 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07610954882322721		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.07610954882322721 | validation: 0.07543946550039454]
	TIME [epoch: 5.74 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08918822427008403		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.08918822427008403 | validation: 0.09377508175880085]
	TIME [epoch: 5.76 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08616173570172984		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.08616173570172984 | validation: 0.05964811900364166]
	TIME [epoch: 5.78 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06767274113243008		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.06767274113243008 | validation: 0.07862131661370547]
	TIME [epoch: 5.74 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06792952798224715		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.06792952798224715 | validation: 0.06114513792482896]
	TIME [epoch: 5.74 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05889191781717326		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.05889191781717326 | validation: 0.057227217470247844]
	TIME [epoch: 5.74 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05644176577383875		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.05644176577383875 | validation: 0.0633771451437186]
	TIME [epoch: 5.73 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062368892628020346		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.062368892628020346 | validation: 0.06802017918607814]
	TIME [epoch: 5.74 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0926105879453849		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.0926105879453849 | validation: 0.1270056892647483]
	TIME [epoch: 5.77 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12509736119016432		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.12509736119016432 | validation: 0.08409130498651216]
	TIME [epoch: 5.75 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08482979084739946		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.08482979084739946 | validation: 0.06387597588819065]
	TIME [epoch: 5.75 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07573271021424272		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.07573271021424272 | validation: 0.08915920981245648]
	TIME [epoch: 5.74 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08686057096106549		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.08686057096106549 | validation: 0.15217051171900253]
	TIME [epoch: 5.74 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09150212267898895		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.09150212267898895 | validation: 0.07426508674214297]
	TIME [epoch: 5.74 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07012705057397006		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.07012705057397006 | validation: 0.05359825261719916]
	TIME [epoch: 5.77 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06944235479196625		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.06944235479196625 | validation: 0.05953710312914904]
	TIME [epoch: 5.77 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0833996699254334		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.0833996699254334 | validation: 0.07416850122973216]
	TIME [epoch: 5.76 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07172328169576087		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.07172328169576087 | validation: 0.0809122084060845]
	TIME [epoch: 5.73 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08319761570362962		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.08319761570362962 | validation: 0.1037314990732358]
	TIME [epoch: 5.75 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11330750897530191		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.11330750897530191 | validation: 0.07980003043645667]
	TIME [epoch: 5.75 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0664941557801732		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.0664941557801732 | validation: 0.06237598884005266]
	TIME [epoch: 5.73 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07098664722436926		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.07098664722436926 | validation: 0.0761994092036223]
	TIME [epoch: 5.78 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07652531086460962		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.07652531086460962 | validation: 0.1420330561209007]
	TIME [epoch: 5.75 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1089310309620814		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.1089310309620814 | validation: 0.06574459837947391]
	TIME [epoch: 5.73 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09864636429866519		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.09864636429866519 | validation: 0.12047333995085709]
	TIME [epoch: 5.74 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487146052631657		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.1487146052631657 | validation: 0.15141127092781292]
	TIME [epoch: 5.76 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0992551068552798		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.0992551068552798 | validation: 0.05867301416441375]
	TIME [epoch: 5.74 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07936863369888858		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.07936863369888858 | validation: 0.07682410132139297]
	TIME [epoch: 5.77 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06752429847174923		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.06752429847174923 | validation: 0.0666833135140946]
	TIME [epoch: 5.75 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06397324004418736		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.06397324004418736 | validation: 0.0802467030814033]
	TIME [epoch: 5.74 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1180273846083339		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.1180273846083339 | validation: 0.15774142455782034]
	TIME [epoch: 5.75 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10965295570003253		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.10965295570003253 | validation: 0.03626362075838476]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_668.pth
	Model improved!!!
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05436265930461215		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.05436265930461215 | validation: 0.05073310381624986]
	TIME [epoch: 5.75 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0734163878366621		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.0734163878366621 | validation: 0.06209518576649118]
	TIME [epoch: 5.75 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08351953939192319		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.08351953939192319 | validation: 0.10430128767877334]
	TIME [epoch: 5.78 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09191109332090458		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.09191109332090458 | validation: 0.06711298402402154]
	TIME [epoch: 5.75 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060904265937244975		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.060904265937244975 | validation: 0.042483195391025956]
	TIME [epoch: 5.74 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047394458822572545		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.047394458822572545 | validation: 0.06812186082273837]
	TIME [epoch: 5.75 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12164667654520633		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.12164667654520633 | validation: 0.06304682396352854]
	TIME [epoch: 5.74 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06311151330159812		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.06311151330159812 | validation: 0.09426891272757519]
	TIME [epoch: 5.73 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07324071400860654		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.07324071400860654 | validation: 0.03328924173736686]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_677.pth
	Model improved!!!
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04280293626636099		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.04280293626636099 | validation: 0.04006231181117182]
	TIME [epoch: 5.77 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05200146766785349		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.05200146766785349 | validation: 0.039254152394831966]
	TIME [epoch: 5.75 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06662745709555529		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.06662745709555529 | validation: 0.11878426387493524]
	TIME [epoch: 5.73 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09865571148053977		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.09865571148053977 | validation: 0.0778755646115774]
	TIME [epoch: 5.74 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06259673735938051		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.06259673735938051 | validation: 0.04794136942079411]
	TIME [epoch: 5.73 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07810263846480978		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.07810263846480978 | validation: 0.0845035457398485]
	TIME [epoch: 5.74 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09453624377542927		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.09453624377542927 | validation: 0.10610186602028314]
	TIME [epoch: 5.78 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07939243141699864		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.07939243141699864 | validation: 0.0522342587000752]
	TIME [epoch: 5.74 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057026691459392154		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.057026691459392154 | validation: 0.0952098395730539]
	TIME [epoch: 5.75 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11584392348293245		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.11584392348293245 | validation: 0.09047360466937261]
	TIME [epoch: 5.73 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06669112644779127		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.06669112644779127 | validation: 0.06623114636534355]
	TIME [epoch: 5.73 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06475713053558872		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.06475713053558872 | validation: 0.06802646603486888]
	TIME [epoch: 5.74 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052390993649595374		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.052390993649595374 | validation: 0.06764990087898826]
	TIME [epoch: 5.79 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06535440383064778		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.06535440383064778 | validation: 0.05316189007199755]
	TIME [epoch: 5.75 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06343473888400669		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.06343473888400669 | validation: 0.0641175353478742]
	TIME [epoch: 5.75 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08390138379017362		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.08390138379017362 | validation: 0.04112957664270647]
	TIME [epoch: 5.75 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05049166625762826		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.05049166625762826 | validation: 0.057016805804576264]
	TIME [epoch: 5.76 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052621024554320404		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.052621024554320404 | validation: 0.030131973470389595]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_695.pth
	Model improved!!!
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04741264406548147		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.04741264406548147 | validation: 0.0382868682641308]
	TIME [epoch: 5.75 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04875319809490813		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.04875319809490813 | validation: 0.03759876010214888]
	TIME [epoch: 5.77 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05588650053180717		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.05588650053180717 | validation: 0.0405356619592102]
	TIME [epoch: 5.75 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05782918946938464		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.05782918946938464 | validation: 0.060365173799457106]
	TIME [epoch: 5.74 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062060806957170735		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.062060806957170735 | validation: 0.0454053304246033]
	TIME [epoch: 5.75 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0428340981609662		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.0428340981609662 | validation: 0.043349282291405764]
	TIME [epoch: 5.74 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055555122626239024		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.055555122626239024 | validation: 0.059199040146168065]
	TIME [epoch: 5.74 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07369352379439427		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.07369352379439427 | validation: 0.1334496143710723]
	TIME [epoch: 5.78 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11838618727694865		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.11838618727694865 | validation: 0.06138907102756463]
	TIME [epoch: 5.75 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07032400591214202		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.07032400591214202 | validation: 0.04713986792725294]
	TIME [epoch: 5.75 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0639372718307937		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.0639372718307937 | validation: 0.06704604372110229]
	TIME [epoch: 5.75 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05591308090977394		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.05591308090977394 | validation: 0.051727026960375115]
	TIME [epoch: 5.74 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06688829906640248		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.06688829906640248 | validation: 0.11039555817242853]
	TIME [epoch: 5.75 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09926350894285169		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.09926350894285169 | validation: 0.06671774738443668]
	TIME [epoch: 5.76 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05260596538269248		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.05260596538269248 | validation: 0.06922869584158484]
	TIME [epoch: 5.79 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06479200384274753		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.06479200384274753 | validation: 0.05384343200333748]
	TIME [epoch: 5.75 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04680183836755328		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.04680183836755328 | validation: 0.06267686021629111]
	TIME [epoch: 5.74 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06353003551267468		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.06353003551267468 | validation: 0.05806505871539302]
	TIME [epoch: 5.75 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05157523042843718		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.05157523042843718 | validation: 0.04655063580282635]
	TIME [epoch: 5.74 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053559220930401656		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.053559220930401656 | validation: 0.043612443212097216]
	TIME [epoch: 5.74 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05106502512977178		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.05106502512977178 | validation: 0.06067138312579218]
	TIME [epoch: 5.78 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06421946040863433		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.06421946040863433 | validation: 0.07721100393216836]
	TIME [epoch: 5.75 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10035295330228369		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.10035295330228369 | validation: 0.07540335898065893]
	TIME [epoch: 5.74 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06045381643458141		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.06045381643458141 | validation: 0.047429727333103654]
	TIME [epoch: 5.74 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05469846516878512		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.05469846516878512 | validation: 0.06012383614424243]
	TIME [epoch: 5.75 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04752180294455196		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.04752180294455196 | validation: 0.03282413885273715]
	TIME [epoch: 5.74 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0412930107925617		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.0412930107925617 | validation: 0.030204337846051806]
	TIME [epoch: 5.76 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0708339851903895		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.0708339851903895 | validation: 0.10650835157107072]
	TIME [epoch: 5.77 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0865048847772057		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.0865048847772057 | validation: 0.04212118955646625]
	TIME [epoch: 5.74 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04843527004044748		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.04843527004044748 | validation: 0.03756107175428517]
	TIME [epoch: 5.74 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04592054661194719		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.04592054661194719 | validation: 0.05205245039441275]
	TIME [epoch: 5.74 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07792679375264858		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.07792679375264858 | validation: 0.0856489187403688]
	TIME [epoch: 5.74 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08432984841954078		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.08432984841954078 | validation: 0.09187986901531028]
	TIME [epoch: 5.75 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10706410600262158		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.10706410600262158 | validation: 0.08899459502802866]
	TIME [epoch: 5.78 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08707028256429135		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.08707028256429135 | validation: 0.052676977064653435]
	TIME [epoch: 5.75 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07302725368347282		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.07302725368347282 | validation: 0.07665079563817924]
	TIME [epoch: 5.74 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0765604639401092		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.0765604639401092 | validation: 0.058248214974906086]
	TIME [epoch: 5.74 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06515062770430904		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.06515062770430904 | validation: 0.051803877494479254]
	TIME [epoch: 5.75 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08533060476566603		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.08533060476566603 | validation: 0.04696644820696989]
	TIME [epoch: 5.74 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04989080807622867		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.04989080807622867 | validation: 0.04659188459759893]
	TIME [epoch: 5.77 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042675190890618525		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.042675190890618525 | validation: 0.0440915999555132]
	TIME [epoch: 5.75 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05099635957601947		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.05099635957601947 | validation: 0.0830005947894821]
	TIME [epoch: 5.75 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08540861936404429		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.08540861936404429 | validation: 0.04136598874876482]
	TIME [epoch: 5.74 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0401476810066983		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.0401476810066983 | validation: 0.04917027495990338]
	TIME [epoch: 5.74 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04397115505982861		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.04397115505982861 | validation: 0.02894493303199033]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_740.pth
	Model improved!!!
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037247583287442716		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.037247583287442716 | validation: 0.04221120378002295]
	TIME [epoch: 5.74 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04800050783899426		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.04800050783899426 | validation: 0.04865583909406704]
	TIME [epoch: 5.77 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04251490865524282		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.04251490865524282 | validation: 0.0346308107933762]
	TIME [epoch: 5.74 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03834409283266392		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.03834409283266392 | validation: 0.040278359204464716]
	TIME [epoch: 5.74 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04546773521133085		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.04546773521133085 | validation: 0.032320912159344656]
	TIME [epoch: 5.74 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041893668301228974		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.041893668301228974 | validation: 0.05312734310064014]
	TIME [epoch: 5.74 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04720268943080607		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.04720268943080607 | validation: 0.04379972729072809]
	TIME [epoch: 5.73 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04597427739611774		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.04597427739611774 | validation: 0.04706309587194724]
	TIME [epoch: 5.76 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05172426863392518		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.05172426863392518 | validation: 0.037928947062198314]
	TIME [epoch: 5.75 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04853618488856783		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.04853618488856783 | validation: 0.041888125311290304]
	TIME [epoch: 5.74 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044065272519869816		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.044065272519869816 | validation: 0.0351480689447944]
	TIME [epoch: 5.73 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04194832761144458		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.04194832761144458 | validation: 0.061334208958017576]
	TIME [epoch: 5.74 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03949226270084766		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.03949226270084766 | validation: 0.0315069673919896]
	TIME [epoch: 5.74 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05953910528343691		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.05953910528343691 | validation: 0.058059521125580514]
	TIME [epoch: 5.74 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0558863501813241		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.0558863501813241 | validation: 0.05436001939070348]
	TIME [epoch: 5.78 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0828577432390053		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.0828577432390053 | validation: 0.06636197696376998]
	TIME [epoch: 5.75 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06581775038843116		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.06581775038843116 | validation: 0.05549898792702811]
	TIME [epoch: 5.73 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05184857324460748		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.05184857324460748 | validation: 0.041730866710915866]
	TIME [epoch: 5.73 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042787178874600394		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.042787178874600394 | validation: 0.04565521681402137]
	TIME [epoch: 5.73 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05230668879243156		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.05230668879243156 | validation: 0.041064751942398926]
	TIME [epoch: 5.74 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06237889053953624		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.06237889053953624 | validation: 0.05968732333736276]
	TIME [epoch: 5.77 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0444172583924721		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.0444172583924721 | validation: 0.03895974173303242]
	TIME [epoch: 5.75 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04496024456891924		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.04496024456891924 | validation: 0.061267213561934215]
	TIME [epoch: 5.74 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0516505832313778		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.0516505832313778 | validation: 0.045244973611103405]
	TIME [epoch: 5.74 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05223804101620832		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.05223804101620832 | validation: 0.04265232322960905]
	TIME [epoch: 5.73 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05137789229311601		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.05137789229311601 | validation: 0.04345066378344677]
	TIME [epoch: 5.74 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06134013179961763		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.06134013179961763 | validation: 0.044176893458909475]
	TIME [epoch: 5.74 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06702106195603912		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.06702106195603912 | validation: 0.0745018290023635]
	TIME [epoch: 5.78 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05999441438474187		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.05999441438474187 | validation: 0.05994998953769759]
	TIME [epoch: 5.75 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07501022848359648		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.07501022848359648 | validation: 0.09457167110954258]
	TIME [epoch: 5.74 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06017276035537059		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.06017276035537059 | validation: 0.03723290883231779]
	TIME [epoch: 5.74 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06201877828783185		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.06201877828783185 | validation: 0.047616690143849824]
	TIME [epoch: 5.75 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06151231655706555		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.06151231655706555 | validation: 0.04704716186379689]
	TIME [epoch: 5.73 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048288619918660736		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.048288619918660736 | validation: 0.06939249934016212]
	TIME [epoch: 5.76 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054311609408335626		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.054311609408335626 | validation: 0.05143775732660529]
	TIME [epoch: 5.75 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03578571173446597		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.03578571173446597 | validation: 0.03663945915643422]
	TIME [epoch: 5.74 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038341597450009195		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.038341597450009195 | validation: 0.04088082709651138]
	TIME [epoch: 5.74 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04190435147166714		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.04190435147166714 | validation: 0.03565496568363184]
	TIME [epoch: 5.74 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038513732433929686		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.038513732433929686 | validation: 0.03836830584828057]
	TIME [epoch: 5.74 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04966148014469662		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.04966148014469662 | validation: 0.04057097338869329]
	TIME [epoch: 5.74 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04147002196063398		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.04147002196063398 | validation: 0.034597480358198415]
	TIME [epoch: 5.78 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03365881608348493		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.03365881608348493 | validation: 0.027481894217976297]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_782.pth
	Model improved!!!
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0335146230822522		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.0335146230822522 | validation: 0.04508158202009625]
	TIME [epoch: 5.74 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049481606055995664		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.049481606055995664 | validation: 0.07716462474344489]
	TIME [epoch: 5.74 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057150475460149654		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.057150475460149654 | validation: 0.0325565365493533]
	TIME [epoch: 5.74 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055013095432452544		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.055013095432452544 | validation: 0.044753450411846314]
	TIME [epoch: 5.74 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042275378116070614		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.042275378116070614 | validation: 0.029180467782788946]
	TIME [epoch: 5.78 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0442588848026818		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.0442588848026818 | validation: 0.05314960827084848]
	TIME [epoch: 5.74 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05306736252429188		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.05306736252429188 | validation: 0.05584534153064717]
	TIME [epoch: 5.74 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05122660286988984		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.05122660286988984 | validation: 0.041244375888487214]
	TIME [epoch: 5.74 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06813049961244905		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.06813049961244905 | validation: 0.07679416664964273]
	TIME [epoch: 5.73 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061751185594572384		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.061751185594572384 | validation: 0.03224198525770351]
	TIME [epoch: 5.73 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043014181749042854		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.043014181749042854 | validation: 0.04829291186524988]
	TIME [epoch: 5.75 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05207527481313441		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.05207527481313441 | validation: 0.0365771787604632]
	TIME [epoch: 5.76 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05112830555944857		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.05112830555944857 | validation: 0.03337315026131892]
	TIME [epoch: 5.75 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039396698115192585		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.039396698115192585 | validation: 0.05020039905586716]
	TIME [epoch: 5.75 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04807806007544377		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.04807806007544377 | validation: 0.045123443901580185]
	TIME [epoch: 5.74 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055605103711978555		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.055605103711978555 | validation: 0.03402583239913918]
	TIME [epoch: 5.74 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037598129785171006		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.037598129785171006 | validation: 0.0444785516505496]
	TIME [epoch: 5.74 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046450451693431344		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.046450451693431344 | validation: 0.0664404241109152]
	TIME [epoch: 5.78 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05605275029871931		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.05605275029871931 | validation: 0.021996508377048172]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_801.pth
	Model improved!!!
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041904978513155555		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.041904978513155555 | validation: 0.04253036323156947]
	TIME [epoch: 5.73 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05253323230652364		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.05253323230652364 | validation: 0.04432876508846743]
	TIME [epoch: 5.74 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06620399260402596		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.06620399260402596 | validation: 0.05498721679159997]
	TIME [epoch: 5.75 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05271174289528615		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.05271174289528615 | validation: 0.04565037465590271]
	TIME [epoch: 5.74 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04486258759636015		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.04486258759636015 | validation: 0.03941086612556711]
	TIME [epoch: 5.76 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04449595133993209		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.04449595133993209 | validation: 0.040936150300808105]
	TIME [epoch: 5.78 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041347840541343314		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.041347840541343314 | validation: 0.039454954033232896]
	TIME [epoch: 5.74 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03689774290239449		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.03689774290239449 | validation: 0.028944533525738208]
	TIME [epoch: 5.73 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04271165296950119		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.04271165296950119 | validation: 0.04314642938696748]
	TIME [epoch: 5.75 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055161107787757124		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.055161107787757124 | validation: 0.07970528328994765]
	TIME [epoch: 5.74 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07008997165185653		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.07008997165185653 | validation: 0.04805615408068541]
	TIME [epoch: 5.75 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040842730686304986		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.040842730686304986 | validation: 0.04014875975337606]
	TIME [epoch: 5.78 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0478722502438121		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.0478722502438121 | validation: 0.05498482325577925]
	TIME [epoch: 5.75 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06953665567093878		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.06953665567093878 | validation: 0.08210889726704157]
	TIME [epoch: 5.74 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07838416642423032		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.07838416642423032 | validation: 0.060110056970976766]
	TIME [epoch: 5.73 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058323068017647764		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.058323068017647764 | validation: 0.06380287163311696]
	TIME [epoch: 5.73 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052485071234857336		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.052485071234857336 | validation: 0.04714493622027671]
	TIME [epoch: 5.74 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05705658514130556		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.05705658514130556 | validation: 0.06720171501565085]
	TIME [epoch: 5.76 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06922958985962017		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.06922958985962017 | validation: 0.0665146583198]
	TIME [epoch: 5.77 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05141787721466211		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.05141787721466211 | validation: 0.03870692929654648]
	TIME [epoch: 5.75 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051347569596155565		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.051347569596155565 | validation: 0.04214009298130621]
	TIME [epoch: 5.75 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058393465671896724		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.058393465671896724 | validation: 0.07335504019612858]
	TIME [epoch: 5.75 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061722146335893985		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.061722146335893985 | validation: 0.062329850475818425]
	TIME [epoch: 5.74 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07122331458919776		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.07122331458919776 | validation: 0.052161408582344165]
	TIME [epoch: 5.74 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0811477388646109		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.0811477388646109 | validation: 0.0615859565139198]
	TIME [epoch: 5.78 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06110354152029467		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.06110354152029467 | validation: 0.04078036375972234]
	TIME [epoch: 5.75 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035317891283130946		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.035317891283130946 | validation: 0.03734442548941384]
	TIME [epoch: 5.74 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03907932390977756		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.03907932390977756 | validation: 0.03416571752572232]
	TIME [epoch: 5.74 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035957531240880296		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.035957531240880296 | validation: 0.040553629526910426]
	TIME [epoch: 5.75 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03718272791742964		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.03718272791742964 | validation: 0.04117937162336615]
	TIME [epoch: 5.74 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03459957168445383		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.03459957168445383 | validation: 0.026962209275114325]
	TIME [epoch: 5.77 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038681732069558966		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.038681732069558966 | validation: 0.03445769610628139]
	TIME [epoch: 5.77 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050405390875318166		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.050405390875318166 | validation: 0.07145492789801314]
	TIME [epoch: 5.74 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10042140215936449		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.10042140215936449 | validation: 0.09731674435363402]
	TIME [epoch: 5.73 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1078721485301171		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.1078721485301171 | validation: 0.048473034311372204]
	TIME [epoch: 5.74 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07372499255134221		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.07372499255134221 | validation: 0.043105021571862315]
	TIME [epoch: 5.74 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04532342836699852		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.04532342836699852 | validation: 0.036943151407714245]
	TIME [epoch: 5.74 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039486020224079994		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.039486020224079994 | validation: 0.03506578952959956]
	TIME [epoch: 5.79 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03895155573612604		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.03895155573612604 | validation: 0.036358672631648256]
	TIME [epoch: 5.75 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04569414824983281		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.04569414824983281 | validation: 0.044207412874739324]
	TIME [epoch: 5.74 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03864431708973472		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.03864431708973472 | validation: 0.03139972568928434]
	TIME [epoch: 5.75 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03881699758053352		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.03881699758053352 | validation: 0.029962879014899864]
	TIME [epoch: 5.73 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035663724856470146		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.035663724856470146 | validation: 0.05025460555435922]
	TIME [epoch: 5.75 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07595196580204744		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.07595196580204744 | validation: 0.09266135478979581]
	TIME [epoch: 5.77 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09244322894390869		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.09244322894390869 | validation: 0.09012519037164136]
	TIME [epoch: 5.76 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058678056558172854		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.058678056558172854 | validation: 0.040557560607782185]
	TIME [epoch: 5.74 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04576917305612994		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.04576917305612994 | validation: 0.03317444826016421]
	TIME [epoch: 5.74 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03607270142262405		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.03607270142262405 | validation: 0.03764031989247857]
	TIME [epoch: 5.75 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036345064692752935		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.036345064692752935 | validation: 0.025889049304292654]
	TIME [epoch: 5.74 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045021081699574084		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.045021081699574084 | validation: 0.0635205813710901]
	TIME [epoch: 5.74 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05184514635955344		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.05184514635955344 | validation: 0.03861621482511803]
	TIME [epoch: 5.78 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03213144077070047		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.03213144077070047 | validation: 0.031168795422553075]
	TIME [epoch: 5.75 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04938437636133626		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.04938437636133626 | validation: 0.05507970289480884]
	TIME [epoch: 5.76 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039298477267454814		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.039298477267454814 | validation: 0.028967974189973395]
	TIME [epoch: 5.75 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033975985969187314		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.033975985969187314 | validation: 0.04580938936164197]
	TIME [epoch: 5.74 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0402298661963427		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.0402298661963427 | validation: 0.045087781650518334]
	TIME [epoch: 5.73 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03985766930876777		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.03985766930876777 | validation: 0.03657369830204873]
	TIME [epoch: 5.78 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029620779085059036		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.029620779085059036 | validation: 0.03325948361510408]
	TIME [epoch: 5.75 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03916681658784543		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.03916681658784543 | validation: 0.03685500312285711]
	TIME [epoch: 5.76 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03867222355756056		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.03867222355756056 | validation: 0.03651040121930585]
	TIME [epoch: 5.75 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03398746302429313		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.03398746302429313 | validation: 0.02298131268422272]
	TIME [epoch: 5.75 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030780367590723424		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.030780367590723424 | validation: 0.03361922776694536]
	TIME [epoch: 5.75 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03817099503166385		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.03817099503166385 | validation: 0.03718422144300284]
	TIME [epoch: 5.75 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039399305413013945		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.039399305413013945 | validation: 0.026501597778567067]
	TIME [epoch: 5.78 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03961782927894994		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.03961782927894994 | validation: 0.03436186873520491]
	TIME [epoch: 5.75 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03520068975760377		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.03520068975760377 | validation: 0.037268372612618984]
	TIME [epoch: 5.74 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0327343145727027		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.0327343145727027 | validation: 0.03245921420653889]
	TIME [epoch: 5.74 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04241059186575826		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.04241059186575826 | validation: 0.031588590716673005]
	TIME [epoch: 5.74 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036251371752851834		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.036251371752851834 | validation: 0.019357710942409786]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_870.pth
	Model improved!!!
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028053107582855445		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.028053107582855445 | validation: 0.0291598521517908]
	TIME [epoch: 5.77 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046174330507466305		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.046174330507466305 | validation: 0.04055983794565288]
	TIME [epoch: 5.77 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03716319564939163		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.03716319564939163 | validation: 0.019141069226425417]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_873.pth
	Model improved!!!
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027888644459201764		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.027888644459201764 | validation: 0.029066904050797832]
	TIME [epoch: 5.74 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02953761571032773		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.02953761571032773 | validation: 0.026464908651029684]
	TIME [epoch: 5.75 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03609738147861885		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.03609738147861885 | validation: 0.03557111723437461]
	TIME [epoch: 5.75 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03611186366332708		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.03611186366332708 | validation: 0.025392897141089492]
	TIME [epoch: 5.77 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03077089921588009		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.03077089921588009 | validation: 0.04101150273954094]
	TIME [epoch: 5.78 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0321891239585893		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.0321891239585893 | validation: 0.02415375075175898]
	TIME [epoch: 5.75 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030564111855055635		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.030564111855055635 | validation: 0.032405005970986334]
	TIME [epoch: 5.74 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03573525449463788		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.03573525449463788 | validation: 0.0374835129686144]
	TIME [epoch: 5.73 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05238862081897411		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.05238862081897411 | validation: 0.08298657011008316]
	TIME [epoch: 5.75 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08273895162657972		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.08273895162657972 | validation: 0.04512488592289986]
	TIME [epoch: 5.75 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03341729244767179		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.03341729244767179 | validation: 0.03754812344499828]
	TIME [epoch: 5.79 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036497464553552204		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.036497464553552204 | validation: 0.050610357136894095]
	TIME [epoch: 5.74 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054297378384372506		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.054297378384372506 | validation: 0.042595870880375655]
	TIME [epoch: 5.75 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04132310753828019		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.04132310753828019 | validation: 0.02178823410495407]
	TIME [epoch: 5.74 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03413249881014187		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.03413249881014187 | validation: 0.028532147757062126]
	TIME [epoch: 5.75 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04534751366220874		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.04534751366220874 | validation: 0.03683434009700446]
	TIME [epoch: 5.75 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04467417193865928		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.04467417193865928 | validation: 0.032282511352408]
	TIME [epoch: 5.76 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041974371815264595		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.041974371815264595 | validation: 0.02706636580454001]
	TIME [epoch: 5.76 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03804794925817581		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.03804794925817581 | validation: 0.027849729029564382]
	TIME [epoch: 5.74 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028672792493428065		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.028672792493428065 | validation: 0.02672064814904135]
	TIME [epoch: 5.74 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029162337755947336		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.029162337755947336 | validation: 0.03228822609396351]
	TIME [epoch: 5.73 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029552498145497208		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.029552498145497208 | validation: 0.029230907145100186]
	TIME [epoch: 5.73 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029302875860754838		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.029302875860754838 | validation: 0.022220895229454692]
	TIME [epoch: 5.74 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03539198052300093		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.03539198052300093 | validation: 0.034058904290421424]
	TIME [epoch: 5.77 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04007964732919231		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.04007964732919231 | validation: 0.04682094508835372]
	TIME [epoch: 5.73 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04352210955445384		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.04352210955445384 | validation: 0.03612477780482378]
	TIME [epoch: 5.73 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035106491248952286		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.035106491248952286 | validation: 0.0355910268514576]
	TIME [epoch: 5.73 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029640246823252878		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.029640246823252878 | validation: 0.03167816474276006]
	TIME [epoch: 5.73 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03405711001853631		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.03405711001853631 | validation: 0.041022811676686775]
	TIME [epoch: 5.75 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043661808161560636		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.043661808161560636 | validation: 0.04308679544538153]
	TIME [epoch: 5.75 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04104201363372626		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.04104201363372626 | validation: 0.03587174158803748]
	TIME [epoch: 5.78 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03687928724237536		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.03687928724237536 | validation: 0.04544573469865469]
	TIME [epoch: 5.73 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03231867753519349		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.03231867753519349 | validation: 0.026533193516479682]
	TIME [epoch: 5.73 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02920837543985571		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.02920837543985571 | validation: 0.028387426175047106]
	TIME [epoch: 5.74 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034675750761852815		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.034675750761852815 | validation: 0.050511658537881525]
	TIME [epoch: 5.75 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04072628137122056		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.04072628137122056 | validation: 0.03140509433238456]
	TIME [epoch: 5.73 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03597053948157102		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.03597053948157102 | validation: 0.03533388654240876]
	TIME [epoch: 5.77 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037587461327675056		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.037587461327675056 | validation: 0.027109374102486525]
	TIME [epoch: 5.73 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02870311954384427		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.02870311954384427 | validation: 0.03020876628905567]
	TIME [epoch: 5.73 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030937123859291822		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.030937123859291822 | validation: 0.028367553415952318]
	TIME [epoch: 5.73 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046018948292257944		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.046018948292257944 | validation: 0.054564494108533756]
	TIME [epoch: 5.75 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04080717943908717		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.04080717943908717 | validation: 0.05014550950376817]
	TIME [epoch: 5.76 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03501789077021192		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.03501789077021192 | validation: 0.035696119287730255]
	TIME [epoch: 5.77 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03090582595932255		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.03090582595932255 | validation: 0.033390536710921306]
	TIME [epoch: 5.78 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03313514028794055		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.03313514028794055 | validation: 0.027513585822125864]
	TIME [epoch: 5.76 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04341851983291358		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.04341851983291358 | validation: 0.04244592580540196]
	TIME [epoch: 5.75 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07120213473912083		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.07120213473912083 | validation: 0.04771571106019511]
	TIME [epoch: 5.73 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04101749645563941		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.04101749645563941 | validation: 0.026881675810058167]
	TIME [epoch: 5.73 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0299215136061105		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.0299215136061105 | validation: 0.03247378706702067]
	TIME [epoch: 5.73 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03089024191990509		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.03089024191990509 | validation: 0.02513864791147462]
	TIME [epoch: 5.78 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03261377233234291		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.03261377233234291 | validation: 0.020375170186745492]
	TIME [epoch: 5.74 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03135993788048895		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.03135993788048895 | validation: 0.03270879912107753]
	TIME [epoch: 5.73 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03438326572266395		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.03438326572266395 | validation: 0.02438274597644498]
	TIME [epoch: 5.73 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0294508332698864		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.0294508332698864 | validation: 0.029517655440645024]
	TIME [epoch: 5.73 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03154586229116314		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.03154586229116314 | validation: 0.028674139616387727]
	TIME [epoch: 5.74 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03790525245040413		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.03790525245040413 | validation: 0.04378585916048014]
	TIME [epoch: 5.74 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0451517799054439		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.0451517799054439 | validation: 0.03597557614056371]
	TIME [epoch: 5.78 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04794412626263925		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.04794412626263925 | validation: 0.03673926200806364]
	TIME [epoch: 5.75 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04142152807840621		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.04142152807840621 | validation: 0.052902484142650225]
	TIME [epoch: 5.76 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049301730384187475		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.049301730384187475 | validation: 0.043193465682918035]
	TIME [epoch: 5.75 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03926331007038706		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.03926331007038706 | validation: 0.03758521079020011]
	TIME [epoch: 5.75 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03946902838008001		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.03946902838008001 | validation: 0.05354744225543385]
	TIME [epoch: 5.75 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0458913624923612		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.0458913624923612 | validation: 0.04780141550471827]
	TIME [epoch: 5.79 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05396484999841916		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.05396484999841916 | validation: 0.054963589139075446]
	TIME [epoch: 5.75 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051467863604868054		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.051467863604868054 | validation: 0.03594861315004626]
	TIME [epoch: 5.75 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041177840523987916		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.041177840523987916 | validation: 0.027833969064468528]
	TIME [epoch: 5.73 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03175263262900217		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.03175263262900217 | validation: 0.035342073299047996]
	TIME [epoch: 5.75 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03525195787079401		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.03525195787079401 | validation: 0.04163308801676133]
	TIME [epoch: 5.75 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04464469425176229		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.04464469425176229 | validation: 0.03420004371815414]
	TIME [epoch: 5.76 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03233364968156829		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.03233364968156829 | validation: 0.026614174039094003]
	TIME [epoch: 5.78 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03345313544671463		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.03345313544671463 | validation: 0.04364474147199836]
	TIME [epoch: 5.75 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0435373274648236		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.0435373274648236 | validation: 0.05648618700366547]
	TIME [epoch: 5.73 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05331681465517082		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.05331681465517082 | validation: 0.06162705033506477]
	TIME [epoch: 5.75 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06726283537637044		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.06726283537637044 | validation: 0.05999784423939516]
	TIME [epoch: 5.74 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06580071973018296		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.06580071973018296 | validation: 0.043388629218173734]
	TIME [epoch: 5.75 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034910879520792075		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.034910879520792075 | validation: 0.03160143834729845]
	TIME [epoch: 5.78 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030754963822663482		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.030754963822663482 | validation: 0.0319179214242728]
	TIME [epoch: 5.76 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04337194567868836		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.04337194567868836 | validation: 0.03071484256769603]
	TIME [epoch: 5.74 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034315186502683746		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.034315186502683746 | validation: 0.03479707999682862]
	TIME [epoch: 5.73 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029689611924573547		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.029689611924573547 | validation: 0.03203526941955532]
	TIME [epoch: 5.74 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0331222523705818		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.0331222523705818 | validation: 0.04151870250446482]
	TIME [epoch: 5.73 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03161396273868887		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.03161396273868887 | validation: 0.03316721075040202]
	TIME [epoch: 5.74 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03168822197082394		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.03168822197082394 | validation: 0.03588167650279686]
	TIME [epoch: 5.77 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04378510691002781		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.04378510691002781 | validation: 0.055053018560726946]
	TIME [epoch: 5.73 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050157949400444324		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.050157949400444324 | validation: 0.05222708098493306]
	TIME [epoch: 5.74 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06577001021630653		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.06577001021630653 | validation: 0.05660071119997696]
	TIME [epoch: 5.73 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05401450530608709		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.05401450530608709 | validation: 0.044059479378924425]
	TIME [epoch: 5.75 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04041285123948106		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.04041285123948106 | validation: 0.04742887631147182]
	TIME [epoch: 5.74 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038700661580780525		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.038700661580780525 | validation: 0.03926524259606239]
	TIME [epoch: 5.78 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02780865126684739		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.02780865126684739 | validation: 0.02606885886677794]
	TIME [epoch: 5.76 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031230481655963115		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.031230481655963115 | validation: 0.030536506044370144]
	TIME [epoch: 5.74 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028093161143014606		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.028093161143014606 | validation: 0.03186170386191612]
	TIME [epoch: 5.73 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03471015808580048		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.03471015808580048 | validation: 0.03374669774082048]
	TIME [epoch: 5.73 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04954124621810724		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.04954124621810724 | validation: 0.052030622659077465]
	TIME [epoch: 5.75 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040822430333229937		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.040822430333229937 | validation: 0.03518494511048446]
	TIME [epoch: 5.78 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03755814031218756		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.03755814031218756 | validation: 0.035159855174993225]
	TIME [epoch: 5.77 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03178207717175779		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.03178207717175779 | validation: 0.03340037900544018]
	TIME [epoch: 5.75 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03702413863952785		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.03702413863952785 | validation: 0.033641286774678536]
	TIME [epoch: 5.75 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039416136050849655		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.039416136050849655 | validation: 0.02925676274506939]
	TIME [epoch: 5.75 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033488803542104956		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.033488803542104956 | validation: 0.03045071564664089]
	TIME [epoch: 5.75 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03373687134910891		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.03373687134910891 | validation: 0.02405297125613549]
	TIME [epoch: 5.73 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032832207283674315		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.032832207283674315 | validation: 0.0374490213980494]
	TIME [epoch: 5.79 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03470506595890475		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.03470506595890475 | validation: 0.03336155507955203]
	TIME [epoch: 5.75 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03048742090307932		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.03048742090307932 | validation: 0.022953449879320083]
	TIME [epoch: 5.75 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031395021789912096		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.031395021789912096 | validation: 0.028446086710546034]
	TIME [epoch: 5.74 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024575693547952443		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.024575693547952443 | validation: 0.02260538275856123]
	TIME [epoch: 5.75 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035821471284202294		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.035821471284202294 | validation: 0.030678105275654535]
	TIME [epoch: 5.75 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042522168048150795		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.042522168048150795 | validation: 0.02026462715851791]
	TIME [epoch: 5.79 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031279862561942685		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.031279862561942685 | validation: 0.015185391873559483]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_982.pth
	Model improved!!!
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02863131629224728		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.02863131629224728 | validation: 0.018547136957937613]
	TIME [epoch: 5.75 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03410369286857599		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.03410369286857599 | validation: 0.023834644423524065]
	TIME [epoch: 5.75 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03310965310532569		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.03310965310532569 | validation: 0.021919799275633065]
	TIME [epoch: 5.74 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031441811423379734		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.031441811423379734 | validation: 0.02548153500581222]
	TIME [epoch: 5.75 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02503590488554816		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.02503590488554816 | validation: 0.028819248998668962]
	TIME [epoch: 5.75 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028709841866462277		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.028709841866462277 | validation: 0.03522022270392736]
	TIME [epoch: 5.8 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04252498937701327		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.04252498937701327 | validation: 0.04964521842960256]
	TIME [epoch: 5.75 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04053334546306655		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.04053334546306655 | validation: 0.03295019999620738]
	TIME [epoch: 5.75 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02849522805755191		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.02849522805755191 | validation: 0.023143765319044086]
	TIME [epoch: 5.75 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03932792559123247		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.03932792559123247 | validation: 0.04923034588926691]
	TIME [epoch: 5.75 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062474822961634445		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.062474822961634445 | validation: 0.06713399124660904]
	TIME [epoch: 5.75 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07985099041105713		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.07985099041105713 | validation: 0.07468955034096265]
	TIME [epoch: 5.78 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06483918608899475		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.06483918608899475 | validation: 0.051125827965196435]
	TIME [epoch: 5.76 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05400178920261735		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.05400178920261735 | validation: 0.06980058163305312]
	TIME [epoch: 5.75 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0630368790146342		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.0630368790146342 | validation: 0.059179878783207907]
	TIME [epoch: 5.76 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04984462611338726		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.04984462611338726 | validation: 0.03597806042606869]
	TIME [epoch: 5.73 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04104155720941882		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.04104155720941882 | validation: 0.03109860181281286]
	TIME [epoch: 5.73 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04232093672848504		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.04232093672848504 | validation: 0.02954345818080628]
	TIME [epoch: 5.74 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03616568834912646		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.03616568834912646 | validation: 0.03527840217149789]
	TIME [epoch: 5.77 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03561485876660291		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.03561485876660291 | validation: 0.03817858481414724]
	TIME [epoch: 5.74 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033079363279653905		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.033079363279653905 | validation: 0.03409253333909081]
	TIME [epoch: 5.75 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03272777273253703		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.03272777273253703 | validation: 0.03801525938931244]
	TIME [epoch: 5.72 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03883517272321654		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.03883517272321654 | validation: 0.05225003779521715]
	TIME [epoch: 5.73 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044122671287222234		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.044122671287222234 | validation: 0.05613579084339422]
	TIME [epoch: 5.73 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043728086018988574		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.043728086018988574 | validation: 0.044136147042949894]
	TIME [epoch: 5.76 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04057886112408365		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.04057886112408365 | validation: 0.038628206166149294]
	TIME [epoch: 5.74 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036177833075534155		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.036177833075534155 | validation: 0.015709185611170347]
	TIME [epoch: 5.73 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028671469303238925		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.028671469303238925 | validation: 0.028210856301725484]
	TIME [epoch: 5.74 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03003022863146102		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.03003022863146102 | validation: 0.024725879178774883]
	TIME [epoch: 5.73 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03747019825678384		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.03747019825678384 | validation: 0.0419972056138435]
	TIME [epoch: 5.75 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032182259536570466		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.032182259536570466 | validation: 0.025719685344047786]
	TIME [epoch: 5.73 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029881400367787345		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.029881400367787345 | validation: 0.023768321726642175]
	TIME [epoch: 5.76 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030674455470205128		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.030674455470205128 | validation: 0.018850719725307084]
	TIME [epoch: 5.73 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027454848168883238		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.027454848168883238 | validation: 0.029528637339539348]
	TIME [epoch: 5.75 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03275245251834072		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.03275245251834072 | validation: 0.029317745326267054]
	TIME [epoch: 5.75 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02879434272620534		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.02879434272620534 | validation: 0.029671847686382043]
	TIME [epoch: 5.75 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029518148317222846		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.029518148317222846 | validation: 0.02603340331738717]
	TIME [epoch: 5.73 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02862246774338214		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.02862246774338214 | validation: 0.01677103778632977]
	TIME [epoch: 5.78 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02782971954281189		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.02782971954281189 | validation: 0.027183421425325226]
	TIME [epoch: 5.74 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02905568286760559		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.02905568286760559 | validation: 0.02550034988320591]
	TIME [epoch: 5.75 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02908406663511861		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.02908406663511861 | validation: 0.023567066801756145]
	TIME [epoch: 5.75 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030803751499132156		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.030803751499132156 | validation: 0.023635185298787553]
	TIME [epoch: 5.75 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0277251426515243		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.0277251426515243 | validation: 0.022887172169033593]
	TIME [epoch: 5.75 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029412732741540697		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.029412732741540697 | validation: 0.028797019883145706]
	TIME [epoch: 5.77 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02617014328823927		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.02617014328823927 | validation: 0.02115648676990737]
	TIME [epoch: 5.78 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02717007475278814		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.02717007475278814 | validation: 0.023074953701458022]
	TIME [epoch: 5.75 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027588169033460678		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.027588169033460678 | validation: 0.019588557105156137]
	TIME [epoch: 5.75 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03085111157645189		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.03085111157645189 | validation: 0.025904962629830774]
	TIME [epoch: 5.74 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02897598786175311		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.02897598786175311 | validation: 0.031788608774920686]
	TIME [epoch: 5.73 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03362795821918137		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.03362795821918137 | validation: 0.022819529545804303]
	TIME [epoch: 5.73 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028081479458148383		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.028081479458148383 | validation: 0.033204049584284384]
	TIME [epoch: 5.77 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028245094369154355		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.028245094369154355 | validation: 0.026928685955312694]
	TIME [epoch: 5.74 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028254254511599457		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.028254254511599457 | validation: 0.03397361026504666]
	TIME [epoch: 5.73 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029057869152389434		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.029057869152389434 | validation: 0.029827595755391467]
	TIME [epoch: 5.73 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03978630649589065		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.03978630649589065 | validation: 0.04406777564290908]
	TIME [epoch: 5.73 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04925632003981518		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.04925632003981518 | validation: 0.05742405978941685]
	TIME [epoch: 5.73 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039788776119937745		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.039788776119937745 | validation: 0.025139104252556624]
	TIME [epoch: 5.77 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028294232081509142		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.028294232081509142 | validation: 0.02083069096203454]
	TIME [epoch: 5.77 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031143191602801844		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.031143191602801844 | validation: 0.028582191365265498]
	TIME [epoch: 5.75 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02966066515644377		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.02966066515644377 | validation: 0.02657011061833435]
	TIME [epoch: 5.75 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027303640505917506		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.027303640505917506 | validation: 0.018534693785098914]
	TIME [epoch: 5.75 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03142860027178735		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.03142860027178735 | validation: 0.02820681554649104]
	TIME [epoch: 5.75 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031798462246443025		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.031798462246443025 | validation: 0.0390808991094036]
	TIME [epoch: 5.73 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0347945638857193		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.0347945638857193 | validation: 0.03497479764572379]
	TIME [epoch: 5.77 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03436418295922819		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.03436418295922819 | validation: 0.029356524393842856]
	TIME [epoch: 5.74 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029231570140442014		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.029231570140442014 | validation: 0.044701721432727964]
	TIME [epoch: 5.73 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032520521599027075		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.032520521599027075 | validation: 0.03318789079942665]
	TIME [epoch: 5.74 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03125481220608422		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.03125481220608422 | validation: 0.012762043035201601]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_1050.pth
	Model improved!!!
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02814474941407323		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.02814474941407323 | validation: 0.029795651897847903]
	TIME [epoch: 5.75 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03227216747928537		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.03227216747928537 | validation: 0.0349771322947155]
	TIME [epoch: 5.75 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026796509221505678		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.026796509221505678 | validation: 0.023857507154689445]
	TIME [epoch: 5.76 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026726390318430014		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.026726390318430014 | validation: 0.03496298339588692]
	TIME [epoch: 5.74 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031021386130358902		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.031021386130358902 | validation: 0.030404134473116313]
	TIME [epoch: 5.73 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031875203698900664		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.031875203698900664 | validation: 0.026003799763555442]
	TIME [epoch: 5.76 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025670590075089688		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.025670590075089688 | validation: 0.029749693862469284]
	TIME [epoch: 5.74 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030517865360936938		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.030517865360936938 | validation: 0.031815841106564616]
	TIME [epoch: 5.74 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032217412572097696		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.032217412572097696 | validation: 0.02532132940516158]
	TIME [epoch: 5.78 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031662390260772035		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.031662390260772035 | validation: 0.025955445506857223]
	TIME [epoch: 5.75 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02607249663830323		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.02607249663830323 | validation: 0.023872371796513484]
	TIME [epoch: 5.75 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028172697862406504		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.028172697862406504 | validation: 0.01910673312192514]
	TIME [epoch: 5.75 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0326407703761681		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.0326407703761681 | validation: 0.030785320894425334]
	TIME [epoch: 5.75 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031200021608789097		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.031200021608789097 | validation: 0.03406541490030771]
	TIME [epoch: 5.75 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03151370290789771		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.03151370290789771 | validation: 0.020717920471535218]
	TIME [epoch: 5.77 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030188920271182234		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.030188920271182234 | validation: 0.035789645893648976]
	TIME [epoch: 5.76 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03628629027715688		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.03628629027715688 | validation: 0.040877438316795]
	TIME [epoch: 5.75 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03971998298165992		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.03971998298165992 | validation: 0.03104314367227304]
	TIME [epoch: 5.75 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035808318408189696		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.035808318408189696 | validation: 0.034307308912344334]
	TIME [epoch: 5.75 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03207346770761893		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.03207346770761893 | validation: 0.03271259551715748]
	TIME [epoch: 5.75 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04189103338156326		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.04189103338156326 | validation: 0.04378705814017874]
	TIME [epoch: 5.75 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03927262360520374		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.03927262360520374 | validation: 0.03128762841516447]
	TIME [epoch: 5.79 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023880900726209603		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.023880900726209603 | validation: 0.02292715632061286]
	TIME [epoch: 5.75 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03066846633972569		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.03066846633972569 | validation: 0.02554424450555718]
	TIME [epoch: 5.74 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030554610285517696		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.030554610285517696 | validation: 0.02560450050565382]
	TIME [epoch: 5.73 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028021166642661195		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.028021166642661195 | validation: 0.023450217999907607]
	TIME [epoch: 5.73 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025691735072943672		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.025691735072943672 | validation: 0.02964755118591783]
	TIME [epoch: 5.73 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03649672238913619		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.03649672238913619 | validation: 0.02901545348164767]
	TIME [epoch: 5.76 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03961051133173095		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.03961051133173095 | validation: 0.03428352221129899]
	TIME [epoch: 5.74 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033435767524631455		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.033435767524631455 | validation: 0.029240396169764704]
	TIME [epoch: 5.73 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029551442828522484		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.029551442828522484 | validation: 0.027497790551626773]
	TIME [epoch: 5.74 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0373479690608442		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.0373479690608442 | validation: 0.030335521756786516]
	TIME [epoch: 5.74 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03169346847209793		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.03169346847209793 | validation: 0.03358199391569766]
	TIME [epoch: 5.74 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043147252232976954		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.043147252232976954 | validation: 0.04785769223753698]
	TIME [epoch: 5.74 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062102538341356914		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.062102538341356914 | validation: 0.07593355612483411]
	TIME [epoch: 5.79 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06441502586473279		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.06441502586473279 | validation: 0.044243214529524864]
	TIME [epoch: 5.74 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042775833002609176		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.042775833002609176 | validation: 0.04494332143949631]
	TIME [epoch: 5.74 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033032903342475856		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.033032903342475856 | validation: 0.031583003857563755]
	TIME [epoch: 5.75 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028465934313548314		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.028465934313548314 | validation: 0.028168502152467287]
	TIME [epoch: 5.73 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03026582819734359		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.03026582819734359 | validation: 0.02299589853475084]
	TIME [epoch: 5.75 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027264650172197216		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.027264650172197216 | validation: 0.023636209941341083]
	TIME [epoch: 5.77 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024014013835643527		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.024014013835643527 | validation: 0.031074501567905807]
	TIME [epoch: 5.76 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023416798002399625		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.023416798002399625 | validation: 0.023517621279094812]
	TIME [epoch: 5.75 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027073834819869132		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.027073834819869132 | validation: 0.02501936921370797]
	TIME [epoch: 5.73 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024365610741967778		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.024365610741967778 | validation: 0.018438251417784136]
	TIME [epoch: 5.74 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026023547426167873		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.026023547426167873 | validation: 0.023202364163039016]
	TIME [epoch: 5.74 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026473671184356444		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.026473671184356444 | validation: 0.022369939748671956]
	TIME [epoch: 5.75 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027332071293617602		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.027332071293617602 | validation: 0.03108616128532764]
	TIME [epoch: 5.79 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029665309784878257		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.029665309784878257 | validation: 0.03044312743218077]
	TIME [epoch: 5.75 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025977118975933907		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.025977118975933907 | validation: 0.025560687315888408]
	TIME [epoch: 5.73 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02681675160091896		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.02681675160091896 | validation: 0.02905914950034191]
	TIME [epoch: 5.74 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025945909189892907		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.025945909189892907 | validation: 0.03350813642730704]
	TIME [epoch: 5.74 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02531290139216763		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.02531290139216763 | validation: 0.02685766783626914]
	TIME [epoch: 5.75 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027736650992872473		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.027736650992872473 | validation: 0.03005162812375808]
	TIME [epoch: 5.77 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028992594084443084		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.028992594084443084 | validation: 0.04043704314889975]
	TIME [epoch: 5.76 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030742916744341382		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.030742916744341382 | validation: 0.033026129591694]
	TIME [epoch: 5.75 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030150649631251396		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.030150649631251396 | validation: 0.028049463749962075]
	TIME [epoch: 5.75 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02898827006127511		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.02898827006127511 | validation: 0.024604831330642278]
	TIME [epoch: 5.74 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027899935134736216		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.027899935134736216 | validation: 0.022038073554047414]
	TIME [epoch: 5.73 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027852385889440667		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.027852385889440667 | validation: 0.02852106786384107]
	TIME [epoch: 5.74 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03900055974632034		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.03900055974632034 | validation: 0.03685051461326953]
	TIME [epoch: 5.79 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043504795789366016		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.043504795789366016 | validation: 0.03853151072691714]
	TIME [epoch: 5.74 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046079995665686095		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.046079995665686095 | validation: 0.05161871399674416]
	TIME [epoch: 5.74 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05940353537939057		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.05940353537939057 | validation: 0.05016123059976121]
	TIME [epoch: 5.74 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043636405300541484		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.043636405300541484 | validation: 0.03601680779989263]
	TIME [epoch: 5.74 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03352948442253387		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.03352948442253387 | validation: 0.03738556623759653]
	TIME [epoch: 5.73 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03464068303467723		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.03464068303467723 | validation: 0.028167255140182715]
	TIME [epoch: 5.75 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03134437393998604		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.03134437393998604 | validation: 0.028026474617599596]
	TIME [epoch: 5.76 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02665076503181672		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.02665076503181672 | validation: 0.023582761383244697]
	TIME [epoch: 5.73 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02939490357721166		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.02939490357721166 | validation: 0.03835065998051726]
	TIME [epoch: 5.74 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02372326900195766		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.02372326900195766 | validation: 0.02964359977518232]
	TIME [epoch: 5.73 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02338529316880346		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.02338529316880346 | validation: 0.02898611308600578]
	TIME [epoch: 5.75 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03052177239893631		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.03052177239893631 | validation: 0.037396687255152855]
	TIME [epoch: 5.75 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029338371209361263		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.029338371209361263 | validation: 0.037049634356876505]
	TIME [epoch: 5.8 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02802067606210329		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.02802067606210329 | validation: 0.03173159440358725]
	TIME [epoch: 5.75 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03294446905803486		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.03294446905803486 | validation: 0.03520716095910846]
	TIME [epoch: 5.75 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029157171288804566		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.029157171288804566 | validation: 0.02141688335666121]
	TIME [epoch: 5.73 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02691327351922248		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.02691327351922248 | validation: 0.02311057031119244]
	TIME [epoch: 5.73 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027979661442511274		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.027979661442511274 | validation: 0.02914748566414138]
	TIME [epoch: 5.73 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029966731278721914		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.029966731278721914 | validation: 0.035152958923503876]
	TIME [epoch: 5.78 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03387309738222068		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.03387309738222068 | validation: 0.03103939069870021]
	TIME [epoch: 5.76 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031413614865918864		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.031413614865918864 | validation: 0.026407572415190095]
	TIME [epoch: 5.75 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02577616474112668		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.02577616474112668 | validation: 0.022694055824961153]
	TIME [epoch: 5.74 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030073317005991664		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.030073317005991664 | validation: 0.020202127261222818]
	TIME [epoch: 5.74 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024811195476391257		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.024811195476391257 | validation: 0.01890742834000035]
	TIME [epoch: 5.74 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02381423716711238		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.02381423716711238 | validation: 0.03130095061336191]
	TIME [epoch: 5.73 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034093004737151864		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.034093004737151864 | validation: 0.031893933754041814]
	TIME [epoch: 5.77 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029189823252931076		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.029189823252931076 | validation: 0.021959008135617505]
	TIME [epoch: 5.75 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024834515813309005		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.024834515813309005 | validation: 0.03250015796212937]
	TIME [epoch: 5.75 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026579252931894108		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.026579252931894108 | validation: 0.02458854096097024]
	TIME [epoch: 5.75 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02434148357771866		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.02434148357771866 | validation: 0.021659512179091275]
	TIME [epoch: 5.73 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025385830380974785		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.025385830380974785 | validation: 0.03418258262207261]
	TIME [epoch: 5.74 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025814309520505677		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.025814309520505677 | validation: 0.03580031950488889]
	TIME [epoch: 5.79 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029080297267563532		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.029080297267563532 | validation: 0.03273567577636637]
	TIME [epoch: 5.74 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030560857682159364		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.030560857682159364 | validation: 0.0359604054004628]
	TIME [epoch: 5.74 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030940893273637048		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.030940893273637048 | validation: 0.024792982345288993]
	TIME [epoch: 5.74 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024056066466408062		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.024056066466408062 | validation: 0.02269969018226968]
	TIME [epoch: 5.73 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02419716439094792		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.02419716439094792 | validation: 0.02571482776091233]
	TIME [epoch: 5.74 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026531888165848443		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.026531888165848443 | validation: 0.02499564543486976]
	TIME [epoch: 5.76 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025712991372370087		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.025712991372370087 | validation: 0.029651500329732104]
	TIME [epoch: 5.77 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028318468345383915		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.028318468345383915 | validation: 0.028177283846042265]
	TIME [epoch: 5.76 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029170331186209146		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.029170331186209146 | validation: 0.03521842140032187]
	TIME [epoch: 5.74 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03741683941116343		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.03741683941116343 | validation: 0.034286302973657916]
	TIME [epoch: 5.74 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037836699903190704		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.037836699903190704 | validation: 0.03009580819323696]
	TIME [epoch: 5.74 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026647604050017752		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.026647604050017752 | validation: 0.02812501476946384]
	TIME [epoch: 5.75 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024803093520623994		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.024803093520623994 | validation: 0.02765510609494938]
	TIME [epoch: 5.78 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023543984049916988		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.023543984049916988 | validation: 0.02747389865542379]
	TIME [epoch: 5.76 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026689150981843622		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.026689150981843622 | validation: 0.0191933921425544]
	TIME [epoch: 5.75 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026882954055155762		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.026882954055155762 | validation: 0.029000863859576384]
	TIME [epoch: 5.74 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025304304476695114		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.025304304476695114 | validation: 0.028556271381477424]
	TIME [epoch: 5.75 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027672315546098745		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.027672315546098745 | validation: 0.02127949089381123]
	TIME [epoch: 5.74 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028980825912869393		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.028980825912869393 | validation: 0.028814480881680905]
	TIME [epoch: 5.76 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03289498888174906		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.03289498888174906 | validation: 0.029233805885728034]
	TIME [epoch: 5.76 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03818200376402278		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.03818200376402278 | validation: 0.03766834894059912]
	TIME [epoch: 5.73 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03773704667385002		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.03773704667385002 | validation: 0.03356798346708388]
	TIME [epoch: 5.75 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032918734525676986		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.032918734525676986 | validation: 0.028992038792870566]
	TIME [epoch: 5.75 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031367507610269046		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.031367507610269046 | validation: 0.03749126618536733]
	TIME [epoch: 5.73 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03575295282417385		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.03575295282417385 | validation: 0.033319455178102454]
	TIME [epoch: 5.74 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026773218810415406		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.026773218810415406 | validation: 0.028217924557674835]
	TIME [epoch: 5.79 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026208182014528875		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.026208182014528875 | validation: 0.03218706104201164]
	TIME [epoch: 5.75 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02407144007661974		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.02407144007661974 | validation: 0.028745678251914788]
	TIME [epoch: 5.75 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03203482630273939		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.03203482630273939 | validation: 0.03388678474821412]
	TIME [epoch: 5.74 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03428748883561487		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.03428748883561487 | validation: 0.033851554908258315]
	TIME [epoch: 5.73 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03256006786397891		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.03256006786397891 | validation: 0.03236932118724322]
	TIME [epoch: 5.74 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03449574699024982		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.03449574699024982 | validation: 0.028763637354359894]
	TIME [epoch: 5.76 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02929470748411633		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.02929470748411633 | validation: 0.023727252754306462]
	TIME [epoch: 5.77 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026686235315060286		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.026686235315060286 | validation: 0.019714887008225983]
	TIME [epoch: 5.75 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029475906372677423		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.029475906372677423 | validation: 0.02484139074543079]
	TIME [epoch: 5.74 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03137313059570375		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.03137313059570375 | validation: 0.03141459584258431]
	TIME [epoch: 5.75 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029326430230600012		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.029326430230600012 | validation: 0.029191132516472002]
	TIME [epoch: 5.74 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025111616661891118		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.025111616661891118 | validation: 0.031546037768719566]
	TIME [epoch: 5.75 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02797499592447692		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.02797499592447692 | validation: 0.0233579946660167]
	TIME [epoch: 5.77 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029314234773155146		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.029314234773155146 | validation: 0.026415276544313353]
	TIME [epoch: 5.73 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028257197483379168		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.028257197483379168 | validation: 0.03942118750660555]
	TIME [epoch: 5.74 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03230607235548138		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.03230607235548138 | validation: 0.024407155412079332]
	TIME [epoch: 5.73 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02471057531173935		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.02471057531173935 | validation: 0.02166475170968905]
	TIME [epoch: 5.75 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025868343184946085		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.025868343184946085 | validation: 0.027665198025929445]
	TIME [epoch: 5.75 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030759607888080995		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.030759607888080995 | validation: 0.02620777692850966]
	TIME [epoch: 5.75 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028943411081699653		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.028943411081699653 | validation: 0.03313323372356179]
	TIME [epoch: 5.78 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026626627985264006		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.026626627985264006 | validation: 0.027517144909607376]
	TIME [epoch: 5.74 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028510102935912038		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.028510102935912038 | validation: 0.0235083469247932]
	TIME [epoch: 5.73 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028427171499492705		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.028427171499492705 | validation: 0.028377338311117353]
	TIME [epoch: 5.75 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02612149998969135		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.02612149998969135 | validation: 0.02742073039106982]
	TIME [epoch: 5.75 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0326152796368302		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.0326152796368302 | validation: 0.03731739595919196]
	TIME [epoch: 5.75 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033362440904348575		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.033362440904348575 | validation: 0.03131531724009804]
	TIME [epoch: 5.78 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030608390652704126		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.030608390652704126 | validation: 0.025639991675673983]
	TIME [epoch: 5.76 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02735437525656719		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.02735437525656719 | validation: 0.028458909957247005]
	TIME [epoch: 5.75 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02462235958564559		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.02462235958564559 | validation: 0.031859976202394155]
	TIME [epoch: 5.75 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023205828315842794		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.023205828315842794 | validation: 0.019555701951416118]
	TIME [epoch: 5.75 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028471158997134777		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.028471158997134777 | validation: 0.028254027511068206]
	TIME [epoch: 5.75 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02773167089953677		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.02773167089953677 | validation: 0.036060806320641146]
	TIME [epoch: 5.77 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02721015190267099		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.02721015190267099 | validation: 0.02180768055290367]
	TIME [epoch: 5.78 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022196062479271528		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.022196062479271528 | validation: 0.03285096179575798]
	TIME [epoch: 5.75 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03017181818115856		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.03017181818115856 | validation: 0.024939622781421422]
	TIME [epoch: 5.74 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027974639640178933		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.027974639640178933 | validation: 0.021385714696744468]
	TIME [epoch: 5.75 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0238162421443281		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.0238162421443281 | validation: 0.034965615093376944]
	TIME [epoch: 5.74 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029197408348196674		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.029197408348196674 | validation: 0.02942873832779079]
	TIME [epoch: 5.75 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02586504454913373		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.02586504454913373 | validation: 0.02364924929261271]
	TIME [epoch: 5.77 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025932269856283795		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.025932269856283795 | validation: 0.01955729302076876]
	TIME [epoch: 5.74 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024537565584831618		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.024537565584831618 | validation: 0.028055850782171998]
	TIME [epoch: 5.75 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026970655019243554		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.026970655019243554 | validation: 0.025425669187698095]
	TIME [epoch: 5.74 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02597250892666489		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.02597250892666489 | validation: 0.021777277448373003]
	TIME [epoch: 5.74 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027241227142878185		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.027241227142878185 | validation: 0.034684299578388776]
	TIME [epoch: 5.74 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028770571659175417		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.028770571659175417 | validation: 0.028883624282376088]
	TIME [epoch: 5.77 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03167264119980966		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.03167264119980966 | validation: 0.032209823208126764]
	TIME [epoch: 5.76 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034714776126241284		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.034714776126241284 | validation: 0.029152811195036415]
	TIME [epoch: 5.75 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028967504691527216		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.028967504691527216 | validation: 0.017205960532789867]
	TIME [epoch: 5.75 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028342547421919016		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.028342547421919016 | validation: 0.020854619291010894]
	TIME [epoch: 5.75 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026569290056089323		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.026569290056089323 | validation: 0.027075960611935596]
	TIME [epoch: 5.73 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031513447032362585		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.031513447032362585 | validation: 0.02853859179144286]
	TIME [epoch: 5.73 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031901170108094797		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.031901170108094797 | validation: 0.020010465907789272]
	TIME [epoch: 5.78 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02507305383341022		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.02507305383341022 | validation: 0.021182773467069184]
	TIME [epoch: 5.75 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022167300006156708		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.022167300006156708 | validation: 0.0219720106646364]
	TIME [epoch: 5.74 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023675839306559185		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.023675839306559185 | validation: 0.019973754806007455]
	TIME [epoch: 5.75 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021297696431416754		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.021297696431416754 | validation: 0.025683472262304212]
	TIME [epoch: 5.73 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01898051059995154		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.01898051059995154 | validation: 0.01647652636183186]
	TIME [epoch: 5.75 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023869539938049904		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.023869539938049904 | validation: 0.02754108981400586]
	TIME [epoch: 5.78 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02618405718777684		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.02618405718777684 | validation: 0.026111871636783395]
	TIME [epoch: 5.76 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024092798914277562		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.024092798914277562 | validation: 0.025020684341713777]
	TIME [epoch: 5.73 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023454645573832304		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.023454645573832304 | validation: 0.024725512291316365]
	TIME [epoch: 5.73 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024725240236987342		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.024725240236987342 | validation: 0.026581238023187605]
	TIME [epoch: 5.74 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02366507165259281		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.02366507165259281 | validation: 0.028261965694267727]
	TIME [epoch: 5.73 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027521751521918495		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.027521751521918495 | validation: 0.027403496209767432]
	TIME [epoch: 5.73 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02367104447213899		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.02367104447213899 | validation: 0.02635517115535786]
	TIME [epoch: 5.77 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023842348640241148		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.023842348640241148 | validation: 0.026552728302401116]
	TIME [epoch: 5.75 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025634835872613553		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.025634835872613553 | validation: 0.03575940084558146]
	TIME [epoch: 5.73 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03219397620933882		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.03219397620933882 | validation: 0.03204891421826449]
	TIME [epoch: 5.74 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028637898795450638		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.028637898795450638 | validation: 0.025708393384615152]
	TIME [epoch: 5.74 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024700667776223966		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.024700667776223966 | validation: 0.027118990285484586]
	TIME [epoch: 5.74 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02468995204981877		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.02468995204981877 | validation: 0.024503961919706]
	TIME [epoch: 5.76 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02315809998248064		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.02315809998248064 | validation: 0.026341939956621898]
	TIME [epoch: 5.76 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02086958670815671		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.02086958670815671 | validation: 0.03545452116966738]
	TIME [epoch: 5.74 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025948004292126063		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.025948004292126063 | validation: 0.021633683781511977]
	TIME [epoch: 5.75 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02401670329647393		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.02401670329647393 | validation: 0.029524320075808862]
	TIME [epoch: 5.73 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02718834619578852		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.02718834619578852 | validation: 0.025152282465957194]
	TIME [epoch: 5.75 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020894705784790902		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.020894705784790902 | validation: 0.0324135656166537]
	TIME [epoch: 5.74 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024687719175443542		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.024687719175443542 | validation: 0.01881893582962801]
	TIME [epoch: 5.79 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02647397731572869		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.02647397731572869 | validation: 0.03555907184526569]
	TIME [epoch: 5.72 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02244467273313132		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.02244467273313132 | validation: 0.025948219387156114]
	TIME [epoch: 5.74 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02636291154161753		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.02636291154161753 | validation: 0.022174524782254533]
	TIME [epoch: 5.74 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02510214649688582		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.02510214649688582 | validation: 0.024430354317165746]
	TIME [epoch: 5.74 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025870803459575337		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.025870803459575337 | validation: 0.023664777947105958]
	TIME [epoch: 5.73 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02635557523678605		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.02635557523678605 | validation: 0.026239805251567543]
	TIME [epoch: 5.78 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02683011130664756		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.02683011130664756 | validation: 0.02764144495313347]
	TIME [epoch: 5.76 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02753156513050111		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.02753156513050111 | validation: 0.02294742226278899]
	TIME [epoch: 5.75 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028324853754079966		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.028324853754079966 | validation: 0.018705985285417694]
	TIME [epoch: 5.73 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025863405380942044		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.025863405380942044 | validation: 0.02532878660265074]
	TIME [epoch: 5.75 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026504787542131616		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.026504787542131616 | validation: 0.017034513831284414]
	TIME [epoch: 5.73 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020397782087743167		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.020397782087743167 | validation: 0.02537736733960034]
	TIME [epoch: 5.75 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026709101264993356		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.026709101264993356 | validation: 0.02017320676949586]
	TIME [epoch: 5.79 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02635875553127228		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.02635875553127228 | validation: 0.025327096356471703]
	TIME [epoch: 5.75 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02475165440067729		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.02475165440067729 | validation: 0.02693669718645051]
	TIME [epoch: 5.73 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0244567147981561		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.0244567147981561 | validation: 0.023782662780206926]
	TIME [epoch: 5.74 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027393158896297048		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.027393158896297048 | validation: 0.029160316201675456]
	TIME [epoch: 5.73 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02608088813982292		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.02608088813982292 | validation: 0.031086452406760074]
	TIME [epoch: 5.74 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02643233015193818		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.02643233015193818 | validation: 0.023803980351412467]
	TIME [epoch: 5.78 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02650893065399834		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.02650893065399834 | validation: 0.025181923434871675]
	TIME [epoch: 5.75 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02268003067635716		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.02268003067635716 | validation: 0.021372714553081394]
	TIME [epoch: 5.73 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0229953328336048		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.0229953328336048 | validation: 0.023957727396017692]
	TIME [epoch: 5.73 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021249092260250485		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.021249092260250485 | validation: 0.026717751972048037]
	TIME [epoch: 5.74 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025556948653271197		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.025556948653271197 | validation: 0.03399093646771419]
	TIME [epoch: 5.74 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024077830642919407		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.024077830642919407 | validation: 0.03317231151048194]
	TIME [epoch: 5.74 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024491966535376893		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.024491966535376893 | validation: 0.026983347146350194]
	TIME [epoch: 5.78 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02231481592449923		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.02231481592449923 | validation: 0.031885107677593345]
	TIME [epoch: 5.75 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028513841063421273		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.028513841063421273 | validation: 0.03647779472834759]
	TIME [epoch: 5.75 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024121816078139464		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.024121816078139464 | validation: 0.026699008070472204]
	TIME [epoch: 5.75 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02642154665521386		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.02642154665521386 | validation: 0.021445953138629337]
	TIME [epoch: 5.73 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027304108940925942		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.027304108940925942 | validation: 0.01626952360716482]
	TIME [epoch: 5.74 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023618506238108874		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.023618506238108874 | validation: 0.025627871423523338]
	TIME [epoch: 5.77 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02164895938578093		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.02164895938578093 | validation: 0.022695420159225627]
	TIME [epoch: 5.75 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02015287715220427		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.02015287715220427 | validation: 0.024820299049338593]
	TIME [epoch: 5.73 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024540951709032255		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.024540951709032255 | validation: 0.026852330202985053]
	TIME [epoch: 5.74 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024037865291694088		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.024037865291694088 | validation: 0.02415810975401026]
	TIME [epoch: 5.75 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026952006731740745		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.026952006731740745 | validation: 0.033718387879624806]
	TIME [epoch: 5.75 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025678335191425518		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.025678335191425518 | validation: 0.029529893241583862]
	TIME [epoch: 5.75 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02687780832184084		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.02687780832184084 | validation: 0.027466734769290912]
	TIME [epoch: 5.77 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02543008245564676		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.02543008245564676 | validation: 0.02691282044425835]
	TIME [epoch: 5.73 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023520508934305052		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.023520508934305052 | validation: 0.02440241266410363]
	TIME [epoch: 5.74 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028950064769960527		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.028950064769960527 | validation: 0.036874375163737295]
	TIME [epoch: 5.74 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0270748870253382		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.0270748870253382 | validation: 0.027998456960875658]
	TIME [epoch: 5.74 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030770150141226284		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.030770150141226284 | validation: 0.027171738541863957]
	TIME [epoch: 5.74 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030564389535132873		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.030564389535132873 | validation: 0.019627223530902262]
	TIME [epoch: 5.79 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029740560239531588		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.029740560239531588 | validation: 0.02997270197040673]
	TIME [epoch: 5.75 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02831369917639479		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.02831369917639479 | validation: 0.03436074252097593]
	TIME [epoch: 5.75 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03020776218556888		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.03020776218556888 | validation: 0.025648404185384947]
	TIME [epoch: 5.74 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02989166131298682		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.02989166131298682 | validation: 0.03201702835439226]
	TIME [epoch: 5.75 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024333356505792082		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.024333356505792082 | validation: 0.027075444803672095]
	TIME [epoch: 5.73 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026383400866726213		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.026383400866726213 | validation: 0.025335931322227157]
	TIME [epoch: 5.74 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02574564821242076		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.02574564821242076 | validation: 0.0175405734568607]
	TIME [epoch: 5.75 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02601085117098363		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.02601085117098363 | validation: 0.02699379961818396]
	TIME [epoch: 5.75 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024873061009406176		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.024873061009406176 | validation: 0.021168254832018462]
	TIME [epoch: 5.72 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02161037055450962		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.02161037055450962 | validation: 0.028081245489890515]
	TIME [epoch: 5.73 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025208528755669903		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.025208528755669903 | validation: 0.02329213108526886]
	TIME [epoch: 5.73 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02635608570071097		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.02635608570071097 | validation: 0.034765780703937293]
	TIME [epoch: 5.73 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02491994213236273		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.02491994213236273 | validation: 0.022395141214337177]
	TIME [epoch: 5.79 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02689139140915311		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.02689139140915311 | validation: 0.03125490802923426]
	TIME [epoch: 5.73 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026469786034654573		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.026469786034654573 | validation: 0.028583701405847588]
	TIME [epoch: 5.72 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025578724574507692		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.025578724574507692 | validation: 0.02853776760716067]
	TIME [epoch: 5.73 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023525826152418244		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.023525826152418244 | validation: 0.025262423230601662]
	TIME [epoch: 5.73 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022335038045201344		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.022335038045201344 | validation: 0.028226437550270135]
	TIME [epoch: 5.74 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02600239089532473		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.02600239089532473 | validation: 0.029928759755065117]
	TIME [epoch: 5.76 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02591760503234217		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.02591760503234217 | validation: 0.03507179668073072]
	TIME [epoch: 5.78 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02477320770871046		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.02477320770871046 | validation: 0.01885546314813978]
	TIME [epoch: 5.73 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02080795676806048		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.02080795676806048 | validation: 0.02638659012097977]
	TIME [epoch: 5.73 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0230046369583307		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.0230046369583307 | validation: 0.017415168807741015]
	TIME [epoch: 5.73 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02402123530261429		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.02402123530261429 | validation: 0.0205116707955671]
	TIME [epoch: 5.73 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023994160939466474		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.023994160939466474 | validation: 0.01662070291421285]
	TIME [epoch: 5.73 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0286705900672495		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.0286705900672495 | validation: 0.029761145998375853]
	TIME [epoch: 5.77 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024853645562683276		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.024853645562683276 | validation: 0.03162205748274552]
	TIME [epoch: 5.74 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025780882897061916		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.025780882897061916 | validation: 0.02897151283117146]
	TIME [epoch: 5.74 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02724909095541226		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.02724909095541226 | validation: 0.02551807044373363]
	TIME [epoch: 5.72 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02409360454172131		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.02409360454172131 | validation: 0.030558027535527908]
	TIME [epoch: 5.75 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024015573027288958		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.024015573027288958 | validation: 0.02278944758901932]
	TIME [epoch: 5.74 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028098945013270496		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.028098945013270496 | validation: 0.029405346372927382]
	TIME [epoch: 5.76 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028610141638970375		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.028610141638970375 | validation: 0.022084515456079208]
	TIME [epoch: 5.78 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02608344821061947		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.02608344821061947 | validation: 0.028802637257662803]
	TIME [epoch: 5.75 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024093518499839785		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.024093518499839785 | validation: 0.024289468224533612]
	TIME [epoch: 5.74 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02581969318914326		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.02581969318914326 | validation: 0.019454529953338465]
	TIME [epoch: 5.74 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02434922477772986		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.02434922477772986 | validation: 0.016811500971443537]
	TIME [epoch: 5.72 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02198350261599689		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.02198350261599689 | validation: 0.021203370213792636]
	TIME [epoch: 5.73 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023407286133174096		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.023407286133174096 | validation: 0.01809688781073362]
	TIME [epoch: 5.77 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02371946490645689		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.02371946490645689 | validation: 0.024821741928623024]
	TIME [epoch: 5.73 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02367907963550477		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.02367907963550477 | validation: 0.027345734613595116]
	TIME [epoch: 5.73 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021872865902427673		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.021872865902427673 | validation: 0.02320350183073142]
	TIME [epoch: 5.73 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02379673621435891		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.02379673621435891 | validation: 0.021786340826686727]
	TIME [epoch: 5.72 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02229534727610887		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.02229534727610887 | validation: 0.01831569977380252]
	TIME [epoch: 5.73 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021745633730731614		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.021745633730731614 | validation: 0.020670438429375455]
	TIME [epoch: 5.74 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024614461788067858		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.024614461788067858 | validation: 0.03145601353674187]
	TIME [epoch: 5.78 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027943282665002445		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.027943282665002445 | validation: 0.027534653742443446]
	TIME [epoch: 5.75 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026320598555924328		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.026320598555924328 | validation: 0.023903809883924338]
	TIME [epoch: 5.75 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027551461472768914		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.027551461472768914 | validation: 0.02348319591953259]
	TIME [epoch: 5.73 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030269615563843298		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.030269615563843298 | validation: 0.019978124698811647]
	TIME [epoch: 5.75 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027428001792050544		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.027428001792050544 | validation: 0.020771893234290007]
	TIME [epoch: 5.75 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029716288094132327		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.029716288094132327 | validation: 0.02551132438860751]
	TIME [epoch: 5.78 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025970175410318288		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.025970175410318288 | validation: 0.02138499182940621]
	TIME [epoch: 5.73 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027043616047567942		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.027043616047567942 | validation: 0.030591560819508645]
	TIME [epoch: 5.73 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0321621554176883		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.0321621554176883 | validation: 0.015048055160678593]
	TIME [epoch: 5.73 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02869258675874303		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.02869258675874303 | validation: 0.03891583550805454]
	TIME [epoch: 5.73 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031201375024633694		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.031201375024633694 | validation: 0.0252636048423084]
	TIME [epoch: 5.75 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02286941756045016		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.02286941756045016 | validation: 0.0314052282733063]
	TIME [epoch: 5.78 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024453407082409714		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.024453407082409714 | validation: 0.03016724675556789]
	TIME [epoch: 5.76 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025504488618639104		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.025504488618639104 | validation: 0.02421108332168533]
	TIME [epoch: 5.73 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024197017283853997		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.024197017283853997 | validation: 0.030810566674312805]
	TIME [epoch: 5.72 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026223346996655978		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.026223346996655978 | validation: 0.020638561737311836]
	TIME [epoch: 5.72 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023024809733165615		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.023024809733165615 | validation: 0.02705571143976544]
	TIME [epoch: 5.72 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0258595984111839		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.0258595984111839 | validation: 0.03251766310663088]
	TIME [epoch: 5.73 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028482940069187668		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.028482940069187668 | validation: 0.034050190713046685]
	TIME [epoch: 5.77 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03255946278086856		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.03255946278086856 | validation: 0.037936820495152665]
	TIME [epoch: 5.73 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030377717573568414		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.030377717573568414 | validation: 0.030728998989343052]
	TIME [epoch: 5.73 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03179312949952188		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.03179312949952188 | validation: 0.028613774081132956]
	TIME [epoch: 5.73 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025452439502642744		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.025452439502642744 | validation: 0.02734689574823741]
	TIME [epoch: 5.73 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02574227180338866		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.02574227180338866 | validation: 0.02371528590082298]
	TIME [epoch: 5.72 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02525993626378247		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.02525993626378247 | validation: 0.023991101668212604]
	TIME [epoch: 5.75 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028271795881462416		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.028271795881462416 | validation: 0.02442788308371802]
	TIME [epoch: 5.74 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02417295146981942		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.02417295146981942 | validation: 0.030270978581637437]
	TIME [epoch: 5.73 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024744616492324303		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.024744616492324303 | validation: 0.03137835466532035]
	TIME [epoch: 5.73 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025265431146796493		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.025265431146796493 | validation: 0.027059766737641038]
	TIME [epoch: 5.73 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024968890354547427		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.024968890354547427 | validation: 0.024954912835810552]
	TIME [epoch: 5.75 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022983691975034536		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.022983691975034536 | validation: 0.030015265522394252]
	TIME [epoch: 5.74 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02352264720650858		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.02352264720650858 | validation: 0.025543778951323672]
	TIME [epoch: 5.77 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025824861218505694		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.025824861218505694 | validation: 0.01880377229289745]
	TIME [epoch: 5.74 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028066649092760052		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.028066649092760052 | validation: 0.020057827220764587]
	TIME [epoch: 5.73 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025461747333199634		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.025461747333199634 | validation: 0.025157474489235325]
	TIME [epoch: 5.73 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025566026918893155		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.025566026918893155 | validation: 0.02024136505281165]
	TIME [epoch: 5.72 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024312873302640807		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.024312873302640807 | validation: 0.022279336510438796]
	TIME [epoch: 5.72 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020412535406209263		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.020412535406209263 | validation: 0.03047742066775617]
	TIME [epoch: 5.76 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021988525588716775		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.021988525588716775 | validation: 0.03097615103807785]
	TIME [epoch: 5.74 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021074279461833566		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.021074279461833566 | validation: 0.022556807902360084]
	TIME [epoch: 5.73 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022012004583154735		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.022012004583154735 | validation: 0.024357200525447147]
	TIME [epoch: 5.73 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02321237054335896		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.02321237054335896 | validation: 0.022540562285869196]
	TIME [epoch: 5.73 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026003777518050653		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.026003777518050653 | validation: 0.02372081408420348]
	TIME [epoch: 5.74 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03051374020824672		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.03051374020824672 | validation: 0.03371494998983652]
	TIME [epoch: 5.73 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027256475043755328		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.027256475043755328 | validation: 0.025434218551129487]
	TIME [epoch: 5.77 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028921564683194137		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.028921564683194137 | validation: 0.026122467786443514]
	TIME [epoch: 5.73 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02304527753709234		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.02304527753709234 | validation: 0.029377674986721756]
	TIME [epoch: 5.73 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021996494575416085		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.021996494575416085 | validation: 0.019157958518992303]
	TIME [epoch: 5.73 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0244709697739914		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.0244709697739914 | validation: 0.017189396315389623]
	TIME [epoch: 5.73 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02432070014192941		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.02432070014192941 | validation: 0.013309109755518656]
	TIME [epoch: 5.74 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030854802678312847		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.030854802678312847 | validation: 0.01802486491392516]
	TIME [epoch: 5.76 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029217686965991564		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.029217686965991564 | validation: 0.03262281066209716]
	TIME [epoch: 5.75 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026799162721865184		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.026799162721865184 | validation: 0.0196133062755376]
	TIME [epoch: 5.73 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025973928796534956		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.025973928796534956 | validation: 0.016723451635990125]
	TIME [epoch: 5.73 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02581881860358795		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.02581881860358795 | validation: 0.022340873791298482]
	TIME [epoch: 5.73 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01826612225702359		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.01826612225702359 | validation: 0.024194453227216757]
	TIME [epoch: 5.74 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023052360709088355		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.023052360709088355 | validation: 0.01973005181416341]
	TIME [epoch: 5.73 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02114186336755344		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.02114186336755344 | validation: 0.019530626471619694]
	TIME [epoch: 5.77 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02220089750189871		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.02220089750189871 | validation: 0.02735274218939872]
	TIME [epoch: 5.74 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020859138205561862		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.020859138205561862 | validation: 0.01654298015408256]
	TIME [epoch: 5.73 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02524226132403299		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.02524226132403299 | validation: 0.025244213077984315]
	TIME [epoch: 5.73 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020901057895564797		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.020901057895564797 | validation: 0.016744520328586136]
	TIME [epoch: 5.73 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021725206445348918		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.021725206445348918 | validation: 0.01981316957154401]
	TIME [epoch: 5.73 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02310057215787594		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.02310057215787594 | validation: 0.028118358056803138]
	TIME [epoch: 5.75 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024838138907894564		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.024838138907894564 | validation: 0.02270990782822268]
	TIME [epoch: 5.75 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022991328719854362		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.022991328719854362 | validation: 0.022775467720186463]
	TIME [epoch: 5.75 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024757426306342922		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.024757426306342922 | validation: 0.026657148957475875]
	TIME [epoch: 5.74 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02229489780629584		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.02229489780629584 | validation: 0.015235656762203571]
	TIME [epoch: 5.73 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027094584048872588		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.027094584048872588 | validation: 0.021799786084100582]
	TIME [epoch: 5.73 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025436428860606965		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.025436428860606965 | validation: 0.02428606846867408]
	TIME [epoch: 5.73 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02209628398568521		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.02209628398568521 | validation: 0.013535102488839067]
	TIME [epoch: 5.77 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025921483676746834		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.025921483676746834 | validation: 0.021054061824859704]
	TIME [epoch: 5.73 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023213918992237785		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.023213918992237785 | validation: 0.022074598289968782]
	TIME [epoch: 5.75 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020937699618909098		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.020937699618909098 | validation: 0.02759739893484458]
	TIME [epoch: 5.73 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023544793028094674		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.023544793028094674 | validation: 0.024062570432063914]
	TIME [epoch: 5.73 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02176408454738303		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.02176408454738303 | validation: 0.0220618388640238]
	TIME [epoch: 5.72 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027109626422571614		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.027109626422571614 | validation: 0.021597034287642352]
	TIME [epoch: 5.77 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024213694376342514		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.024213694376342514 | validation: 0.02816577139459696]
	TIME [epoch: 5.77 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027111416718661577		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.027111416718661577 | validation: 0.022835877110360833]
	TIME [epoch: 5.75 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021142568758659927		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.021142568758659927 | validation: 0.025888596301341077]
	TIME [epoch: 5.73 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02544949701911193		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.02544949701911193 | validation: 0.02082333985249845]
	TIME [epoch: 5.73 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02662187278199163		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.02662187278199163 | validation: 0.02741090140962027]
	TIME [epoch: 5.73 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026457764463106524		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.026457764463106524 | validation: 0.023175540270729954]
	TIME [epoch: 5.73 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023386934699475885		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.023386934699475885 | validation: 0.02293950314327634]
	TIME [epoch: 5.78 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023720023397265665		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.023720023397265665 | validation: 0.02231238777278886]
	TIME [epoch: 5.73 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022060744290035985		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.022060744290035985 | validation: 0.027553821984553677]
	TIME [epoch: 5.73 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02437159802356198		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.02437159802356198 | validation: 0.02784243535266243]
	TIME [epoch: 5.74 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02446469685240773		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.02446469685240773 | validation: 0.023764647403758225]
	TIME [epoch: 5.74 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026570076506493866		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.026570076506493866 | validation: 0.020351722272937006]
	TIME [epoch: 5.73 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02800023636180381		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.02800023636180381 | validation: 0.02948218003659467]
	TIME [epoch: 5.76 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02536290577269827		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.02536290577269827 | validation: 0.029445688096981195]
	TIME [epoch: 5.75 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02531550202647325		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.02531550202647325 | validation: 0.02194310460942326]
	TIME [epoch: 5.74 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025559897925191304		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.025559897925191304 | validation: 0.01880379150212782]
	TIME [epoch: 5.73 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02846385446752156		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.02846385446752156 | validation: 0.023553127943177495]
	TIME [epoch: 5.73 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027638757076709354		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.027638757076709354 | validation: 0.026057390676596136]
	TIME [epoch: 5.73 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030762101863402825		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.030762101863402825 | validation: 0.021422974746141313]
	TIME [epoch: 5.73 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02894039154792529		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.02894039154792529 | validation: 0.027283849495967294]
	TIME [epoch: 5.77 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027022966765825704		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.027022966765825704 | validation: 0.02000319086238314]
	TIME [epoch: 5.75 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02442448382986641		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.02442448382986641 | validation: 0.023334297542944533]
	TIME [epoch: 5.73 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025766876334343377		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.025766876334343377 | validation: 0.02001068189593329]
	TIME [epoch: 5.75 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024452760713463435		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.024452760713463435 | validation: 0.0237316128048138]
	TIME [epoch: 5.73 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027652044411472256		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.027652044411472256 | validation: 0.01940404298287764]
	TIME [epoch: 5.75 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023821370868811264		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.023821370868811264 | validation: 0.02526049012667752]
	TIME [epoch: 5.77 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023576270926815864		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.023576270926815864 | validation: 0.029654223962787177]
	TIME [epoch: 5.73 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022428736838661107		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.022428736838661107 | validation: 0.026001983244585487]
	TIME [epoch: 5.74 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025526587716876752		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.025526587716876752 | validation: 0.0187422896746718]
	TIME [epoch: 5.74 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02856215152494169		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.02856215152494169 | validation: 0.025965035396133925]
	TIME [epoch: 5.73 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023730963363918278		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.023730963363918278 | validation: 0.03025133611964595]
	TIME [epoch: 5.73 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02096680879655015		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.02096680879655015 | validation: 0.02678228226005468]
	TIME [epoch: 5.75 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02779100612581517		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.02779100612581517 | validation: 0.03115821524200598]
	TIME [epoch: 5.76 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025726093369349157		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.025726093369349157 | validation: 0.02163477014433071]
	TIME [epoch: 5.75 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026749166599959625		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.026749166599959625 | validation: 0.029883478455384242]
	TIME [epoch: 5.73 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025718012288938746		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.025718012288938746 | validation: 0.014291770951831909]
	TIME [epoch: 5.73 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02675642740144723		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.02675642740144723 | validation: 0.029919815388000776]
	TIME [epoch: 5.73 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027543911670904277		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.027543911670904277 | validation: 0.02663257604650334]
	TIME [epoch: 5.73 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025744996118219846		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.025744996118219846 | validation: 0.028924324326139506]
	TIME [epoch: 5.77 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023916897929648632		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.023916897929648632 | validation: 0.028744055928757752]
	TIME [epoch: 5.75 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024215392365633186		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.024215392365633186 | validation: 0.025365941369568865]
	TIME [epoch: 5.73 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024618308215571334		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.024618308215571334 | validation: 0.02532490301584559]
	TIME [epoch: 5.75 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025484833237889158		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.025484833237889158 | validation: 0.024729029544249718]
	TIME [epoch: 5.74 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023915082257112873		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.023915082257112873 | validation: 0.018762878740164454]
	TIME [epoch: 5.75 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023690124711255766		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.023690124711255766 | validation: 0.02322582493914709]
	TIME [epoch: 5.75 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024729150676636818		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.024729150676636818 | validation: 0.017027147705522428]
	TIME [epoch: 5.76 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025675342252061084		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.025675342252061084 | validation: 0.015367662237667156]
	TIME [epoch: 5.74 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022075846424639035		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.022075846424639035 | validation: 0.020141060519869854]
	TIME [epoch: 5.75 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022405635127581		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.022405635127581 | validation: 0.02865994997435828]
	TIME [epoch: 5.74 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021077572426930934		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.021077572426930934 | validation: 0.00836980517181143]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_1465.pth
	Model improved!!!
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022073576806472848		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.022073576806472848 | validation: 0.016553256145329237]
	TIME [epoch: 5.73 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025017028659053264		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.025017028659053264 | validation: 0.016215550885068673]
	TIME [epoch: 6.05 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02115708132909043		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.02115708132909043 | validation: 0.029010962816788152]
	TIME [epoch: 5.74 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022312178579290205		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.022312178579290205 | validation: 0.01578986286220897]
	TIME [epoch: 5.74 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022861749081739793		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.022861749081739793 | validation: 0.02081677040132439]
	TIME [epoch: 5.74 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0197007167020052		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.0197007167020052 | validation: 0.02312129978063441]
	TIME [epoch: 5.74 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024274940366539693		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.024274940366539693 | validation: 0.019895733558594985]
	TIME [epoch: 5.74 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020721799813064393		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.020721799813064393 | validation: 0.020127158580733454]
	TIME [epoch: 5.77 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023649537796096597		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.023649537796096597 | validation: 0.023279314573117386]
	TIME [epoch: 5.76 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021268046511343664		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.021268046511343664 | validation: 0.018179437803919278]
	TIME [epoch: 5.74 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02330049018364314		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.02330049018364314 | validation: 0.019893471871544787]
	TIME [epoch: 5.74 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0245234364898331		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.0245234364898331 | validation: 0.024410172266518124]
	TIME [epoch: 5.74 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02370647660053267		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.02370647660053267 | validation: 0.025977064308802835]
	TIME [epoch: 5.74 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023857009880307985		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.023857009880307985 | validation: 0.022021939920063786]
	TIME [epoch: 5.74 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020253042086800607		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.020253042086800607 | validation: 0.012630793744665159]
	TIME [epoch: 5.78 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017778356537204172		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.017778356537204172 | validation: 0.01997643279960665]
	TIME [epoch: 5.74 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024448775705180635		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.024448775705180635 | validation: 0.025977918760146074]
	TIME [epoch: 5.74 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023210941267088902		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.023210941267088902 | validation: 0.021092030299413707]
	TIME [epoch: 5.74 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021106626095352948		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.021106626095352948 | validation: 0.01818559903634603]
	TIME [epoch: 5.74 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025330540374115088		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.025330540374115088 | validation: 0.02102486351830202]
	TIME [epoch: 5.73 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02438758806800278		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.02438758806800278 | validation: 0.024228890379902817]
	TIME [epoch: 5.76 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02327145280127542		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.02327145280127542 | validation: 0.021282866699916282]
	TIME [epoch: 5.75 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017195378151836402		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.017195378151836402 | validation: 0.008287681170370112]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_1488.pth
	Model improved!!!
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021864891444504465		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.021864891444504465 | validation: 0.024490688366988964]
	TIME [epoch: 5.74 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02550620260214775		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.02550620260214775 | validation: 0.020226555503738194]
	TIME [epoch: 5.74 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027074607136443704		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.027074607136443704 | validation: 0.020945530603776605]
	TIME [epoch: 5.74 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02350823323407214		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.02350823323407214 | validation: 0.02530910690054157]
	TIME [epoch: 5.74 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022895925065347364		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.022895925065347364 | validation: 0.023675573311807106]
	TIME [epoch: 5.78 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024718859559845548		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.024718859559845548 | validation: 0.015555578212759226]
	TIME [epoch: 5.74 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0214335616625634		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.0214335616625634 | validation: 0.025499207026652867]
	TIME [epoch: 5.74 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019396333794109197		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.019396333794109197 | validation: 0.01982705116498826]
	TIME [epoch: 5.74 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02162986911864552		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.02162986911864552 | validation: 0.023979887948636768]
	TIME [epoch: 5.74 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01895989623137763		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.01895989623137763 | validation: 0.029767784782065893]
	TIME [epoch: 5.74 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024334669625897448		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.024334669625897448 | validation: 0.026725129736781508]
	TIME [epoch: 5.77 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021298671349633272		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.021298671349633272 | validation: 0.022851019996062566]
	TIME [epoch: 5.74 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023575792517354487		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.023575792517354487 | validation: 0.029358321661904614]
	TIME [epoch: 5.73 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024114597429584966		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.024114597429584966 | validation: 0.018766556586901535]
	TIME [epoch: 5.74 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02504302081101199		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.02504302081101199 | validation: 0.026703214293691328]
	TIME [epoch: 5.74 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025386395479139345		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.025386395479139345 | validation: 0.017495476960786127]
	TIME [epoch: 5.74 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02216234318987811		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.02216234318987811 | validation: 0.027007828397610317]
	TIME [epoch: 5.75 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021629337978461304		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.021629337978461304 | validation: 0.02465167697433553]
	TIME [epoch: 5.76 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025772345356255326		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.025772345356255326 | validation: 0.028757295728084564]
	TIME [epoch: 5.74 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025336275711906567		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.025336275711906567 | validation: 0.025186653901600055]
	TIME [epoch: 5.73 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025843272138340194		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.025843272138340194 | validation: 0.02490617471359104]
	TIME [epoch: 5.74 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023030013992688534		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.023030013992688534 | validation: 0.02189419856017798]
	TIME [epoch: 5.74 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022858703952763057		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.022858703952763057 | validation: 0.0215153199497432]
	TIME [epoch: 5.74 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023231284516748378		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.023231284516748378 | validation: 0.021347658979148917]
	TIME [epoch: 5.78 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022003436857521996		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.022003436857521996 | validation: 0.021883131088679144]
	TIME [epoch: 5.74 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021351765783827654		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.021351765783827654 | validation: 0.01882876288491021]
	TIME [epoch: 5.74 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022888297340359		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.022888297340359 | validation: 0.021344602885641262]
	TIME [epoch: 5.73 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023915711782158282		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.023915711782158282 | validation: 0.03021888917953401]
	TIME [epoch: 5.73 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019343475385491218		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.019343475385491218 | validation: 0.01654651025907764]
	TIME [epoch: 5.74 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020401865514744273		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.020401865514744273 | validation: 0.02740532016659085]
	TIME [epoch: 5.75 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019489251590286832		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.019489251590286832 | validation: 0.023855379401102134]
	TIME [epoch: 5.76 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024505875359644616		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.024505875359644616 | validation: 0.024557977838122743]
	TIME [epoch: 5.74 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024017988952124265		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.024017988952124265 | validation: 0.0242397619714912]
	TIME [epoch: 5.74 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021699871350097686		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.021699871350097686 | validation: 0.01461627483755147]
	TIME [epoch: 5.73 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019479891713700678		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.019479891713700678 | validation: 0.022825839014566435]
	TIME [epoch: 5.73 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019809930160268503		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.019809930160268503 | validation: 0.026899847679382766]
	TIME [epoch: 5.73 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02453951637361509		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.02453951637361509 | validation: 0.023031735611906346]
	TIME [epoch: 5.77 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024946081824491304		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.024946081824491304 | validation: 0.01817222546465161]
	TIME [epoch: 5.75 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023482603557498323		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.023482603557498323 | validation: 0.01878152276107546]
	TIME [epoch: 5.74 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02536266926357817		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.02536266926357817 | validation: 0.00997742359308567]
	TIME [epoch: 5.74 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022320581213621644		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.022320581213621644 | validation: 0.022814940916457967]
	TIME [epoch: 5.73 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022651479212907912		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.022651479212907912 | validation: 0.020243189529068003]
	TIME [epoch: 5.73 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02306742369720511		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.02306742369720511 | validation: 0.027392391602141648]
	TIME [epoch: 5.74 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022733680968630203		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.022733680968630203 | validation: 0.03343173599566778]
	TIME [epoch: 5.77 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018073127416592016		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.018073127416592016 | validation: 0.025580277017047785]
	TIME [epoch: 5.74 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020691482238912456		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.020691482238912456 | validation: 0.025495142659302507]
	TIME [epoch: 5.74 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026367798579172097		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.026367798579172097 | validation: 0.023211697397517314]
	TIME [epoch: 5.74 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02845313457831957		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.02845313457831957 | validation: 0.020982613547285783]
	TIME [epoch: 5.73 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02146175335461472		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.02146175335461472 | validation: 0.03164168715035592]
	TIME [epoch: 5.73 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023976042493335615		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.023976042493335615 | validation: 0.017141018813143387]
	TIME [epoch: 5.77 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02615597697184355		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.02615597697184355 | validation: 0.01905902349998219]
	TIME [epoch: 5.74 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0251128375303125		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.0251128375303125 | validation: 0.0231711617966688]
	TIME [epoch: 5.74 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024484872139136676		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.024484872139136676 | validation: 0.024484821456864942]
	TIME [epoch: 5.74 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021347481916576132		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.021347481916576132 | validation: 0.020125354626807056]
	TIME [epoch: 5.73 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025007542564491107		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.025007542564491107 | validation: 0.02234322719502667]
	TIME [epoch: 5.73 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0252553462884809		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.0252553462884809 | validation: 0.01971451119512321]
	TIME [epoch: 5.74 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021120475594887136		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.021120475594887136 | validation: 0.020020836863519947]
	TIME [epoch: 5.77 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022017269807276592		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.022017269807276592 | validation: 0.026090167302609723]
	TIME [epoch: 5.74 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02418060506764804		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.02418060506764804 | validation: 0.03663069421693305]
	TIME [epoch: 5.74 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023757047989633816		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.023757047989633816 | validation: 0.02664855941109896]
	TIME [epoch: 5.74 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029285796885048822		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.029285796885048822 | validation: 0.030156251583367617]
	TIME [epoch: 5.73 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026540599440934377		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.026540599440934377 | validation: 0.028358159838093266]
	TIME [epoch: 5.73 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028699607444704605		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.028699607444704605 | validation: 0.02952081079505194]
	TIME [epoch: 5.77 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02944134654287501		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.02944134654287501 | validation: 0.026171953081546764]
	TIME [epoch: 5.74 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03199850490868872		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.03199850490868872 | validation: 0.02999876356157776]
	TIME [epoch: 5.74 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028993017028626163		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.028993017028626163 | validation: 0.021683921615070736]
	TIME [epoch: 5.74 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030825753565923895		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.030825753565923895 | validation: 0.033856790931725673]
	TIME [epoch: 5.74 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027125003603436743		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.027125003603436743 | validation: 0.022834931625326575]
	TIME [epoch: 5.74 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029560056620691298		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.029560056620691298 | validation: 0.03425796094197286]
	TIME [epoch: 5.77 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0272242256245442		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.0272242256245442 | validation: 0.02606167200703426]
	TIME [epoch: 5.75 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02374160658297303		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.02374160658297303 | validation: 0.022274594158215474]
	TIME [epoch: 5.75 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02536238881325682		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.02536238881325682 | validation: 0.03239914013262966]
	TIME [epoch: 5.73 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027975566358690244		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.027975566358690244 | validation: 0.023446800883818952]
	TIME [epoch: 5.74 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02561363250271588		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.02561363250271588 | validation: 0.02753177633946662]
	TIME [epoch: 5.74 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02860716472643548		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.02860716472643548 | validation: 0.024503321548756677]
	TIME [epoch: 5.74 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02648068647194702		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.02648068647194702 | validation: 0.027425698955304334]
	TIME [epoch: 5.8 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030883644933356193		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.030883644933356193 | validation: 0.032668516919311295]
	TIME [epoch: 5.74 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03219833334668483		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.03219833334668483 | validation: 0.02117219543173194]
	TIME [epoch: 5.74 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02847012645393256		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.02847012645393256 | validation: 0.025274894636972554]
	TIME [epoch: 5.73 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026358270843919288		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.026358270843919288 | validation: 0.027112215146371566]
	TIME [epoch: 5.75 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02732689070736379		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.02732689070736379 | validation: 0.02490347918618596]
	TIME [epoch: 5.74 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024609820530765623		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.024609820530765623 | validation: 0.016634385417435223]
	TIME [epoch: 5.77 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02543864997466954		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.02543864997466954 | validation: 0.028017315844563767]
	TIME [epoch: 5.75 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023601118085938632		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.023601118085938632 | validation: 0.02714295722171184]
	TIME [epoch: 5.74 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022575620121069923		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.022575620121069923 | validation: 0.024715398338314203]
	TIME [epoch: 5.75 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024361018390833718		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.024361018390833718 | validation: 0.031629194429259704]
	TIME [epoch: 5.73 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02365321911177644		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.02365321911177644 | validation: 0.028309079163359438]
	TIME [epoch: 5.73 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024249353560491398		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.024249353560491398 | validation: 0.029966205594015083]
	TIME [epoch: 5.75 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02684181673039767		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.02684181673039767 | validation: 0.02597949158588738]
	TIME [epoch: 5.78 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02598708436604565		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.02598708436604565 | validation: 0.029494557980143304]
	TIME [epoch: 5.75 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019934384226680188		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.019934384226680188 | validation: 0.015068989515570065]
	TIME [epoch: 5.75 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023577479263178817		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.023577479263178817 | validation: 0.028405513213082212]
	TIME [epoch: 5.75 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022161133931382616		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.022161133931382616 | validation: 0.026184375437288285]
	TIME [epoch: 5.73 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021335346820984494		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.021335346820984494 | validation: 0.02370701779605097]
	TIME [epoch: 5.73 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023035684479387062		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.023035684479387062 | validation: 0.01577636377699892]
	TIME [epoch: 5.76 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024322614088171605		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.024322614088171605 | validation: 0.027746290934863353]
	TIME [epoch: 5.75 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022065876116574946		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.022065876116574946 | validation: 0.01473379639559274]
	TIME [epoch: 5.74 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021751745597625945		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.021751745597625945 | validation: 0.0242509350609093]
	TIME [epoch: 5.74 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01910712477715712		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.01910712477715712 | validation: 0.024627684484089578]
	TIME [epoch: 5.73 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022528351960086006		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.022528351960086006 | validation: 0.0257558646388033]
	TIME [epoch: 5.73 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025209919663787574		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.025209919663787574 | validation: 0.01934485953890774]
	TIME [epoch: 5.73 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02239376128587042		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.02239376128587042 | validation: 0.02056625274474609]
	TIME [epoch: 5.78 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02086997477402467		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.02086997477402467 | validation: 0.019881537217066016]
	TIME [epoch: 5.73 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02071241811166223		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.02071241811166223 | validation: 0.026786186240811083]
	TIME [epoch: 5.74 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02164725396956316		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.02164725396956316 | validation: 0.016104018787408275]
	TIME [epoch: 5.74 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02465101707231874		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.02465101707231874 | validation: 0.010523031355614066]
	TIME [epoch: 5.75 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018893277919566825		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.018893277919566825 | validation: 0.022653807909341572]
	TIME [epoch: 5.73 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021100195608352964		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.021100195608352964 | validation: 0.021594403950644808]
	TIME [epoch: 5.76 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020592728006449585		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.020592728006449585 | validation: 0.01738781034757089]
	TIME [epoch: 5.76 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022528291508520985		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.022528291508520985 | validation: 0.016501444785613634]
	TIME [epoch: 5.74 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019683739065677493		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.019683739065677493 | validation: 0.024950197411823846]
	TIME [epoch: 5.74 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021529629758506925		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.021529629758506925 | validation: 0.022199998018009977]
	TIME [epoch: 5.75 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02227200610737595		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.02227200610737595 | validation: 0.01881963010583699]
	TIME [epoch: 5.73 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021965200688570743		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.021965200688570743 | validation: 0.015141892103058456]
	TIME [epoch: 5.74 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01825859142536211		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.01825859142536211 | validation: 0.019996213527816067]
	TIME [epoch: 5.77 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020779485809388355		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.020779485809388355 | validation: 0.01983202301790453]
	TIME [epoch: 5.75 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024588876881544472		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.024588876881544472 | validation: 0.013833541403763333]
	TIME [epoch: 5.74 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025842395400253612		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.025842395400253612 | validation: 0.023068600974498255]
	TIME [epoch: 5.75 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02186085254095819		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.02186085254095819 | validation: 0.02140798444039758]
	TIME [epoch: 5.73 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024078189265683208		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.024078189265683208 | validation: 0.020154317991195273]
	TIME [epoch: 5.74 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02645025754071076		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.02645025754071076 | validation: 0.027609780710694785]
	TIME [epoch: 5.76 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022567304949393383		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.022567304949393383 | validation: 0.022357170507393737]
	TIME [epoch: 5.74 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023263131527361338		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.023263131527361338 | validation: 0.027524096046405173]
	TIME [epoch: 5.74 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02193612814543936		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.02193612814543936 | validation: 0.01714573679914599]
	TIME [epoch: 5.73 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019754835677554518		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.019754835677554518 | validation: 0.021805181505282444]
	TIME [epoch: 5.74 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02232776969003504		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.02232776969003504 | validation: 0.014017139311594715]
	TIME [epoch: 5.73 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022950265400795686		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.022950265400795686 | validation: 0.01637592406226676]
	TIME [epoch: 5.76 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021419957177927745		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.021419957177927745 | validation: 0.02836919140211841]
	TIME [epoch: 5.77 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022481141706880543		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.022481141706880543 | validation: 0.022134822045020954]
	TIME [epoch: 5.74 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024250196343784166		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.024250196343784166 | validation: 0.02316270155583952]
	TIME [epoch: 5.74 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024034382488296698		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.024034382488296698 | validation: 0.013813342726697113]
	TIME [epoch: 5.75 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02135991257617758		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.02135991257617758 | validation: 0.023098479158183007]
	TIME [epoch: 5.73 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02259129703241443		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.02259129703241443 | validation: 0.021212140375638892]
	TIME [epoch: 5.74 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02135143984906757		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.02135143984906757 | validation: 0.026627405933878842]
	TIME [epoch: 5.77 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022243182709283278		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.022243182709283278 | validation: 0.022182426137614036]
	TIME [epoch: 5.73 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021966649901912088		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.021966649901912088 | validation: 0.014267940799528311]
	TIME [epoch: 5.73 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022847407603060574		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.022847407603060574 | validation: 0.02050377511659332]
	TIME [epoch: 5.73 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027456467820211057		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.027456467820211057 | validation: 0.01890351351629942]
	TIME [epoch: 5.74 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024138474292182074		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.024138474292182074 | validation: 0.0263482891298913]
	TIME [epoch: 5.74 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025102521074881246		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.025102521074881246 | validation: 0.015493409770521835]
	TIME [epoch: 5.75 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023282342738717144		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.023282342738717144 | validation: 0.017112963920174234]
	TIME [epoch: 5.75 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02643595488780816		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.02643595488780816 | validation: 0.01636072609180829]
	TIME [epoch: 5.74 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02477235782224089		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.02477235782224089 | validation: 0.02069279601127904]
	TIME [epoch: 5.73 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023698537228550677		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.023698537228550677 | validation: 0.025869358120801548]
	TIME [epoch: 5.73 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02338335491654425		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.02338335491654425 | validation: 0.016037645525084587]
	TIME [epoch: 5.74 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023328733267180393		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.023328733267180393 | validation: 0.026284756558514744]
	TIME [epoch: 5.74 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022440085772438095		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.022440085772438095 | validation: 0.022132511321648975]
	TIME [epoch: 5.77 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024613599632193017		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.024613599632193017 | validation: 0.020790168734884703]
	TIME [epoch: 5.74 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0220648044650413		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.0220648044650413 | validation: 0.022240379783139374]
	TIME [epoch: 5.73 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024518258847981457		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.024518258847981457 | validation: 0.017819693172612762]
	TIME [epoch: 5.73 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02210951866731081		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.02210951866731081 | validation: 0.01904136167721254]
	TIME [epoch: 5.74 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019097429027995827		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.019097429027995827 | validation: 0.017904096858752782]
	TIME [epoch: 5.74 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019875645609066996		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.019875645609066996 | validation: 0.02086861647513722]
	TIME [epoch: 5.74 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022429981125444073		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.022429981125444073 | validation: 0.023259715325915892]
	TIME [epoch: 5.78 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02115044548861517		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.02115044548861517 | validation: 0.020951339143055147]
	TIME [epoch: 5.74 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019832007856878636		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.019832007856878636 | validation: 0.023024140152183858]
	TIME [epoch: 5.74 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021829591199203906		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.021829591199203906 | validation: 0.01743015927272648]
	TIME [epoch: 5.73 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021598894109165358		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.021598894109165358 | validation: 0.017101853084295793]
	TIME [epoch: 5.75 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02238811522102438		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.02238811522102438 | validation: 0.023466599695764423]
	TIME [epoch: 5.74 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01896846672078529		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.01896846672078529 | validation: 0.024761836972747055]
	TIME [epoch: 5.77 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024403241598555617		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.024403241598555617 | validation: 0.015151389673302531]
	TIME [epoch: 5.75 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025772926975836156		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.025772926975836156 | validation: 0.015119359442065345]
	TIME [epoch: 5.73 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020113799405665538		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.020113799405665538 | validation: 0.03017482700693124]
	TIME [epoch: 5.73 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02345864383083108		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.02345864383083108 | validation: 0.03171891767781279]
	TIME [epoch: 5.73 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0241623988705923		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.0241623988705923 | validation: 0.02817695907182502]
	TIME [epoch: 5.73 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025260467699126096		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.025260467699126096 | validation: 0.02136774583257128]
	TIME [epoch: 5.75 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02369020216651482		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.02369020216651482 | validation: 0.017838373279315253]
	TIME [epoch: 5.77 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026071718484012872		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.026071718484012872 | validation: 0.02643732600721555]
	TIME [epoch: 5.74 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023326325777447227		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.023326325777447227 | validation: 0.02857226456448988]
	TIME [epoch: 5.74 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022094344260256762		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.022094344260256762 | validation: 0.017741295851509402]
	TIME [epoch: 5.73 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020125953588101403		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.020125953588101403 | validation: 0.019897334902007412]
	TIME [epoch: 5.73 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019706937457284628		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.019706937457284628 | validation: 0.01859068567787172]
	TIME [epoch: 5.73 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02198945381160777		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.02198945381160777 | validation: 0.02998854285073434]
	TIME [epoch: 5.77 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02534923650791565		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.02534923650791565 | validation: 0.025550556339740217]
	TIME [epoch: 5.73 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022478167203790575		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.022478167203790575 | validation: 0.025412315546202095]
	TIME [epoch: 5.73 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018567364035561508		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.018567364035561508 | validation: 0.02516875680786675]
	TIME [epoch: 5.73 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0227834221903704		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.0227834221903704 | validation: 0.0185795539753133]
	TIME [epoch: 5.73 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022484828724463956		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.022484828724463956 | validation: 0.018341939279277752]
	TIME [epoch: 5.73 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021681894217076746		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.021681894217076746 | validation: 0.02035224145270694]
	TIME [epoch: 5.75 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021589810207945207		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.021589810207945207 | validation: 0.021205978213490212]
	TIME [epoch: 5.74 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01986256447188776		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.01986256447188776 | validation: 0.019260301735964346]
	TIME [epoch: 5.73 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022359868919492615		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.022359868919492615 | validation: 0.025784203296700833]
	TIME [epoch: 5.73 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025479902246046876		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.025479902246046876 | validation: 0.024252959480151676]
	TIME [epoch: 5.73 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02244307242049386		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.02244307242049386 | validation: 0.007201690077156275]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240310_003040/states/model_tr_study2_1672.pth
	Model improved!!!
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020834933135736592		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.020834933135736592 | validation: 0.018658363088997276]
	TIME [epoch: 5.73 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021832559158779442		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.021832559158779442 | validation: 0.016794306012068154]
	TIME [epoch: 5.77 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021935495256683618		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.021935495256683618 | validation: 0.021295934791518558]
	TIME [epoch: 5.74 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02467656629887976		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.02467656629887976 | validation: 0.023440729028246912]
	TIME [epoch: 5.73 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024632258344998246		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.024632258344998246 | validation: 0.02032181070630247]
	TIME [epoch: 5.73 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024894613174093833		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.024894613174093833 | validation: 0.019659708514613756]
	TIME [epoch: 5.73 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02472551327460117		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.02472551327460117 | validation: 0.020639622867781895]
	TIME [epoch: 5.73 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02341710032127555		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.02341710032127555 | validation: 0.028215667325304564]
	TIME [epoch: 5.76 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02354569417499238		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.02354569417499238 | validation: 0.01643187945427879]
	TIME [epoch: 5.74 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021733932766768767		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.021733932766768767 | validation: 0.009405286442829992]
	TIME [epoch: 5.74 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02375198235606493		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.02375198235606493 | validation: 0.021489869298394908]
	TIME [epoch: 5.74 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021324937157216887		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.021324937157216887 | validation: 0.021745886611267987]
	TIME [epoch: 5.74 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0204617790326454		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.0204617790326454 | validation: 0.0186825542113384]
	TIME [epoch: 5.73 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026242009382370958		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.026242009382370958 | validation: 0.02521585269102901]
	TIME [epoch: 5.74 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022764416458241142		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.022764416458241142 | validation: 0.023206358256676888]
	TIME [epoch: 5.77 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022319282824768475		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.022319282824768475 | validation: 0.022935147315144004]
	TIME [epoch: 5.73 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022953912145171364		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.022953912145171364 | validation: 0.026391121467225977]
	TIME [epoch: 5.73 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02325140595053582		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.02325140595053582 | validation: 0.026100713538287863]
	TIME [epoch: 5.73 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019546860539337744		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.019546860539337744 | validation: 0.01661176770558401]
	TIME [epoch: 5.73 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021849587866024013		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.021849587866024013 | validation: 0.017566424677180354]
	TIME [epoch: 5.75 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022775132172291306		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.022775132172291306 | validation: 0.020532211082421054]
	TIME [epoch: 5.79 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023402905677128497		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.023402905677128497 | validation: 0.02593124476366209]
	TIME [epoch: 5.75 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02227061511670456		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.02227061511670456 | validation: 0.026200803927968672]
	TIME [epoch: 5.75 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021587441263945406		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.021587441263945406 | validation: 0.011865288634636052]
	TIME [epoch: 5.75 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022184232799221902		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.022184232799221902 | validation: 0.015901376976201743]
	TIME [epoch: 5.75 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023838176627081962		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.023838176627081962 | validation: 0.022185655364448744]
	TIME [epoch: 5.75 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018151114445657267		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.018151114445657267 | validation: 0.01950933120496761]
	TIME [epoch: 5.76 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024428943576732698		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.024428943576732698 | validation: 0.02036673459629448]
	TIME [epoch: 5.77 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023381120663165906		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.023381120663165906 | validation: 0.027092992937119274]
	TIME [epoch: 5.75 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021947634651301902		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.021947634651301902 | validation: 0.02217067641884044]
	TIME [epoch: 5.75 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021589444745670067		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.021589444745670067 | validation: 0.019720396417668956]
	TIME [epoch: 5.76 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020913291980357733		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.020913291980357733 | validation: 0.019503462386510195]
	TIME [epoch: 5.74 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02006890368293738		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.02006890368293738 | validation: 0.019049041503086547]
	TIME [epoch: 5.75 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02013868993029917		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.02013868993029917 | validation: 0.01872434050758714]
	TIME [epoch: 5.77 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02059486533424584		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.02059486533424584 | validation: 0.01948905598285061]
	TIME [epoch: 5.76 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02349833935097425		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.02349833935097425 | validation: 0.02748764126754881]
	TIME [epoch: 5.75 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022751604274743233		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.022751604274743233 | validation: 0.018985159781056863]
	TIME [epoch: 5.74 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02141341270717927		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.02141341270717927 | validation: 0.024224620668154798]
	TIME [epoch: 5.74 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01831581640759622		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.01831581640759622 | validation: 0.025447836405388797]
	TIME [epoch: 5.75 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020485819833342758		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.020485819833342758 | validation: 0.018694267804099832]
	TIME [epoch: 5.75 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024036203109861463		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.024036203109861463 | validation: 0.02209249777501537]
	TIME [epoch: 5.77 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02133547417947492		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.02133547417947492 | validation: 0.017783794356676815]
	TIME [epoch: 5.75 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023800087297615548		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.023800087297615548 | validation: 0.020087132029290976]
	TIME [epoch: 5.75 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022171146324213117		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.022171146324213117 | validation: 0.014945262827557615]
	TIME [epoch: 5.75 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020833056224901128		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.020833056224901128 | validation: 0.02311435358711135]
	TIME [epoch: 5.74 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024922206893854316		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.024922206893854316 | validation: 0.01637568416760985]
	TIME [epoch: 5.74 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02254004122278002		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.02254004122278002 | validation: 0.025361393734257564]
	TIME [epoch: 5.77 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024667287290825457		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.024667287290825457 | validation: 0.024301483781062436]
	TIME [epoch: 5.73 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024268098171786785		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.024268098171786785 | validation: 0.028163658802603814]
	TIME [epoch: 5.73 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021900409428784837		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.021900409428784837 | validation: 0.016672899225155764]
	TIME [epoch: 5.73 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018629312526242475		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.018629312526242475 | validation: 0.022340138267027392]
	TIME [epoch: 5.73 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020562147572513907		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.020562147572513907 | validation: 0.023867330612327643]
	TIME [epoch: 5.73 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019295239180461964		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.019295239180461964 | validation: 0.016200145906352447]
	TIME [epoch: 5.75 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02335648442966347		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.02335648442966347 | validation: 0.02642751239966745]
	TIME [epoch: 5.75 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023401208433314016		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.023401208433314016 | validation: 0.019050438114789032]
	TIME [epoch: 5.73 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02098182665898026		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.02098182665898026 | validation: 0.020548950158400123]
	TIME [epoch: 5.73 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022530694807395203		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.022530694807395203 | validation: 0.01949969439499077]
	TIME [epoch: 5.74 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022336555368710327		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.022336555368710327 | validation: 0.019408157800222696]
	TIME [epoch: 5.73 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017711902692540537		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.017711902692540537 | validation: 0.02369521454973265]
	TIME [epoch: 5.74 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024068293448215546		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.024068293448215546 | validation: 0.014569524321458508]
	TIME [epoch: 5.76 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020950382457198588		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.020950382457198588 | validation: 0.024192473355734156]
	TIME [epoch: 5.75 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022789096193761908		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.022789096193761908 | validation: 0.01844828995863371]
	TIME [epoch: 5.74 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020998075975425693		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.020998075975425693 | validation: 0.025002742174000996]
	TIME [epoch: 5.74 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022340020572058736		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.022340020572058736 | validation: 0.028536764439525172]
	TIME [epoch: 5.74 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02387742483860152		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.02387742483860152 | validation: 0.027673461039502315]
	TIME [epoch: 5.75 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022093485667140592		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.022093485667140592 | validation: 0.017453151650686942]
	TIME [epoch: 5.77 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02028316974143439		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.02028316974143439 | validation: 0.010696094666338899]
	TIME [epoch: 5.74 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02291728141220875		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.02291728141220875 | validation: 0.015234594925307104]
	TIME [epoch: 5.74 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021775989643033383		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.021775989643033383 | validation: 0.020963969012842615]
	TIME [epoch: 5.74 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023237911536293773		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.023237911536293773 | validation: 0.026255295864032663]
	TIME [epoch: 5.73 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016506946162891778		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.016506946162891778 | validation: 0.025661193231681922]
	TIME [epoch: 5.72 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02070157095816451		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.02070157095816451 | validation: 0.026155519308792296]
	TIME [epoch: 5.74 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021110414773915467		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.021110414773915467 | validation: 0.026267260869914454]
	TIME [epoch: 5.77 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021704302065762706		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.021704302065762706 | validation: 0.014699146695914402]
	TIME [epoch: 5.74 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023650518544300086		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.023650518544300086 | validation: 0.016401115883485088]
	TIME [epoch: 5.74 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020659782674906264		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.020659782674906264 | validation: 0.025996343235961086]
	TIME [epoch: 5.74 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019511606454264176		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.019511606454264176 | validation: 0.022592579203399975]
	TIME [epoch: 5.72 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0211007933775905		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.0211007933775905 | validation: 0.017817476667157894]
	TIME [epoch: 5.74 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022003218998971636		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.022003218998971636 | validation: 0.026688878244066388]
	TIME [epoch: 5.77 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0200280969595523		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.0200280969595523 | validation: 0.01809101359108975]
	TIME [epoch: 5.76 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019185860483439038		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.019185860483439038 | validation: 0.021553163766372233]
	TIME [epoch: 5.75 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01871465741797439		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.01871465741797439 | validation: 0.022511351784678828]
	TIME [epoch: 5.74 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02195235739709138		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.02195235739709138 | validation: 0.02009870224318794]
	TIME [epoch: 5.73 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023658927974183567		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.023658927974183567 | validation: 0.022699012936865933]
	TIME [epoch: 5.74 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020589718876309993		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.020589718876309993 | validation: 0.014878417726629723]
	TIME [epoch: 5.74 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020351302429647763		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.020351302429647763 | validation: 0.020802151777904197]
	TIME [epoch: 5.77 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021842175133832048		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.021842175133832048 | validation: 0.024431868712419296]
	TIME [epoch: 5.73 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022686344225563437		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.022686344225563437 | validation: 0.022204592349188937]
	TIME [epoch: 5.72 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026273448528922178		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.026273448528922178 | validation: 0.02594975920542491]
	TIME [epoch: 5.73 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024222539049095763		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.024222539049095763 | validation: 0.01918739912244498]
	TIME [epoch: 5.75 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018464473482687253		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.018464473482687253 | validation: 0.017696310406002672]
	TIME [epoch: 5.74 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024460070991518732		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.024460070991518732 | validation: 0.014761583092859035]
	TIME [epoch: 5.75 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018887144637166498		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.018887144637166498 | validation: 0.024394421443313493]
	TIME [epoch: 5.75 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018532412070319804		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.018532412070319804 | validation: 0.025480733344045072]
	TIME [epoch: 5.74 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019712197792690782		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.019712197792690782 | validation: 0.019011716197299376]
	TIME [epoch: 5.74 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025134944856728444		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.025134944856728444 | validation: 0.017720766441937073]
	TIME [epoch: 5.73 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02170346507348006		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.02170346507348006 | validation: 0.021611931377401188]
	TIME [epoch: 5.73 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01922806998770594		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.01922806998770594 | validation: 0.021318364143186042]
	TIME [epoch: 5.73 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022427695560064805		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.022427695560064805 | validation: 0.018340106571322713]
	TIME [epoch: 5.77 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02059132712517736		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.02059132712517736 | validation: 0.024173622790858298]
	TIME [epoch: 5.73 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022496256592931377		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.022496256592931377 | validation: 0.02012597806267112]
	TIME [epoch: 5.74 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023004978876209763		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.023004978876209763 | validation: 0.025347687411475268]
	TIME [epoch: 5.73 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020443255298927775		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.020443255298927775 | validation: 0.022290889986331486]
	TIME [epoch: 5.75 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023810533532058205		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.023810533532058205 | validation: 0.017843267870714406]
	TIME [epoch: 5.74 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023174954923870505		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.023174954923870505 | validation: 0.020912982949910702]
	TIME [epoch: 5.78 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02272953463825251		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.02272953463825251 | validation: 0.017727874444794903]
	TIME [epoch: 5.74 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022478801523123433		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.022478801523123433 | validation: 0.016627185025996673]
	TIME [epoch: 5.73 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020490798185328434		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.020490798185328434 | validation: 0.02163598143992622]
	TIME [epoch: 5.73 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024095993548099222		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.024095993548099222 | validation: 0.025018396488653467]
	TIME [epoch: 5.73 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020739640496466327		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.020739640496466327 | validation: 0.02178639289875428]
	TIME [epoch: 5.74 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022607514826399108		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.022607514826399108 | validation: 0.023289385033161757]
	TIME [epoch: 5.74 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020679544209773346		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.020679544209773346 | validation: 0.01684827971603189]
	TIME [epoch: 5.78 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020015768870222043		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.020015768870222043 | validation: 0.018992239706321298]
	TIME [epoch: 5.74 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024206880831000623		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.024206880831000623 | validation: 0.011739391657788563]
	TIME [epoch: 5.74 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020009044037007123		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.020009044037007123 | validation: 0.018884172208806213]
	TIME [epoch: 5.74 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024669803308824005		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.024669803308824005 | validation: 0.02262824148892579]
	TIME [epoch: 5.75 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022383544487905145		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.022383544487905145 | validation: 0.02131640335146656]
	TIME [epoch: 5.73 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025506279912039336		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.025506279912039336 | validation: 0.017141994246381822]
	TIME [epoch: 5.78 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020827265339388213		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.020827265339388213 | validation: 0.022797475657905023]
	TIME [epoch: 5.75 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024062302243351805		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.024062302243351805 | validation: 0.02803243454565015]
	TIME [epoch: 5.74 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02389419479667477		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.02389419479667477 | validation: 0.020154787115934977]
	TIME [epoch: 5.75 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02122441702272132		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.02122441702272132 | validation: 0.021741635501816927]
	TIME [epoch: 5.75 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023554812447668584		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.023554812447668584 | validation: 0.017491829574350845]
	TIME [epoch: 5.75 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023925887582487145		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.023925887582487145 | validation: 0.016429205135935883]
	TIME [epoch: 5.74 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022299618900944344		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.022299618900944344 | validation: 0.015273997020447903]
	TIME [epoch: 5.76 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02278999720884789		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.02278999720884789 | validation: 0.027268776105835016]
	TIME [epoch: 5.75 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018867133574164426		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.018867133574164426 | validation: 0.018446014866366885]
	TIME [epoch: 5.75 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0229832434263086		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.0229832434263086 | validation: 0.020611678227052406]
	TIME [epoch: 5.75 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02418204573830195		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.02418204573830195 | validation: 0.021561197720173286]
	TIME [epoch: 5.75 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018877102962145953		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.018877102962145953 | validation: 0.013395254162475447]
	TIME [epoch: 5.75 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02152680482920913		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.02152680482920913 | validation: 0.016532119802587116]
	TIME [epoch: 5.79 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022275054631234078		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.022275054631234078 | validation: 0.02358222544685037]
	TIME [epoch: 5.76 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022937925632546055		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.022937925632546055 | validation: 0.022277117068973343]
	TIME [epoch: 5.74 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019337279748424432		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.019337279748424432 | validation: 0.01036078768483897]
	TIME [epoch: 5.74 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021973113372889423		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.021973113372889423 | validation: 0.023094063522666054]
	TIME [epoch: 5.73 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018671079702953182		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.018671079702953182 | validation: 0.024430209532081314]
	TIME [epoch: 5.74 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023228260069222746		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.023228260069222746 | validation: 0.016629351902245366]
	TIME [epoch: 5.76 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022196348474114194		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.022196348474114194 | validation: 0.016502235335119388]
	TIME [epoch: 5.78 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02668670681354591		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.02668670681354591 | validation: 0.018826241901953346]
	TIME [epoch: 5.74 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021176574865737666		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.021176574865737666 | validation: 0.018198729855905166]
	TIME [epoch: 5.75 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02220836928376135		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.02220836928376135 | validation: 0.016596534904340807]
	TIME [epoch: 5.74 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02214640597383229		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.02214640597383229 | validation: 0.016713300011167415]
	TIME [epoch: 5.75 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021574968580480133		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.021574968580480133 | validation: 0.022292651160489337]
	TIME [epoch: 5.73 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025935721355335457		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.025935721355335457 | validation: 0.029598823047737165]
	TIME [epoch: 5.77 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024879789763946336		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.024879789763946336 | validation: 0.021426525936645006]
	TIME [epoch: 5.74 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020191128714322888		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.020191128714322888 | validation: 0.016132337551839408]
	TIME [epoch: 5.73 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02252377129242573		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.02252377129242573 | validation: 0.01727028295989311]
	TIME [epoch: 5.73 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021186019580689053		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.021186019580689053 | validation: 0.027097275126611243]
	TIME [epoch: 5.73 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017265194905421787		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.017265194905421787 | validation: 0.014416991746537879]
	TIME [epoch: 5.73 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02322411552990492		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.02322411552990492 | validation: 0.01728889421574579]
	TIME [epoch: 5.75 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022361035438487234		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.022361035438487234 | validation: 0.023354910199658675]
	TIME [epoch: 5.76 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02302816901261024		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.02302816901261024 | validation: 0.029723620655599758]
	TIME [epoch: 5.74 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02057737651317916		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.02057737651317916 | validation: 0.013775891598462958]
	TIME [epoch: 5.73 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018489775080501477		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.018489775080501477 | validation: 0.020280636614489343]
	TIME [epoch: 5.75 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02540855183564987		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.02540855183564987 | validation: 0.02384305701318364]
	TIME [epoch: 5.73 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02162511449974755		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.02162511449974755 | validation: 0.024459275513740195]
	TIME [epoch: 5.73 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023747050888504435		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.023747050888504435 | validation: 0.01785129909597491]
	TIME [epoch: 5.77 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021411835035051736		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.021411835035051736 | validation: 0.01730305764925321]
	TIME [epoch: 5.73 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01912159673260652		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.01912159673260652 | validation: 0.024527984493224287]
	TIME [epoch: 5.73 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019510058062285472		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.019510058062285472 | validation: 0.02713671272242351]
	TIME [epoch: 5.73 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022180506359669165		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.022180506359669165 | validation: 0.022169694831849253]
	TIME [epoch: 5.73 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02133055023659318		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.02133055023659318 | validation: 0.012206341817048789]
	TIME [epoch: 5.73 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023416229766714203		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.023416229766714203 | validation: 0.017294374038118697]
	TIME [epoch: 5.78 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02223102070595685		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.02223102070595685 | validation: 0.01666378161455029]
	TIME [epoch: 5.74 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023244277764341955		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.023244277764341955 | validation: 0.023857824172904957]
	TIME [epoch: 5.72 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021845310284013188		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.021845310284013188 | validation: 0.016470135789024735]
	TIME [epoch: 5.72 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023544226410151185		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.023544226410151185 | validation: 0.02115093442635696]
	TIME [epoch: 5.72 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019717177365605517		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.019717177365605517 | validation: 0.018795938875859414]
	TIME [epoch: 5.74 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021935908503465842		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.021935908503465842 | validation: 0.03167832440746666]
	TIME [epoch: 5.73 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02575718767035169		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.02575718767035169 | validation: 0.02723782249215039]
	TIME [epoch: 5.78 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020817408789076314		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.020817408789076314 | validation: 0.026474154986214398]
	TIME [epoch: 5.75 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020693765896445285		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.020693765896445285 | validation: 0.024018769499877753]
	TIME [epoch: 5.74 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02421484199414867		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.02421484199414867 | validation: 0.017968071756895392]
	TIME [epoch: 5.73 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022211597754531943		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.022211597754531943 | validation: 0.02778045464275664]
	TIME [epoch: 5.73 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01950386173300725		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.01950386173300725 | validation: 0.02264182090234594]
	TIME [epoch: 5.74 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021449083695967062		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.021449083695967062 | validation: 0.026419855667159525]
	TIME [epoch: 5.76 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023435954340484108		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.023435954340484108 | validation: 0.024774501740699787]
	TIME [epoch: 5.74 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022559876864115324		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.022559876864115324 | validation: 0.021265559729044425]
	TIME [epoch: 5.74 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021171999309775345		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.021171999309775345 | validation: 0.018584112357808297]
	TIME [epoch: 5.73 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02101752335103504		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.02101752335103504 | validation: 0.015896548456013168]
	TIME [epoch: 5.74 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02232474255747841		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.02232474255747841 | validation: 0.01783378118733278]
	TIME [epoch: 5.73 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02346684721724076		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.02346684721724076 | validation: 0.01988077078606359]
	TIME [epoch: 5.74 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020121238108022844		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.020121238108022844 | validation: 0.023522677775922193]
	TIME [epoch: 5.79 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021560538724190625		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.021560538724190625 | validation: 0.019628409075312353]
	TIME [epoch: 5.74 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021962868756589		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.021962868756589 | validation: 0.024505771757620358]
	TIME [epoch: 5.74 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023078999229833155		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.023078999229833155 | validation: 0.03128737290393338]
	TIME [epoch: 5.73 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019638778494381136		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.019638778494381136 | validation: 0.02718552454600648]
	TIME [epoch: 5.73 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023043286027511954		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.023043286027511954 | validation: 0.01675107851140519]
	TIME [epoch: 5.73 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02077792351463536		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.02077792351463536 | validation: 0.02726026022474965]
	TIME [epoch: 5.78 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02145952477449447		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.02145952477449447 | validation: 0.02731416034612276]
	TIME [epoch: 5.76 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020136555736284038		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.020136555736284038 | validation: 0.016562832532723577]
	TIME [epoch: 5.73 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025130220825673722		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.025130220825673722 | validation: 0.01968162418522861]
	TIME [epoch: 5.74 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019747939031899753		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.019747939031899753 | validation: 0.02501123848967934]
	TIME [epoch: 5.74 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02045497206363588		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.02045497206363588 | validation: 0.021066214974012634]
	TIME [epoch: 5.73 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017513323975608598		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.017513323975608598 | validation: 0.026380519801662505]
	TIME [epoch: 5.73 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021398068469575923		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.021398068469575923 | validation: 0.021920701090666874]
	TIME [epoch: 5.78 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022467479441609477		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.022467479441609477 | validation: 0.02399274687735881]
	TIME [epoch: 5.73 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02265142534808754		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.02265142534808754 | validation: 0.023221572721221242]
	TIME [epoch: 5.74 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02424800840508137		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.02424800840508137 | validation: 0.015118205239736553]
	TIME [epoch: 5.74 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02389886366629542		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.02389886366629542 | validation: 0.02228607115714216]
	TIME [epoch: 5.74 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018755989743990367		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.018755989743990367 | validation: 0.0221689890199018]
	TIME [epoch: 5.75 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02102641990926422		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.02102641990926422 | validation: 0.022092447516811907]
	TIME [epoch: 5.77 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020030455413963075		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.020030455413963075 | validation: 0.02888589945492197]
	TIME [epoch: 5.73 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02247300493501575		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.02247300493501575 | validation: 0.015916206768446076]
	TIME [epoch: 5.73 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019698159912779616		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.019698159912779616 | validation: 0.02290041225203999]
	TIME [epoch: 5.74 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021000030930452124		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.021000030930452124 | validation: 0.03152915445116888]
	TIME [epoch: 5.74 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01948830828971867		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.01948830828971867 | validation: 0.02143383489674484]
	TIME [epoch: 5.73 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0196304054908932		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.0196304054908932 | validation: 0.0212561192304047]
	TIME [epoch: 5.76 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016658533365563912		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.016658533365563912 | validation: 0.022638358519642826]
	TIME [epoch: 5.77 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021602904021941212		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.021602904021941212 | validation: 0.018688286316119976]
	TIME [epoch: 5.73 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018468093955406276		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.018468093955406276 | validation: 0.027999798069613734]
	TIME [epoch: 5.75 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019946314306402604		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.019946314306402604 | validation: 0.020657703505115223]
	TIME [epoch: 5.74 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019728410861454507		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.019728410861454507 | validation: 0.018102678688815082]
	TIME [epoch: 5.73 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023109764890464866		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.023109764890464866 | validation: 0.02753208638846445]
	TIME [epoch: 5.74 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022645172736885197		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.022645172736885197 | validation: 0.024142008326993883]
	TIME [epoch: 5.77 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022763702606860798		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.022763702606860798 | validation: 0.0230015824429432]
	TIME [epoch: 5.74 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020644528407042735		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.020644528407042735 | validation: 0.01967802579498403]
	TIME [epoch: 5.74 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020352301137445614		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.020352301137445614 | validation: 0.01721858221439677]
	TIME [epoch: 5.74 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021897138934487477		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.021897138934487477 | validation: 0.02312767177357068]
	TIME [epoch: 5.74 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020180955948540545		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.020180955948540545 | validation: 0.028314150755598157]
	TIME [epoch: 5.73 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019442281326244502		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.019442281326244502 | validation: 0.023506692747132255]
	TIME [epoch: 5.75 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021311034956425213		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.021311034956425213 | validation: 0.020203328359045473]
	TIME [epoch: 5.76 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01915793753281226		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.01915793753281226 | validation: 0.014873776556129701]
	TIME [epoch: 5.74 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021166512708474576		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.021166512708474576 | validation: 0.01814698772998975]
	TIME [epoch: 5.73 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02187637926526821		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.02187637926526821 | validation: 0.024148309726563705]
	TIME [epoch: 5.73 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020420669440806616		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.020420669440806616 | validation: 0.017054995628137077]
	TIME [epoch: 5.74 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020935368663057785		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.020935368663057785 | validation: 0.023632245712127086]
	TIME [epoch: 5.74 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01971735312060448		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.01971735312060448 | validation: 0.023629295238996526]
	TIME [epoch: 5.79 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02332566759963215		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.02332566759963215 | validation: 0.019451002757314494]
	TIME [epoch: 5.74 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019693981364979143		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.019693981364979143 | validation: 0.022046332204445247]
	TIME [epoch: 5.75 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023583070676236256		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.023583070676236256 | validation: 0.024392102067852774]
	TIME [epoch: 5.73 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02167296362749005		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.02167296362749005 | validation: 0.026966541817636518]
	TIME [epoch: 5.74 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020451291023633158		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.020451291023633158 | validation: 0.01882133711346236]
	TIME [epoch: 5.73 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02249791465392801		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.02249791465392801 | validation: 0.02521508409735941]
	TIME [epoch: 5.75 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020287998089206467		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.020287998089206467 | validation: 0.023718602587428715]
	TIME [epoch: 5.77 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0221006156139233		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.0221006156139233 | validation: 0.017897562690187847]
	TIME [epoch: 5.75 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024010781628652157		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.024010781628652157 | validation: 0.01568510862511899]
	TIME [epoch: 5.74 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019749737260457693		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.019749737260457693 | validation: 0.021922424050694517]
	TIME [epoch: 5.73 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022992386718796387		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.022992386718796387 | validation: 0.020220100615275394]
	TIME [epoch: 5.75 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022358797896788286		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.022358797896788286 | validation: 0.02054649132906567]
	TIME [epoch: 5.75 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020060703293997686		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.020060703293997686 | validation: 0.02169140003787218]
	TIME [epoch: 5.79 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021668896240316447		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.021668896240316447 | validation: 0.020344755382326128]
	TIME [epoch: 5.74 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02290624498334883		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.02290624498334883 | validation: 0.022061183352219703]
	TIME [epoch: 5.74 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018133701780834576		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.018133701780834576 | validation: 0.02201796993487946]
	TIME [epoch: 5.73 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021100481645424194		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.021100481645424194 | validation: 0.016288072960408562]
	TIME [epoch: 5.75 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0222309742764167		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.0222309742764167 | validation: 0.022216160238269694]
	TIME [epoch: 5.74 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01820540366837302		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.01820540366837302 | validation: 0.011043602189044347]
	TIME [epoch: 5.77 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02365206414877703		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.02365206414877703 | validation: 0.019018630382739304]
	TIME [epoch: 5.76 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021900588996501203		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.021900588996501203 | validation: 0.022813026879000546]
	TIME [epoch: 5.75 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020158707604986417		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.020158707604986417 | validation: 0.02225780859945874]
	TIME [epoch: 5.74 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020069713225332943		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.020069713225332943 | validation: 0.012659688244823589]
	TIME [epoch: 5.74 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021213034132755472		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.021213034132755472 | validation: 0.02558733239197594]
	TIME [epoch: 5.74 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01979968430885311		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.01979968430885311 | validation: 0.015107017168994165]
	TIME [epoch: 5.75 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021048091776081242		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.021048091776081242 | validation: 0.01623664472945571]
	TIME [epoch: 5.79 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020419297323395435		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.020419297323395435 | validation: 0.015570285251200498]
	TIME [epoch: 5.74 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022137000545484432		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.022137000545484432 | validation: 0.02105408692824419]
	TIME [epoch: 5.75 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02184576708964682		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.02184576708964682 | validation: 0.02458805632066298]
	TIME [epoch: 5.74 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02129959639516125		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.02129959639516125 | validation: 0.027940903933012108]
	TIME [epoch: 5.73 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02062711734566674		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.02062711734566674 | validation: 0.01818261074203843]
	TIME [epoch: 5.74 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024580355122445358		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.024580355122445358 | validation: 0.02532407788099934]
	TIME [epoch: 5.76 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021653711892908337		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.021653711892908337 | validation: 0.02036898462059348]
	TIME [epoch: 5.76 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02270726882275224		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.02270726882275224 | validation: 0.01384320277278592]
	TIME [epoch: 5.74 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018407812353565048		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.018407812353565048 | validation: 0.024140278522518467]
	TIME [epoch: 5.73 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02531837483087094		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.02531837483087094 | validation: 0.023292556647724193]
	TIME [epoch: 5.74 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020484666220375463		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.020484666220375463 | validation: 0.022108174107678992]
	TIME [epoch: 5.74 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024779443553709778		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.024779443553709778 | validation: 0.014377901847911174]
	TIME [epoch: 5.74 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021072034631165654		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.021072034631165654 | validation: 0.018541960841307867]
	TIME [epoch: 5.76 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019068933892803293		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.019068933892803293 | validation: 0.021013017970014577]
	TIME [epoch: 5.73 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021800957815760635		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.021800957815760635 | validation: 0.024900481814188812]
	TIME [epoch: 5.73 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025236023867432504		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.025236023867432504 | validation: 0.01488078214795761]
	TIME [epoch: 5.73 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023227982994586477		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.023227982994586477 | validation: 0.02477658476124639]
	TIME [epoch: 5.75 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02166649989932364		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.02166649989932364 | validation: 0.01924051366835948]
	TIME [epoch: 5.73 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02288239569298041		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.02288239569298041 | validation: 0.019605607656954002]
	TIME [epoch: 5.76 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02189325340572554		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.02189325340572554 | validation: 0.01596875280409005]
	TIME [epoch: 5.74 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02542157673480736		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.02542157673480736 | validation: 0.0202760393188588]
	TIME [epoch: 5.75 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021600727974386284		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.021600727974386284 | validation: 0.009017190020263832]
	TIME [epoch: 5.75 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022757966457283493		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.022757966457283493 | validation: 0.017478216597065794]
	TIME [epoch: 5.73 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023648090951801277		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.023648090951801277 | validation: 0.02315939867107453]
	TIME [epoch: 5.72 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02095035630252157		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.02095035630252157 | validation: 0.020904820527434663]
	TIME [epoch: 5.74 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023234843515252915		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.023234843515252915 | validation: 0.024687862713969687]
	TIME [epoch: 5.78 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024901844793604976		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.024901844793604976 | validation: 0.028355738992234328]
	TIME [epoch: 5.75 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023057075624499927		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.023057075624499927 | validation: 0.018685845284774873]
	TIME [epoch: 5.75 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01977322646581386		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.01977322646581386 | validation: 0.01440018221426857]
	TIME [epoch: 5.75 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024444432079100648		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.024444432079100648 | validation: 0.022806683241996206]
	TIME [epoch: 5.75 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019378264621587777		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.019378264621587777 | validation: 0.01200595100577192]
	TIME [epoch: 5.75 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027101110917059176		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.027101110917059176 | validation: 0.023388446768533484]
	TIME [epoch: 5.78 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024936540468316486		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.024936540468316486 | validation: 0.01997108840954317]
	TIME [epoch: 5.75 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01801835852220531		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.01801835852220531 | validation: 0.012495153998629698]
	TIME [epoch: 5.73 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021371637719569243		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.021371637719569243 | validation: 0.016989589360248424]
	TIME [epoch: 5.75 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020052575791576308		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.020052575791576308 | validation: 0.019692394424368546]
	TIME [epoch: 5.75 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022181042125885994		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.022181042125885994 | validation: 0.03466642923456651]
	TIME [epoch: 5.73 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0168234264444914		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.0168234264444914 | validation: 0.01791167006338899]
	TIME [epoch: 5.76 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01673377688908762		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.01673377688908762 | validation: 0.022636054547794177]
	TIME [epoch: 5.76 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021116045675410533		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.021116045675410533 | validation: 0.02190150679763339]
	TIME [epoch: 5.73 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020174331829903098		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.020174331829903098 | validation: 0.021910748090301083]
	TIME [epoch: 5.74 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02154534622913301		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.02154534622913301 | validation: 0.01825319544982571]
	TIME [epoch: 5.72 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01768978018973872		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.01768978018973872 | validation: 0.020439705340914594]
	TIME [epoch: 5.75 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025972869749230867		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.025972869749230867 | validation: 0.017179954702114635]
	TIME [epoch: 5.75 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023846470088503408		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.023846470088503408 | validation: 0.015305023428432372]
	TIME [epoch: 5.78 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02073643996371799		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.02073643996371799 | validation: 0.026674975994027877]
	TIME [epoch: 5.75 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01973052522609451		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.01973052522609451 | validation: 0.01993072719251419]
	TIME [epoch: 5.75 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020887151948794556		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.020887151948794556 | validation: 0.02088049706040457]
	TIME [epoch: 5.74 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021740321217959543		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.021740321217959543 | validation: 0.0231301176286836]
	TIME [epoch: 5.74 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019489465487537404		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.019489465487537404 | validation: 0.020506688849577195]
	TIME [epoch: 5.74 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022764886330188312		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.022764886330188312 | validation: 0.013912359714950197]
	TIME [epoch: 5.75 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022807465046686966		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.022807465046686966 | validation: 0.025240344444136892]
	TIME [epoch: 5.78 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020844977640959224		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.020844977640959224 | validation: 0.015759361510336353]
	TIME [epoch: 5.76 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021605320610473825		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.021605320610473825 | validation: 0.023217052296581803]
	TIME [epoch: 5.73 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022302316725056927		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.022302316725056927 | validation: 0.015885487442981565]
	TIME [epoch: 5.73 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019684090551907143		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.019684090551907143 | validation: 0.02156894890604152]
	TIME [epoch: 5.74 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019142712471327705		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.019142712471327705 | validation: 0.01585266435968163]
	TIME [epoch: 5.74 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019369896991179955		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.019369896991179955 | validation: 0.02361230830329383]
	TIME [epoch: 5.78 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02143984547435629		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.02143984547435629 | validation: 0.01705212808946001]
	TIME [epoch: 5.74 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024986232703411743		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.024986232703411743 | validation: 0.02150355250164003]
	TIME [epoch: 5.75 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023147494229989456		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.023147494229989456 | validation: 0.02137255610214984]
	TIME [epoch: 5.75 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021466011699031045		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.021466011699031045 | validation: 0.02009708660879009]
	TIME [epoch: 5.75 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02051107998774981		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.02051107998774981 | validation: 0.014053996316107282]
	TIME [epoch: 5.75 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02171758114905327		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.02171758114905327 | validation: 0.0246948847558639]
	TIME [epoch: 5.77 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02396246157394875		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.02396246157394875 | validation: 0.010911774790500588]
	TIME [epoch: 5.76 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024199554092046358		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.024199554092046358 | validation: 0.021657755704091227]
	TIME [epoch: 5.73 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017785829788212495		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.017785829788212495 | validation: 0.024459441901903193]
	TIME [epoch: 5.75 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02168561910597659		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.02168561910597659 | validation: 0.01987561253968313]
	TIME [epoch: 5.73 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024249821242923478		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.024249821242923478 | validation: 0.02366408090147866]
	TIME [epoch: 5.74 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022688679571317448		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.022688679571317448 | validation: 0.01686739782350957]
	TIME [epoch: 5.76 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02039409298526872		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.02039409298526872 | validation: 0.020855415652504972]
	TIME [epoch: 5.79 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023461355703779142		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.023461355703779142 | validation: 0.014174502272828743]
	TIME [epoch: 5.74 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017682936843244332		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.017682936843244332 | validation: 0.02230681218255678]
	TIME [epoch: 5.75 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019504686382844007		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.019504686382844007 | validation: 0.0220408629999446]
	TIME [epoch: 5.73 sec]
Finished training in 11688.998 seconds.
