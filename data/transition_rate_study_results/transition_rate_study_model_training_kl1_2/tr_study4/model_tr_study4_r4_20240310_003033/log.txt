Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r4', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r4', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 730165043

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.916884185387017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.916884185387017 | validation: 8.274666255591676]
	TIME [epoch: 100 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.47570041500246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.47570041500246 | validation: 7.419385563755683]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.930393381106514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.930393381106514 | validation: 6.896172338549223]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.798693638441388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.798693638441388 | validation: 6.760367411288042]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7173186196954475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7173186196954475 | validation: 5.7913026977552065]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.733940123424506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.733940123424506 | validation: 6.190569398606583]
	TIME [epoch: 11.6 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.842859514122853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.842859514122853 | validation: 5.3594874355025945]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.516726355629442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.516726355629442 | validation: 4.883766943259694]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.219446910415217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.219446910415217 | validation: 4.9947762920549925]
	TIME [epoch: 11.6 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.041956581465251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.041956581465251 | validation: 6.219573753837544]
	TIME [epoch: 11.6 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.681337852267245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.681337852267245 | validation: 3.4515651301331123]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.713661009101605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.713661009101605 | validation: 5.453985405009262]
	TIME [epoch: 11.6 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.379353130635043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.379353130635043 | validation: 3.575606451991672]
	TIME [epoch: 11.6 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5111355123000156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5111355123000156 | validation: 3.3149108083874155]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1551661955107324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1551661955107324 | validation: 3.324479438672368]
	TIME [epoch: 11.6 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2162289850898897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2162289850898897 | validation: 3.1159727227261103]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1441205624382924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1441205624382924 | validation: 3.065757545601631]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9099637674751317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9099637674751317 | validation: 2.7854188554050556]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3135745844236757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3135745844236757 | validation: 3.337014239636317]
	TIME [epoch: 11.5 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2310355813877396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2310355813877396 | validation: 2.7441829765326795]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.668587426100379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.668587426100379 | validation: 2.523818956414624]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5524080316156903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5524080316156903 | validation: 2.7190370652275]
	TIME [epoch: 11.5 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6990794526248654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6990794526248654 | validation: 2.692248816608759]
	TIME [epoch: 11.5 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5452147572226584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5452147572226584 | validation: 2.468657788297402]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5191756335119426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5191756335119426 | validation: 3.234304646419056]
	TIME [epoch: 11.6 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4158237248767875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4158237248767875 | validation: 2.2649850421802746]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1977311499663528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1977311499663528 | validation: 2.2531620628847517]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0517656523364685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0517656523364685 | validation: 2.5259759896766294]
	TIME [epoch: 11.6 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0535152660800873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0535152660800873 | validation: 2.4802810780294453]
	TIME [epoch: 11.6 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.196514302568968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.196514302568968 | validation: 2.7456110008606074]
	TIME [epoch: 11.6 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9787719842761335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9787719842761335 | validation: 1.7076965116639946]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0606191356696595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0606191356696595 | validation: 1.6892295754375568]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5445031208121258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5445031208121258 | validation: 1.5758254584502354]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7105772450327792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7105772450327792 | validation: 1.841594892445122]
	TIME [epoch: 11.6 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4718482813587628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4718482813587628 | validation: 1.9347896928592945]
	TIME [epoch: 11.6 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6044873301674212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6044873301674212 | validation: 1.163091575308349]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3141976681092167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3141976681092167 | validation: 1.1125414758036254]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3148024388548785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3148024388548785 | validation: 2.1385208969250296]
	TIME [epoch: 11.6 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4598999310340393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4598999310340393 | validation: 0.9902176842623331]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1929184862348539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1929184862348539 | validation: 0.990486368192573]
	TIME [epoch: 11.6 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9365044687996493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9365044687996493 | validation: 1.0230306158582447]
	TIME [epoch: 11.6 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.039189400185784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.039189400185784 | validation: 0.8705873322871136]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8409252461038724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8409252461038724 | validation: 1.2666082997107961]
	TIME [epoch: 11.6 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0691646768220813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0691646768220813 | validation: 0.8354859479630043]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8950278185929672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8950278185929672 | validation: 2.3135574252224087]
	TIME [epoch: 11.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3770057516809855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3770057516809855 | validation: 0.6691488511158289]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9656471103889988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9656471103889988 | validation: 0.8867078848143547]
	TIME [epoch: 11.6 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9134934674450963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9134934674450963 | validation: 0.8810836462606494]
	TIME [epoch: 11.6 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7903813251333253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7903813251333253 | validation: 1.1099604079494236]
	TIME [epoch: 11.6 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1240704105691395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1240704105691395 | validation: 0.8562766987517634]
	TIME [epoch: 11.6 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8839377466489764		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.8839377466489764 | validation: 0.7254337960221442]
	TIME [epoch: 11.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.833255269462098		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.833255269462098 | validation: 1.1069881679610194]
	TIME [epoch: 11.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1399142719433206		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.1399142719433206 | validation: 0.9650715394001784]
	TIME [epoch: 11.6 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8787920051386071		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.8787920051386071 | validation: 0.9208130219434887]
	TIME [epoch: 11.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.018659093817315		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.018659093817315 | validation: 0.8819909555561428]
	TIME [epoch: 11.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8769471870040508		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.8769471870040508 | validation: 0.6489092202029658]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1829865637200696		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.1829865637200696 | validation: 1.2119461627780208]
	TIME [epoch: 11.6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0668418908456805		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.0668418908456805 | validation: 0.747016884465065]
	TIME [epoch: 11.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7928126432175405		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.7928126432175405 | validation: 0.8100972103268574]
	TIME [epoch: 11.6 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0687258861116062		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.0687258861116062 | validation: 0.6546442703995023]
	TIME [epoch: 11.6 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6807418146218039		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.6807418146218039 | validation: 0.7183458568943292]
	TIME [epoch: 11.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7607532396027156		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.7607532396027156 | validation: 0.9146176605778701]
	TIME [epoch: 11.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7972554286779252		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.7972554286779252 | validation: 0.8880127380912235]
	TIME [epoch: 11.6 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0480091087725985		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.0480091087725985 | validation: 0.7797868587623024]
	TIME [epoch: 11.6 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9244708091585625		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.9244708091585625 | validation: 0.770359732310711]
	TIME [epoch: 11.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7583887154643333		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.7583887154643333 | validation: 0.6566165929116164]
	TIME [epoch: 11.6 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.703519048145857		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.703519048145857 | validation: 0.6233804767637071]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9528300521121721		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.9528300521121721 | validation: 1.130218041646268]
	TIME [epoch: 11.6 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9730861793925718		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.9730861793925718 | validation: 0.9250929059195102]
	TIME [epoch: 11.6 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0074114449996092		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.0074114449996092 | validation: 0.806649166105232]
	TIME [epoch: 11.6 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7797065172781152		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.7797065172781152 | validation: 0.6256242208430979]
	TIME [epoch: 11.6 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8015286375604879		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.8015286375604879 | validation: 0.6877286577727406]
	TIME [epoch: 11.6 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8762219483849828		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.8762219483849828 | validation: 0.6717527674924227]
	TIME [epoch: 11.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8410127751055632		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.8410127751055632 | validation: 0.7003949365199804]
	TIME [epoch: 11.6 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.701808461485582		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.701808461485582 | validation: 0.6112413697730411]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.690772119775432		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.690772119775432 | validation: 1.1765362584042494]
	TIME [epoch: 11.6 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4025367153924264		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.4025367153924264 | validation: 0.9740614467425251]
	TIME [epoch: 11.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8682175582087497		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.8682175582087497 | validation: 0.7076662016726603]
	TIME [epoch: 11.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719581834286355		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.719581834286355 | validation: 0.6650347803092279]
	TIME [epoch: 11.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6945779614830007		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.6945779614830007 | validation: 1.2101227918406776]
	TIME [epoch: 11.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8411469362130127		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.8411469362130127 | validation: 0.6038209773872931]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6699531728496304		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.6699531728496304 | validation: 0.7245305950407972]
	TIME [epoch: 11.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.154587806686256		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.154587806686256 | validation: 1.6069102850578787]
	TIME [epoch: 11.6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3854275354500394		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.3854275354500394 | validation: 0.7938781669213247]
	TIME [epoch: 11.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7755633096557472		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.7755633096557472 | validation: 0.8207411612231819]
	TIME [epoch: 11.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.01084968460572		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.01084968460572 | validation: 1.1592296045284514]
	TIME [epoch: 11.5 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0415762158032378		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.0415762158032378 | validation: 0.7282721457441934]
	TIME [epoch: 11.5 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7146874884409001		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.7146874884409001 | validation: 0.6091187071512932]
	TIME [epoch: 11.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7371510132389447		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.7371510132389447 | validation: 0.5386177019818198]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7086463099903566		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.7086463099903566 | validation: 0.5977956383321112]
	TIME [epoch: 11.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7247209977289509		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.7247209977289509 | validation: 0.6687925304510346]
	TIME [epoch: 11.6 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6342931999346195		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.6342931999346195 | validation: 0.6117655688189821]
	TIME [epoch: 11.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871558882533981		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.6871558882533981 | validation: 0.5658908848266783]
	TIME [epoch: 11.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841737025404644		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.6841737025404644 | validation: 0.588928900773573]
	TIME [epoch: 11.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6240267914213298		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.6240267914213298 | validation: 0.6363045475857007]
	TIME [epoch: 11.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.610622922955429		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.610622922955429 | validation: 0.631471389308589]
	TIME [epoch: 11.6 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2626059312786784		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.2626059312786784 | validation: 0.6299803739600528]
	TIME [epoch: 11.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6228067124714382		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.6228067124714382 | validation: 0.5979202130714042]
	TIME [epoch: 11.6 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6582256552669966		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.6582256552669966 | validation: 0.5945113608155981]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6509085375270874		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.6509085375270874 | validation: 0.4711874892722597]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6681807779008628		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.6681807779008628 | validation: 0.46879454130680887]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6301240998105205		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.6301240998105205 | validation: 0.5525200141526968]
	TIME [epoch: 11.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.576035990174318		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.576035990174318 | validation: 0.5041663685265944]
	TIME [epoch: 11.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7547090634936238		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.7547090634936238 | validation: 0.6869452018018743]
	TIME [epoch: 11.6 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9671297522043025		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.9671297522043025 | validation: 0.5896860646527526]
	TIME [epoch: 11.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0139284702556408		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.0139284702556408 | validation: 1.24486885852968]
	TIME [epoch: 11.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9685913093898391		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.9685913093898391 | validation: 0.7691277793512711]
	TIME [epoch: 11.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7233304184786502		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.7233304184786502 | validation: 0.9343306684798793]
	TIME [epoch: 11.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7787175542611168		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.7787175542611168 | validation: 0.624232923062722]
	TIME [epoch: 11.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5925572983838453		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.5925572983838453 | validation: 0.5998407306352946]
	TIME [epoch: 11.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8376703688111329		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.8376703688111329 | validation: 1.746987077984317]
	TIME [epoch: 11.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.358616845094953		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.358616845094953 | validation: 0.5776285469020688]
	TIME [epoch: 11.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7071611717076687		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.7071611717076687 | validation: 0.6355982715083632]
	TIME [epoch: 11.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6461372395160265		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.6461372395160265 | validation: 0.5318573625361106]
	TIME [epoch: 11.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6954438673152469		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.6954438673152469 | validation: 0.66104622059224]
	TIME [epoch: 11.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6667471917458834		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.6667471917458834 | validation: 0.6053929768207228]
	TIME [epoch: 11.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5772946447008412		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.5772946447008412 | validation: 0.5019566664802391]
	TIME [epoch: 11.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5257067404523544		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.5257067404523544 | validation: 0.5967628016267763]
	TIME [epoch: 11.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5351842359184629		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.5351842359184629 | validation: 0.4995066558183325]
	TIME [epoch: 11.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6829999914034517		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.6829999914034517 | validation: 0.8452378791933078]
	TIME [epoch: 11.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7066515866611024		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.7066515866611024 | validation: 0.8157575785353464]
	TIME [epoch: 11.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6115194028028524		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.6115194028028524 | validation: 0.6071187994659455]
	TIME [epoch: 11.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1884123841454848		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.1884123841454848 | validation: 0.49367384730455044]
	TIME [epoch: 11.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5304301316228078		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.5304301316228078 | validation: 0.5167450467646433]
	TIME [epoch: 11.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6366557270622532		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.6366557270622532 | validation: 0.6005108493863973]
	TIME [epoch: 11.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5792865864319309		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.5792865864319309 | validation: 0.5387578621201342]
	TIME [epoch: 11.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6094651499111149		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.6094651499111149 | validation: 0.8124233593943574]
	TIME [epoch: 11.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6580105940877538		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.6580105940877538 | validation: 0.585087599395601]
	TIME [epoch: 11.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5324615638646513		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.5324615638646513 | validation: 0.7419933942275566]
	TIME [epoch: 11.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5900462496405676		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.5900462496405676 | validation: 0.6810927915574148]
	TIME [epoch: 11.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5964953633408089		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.5964953633408089 | validation: 0.9279060631689953]
	TIME [epoch: 11.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7735772172287374		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.7735772172287374 | validation: 0.5386365092641278]
	TIME [epoch: 11.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6077982071907171		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.6077982071907171 | validation: 1.29009067007071]
	TIME [epoch: 11.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1823536107614812		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.1823536107614812 | validation: 0.861604956221016]
	TIME [epoch: 11.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7778731749897275		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.7778731749897275 | validation: 0.6942995552186939]
	TIME [epoch: 11.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.76517508801523		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.76517508801523 | validation: 0.7700104704769399]
	TIME [epoch: 11.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.883903897393786		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.883903897393786 | validation: 0.6848401022604159]
	TIME [epoch: 11.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6910331978564047		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.6910331978564047 | validation: 0.8614921184630583]
	TIME [epoch: 11.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1078486702375072		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.1078486702375072 | validation: 1.0681499110016983]
	TIME [epoch: 11.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7189682380173181		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.7189682380173181 | validation: 0.6400439161563896]
	TIME [epoch: 11.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6214405607226294		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.6214405607226294 | validation: 0.4461480593352726]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5639767130948777		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.5639767130948777 | validation: 0.4462857939696545]
	TIME [epoch: 11.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5373158994476244		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.5373158994476244 | validation: 0.46053201328758064]
	TIME [epoch: 11.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6114763387026934		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.6114763387026934 | validation: 0.6219048434133103]
	TIME [epoch: 11.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5669124981883435		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.5669124981883435 | validation: 0.6538602074836698]
	TIME [epoch: 11.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5186061831826685		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.5186061831826685 | validation: 0.6863824685325537]
	TIME [epoch: 11.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.557224823951627		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.557224823951627 | validation: 0.7459458153504572]
	TIME [epoch: 11.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5781272540321964		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.5781272540321964 | validation: 0.4571166302414156]
	TIME [epoch: 11.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4931788283881364		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.4931788283881364 | validation: 0.39776773570536916]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4721883695336686		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.4721883695336686 | validation: 0.49718294856700823]
	TIME [epoch: 11.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5193775563100856		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.5193775563100856 | validation: 0.4405680787638346]
	TIME [epoch: 11.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6181372690885625		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.6181372690885625 | validation: 0.5883830129342966]
	TIME [epoch: 11.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5754704144087945		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.5754704144087945 | validation: 0.4623818561375614]
	TIME [epoch: 11.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5202280843744913		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.5202280843744913 | validation: 0.5796280519699747]
	TIME [epoch: 11.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5540525399977176		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.5540525399977176 | validation: 1.3271849500551849]
	TIME [epoch: 11.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8068659816271471		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.8068659816271471 | validation: 0.5422190806526618]
	TIME [epoch: 11.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5748915095899015		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.5748915095899015 | validation: 0.39304982959635626]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6221455909247178		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.6221455909247178 | validation: 0.7281143161130456]
	TIME [epoch: 11.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6374891833224995		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.6374891833224995 | validation: 0.4687685382758843]
	TIME [epoch: 11.6 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5048127032490252		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.5048127032490252 | validation: 0.5505340184143167]
	TIME [epoch: 11.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5149499607552105		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.5149499607552105 | validation: 0.42255081250295456]
	TIME [epoch: 11.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49019882028573253		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.49019882028573253 | validation: 0.42257973338514476]
	TIME [epoch: 11.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4123344093610257		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.4123344093610257 | validation: 0.5614562112638076]
	TIME [epoch: 11.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.565333524608369		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.565333524608369 | validation: 0.6037620126432856]
	TIME [epoch: 11.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5276986579086543		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.5276986579086543 | validation: 0.45107457805058304]
	TIME [epoch: 11.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4764444982247624		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.4764444982247624 | validation: 0.5704164767126032]
	TIME [epoch: 11.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49729222257552996		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.49729222257552996 | validation: 0.5555411617883631]
	TIME [epoch: 11.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5832691508414501		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.5832691508414501 | validation: 2.0053013544682408]
	TIME [epoch: 11.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0087192601151114		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.0087192601151114 | validation: 0.7232111112007135]
	TIME [epoch: 11.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5907064063187173		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.5907064063187173 | validation: 0.3611549107821269]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6154668118084501		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.6154668118084501 | validation: 0.4089849978118667]
	TIME [epoch: 11.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4272545889238929		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.4272545889238929 | validation: 0.3364371029495841]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49122300685036946		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.49122300685036946 | validation: 0.5922999845854572]
	TIME [epoch: 11.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4952443416591871		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.4952443416591871 | validation: 0.39249020042312155]
	TIME [epoch: 11.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41463349219363554		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.41463349219363554 | validation: 0.6265803331451809]
	TIME [epoch: 11.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4858984545299741		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.4858984545299741 | validation: 0.42809649569310076]
	TIME [epoch: 11.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4072754883796045		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.4072754883796045 | validation: 0.7367668644768662]
	TIME [epoch: 11.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47251426551149245		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.47251426551149245 | validation: 0.4495790066357465]
	TIME [epoch: 11.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3631087273765008		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.3631087273765008 | validation: 0.30764102228283136]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3995444095682401		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.3995444095682401 | validation: 0.4683905602850837]
	TIME [epoch: 11.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4970648112040265		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.4970648112040265 | validation: 0.7502203996910308]
	TIME [epoch: 11.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8476892027355788		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.8476892027355788 | validation: 0.6661322305977022]
	TIME [epoch: 11.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8264938868087105		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.8264938868087105 | validation: 0.5237301868118633]
	TIME [epoch: 11.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5448945566520944		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.5448945566520944 | validation: 0.4846710362677232]
	TIME [epoch: 11.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4377207725727779		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.4377207725727779 | validation: 0.37393838428425286]
	TIME [epoch: 11.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6704421238684873		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.6704421238684873 | validation: 0.7207160160467748]
	TIME [epoch: 11.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9088830821305306		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.9088830821305306 | validation: 0.7496813322047714]
	TIME [epoch: 11.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.637763866951125		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.637763866951125 | validation: 0.565535521891439]
	TIME [epoch: 11.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840515519478689		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.6840515519478689 | validation: 1.10708843903889]
	TIME [epoch: 11.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0574704842557492		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.0574704842557492 | validation: 1.3437193929977918]
	TIME [epoch: 11.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.22529647258916		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.22529647258916 | validation: 0.746703280772601]
	TIME [epoch: 11.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9080180733743091		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.9080180733743091 | validation: 1.3011336304843042]
	TIME [epoch: 11.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9812495937880225		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.9812495937880225 | validation: 0.7674849204022747]
	TIME [epoch: 11.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8281615571208637		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.8281615571208637 | validation: 0.7522303278161014]
	TIME [epoch: 11.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6230334938999733		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.6230334938999733 | validation: 0.5893078629428732]
	TIME [epoch: 11.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8660578892656621		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.8660578892656621 | validation: 0.46181335227270237]
	TIME [epoch: 11.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5107260716083508		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.5107260716083508 | validation: 0.4673740545981421]
	TIME [epoch: 11.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4554468475146669		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.4554468475146669 | validation: 0.42861607283490727]
	TIME [epoch: 11.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5085102598739047		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.5085102598739047 | validation: 0.310292329128845]
	TIME [epoch: 11.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4834655401594941		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.4834655401594941 | validation: 0.33222875554878484]
	TIME [epoch: 11.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4285801580345068		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.4285801580345068 | validation: 0.3970371465794429]
	TIME [epoch: 11.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48085730501522017		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.48085730501522017 | validation: 0.4573576570286362]
	TIME [epoch: 11.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4894295959072862		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.4894295959072862 | validation: 0.3683881271076156]
	TIME [epoch: 11.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3841083765250367		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.3841083765250367 | validation: 0.3917911694719291]
	TIME [epoch: 11.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4072547643882973		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.4072547643882973 | validation: 0.46459242330811046]
	TIME [epoch: 11.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4001744102117845		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.4001744102117845 | validation: 0.3507207172807018]
	TIME [epoch: 11.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35424955834230143		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.35424955834230143 | validation: 0.3612967524191609]
	TIME [epoch: 11.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5378039655399054		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.5378039655399054 | validation: 0.695776714074903]
	TIME [epoch: 11.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.60593483625097		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.60593483625097 | validation: 1.2118322148141722]
	TIME [epoch: 11.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7477106985888871		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.7477106985888871 | validation: 0.4812281295189548]
	TIME [epoch: 11.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.613531614882211		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.613531614882211 | validation: 1.217656354317929]
	TIME [epoch: 11.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6692421006198208		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.6692421006198208 | validation: 0.5997772003337342]
	TIME [epoch: 11.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6496420661583532		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.6496420661583532 | validation: 0.45971912913014806]
	TIME [epoch: 11.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.561544532058579		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.561544532058579 | validation: 0.4076915931904063]
	TIME [epoch: 11.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4106423594789943		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.4106423594789943 | validation: 0.8537063338101726]
	TIME [epoch: 11.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7185847136241896		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.7185847136241896 | validation: 0.40159763743342697]
	TIME [epoch: 11.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34735106377255603		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.34735106377255603 | validation: 0.2880187402481082]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.382200992244492		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.382200992244492 | validation: 0.5120534228205096]
	TIME [epoch: 11.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4129845462332288		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.4129845462332288 | validation: 1.3644978384453776]
	TIME [epoch: 11.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8539709754342495		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.8539709754342495 | validation: 1.2044557539702687]
	TIME [epoch: 11.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8445384145988073		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.8445384145988073 | validation: 0.9802390458850218]
	TIME [epoch: 11.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9529218104560072		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.9529218104560072 | validation: 0.60120652023611]
	TIME [epoch: 11.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41121185340507327		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.41121185340507327 | validation: 0.40245368369552553]
	TIME [epoch: 11.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41165983022723546		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.41165983022723546 | validation: 0.2966413020727029]
	TIME [epoch: 11.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3370460993977753		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.3370460993977753 | validation: 0.2876861240883579]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_225.pth
	Model improved!!!
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5102509685854302		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.5102509685854302 | validation: 1.0200025626820954]
	TIME [epoch: 11.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7332857565844274		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.7332857565844274 | validation: 0.7061906797002581]
	TIME [epoch: 11.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43239522539111297		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.43239522539111297 | validation: 0.5791321515016128]
	TIME [epoch: 11.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4347278266098497		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.4347278266098497 | validation: 0.6258458225358619]
	TIME [epoch: 11.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5947778648614248		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.5947778648614248 | validation: 0.3473866801738717]
	TIME [epoch: 11.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3584318035768584		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.3584318035768584 | validation: 0.25566527491887514]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43846982233865067		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.43846982233865067 | validation: 0.41829984736417447]
	TIME [epoch: 11.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46297356927818634		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.46297356927818634 | validation: 0.5559270536294684]
	TIME [epoch: 11.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4996004407686788		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.4996004407686788 | validation: 0.29570302688411415]
	TIME [epoch: 11.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3385823039992948		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.3385823039992948 | validation: 0.5539537224524815]
	TIME [epoch: 11.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6091433812190529		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.6091433812190529 | validation: 0.47777939496738775]
	TIME [epoch: 11.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3851994174725992		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.3851994174725992 | validation: 0.27825190268386396]
	TIME [epoch: 11.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.338513635087802		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.338513635087802 | validation: 0.4026160132416555]
	TIME [epoch: 11.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.335049926230455		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.335049926230455 | validation: 0.4166175503071874]
	TIME [epoch: 11.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3880742036638644		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.3880742036638644 | validation: 0.42243184469525746]
	TIME [epoch: 11.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4531161059148928		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.4531161059148928 | validation: 0.6900127593132895]
	TIME [epoch: 11.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3934423602732851		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.3934423602732851 | validation: 0.30946407970667744]
	TIME [epoch: 11.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3973038197139466		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.3973038197139466 | validation: 0.4098704629252754]
	TIME [epoch: 11.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4259320630284831		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.4259320630284831 | validation: 0.41635099670795356]
	TIME [epoch: 11.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3683975404968111		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.3683975404968111 | validation: 0.3940317197217357]
	TIME [epoch: 11.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48347924416956367		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.48347924416956367 | validation: 0.3405166176379483]
	TIME [epoch: 11.6 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2814015262450767		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.2814015262450767 | validation: 0.30891896719796114]
	TIME [epoch: 11.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3522831664159085		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.3522831664159085 | validation: 0.43650021125906324]
	TIME [epoch: 11.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31125733565728486		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.31125733565728486 | validation: 0.23996024801959615]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2958450621230369		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.2958450621230369 | validation: 0.3122696486643095]
	TIME [epoch: 11.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44534048705195084		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.44534048705195084 | validation: 0.3748429691631502]
	TIME [epoch: 11.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38125282025604		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.38125282025604 | validation: 0.2785794625435089]
	TIME [epoch: 11.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33396506439447304		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.33396506439447304 | validation: 0.26925046844007766]
	TIME [epoch: 11.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.370016698811583		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.370016698811583 | validation: 0.3155390466271532]
	TIME [epoch: 11.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36920904528875775		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.36920904528875775 | validation: 0.6964667782355088]
	TIME [epoch: 11.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5198446855162481		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.5198446855162481 | validation: 0.5228711217445348]
	TIME [epoch: 11.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47122286869252905		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.47122286869252905 | validation: 0.32251033097480075]
	TIME [epoch: 11.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3716468370297152		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.3716468370297152 | validation: 0.3163101141045613]
	TIME [epoch: 11.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30196720896643675		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.30196720896643675 | validation: 0.29882419412184036]
	TIME [epoch: 11.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31125192543843966		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.31125192543843966 | validation: 0.7999925618283734]
	TIME [epoch: 11.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42956617617019677		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.42956617617019677 | validation: 0.3053816134353086]
	TIME [epoch: 11.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3307006099067278		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.3307006099067278 | validation: 0.28976799893301175]
	TIME [epoch: 11.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2840329918117569		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.2840329918117569 | validation: 0.38227373442625473]
	TIME [epoch: 11.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28059419145063386		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.28059419145063386 | validation: 0.724328172987372]
	TIME [epoch: 11.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4864175033824124		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.4864175033824124 | validation: 0.3901273023066323]
	TIME [epoch: 11.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3422996600799146		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.3422996600799146 | validation: 0.2727836286984808]
	TIME [epoch: 11.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26875064826675055		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.26875064826675055 | validation: 0.2983022152315008]
	TIME [epoch: 11.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27951442201297966		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.27951442201297966 | validation: 0.2853889320962963]
	TIME [epoch: 11.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32532652257087763		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.32532652257087763 | validation: 0.24912388813672573]
	TIME [epoch: 11.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3253444663761026		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.3253444663761026 | validation: 0.26320702494778003]
	TIME [epoch: 11.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6431546796461588		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.6431546796461588 | validation: 0.22553482296661867]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3574710408562797		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.3574710408562797 | validation: 0.3189821723153053]
	TIME [epoch: 11.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46188347912280037		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.46188347912280037 | validation: 0.3015023842629341]
	TIME [epoch: 11.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29581692287569644		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.29581692287569644 | validation: 0.2921775462342585]
	TIME [epoch: 11.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28294824676408714		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.28294824676408714 | validation: 0.2405124637231457]
	TIME [epoch: 11.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2711559362310729		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.2711559362310729 | validation: 0.2949578260435446]
	TIME [epoch: 11.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31197428509252534		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.31197428509252534 | validation: 0.28818923745317904]
	TIME [epoch: 11.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8770718761003157		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.8770718761003157 | validation: 1.4103128993971925]
	TIME [epoch: 11.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6647371885299731		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.6647371885299731 | validation: 0.5352027238359822]
	TIME [epoch: 11.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4676794631905342		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.4676794631905342 | validation: 0.5968911793074768]
	TIME [epoch: 11.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5925234106109207		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.5925234106109207 | validation: 0.3868164284354413]
	TIME [epoch: 11.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4986460996057543		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.4986460996057543 | validation: 0.5287770503800848]
	TIME [epoch: 11.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6236620785087759		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.6236620785087759 | validation: 0.4268675662306965]
	TIME [epoch: 11.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37190785182245306		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.37190785182245306 | validation: 0.3537883259988309]
	TIME [epoch: 11.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34240624845678486		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.34240624845678486 | validation: 0.2761227236921671]
	TIME [epoch: 11.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3540650987017007		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.3540650987017007 | validation: 0.4282827943013128]
	TIME [epoch: 11.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3875604665447307		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.3875604665447307 | validation: 0.3608436049370266]
	TIME [epoch: 11.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3943795392460132		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.3943795392460132 | validation: 0.40063654862510895]
	TIME [epoch: 11.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3689983716103716		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.3689983716103716 | validation: 0.3051403546201388]
	TIME [epoch: 11.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3309616166341146		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.3309616166341146 | validation: 0.30259014534911793]
	TIME [epoch: 11.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34027394584127424		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.34027394584127424 | validation: 0.27579052495744255]
	TIME [epoch: 11.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3242702691305408		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.3242702691305408 | validation: 0.32277670581215845]
	TIME [epoch: 11.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3245790410669173		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.3245790410669173 | validation: 0.23810763248588362]
	TIME [epoch: 11.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2652205861828039		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.2652205861828039 | validation: 0.6960876576049332]
	TIME [epoch: 11.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4916170480224741		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.4916170480224741 | validation: 0.2446791094628238]
	TIME [epoch: 11.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3414663479941589		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.3414663479941589 | validation: 0.21767089320865268]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4780476313982186		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.4780476313982186 | validation: 0.23269703678599707]
	TIME [epoch: 11.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29412203323300334		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.29412203323300334 | validation: 0.5707123549387373]
	TIME [epoch: 11.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3816695360769923		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.3816695360769923 | validation: 0.3344304009240699]
	TIME [epoch: 11.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29876391393558754		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.29876391393558754 | validation: 0.22297072346015775]
	TIME [epoch: 11.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25063060189673697		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.25063060189673697 | validation: 0.23674200493951983]
	TIME [epoch: 11.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3653407195693198		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.3653407195693198 | validation: 0.30853598830590473]
	TIME [epoch: 11.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31003573327009665		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.31003573327009665 | validation: 0.2614149157066106]
	TIME [epoch: 11.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2945617805586984		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.2945617805586984 | validation: 0.2896872269729478]
	TIME [epoch: 11.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29260399779935364		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.29260399779935364 | validation: 0.2343230643973462]
	TIME [epoch: 11.5 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29029008332135603		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.29029008332135603 | validation: 0.27452765274557306]
	TIME [epoch: 11.5 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3742075347572324		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.3742075347572324 | validation: 0.2368580641178968]
	TIME [epoch: 11.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37773135713410877		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.37773135713410877 | validation: 0.24345880380282928]
	TIME [epoch: 11.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2859912691994313		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.2859912691994313 | validation: 0.2819242766737498]
	TIME [epoch: 11.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3103576514634777		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.3103576514634777 | validation: 0.2968557829754496]
	TIME [epoch: 11.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3483314610818581		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.3483314610818581 | validation: 0.47353419868766194]
	TIME [epoch: 11.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35261163053044625		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.35261163053044625 | validation: 0.3095238384660747]
	TIME [epoch: 11.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35496978768353205		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.35496978768353205 | validation: 0.2393418939495238]
	TIME [epoch: 11.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25427298453764724		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.25427298453764724 | validation: 0.21426259376857013]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_314.pth
	Model improved!!!
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2667793789255764		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.2667793789255764 | validation: 0.24747624452045422]
	TIME [epoch: 11.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2574318594601647		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.2574318594601647 | validation: 0.20480759537953802]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6877534622583467		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.6877534622583467 | validation: 0.29209123148426197]
	TIME [epoch: 11.6 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2994280738123842		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.2994280738123842 | validation: 0.23563627884242525]
	TIME [epoch: 11.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3477813085675652		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.3477813085675652 | validation: 0.6009879220989648]
	TIME [epoch: 11.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3801316082592068		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.3801316082592068 | validation: 0.21260112526968886]
	TIME [epoch: 11.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26732253288607766		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.26732253288607766 | validation: 0.27546964536795615]
	TIME [epoch: 11.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3570547343808166		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.3570547343808166 | validation: 0.22708111818790386]
	TIME [epoch: 11.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2726993097255744		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.2726993097255744 | validation: 0.24343879046288713]
	TIME [epoch: 11.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2876701861813348		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.2876701861813348 | validation: 0.21946773432623545]
	TIME [epoch: 11.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24135190199419942		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.24135190199419942 | validation: 0.2386038165752202]
	TIME [epoch: 11.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24704299831097712		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.24704299831097712 | validation: 0.27967071687835826]
	TIME [epoch: 11.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2376202363311735		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.2376202363311735 | validation: 0.3310743309563703]
	TIME [epoch: 11.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2745991295626946		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.2745991295626946 | validation: 0.22007780403097144]
	TIME [epoch: 11.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27350238313288733		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.27350238313288733 | validation: 0.3090522272959988]
	TIME [epoch: 11.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4052134937401034		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.4052134937401034 | validation: 0.34686162945449495]
	TIME [epoch: 11.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34216047304929853		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.34216047304929853 | validation: 0.2509207561165593]
	TIME [epoch: 11.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2821901281496433		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.2821901281496433 | validation: 0.2711300729875137]
	TIME [epoch: 11.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37912242064770907		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.37912242064770907 | validation: 0.5406137225412911]
	TIME [epoch: 11.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41688770849718393		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.41688770849718393 | validation: 0.23726967514438546]
	TIME [epoch: 11.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22819862373294222		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.22819862373294222 | validation: 0.190597594094804]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24469573710437836		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.24469573710437836 | validation: 0.25953625740259534]
	TIME [epoch: 11.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2630612060029442		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.2630612060029442 | validation: 0.24961263388668464]
	TIME [epoch: 11.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27715156432390486		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.27715156432390486 | validation: 0.17880375330518314]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_338.pth
	Model improved!!!
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2391660790053689		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.2391660790053689 | validation: 0.25541297571596466]
	TIME [epoch: 11.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24440476856631174		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.24440476856631174 | validation: 0.2256651438407713]
	TIME [epoch: 11.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23098095663833323		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.23098095663833323 | validation: 0.2575000083933484]
	TIME [epoch: 11.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26600978088618654		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.26600978088618654 | validation: 0.17957445757824997]
	TIME [epoch: 11.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.260126284475807		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.260126284475807 | validation: 0.24001584399209921]
	TIME [epoch: 11.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22804541277836957		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.22804541277836957 | validation: 0.21499231644497932]
	TIME [epoch: 11.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23278334284615235		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.23278334284615235 | validation: 0.3207275022358716]
	TIME [epoch: 11.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4352514867639327		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.4352514867639327 | validation: 0.1499572996494244]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_346.pth
	Model improved!!!
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32669482434346125		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.32669482434346125 | validation: 0.35859681795376247]
	TIME [epoch: 11.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3126072339671779		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.3126072339671779 | validation: 0.3849996277460841]
	TIME [epoch: 11.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4775018858324049		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.4775018858324049 | validation: 0.3606530767739771]
	TIME [epoch: 11.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48295287522995906		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.48295287522995906 | validation: 0.22987059491603404]
	TIME [epoch: 11.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36576058637240383		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.36576058637240383 | validation: 0.2857650580374436]
	TIME [epoch: 11.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3828071682477937		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.3828071682477937 | validation: 0.3640162017092351]
	TIME [epoch: 11.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3206733975330914		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.3206733975330914 | validation: 0.2615625704215032]
	TIME [epoch: 11.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23958240163273403		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.23958240163273403 | validation: 0.20586384607270528]
	TIME [epoch: 11.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24365647569086735		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.24365647569086735 | validation: 0.3280095743835305]
	TIME [epoch: 11.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27010749903241377		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.27010749903241377 | validation: 0.28131365506520445]
	TIME [epoch: 11.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2500645625922304		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.2500645625922304 | validation: 0.23018148881558417]
	TIME [epoch: 11.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41282685854653484		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.41282685854653484 | validation: 0.4199572471897728]
	TIME [epoch: 11.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5019984437152949		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.5019984437152949 | validation: 0.5025142649388966]
	TIME [epoch: 11.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4064296042480508		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.4064296042480508 | validation: 0.3579972064892014]
	TIME [epoch: 11.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3492628547613741		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.3492628547613741 | validation: 0.30390783090558077]
	TIME [epoch: 11.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36031951195443246		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.36031951195443246 | validation: 0.37441724068576365]
	TIME [epoch: 11.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2878169856112952		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.2878169856112952 | validation: 0.2102268265066675]
	TIME [epoch: 11.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.237536614890582		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.237536614890582 | validation: 0.22277681151210302]
	TIME [epoch: 11.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.239129181263915		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.239129181263915 | validation: 0.17892646348320507]
	TIME [epoch: 11.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2666219397062583		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.2666219397062583 | validation: 0.18629479348911676]
	TIME [epoch: 11.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24086627354838153		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.24086627354838153 | validation: 0.18015552742364604]
	TIME [epoch: 11.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23068973539929596		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.23068973539929596 | validation: 0.19897712673984502]
	TIME [epoch: 11.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26823390927594304		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.26823390927594304 | validation: 0.22538474927765179]
	TIME [epoch: 11.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3232879668500458		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.3232879668500458 | validation: 0.4211168656381703]
	TIME [epoch: 11.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4453964314679633		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.4453964314679633 | validation: 0.2441120952126522]
	TIME [epoch: 11.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2746443434807311		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.2746443434807311 | validation: 0.17178141559990587]
	TIME [epoch: 11.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23860590868907333		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.23860590868907333 | validation: 0.37075261496766077]
	TIME [epoch: 11.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37119842920313867		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.37119842920313867 | validation: 0.3897320117374731]
	TIME [epoch: 11.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3656144783402574		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.3656144783402574 | validation: 0.25814466405154474]
	TIME [epoch: 11.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.309903867443158		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.309903867443158 | validation: 0.25135919336351487]
	TIME [epoch: 11.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2617127064129673		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.2617127064129673 | validation: 0.161989102910918]
	TIME [epoch: 11.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2992775752464464		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.2992775752464464 | validation: 0.25935615072229484]
	TIME [epoch: 11.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3447871093710247		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.3447871093710247 | validation: 0.2777128417853547]
	TIME [epoch: 11.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2760057047450971		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.2760057047450971 | validation: 0.18190517146310758]
	TIME [epoch: 11.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24024260209258944		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.24024260209258944 | validation: 0.1942062838429918]
	TIME [epoch: 11.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19605121675174977		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.19605121675174977 | validation: 0.20731818682464506]
	TIME [epoch: 11.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23400210235675148		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.23400210235675148 | validation: 0.24243816047988312]
	TIME [epoch: 11.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27486282308297894		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.27486282308297894 | validation: 0.3907612319326782]
	TIME [epoch: 11.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.278778823869848		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.278778823869848 | validation: 0.2968580661014619]
	TIME [epoch: 11.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2648581766378536		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.2648581766378536 | validation: 0.2964250033426214]
	TIME [epoch: 11.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2447832670596297		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.2447832670596297 | validation: 0.19739669164503224]
	TIME [epoch: 11.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21864037914853512		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.21864037914853512 | validation: 0.1844653308194345]
	TIME [epoch: 11.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18887215122507006		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.18887215122507006 | validation: 0.3058929270292381]
	TIME [epoch: 11.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24761278235038936		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.24761278235038936 | validation: 0.262721469487469]
	TIME [epoch: 11.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29793127957434673		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.29793127957434673 | validation: 0.2905340023983974]
	TIME [epoch: 11.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2592680731227855		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.2592680731227855 | validation: 0.17791815177316886]
	TIME [epoch: 11.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18218585648688365		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.18218585648688365 | validation: 0.22648166120439547]
	TIME [epoch: 11.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1876506806419059		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.1876506806419059 | validation: 0.2592701269208188]
	TIME [epoch: 11.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19922714089101604		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.19922714089101604 | validation: 0.18964094914634266]
	TIME [epoch: 11.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2245116656982279		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.2245116656982279 | validation: 0.2532107938429505]
	TIME [epoch: 11.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20464256229043049		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.20464256229043049 | validation: 0.21238530189850444]
	TIME [epoch: 11.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19531238810428994		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.19531238810428994 | validation: 0.15688270770043766]
	TIME [epoch: 11.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18378980451207863		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.18378980451207863 | validation: 0.17855055236842426]
	TIME [epoch: 11.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1957065389883949		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.1957065389883949 | validation: 0.14457238547023527]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2722322791132769		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.2722322791132769 | validation: 0.4924243334921269]
	TIME [epoch: 11.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3172565525317725		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.3172565525317725 | validation: 0.1770698109411333]
	TIME [epoch: 11.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2505002379788424		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.2505002379788424 | validation: 0.19479201261019813]
	TIME [epoch: 11.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.211793944696442		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.211793944696442 | validation: 0.16566854862205851]
	TIME [epoch: 11.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16737765606320576		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.16737765606320576 | validation: 0.23500142207409835]
	TIME [epoch: 11.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3181178932999863		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.3181178932999863 | validation: 0.2271498740194732]
	TIME [epoch: 11.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.261978919698877		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.261978919698877 | validation: 0.20904126122550232]
	TIME [epoch: 11.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23115362612853868		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.23115362612853868 | validation: 0.23312783869020343]
	TIME [epoch: 11.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21683305132961628		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.21683305132961628 | validation: 0.20166001437628076]
	TIME [epoch: 11.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22231473722263473		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.22231473722263473 | validation: 0.1521790538958683]
	TIME [epoch: 11.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17091278932664822		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.17091278932664822 | validation: 0.18230158560372167]
	TIME [epoch: 11.6 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19734761568623843		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.19734761568623843 | validation: 0.18213432549299893]
	TIME [epoch: 11.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18515947183765802		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.18515947183765802 | validation: 0.2157385497856992]
	TIME [epoch: 11.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20978060874120963		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.20978060874120963 | validation: 0.21226593889129405]
	TIME [epoch: 11.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18981862704098276		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.18981862704098276 | validation: 0.17767106838028243]
	TIME [epoch: 11.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1972308807162139		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.1972308807162139 | validation: 0.2001490115274546]
	TIME [epoch: 11.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2705490431239357		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.2705490431239357 | validation: 0.3217118766314404]
	TIME [epoch: 11.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2711637909150787		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.2711637909150787 | validation: 0.19853187434939515]
	TIME [epoch: 11.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2559216170130886		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.2559216170130886 | validation: 0.27589207751470585]
	TIME [epoch: 11.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25934607618718725		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.25934607618718725 | validation: 0.26040580322543977]
	TIME [epoch: 11.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23067086200574674		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.23067086200574674 | validation: 0.2894775088252927]
	TIME [epoch: 11.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3223788032143247		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.3223788032143247 | validation: 0.15543431218262613]
	TIME [epoch: 11.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17690189179879978		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.17690189179879978 | validation: 0.18154415617835856]
	TIME [epoch: 11.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3008528945204082		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.3008528945204082 | validation: 0.1674973033348011]
	TIME [epoch: 11.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2220671952859613		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.2220671952859613 | validation: 0.298360844290099]
	TIME [epoch: 11.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21270328491380808		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.21270328491380808 | validation: 0.15988725291752118]
	TIME [epoch: 11.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17877752487889872		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.17877752487889872 | validation: 0.14210284790275993]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_427.pth
	Model improved!!!
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1747856854504235		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.1747856854504235 | validation: 0.17090296242651248]
	TIME [epoch: 11.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19555135988154532		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.19555135988154532 | validation: 0.18489508304361546]
	TIME [epoch: 11.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20885753919890157		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.20885753919890157 | validation: 0.22247890455755823]
	TIME [epoch: 11.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34700163231745845		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.34700163231745845 | validation: 0.25037184944442653]
	TIME [epoch: 11.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2232119208462355		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.2232119208462355 | validation: 0.2662086634879914]
	TIME [epoch: 11.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3069449496757425		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.3069449496757425 | validation: 0.23095398572645917]
	TIME [epoch: 11.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2324901934688316		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.2324901934688316 | validation: 0.1482169480401992]
	TIME [epoch: 11.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2649531429103501		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.2649531429103501 | validation: 0.2052139304714855]
	TIME [epoch: 11.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20145280790854386		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.20145280790854386 | validation: 0.2216293080538349]
	TIME [epoch: 11.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2550495334924279		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.2550495334924279 | validation: 0.20423016805175465]
	TIME [epoch: 11.6 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26332818961351734		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.26332818961351734 | validation: 0.32552764473673185]
	TIME [epoch: 11.6 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3287925109916946		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.3287925109916946 | validation: 0.20605788488395071]
	TIME [epoch: 11.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20954871602410977		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.20954871602410977 | validation: 0.3020615818652718]
	TIME [epoch: 11.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3021417806983028		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.3021417806983028 | validation: 0.32977639535679926]
	TIME [epoch: 11.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5125389717731247		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.5125389717731247 | validation: 0.5418513039497534]
	TIME [epoch: 11.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40269073617968215		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.40269073617968215 | validation: 0.18393139015734078]
	TIME [epoch: 11.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2190532185410341		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.2190532185410341 | validation: 0.16646594433745435]
	TIME [epoch: 11.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21852279139947164		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.21852279139947164 | validation: 0.25151389246319406]
	TIME [epoch: 11.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2790512264290622		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.2790512264290622 | validation: 0.23408784986254952]
	TIME [epoch: 11.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2459110303086524		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.2459110303086524 | validation: 0.219023538245363]
	TIME [epoch: 11.6 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28089729619209713		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.28089729619209713 | validation: 0.31504817172501165]
	TIME [epoch: 11.6 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31649638322786267		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.31649638322786267 | validation: 0.3831223731808666]
	TIME [epoch: 11.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6410194524628621		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.6410194524628621 | validation: 0.5445397114079805]
	TIME [epoch: 11.6 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5043736618375215		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.5043736618375215 | validation: 0.5024836467503232]
	TIME [epoch: 11.6 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5115062193427501		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.5115062193427501 | validation: 0.30283846107635987]
	TIME [epoch: 11.6 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3089241254628018		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.3089241254628018 | validation: 0.31286781845913575]
	TIME [epoch: 11.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3160398965321287		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.3160398965321287 | validation: 0.4489594597087846]
	TIME [epoch: 11.6 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.504928361124479		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.504928361124479 | validation: 0.30775625532220136]
	TIME [epoch: 11.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.361361602552526		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.361361602552526 | validation: 0.4258986575579931]
	TIME [epoch: 11.6 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4972708628278097		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.4972708628278097 | validation: 0.3384393952452997]
	TIME [epoch: 11.6 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28777324335234283		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.28777324335234283 | validation: 0.3048398782392068]
	TIME [epoch: 11.6 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33235610349773476		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.33235610349773476 | validation: 0.26254187136688595]
	TIME [epoch: 11.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32962966339532923		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.32962966339532923 | validation: 0.3483638071850449]
	TIME [epoch: 11.6 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36869419924294766		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.36869419924294766 | validation: 0.23191289930506603]
	TIME [epoch: 11.6 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24611621354270607		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.24611621354270607 | validation: 0.20946282504075378]
	TIME [epoch: 11.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21454526782076658		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.21454526782076658 | validation: 0.1543542594825049]
	TIME [epoch: 11.6 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19237645665778103		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.19237645665778103 | validation: 0.18913962373329568]
	TIME [epoch: 11.6 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34616307509822475		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.34616307509822475 | validation: 0.47799281404316574]
	TIME [epoch: 11.6 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4034421243394558		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.4034421243394558 | validation: 0.1584092579955796]
	TIME [epoch: 11.6 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22364399143717723		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.22364399143717723 | validation: 0.19959503839021978]
	TIME [epoch: 11.6 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24839735004944347		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.24839735004944347 | validation: 0.1833490123627044]
	TIME [epoch: 11.6 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.216065348842188		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.216065348842188 | validation: 0.21049870905717352]
	TIME [epoch: 11.6 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27389935760386774		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.27389935760386774 | validation: 0.2313973360197623]
	TIME [epoch: 11.6 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24426479021586073		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.24426479021586073 | validation: 0.280948282107759]
	TIME [epoch: 11.6 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3103086662108921		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.3103086662108921 | validation: 0.23339497852645058]
	TIME [epoch: 11.6 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2558338709470136		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.2558338709470136 | validation: 0.20900539323164535]
	TIME [epoch: 11.6 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2357476645086233		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.2357476645086233 | validation: 0.17747088755898982]
	TIME [epoch: 11.6 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2122258301643083		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.2122258301643083 | validation: 0.15889327095265598]
	TIME [epoch: 11.6 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18948060763324207		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.18948060763324207 | validation: 0.15215945950537038]
	TIME [epoch: 11.6 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18520677730290405		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.18520677730290405 | validation: 0.22506659170861887]
	TIME [epoch: 11.6 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20074559264380845		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.20074559264380845 | validation: 0.19598491888744746]
	TIME [epoch: 11.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21756354906809067		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.21756354906809067 | validation: 0.28282219820100873]
	TIME [epoch: 11.6 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23917160375374438		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.23917160375374438 | validation: 0.16685526682691992]
	TIME [epoch: 11.6 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.220753809451058		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.220753809451058 | validation: 0.22201152003036156]
	TIME [epoch: 11.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21050662874902393		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.21050662874902393 | validation: 0.1868902324984479]
	TIME [epoch: 11.6 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21053501612271192		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.21053501612271192 | validation: 0.2798684317681087]
	TIME [epoch: 11.6 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5385624854336533		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.5385624854336533 | validation: 0.4600613378744188]
	TIME [epoch: 11.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5023067358979209		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.5023067358979209 | validation: 0.44753614504332023]
	TIME [epoch: 11.6 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30713471010430016		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.30713471010430016 | validation: 0.18534601669255218]
	TIME [epoch: 11.6 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1976827435400962		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.1976827435400962 | validation: 0.16997932065401494]
	TIME [epoch: 11.6 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26208008935233484		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.26208008935233484 | validation: 0.653407764708705]
	TIME [epoch: 11.6 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6693494171216992		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.6693494171216992 | validation: 0.38616134283303427]
	TIME [epoch: 11.6 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46149587234295397		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.46149587234295397 | validation: 0.5368153521213919]
	TIME [epoch: 11.6 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49274463878989866		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.49274463878989866 | validation: 0.26591750903198047]
	TIME [epoch: 11.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3106125760763043		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.3106125760763043 | validation: 0.29826558468114833]
	TIME [epoch: 11.6 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3584345303393396		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.3584345303393396 | validation: 0.22140722586260053]
	TIME [epoch: 11.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23611085678359356		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.23611085678359356 | validation: 0.19388754279045436]
	TIME [epoch: 11.6 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2768943525879303		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.2768943525879303 | validation: 0.2585974442923033]
	TIME [epoch: 11.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32613528675127634		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.32613528675127634 | validation: 0.34559548407507285]
	TIME [epoch: 11.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.448802414161475		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.448802414161475 | validation: 0.33209053255920623]
	TIME [epoch: 11.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3793695354059967		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.3793695354059967 | validation: 0.2861581604720799]
	TIME [epoch: 11.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31601216468448856		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.31601216468448856 | validation: 0.2650019941865684]
	TIME [epoch: 11.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3631535387646478		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.3631535387646478 | validation: 0.3326734371169425]
	TIME [epoch: 11.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5160649921780551		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.5160649921780551 | validation: 0.2956518657872395]
	TIME [epoch: 11.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35250997475278956		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.35250997475278956 | validation: 0.3313819644841932]
	TIME [epoch: 11.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3437872734553167		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.3437872734553167 | validation: 0.2882483214494607]
	TIME [epoch: 11.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3435239076011501		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.3435239076011501 | validation: 0.2450358029275785]
	TIME [epoch: 11.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4642246664155023		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.4642246664155023 | validation: 0.3489608885987137]
	TIME [epoch: 11.6 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4214591952994718		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.4214591952994718 | validation: 0.31804416090532833]
	TIME [epoch: 11.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41059076261131566		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.41059076261131566 | validation: 0.2805932242179324]
	TIME [epoch: 11.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3359185787705958		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.3359185787705958 | validation: 0.25555788896418286]
	TIME [epoch: 11.6 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3197431800737234		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.3197431800737234 | validation: 0.27000129665534095]
	TIME [epoch: 11.6 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3664675013232692		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.3664675013232692 | validation: 0.2711200061238019]
	TIME [epoch: 11.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30707174544994137		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.30707174544994137 | validation: 0.2681353507470402]
	TIME [epoch: 11.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3022193188597322		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.3022193188597322 | validation: 0.2771907974668266]
	TIME [epoch: 11.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28858297464403304		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.28858297464403304 | validation: 0.21550905099539616]
	TIME [epoch: 11.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27992591627611124		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.27992591627611124 | validation: 0.2649952414007242]
	TIME [epoch: 11.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2596093325876782		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.2596093325876782 | validation: 0.26102157840550577]
	TIME [epoch: 11.6 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25593397059153966		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.25593397059153966 | validation: 0.20034952313423238]
	TIME [epoch: 11.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20586890540353656		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.20586890540353656 | validation: 0.22275800633268852]
	TIME [epoch: 11.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3295464392924353		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.3295464392924353 | validation: 0.26436675988514247]
	TIME [epoch: 11.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2634248361413156		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.2634248361413156 | validation: 0.24680383455671917]
	TIME [epoch: 11.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23801187937387425		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.23801187937387425 | validation: 0.2023183048096584]
	TIME [epoch: 11.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21316137679061173		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.21316137679061173 | validation: 0.18587253462917158]
	TIME [epoch: 11.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21323179466792846		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.21323179466792846 | validation: 0.22537124675536332]
	TIME [epoch: 11.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2360754819349532		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.2360754819349532 | validation: 0.22778199138170308]
	TIME [epoch: 11.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24379671811862777		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.24379671811862777 | validation: 0.21171632845741806]
	TIME [epoch: 11.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22073881376633744		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.22073881376633744 | validation: 0.2111722497363299]
	TIME [epoch: 11.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24744243889614348		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.24744243889614348 | validation: 0.23821283480713704]
	TIME [epoch: 11.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21901453161014692		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.21901453161014692 | validation: 0.14877518765528647]
	TIME [epoch: 11.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1812301516698585		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.1812301516698585 | validation: 0.18936378307313503]
	TIME [epoch: 11.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19167118206328038		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.19167118206328038 | validation: 0.21840955436209256]
	TIME [epoch: 11.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25383707421595403		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.25383707421595403 | validation: 0.16025423289887009]
	TIME [epoch: 11.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17009882421875624		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.17009882421875624 | validation: 0.16826534274015306]
	TIME [epoch: 11.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18664008068279148		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.18664008068279148 | validation: 0.17019004505054822]
	TIME [epoch: 11.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19773421734760827		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.19773421734760827 | validation: 0.15517882553276477]
	TIME [epoch: 11.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18505881173748176		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.18505881173748176 | validation: 0.1612811141169404]
	TIME [epoch: 11.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21122665154052972		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.21122665154052972 | validation: 0.16783074228671274]
	TIME [epoch: 11.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16774927199546785		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.16774927199546785 | validation: 0.182351998340082]
	TIME [epoch: 11.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21509340921163594		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.21509340921163594 | validation: 0.222277646283885]
	TIME [epoch: 11.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19436371123539062		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.19436371123539062 | validation: 0.1652543934001192]
	TIME [epoch: 11.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17190555916119332		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.17190555916119332 | validation: 0.1606246298700293]
	TIME [epoch: 11.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17221227283366647		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.17221227283366647 | validation: 0.1588549431892973]
	TIME [epoch: 11.6 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18071892811635326		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.18071892811635326 | validation: 0.15188961997428244]
	TIME [epoch: 11.6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1591417386543224		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.1591417386543224 | validation: 0.1609591604016029]
	TIME [epoch: 11.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16736275907399656		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.16736275907399656 | validation: 0.15403693020283116]
	TIME [epoch: 11.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16444963714819194		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.16444963714819194 | validation: 0.17857213440937944]
	TIME [epoch: 11.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1964954985355923		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.1964954985355923 | validation: 0.17770750588261275]
	TIME [epoch: 11.6 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18701742280631697		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.18701742280631697 | validation: 0.17626427928640861]
	TIME [epoch: 11.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15401693418976117		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.15401693418976117 | validation: 0.17761778097268086]
	TIME [epoch: 11.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18855780203457978		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.18855780203457978 | validation: 0.163405727972183]
	TIME [epoch: 11.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16528692500395314		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.16528692500395314 | validation: 0.1306854765553597]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_549.pth
	Model improved!!!
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18183090988952857		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.18183090988952857 | validation: 0.1849626040737175]
	TIME [epoch: 11.6 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17032200716986673		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.17032200716986673 | validation: 0.1396159719836542]
	TIME [epoch: 11.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19254692901701081		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.19254692901701081 | validation: 0.19665323645738453]
	TIME [epoch: 11.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22903321234322943		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.22903321234322943 | validation: 0.2721554981298162]
	TIME [epoch: 11.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21718735024311905		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.21718735024311905 | validation: 0.20890013827601553]
	TIME [epoch: 11.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1751970695399382		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.1751970695399382 | validation: 0.1713338772884393]
	TIME [epoch: 11.6 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16701816643176565		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.16701816643176565 | validation: 0.179801457004208]
	TIME [epoch: 11.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1672951701325925		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.1672951701325925 | validation: 0.1530853910575011]
	TIME [epoch: 11.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14008189209454203		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.14008189209454203 | validation: 0.18324368359863458]
	TIME [epoch: 11.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16026142957553274		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.16026142957553274 | validation: 0.179031898190784]
	TIME [epoch: 11.6 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15402560793602726		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.15402560793602726 | validation: 0.10976123434603129]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_560.pth
	Model improved!!!
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16757050857476785		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.16757050857476785 | validation: 0.19537236754322834]
	TIME [epoch: 11.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2166447649464721		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.2166447649464721 | validation: 0.19384979972758348]
	TIME [epoch: 11.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18556456982302244		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.18556456982302244 | validation: 0.16302904077536134]
	TIME [epoch: 11.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17299917360695932		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.17299917360695932 | validation: 0.14244615368912095]
	TIME [epoch: 11.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17983151774937225		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.17983151774937225 | validation: 0.18049741953142184]
	TIME [epoch: 11.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19428327553453606		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.19428327553453606 | validation: 0.2378496851064234]
	TIME [epoch: 11.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1899088493168816		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.1899088493168816 | validation: 0.1374448306590937]
	TIME [epoch: 11.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15273537909212503		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.15273537909212503 | validation: 0.16096747281902887]
	TIME [epoch: 11.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1823152048148991		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.1823152048148991 | validation: 0.16993205936057604]
	TIME [epoch: 11.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16629900069425402		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.16629900069425402 | validation: 0.149912753022835]
	TIME [epoch: 11.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15502877416122518		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.15502877416122518 | validation: 0.14603568716861814]
	TIME [epoch: 11.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19326079425548975		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.19326079425548975 | validation: 0.23907472150423878]
	TIME [epoch: 11.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2132140943732464		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.2132140943732464 | validation: 0.23545647277155796]
	TIME [epoch: 11.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21748649988707278		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.21748649988707278 | validation: 0.13853841198349293]
	TIME [epoch: 11.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14132768807782908		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.14132768807782908 | validation: 0.14913803631960781]
	TIME [epoch: 11.6 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14024177315921643		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.14024177315921643 | validation: 0.11852499387712069]
	TIME [epoch: 11.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16694745362254698		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.16694745362254698 | validation: 0.1901446548467063]
	TIME [epoch: 11.6 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12921851041565588		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.12921851041565588 | validation: 0.11974677470115504]
	TIME [epoch: 11.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11096431226201563		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.11096431226201563 | validation: 0.09346324575146076]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_579.pth
	Model improved!!!
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11431481310536241		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.11431481310536241 | validation: 0.11870824313563054]
	TIME [epoch: 11.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11602412550964329		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.11602412550964329 | validation: 0.11521435585664928]
	TIME [epoch: 11.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12638317392238807		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.12638317392238807 | validation: 0.1551465486759]
	TIME [epoch: 11.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15677335477638227		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.15677335477638227 | validation: 0.14650634562522616]
	TIME [epoch: 11.6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13857062356779185		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.13857062356779185 | validation: 0.11411932564407859]
	TIME [epoch: 11.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12954498436973333		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.12954498436973333 | validation: 0.10336528862144168]
	TIME [epoch: 11.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11372118457527908		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.11372118457527908 | validation: 0.09138864634012464]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_586.pth
	Model improved!!!
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1341351208513119		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.1341351208513119 | validation: 0.17246843678753768]
	TIME [epoch: 11.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2790184545159035		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.2790184545159035 | validation: 0.429450626635401]
	TIME [epoch: 11.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5009224220968306		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.5009224220968306 | validation: 0.5572144966775119]
	TIME [epoch: 11.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5696992834651573		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.5696992834651573 | validation: 0.37528120181927505]
	TIME [epoch: 11.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40699627761706203		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.40699627761706203 | validation: 0.25831111160159925]
	TIME [epoch: 11.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3145159357246726		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.3145159357246726 | validation: 0.2316945674095212]
	TIME [epoch: 11.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23303659104137636		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.23303659104137636 | validation: 0.16471349282759726]
	TIME [epoch: 11.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19774128125309995		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.19774128125309995 | validation: 0.1695699063173452]
	TIME [epoch: 11.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2509534530341451		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.2509534530341451 | validation: 0.3804592671073922]
	TIME [epoch: 11.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3938926220212221		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.3938926220212221 | validation: 0.2967349354862415]
	TIME [epoch: 11.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33751557142268296		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.33751557142268296 | validation: 0.23816187823716248]
	TIME [epoch: 11.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25325358782725915		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.25325358782725915 | validation: 0.22172968518938768]
	TIME [epoch: 11.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3419713827028304		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.3419713827028304 | validation: 0.3543359023462297]
	TIME [epoch: 11.6 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3380868018446937		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.3380868018446937 | validation: 0.211674604011048]
	TIME [epoch: 11.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20970554587099		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.20970554587099 | validation: 0.19250687215757661]
	TIME [epoch: 11.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18908193870401274		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.18908193870401274 | validation: 0.14566294298145427]
	TIME [epoch: 11.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16295170473559764		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.16295170473559764 | validation: 0.14607911001782115]
	TIME [epoch: 11.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17615918975564854		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.17615918975564854 | validation: 0.14732065880333145]
	TIME [epoch: 11.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1572987549141877		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.1572987549141877 | validation: 0.15377431490975807]
	TIME [epoch: 11.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13276753872778238		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.13276753872778238 | validation: 0.12551700528056114]
	TIME [epoch: 11.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12558706354118004		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.12558706354118004 | validation: 0.16558306330977396]
	TIME [epoch: 11.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17361653345474762		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.17361653345474762 | validation: 0.11422729216713777]
	TIME [epoch: 11.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11997567896882522		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.11997567896882522 | validation: 0.1414249428807448]
	TIME [epoch: 11.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11570021711244535		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.11570021711244535 | validation: 0.12327056658326623]
	TIME [epoch: 11.6 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1427406248476053		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.1427406248476053 | validation: 0.1524440633850572]
	TIME [epoch: 11.6 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13602574278515545		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.13602574278515545 | validation: 0.15676933968163567]
	TIME [epoch: 11.6 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1223168525617934		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.1223168525617934 | validation: 0.14110510502378865]
	TIME [epoch: 11.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15654317259195683		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.15654317259195683 | validation: 0.19635872666529136]
	TIME [epoch: 11.6 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15357441300803876		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.15357441300803876 | validation: 0.16412375208060134]
	TIME [epoch: 11.6 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18453858328089032		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.18453858328089032 | validation: 0.33061489479472306]
	TIME [epoch: 11.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2595726078869489		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.2595726078869489 | validation: 0.29512443461490856]
	TIME [epoch: 11.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2105414003844701		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.2105414003844701 | validation: 0.18309352562870465]
	TIME [epoch: 11.6 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1931676185979869		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.1931676185979869 | validation: 0.31576734163937314]
	TIME [epoch: 11.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20234053964385357		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.20234053964385357 | validation: 0.164350869965483]
	TIME [epoch: 11.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12835487872707813		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.12835487872707813 | validation: 0.1014189755548724]
	TIME [epoch: 11.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11285802418943786		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.11285802418943786 | validation: 0.11109594550595862]
	TIME [epoch: 11.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1216368086004016		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.1216368086004016 | validation: 0.10209297136228557]
	TIME [epoch: 11.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09726373082073907		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.09726373082073907 | validation: 0.11358364801971517]
	TIME [epoch: 11.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11534730327614622		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.11534730327614622 | validation: 0.10343975327102044]
	TIME [epoch: 11.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09023455896583837		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.09023455896583837 | validation: 0.09258743523199701]
	TIME [epoch: 11.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10494678390074538		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.10494678390074538 | validation: 0.10270168399497137]
	TIME [epoch: 11.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11886677262683365		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.11886677262683365 | validation: 0.06982277853227721]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_628.pth
	Model improved!!!
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09157370514922884		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.09157370514922884 | validation: 0.10755228594154505]
	TIME [epoch: 11.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0872217549013646		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.0872217549013646 | validation: 0.07093286491438262]
	TIME [epoch: 11.6 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09123931738608496		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.09123931738608496 | validation: 0.09415212635640402]
	TIME [epoch: 11.6 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0826983714480808		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.0826983714480808 | validation: 0.08391377617305722]
	TIME [epoch: 11.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08633970957182972		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.08633970957182972 | validation: 0.08632399233886962]
	TIME [epoch: 11.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09824979406912235		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.09824979406912235 | validation: 0.12564475605051448]
	TIME [epoch: 11.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10649820275276123		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.10649820275276123 | validation: 0.11586338808509827]
	TIME [epoch: 11.6 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10293097114679545		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.10293097114679545 | validation: 0.06230101713671205]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_636.pth
	Model improved!!!
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08114601693303763		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.08114601693303763 | validation: 0.06684212987042462]
	TIME [epoch: 11.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07726698017802458		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.07726698017802458 | validation: 0.11247522510757087]
	TIME [epoch: 11.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12463766526832466		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.12463766526832466 | validation: 0.10772357432438767]
	TIME [epoch: 11.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09890885337040806		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.09890885337040806 | validation: 0.10224622931337725]
	TIME [epoch: 11.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0925986737890363		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.0925986737890363 | validation: 0.09322761647512234]
	TIME [epoch: 11.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09200486384507342		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.09200486384507342 | validation: 0.07513699193873218]
	TIME [epoch: 11.6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12336310894458846		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.12336310894458846 | validation: 0.1326936148718733]
	TIME [epoch: 11.6 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13568284593636726		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.13568284593636726 | validation: 0.09954088222755399]
	TIME [epoch: 11.6 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11667440504749148		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.11667440504749148 | validation: 0.10839135192415668]
	TIME [epoch: 11.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09754535663387616		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.09754535663387616 | validation: 0.08614291600661073]
	TIME [epoch: 11.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11865628328606029		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.11865628328606029 | validation: 0.09175351626467552]
	TIME [epoch: 11.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11845072939664483		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.11845072939664483 | validation: 0.132891648150995]
	TIME [epoch: 11.6 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11294879650942911		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.11294879650942911 | validation: 0.1353634609745306]
	TIME [epoch: 11.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14001474629425914		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.14001474629425914 | validation: 0.11069404051262481]
	TIME [epoch: 11.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1454011878312691		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.1454011878312691 | validation: 0.16020342487910447]
	TIME [epoch: 11.6 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17605238637204726		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.17605238637204726 | validation: 0.13312074845172847]
	TIME [epoch: 11.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16324379638597275		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.16324379638597275 | validation: 0.1443456217935661]
	TIME [epoch: 11.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17456659561777038		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.17456659561777038 | validation: 0.12741542829035768]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13019749099934835		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.13019749099934835 | validation: 0.10154425627337568]
	TIME [epoch: 11.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1125707445040259		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.1125707445040259 | validation: 0.10984986667009157]
	TIME [epoch: 11.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13337074382989195		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.13337074382989195 | validation: 0.12555914130197968]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1168280081400234		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.1168280081400234 | validation: 0.08694634269136295]
	TIME [epoch: 11.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10032849639043064		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.10032849639043064 | validation: 0.11760285688446663]
	TIME [epoch: 11.5 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10031825218414098		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.10031825218414098 | validation: 0.08381340415455472]
	TIME [epoch: 11.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10669035013469262		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.10669035013469262 | validation: 0.09558097129746113]
	TIME [epoch: 11.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10323958743663307		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.10323958743663307 | validation: 0.08407107316739838]
	TIME [epoch: 11.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09524884398185242		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.09524884398185242 | validation: 0.08654509163735125]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11953177336986034		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.11953177336986034 | validation: 0.11614643958445772]
	TIME [epoch: 11.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10767874208307299		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.10767874208307299 | validation: 0.10147857180699706]
	TIME [epoch: 11.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11333920549661247		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.11333920549661247 | validation: 0.08149978838050052]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08979267072526541		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.08979267072526541 | validation: 0.08946085030070938]
	TIME [epoch: 11.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10757409299726706		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.10757409299726706 | validation: 0.08982423861888879]
	TIME [epoch: 11.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12709250076981515		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.12709250076981515 | validation: 0.11430435431971167]
	TIME [epoch: 11.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13800971482095206		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.13800971482095206 | validation: 0.1467470967612832]
	TIME [epoch: 11.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1942939075659405		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.1942939075659405 | validation: 0.1628029153842248]
	TIME [epoch: 11.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19391598849407643		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.19391598849407643 | validation: 0.18867874830879622]
	TIME [epoch: 11.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17728788048288327		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.17728788048288327 | validation: 0.1042261831963633]
	TIME [epoch: 11.6 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12949753928596613		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.12949753928596613 | validation: 0.12633723437740207]
	TIME [epoch: 11.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13781237313493144		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.13781237313493144 | validation: 0.12726472912181885]
	TIME [epoch: 11.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11489658469636481		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.11489658469636481 | validation: 0.10680747063545065]
	TIME [epoch: 11.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12632733449079703		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.12632733449079703 | validation: 0.13942706466483248]
	TIME [epoch: 11.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1339579557133084		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.1339579557133084 | validation: 0.08870588985967041]
	TIME [epoch: 11.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10576135202270948		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.10576135202270948 | validation: 0.09537166591213633]
	TIME [epoch: 11.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11615005996725611		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.11615005996725611 | validation: 0.10379083531758632]
	TIME [epoch: 11.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14842979345243318		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.14842979345243318 | validation: 0.16114144110310158]
	TIME [epoch: 11.6 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1524965004157041		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.1524965004157041 | validation: 0.10453587537967364]
	TIME [epoch: 11.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10380657917069605		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.10380657917069605 | validation: 0.07726899844463056]
	TIME [epoch: 11.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09716840491183314		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.09716840491183314 | validation: 0.10351579296254154]
	TIME [epoch: 11.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1185748367218776		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.1185748367218776 | validation: 0.09716052307043888]
	TIME [epoch: 11.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12642441500583157		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.12642441500583157 | validation: 0.10200382440568104]
	TIME [epoch: 11.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1238404389126849		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.1238404389126849 | validation: 0.15056674053573796]
	TIME [epoch: 11.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17541644601477677		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.17541644601477677 | validation: 0.13172363731212433]
	TIME [epoch: 11.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13516136124883682		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.13516136124883682 | validation: 0.13873281810042035]
	TIME [epoch: 11.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291937726168941		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.1291937726168941 | validation: 0.08507426934070349]
	TIME [epoch: 11.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10183273299456785		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.10183273299456785 | validation: 0.07234915408509998]
	TIME [epoch: 11.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09607124198438073		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.09607124198438073 | validation: 0.0843590895999618]
	TIME [epoch: 11.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09297167099286995		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.09297167099286995 | validation: 0.07761469575350696]
	TIME [epoch: 11.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09156985173070448		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.09156985173070448 | validation: 0.10426363938551637]
	TIME [epoch: 11.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10869278816877277		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.10869278816877277 | validation: 0.080489795473039]
	TIME [epoch: 11.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08366218650771495		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.08366218650771495 | validation: 0.06186795368006944]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_696.pth
	Model improved!!!
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07786180009700105		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.07786180009700105 | validation: 0.07619160657644276]
	TIME [epoch: 11.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08115989123178702		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.08115989123178702 | validation: 0.09319489967824648]
	TIME [epoch: 11.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08227249661539722		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.08227249661539722 | validation: 0.06720013944276686]
	TIME [epoch: 11.6 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08539411268926309		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.08539411268926309 | validation: 0.09063013623393693]
	TIME [epoch: 11.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09135953475895535		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.09135953475895535 | validation: 0.09026685295593209]
	TIME [epoch: 11.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09746894127626994		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.09746894127626994 | validation: 0.07916590574432934]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09818284214001637		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.09818284214001637 | validation: 0.08764501847160071]
	TIME [epoch: 11.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10329570971108824		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.10329570971108824 | validation: 0.1266719447433141]
	TIME [epoch: 11.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13470906281144912		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.13470906281144912 | validation: 0.07843762036755118]
	TIME [epoch: 11.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09558932333260853		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.09558932333260853 | validation: 0.09266819071809057]
	TIME [epoch: 11.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09849956054871395		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.09849956054871395 | validation: 0.08409330199191334]
	TIME [epoch: 11.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11558888362986292		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.11558888362986292 | validation: 0.10122040617431914]
	TIME [epoch: 11.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1505634706342865		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.1505634706342865 | validation: 0.15824391396431176]
	TIME [epoch: 11.5 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19090088276190117		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.19090088276190117 | validation: 0.15355286942754368]
	TIME [epoch: 11.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2155130126044431		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.2155130126044431 | validation: 0.2331282672633563]
	TIME [epoch: 11.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23514883261162287		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.23514883261162287 | validation: 0.14938402249876162]
	TIME [epoch: 11.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14728026000496164		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.14728026000496164 | validation: 0.12318052075243698]
	TIME [epoch: 11.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13005264623173016		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.13005264623173016 | validation: 0.09701101042019954]
	TIME [epoch: 11.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09851899096271258		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.09851899096271258 | validation: 0.07339472313246319]
	TIME [epoch: 11.5 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09217285730317869		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.09217285730317869 | validation: 0.08047526006348374]
	TIME [epoch: 11.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0870982473281548		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.0870982473281548 | validation: 0.06871726770877253]
	TIME [epoch: 11.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08158689532576788		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.08158689532576788 | validation: 0.06299975515051483]
	TIME [epoch: 11.6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06420383891561164		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.06420383891561164 | validation: 0.06817086025010913]
	TIME [epoch: 11.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0653793320921982		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.0653793320921982 | validation: 0.07122564051623309]
	TIME [epoch: 11.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07298115035041688		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.07298115035041688 | validation: 0.08543827723359247]
	TIME [epoch: 11.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07110839591220337		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.07110839591220337 | validation: 0.06637092013009437]
	TIME [epoch: 11.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07355858243939103		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.07355858243939103 | validation: 0.07092944935657897]
	TIME [epoch: 11.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0817499457813459		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.0817499457813459 | validation: 0.07937880079980357]
	TIME [epoch: 11.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07044257971213796		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.07044257971213796 | validation: 0.07663479621821159]
	TIME [epoch: 11.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09256261221152695		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.09256261221152695 | validation: 0.06143638390174811]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_726.pth
	Model improved!!!
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06738936469092685		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.06738936469092685 | validation: 0.06992648494842817]
	TIME [epoch: 11.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07872806577873588		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.07872806577873588 | validation: 0.05587858142038076]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_728.pth
	Model improved!!!
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08494277154318405		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.08494277154318405 | validation: 0.06770820611536112]
	TIME [epoch: 11.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07384361390959529		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.07384361390959529 | validation: 0.06127365419477736]
	TIME [epoch: 11.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07482339966461668		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.07482339966461668 | validation: 0.06271956615585085]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09894239131819013		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.09894239131819013 | validation: 0.1100651196207719]
	TIME [epoch: 11.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10389835424243682		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.10389835424243682 | validation: 0.08731605689661938]
	TIME [epoch: 11.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07999529420456858		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.07999529420456858 | validation: 0.07098354704265811]
	TIME [epoch: 11.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1102636418717742		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.1102636418717742 | validation: 0.13201838730117246]
	TIME [epoch: 11.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13857555492978652		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.13857555492978652 | validation: 0.09021576958360847]
	TIME [epoch: 11.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10970930290370376		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.10970930290370376 | validation: 0.09996793608530492]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09686581035538382		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.09686581035538382 | validation: 0.09432608865763342]
	TIME [epoch: 11.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10000322714314752		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.10000322714314752 | validation: 0.09675911935553812]
	TIME [epoch: 11.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09584242041738929		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.09584242041738929 | validation: 0.10413638350755346]
	TIME [epoch: 11.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11419598274107881		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.11419598274107881 | validation: 0.08135169213008746]
	TIME [epoch: 11.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08923373001266557		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.08923373001266557 | validation: 0.09660065528376585]
	TIME [epoch: 11.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08008474280221352		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.08008474280221352 | validation: 0.0792675535507165]
	TIME [epoch: 11.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0668628949408416		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.0668628949408416 | validation: 0.08263098027285266]
	TIME [epoch: 11.6 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0768712971672127		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.0768712971672127 | validation: 0.06663202595831559]
	TIME [epoch: 11.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08330631519195232		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.08330631519195232 | validation: 0.11107253940612805]
	TIME [epoch: 11.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10962814186128547		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.10962814186128547 | validation: 0.10705928051547055]
	TIME [epoch: 11.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11817903577043636		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.11817903577043636 | validation: 0.11759898236901481]
	TIME [epoch: 11.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13430780824996413		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.13430780824996413 | validation: 0.12378390965442489]
	TIME [epoch: 11.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11075183849942033		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.11075183849942033 | validation: 0.09711146365303391]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10652731492110479		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.10652731492110479 | validation: 0.11381389283813541]
	TIME [epoch: 11.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1300672080631988		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.1300672080631988 | validation: 0.10513402121874565]
	TIME [epoch: 11.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11173041700815056		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.11173041700815056 | validation: 0.11777858802052744]
	TIME [epoch: 11.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16094615896629808		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.16094615896629808 | validation: 0.12954771689861688]
	TIME [epoch: 11.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13436961570572487		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.13436961570572487 | validation: 0.09039377720431567]
	TIME [epoch: 11.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06850450039404424		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.06850450039404424 | validation: 0.059702051435895735]
	TIME [epoch: 11.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10317546106664421		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.10317546106664421 | validation: 0.09075722507572082]
	TIME [epoch: 11.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10926084412364521		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.10926084412364521 | validation: 0.06907787302755321]
	TIME [epoch: 11.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07141439304920719		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.07141439304920719 | validation: 0.07107361372351942]
	TIME [epoch: 11.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0647616105376328		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.0647616105376328 | validation: 0.05903927023395368]
	TIME [epoch: 11.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06404054708385071		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.06404054708385071 | validation: 0.07198086934366713]
	TIME [epoch: 11.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07150242237970834		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.07150242237970834 | validation: 0.06456163542515386]
	TIME [epoch: 11.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0549002472041979		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.0549002472041979 | validation: 0.08310329753754851]
	TIME [epoch: 11.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13198598828571045		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.13198598828571045 | validation: 0.11328896038313507]
	TIME [epoch: 11.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10709400789280689		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.10709400789280689 | validation: 0.06061029868011092]
	TIME [epoch: 11.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06407695621170037		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.06407695621170037 | validation: 0.047206153582210274]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_766.pth
	Model improved!!!
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05628613166228222		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.05628613166228222 | validation: 0.04675275263321961]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_767.pth
	Model improved!!!
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05996673117699071		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.05996673117699071 | validation: 0.05443597204891311]
	TIME [epoch: 11.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05510657499738471		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.05510657499738471 | validation: 0.05718321868665699]
	TIME [epoch: 11.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057388924734149104		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.057388924734149104 | validation: 0.05091148575202581]
	TIME [epoch: 11.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05028368305421396		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.05028368305421396 | validation: 0.05366810497705881]
	TIME [epoch: 11.6 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05384474415805271		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.05384474415805271 | validation: 0.04582702197079919]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_772.pth
	Model improved!!!
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06513101187203418		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.06513101187203418 | validation: 0.059765446696155175]
	TIME [epoch: 11.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07287762266838034		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.07287762266838034 | validation: 0.05768784067501823]
	TIME [epoch: 11.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07425007908921452		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.07425007908921452 | validation: 0.06527552498375201]
	TIME [epoch: 11.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07615900423195418		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.07615900423195418 | validation: 0.08634471391596665]
	TIME [epoch: 11.6 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09938373547523639		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.09938373547523639 | validation: 0.07952858537729042]
	TIME [epoch: 11.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0819650267567825		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.0819650267567825 | validation: 0.09820551749871136]
	TIME [epoch: 11.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08943287149752094		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.08943287149752094 | validation: 0.05552464108340268]
	TIME [epoch: 11.6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055472947644864025		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.055472947644864025 | validation: 0.0519940154721667]
	TIME [epoch: 11.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04511739796177691		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.04511739796177691 | validation: 0.05424650831425337]
	TIME [epoch: 11.6 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05904944531764257		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.05904944531764257 | validation: 0.06869626704010233]
	TIME [epoch: 11.6 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06771424541633315		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.06771424541633315 | validation: 0.050799086620478315]
	TIME [epoch: 11.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058657412198777736		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.058657412198777736 | validation: 0.07420602500240302]
	TIME [epoch: 11.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060723406233935434		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.060723406233935434 | validation: 0.07735992904594775]
	TIME [epoch: 11.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07233474170077972		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.07233474170077972 | validation: 0.05044673823561771]
	TIME [epoch: 11.6 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05468317035726274		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.05468317035726274 | validation: 0.04724743415930049]
	TIME [epoch: 11.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05298630582198087		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.05298630582198087 | validation: 0.03618032647587464]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_788.pth
	Model improved!!!
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04795645139407661		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.04795645139407661 | validation: 0.04441155293502031]
	TIME [epoch: 11.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055913114403175854		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.055913114403175854 | validation: 0.06867048889995679]
	TIME [epoch: 11.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08375394757038646		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.08375394757038646 | validation: 0.11509866479701977]
	TIME [epoch: 11.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09738483849409985		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.09738483849409985 | validation: 0.08475185658110633]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08870083694587018		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.08870083694587018 | validation: 0.07981107632791327]
	TIME [epoch: 11.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07141653473263483		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.07141653473263483 | validation: 0.07333005177238419]
	TIME [epoch: 11.6 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07041193287388817		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.07041193287388817 | validation: 0.06771260448599868]
	TIME [epoch: 11.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060758199325088025		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.060758199325088025 | validation: 0.06382421537736505]
	TIME [epoch: 11.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0766382857222389		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.0766382857222389 | validation: 0.07173175016756707]
	TIME [epoch: 11.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0785614962557003		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.0785614962557003 | validation: 0.06796958598660574]
	TIME [epoch: 11.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07947283961798866		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.07947283961798866 | validation: 0.06047628562116265]
	TIME [epoch: 11.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07350859896990367		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.07350859896990367 | validation: 0.06696031283271932]
	TIME [epoch: 11.6 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0757540113234952		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.0757540113234952 | validation: 0.06382020941330667]
	TIME [epoch: 11.5 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09890971133127555		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.09890971133127555 | validation: 0.08537884834127767]
	TIME [epoch: 11.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08375402336076636		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.08375402336076636 | validation: 0.06785847392285999]
	TIME [epoch: 11.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08916521673775334		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.08916521673775334 | validation: 0.06795465805552771]
	TIME [epoch: 11.6 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07357465206613915		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.07357465206613915 | validation: 0.0781348044368892]
	TIME [epoch: 11.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0911716914140782		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.0911716914140782 | validation: 0.0901800198185731]
	TIME [epoch: 11.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07699017317667438		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.07699017317667438 | validation: 0.07136968011509943]
	TIME [epoch: 11.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07662154844152552		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.07662154844152552 | validation: 0.06333589595786249]
	TIME [epoch: 11.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0746415301639947		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.0746415301639947 | validation: 0.06979162827767078]
	TIME [epoch: 11.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0723986021577629		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.0723986021577629 | validation: 0.05312918716778159]
	TIME [epoch: 11.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0672300607953234		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.0672300607953234 | validation: 0.05960982015967598]
	TIME [epoch: 11.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.067997936441444		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.067997936441444 | validation: 0.07418679910334965]
	TIME [epoch: 11.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07872984894575824		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.07872984894575824 | validation: 0.053668261398627036]
	TIME [epoch: 11.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08824920444349926		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.08824920444349926 | validation: 0.09440570975354025]
	TIME [epoch: 11.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0969719487279102		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.0969719487279102 | validation: 0.08676254584177376]
	TIME [epoch: 11.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12273373793841123		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.12273373793841123 | validation: 0.11434831724861094]
	TIME [epoch: 11.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12505005923981072		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.12505005923981072 | validation: 0.09608521758331463]
	TIME [epoch: 11.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09237845471811809		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.09237845471811809 | validation: 0.06388900864230404]
	TIME [epoch: 11.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06938444765912648		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.06938444765912648 | validation: 0.048251971137904415]
	TIME [epoch: 11.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05466314126714192		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.05466314126714192 | validation: 0.05358193668459275]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06905647419884854		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.06905647419884854 | validation: 0.05943902795533673]
	TIME [epoch: 11.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05976842517644099		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.05976842517644099 | validation: 0.045043000587553304]
	TIME [epoch: 11.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06039918032266188		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.06039918032266188 | validation: 0.059722453863388286]
	TIME [epoch: 11.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07768211770149056		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.07768211770149056 | validation: 0.06430749591132034]
	TIME [epoch: 11.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0787307588976405		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.0787307588976405 | validation: 0.06172535675025768]
	TIME [epoch: 11.5 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09145303071393374		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.09145303071393374 | validation: 0.09663268983447931]
	TIME [epoch: 11.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10968006406241204		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.10968006406241204 | validation: 0.08301422548002323]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08924493771077334		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.08924493771077334 | validation: 0.06859689717980896]
	TIME [epoch: 11.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0640442862827397		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.0640442862827397 | validation: 0.05726481900233935]
	TIME [epoch: 11.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06721810279807877		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.06721810279807877 | validation: 0.06232275106530596]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0738316345662457		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.0738316345662457 | validation: 0.08572879238080666]
	TIME [epoch: 11.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07842977911331553		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.07842977911331553 | validation: 0.04657105302584224]
	TIME [epoch: 11.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0547624827103306		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.0547624827103306 | validation: 0.059947295807115206]
	TIME [epoch: 11.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07040159178791953		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.07040159178791953 | validation: 0.062157156291813696]
	TIME [epoch: 11.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0663489977001604		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.0663489977001604 | validation: 0.06083212041080856]
	TIME [epoch: 11.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06479312813964236		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.06479312813964236 | validation: 0.07538525018764214]
	TIME [epoch: 11.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08657659220245979		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.08657659220245979 | validation: 0.09308919370383417]
	TIME [epoch: 11.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08023689876921186		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.08023689876921186 | validation: 0.08055582560775587]
	TIME [epoch: 11.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0889624532651254		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.0889624532651254 | validation: 0.08760475832761111]
	TIME [epoch: 11.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07712072637988697		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.07712072637988697 | validation: 0.07748974662084097]
	TIME [epoch: 11.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07275633448492193		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.07275633448492193 | validation: 0.05680306303556739]
	TIME [epoch: 11.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0584189495130491		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.0584189495130491 | validation: 0.06133741404948625]
	TIME [epoch: 11.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06144536583154106		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.06144536583154106 | validation: 0.05274252050955402]
	TIME [epoch: 11.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05525965065862577		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.05525965065862577 | validation: 0.08706792629161514]
	TIME [epoch: 11.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08253544733020418		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.08253544733020418 | validation: 0.055347383596732254]
	TIME [epoch: 11.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06918247544486524		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.06918247544486524 | validation: 0.059099556412655456]
	TIME [epoch: 11.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06244093680515021		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.06244093680515021 | validation: 0.07063420494156887]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07225872551584023		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.07225872551584023 | validation: 0.07097546434433849]
	TIME [epoch: 11.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07437847892787497		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.07437847892787497 | validation: 0.07167819809506094]
	TIME [epoch: 11.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07834065543653754		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.07834065543653754 | validation: 0.09077997095547845]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07978991607772605		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.07978991607772605 | validation: 0.08512827419341228]
	TIME [epoch: 11.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09862957725403512		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.09862957725403512 | validation: 0.1201207395020516]
	TIME [epoch: 11.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10298117423471742		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.10298117423471742 | validation: 0.08233756531155922]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07984576482674988		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.07984576482674988 | validation: 0.07635887289814404]
	TIME [epoch: 11.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06981278716103531		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.06981278716103531 | validation: 0.10281576327317002]
	TIME [epoch: 11.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0926845589127276		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.0926845589127276 | validation: 0.08098320025355651]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08314049384247878		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.08314049384247878 | validation: 0.06973038158624612]
	TIME [epoch: 11.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07810355159531497		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.07810355159531497 | validation: 0.09744196986449127]
	TIME [epoch: 11.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08001148926196255		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.08001148926196255 | validation: 0.09065689130544882]
	TIME [epoch: 11.5 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0815619245216011		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.0815619245216011 | validation: 0.08199823198326431]
	TIME [epoch: 11.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08233080564711942		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.08233080564711942 | validation: 0.07572726639218233]
	TIME [epoch: 11.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08668818401192091		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.08668818401192091 | validation: 0.09180639313513336]
	TIME [epoch: 11.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13108129931518775		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.13108129931518775 | validation: 0.16147923440810238]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15796487110350554		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.15796487110350554 | validation: 0.10992585871201213]
	TIME [epoch: 11.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10069757163310283		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.10069757163310283 | validation: 0.08976775567226397]
	TIME [epoch: 11.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08974818234285717		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.08974818234285717 | validation: 0.07756032289949637]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09286317315423112		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.09286317315423112 | validation: 0.09830702634253183]
	TIME [epoch: 11.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08460996885316924		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.08460996885316924 | validation: 0.08027299291288392]
	TIME [epoch: 11.6 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07530935323051441		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.07530935323051441 | validation: 0.07044309425898199]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07938575955069861		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.07938575955069861 | validation: 0.08145343893620967]
	TIME [epoch: 11.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07519579133540784		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.07519579133540784 | validation: 0.051188938808754636]
	TIME [epoch: 11.6 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06820891101046962		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.06820891101046962 | validation: 0.06223049087347933]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062146743258601436		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.062146743258601436 | validation: 0.05781625035420922]
	TIME [epoch: 11.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06371502018585783		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.06371502018585783 | validation: 0.052168445398500664]
	TIME [epoch: 11.6 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06733761715551831		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.06733761715551831 | validation: 0.06477054164288383]
	TIME [epoch: 11.6 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06289495384285974		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.06289495384285974 | validation: 0.04007235884256798]
	TIME [epoch: 11.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0487329017614061		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.0487329017614061 | validation: 0.03759642452495505]
	TIME [epoch: 11.6 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047986207556115816		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.047986207556115816 | validation: 0.043754826718564115]
	TIME [epoch: 11.6 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061796275515963096		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.061796275515963096 | validation: 0.06663743795266296]
	TIME [epoch: 11.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05882472522555127		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.05882472522555127 | validation: 0.059440838065856774]
	TIME [epoch: 11.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06276202984770361		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.06276202984770361 | validation: 0.07523557249243652]
	TIME [epoch: 11.6 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08201226077247187		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.08201226077247187 | validation: 0.07145630088192255]
	TIME [epoch: 11.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06607528362405242		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.06607528362405242 | validation: 0.05115442502259896]
	TIME [epoch: 11.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06959591139532889		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.06959591139532889 | validation: 0.067726760240348]
	TIME [epoch: 11.6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07265234233299436		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.07265234233299436 | validation: 0.05290005977406319]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07064672799936142		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.07064672799936142 | validation: 0.07143428079578298]
	TIME [epoch: 11.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06662642348694985		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.06662642348694985 | validation: 0.04653636677119161]
	TIME [epoch: 11.6 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06177616073325845		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.06177616073325845 | validation: 0.06386214246986877]
	TIME [epoch: 11.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08635609702179223		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.08635609702179223 | validation: 0.09004727977126496]
	TIME [epoch: 11.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09468078749141641		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.09468078749141641 | validation: 0.06165841815111419]
	TIME [epoch: 11.6 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07650365165588202		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.07650365165588202 | validation: 0.05545199938664507]
	TIME [epoch: 11.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07073678297741884		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.07073678297741884 | validation: 0.0678791193134469]
	TIME [epoch: 11.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07373107212919046		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.07373107212919046 | validation: 0.07376917849393821]
	TIME [epoch: 11.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0870493538336388		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.0870493538336388 | validation: 0.07447186967291498]
	TIME [epoch: 11.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07641864376659271		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.07641864376659271 | validation: 0.06608523598405557]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05715683602528266		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.05715683602528266 | validation: 0.04458380085575911]
	TIME [epoch: 11.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055624000391119505		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.055624000391119505 | validation: 0.04719675250076174]
	TIME [epoch: 11.6 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05580204531105891		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.05580204531105891 | validation: 0.05221037942425892]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05392232561039566		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.05392232561039566 | validation: 0.05686444175655143]
	TIME [epoch: 11.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05839613425820432		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.05839613425820432 | validation: 0.04149987817529208]
	TIME [epoch: 11.6 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05344665866381801		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.05344665866381801 | validation: 0.03390828724019698]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_901.pth
	Model improved!!!
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04917397131261693		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.04917397131261693 | validation: 0.037858567379434396]
	TIME [epoch: 11.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05303915627742571		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.05303915627742571 | validation: 0.047352394576010495]
	TIME [epoch: 11.6 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057880271525337534		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.057880271525337534 | validation: 0.044991002607601395]
	TIME [epoch: 11.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06733044442983321		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.06733044442983321 | validation: 0.06006667793938912]
	TIME [epoch: 11.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05904418301480098		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.05904418301480098 | validation: 0.05009570044624221]
	TIME [epoch: 11.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06571813274866518		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.06571813274866518 | validation: 0.06004770464660825]
	TIME [epoch: 11.6 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06253526800568279		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.06253526800568279 | validation: 0.06201739190280455]
	TIME [epoch: 11.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06356456477757197		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.06356456477757197 | validation: 0.056401278519291116]
	TIME [epoch: 11.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05898200156387612		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.05898200156387612 | validation: 0.04905118151975619]
	TIME [epoch: 11.6 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06402716316037887		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.06402716316037887 | validation: 0.07169462323363306]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08076840608429228		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.08076840608429228 | validation: 0.06687435043968608]
	TIME [epoch: 11.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.085271765997512		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.085271765997512 | validation: 0.08157666297570285]
	TIME [epoch: 11.6 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08851921628409386		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.08851921628409386 | validation: 0.08039812350735108]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08815360352178861		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.08815360352178861 | validation: 0.06374658135871675]
	TIME [epoch: 11.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07966142669533992		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.07966142669533992 | validation: 0.05989773588503475]
	TIME [epoch: 11.6 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06786485409082763		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.06786485409082763 | validation: 0.06587051161188108]
	TIME [epoch: 11.6 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06370715672850785		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.06370715672850785 | validation: 0.03882988204355085]
	TIME [epoch: 11.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050239028294084956		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.050239028294084956 | validation: 0.042275914603686786]
	TIME [epoch: 11.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05948418311645619		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.05948418311645619 | validation: 0.06742312394923264]
	TIME [epoch: 11.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07270069046033932		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.07270069046033932 | validation: 0.0685735479490969]
	TIME [epoch: 11.6 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07189599375680204		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.07189599375680204 | validation: 0.04551429193598643]
	TIME [epoch: 11.6 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049291815313691804		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.049291815313691804 | validation: 0.041490626622933624]
	TIME [epoch: 11.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05313600260365617		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.05313600260365617 | validation: 0.05107475382309127]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06701313466678274		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.06701313466678274 | validation: 0.052282971249146666]
	TIME [epoch: 11.6 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0917552099339383		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.0917552099339383 | validation: 0.10503933774660514]
	TIME [epoch: 11.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357758606819906		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.1357758606819906 | validation: 0.09423198019702472]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10230812803829639		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.10230812803829639 | validation: 0.08639376689656646]
	TIME [epoch: 11.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08101114489775776		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.08101114489775776 | validation: 0.0536441421485671]
	TIME [epoch: 11.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06258996446159124		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.06258996446159124 | validation: 0.05986913730052866]
	TIME [epoch: 11.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08596498913839537		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.08596498913839537 | validation: 0.07215294697785575]
	TIME [epoch: 11.6 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07128311255057145		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.07128311255057145 | validation: 0.052085927369207814]
	TIME [epoch: 11.6 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061434184461095116		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.061434184461095116 | validation: 0.04901060092607862]
	TIME [epoch: 11.6 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06325569171620105		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.06325569171620105 | validation: 0.056384531488583925]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06103609511961388		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.06103609511961388 | validation: 0.06089220972292612]
	TIME [epoch: 11.6 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06459969601238436		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.06459969601238436 | validation: 0.043418843997622435]
	TIME [epoch: 11.6 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053248313136490893		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.053248313136490893 | validation: 0.04838430588027449]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05939648200273813		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.05939648200273813 | validation: 0.03771218707798186]
	TIME [epoch: 11.5 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04902642225755071		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.04902642225755071 | validation: 0.04273401374633467]
	TIME [epoch: 11.6 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04294088272816934		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.04294088272816934 | validation: 0.041331119919957936]
	TIME [epoch: 11.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04653638909065065		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.04653638909065065 | validation: 0.0319130081219537]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_941.pth
	Model improved!!!
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04578798973105282		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.04578798973105282 | validation: 0.04184490825002658]
	TIME [epoch: 11.6 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04701657682840532		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.04701657682840532 | validation: 0.04848552900389814]
	TIME [epoch: 11.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04733112369881491		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.04733112369881491 | validation: 0.03579846011701952]
	TIME [epoch: 11.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04301543739504832		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.04301543739504832 | validation: 0.04624332940003328]
	TIME [epoch: 11.6 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04579433298756248		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.04579433298756248 | validation: 0.05033611434725462]
	TIME [epoch: 11.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061897382409404254		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.061897382409404254 | validation: 0.049305748869789334]
	TIME [epoch: 11.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05317578457024239		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.05317578457024239 | validation: 0.04101788352179964]
	TIME [epoch: 11.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05026222312869181		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.05026222312869181 | validation: 0.03944762247778421]
	TIME [epoch: 11.6 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054394192946473977		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.054394192946473977 | validation: 0.05505692169319687]
	TIME [epoch: 11.6 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06322523448778083		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.06322523448778083 | validation: 0.05672473252547217]
	TIME [epoch: 11.6 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055191438087292634		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.055191438087292634 | validation: 0.043362416938403994]
	TIME [epoch: 11.6 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05625521843789883		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.05625521843789883 | validation: 0.053271829127203046]
	TIME [epoch: 11.6 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053949563855585456		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.053949563855585456 | validation: 0.054127626440460035]
	TIME [epoch: 11.6 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0734493156332031		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.0734493156332031 | validation: 0.08564717078676541]
	TIME [epoch: 11.6 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07320269964498491		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.07320269964498491 | validation: 0.059161847107934255]
	TIME [epoch: 11.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06578869014604724		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.06578869014604724 | validation: 0.08193985650644789]
	TIME [epoch: 11.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08335744559612653		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.08335744559612653 | validation: 0.08894801562382786]
	TIME [epoch: 11.6 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08798588663007943		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.08798588663007943 | validation: 0.10391510964798154]
	TIME [epoch: 11.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10456655722964077		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.10456655722964077 | validation: 0.1134858934428268]
	TIME [epoch: 11.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1031411407334323		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.1031411407334323 | validation: 0.0888035172227769]
	TIME [epoch: 11.6 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09319311346878535		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.09319311346878535 | validation: 0.12519909527597578]
	TIME [epoch: 11.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12508859744374104		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.12508859744374104 | validation: 0.14096553187852756]
	TIME [epoch: 11.6 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11465592059894839		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.11465592059894839 | validation: 0.09960425529972472]
	TIME [epoch: 11.6 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08652929789280948		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.08652929789280948 | validation: 0.06937584732763256]
	TIME [epoch: 11.6 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07250921179343288		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.07250921179343288 | validation: 0.06719626258491648]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059974489693490535		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.059974489693490535 | validation: 0.05454220853557836]
	TIME [epoch: 11.6 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05305108418123975		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.05305108418123975 | validation: 0.04843441359052197]
	TIME [epoch: 11.6 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05388039460139563		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.05388039460139563 | validation: 0.0472125995501643]
	TIME [epoch: 11.6 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05672741854019991		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.05672741854019991 | validation: 0.06085557416162532]
	TIME [epoch: 11.6 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06200419383561308		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.06200419383561308 | validation: 0.05002219661045757]
	TIME [epoch: 11.6 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058839517431325636		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.058839517431325636 | validation: 0.05388163121840982]
	TIME [epoch: 11.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053664100086821355		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.053664100086821355 | validation: 0.05881574831483052]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06136261785625493		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.06136261785625493 | validation: 0.055045550294195396]
	TIME [epoch: 11.6 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06081205882872208		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.06081205882872208 | validation: 0.07663979910837929]
	TIME [epoch: 11.5 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07298312829212732		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.07298312829212732 | validation: 0.07426073895068162]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07313070681105913		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.07313070681105913 | validation: 0.0882189501598927]
	TIME [epoch: 11.6 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07564057568454728		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.07564057568454728 | validation: 0.0759367421907528]
	TIME [epoch: 11.6 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06774470519130801		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.06774470519130801 | validation: 0.06602989942718267]
	TIME [epoch: 11.6 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06407735903685928		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.06407735903685928 | validation: 0.06695087908986493]
	TIME [epoch: 11.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05844271054095064		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.05844271054095064 | validation: 0.042643452783139794]
	TIME [epoch: 11.6 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058575181776265764		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.058575181776265764 | validation: 0.05961469501754125]
	TIME [epoch: 11.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06305620636004648		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.06305620636004648 | validation: 0.06146550540144073]
	TIME [epoch: 11.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05789521729709293		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.05789521729709293 | validation: 0.05068710388542717]
	TIME [epoch: 11.6 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04578617902415099		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.04578617902415099 | validation: 0.045689422010534324]
	TIME [epoch: 11.6 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047318694506292606		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.047318694506292606 | validation: 0.05675344612331703]
	TIME [epoch: 11.6 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05073620750513817		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.05073620750513817 | validation: 0.04462995997354474]
	TIME [epoch: 11.6 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04960999858499811		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.04960999858499811 | validation: 0.051887337366629156]
	TIME [epoch: 11.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06204125032979013		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.06204125032979013 | validation: 0.05830927540013163]
	TIME [epoch: 11.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06435407646359953		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.06435407646359953 | validation: 0.06036789556469845]
	TIME [epoch: 11.6 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06564748146835685		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.06564748146835685 | validation: 0.05587738733931945]
	TIME [epoch: 11.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06322210528289167		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.06322210528289167 | validation: 0.057493335079870235]
	TIME [epoch: 11.6 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05472239115414011		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.05472239115414011 | validation: 0.04819429601361861]
	TIME [epoch: 11.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05689999027475409		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.05689999027475409 | validation: 0.048323859580067276]
	TIME [epoch: 11.6 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05609512387867966		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.05609512387867966 | validation: 0.04655276672952208]
	TIME [epoch: 11.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05076537142787296		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.05076537142787296 | validation: 0.041747976206123416]
	TIME [epoch: 11.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04230704028878586		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.04230704028878586 | validation: 0.03335566157138346]
	TIME [epoch: 11.6 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043257044210659706		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.043257044210659706 | validation: 0.03838974150265832]
	TIME [epoch: 11.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04622820446968314		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.04622820446968314 | validation: 0.04582910537135924]
	TIME [epoch: 11.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05629357131168225		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.05629357131168225 | validation: 0.057519321329365804]
	TIME [epoch: 11.6 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05848827683167828		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.05848827683167828 | validation: 0.04571467773784723]
	TIME [epoch: 11.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055419235596423144		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.055419235596423144 | validation: 0.06251271264394866]
	TIME [epoch: 11.6 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05049173446709712		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.05049173446709712 | validation: 0.03837158916138465]
	TIME [epoch: 11.6 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04364818586942028		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.04364818586942028 | validation: 0.033875796430172446]
	TIME [epoch: 11.6 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044383593594187504		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.044383593594187504 | validation: 0.04181653251639531]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04769556464089748		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.04769556464089748 | validation: 0.0397510622923886]
	TIME [epoch: 11.6 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056321401471697015		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.056321401471697015 | validation: 0.06049030083108863]
	TIME [epoch: 11.6 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058491429310726005		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.058491429310726005 | validation: 0.03406488339883261]
	TIME [epoch: 11.6 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05030504307157946		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.05030504307157946 | validation: 0.048947619137949136]
	TIME [epoch: 11.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05504898675829675		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.05504898675829675 | validation: 0.054500026221077906]
	TIME [epoch: 11.6 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05331199818283189		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.05331199818283189 | validation: 0.04336545094408214]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046627198326785455		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.046627198326785455 | validation: 0.0405717189212867]
	TIME [epoch: 11.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041743874901937816		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.041743874901937816 | validation: 0.0360234439707971]
	TIME [epoch: 11.6 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04390945446698695		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.04390945446698695 | validation: 0.03931044173764747]
	TIME [epoch: 11.6 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042999975357769005		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.042999975357769005 | validation: 0.04401598600618459]
	TIME [epoch: 11.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04357331226105743		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.04357331226105743 | validation: 0.039998204173298205]
	TIME [epoch: 11.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046191920834944535		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.046191920834944535 | validation: 0.049818788554051675]
	TIME [epoch: 11.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04792307805470461		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.04792307805470461 | validation: 0.05669848495647337]
	TIME [epoch: 11.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06485821521970159		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.06485821521970159 | validation: 0.07574982970548465]
	TIME [epoch: 11.6 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07047688011479801		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.07047688011479801 | validation: 0.0636861991172081]
	TIME [epoch: 11.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06297827789458116		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.06297827789458116 | validation: 0.0681803909561836]
	TIME [epoch: 11.6 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06971930881725326		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.06971930881725326 | validation: 0.06194097395895794]
	TIME [epoch: 11.5 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06411772609482644		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.06411772609482644 | validation: 0.06892119029834928]
	TIME [epoch: 11.6 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06531117298288172		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.06531117298288172 | validation: 0.06442077857499409]
	TIME [epoch: 11.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06341809537564046		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.06341809537564046 | validation: 0.07977505731903815]
	TIME [epoch: 11.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07363030997171652		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.07363030997171652 | validation: 0.07482293288246722]
	TIME [epoch: 11.6 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06753393196273767		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.06753393196273767 | validation: 0.06580604452768676]
	TIME [epoch: 11.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06927295286199063		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.06927295286199063 | validation: 0.09019055883847805]
	TIME [epoch: 11.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0848886540222689		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.0848886540222689 | validation: 0.08788583045421194]
	TIME [epoch: 11.6 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10280076298537745		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.10280076298537745 | validation: 0.12305822441918528]
	TIME [epoch: 11.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11329766462036732		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.11329766462036732 | validation: 0.11565630796679054]
	TIME [epoch: 11.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09800303296928758		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.09800303296928758 | validation: 0.0966301827291457]
	TIME [epoch: 11.6 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0867569653946753		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.0867569653946753 | validation: 0.07537011130539685]
	TIME [epoch: 11.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07420016323235187		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.07420016323235187 | validation: 0.07823098156613036]
	TIME [epoch: 11.6 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0919325830098664		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.0919325830098664 | validation: 0.09583819369922339]
	TIME [epoch: 11.6 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10459814765556112		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.10459814765556112 | validation: 0.12430592195369046]
	TIME [epoch: 11.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12619555597480445		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.12619555597480445 | validation: 0.13317043453572286]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12252388932462396		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.12252388932462396 | validation: 0.11712734367429818]
	TIME [epoch: 11.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11727986655121952		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.11727986655121952 | validation: 0.14533721439314723]
	TIME [epoch: 11.6 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14355656021588842		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.14355656021588842 | validation: 0.14297958909935887]
	TIME [epoch: 11.6 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12580215507128506		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.12580215507128506 | validation: 0.1200032162938309]
	TIME [epoch: 11.6 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10998564611830453		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.10998564611830453 | validation: 0.105241026905827]
	TIME [epoch: 11.6 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08546449688391117		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.08546449688391117 | validation: 0.08522253157443074]
	TIME [epoch: 11.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07987443625615466		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.07987443625615466 | validation: 0.07053571123870626]
	TIME [epoch: 11.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06461262114275437		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.06461262114275437 | validation: 0.05898343487651988]
	TIME [epoch: 11.6 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06319154638494293		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.06319154638494293 | validation: 0.062066640047558796]
	TIME [epoch: 11.6 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06611888609968428		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.06611888609968428 | validation: 0.06417540072876092]
	TIME [epoch: 11.6 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053346366811681166		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.053346366811681166 | validation: 0.04491334767927747]
	TIME [epoch: 11.6 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05922624750928676		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.05922624750928676 | validation: 0.06681288567429372]
	TIME [epoch: 11.6 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059126089837980664		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.059126089837980664 | validation: 0.049838497828033734]
	TIME [epoch: 11.6 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04923975711065973		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.04923975711065973 | validation: 0.04252473920589122]
	TIME [epoch: 11.6 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05760698757374594		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.05760698757374594 | validation: 0.05782822172805867]
	TIME [epoch: 11.6 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06034371249610579		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.06034371249610579 | validation: 0.050120216051186724]
	TIME [epoch: 11.6 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06514127331636294		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.06514127331636294 | validation: 0.06926640556667835]
	TIME [epoch: 11.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07220217842760492		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.07220217842760492 | validation: 0.0607456386233852]
	TIME [epoch: 11.6 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062695015324373		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.062695015324373 | validation: 0.04583324006740669]
	TIME [epoch: 11.6 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05265599589978825		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.05265599589978825 | validation: 0.049005277629629904]
	TIME [epoch: 11.6 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059089649285987624		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.059089649285987624 | validation: 0.07279397808556581]
	TIME [epoch: 11.6 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06311027007483078		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.06311027007483078 | validation: 0.05644216499309547]
	TIME [epoch: 11.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06925767687537288		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.06925767687537288 | validation: 0.06543268266255409]
	TIME [epoch: 11.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0619678011975111		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.0619678011975111 | validation: 0.057555197125211316]
	TIME [epoch: 11.6 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06293374361512126		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.06293374361512126 | validation: 0.05668561249239654]
	TIME [epoch: 11.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05474739227049822		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.05474739227049822 | validation: 0.04915997867659901]
	TIME [epoch: 11.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04778088478925345		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.04778088478925345 | validation: 0.053227601743300774]
	TIME [epoch: 11.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05084416268394801		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.05084416268394801 | validation: 0.050115157145131414]
	TIME [epoch: 11.6 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050800766417751726		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.050800766417751726 | validation: 0.03948699760630539]
	TIME [epoch: 11.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04909162970942654		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.04909162970942654 | validation: 0.04682858839059234]
	TIME [epoch: 11.6 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048112293546008815		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.048112293546008815 | validation: 0.046546219416028115]
	TIME [epoch: 11.6 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05621141535109675		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.05621141535109675 | validation: 0.05239307248621355]
	TIME [epoch: 11.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055993873877912576		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.055993873877912576 | validation: 0.0471612553869587]
	TIME [epoch: 11.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047171734167874804		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.047171734167874804 | validation: 0.0463185238887062]
	TIME [epoch: 11.6 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05026059260834115		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.05026059260834115 | validation: 0.06429487184055789]
	TIME [epoch: 11.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06374175331224993		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.06374175331224993 | validation: 0.06459027485718707]
	TIME [epoch: 11.5 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07585771909727872		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.07585771909727872 | validation: 0.08562483194370778]
	TIME [epoch: 11.6 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08153017351923063		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.08153017351923063 | validation: 0.0845132308711686]
	TIME [epoch: 11.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07694717089162191		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.07694717089162191 | validation: 0.06301573149522141]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0673643125113416		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.0673643125113416 | validation: 0.06744322533985497]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06642381534563983		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.06642381534563983 | validation: 0.06765363700068001]
	TIME [epoch: 11.6 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06924406529782917		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.06924406529782917 | validation: 0.08184314635295642]
	TIME [epoch: 11.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06618976574301036		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.06618976574301036 | validation: 0.061130400103511916]
	TIME [epoch: 11.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05613279029791538		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.05613279029791538 | validation: 0.046196855733518005]
	TIME [epoch: 11.6 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04822270818395955		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.04822270818395955 | validation: 0.04588289585958667]
	TIME [epoch: 11.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04540039829680403		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.04540039829680403 | validation: 0.04804680905518142]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04473082077836131		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.04473082077836131 | validation: 0.0418109174779647]
	TIME [epoch: 11.6 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04576127936909685		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.04576127936909685 | validation: 0.04437372827941597]
	TIME [epoch: 11.6 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04980673648199549		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.04980673648199549 | validation: 0.05908819027770061]
	TIME [epoch: 11.6 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053227728642835655		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.053227728642835655 | validation: 0.05464236671726285]
	TIME [epoch: 11.6 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057746379633726544		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.057746379633726544 | validation: 0.05259583969034631]
	TIME [epoch: 11.6 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059951513390927066		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.059951513390927066 | validation: 0.050978491334105085]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054458968215069944		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.054458968215069944 | validation: 0.051865971266255965]
	TIME [epoch: 11.6 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047558665376827916		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.047558665376827916 | validation: 0.05059015077023285]
	TIME [epoch: 11.6 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055063360925908834		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.055063360925908834 | validation: 0.054695805834743975]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05146226441294674		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.05146226441294674 | validation: 0.04366733991377489]
	TIME [epoch: 11.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057660568761773306		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.057660568761773306 | validation: 0.058796544862337256]
	TIME [epoch: 11.6 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06269032315886205		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.06269032315886205 | validation: 0.06691144978298062]
	TIME [epoch: 11.6 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06988973654905128		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.06988973654905128 | validation: 0.08731491366599514]
	TIME [epoch: 11.6 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07100078007992489		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.07100078007992489 | validation: 0.054197219425843705]
	TIME [epoch: 11.6 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055111413101275784		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.055111413101275784 | validation: 0.0559860223543371]
	TIME [epoch: 11.6 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0667253926431112		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.0667253926431112 | validation: 0.06376304763192917]
	TIME [epoch: 11.6 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060369964574285916		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.060369964574285916 | validation: 0.056211263731555924]
	TIME [epoch: 11.6 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055048060936946544		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.055048060936946544 | validation: 0.050370946893110155]
	TIME [epoch: 11.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05182605515172206		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.05182605515172206 | validation: 0.053216885131857856]
	TIME [epoch: 11.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05584123484058099		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.05584123484058099 | validation: 0.05277149218433839]
	TIME [epoch: 11.6 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057071311535294066		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.057071311535294066 | validation: 0.050644143942091394]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04742575606427107		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.04742575606427107 | validation: 0.061340052580534155]
	TIME [epoch: 11.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05534590500250823		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.05534590500250823 | validation: 0.05865802472568778]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05803260010364753		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.05803260010364753 | validation: 0.05800811424252336]
	TIME [epoch: 11.6 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05171892011365715		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.05171892011365715 | validation: 0.048169253512228706]
	TIME [epoch: 11.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046068209100745966		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.046068209100745966 | validation: 0.05203721377588266]
	TIME [epoch: 11.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05190027248935609		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.05190027248935609 | validation: 0.057261224160140345]
	TIME [epoch: 11.6 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04936070093786887		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.04936070093786887 | validation: 0.05906272391070989]
	TIME [epoch: 11.5 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05191674341831493		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.05191674341831493 | validation: 0.046079398911768696]
	TIME [epoch: 11.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057050914804061145		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.057050914804061145 | validation: 0.05102391573357929]
	TIME [epoch: 11.6 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05469056298132871		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.05469056298132871 | validation: 0.04668281942870164]
	TIME [epoch: 11.6 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050760308100481294		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.050760308100481294 | validation: 0.052058376463792036]
	TIME [epoch: 11.6 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058511422018916195		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.058511422018916195 | validation: 0.06527632844579184]
	TIME [epoch: 11.6 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06144870594889351		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.06144870594889351 | validation: 0.05828657802239451]
	TIME [epoch: 11.5 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05502525954728281		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.05502525954728281 | validation: 0.051394681714560984]
	TIME [epoch: 11.6 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05446024170091921		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.05446024170091921 | validation: 0.04520101664300425]
	TIME [epoch: 11.6 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05730034690388226		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.05730034690388226 | validation: 0.04331488197408586]
	TIME [epoch: 11.6 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05170098245570521		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.05170098245570521 | validation: 0.036908509559526195]
	TIME [epoch: 11.6 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053954900576583906		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.053954900576583906 | validation: 0.05224217987031386]
	TIME [epoch: 11.6 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05567367556313135		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.05567367556313135 | validation: 0.05409349109407322]
	TIME [epoch: 11.6 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06564590763957999		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.06564590763957999 | validation: 0.0567070566927278]
	TIME [epoch: 11.6 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056785828356488856		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.056785828356488856 | validation: 0.04898451396916434]
	TIME [epoch: 11.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05471685030190548		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.05471685030190548 | validation: 0.05413707028487044]
	TIME [epoch: 11.6 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05373540081213049		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.05373540081213049 | validation: 0.06315458936481323]
	TIME [epoch: 11.6 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06466709616272813		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.06466709616272813 | validation: 0.0519989744391341]
	TIME [epoch: 11.6 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06494351024344691		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.06494351024344691 | validation: 0.05159697402365637]
	TIME [epoch: 11.6 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058850099994849234		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.058850099994849234 | validation: 0.045916171214394834]
	TIME [epoch: 11.6 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05559421534831588		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.05559421534831588 | validation: 0.04992880709973159]
	TIME [epoch: 11.6 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05398880578935032		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.05398880578935032 | validation: 0.0462273271082101]
	TIME [epoch: 11.6 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047605573873163866		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.047605573873163866 | validation: 0.04243867329908426]
	TIME [epoch: 11.6 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047362215072617106		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.047362215072617106 | validation: 0.04054258060114074]
	TIME [epoch: 11.6 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048860061511203715		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.048860061511203715 | validation: 0.04526225395921186]
	TIME [epoch: 11.6 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04620922615433204		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.04620922615433204 | validation: 0.05019960117163569]
	TIME [epoch: 11.6 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0499858580269579		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.0499858580269579 | validation: 0.03679813610064308]
	TIME [epoch: 11.6 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045116065875619824		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.045116065875619824 | validation: 0.043221227155370835]
	TIME [epoch: 11.6 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049303398715161394		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.049303398715161394 | validation: 0.04975013423604736]
	TIME [epoch: 11.6 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04196610496875945		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.04196610496875945 | validation: 0.04787959553610374]
	TIME [epoch: 11.6 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04912749383458583		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.04912749383458583 | validation: 0.04447198323345801]
	TIME [epoch: 11.6 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052426542697725634		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.052426542697725634 | validation: 0.04725513614801542]
	TIME [epoch: 11.6 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05552285035250655		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.05552285035250655 | validation: 0.05089823315787623]
	TIME [epoch: 11.6 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05405725316156404		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.05405725316156404 | validation: 0.05644925515624181]
	TIME [epoch: 11.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0655128787392033		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.0655128787392033 | validation: 0.06980582277033273]
	TIME [epoch: 11.6 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06819060140892653		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.06819060140892653 | validation: 0.06198820485069954]
	TIME [epoch: 11.6 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07324379571399918		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.07324379571399918 | validation: 0.0760495424421239]
	TIME [epoch: 11.6 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07580170135255011		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.07580170135255011 | validation: 0.07553549512385554]
	TIME [epoch: 11.6 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06863423004340419		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.06863423004340419 | validation: 0.06811047227954595]
	TIME [epoch: 11.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06576535638025502		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.06576535638025502 | validation: 0.06336098230394553]
	TIME [epoch: 11.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061314790210490674		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.061314790210490674 | validation: 0.0656388688275296]
	TIME [epoch: 11.6 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05838589996137977		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.05838589996137977 | validation: 0.055906036115191564]
	TIME [epoch: 11.6 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052264153752255224		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.052264153752255224 | validation: 0.05016250896398505]
	TIME [epoch: 11.6 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0553801230799063		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.0553801230799063 | validation: 0.046775440412238294]
	TIME [epoch: 11.6 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05509024064710426		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.05509024064710426 | validation: 0.04807700524666096]
	TIME [epoch: 11.6 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0497394085875391		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.0497394085875391 | validation: 0.04014480070464838]
	TIME [epoch: 11.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0480090014499738		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.0480090014499738 | validation: 0.045781455923042336]
	TIME [epoch: 11.6 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04836610030166233		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.04836610030166233 | validation: 0.051937932404695165]
	TIME [epoch: 11.6 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050390110865509125		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.050390110865509125 | validation: 0.049912860493416825]
	TIME [epoch: 11.6 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04950984042486133		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.04950984042486133 | validation: 0.041064926863642645]
	TIME [epoch: 11.6 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04722788116298819		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.04722788116298819 | validation: 0.04087231580147835]
	TIME [epoch: 11.6 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043985150682510576		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.043985150682510576 | validation: 0.04270842576454769]
	TIME [epoch: 11.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04677315270344551		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.04677315270344551 | validation: 0.040170090945311036]
	TIME [epoch: 11.6 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04540841535715981		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.04540841535715981 | validation: 0.04845500117534966]
	TIME [epoch: 11.6 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04348861982625895		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.04348861982625895 | validation: 0.03807771084984141]
	TIME [epoch: 11.6 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046681360521002024		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.046681360521002024 | validation: 0.04598355226859217]
	TIME [epoch: 11.6 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04064541611291962		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.04064541611291962 | validation: 0.03241642619002016]
	TIME [epoch: 11.6 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04178217082148405		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.04178217082148405 | validation: 0.04336469025314973]
	TIME [epoch: 11.6 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04804041012089875		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.04804041012089875 | validation: 0.043781994620968025]
	TIME [epoch: 11.6 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04940402890420742		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.04940402890420742 | validation: 0.05081668900767901]
	TIME [epoch: 11.6 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05259314391601884		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.05259314391601884 | validation: 0.054746673161650716]
	TIME [epoch: 11.6 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05770956763772373		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.05770956763772373 | validation: 0.038371487350453745]
	TIME [epoch: 11.6 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04844464532605659		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.04844464532605659 | validation: 0.04231463509761334]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04552658946375099		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.04552658946375099 | validation: 0.051056071289480476]
	TIME [epoch: 11.6 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044850378266787116		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.044850378266787116 | validation: 0.03669699727214927]
	TIME [epoch: 11.6 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04753405487710752		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.04753405487710752 | validation: 0.05013432836029612]
	TIME [epoch: 11.6 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050309898734452074		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.050309898734452074 | validation: 0.042671360132049564]
	TIME [epoch: 11.6 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04997172464385777		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.04997172464385777 | validation: 0.040972508562880476]
	TIME [epoch: 11.6 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04589801554669116		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.04589801554669116 | validation: 0.033845226757989885]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04590032629421774		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.04590032629421774 | validation: 0.03530962546190888]
	TIME [epoch: 11.6 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045102612844262424		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.045102612844262424 | validation: 0.026987466670207374]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_1181.pth
	Model improved!!!
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03993823795216543		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.03993823795216543 | validation: 0.028476368705728065]
	TIME [epoch: 11.6 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04513601051810866		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.04513601051810866 | validation: 0.03571172839612081]
	TIME [epoch: 11.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042193379207760964		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.042193379207760964 | validation: 0.02902071012573247]
	TIME [epoch: 11.6 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04559424619797428		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.04559424619797428 | validation: 0.034660562403933594]
	TIME [epoch: 11.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044407776718582564		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.044407776718582564 | validation: 0.049058590671087234]
	TIME [epoch: 11.6 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053107562855628475		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.053107562855628475 | validation: 0.04596643997393338]
	TIME [epoch: 11.6 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051023111072898045		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.051023111072898045 | validation: 0.037030729052726676]
	TIME [epoch: 11.6 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04770390593915328		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.04770390593915328 | validation: 0.040656548774688994]
	TIME [epoch: 11.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046657517380050396		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.046657517380050396 | validation: 0.04658623431381514]
	TIME [epoch: 11.6 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04337659229439812		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.04337659229439812 | validation: 0.046240977739943054]
	TIME [epoch: 11.6 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04279219848120654		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.04279219848120654 | validation: 0.03909457245340245]
	TIME [epoch: 11.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04279802518157905		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.04279802518157905 | validation: 0.04214573451584627]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049843644291244084		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.049843644291244084 | validation: 0.04538727375386793]
	TIME [epoch: 11.6 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06394474673112419		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.06394474673112419 | validation: 0.05611305747187555]
	TIME [epoch: 11.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05109157417369151		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.05109157417369151 | validation: 0.042052200399399726]
	TIME [epoch: 11.6 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04574888947313066		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.04574888947313066 | validation: 0.04435077945708118]
	TIME [epoch: 11.6 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04213028145352845		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.04213028145352845 | validation: 0.038705785752119484]
	TIME [epoch: 11.6 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04873502140455953		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.04873502140455953 | validation: 0.04887137931055998]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048263821348012104		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.048263821348012104 | validation: 0.04624398083376647]
	TIME [epoch: 11.6 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047452895609943355		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.047452895609943355 | validation: 0.044014346840810945]
	TIME [epoch: 11.6 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05248667486354548		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.05248667486354548 | validation: 0.04321418997610551]
	TIME [epoch: 11.6 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05919691023907457		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.05919691023907457 | validation: 0.05872778751203409]
	TIME [epoch: 11.6 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06663909509311756		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.06663909509311756 | validation: 0.046008738742780365]
	TIME [epoch: 11.6 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056849185738446856		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.056849185738446856 | validation: 0.0485478369349703]
	TIME [epoch: 11.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059794380323765876		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.059794380323765876 | validation: 0.05943734797277706]
	TIME [epoch: 11.6 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06024071133302084		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.06024071133302084 | validation: 0.04842219632822996]
	TIME [epoch: 11.6 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05832756247515744		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.05832756247515744 | validation: 0.05369163298359259]
	TIME [epoch: 11.6 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06332959029813773		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.06332959029813773 | validation: 0.05046562515442707]
	TIME [epoch: 11.6 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056922761607638796		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.056922761607638796 | validation: 0.04140237795202744]
	TIME [epoch: 11.6 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05245197909691077		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.05245197909691077 | validation: 0.046216810233866035]
	TIME [epoch: 11.6 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051165947261146635		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.051165947261146635 | validation: 0.04560993780418572]
	TIME [epoch: 11.6 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04868783837012833		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.04868783837012833 | validation: 0.044685012604209685]
	TIME [epoch: 11.6 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053242246216828125		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.053242246216828125 | validation: 0.03879615572335571]
	TIME [epoch: 11.6 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051085332229881486		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.051085332229881486 | validation: 0.04074870546428013]
	TIME [epoch: 11.6 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048936695886660726		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.048936695886660726 | validation: 0.0490113260220101]
	TIME [epoch: 11.6 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04498214754393048		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.04498214754393048 | validation: 0.041879955392723406]
	TIME [epoch: 11.6 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0445103210608085		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.0445103210608085 | validation: 0.04105226193792389]
	TIME [epoch: 11.6 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04331431123495638		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.04331431123495638 | validation: 0.04895990006080516]
	TIME [epoch: 11.6 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043319832253741364		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.043319832253741364 | validation: 0.04191240473218249]
	TIME [epoch: 11.6 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047285240650223104		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.047285240650223104 | validation: 0.04478262580424451]
	TIME [epoch: 11.6 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045056354322093546		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.045056354322093546 | validation: 0.03310115644795562]
	TIME [epoch: 11.6 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04475565177998538		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.04475565177998538 | validation: 0.03978322784147962]
	TIME [epoch: 11.6 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043172860781624786		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.043172860781624786 | validation: 0.0387454091406121]
	TIME [epoch: 11.6 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04231863546298865		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.04231863546298865 | validation: 0.044790803625101745]
	TIME [epoch: 11.6 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046890978276384		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.046890978276384 | validation: 0.04264598800540001]
	TIME [epoch: 11.6 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04206894223049261		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.04206894223049261 | validation: 0.03638657654856405]
	TIME [epoch: 11.6 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04034827113156998		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.04034827113156998 | validation: 0.04199534865522998]
	TIME [epoch: 11.6 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0395461153198574		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.0395461153198574 | validation: 0.029171477525137705]
	TIME [epoch: 11.6 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03913387093616695		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.03913387093616695 | validation: 0.03203808152647323]
	TIME [epoch: 11.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041702960709393486		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.041702960709393486 | validation: 0.03961405966314263]
	TIME [epoch: 11.6 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03720421698938961		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.03720421698938961 | validation: 0.04014402996711055]
	TIME [epoch: 11.6 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03947526537816548		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.03947526537816548 | validation: 0.04688556009885808]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041281904508810696		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.041281904508810696 | validation: 0.04036214186857816]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04223037158504792		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.04223037158504792 | validation: 0.03973193136593418]
	TIME [epoch: 11.6 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04063493581586347		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.04063493581586347 | validation: 0.03696393617683996]
	TIME [epoch: 11.6 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04013701191029404		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.04013701191029404 | validation: 0.03600492035325468]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04154083363017231		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.04154083363017231 | validation: 0.039318011906597464]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040641026943153476		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.040641026943153476 | validation: 0.04008553528940904]
	TIME [epoch: 11.6 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04295086104790623		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.04295086104790623 | validation: 0.03229904381029206]
	TIME [epoch: 11.6 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04191429988289143		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.04191429988289143 | validation: 0.029186666096303628]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03812209608803337		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.03812209608803337 | validation: 0.03437129718662423]
	TIME [epoch: 11.6 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04003107845172561		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.04003107845172561 | validation: 0.03550286256781325]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04654323651791256		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.04654323651791256 | validation: 0.04383728458681226]
	TIME [epoch: 11.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04301973251413111		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.04301973251413111 | validation: 0.0335390127144873]
	TIME [epoch: 11.6 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040556220876567635		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.040556220876567635 | validation: 0.041417475943872295]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043412706178992774		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.043412706178992774 | validation: 0.03623725440747217]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042071485401926866		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.042071485401926866 | validation: 0.031903459053407274]
	TIME [epoch: 11.6 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042058506326311		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.042058506326311 | validation: 0.036084535906038405]
	TIME [epoch: 11.6 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043644173448688844		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.043644173448688844 | validation: 0.03840919048109717]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042604560974822875		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.042604560974822875 | validation: 0.04057106357499622]
	TIME [epoch: 11.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03946169552210937		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.03946169552210937 | validation: 0.03674773003545261]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041570106391756574		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.041570106391756574 | validation: 0.04212769226299934]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046500620737593076		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.046500620737593076 | validation: 0.03446590090352097]
	TIME [epoch: 11.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04758545662684126		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.04758545662684126 | validation: 0.03804426227696154]
	TIME [epoch: 11.6 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04187570317414541		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.04187570317414541 | validation: 0.03713599395715105]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04447073240584502		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.04447073240584502 | validation: 0.039019834443040795]
	TIME [epoch: 11.5 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04470363549968201		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.04470363549968201 | validation: 0.051790997246485684]
	TIME [epoch: 11.6 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04296140055834783		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.04296140055834783 | validation: 0.0414139529482053]
	TIME [epoch: 11.6 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051225815391716646		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.051225815391716646 | validation: 0.041816820487886555]
	TIME [epoch: 11.6 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04858909883643743		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.04858909883643743 | validation: 0.04553053090553121]
	TIME [epoch: 11.6 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04680359662749182		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.04680359662749182 | validation: 0.03901742011977508]
	TIME [epoch: 11.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04279660396210333		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.04279660396210333 | validation: 0.034975763257386]
	TIME [epoch: 11.6 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04101303613353211		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.04101303613353211 | validation: 0.03507679230977425]
	TIME [epoch: 11.6 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040934645432009434		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.040934645432009434 | validation: 0.04770716774389034]
	TIME [epoch: 11.6 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045134542896616836		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.045134542896616836 | validation: 0.04726872986828237]
	TIME [epoch: 11.6 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04034095188452247		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.04034095188452247 | validation: 0.04197436201687276]
	TIME [epoch: 11.5 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04209719833968859		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.04209719833968859 | validation: 0.0366641043987014]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04216651787502497		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.04216651787502497 | validation: 0.03239974352356525]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040174558633573616		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.040174558633573616 | validation: 0.03847518557972363]
	TIME [epoch: 11.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037900489763818615		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.037900489763818615 | validation: 0.040714867375035546]
	TIME [epoch: 11.6 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040417723771411125		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.040417723771411125 | validation: 0.042965527278721355]
	TIME [epoch: 11.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04237403900861356		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.04237403900861356 | validation: 0.03527287875399651]
	TIME [epoch: 11.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040317871248542934		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.040317871248542934 | validation: 0.03789251748776858]
	TIME [epoch: 11.6 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0398087826927546		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.0398087826927546 | validation: 0.03634201614564093]
	TIME [epoch: 11.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03995381166803276		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.03995381166803276 | validation: 0.03732496839416267]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04218798553754028		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.04218798553754028 | validation: 0.04271420717074194]
	TIME [epoch: 11.6 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04176546466839112		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.04176546466839112 | validation: 0.0402009604277018]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042464047601908736		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.042464047601908736 | validation: 0.041526379475913686]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043371289760672616		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.043371289760672616 | validation: 0.031500277057365564]
	TIME [epoch: 11.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038504910249665424		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.038504910249665424 | validation: 0.03473050625009223]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044320108067848654		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.044320108067848654 | validation: 0.03673226935500898]
	TIME [epoch: 11.6 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04468872406641759		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.04468872406641759 | validation: 0.03494125123014905]
	TIME [epoch: 11.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04690059713650355		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.04690059713650355 | validation: 0.03132910955368657]
	TIME [epoch: 11.6 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04451401110788132		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.04451401110788132 | validation: 0.042263658692710496]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041747612947723535		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.041747612947723535 | validation: 0.031984795164589984]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04230076899313809		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.04230076899313809 | validation: 0.037014630770134706]
	TIME [epoch: 11.6 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04497546100742489		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.04497546100742489 | validation: 0.036181223802020844]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04014106334841972		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.04014106334841972 | validation: 0.03433095047840069]
	TIME [epoch: 11.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04111022734245783		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.04111022734245783 | validation: 0.03499396185507534]
	TIME [epoch: 11.6 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04181355529260003		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.04181355529260003 | validation: 0.038537012729634154]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04565363669233931		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.04565363669233931 | validation: 0.034541377072152823]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045874793367911934		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.045874793367911934 | validation: 0.042620396335044115]
	TIME [epoch: 11.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042469725902337524		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.042469725902337524 | validation: 0.041498675519705056]
	TIME [epoch: 11.6 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04252706403943253		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.04252706403943253 | validation: 0.025606119708672624]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_1295.pth
	Model improved!!!
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04444462215869716		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.04444462215869716 | validation: 0.036093546008971335]
	TIME [epoch: 11.6 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04310494017740663		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.04310494017740663 | validation: 0.029874777939156365]
	TIME [epoch: 11.6 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04241836889674737		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.04241836889674737 | validation: 0.032788065920844184]
	TIME [epoch: 11.6 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0410167025517977		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.0410167025517977 | validation: 0.03277240054949201]
	TIME [epoch: 11.5 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04476959532157937		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.04476959532157937 | validation: 0.039199732710067076]
	TIME [epoch: 11.6 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04326259896228593		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.04326259896228593 | validation: 0.03846444736917453]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04015962104798669		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.04015962104798669 | validation: 0.03442111772856664]
	TIME [epoch: 11.5 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04053041570288228		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.04053041570288228 | validation: 0.03211677619278995]
	TIME [epoch: 11.6 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0408562680347673		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.0408562680347673 | validation: 0.03737127631229536]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04103330004935446		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.04103330004935446 | validation: 0.03767636208946032]
	TIME [epoch: 11.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04537860685992622		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.04537860685992622 | validation: 0.03775008152295295]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0472155754282626		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.0472155754282626 | validation: 0.044698127984347046]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045557051362371336		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.045557051362371336 | validation: 0.03418583548539256]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04208444742028421		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.04208444742028421 | validation: 0.04013744619504039]
	TIME [epoch: 11.5 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0466093484789544		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.0466093484789544 | validation: 0.034411713914009615]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046259826497792866		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.046259826497792866 | validation: 0.0415191470231741]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04539765257736246		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.04539765257736246 | validation: 0.04177075578529003]
	TIME [epoch: 11.6 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04833136687001958		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.04833136687001958 | validation: 0.03903212657664616]
	TIME [epoch: 11.6 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052042791635446305		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.052042791635446305 | validation: 0.0445261690321093]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050429068062882255		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.050429068062882255 | validation: 0.045951133001554165]
	TIME [epoch: 11.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05294591916164108		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.05294591916164108 | validation: 0.03567904399401448]
	TIME [epoch: 11.6 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046178700955187696		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.046178700955187696 | validation: 0.0360093758100668]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045086633509134624		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.045086633509134624 | validation: 0.034913709456773405]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04612725492419543		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.04612725492419543 | validation: 0.03544662103934019]
	TIME [epoch: 11.6 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050312266645474		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.050312266645474 | validation: 0.03900373794346673]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042507205950190086		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.042507205950190086 | validation: 0.04297907294625173]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05022120962097172		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.05022120962097172 | validation: 0.04250911874395392]
	TIME [epoch: 11.6 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049886215055509726		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.049886215055509726 | validation: 0.049035528310987404]
	TIME [epoch: 11.6 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04750252420240484		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.04750252420240484 | validation: 0.0393981706880646]
	TIME [epoch: 11.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048939729910984525		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.048939729910984525 | validation: 0.034924849395631376]
	TIME [epoch: 11.6 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051473745195080536		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.051473745195080536 | validation: 0.042984370908209384]
	TIME [epoch: 11.6 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04848665066917629		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.04848665066917629 | validation: 0.04295864361400646]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053276945046271715		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.053276945046271715 | validation: 0.04922137643349811]
	TIME [epoch: 11.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0528838990205569		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.0528838990205569 | validation: 0.05098490421014275]
	TIME [epoch: 11.6 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052155600806317204		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.052155600806317204 | validation: 0.04509729616620408]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048087693749248185		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.048087693749248185 | validation: 0.04211376944326634]
	TIME [epoch: 11.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046277352513168876		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.046277352513168876 | validation: 0.042979860545073974]
	TIME [epoch: 11.6 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04393369978865646		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.04393369978865646 | validation: 0.04110333836444843]
	TIME [epoch: 11.6 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04870244645987884		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.04870244645987884 | validation: 0.04106416440986532]
	TIME [epoch: 11.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04537093362428441		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.04537093362428441 | validation: 0.03682829435095353]
	TIME [epoch: 11.6 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046070818153887125		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.046070818153887125 | validation: 0.03568464369268683]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04666101669074527		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.04666101669074527 | validation: 0.03973932379476475]
	TIME [epoch: 11.6 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04900600830489153		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.04900600830489153 | validation: 0.04876949555217738]
	TIME [epoch: 11.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055005061925276946		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.055005061925276946 | validation: 0.04636882623064402]
	TIME [epoch: 11.6 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05040248759561905		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.05040248759561905 | validation: 0.04853471546732876]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05110190884943351		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.05110190884943351 | validation: 0.0492115928208635]
	TIME [epoch: 11.6 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04815332734611785		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.04815332734611785 | validation: 0.039187528752456464]
	TIME [epoch: 11.6 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050437738110709285		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.050437738110709285 | validation: 0.052218411170747214]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051166195822835124		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.051166195822835124 | validation: 0.04131986142861119]
	TIME [epoch: 11.6 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05115769010170835		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.05115769010170835 | validation: 0.04252754055991688]
	TIME [epoch: 11.6 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04678980979429041		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.04678980979429041 | validation: 0.04329599375929348]
	TIME [epoch: 11.6 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04446005840154012		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.04446005840154012 | validation: 0.035396504350285816]
	TIME [epoch: 11.5 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045976391689744586		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.045976391689744586 | validation: 0.036974158648375444]
	TIME [epoch: 11.6 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047814698560388745		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.047814698560388745 | validation: 0.031890715288056815]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045262375398981286		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.045262375398981286 | validation: 0.04093914450410701]
	TIME [epoch: 11.5 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04753126839169007		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.04753126839169007 | validation: 0.04644531762704977]
	TIME [epoch: 11.5 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043119725182356634		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.043119725182356634 | validation: 0.0319553942334435]
	TIME [epoch: 11.6 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04540404330206855		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.04540404330206855 | validation: 0.029170565736184564]
	TIME [epoch: 11.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044404465418129854		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.044404465418129854 | validation: 0.040308379287261345]
	TIME [epoch: 11.5 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045056367903276544		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.045056367903276544 | validation: 0.04483086506134708]
	TIME [epoch: 11.6 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04465796359158994		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.04465796359158994 | validation: 0.03286148901143337]
	TIME [epoch: 11.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044730400854055094		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.044730400854055094 | validation: 0.037889702158920756]
	TIME [epoch: 11.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045100086135923076		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.045100086135923076 | validation: 0.042097828561450154]
	TIME [epoch: 11.6 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0459393564127986		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.0459393564127986 | validation: 0.040869737676959075]
	TIME [epoch: 11.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04220824089219183		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.04220824089219183 | validation: 0.03486612816440189]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042010545173978064		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.042010545173978064 | validation: 0.03269445732787193]
	TIME [epoch: 11.6 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04365232212861611		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.04365232212861611 | validation: 0.03193329604873529]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04355345133938318		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.04355345133938318 | validation: 0.03708215962364013]
	TIME [epoch: 11.5 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04342838065849254		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.04342838065849254 | validation: 0.03587149782134616]
	TIME [epoch: 11.6 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04274624088910529		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.04274624088910529 | validation: 0.043419550166948165]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043573404093400325		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.043573404093400325 | validation: 0.03716626206617141]
	TIME [epoch: 11.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044353375111546064		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.044353375111546064 | validation: 0.047227751235991024]
	TIME [epoch: 11.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050580029184449336		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.050580029184449336 | validation: 0.03608431471876334]
	TIME [epoch: 11.6 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045730170759747994		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.045730170759747994 | validation: 0.034435062445441436]
	TIME [epoch: 11.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04672795270463709		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.04672795270463709 | validation: 0.0411871230204393]
	TIME [epoch: 11.5 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04543900708723002		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.04543900708723002 | validation: 0.0414961023011577]
	TIME [epoch: 11.6 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04595288687340776		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.04595288687340776 | validation: 0.033980156397145904]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04643926386252119		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.04643926386252119 | validation: 0.04799819982216149]
	TIME [epoch: 11.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04362060831061241		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.04362060831061241 | validation: 0.04574549352707046]
	TIME [epoch: 11.6 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0417272543729252		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.0417272543729252 | validation: 0.040215322760435004]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04379685876434475		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.04379685876434475 | validation: 0.040423168815900884]
	TIME [epoch: 11.5 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04389275732468617		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.04389275732468617 | validation: 0.04022893983502298]
	TIME [epoch: 11.6 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04335299974224094		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.04335299974224094 | validation: 0.04133020440395147]
	TIME [epoch: 11.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042623155771229784		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.042623155771229784 | validation: 0.041491956367382614]
	TIME [epoch: 11.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04018532556898212		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.04018532556898212 | validation: 0.03281879065767184]
	TIME [epoch: 11.6 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03860435301998177		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.03860435301998177 | validation: 0.03743264433539275]
	TIME [epoch: 11.6 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041465778846394984		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.041465778846394984 | validation: 0.03897766515102286]
	TIME [epoch: 11.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038982641126749845		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.038982641126749845 | validation: 0.033496434397489915]
	TIME [epoch: 11.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04177619021925598		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.04177619021925598 | validation: 0.044598608502568755]
	TIME [epoch: 11.6 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04408314665048904		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.04408314665048904 | validation: 0.028133489596596534]
	TIME [epoch: 11.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04049587878042804		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.04049587878042804 | validation: 0.034887542473373986]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04334938182428559		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.04334938182428559 | validation: 0.03055031526302829]
	TIME [epoch: 11.6 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04039703980898146		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.04039703980898146 | validation: 0.036387391689527954]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038065760423364896		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.038065760423364896 | validation: 0.03786744787457238]
	TIME [epoch: 11.6 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04184075533278474		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.04184075533278474 | validation: 0.029355282569028834]
	TIME [epoch: 11.6 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04372172587215575		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.04372172587215575 | validation: 0.03860628596126113]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04427645426700538		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.04427645426700538 | validation: 0.045037603038672755]
	TIME [epoch: 11.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04426615984067256		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.04426615984067256 | validation: 0.03796974606586917]
	TIME [epoch: 11.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04437637115044095		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.04437637115044095 | validation: 0.03432937581642845]
	TIME [epoch: 11.6 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041028588765246995		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.041028588765246995 | validation: 0.04144201260846135]
	TIME [epoch: 11.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0498499591785955		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.0498499591785955 | validation: 0.0398579558112606]
	TIME [epoch: 11.5 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050798572409867876		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.050798572409867876 | validation: 0.04040800466712372]
	TIME [epoch: 11.6 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04800567630540038		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.04800567630540038 | validation: 0.04800096797952747]
	TIME [epoch: 11.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05000067434903627		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.05000067434903627 | validation: 0.04376710991438798]
	TIME [epoch: 11.5 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04991361438784341		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.04991361438784341 | validation: 0.044050249750514595]
	TIME [epoch: 11.6 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04642973118029792		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.04642973118029792 | validation: 0.039183287147042944]
	TIME [epoch: 11.6 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045098674503843555		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.045098674503843555 | validation: 0.029558788948605384]
	TIME [epoch: 11.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04962732771244317		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.04962732771244317 | validation: 0.042819089919279726]
	TIME [epoch: 11.6 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05108527744030468		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.05108527744030468 | validation: 0.032852197783707446]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050154595758596356		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.050154595758596356 | validation: 0.030955289110793205]
	TIME [epoch: 11.6 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047711723795380516		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.047711723795380516 | validation: 0.04416003469053016]
	TIME [epoch: 11.6 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04587464875424916		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.04587464875424916 | validation: 0.04049424285054024]
	TIME [epoch: 11.6 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043652544161886804		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.043652544161886804 | validation: 0.03093130820379774]
	TIME [epoch: 11.5 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04992092983486624		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.04992092983486624 | validation: 0.03704382404783318]
	TIME [epoch: 11.6 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047373818233173715		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.047373818233173715 | validation: 0.04247925708958312]
	TIME [epoch: 11.6 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04945870916073834		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.04945870916073834 | validation: 0.04075004547653485]
	TIME [epoch: 11.6 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04408805660255161		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.04408805660255161 | validation: 0.04204790635360272]
	TIME [epoch: 11.6 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04446272894986106		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.04446272894986106 | validation: 0.036220706185410456]
	TIME [epoch: 11.6 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047818088376510776		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.047818088376510776 | validation: 0.042431230078140335]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04501291888591363		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.04501291888591363 | validation: 0.041229714806477795]
	TIME [epoch: 11.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04828673655278154		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.04828673655278154 | validation: 0.03463814563747533]
	TIME [epoch: 11.6 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04476545309792602		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.04476545309792602 | validation: 0.03619091407579984]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04427961355262661		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.04427961355262661 | validation: 0.038638203497447704]
	TIME [epoch: 11.6 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047305898654238066		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.047305898654238066 | validation: 0.027772536079296632]
	TIME [epoch: 11.6 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043322462079091316		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.043322462079091316 | validation: 0.029567357579614498]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04382258228870871		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.04382258228870871 | validation: 0.03086208824906458]
	TIME [epoch: 11.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04551375919589438		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.04551375919589438 | validation: 0.04115280516304447]
	TIME [epoch: 11.6 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04848460544511426		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.04848460544511426 | validation: 0.03747008943133621]
	TIME [epoch: 11.6 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0444107825429539		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.0444107825429539 | validation: 0.03871211566220157]
	TIME [epoch: 11.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041947557145117075		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.041947557145117075 | validation: 0.03882485902515425]
	TIME [epoch: 11.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04561000718584449		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.04561000718584449 | validation: 0.045185355227650645]
	TIME [epoch: 11.6 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04288405752424523		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.04288405752424523 | validation: 0.03397598081375112]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04009547024405372		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.04009547024405372 | validation: 0.02762541417524232]
	TIME [epoch: 11.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04181828440013547		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.04181828440013547 | validation: 0.03358166360517771]
	TIME [epoch: 11.6 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04193744271356404		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.04193744271356404 | validation: 0.029669632343710898]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03943443461733914		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.03943443461733914 | validation: 0.04163690444752034]
	TIME [epoch: 11.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04331606477551507		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.04331606477551507 | validation: 0.031459197546043934]
	TIME [epoch: 11.6 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04341771134709529		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.04341771134709529 | validation: 0.046030987096516165]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041039738915755714		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.041039738915755714 | validation: 0.027056368999609073]
	TIME [epoch: 11.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039810449149403196		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.039810449149403196 | validation: 0.027619714034381522]
	TIME [epoch: 11.5 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04260141143710915		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.04260141143710915 | validation: 0.02792664331770502]
	TIME [epoch: 11.6 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04284400464828489		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.04284400464828489 | validation: 0.028275276138355548]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03946179281850759		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.03946179281850759 | validation: 0.03692474048998864]
	TIME [epoch: 11.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03868441079876281		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.03868441079876281 | validation: 0.04090914896962759]
	TIME [epoch: 11.6 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04456352356773719		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.04456352356773719 | validation: 0.03068360476531838]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041614289433625364		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.041614289433625364 | validation: 0.04455418972002015]
	TIME [epoch: 11.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03678307283124829		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.03678307283124829 | validation: 0.03318805465699831]
	TIME [epoch: 11.6 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04113556097137675		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.04113556097137675 | validation: 0.03157645515637939]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04274223742555809		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.04274223742555809 | validation: 0.039463990248261895]
	TIME [epoch: 11.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04232769653429004		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.04232769653429004 | validation: 0.030114345987853453]
	TIME [epoch: 11.6 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0426510076902791		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.0426510076902791 | validation: 0.038327647878703734]
	TIME [epoch: 11.6 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04083068172006455		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.04083068172006455 | validation: 0.03394152899084748]
	TIME [epoch: 11.6 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043461098753076514		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.043461098753076514 | validation: 0.03732315612053724]
	TIME [epoch: 11.6 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04361384414984542		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.04361384414984542 | validation: 0.03477076202926554]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04104262637598546		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.04104262637598546 | validation: 0.04381429296278837]
	TIME [epoch: 11.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04362707415785433		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.04362707415785433 | validation: 0.03171383385233713]
	TIME [epoch: 11.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041496173824471294		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.041496173824471294 | validation: 0.040322536790176534]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04679504335170616		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.04679504335170616 | validation: 0.03722760901683956]
	TIME [epoch: 11.6 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04638089046725079		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.04638089046725079 | validation: 0.03574728636414269]
	TIME [epoch: 11.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04213908641727435		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.04213908641727435 | validation: 0.03538754823091105]
	TIME [epoch: 11.6 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04057557002678096		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.04057557002678096 | validation: 0.0365147416434776]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04002442126565613		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.04002442126565613 | validation: 0.035089463668025456]
	TIME [epoch: 11.5 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03897310761551758		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.03897310761551758 | validation: 0.03536193939734907]
	TIME [epoch: 11.6 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04583743964154631		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.04583743964154631 | validation: 0.040030217807021574]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04120912818912116		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.04120912818912116 | validation: 0.03359045824872826]
	TIME [epoch: 11.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043715121259961076		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.043715121259961076 | validation: 0.03530698146247699]
	TIME [epoch: 11.6 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041674434796273745		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.041674434796273745 | validation: 0.036907291943156534]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03953487547370101		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.03953487547370101 | validation: 0.03207032670110415]
	TIME [epoch: 11.6 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040087655464786126		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.040087655464786126 | validation: 0.02942711854213017]
	TIME [epoch: 11.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04351677286545814		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.04351677286545814 | validation: 0.026592327240469553]
	TIME [epoch: 11.6 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04057541300362305		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.04057541300362305 | validation: 0.038789722822777734]
	TIME [epoch: 11.6 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04362586864511256		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.04362586864511256 | validation: 0.026428008411523953]
	TIME [epoch: 11.6 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04257027330609228		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.04257027330609228 | validation: 0.041935431894034814]
	TIME [epoch: 11.6 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04251170475038847		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.04251170475038847 | validation: 0.03484212959737219]
	TIME [epoch: 11.6 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043900956101061823		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.043900956101061823 | validation: 0.035908291679158676]
	TIME [epoch: 11.6 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04326267317963617		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.04326267317963617 | validation: 0.03401230235357192]
	TIME [epoch: 11.6 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041921673920028685		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.041921673920028685 | validation: 0.03968760471813214]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04348854824658571		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.04348854824658571 | validation: 0.03714676363098764]
	TIME [epoch: 11.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045507075106529515		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.045507075106529515 | validation: 0.032293012880094965]
	TIME [epoch: 11.6 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04270321285233217		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.04270321285233217 | validation: 0.034556700608546036]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04676448436563243		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.04676448436563243 | validation: 0.04199703967543344]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04499351570034885		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.04499351570034885 | validation: 0.046281384146831854]
	TIME [epoch: 11.6 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047728583736507235		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.047728583736507235 | validation: 0.03757918009532559]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04765098062531757		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.04765098062531757 | validation: 0.03239234641978695]
	TIME [epoch: 11.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04563311839865783		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.04563311839865783 | validation: 0.04162860268324001]
	TIME [epoch: 11.5 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04845619705038501		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.04845619705038501 | validation: 0.03494395231007352]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045369398407681866		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.045369398407681866 | validation: 0.03517948479451898]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042669557540449335		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.042669557540449335 | validation: 0.03472548044968018]
	TIME [epoch: 11.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041170087112591555		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.041170087112591555 | validation: 0.02911780606362054]
	TIME [epoch: 11.6 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037823619746716455		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.037823619746716455 | validation: 0.030839050540090673]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04070469217093449		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.04070469217093449 | validation: 0.033112067638677835]
	TIME [epoch: 11.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03325038083280291		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.03325038083280291 | validation: 0.03617071762098193]
	TIME [epoch: 11.6 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03887306656759265		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.03887306656759265 | validation: 0.03202062917647521]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03699830156297422		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.03699830156297422 | validation: 0.03184551488675418]
	TIME [epoch: 11.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03726806649886377		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.03726806649886377 | validation: 0.038544171245046166]
	TIME [epoch: 11.6 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04086448588179288		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.04086448588179288 | validation: 0.03335232513511834]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04081388686981106		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.04081388686981106 | validation: 0.03754375782611684]
	TIME [epoch: 11.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03756576578644352		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.03756576578644352 | validation: 0.03859926930678451]
	TIME [epoch: 11.5 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040468862278325614		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.040468862278325614 | validation: 0.02968282399613829]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03685361342045173		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.03685361342045173 | validation: 0.03175704055054092]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03653628479484641		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.03653628479484641 | validation: 0.0332885413229895]
	TIME [epoch: 11.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04071557069057263		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.04071557069057263 | validation: 0.03652874999094791]
	TIME [epoch: 11.6 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04105644284205773		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.04105644284205773 | validation: 0.03575889644348666]
	TIME [epoch: 11.6 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04738203617987815		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.04738203617987815 | validation: 0.03635644365730609]
	TIME [epoch: 11.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04265200882740671		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.04265200882740671 | validation: 0.03198777104444368]
	TIME [epoch: 11.6 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03923789822102314		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.03923789822102314 | validation: 0.03259486034674924]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042043950773042724		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.042043950773042724 | validation: 0.032022228674231164]
	TIME [epoch: 11.6 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03917630378613514		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.03917630378613514 | validation: 0.038495071884863674]
	TIME [epoch: 11.6 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03851574794409248		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.03851574794409248 | validation: 0.03821911090756828]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038009207991510766		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.038009207991510766 | validation: 0.02815993038175881]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04196635196509697		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.04196635196509697 | validation: 0.025444085790716074]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_1506.pth
	Model improved!!!
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04000227410346508		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.04000227410346508 | validation: 0.03200588414019553]
	TIME [epoch: 11.6 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037727936186254044		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.037727936186254044 | validation: 0.04132873935713352]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039114445103056214		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.039114445103056214 | validation: 0.027898267069363002]
	TIME [epoch: 11.6 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035771012310397685		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.035771012310397685 | validation: 0.029506928520157825]
	TIME [epoch: 11.6 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040078876912160846		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.040078876912160846 | validation: 0.037173527239043484]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04004047558566267		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.04004047558566267 | validation: 0.03666176349817965]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038320341578119546		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.038320341578119546 | validation: 0.03456425435736474]
	TIME [epoch: 11.6 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03772428856715052		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.03772428856715052 | validation: 0.0320001831638406]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0380121130185614		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.0380121130185614 | validation: 0.03976699819358719]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035860393514533906		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.035860393514533906 | validation: 0.03459668655797555]
	TIME [epoch: 11.6 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03720019604477178		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.03720019604477178 | validation: 0.0356335265400679]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04074954281816078		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.04074954281816078 | validation: 0.03855059245136599]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0388120443260996		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.0388120443260996 | validation: 0.026944917619824343]
	TIME [epoch: 11.6 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039788521570392636		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.039788521570392636 | validation: 0.0368231828761698]
	TIME [epoch: 11.6 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0386016164141942		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.0386016164141942 | validation: 0.03423242978186305]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03729455463537132		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.03729455463537132 | validation: 0.03448383167424361]
	TIME [epoch: 11.6 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038103376681888027		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.038103376681888027 | validation: 0.03474048792678789]
	TIME [epoch: 11.6 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03567213966921402		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.03567213966921402 | validation: 0.037315067948831444]
	TIME [epoch: 11.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042498319160909695		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.042498319160909695 | validation: 0.026206198414298325]
	TIME [epoch: 11.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03956349859439434		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.03956349859439434 | validation: 0.031549914038862543]
	TIME [epoch: 11.6 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036656479956969794		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.036656479956969794 | validation: 0.03393287020946017]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03864035067984474		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.03864035067984474 | validation: 0.027326567853148128]
	TIME [epoch: 11.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039960983629232436		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.039960983629232436 | validation: 0.035007558943600595]
	TIME [epoch: 11.6 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03704122334493159		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.03704122334493159 | validation: 0.03819017933996314]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038497060255545855		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.038497060255545855 | validation: 0.033092146600804145]
	TIME [epoch: 11.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036387179586190005		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.036387179586190005 | validation: 0.03281763492613561]
	TIME [epoch: 11.6 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03826983477253688		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.03826983477253688 | validation: 0.03554779984388762]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036680520444018996		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.036680520444018996 | validation: 0.029466881332925948]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036050959969451506		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.036050959969451506 | validation: 0.027302501305797068]
	TIME [epoch: 11.6 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03711529348123717		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.03711529348123717 | validation: 0.03167822654830296]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03688498737008078		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.03688498737008078 | validation: 0.029016611934941032]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037686794702557265		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.037686794702557265 | validation: 0.03308707404811512]
	TIME [epoch: 11.6 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03909232911020617		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.03909232911020617 | validation: 0.036510780943685366]
	TIME [epoch: 11.6 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03594114854801001		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.03594114854801001 | validation: 0.026739636968220938]
	TIME [epoch: 11.5 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03595678606567587		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.03595678606567587 | validation: 0.02688696153735955]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03827047069017625		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.03827047069017625 | validation: 0.027935063225668435]
	TIME [epoch: 11.6 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03863844698849618		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.03863844698849618 | validation: 0.03303222506136421]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035976770142890274		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.035976770142890274 | validation: 0.02970523190283904]
	TIME [epoch: 11.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03552669903886803		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.03552669903886803 | validation: 0.029983799125175563]
	TIME [epoch: 11.6 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03433949832707995		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.03433949832707995 | validation: 0.032937638571058615]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035082943591146575		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.035082943591146575 | validation: 0.03355862315224534]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0389127806066592		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.0389127806066592 | validation: 0.0324195339032773]
	TIME [epoch: 11.6 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03388762644892164		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.03388762644892164 | validation: 0.028928200740289053]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03470565499073486		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.03470565499073486 | validation: 0.029641060587811664]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033469142344366425		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.033469142344366425 | validation: 0.028463705904703752]
	TIME [epoch: 11.6 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034113215966654106		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.034113215966654106 | validation: 0.03557882664028083]
	TIME [epoch: 11.6 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039029939963279796		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.039029939963279796 | validation: 0.028179834467332077]
	TIME [epoch: 11.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034072914141302396		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.034072914141302396 | validation: 0.038856239859967244]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03414166122121989		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.03414166122121989 | validation: 0.03766072546412852]
	TIME [epoch: 11.6 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03636500244942659		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.03636500244942659 | validation: 0.025460484762210182]
	TIME [epoch: 11.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03473734238632701		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.03473734238632701 | validation: 0.026365088041973576]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03585107893606313		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.03585107893606313 | validation: 0.03295814121204945]
	TIME [epoch: 11.6 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036506393604390834		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.036506393604390834 | validation: 0.03654573171696442]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03235817955638155		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.03235817955638155 | validation: 0.03229273691068785]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036433897381666414		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.036433897381666414 | validation: 0.032813626532991226]
	TIME [epoch: 11.6 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03391809374128439		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.03391809374128439 | validation: 0.027048499133211914]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03731391490625304		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.03731391490625304 | validation: 0.0350478572117567]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03446705245705184		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.03446705245705184 | validation: 0.03411027623259552]
	TIME [epoch: 11.6 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03603750211661461		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.03603750211661461 | validation: 0.034934177533271854]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03764257367752941		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.03764257367752941 | validation: 0.032259225616068594]
	TIME [epoch: 11.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03604529539364559		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.03604529539364559 | validation: 0.02704799868689992]
	TIME [epoch: 11.6 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03475541658796561		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.03475541658796561 | validation: 0.028015499742233673]
	TIME [epoch: 11.6 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03823480165196858		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.03823480165196858 | validation: 0.030789724234109552]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039784889439016174		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.039784889439016174 | validation: 0.03444973466947103]
	TIME [epoch: 11.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038500753123656375		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.038500753123656375 | validation: 0.03581528361185539]
	TIME [epoch: 11.6 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03998963642168395		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.03998963642168395 | validation: 0.029677052445039133]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03908513411808673		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.03908513411808673 | validation: 0.032375309269672234]
	TIME [epoch: 11.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03542854128144867		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.03542854128144867 | validation: 0.04114684686804592]
	TIME [epoch: 11.6 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03757747086333442		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.03757747086333442 | validation: 0.0316608686394357]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03803751281786505		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.03803751281786505 | validation: 0.03231096274939493]
	TIME [epoch: 11.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03561142920717597		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.03561142920717597 | validation: 0.03285897280008936]
	TIME [epoch: 11.6 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0376219739418568		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.0376219739418568 | validation: 0.033972965869889925]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037785833321296015		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.037785833321296015 | validation: 0.0316187317682967]
	TIME [epoch: 11.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035406124333780306		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.035406124333780306 | validation: 0.035490082636947355]
	TIME [epoch: 11.6 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03919590796704947		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.03919590796704947 | validation: 0.03313034471540464]
	TIME [epoch: 11.6 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039728339336065746		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.039728339336065746 | validation: 0.04352480974281457]
	TIME [epoch: 11.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03962767511457202		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.03962767511457202 | validation: 0.03931928445200716]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04120243842298586		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.04120243842298586 | validation: 0.03203723603840659]
	TIME [epoch: 11.6 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03926492516622308		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.03926492516622308 | validation: 0.03497013413519377]
	TIME [epoch: 11.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034889229731991475		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.034889229731991475 | validation: 0.030423064761191422]
	TIME [epoch: 11.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03766219947146929		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.03766219947146929 | validation: 0.02332628070195924]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_1587.pth
	Model improved!!!
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043004234292414754		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.043004234292414754 | validation: 0.03500845286628948]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036385078552811256		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.036385078552811256 | validation: 0.03493881368171705]
	TIME [epoch: 11.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03917335602278854		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.03917335602278854 | validation: 0.03351549613613789]
	TIME [epoch: 11.6 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03787644893179526		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.03787644893179526 | validation: 0.03728462382592186]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03542393557398339		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.03542393557398339 | validation: 0.030051933435982323]
	TIME [epoch: 11.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03423670403277125		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.03423670403277125 | validation: 0.029947728347414757]
	TIME [epoch: 11.6 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036765917901949365		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.036765917901949365 | validation: 0.03244101703688098]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03556776445680194		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.03556776445680194 | validation: 0.03048884895122815]
	TIME [epoch: 11.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03473344280833655		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.03473344280833655 | validation: 0.03481391998726931]
	TIME [epoch: 11.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035577178242908764		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.035577178242908764 | validation: 0.02532374213311397]
	TIME [epoch: 11.6 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033976539092342856		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.033976539092342856 | validation: 0.02933758159569162]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03468177692602607		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.03468177692602607 | validation: 0.027030317827673966]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03222144116162359		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.03222144116162359 | validation: 0.032132786175296905]
	TIME [epoch: 11.6 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03448747487167882		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.03448747487167882 | validation: 0.02755109723227643]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03736129675985238		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.03736129675985238 | validation: 0.03147683958771828]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034839767500697456		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.034839767500697456 | validation: 0.03541650194209521]
	TIME [epoch: 11.6 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03751718855082865		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.03751718855082865 | validation: 0.033568609627418214]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034951139027974025		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.034951139027974025 | validation: 0.03202691124875069]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03508749375139845		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.03508749375139845 | validation: 0.03292188239886319]
	TIME [epoch: 11.6 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03724236896292481		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.03724236896292481 | validation: 0.03125577950944503]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03542102418722394		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.03542102418722394 | validation: 0.03663112796037613]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03658605129967632		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.03658605129967632 | validation: 0.028541127437118063]
	TIME [epoch: 11.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03716847539485804		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.03716847539485804 | validation: 0.03546473932694595]
	TIME [epoch: 11.6 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03652413237025714		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.03652413237025714 | validation: 0.030559508458137898]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03443688338542712		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.03443688338542712 | validation: 0.03554744554297449]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03743329420993301		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.03743329420993301 | validation: 0.034072900173712506]
	TIME [epoch: 11.6 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03738726652732419		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.03738726652732419 | validation: 0.03161071422509405]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037538061994574		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.037538061994574 | validation: 0.039915474187655384]
	TIME [epoch: 11.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03517893555402943		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.03517893555402943 | validation: 0.029486996051692402]
	TIME [epoch: 11.6 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03538856534786759		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.03538856534786759 | validation: 0.027713795588934657]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03433313472663341		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.03433313472663341 | validation: 0.016871159232062418]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240310_003033/states/model_tr_study4_1618.pth
	Model improved!!!
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034156092021675154		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.034156092021675154 | validation: 0.03759128179247044]
	TIME [epoch: 11.6 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03599821535762489		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.03599821535762489 | validation: 0.03106246229541286]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035403968676983366		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.035403968676983366 | validation: 0.03463902874027722]
	TIME [epoch: 11.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03463129812973807		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.03463129812973807 | validation: 0.0241958328620907]
	TIME [epoch: 11.6 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036789851809450644		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.036789851809450644 | validation: 0.027051945368579126]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03528971342098458		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.03528971342098458 | validation: 0.0317132472583932]
	TIME [epoch: 11.5 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0377059896344452		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.0377059896344452 | validation: 0.03614396466454398]
	TIME [epoch: 11.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034980255606808265		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.034980255606808265 | validation: 0.024611589302098884]
	TIME [epoch: 11.6 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03241229467848191		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.03241229467848191 | validation: 0.026169672954325384]
	TIME [epoch: 11.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0364466997001442		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.0364466997001442 | validation: 0.02767793224741617]
	TIME [epoch: 11.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038826172316574786		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.038826172316574786 | validation: 0.030002513799985336]
	TIME [epoch: 11.6 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038437346484553936		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.038437346484553936 | validation: 0.02913274100502802]
	TIME [epoch: 11.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03500605820976068		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.03500605820976068 | validation: 0.03317031232874609]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03740662433744668		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.03740662433744668 | validation: 0.024143183734453424]
	TIME [epoch: 11.6 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034412814294465		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.034412814294465 | validation: 0.03454105946085839]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035765506851489194		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.035765506851489194 | validation: 0.0378821078650696]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03997598273725519		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.03997598273725519 | validation: 0.027277716617427863]
	TIME [epoch: 11.6 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03758024724176168		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.03758024724176168 | validation: 0.023496255431363716]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03674928708926313		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.03674928708926313 | validation: 0.02981773926903535]
	TIME [epoch: 11.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03505168813233872		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.03505168813233872 | validation: 0.03120209265704503]
	TIME [epoch: 11.6 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03409531314179788		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.03409531314179788 | validation: 0.02873106035781503]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03494193344620477		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.03494193344620477 | validation: 0.030742765225566716]
	TIME [epoch: 11.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03984252491938116		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.03984252491938116 | validation: 0.024196540877000593]
	TIME [epoch: 11.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03704669064224077		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.03704669064224077 | validation: 0.025582894857167505]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03801014808036957		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.03801014808036957 | validation: 0.030306428974294728]
	TIME [epoch: 11.6 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03576519341869563		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.03576519341869563 | validation: 0.03653221528809955]
	TIME [epoch: 11.6 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03909660144696449		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.03909660144696449 | validation: 0.030376800955657136]
	TIME [epoch: 11.6 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03702055965258968		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.03702055965258968 | validation: 0.0376973011973686]
	TIME [epoch: 11.5 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03877565220697367		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.03877565220697367 | validation: 0.03855254714020021]
	TIME [epoch: 11.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03640977665846636		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.03640977665846636 | validation: 0.03310630576186631]
	TIME [epoch: 11.6 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03294466599466465		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.03294466599466465 | validation: 0.02904873144276575]
	TIME [epoch: 11.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04081704767441973		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.04081704767441973 | validation: 0.033421876224229104]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039440358826132095		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.039440358826132095 | validation: 0.02322654278300213]
	TIME [epoch: 11.6 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03128222370999952		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.03128222370999952 | validation: 0.027985492670174104]
	TIME [epoch: 11.6 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03600506243284812		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.03600506243284812 | validation: 0.02643006643463213]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03569122238679076		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.03569122238679076 | validation: 0.02945261857122423]
	TIME [epoch: 11.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03913456648702454		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.03913456648702454 | validation: 0.03588185233445163]
	TIME [epoch: 11.6 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03721943068895887		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.03721943068895887 | validation: 0.032042244656786435]
	TIME [epoch: 11.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03710570891932968		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.03710570891932968 | validation: 0.031605732963840866]
	TIME [epoch: 11.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038208838123812316		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.038208838123812316 | validation: 0.03312822048383708]
	TIME [epoch: 11.6 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037240787606260047		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.037240787606260047 | validation: 0.034876153089457296]
	TIME [epoch: 11.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03531144628174769		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.03531144628174769 | validation: 0.032911671894159764]
	TIME [epoch: 11.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037376765872155084		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.037376765872155084 | validation: 0.035388604405975396]
	TIME [epoch: 11.6 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037063763100364605		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.037063763100364605 | validation: 0.029254148187758157]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037401755704083495		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.037401755704083495 | validation: 0.030913680628875635]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03662475675660456		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.03662475675660456 | validation: 0.032223723744757536]
	TIME [epoch: 11.6 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03558224622533225		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.03558224622533225 | validation: 0.029054525094342597]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037385274676703564		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.037385274676703564 | validation: 0.034764401323619944]
	TIME [epoch: 11.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03483998691226432		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.03483998691226432 | validation: 0.02911298484537234]
	TIME [epoch: 11.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038846765672250476		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.038846765672250476 | validation: 0.03244975548465141]
	TIME [epoch: 11.6 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037264819310291596		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.037264819310291596 | validation: 0.0385158860092097]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03860296032532161		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.03860296032532161 | validation: 0.03353925825779375]
	TIME [epoch: 11.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03635773302055143		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.03635773302055143 | validation: 0.031025592115266676]
	TIME [epoch: 11.6 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03559293210266978		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.03559293210266978 | validation: 0.036305883879150354]
	TIME [epoch: 11.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036612309484630554		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.036612309484630554 | validation: 0.032120857026369805]
	TIME [epoch: 11.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0381244672124551		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.0381244672124551 | validation: 0.03145420305099744]
	TIME [epoch: 11.6 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03332777532090848		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.03332777532090848 | validation: 0.030010690397663]
	TIME [epoch: 11.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03536462536237217		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.03536462536237217 | validation: 0.027712834222029886]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03579106915235045		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.03579106915235045 | validation: 0.03926989077279696]
	TIME [epoch: 11.6 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03222550988556226		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.03222550988556226 | validation: 0.03497397593480044]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03673347687415314		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.03673347687415314 | validation: 0.039438176283749925]
	TIME [epoch: 11.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03789972486152869		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.03789972486152869 | validation: 0.03603995910802987]
	TIME [epoch: 11.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040286155649322725		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.040286155649322725 | validation: 0.028166017485395867]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03777942504983567		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.03777942504983567 | validation: 0.020771819076272704]
	TIME [epoch: 11.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0367497447563469		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.0367497447563469 | validation: 0.023072255337358964]
	TIME [epoch: 11.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0402159296810336		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.0402159296810336 | validation: 0.03582294787044448]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034305584216233406		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.034305584216233406 | validation: 0.02662724554943722]
	TIME [epoch: 11.6 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03722439435439798		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.03722439435439798 | validation: 0.0320615189138764]
	TIME [epoch: 11.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0351923654216748		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.0351923654216748 | validation: 0.031213703199904526]
	TIME [epoch: 11.6 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03730451957163128		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.03730451957163128 | validation: 0.03038716454163638]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034680393909039584		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.034680393909039584 | validation: 0.0371893490298481]
	TIME [epoch: 11.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034682290123339746		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.034682290123339746 | validation: 0.03236593998381772]
	TIME [epoch: 11.6 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03651375416528224		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.03651375416528224 | validation: 0.03794289011877508]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036572385496376494		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.036572385496376494 | validation: 0.028077997432709924]
	TIME [epoch: 11.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03733737482509871		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.03733737482509871 | validation: 0.029989994424301607]
	TIME [epoch: 11.6 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03882921632130573		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.03882921632130573 | validation: 0.026420877689005456]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031366490668536		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.031366490668536 | validation: 0.03231962084659655]
	TIME [epoch: 11.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04015912779576351		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.04015912779576351 | validation: 0.03880594129478342]
	TIME [epoch: 11.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035344558532818454		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.035344558532818454 | validation: 0.027815927338200912]
	TIME [epoch: 11.6 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03670836961325552		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.03670836961325552 | validation: 0.027437083817819154]
	TIME [epoch: 11.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03662105435888921		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.03662105435888921 | validation: 0.0343234024064536]
	TIME [epoch: 11.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037352153640495295		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.037352153640495295 | validation: 0.029348741926649175]
	TIME [epoch: 11.6 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0349993072529411		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.0349993072529411 | validation: 0.03759600301500048]
	TIME [epoch: 11.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037611295395472664		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.037611295395472664 | validation: 0.033284442864320314]
	TIME [epoch: 11.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03769548511543918		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.03769548511543918 | validation: 0.025740419250690927]
	TIME [epoch: 11.6 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0342190419404233		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.0342190419404233 | validation: 0.03270387715061082]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03881568051985293		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.03881568051985293 | validation: 0.033732397748703395]
	TIME [epoch: 11.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037723381134466785		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.037723381134466785 | validation: 0.03193691490930643]
	TIME [epoch: 11.6 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036818759963136306		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.036818759963136306 | validation: 0.02912546813357035]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03518407357375038		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.03518407357375038 | validation: 0.03005935741370531]
	TIME [epoch: 11.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038451123027532244		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.038451123027532244 | validation: 0.03410731394677937]
	TIME [epoch: 11.6 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03515318366784506		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.03515318366784506 | validation: 0.0314262137852783]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033334417695719425		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.033334417695719425 | validation: 0.03718916705248242]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03517287224732823		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.03517287224732823 | validation: 0.0229779237141029]
	TIME [epoch: 11.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03692788290590995		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.03692788290590995 | validation: 0.03432784838048186]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03762147162389448		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.03762147162389448 | validation: 0.027323602772229182]
	TIME [epoch: 11.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03631555214812568		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.03631555214812568 | validation: 0.028574293328024584]
	TIME [epoch: 11.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03580186338913584		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.03580186338913584 | validation: 0.028936641287462674]
	TIME [epoch: 11.6 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03471172852717629		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.03471172852717629 | validation: 0.03212081115033579]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035527976570298644		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.035527976570298644 | validation: 0.029268637372683006]
	TIME [epoch: 11.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03601146526369598		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.03601146526369598 | validation: 0.027457369271810167]
	TIME [epoch: 11.6 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03487320769739005		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.03487320769739005 | validation: 0.029292290615596368]
	TIME [epoch: 11.6 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035062862886971705		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.035062862886971705 | validation: 0.032133420010167155]
	TIME [epoch: 11.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03886311398331844		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.03886311398331844 | validation: 0.025364246857495366]
	TIME [epoch: 11.6 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03665685447780458		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.03665685447780458 | validation: 0.029333416153925516]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03532000847081929		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.03532000847081929 | validation: 0.03421951227687166]
	TIME [epoch: 11.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03656290352197096		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.03656290352197096 | validation: 0.030403603561534282]
	TIME [epoch: 11.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03178499912338161		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.03178499912338161 | validation: 0.03936971707152065]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036609025580962365		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.036609025580962365 | validation: 0.032410365769052964]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037554005604297704		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.037554005604297704 | validation: 0.031944588243116176]
	TIME [epoch: 11.5 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03641355016358615		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.03641355016358615 | validation: 0.03320978469659504]
	TIME [epoch: 11.6 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03621844951646255		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.03621844951646255 | validation: 0.02321742542493587]
	TIME [epoch: 11.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03830496963611202		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.03830496963611202 | validation: 0.035671451407443294]
	TIME [epoch: 11.5 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035372142516662		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.035372142516662 | validation: 0.02840076940127667]
	TIME [epoch: 11.6 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03541929946728475		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.03541929946728475 | validation: 0.032592710156142374]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036970282698052165		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.036970282698052165 | validation: 0.026189592479093134]
	TIME [epoch: 11.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03290783245032387		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.03290783245032387 | validation: 0.026328411495119265]
	TIME [epoch: 11.6 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033629835132820675		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.033629835132820675 | validation: 0.027680440044366855]
	TIME [epoch: 11.6 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03507080259104692		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.03507080259104692 | validation: 0.028684961855653893]
	TIME [epoch: 11.6 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032824705007629205		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.032824705007629205 | validation: 0.03076717986019174]
	TIME [epoch: 11.6 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034506370338430584		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.034506370338430584 | validation: 0.036795008917717274]
	TIME [epoch: 11.6 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03891068338412001		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.03891068338412001 | validation: 0.025793437036446064]
	TIME [epoch: 11.6 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03603900550813609		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.03603900550813609 | validation: 0.026558919487619917]
	TIME [epoch: 11.6 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03644040527828887		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.03644040527828887 | validation: 0.028964573742635107]
	TIME [epoch: 11.6 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03459493526784002		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.03459493526784002 | validation: 0.03134857960027054]
	TIME [epoch: 11.6 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033755135377277715		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.033755135377277715 | validation: 0.035313182955288104]
	TIME [epoch: 11.5 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03299665479274251		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.03299665479274251 | validation: 0.031899780552192676]
	TIME [epoch: 11.6 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03393234632974424		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.03393234632974424 | validation: 0.025632017102135963]
	TIME [epoch: 11.6 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0350235540060757		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.0350235540060757 | validation: 0.027272333356249647]
	TIME [epoch: 11.6 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035158014111756807		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.035158014111756807 | validation: 0.030801496008384596]
	TIME [epoch: 11.6 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03195290343345224		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.03195290343345224 | validation: 0.03090354532212302]
	TIME [epoch: 11.6 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0357263600178003		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.0357263600178003 | validation: 0.03088428018435092]
	TIME [epoch: 11.6 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035993280287248075		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.035993280287248075 | validation: 0.036212718880981896]
	TIME [epoch: 11.6 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03727105385429715		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.03727105385429715 | validation: 0.031379971941510265]
	TIME [epoch: 11.6 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037229758908965176		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.037229758908965176 | validation: 0.030829940521110002]
	TIME [epoch: 11.6 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037555911162193575		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.037555911162193575 | validation: 0.02935734048478889]
	TIME [epoch: 11.6 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03649802149488789		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.03649802149488789 | validation: 0.024789180518206194]
	TIME [epoch: 11.6 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0359825227366046		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.0359825227366046 | validation: 0.032115645493791124]
	TIME [epoch: 11.6 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035656781825815165		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.035656781825815165 | validation: 0.03189382952855622]
	TIME [epoch: 11.6 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03529710728510561		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.03529710728510561 | validation: 0.02900731637379967]
	TIME [epoch: 11.6 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03559933133175028		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.03559933133175028 | validation: 0.03497374992209005]
	TIME [epoch: 11.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036045627313771714		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.036045627313771714 | validation: 0.030138590218816496]
	TIME [epoch: 11.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03569418488795922		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.03569418488795922 | validation: 0.030955366755556157]
	TIME [epoch: 11.6 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03497718333870538		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.03497718333870538 | validation: 0.028722972648882836]
	TIME [epoch: 11.6 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03793682791836887		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.03793682791836887 | validation: 0.02932828022124931]
	TIME [epoch: 11.6 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03657192892663016		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.03657192892663016 | validation: 0.032015970677577194]
	TIME [epoch: 11.6 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036618460216665705		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.036618460216665705 | validation: 0.031603882215285733]
	TIME [epoch: 11.6 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03633988972712697		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.03633988972712697 | validation: 0.035488288787454296]
	TIME [epoch: 11.6 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03533911964736573		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.03533911964736573 | validation: 0.02579299000360532]
	TIME [epoch: 11.6 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03576183292055659		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.03576183292055659 | validation: 0.026533533570685514]
	TIME [epoch: 11.6 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04004816954215779		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.04004816954215779 | validation: 0.03207524672255937]
	TIME [epoch: 11.6 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03186203333514394		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.03186203333514394 | validation: 0.030167335566741397]
	TIME [epoch: 11.6 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036909465410535566		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.036909465410535566 | validation: 0.03737501249942848]
	TIME [epoch: 11.6 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03587235460861504		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.03587235460861504 | validation: 0.0307858883835755]
	TIME [epoch: 11.6 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036564188671271314		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.036564188671271314 | validation: 0.0283263898213929]
	TIME [epoch: 11.6 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03534964084674834		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.03534964084674834 | validation: 0.02933553595523665]
	TIME [epoch: 11.6 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03757033616008737		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.03757033616008737 | validation: 0.034434439364802075]
	TIME [epoch: 11.6 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037086953951413065		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.037086953951413065 | validation: 0.027339312989470118]
	TIME [epoch: 11.6 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03726960563164846		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.03726960563164846 | validation: 0.03324494206227212]
	TIME [epoch: 11.6 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03653256948439666		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.03653256948439666 | validation: 0.029122123627724324]
	TIME [epoch: 11.6 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036642350237036284		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.036642350237036284 | validation: 0.032991999206064854]
	TIME [epoch: 11.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03192737511028665		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.03192737511028665 | validation: 0.03250605290864166]
	TIME [epoch: 11.6 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0359857041902828		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.0359857041902828 | validation: 0.03344957736428686]
	TIME [epoch: 11.6 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038524752775891895		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.038524752775891895 | validation: 0.038915426857004776]
	TIME [epoch: 11.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035867585238433024		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.035867585238433024 | validation: 0.03038920790008825]
	TIME [epoch: 11.6 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037317012734778506		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.037317012734778506 | validation: 0.026973605249216773]
	TIME [epoch: 11.6 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03618656382571637		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.03618656382571637 | validation: 0.028219316070098265]
	TIME [epoch: 11.6 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036451655754101024		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.036451655754101024 | validation: 0.025577130104198053]
	TIME [epoch: 11.6 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03502326737215106		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.03502326737215106 | validation: 0.023814747215801253]
	TIME [epoch: 11.6 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031693022359008186		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.031693022359008186 | validation: 0.030033249983448293]
	TIME [epoch: 11.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035513325806443105		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.035513325806443105 | validation: 0.032518395541793185]
	TIME [epoch: 11.6 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03458584573459701		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.03458584573459701 | validation: 0.028681623713040536]
	TIME [epoch: 11.6 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0359421961477613		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.0359421961477613 | validation: 0.029478405217259696]
	TIME [epoch: 11.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03715387322195053		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.03715387322195053 | validation: 0.02728077213592492]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03662048666186914		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.03662048666186914 | validation: 0.027776657216974972]
	TIME [epoch: 11.6 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03703904958069518		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.03703904958069518 | validation: 0.025843933754970766]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037400887274028696		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.037400887274028696 | validation: 0.036808516696086827]
	TIME [epoch: 11.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034915305140771624		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.034915305140771624 | validation: 0.03430728444004248]
	TIME [epoch: 11.6 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03801783358932655		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.03801783358932655 | validation: 0.038079822115292754]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034567625046290684		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.034567625046290684 | validation: 0.0362506149240699]
	TIME [epoch: 11.6 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038209388519351295		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.038209388519351295 | validation: 0.02294766252901206]
	TIME [epoch: 11.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03563125902892179		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.03563125902892179 | validation: 0.03242973403285251]
	TIME [epoch: 11.6 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037843565867005706		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.037843565867005706 | validation: 0.031291787899280554]
	TIME [epoch: 11.6 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03901971102405852		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.03901971102405852 | validation: 0.026976727625712394]
	TIME [epoch: 11.6 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03841602820269203		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.03841602820269203 | validation: 0.0296591528609903]
	TIME [epoch: 11.6 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03590390554976825		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.03590390554976825 | validation: 0.034764202587523954]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03624723894201787		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.03624723894201787 | validation: 0.02725898960222013]
	TIME [epoch: 11.6 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03947793549299074		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.03947793549299074 | validation: 0.03540621113116233]
	TIME [epoch: 11.6 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03926128533257987		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.03926128533257987 | validation: 0.0314660593958464]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03783701636755522		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.03783701636755522 | validation: 0.029262950722785935]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0385222694676155		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.0385222694676155 | validation: 0.023475388727685367]
	TIME [epoch: 11.6 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033678650937026315		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.033678650937026315 | validation: 0.02944979593417001]
	TIME [epoch: 11.6 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03461072311514929		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.03461072311514929 | validation: 0.031606802704748124]
	TIME [epoch: 11.6 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035099640248972455		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.035099640248972455 | validation: 0.036281878591360714]
	TIME [epoch: 11.6 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03722326801702136		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.03722326801702136 | validation: 0.043370652762674745]
	TIME [epoch: 11.6 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03632967281558981		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.03632967281558981 | validation: 0.030446867325614583]
	TIME [epoch: 11.6 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034403725620333024		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.034403725620333024 | validation: 0.025558157644878027]
	TIME [epoch: 11.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037380969418340584		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.037380969418340584 | validation: 0.031242026450269373]
	TIME [epoch: 11.6 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03264030772550713		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.03264030772550713 | validation: 0.028216534572665833]
	TIME [epoch: 11.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037193260249811344		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.037193260249811344 | validation: 0.026455803721211434]
	TIME [epoch: 11.6 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03567947205542351		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.03567947205542351 | validation: 0.034852292617082184]
	TIME [epoch: 11.6 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035568330344278414		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.035568330344278414 | validation: 0.03247471728417274]
	TIME [epoch: 11.6 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034061834726769026		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.034061834726769026 | validation: 0.0282131204602394]
	TIME [epoch: 11.6 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03611507276398597		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.03611507276398597 | validation: 0.032009426074464414]
	TIME [epoch: 11.6 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03777810875889669		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.03777810875889669 | validation: 0.022219347782360687]
	TIME [epoch: 11.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03297203848180959		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.03297203848180959 | validation: 0.0382920325989942]
	TIME [epoch: 11.6 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03441181028137222		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.03441181028137222 | validation: 0.03140513821086069]
	TIME [epoch: 11.6 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032348449511988175		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.032348449511988175 | validation: 0.02831465027783697]
	TIME [epoch: 11.6 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03235819252722304		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.03235819252722304 | validation: 0.03070498195450423]
	TIME [epoch: 11.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03663706561473624		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.03663706561473624 | validation: 0.033093175507049606]
	TIME [epoch: 11.6 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03713050547371337		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.03713050547371337 | validation: 0.030543638001361097]
	TIME [epoch: 11.6 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03903103480193135		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.03903103480193135 | validation: 0.025281840252195258]
	TIME [epoch: 11.6 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03468090251199184		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.03468090251199184 | validation: 0.03167940057494416]
	TIME [epoch: 11.5 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03451153141788276		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.03451153141788276 | validation: 0.03328995363400868]
	TIME [epoch: 11.6 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036851594046359334		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.036851594046359334 | validation: 0.025891462788007004]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03548411182304993		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.03548411182304993 | validation: 0.03424434585786198]
	TIME [epoch: 11.6 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03437926057467783		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.03437926057467783 | validation: 0.02530839989661125]
	TIME [epoch: 11.6 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03453977247895564		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.03453977247895564 | validation: 0.026058827025682997]
	TIME [epoch: 11.6 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03443925084969819		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.03443925084969819 | validation: 0.03367320387134499]
	TIME [epoch: 11.6 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03918278357810935		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.03918278357810935 | validation: 0.025907140145863417]
	TIME [epoch: 11.6 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03718923071883973		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.03718923071883973 | validation: 0.034713190367595785]
	TIME [epoch: 11.6 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03558353342827622		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.03558353342827622 | validation: 0.02416893618006404]
	TIME [epoch: 11.6 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04048648750753101		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.04048648750753101 | validation: 0.0321751612066104]
	TIME [epoch: 11.6 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0382021742133582		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.0382021742133582 | validation: 0.03137182471962783]
	TIME [epoch: 11.6 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034530415282125984		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.034530415282125984 | validation: 0.035415386603350925]
	TIME [epoch: 11.6 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035798073685852194		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.035798073685852194 | validation: 0.031005319670829517]
	TIME [epoch: 11.5 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03570701685919893		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.03570701685919893 | validation: 0.035114705786531614]
	TIME [epoch: 11.6 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038401259963608575		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.038401259963608575 | validation: 0.03146883883822363]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03303152681406297		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.03303152681406297 | validation: 0.032105364185412814]
	TIME [epoch: 11.5 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03563707968276199		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.03563707968276199 | validation: 0.03704067407101541]
	TIME [epoch: 11.6 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04083497164320467		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.04083497164320467 | validation: 0.024284101982158066]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03426610475274366		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.03426610475274366 | validation: 0.026698530917418726]
	TIME [epoch: 11.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03931618366032821		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.03931618366032821 | validation: 0.03825832841731371]
	TIME [epoch: 11.6 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03706343559585372		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.03706343559585372 | validation: 0.025890621778080894]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03848743021941977		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.03848743021941977 | validation: 0.021868761196659783]
	TIME [epoch: 11.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03678223846997717		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.03678223846997717 | validation: 0.03453570224237232]
	TIME [epoch: 11.6 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03458916601985275		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.03458916601985275 | validation: 0.038102497568668195]
	TIME [epoch: 11.6 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03793958234766755		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.03793958234766755 | validation: 0.0316632342298925]
	TIME [epoch: 11.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03379189552741383		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.03379189552741383 | validation: 0.031985233522080485]
	TIME [epoch: 11.5 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03584407064155761		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.03584407064155761 | validation: 0.038698233865825264]
	TIME [epoch: 11.6 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03661429209148749		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.03661429209148749 | validation: 0.023893456511514144]
	TIME [epoch: 11.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037433884799142336		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.037433884799142336 | validation: 0.028957274469493505]
	TIME [epoch: 11.6 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03789158714199748		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.03789158714199748 | validation: 0.0324705853565473]
	TIME [epoch: 11.6 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03297754050609938		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.03297754050609938 | validation: 0.030426210281433122]
	TIME [epoch: 11.6 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03942603544489587		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.03942603544489587 | validation: 0.03232599712264132]
	TIME [epoch: 11.6 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028885422181743295		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.028885422181743295 | validation: 0.03172543575190313]
	TIME [epoch: 11.6 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03318670391364867		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.03318670391364867 | validation: 0.029550726821996023]
	TIME [epoch: 11.6 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037580129673596405		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.037580129673596405 | validation: 0.03438439862461012]
	TIME [epoch: 11.6 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03496271427258204		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.03496271427258204 | validation: 0.031030030596413145]
	TIME [epoch: 11.6 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03592432571837724		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.03592432571837724 | validation: 0.022456001281567783]
	TIME [epoch: 11.6 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03476415726839643		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.03476415726839643 | validation: 0.025449644520086242]
	TIME [epoch: 11.6 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033488349522753376		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.033488349522753376 | validation: 0.034211384246482714]
	TIME [epoch: 11.6 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03598105054595376		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.03598105054595376 | validation: 0.021257316246109225]
	TIME [epoch: 11.6 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03561308267808126		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.03561308267808126 | validation: 0.025556058528429806]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03684563533643677		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.03684563533643677 | validation: 0.029106303662922495]
	TIME [epoch: 11.6 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03757123607845147		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.03757123607845147 | validation: 0.030951901975567846]
	TIME [epoch: 11.6 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03429241449701799		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.03429241449701799 | validation: 0.02316739407702187]
	TIME [epoch: 11.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03770293592948662		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.03770293592948662 | validation: 0.027369148023802966]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03620956236731508		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.03620956236731508 | validation: 0.03249475735219255]
	TIME [epoch: 11.6 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033843879039037884		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.033843879039037884 | validation: 0.032881452755645586]
	TIME [epoch: 11.6 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038141570668578484		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.038141570668578484 | validation: 0.03725794522433248]
	TIME [epoch: 11.6 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03647509702377623		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.03647509702377623 | validation: 0.030287965155128535]
	TIME [epoch: 11.6 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0333663599438694		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.0333663599438694 | validation: 0.03129350889191552]
	TIME [epoch: 11.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031097781086483655		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.031097781086483655 | validation: 0.024122965489358533]
	TIME [epoch: 11.6 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03554017305537705		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.03554017305537705 | validation: 0.027535531379239923]
	TIME [epoch: 11.6 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032878655860677494		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.032878655860677494 | validation: 0.03167238340928599]
	TIME [epoch: 11.6 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03630474197720808		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.03630474197720808 | validation: 0.033663212666327644]
	TIME [epoch: 11.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03374032251066027		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.03374032251066027 | validation: 0.030813130199747036]
	TIME [epoch: 11.6 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035628990930457884		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.035628990930457884 | validation: 0.024861737191161543]
	TIME [epoch: 11.6 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03372716778414143		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.03372716778414143 | validation: 0.039378441296028875]
	TIME [epoch: 11.6 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036027533299328555		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.036027533299328555 | validation: 0.027737051103218332]
	TIME [epoch: 11.6 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032125818059881066		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.032125818059881066 | validation: 0.02383933264511939]
	TIME [epoch: 11.6 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0319388020567803		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.0319388020567803 | validation: 0.026457606669890225]
	TIME [epoch: 11.6 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03516410434765923		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.03516410434765923 | validation: 0.03076805302917465]
	TIME [epoch: 11.6 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035138299508407134		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.035138299508407134 | validation: 0.032470087392522495]
	TIME [epoch: 11.6 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03370593830785232		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.03370593830785232 | validation: 0.022646202351432082]
	TIME [epoch: 11.6 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031690243996166476		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.031690243996166476 | validation: 0.029448334083407336]
	TIME [epoch: 11.6 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03426457327152613		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.03426457327152613 | validation: 0.03220714594131518]
	TIME [epoch: 11.6 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03908146058757818		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.03908146058757818 | validation: 0.029599550056291]
	TIME [epoch: 11.6 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033047875914712393		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.033047875914712393 | validation: 0.029599584031249723]
	TIME [epoch: 11.6 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03352175243277776		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.03352175243277776 | validation: 0.027572847660348905]
	TIME [epoch: 11.6 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03489161283142164		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.03489161283142164 | validation: 0.03481277803588057]
	TIME [epoch: 11.5 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037436097306433214		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.037436097306433214 | validation: 0.032876993097962756]
	TIME [epoch: 11.6 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037414293573386666		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.037414293573386666 | validation: 0.03822997609195053]
	TIME [epoch: 11.6 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0350696545198749		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.0350696545198749 | validation: 0.03241405919671822]
	TIME [epoch: 11.6 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036007401125551425		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.036007401125551425 | validation: 0.021638076038937602]
	TIME [epoch: 11.6 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03434926099204584		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.03434926099204584 | validation: 0.031940318312319284]
	TIME [epoch: 11.6 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037799355145234775		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.037799355145234775 | validation: 0.031494571335856765]
	TIME [epoch: 11.6 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03498407101566102		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.03498407101566102 | validation: 0.03309758550596181]
	TIME [epoch: 11.6 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03552306934734707		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.03552306934734707 | validation: 0.028028420843893637]
	TIME [epoch: 11.6 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03371599245043761		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.03371599245043761 | validation: 0.03147270557222587]
	TIME [epoch: 11.6 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038835259803139316		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.038835259803139316 | validation: 0.02470389071128385]
	TIME [epoch: 11.6 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033684032175757384		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.033684032175757384 | validation: 0.03038363605417971]
	TIME [epoch: 11.5 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035079515008370574		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.035079515008370574 | validation: 0.03283409184137104]
	TIME [epoch: 11.6 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03653418911288227		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.03653418911288227 | validation: 0.024268445476243593]
	TIME [epoch: 11.6 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03697243695716815		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.03697243695716815 | validation: 0.031667995170275395]
	TIME [epoch: 11.6 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03338229055026451		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.03338229055026451 | validation: 0.028569769633738397]
	TIME [epoch: 11.6 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03584313453493941		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.03584313453493941 | validation: 0.03136752720069822]
	TIME [epoch: 11.6 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036345704146105384		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.036345704146105384 | validation: 0.03171666210355462]
	TIME [epoch: 11.6 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03432582877504046		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.03432582877504046 | validation: 0.026052589132893014]
	TIME [epoch: 11.6 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036695167896214645		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.036695167896214645 | validation: 0.041064489615615145]
	TIME [epoch: 11.6 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03401681055554156		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.03401681055554156 | validation: 0.03704057449839701]
	TIME [epoch: 11.5 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03580882989876305		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.03580882989876305 | validation: 0.023098415738078106]
	TIME [epoch: 11.6 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03794517823456113		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.03794517823456113 | validation: 0.0354017818151843]
	TIME [epoch: 11.6 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03766964147000589		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.03766964147000589 | validation: 0.020159322386943332]
	TIME [epoch: 11.6 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03653015608535832		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.03653015608535832 | validation: 0.026957863026047527]
	TIME [epoch: 11.6 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03570455909573116		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.03570455909573116 | validation: 0.031526900051153724]
	TIME [epoch: 11.6 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03612438714614554		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.03612438714614554 | validation: 0.03654045590338439]
	TIME [epoch: 11.6 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03581850082102452		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.03581850082102452 | validation: 0.039642222486928155]
	TIME [epoch: 11.6 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03464743783336601		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.03464743783336601 | validation: 0.028269794127492573]
	TIME [epoch: 11.6 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03444879329887205		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.03444879329887205 | validation: 0.03154685657699227]
	TIME [epoch: 11.5 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035077654670428685		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.035077654670428685 | validation: 0.03121689561330663]
	TIME [epoch: 11.5 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038298923646477		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.038298923646477 | validation: 0.029186747877579026]
	TIME [epoch: 11.5 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03616892908175488		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.03616892908175488 | validation: 0.028030308612604086]
	TIME [epoch: 11.5 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03417713169541368		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.03417713169541368 | validation: 0.03489441798496928]
	TIME [epoch: 11.5 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034545823694924836		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.034545823694924836 | validation: 0.03058387344896868]
	TIME [epoch: 11.6 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0328887117069939		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.0328887117069939 | validation: 0.03317544672220355]
	TIME [epoch: 11.6 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03824709165097214		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.03824709165097214 | validation: 0.029219555767206456]
	TIME [epoch: 11.5 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03618484330849838		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.03618484330849838 | validation: 0.029205252939595753]
	TIME [epoch: 11.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035232010601864254		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.035232010601864254 | validation: 0.03920324091037947]
	TIME [epoch: 11.6 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03631944982755624		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.03631944982755624 | validation: 0.03422176357541608]
	TIME [epoch: 11.5 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03834251125850033		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.03834251125850033 | validation: 0.028432538161253806]
	TIME [epoch: 11.5 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03526257648957809		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.03526257648957809 | validation: 0.023807903885277596]
	TIME [epoch: 11.6 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03591150474807425		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.03591150474807425 | validation: 0.027658220403543512]
	TIME [epoch: 11.5 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034640452672828274		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.034640452672828274 | validation: 0.02878961596173431]
	TIME [epoch: 11.5 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03569840830497626		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.03569840830497626 | validation: 0.02977348269976069]
	TIME [epoch: 11.5 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03192630088931227		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.03192630088931227 | validation: 0.0333013047743338]
	TIME [epoch: 11.6 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036238465478273224		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.036238465478273224 | validation: 0.03498991703565184]
	TIME [epoch: 11.5 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03927289025806025		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.03927289025806025 | validation: 0.031676671693442515]
	TIME [epoch: 11.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035801766846832464		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.035801766846832464 | validation: 0.03313186795810595]
	TIME [epoch: 11.6 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036287885345603815		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.036287885345603815 | validation: 0.025686188918358464]
	TIME [epoch: 11.5 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03306371317358026		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.03306371317358026 | validation: 0.036096380454371635]
	TIME [epoch: 11.5 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03305608328708856		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.03305608328708856 | validation: 0.03539398250761795]
	TIME [epoch: 11.6 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03507178387458846		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.03507178387458846 | validation: 0.028949803303298004]
	TIME [epoch: 11.5 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035710102786345066		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.035710102786345066 | validation: 0.023868957970877222]
	TIME [epoch: 11.5 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03416048784294742		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.03416048784294742 | validation: 0.030939844318727382]
	TIME [epoch: 11.6 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035043636897204494		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.035043636897204494 | validation: 0.02626109835368283]
	TIME [epoch: 11.5 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03685442346379056		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.03685442346379056 | validation: 0.029519316295176873]
	TIME [epoch: 11.5 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035143811410445064		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.035143811410445064 | validation: 0.02540041645422548]
	TIME [epoch: 11.6 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034007725565121015		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.034007725565121015 | validation: 0.02533198181212899]
	TIME [epoch: 11.6 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03529846309628922		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.03529846309628922 | validation: 0.03611078915775673]
	TIME [epoch: 11.5 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036235189417710034		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.036235189417710034 | validation: 0.02279052241717763]
	TIME [epoch: 11.6 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03497710629576636		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.03497710629576636 | validation: 0.03219380960867341]
	TIME [epoch: 11.5 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0374486471166499		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.0374486471166499 | validation: 0.03144337939942682]
	TIME [epoch: 11.5 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03481890965687688		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.03481890965687688 | validation: 0.027278899785021748]
	TIME [epoch: 11.6 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037888894885968645		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.037888894885968645 | validation: 0.031159039815044528]
	TIME [epoch: 11.6 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038738863720466775		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.038738863720466775 | validation: 0.03492837303067741]
	TIME [epoch: 11.6 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03674292391788331		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.03674292391788331 | validation: 0.03502193386689051]
	TIME [epoch: 11.6 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03582842413369334		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.03582842413369334 | validation: 0.033325800433254345]
	TIME [epoch: 11.6 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03528844282952302		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.03528844282952302 | validation: 0.03428517184226015]
	TIME [epoch: 11.6 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033781170902294		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.033781170902294 | validation: 0.027226971434634165]
	TIME [epoch: 11.5 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038775540684963514		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.038775540684963514 | validation: 0.029723397957589798]
	TIME [epoch: 11.6 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03859171090044733		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.03859171090044733 | validation: 0.030878656593758384]
	TIME [epoch: 11.6 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03706514727705887		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.03706514727705887 | validation: 0.026417801905148308]
	TIME [epoch: 11.5 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03587092346737523		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.03587092346737523 | validation: 0.03202483825493929]
	TIME [epoch: 11.6 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03616216334643274		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.03616216334643274 | validation: 0.02640017193980271]
	TIME [epoch: 11.6 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03393681325564196		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.03393681325564196 | validation: 0.033416806205510234]
	TIME [epoch: 11.6 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03610034542805069		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.03610034542805069 | validation: 0.027030577863391622]
	TIME [epoch: 11.6 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03484753736500776		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.03484753736500776 | validation: 0.02690127517189543]
	TIME [epoch: 11.6 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03731887804170417		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.03731887804170417 | validation: 0.0289228121132227]
	TIME [epoch: 11.6 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03477502257904734		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.03477502257904734 | validation: 0.03550282548116988]
	TIME [epoch: 11.5 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03334502951730556		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.03334502951730556 | validation: 0.02854780271055898]
	TIME [epoch: 11.6 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03796201430383912		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.03796201430383912 | validation: 0.02789551423660763]
	TIME [epoch: 11.5 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03546015601756681		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.03546015601756681 | validation: 0.031303491541007616]
	TIME [epoch: 11.6 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03815042056696503		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.03815042056696503 | validation: 0.030001853109105206]
	TIME [epoch: 11.6 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03622133852229089		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.03622133852229089 | validation: 0.023824864094910664]
	TIME [epoch: 11.6 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0349731139273442		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.0349731139273442 | validation: 0.02883077365318636]
	TIME [epoch: 11.6 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03545750719387096		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.03545750719387096 | validation: 0.029087538474041028]
	TIME [epoch: 11.6 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03375233767072586		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.03375233767072586 | validation: 0.02794021894717707]
	TIME [epoch: 11.5 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03428511937293091		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.03428511937293091 | validation: 0.03100713532920264]
	TIME [epoch: 11.6 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03434086364454904		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.03434086364454904 | validation: 0.0251340514258678]
	TIME [epoch: 11.6 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03504636735647657		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.03504636735647657 | validation: 0.037749587437247836]
	TIME [epoch: 11.6 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03842536092029463		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.03842536092029463 | validation: 0.02616339648679581]
	TIME [epoch: 11.6 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034868781472911836		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.034868781472911836 | validation: 0.02451887060085312]
	TIME [epoch: 11.5 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03517828970553192		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.03517828970553192 | validation: 0.03556246372044015]
	TIME [epoch: 11.6 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039582070318593954		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.039582070318593954 | validation: 0.0286936115640724]
	TIME [epoch: 11.6 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034253094653157484		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.034253094653157484 | validation: 0.028123466653883444]
	TIME [epoch: 11.5 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032317724826810126		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.032317724826810126 | validation: 0.02564301582860481]
	TIME [epoch: 11.6 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03578551467582258		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.03578551467582258 | validation: 0.032034578655939935]
	TIME [epoch: 11.6 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03917550636920857		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.03917550636920857 | validation: 0.02782099415274222]
	TIME [epoch: 11.6 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03312446567536888		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.03312446567536888 | validation: 0.031234002429734002]
	TIME [epoch: 11.6 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03183829464725348		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.03183829464725348 | validation: 0.027539116719763196]
	TIME [epoch: 11.6 sec]
Finished training in 23318.958 seconds.
