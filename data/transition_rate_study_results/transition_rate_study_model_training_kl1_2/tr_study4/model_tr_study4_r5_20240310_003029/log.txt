Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r5', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2850630809

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.392921363579243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.392921363579243 | validation: 6.767761968052826]
	TIME [epoch: 100 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.903538638018062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.903538638018062 | validation: 5.686366215975859]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8349201278276634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8349201278276634 | validation: 4.97733734064034]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.521058882474826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.521058882474826 | validation: 4.499417270696403]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2289215349156315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2289215349156315 | validation: 4.267148868126875]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.877975582617433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.877975582617433 | validation: 4.0604178939897295]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.756154295844471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.756154295844471 | validation: 3.8442447080399713]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.492466705706815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.492466705706815 | validation: 3.845800226849706]
	TIME [epoch: 11.5 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4578900597642184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4578900597642184 | validation: 3.6289444309806314]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4989429093314826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4989429093314826 | validation: 4.331616843786868]
	TIME [epoch: 11.5 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.933361668319648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.933361668319648 | validation: 3.6035074991465184]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.283791573413133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.283791573413133 | validation: 3.3591057952558656]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1664067661977997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1664067661977997 | validation: 3.311342127700582]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0862231293227134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0862231293227134 | validation: 3.3951118534785634]
	TIME [epoch: 11.5 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1576575101688578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1576575101688578 | validation: 3.4074959350336576]
	TIME [epoch: 11.5 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1872615893006873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1872615893006873 | validation: 3.299000501372521]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.009570855341594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.009570855341594 | validation: 3.3170034449648167]
	TIME [epoch: 11.5 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1462334423367624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1462334423367624 | validation: 3.258416795464764]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0569461524364616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0569461524364616 | validation: 6.485494033006721]
	TIME [epoch: 11.5 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.568764709500302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.568764709500302 | validation: 3.3123231708193357]
	TIME [epoch: 11.5 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.072635653831019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.072635653831019 | validation: 3.119310315082885]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9524737870755713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9524737870755713 | validation: 2.898311251013199]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.75404270172033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.75404270172033 | validation: 2.722016806080444]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8756095777161903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8756095777161903 | validation: 2.76604473969932]
	TIME [epoch: 11.5 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6860689389949313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6860689389949313 | validation: 2.500569714494608]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.617698211820332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.617698211820332 | validation: 3.0125073223293346]
	TIME [epoch: 11.5 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7884207085178963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7884207085178963 | validation: 2.5388610507584515]
	TIME [epoch: 11.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5516242710146653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5516242710146653 | validation: 2.5215805017370534]
	TIME [epoch: 11.5 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3832476925506905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3832476925506905 | validation: 2.3488244296323306]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4976595710279774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4976595710279774 | validation: 2.553780231946172]
	TIME [epoch: 11.5 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.94062632677785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.94062632677785 | validation: 2.5439372594695584]
	TIME [epoch: 11.5 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27510176294413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.27510176294413 | validation: 2.0549925707319927]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2119686666120773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2119686666120773 | validation: 1.8907296533471456]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9228662768164915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9228662768164915 | validation: 1.9042480115144202]
	TIME [epoch: 11.5 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.997337467654422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.997337467654422 | validation: 1.7988802393683592]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9088380148011583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9088380148011583 | validation: 2.2705329477609446]
	TIME [epoch: 11.5 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7734647141991156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7734647141991156 | validation: 1.6793478103978765]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6333646013278191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6333646013278191 | validation: 1.4470771844445296]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5410142884649214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5410142884649214 | validation: 1.1387425228311916]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.240558527260141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.240558527260141 | validation: 1.4880308161594513]
	TIME [epoch: 11.5 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5442831934601386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5442831934601386 | validation: 1.081278314654673]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.419531607149827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.419531607149827 | validation: 1.1215251169479166]
	TIME [epoch: 11.5 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.49296296944661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.49296296944661 | validation: 1.6213399212722266]
	TIME [epoch: 11.5 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3606734717929279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3606734717929279 | validation: 0.9252980377346947]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1799633682705997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1799633682705997 | validation: 0.9621341397612002]
	TIME [epoch: 11.5 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0274892723485103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0274892723485103 | validation: 0.965398628981485]
	TIME [epoch: 11.5 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2329726966591341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2329726966591341 | validation: 1.1012267124598172]
	TIME [epoch: 11.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1135566102487984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1135566102487984 | validation: 1.0963023625177386]
	TIME [epoch: 11.5 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8273637902701874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8273637902701874 | validation: 0.874166467965014]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9401552478169726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9401552478169726 | validation: 2.2368953949687302]
	TIME [epoch: 11.5 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4385151785412071		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.4385151785412071 | validation: 0.5928026808020712]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.807782150236676		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.807782150236676 | validation: 0.6996339330002159]
	TIME [epoch: 11.5 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.924916651633552		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.924916651633552 | validation: 1.06324685293421]
	TIME [epoch: 11.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9383914929939435		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.9383914929939435 | validation: 2.2120152145091505]
	TIME [epoch: 11.5 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.31111085710413		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.31111085710413 | validation: 0.8345013123169348]
	TIME [epoch: 11.5 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8233875877298666		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.8233875877298666 | validation: 0.7361936486235564]
	TIME [epoch: 11.5 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.840401333892707		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.840401333892707 | validation: 1.0420168437973063]
	TIME [epoch: 11.5 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8518026432634722		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.8518026432634722 | validation: 0.7518676349351734]
	TIME [epoch: 11.5 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.014727139176862		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.014727139176862 | validation: 0.7653506709249854]
	TIME [epoch: 11.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9354074691214724		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.9354074691214724 | validation: 0.8788605159047533]
	TIME [epoch: 11.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9344227195301718		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.9344227195301718 | validation: 0.9787245312119661]
	TIME [epoch: 11.5 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7805323423478886		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.7805323423478886 | validation: 1.129597410556208]
	TIME [epoch: 11.5 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8884139059698093		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.8884139059698093 | validation: 0.5742450221805433]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.68067277980087		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.68067277980087 | validation: 1.4532972969304012]
	TIME [epoch: 11.5 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9968166803232366		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.9968166803232366 | validation: 1.1505088497518206]
	TIME [epoch: 11.4 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8710994764100919		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.8710994764100919 | validation: 0.7945440682650056]
	TIME [epoch: 11.5 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8220970451975216		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.8220970451975216 | validation: 0.6264428904133628]
	TIME [epoch: 11.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8260924511436252		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.8260924511436252 | validation: 1.4211501869120309]
	TIME [epoch: 11.5 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9739696444186972		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.9739696444186972 | validation: 1.0627139434221466]
	TIME [epoch: 11.5 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7845218656874609		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.7845218656874609 | validation: 0.8272280840689197]
	TIME [epoch: 11.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6800506831821099		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.6800506831821099 | validation: 0.8626584722203531]
	TIME [epoch: 11.5 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1098698016300947		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.1098698016300947 | validation: 2.2085284000121033]
	TIME [epoch: 11.5 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5919038360724882		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.5919038360724882 | validation: 1.0656387273314314]
	TIME [epoch: 11.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1398645626254098		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.1398645626254098 | validation: 1.025447816696598]
	TIME [epoch: 11.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8374028418869112		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.8374028418869112 | validation: 0.8393645923986681]
	TIME [epoch: 11.5 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7085561412007018		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.7085561412007018 | validation: 0.5389655436247305]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7940334459318008		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.7940334459318008 | validation: 0.6852903503749296]
	TIME [epoch: 11.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6883619809381138		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.6883619809381138 | validation: 0.594092239006979]
	TIME [epoch: 11.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6970180772632486		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.6970180772632486 | validation: 0.9539380299774876]
	TIME [epoch: 11.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3229416563205296		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.3229416563205296 | validation: 0.7227555524513463]
	TIME [epoch: 11.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7014671837793396		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.7014671837793396 | validation: 0.6641311141812415]
	TIME [epoch: 11.5 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6391543151158202		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.6391543151158202 | validation: 0.6968047017274586]
	TIME [epoch: 11.5 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.222091585435456		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.222091585435456 | validation: 0.7203889023952373]
	TIME [epoch: 11.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5937683351181806		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.5937683351181806 | validation: 0.6271533073285638]
	TIME [epoch: 11.5 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6535420915256783		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.6535420915256783 | validation: 0.6516475522228864]
	TIME [epoch: 11.5 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6423032942591753		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.6423032942591753 | validation: 0.7603377967967255]
	TIME [epoch: 11.5 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6588539840287808		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.6588539840287808 | validation: 0.8953201953866942]
	TIME [epoch: 11.5 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.45565312240219		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.45565312240219 | validation: 1.8504148349581289]
	TIME [epoch: 11.5 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1140306591931548		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.1140306591931548 | validation: 0.6323822520093778]
	TIME [epoch: 11.5 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.655057088230227		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.655057088230227 | validation: 0.6854754844361864]
	TIME [epoch: 11.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7269813737920914		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.7269813737920914 | validation: 0.6639558885177451]
	TIME [epoch: 11.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.648965385375735		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.648965385375735 | validation: 0.6742342103745926]
	TIME [epoch: 11.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6651716132676389		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.6651716132676389 | validation: 0.6279215532207948]
	TIME [epoch: 11.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6619746849474243		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.6619746849474243 | validation: 0.745035573702604]
	TIME [epoch: 11.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.667270055801203		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.667270055801203 | validation: 0.5818014508567858]
	TIME [epoch: 11.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8820674546462549		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.8820674546462549 | validation: 1.3143543651013079]
	TIME [epoch: 11.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9096379580636644		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.9096379580636644 | validation: 2.094670475489788]
	TIME [epoch: 11.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1869630907102653		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.1869630907102653 | validation: 0.6792586200552799]
	TIME [epoch: 11.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6243653552696571		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.6243653552696571 | validation: 0.6314230717148219]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5869012641457161		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.5869012641457161 | validation: 0.7555903396604207]
	TIME [epoch: 11.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7443627831884743		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.7443627831884743 | validation: 0.6271697672027269]
	TIME [epoch: 11.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8790384227062393		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.8790384227062393 | validation: 0.6489628287115069]
	TIME [epoch: 11.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7673225867332747		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.7673225867332747 | validation: 0.7441053665036007]
	TIME [epoch: 11.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6645579134311053		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.6645579134311053 | validation: 0.6105527770168937]
	TIME [epoch: 11.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.573432428923197		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.573432428923197 | validation: 0.5622540669962575]
	TIME [epoch: 11.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6604110101172422		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.6604110101172422 | validation: 0.5464313854332947]
	TIME [epoch: 11.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2351418220693824		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.2351418220693824 | validation: 0.9707867599621739]
	TIME [epoch: 11.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8886221432734407		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.8886221432734407 | validation: 0.7144979820480657]
	TIME [epoch: 11.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254140441901824		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.7254140441901824 | validation: 0.7810203913419818]
	TIME [epoch: 11.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6941402696725378		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.6941402696725378 | validation: 0.8443795725045748]
	TIME [epoch: 11.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8254600996352754		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.8254600996352754 | validation: 2.719016766107368]
	TIME [epoch: 11.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7560438519416333		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.7560438519416333 | validation: 0.6732890463385279]
	TIME [epoch: 11.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5918106605805131		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.5918106605805131 | validation: 0.7014418253313338]
	TIME [epoch: 11.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6742495343784285		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.6742495343784285 | validation: 0.7038899869555543]
	TIME [epoch: 11.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6603820792237957		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.6603820792237957 | validation: 0.6743228334224329]
	TIME [epoch: 11.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6922661727544359		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.6922661727544359 | validation: 0.7349378658284155]
	TIME [epoch: 11.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0582698529883		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.0582698529883 | validation: 0.7552111434041229]
	TIME [epoch: 11.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6639481961188789		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.6639481961188789 | validation: 0.6282318843119697]
	TIME [epoch: 11.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6010674251149345		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.6010674251149345 | validation: 0.6783932393072124]
	TIME [epoch: 11.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.625354735683273		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.625354735683273 | validation: 0.6501082851811429]
	TIME [epoch: 11.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6344501614056396		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.6344501614056396 | validation: 0.5862061193048403]
	TIME [epoch: 11.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7036864556064583		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.7036864556064583 | validation: 0.7021280159484172]
	TIME [epoch: 11.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6135634885986668		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.6135634885986668 | validation: 0.6206914223051004]
	TIME [epoch: 11.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6409682775988285		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.6409682775988285 | validation: 0.6231220502834319]
	TIME [epoch: 11.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5955600386984843		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.5955600386984843 | validation: 0.5846232901230646]
	TIME [epoch: 11.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0810413174732478		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.0810413174732478 | validation: 0.8074369517692724]
	TIME [epoch: 11.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025297111402102		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.025297111402102 | validation: 0.8109597396352608]
	TIME [epoch: 11.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8648817055350699		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.8648817055350699 | validation: 0.6638815725438585]
	TIME [epoch: 11.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6319249158849982		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.6319249158849982 | validation: 4.154015604115588]
	TIME [epoch: 11.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6451826980709965		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.6451826980709965 | validation: 0.5946575559412238]
	TIME [epoch: 11.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5532989034835172		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.5532989034835172 | validation: 0.591005809969512]
	TIME [epoch: 11.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5391080041533837		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.5391080041533837 | validation: 0.5771247713631398]
	TIME [epoch: 11.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.62336416273107		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.62336416273107 | validation: 0.5605834835044039]
	TIME [epoch: 11.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5321521996771117		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.5321521996771117 | validation: 0.5217943472158576]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.568853091163144		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.568853091163144 | validation: 0.5025984492305581]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5194093086793807		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.5194093086793807 | validation: 0.6331861182797942]
	TIME [epoch: 11.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6458370426429771		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.6458370426429771 | validation: 0.523472840598706]
	TIME [epoch: 11.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.588933994792457		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.588933994792457 | validation: 0.7516452896405555]
	TIME [epoch: 11.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6911539548324712		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.6911539548324712 | validation: 0.7016352884241762]
	TIME [epoch: 11.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6262906822809449		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.6262906822809449 | validation: 0.6210772319245447]
	TIME [epoch: 11.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7423556927172534		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.7423556927172534 | validation: 0.9213581063002094]
	TIME [epoch: 11.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7238089658380533		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.7238089658380533 | validation: 0.6259089786159117]
	TIME [epoch: 11.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6428810261058435		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.6428810261058435 | validation: 0.5779302156615256]
	TIME [epoch: 11.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.541378553450766		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.541378553450766 | validation: 0.5167222308418462]
	TIME [epoch: 11.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5146550546508681		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.5146550546508681 | validation: 0.5602342472648736]
	TIME [epoch: 11.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5075366571475608		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.5075366571475608 | validation: 0.690754308045897]
	TIME [epoch: 11.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.601186553418014		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.601186553418014 | validation: 1.5528719520089072]
	TIME [epoch: 11.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8730580282768552		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.8730580282768552 | validation: 0.6199289570803302]
	TIME [epoch: 11.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.55335576993044		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.55335576993044 | validation: 0.5038747811170231]
	TIME [epoch: 11.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5577678458765186		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.5577678458765186 | validation: 0.6250665679234416]
	TIME [epoch: 11.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.577970729226606		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.577970729226606 | validation: 0.4412661961610651]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6139842782783002		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.6139842782783002 | validation: 0.6887825564868945]
	TIME [epoch: 11.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6401697679404421		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.6401697679404421 | validation: 1.089635937578892]
	TIME [epoch: 11.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8408064546712157		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.8408064546712157 | validation: 0.5246340885829478]
	TIME [epoch: 11.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6152468835276437		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.6152468835276437 | validation: 0.8633337742783553]
	TIME [epoch: 11.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6551541194026584		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.6551541194026584 | validation: 1.0309639494568998]
	TIME [epoch: 11.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7452227588230239		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.7452227588230239 | validation: 0.8072828396396572]
	TIME [epoch: 11.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.551293757953589		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.551293757953589 | validation: 0.4610278174185075]
	TIME [epoch: 11.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6173854023392799		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.6173854023392799 | validation: 0.9913103452557721]
	TIME [epoch: 11.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7451506107153972		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.7451506107153972 | validation: 0.6014083821656062]
	TIME [epoch: 11.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5514436940243135		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.5514436940243135 | validation: 0.4460150441437493]
	TIME [epoch: 11.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47008658701801065		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.47008658701801065 | validation: 0.565878994472497]
	TIME [epoch: 11.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5024964621021115		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.5024964621021115 | validation: 1.1055690758359986]
	TIME [epoch: 11.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9344298172262535		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 2.9344298172262535 | validation: 3.336289215377545]
	TIME [epoch: 11.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6308357975589205		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 3.6308357975589205 | validation: 3.7098393845233164]
	TIME [epoch: 11.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.699020871565299		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.699020871565299 | validation: 4.153758979864183]
	TIME [epoch: 11.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9544539568339285		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 3.9544539568339285 | validation: 3.39922821780844]
	TIME [epoch: 11.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5404313587286174		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 2.5404313587286174 | validation: 1.0994542686056152]
	TIME [epoch: 11.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9767467822390202		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.9767467822390202 | validation: 1.0596411736695501]
	TIME [epoch: 11.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8743561073514393		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.8743561073514393 | validation: 0.786147964197409]
	TIME [epoch: 11.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0852415500030839		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.0852415500030839 | validation: 0.9879306321419884]
	TIME [epoch: 11.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7562012262368032		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.7562012262368032 | validation: 0.6799799919070435]
	TIME [epoch: 11.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6530964031956714		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.6530964031956714 | validation: 0.5786779101767832]
	TIME [epoch: 11.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5869478236560588		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.5869478236560588 | validation: 0.6491156985571184]
	TIME [epoch: 11.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6327048858651356		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.6327048858651356 | validation: 0.9329427468221824]
	TIME [epoch: 11.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6479846449933041		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.6479846449933041 | validation: 0.5184236274504586]
	TIME [epoch: 11.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5336833665964315		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.5336833665964315 | validation: 0.54704727863229]
	TIME [epoch: 11.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5415915035271481		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.5415915035271481 | validation: 0.6700637261593622]
	TIME [epoch: 11.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6948052646949303		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.6948052646949303 | validation: 1.085012189965519]
	TIME [epoch: 11.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7313821908086124		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.7313821908086124 | validation: 0.6065389470502113]
	TIME [epoch: 11.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6437490486491431		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.6437490486491431 | validation: 1.3320174895773373]
	TIME [epoch: 11.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.175244816906746		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.175244816906746 | validation: 0.695774436288156]
	TIME [epoch: 11.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7349693428295745		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.7349693428295745 | validation: 0.868190301293717]
	TIME [epoch: 11.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7322674415222733		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.7322674415222733 | validation: 0.5991844037346004]
	TIME [epoch: 11.5 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.568948398692136		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.568948398692136 | validation: 0.5239803353953254]
	TIME [epoch: 11.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7144883493435485		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.7144883493435485 | validation: 0.6445878571698032]
	TIME [epoch: 11.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6608734525500993		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.6608734525500993 | validation: 0.7328059843814444]
	TIME [epoch: 11.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6743855878743956		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.6743855878743956 | validation: 0.5403474890330012]
	TIME [epoch: 11.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5083907612897158		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.5083907612897158 | validation: 0.4728027855302595]
	TIME [epoch: 11.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5128216355574169		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.5128216355574169 | validation: 0.5288900976301114]
	TIME [epoch: 11.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5083821156349115		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.5083821156349115 | validation: 0.5730066782822484]
	TIME [epoch: 11.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46747376326477763		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.46747376326477763 | validation: 0.4300368271187378]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4229798113371522		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.4229798113371522 | validation: 0.5702479092066998]
	TIME [epoch: 11.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49576733150347985		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.49576733150347985 | validation: 0.5408257962010913]
	TIME [epoch: 11.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47073314077161754		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.47073314077161754 | validation: 0.4051650424431468]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48304565219422013		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.48304565219422013 | validation: 0.4666912930227389]
	TIME [epoch: 11.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4276778033890429		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.4276778033890429 | validation: 0.4515807311343778]
	TIME [epoch: 11.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4691456212668687		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.4691456212668687 | validation: 0.40234654575800205]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42556164456383155		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.42556164456383155 | validation: 0.4730540704083171]
	TIME [epoch: 11.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41785978401213		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.41785978401213 | validation: 0.5722091942429793]
	TIME [epoch: 11.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47814233930590283		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.47814233930590283 | validation: 0.4000315352493584]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4496167271016954		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.4496167271016954 | validation: 0.4013537335608642]
	TIME [epoch: 11.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4667749299388851		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.4667749299388851 | validation: 0.5434313065100349]
	TIME [epoch: 11.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48540211355239693		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.48540211355239693 | validation: 0.4725630764959227]
	TIME [epoch: 11.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4478975702290134		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.4478975702290134 | validation: 0.8479913882274086]
	TIME [epoch: 11.4 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6281938826557867		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.6281938826557867 | validation: 0.5927101969173704]
	TIME [epoch: 11.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49474851737278636		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.49474851737278636 | validation: 0.3683420123806429]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39680954186000983		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.39680954186000983 | validation: 0.4661595617267139]
	TIME [epoch: 11.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48486939400210305		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.48486939400210305 | validation: 0.6924064362327369]
	TIME [epoch: 11.5 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6406908958868682		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.6406908958868682 | validation: 0.6908511695261089]
	TIME [epoch: 11.5 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5600084397271202		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.5600084397271202 | validation: 0.4594409180200388]
	TIME [epoch: 11.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6664364312627955		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.6664364312627955 | validation: 0.5542222345349482]
	TIME [epoch: 11.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5049233809120521		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.5049233809120521 | validation: 0.4679201564667702]
	TIME [epoch: 11.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39560109502735413		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.39560109502735413 | validation: 0.3292164538591186]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3951846077171529		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.3951846077171529 | validation: 0.35902590403753876]
	TIME [epoch: 11.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45853627670451125		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.45853627670451125 | validation: 0.45090094454702495]
	TIME [epoch: 11.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5118955563834391		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.5118955563834391 | validation: 0.7855964623624664]
	TIME [epoch: 11.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7849307497577184		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.7849307497577184 | validation: 0.46952754402637087]
	TIME [epoch: 11.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.505687296483856		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.505687296483856 | validation: 1.1623061753207082]
	TIME [epoch: 11.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3264314217493107		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.3264314217493107 | validation: 0.6117666171659236]
	TIME [epoch: 11.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5885125534952425		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.5885125534952425 | validation: 0.6363993208123284]
	TIME [epoch: 11.5 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49034656252223807		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.49034656252223807 | validation: 0.3461079871532558]
	TIME [epoch: 11.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4153677592037519		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.4153677592037519 | validation: 0.4160847890067093]
	TIME [epoch: 11.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45240060130426113		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.45240060130426113 | validation: 0.34279232573864366]
	TIME [epoch: 11.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42999998987254934		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.42999998987254934 | validation: 0.902063521573386]
	TIME [epoch: 11.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6631467649162983		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.6631467649162983 | validation: 0.490290443197791]
	TIME [epoch: 11.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4511963816011022		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.4511963816011022 | validation: 0.4078409600932518]
	TIME [epoch: 11.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4753320425816603		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.4753320425816603 | validation: 0.39759583646306157]
	TIME [epoch: 11.4 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1558328393635144		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.1558328393635144 | validation: 0.8830157181157224]
	TIME [epoch: 11.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7408343773630346		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.7408343773630346 | validation: 0.61646241824717]
	TIME [epoch: 11.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47289813330578295		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.47289813330578295 | validation: 0.3751239596406052]
	TIME [epoch: 11.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41672808007383677		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.41672808007383677 | validation: 0.7771759347220837]
	TIME [epoch: 11.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5411335717658824		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.5411335717658824 | validation: 0.3960746366109495]
	TIME [epoch: 11.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.391310874034171		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.391310874034171 | validation: 0.5752843297474971]
	TIME [epoch: 11.4 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4526592052823886		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.4526592052823886 | validation: 0.36431809961646194]
	TIME [epoch: 11.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37551265382955523		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.37551265382955523 | validation: 0.5226520298499727]
	TIME [epoch: 11.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4591110971491186		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.4591110971491186 | validation: 0.4652709907654291]
	TIME [epoch: 11.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4236067235121859		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.4236067235121859 | validation: 0.39781002710160834]
	TIME [epoch: 11.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5106408656986952		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.5106408656986952 | validation: 0.5504072037873672]
	TIME [epoch: 11.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5126463093053322		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.5126463093053322 | validation: 0.5111051043437729]
	TIME [epoch: 11.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4348084834208989		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.4348084834208989 | validation: 0.3548350838829205]
	TIME [epoch: 11.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.484214261341385		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.484214261341385 | validation: 0.46804135011241044]
	TIME [epoch: 11.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47021927618866494		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.47021927618866494 | validation: 0.42222946747879114]
	TIME [epoch: 11.5 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38763379892718286		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.38763379892718286 | validation: 0.7788028761089362]
	TIME [epoch: 11.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5499706633548028		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.5499706633548028 | validation: 0.49627935870867257]
	TIME [epoch: 11.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44591853708836865		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.44591853708836865 | validation: 0.425697213638349]
	TIME [epoch: 11.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3704538854842013		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.3704538854842013 | validation: 0.3873989018359268]
	TIME [epoch: 11.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41219537455804184		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.41219537455804184 | validation: 0.4153081581829423]
	TIME [epoch: 11.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3664246096201384		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.3664246096201384 | validation: 0.351758514816719]
	TIME [epoch: 11.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37801700320721526		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.37801700320721526 | validation: 0.3854475133984981]
	TIME [epoch: 11.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3733319521022539		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.3733319521022539 | validation: 0.3547733184536219]
	TIME [epoch: 11.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33342194926420576		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.33342194926420576 | validation: 0.49538544786669825]
	TIME [epoch: 11.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47175313676867625		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.47175313676867625 | validation: 0.5423618786879898]
	TIME [epoch: 11.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48995122579634864		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.48995122579634864 | validation: 0.5127104649195037]
	TIME [epoch: 11.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44194604214187627		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.44194604214187627 | validation: 0.35949314547296124]
	TIME [epoch: 11.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3790993745672205		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.3790993745672205 | validation: 0.8800251836919931]
	TIME [epoch: 11.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6595096056887153		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.6595096056887153 | validation: 0.3696040873103864]
	TIME [epoch: 11.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.479398411909889		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.479398411909889 | validation: 0.36615501848569365]
	TIME [epoch: 11.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38476788970422127		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.38476788970422127 | validation: 0.3861645773473572]
	TIME [epoch: 11.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3757441146120763		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.3757441146120763 | validation: 0.3044403840473961]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_260.pth
	Model improved!!!
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.296079196428286		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.296079196428286 | validation: 0.29289349471690834]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_261.pth
	Model improved!!!
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44942201026719036		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.44942201026719036 | validation: 0.4220205823870582]
	TIME [epoch: 11.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4274906865445348		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.4274906865445348 | validation: 0.36255152198450885]
	TIME [epoch: 11.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4421525212771916		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.4421525212771916 | validation: 0.40340147766173096]
	TIME [epoch: 11.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5338930133128089		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.5338930133128089 | validation: 0.46396360788572494]
	TIME [epoch: 11.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43039981928329407		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.43039981928329407 | validation: 0.42421018758624757]
	TIME [epoch: 11.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4277501774922162		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.4277501774922162 | validation: 0.5542736260513251]
	TIME [epoch: 11.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4454523792429378		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.4454523792429378 | validation: 0.47404612340212227]
	TIME [epoch: 11.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.460283399540262		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.460283399540262 | validation: 0.3746989436662123]
	TIME [epoch: 11.5 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38771798479897523		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.38771798479897523 | validation: 0.48055616435357906]
	TIME [epoch: 11.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4236220291630108		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.4236220291630108 | validation: 0.4138445946301698]
	TIME [epoch: 11.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3185586648777496		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.3185586648777496 | validation: 0.3004632750132211]
	TIME [epoch: 11.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2846173837347667		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.2846173837347667 | validation: 0.30158492306619106]
	TIME [epoch: 11.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3619440966738664		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.3619440966738664 | validation: 0.26647971386908553]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3949222952479683		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.3949222952479683 | validation: 0.31681036099884663]
	TIME [epoch: 11.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4199658721269217		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.4199658721269217 | validation: 0.33095619361157164]
	TIME [epoch: 11.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31403674775465845		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.31403674775465845 | validation: 0.3306298828998736]
	TIME [epoch: 11.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41622848732779183		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.41622848732779183 | validation: 0.46604795218682177]
	TIME [epoch: 11.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42600019261381267		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.42600019261381267 | validation: 0.6468017188093589]
	TIME [epoch: 11.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5958884213733089		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.5958884213733089 | validation: 0.451098156255248]
	TIME [epoch: 11.4 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4123831107113979		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.4123831107113979 | validation: 0.3264904184579284]
	TIME [epoch: 11.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3499638712505202		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.3499638712505202 | validation: 0.3215880300318416]
	TIME [epoch: 11.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31255416906229433		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.31255416906229433 | validation: 0.27571126700059206]
	TIME [epoch: 11.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3627356271838982		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.3627356271838982 | validation: 0.7530809199551002]
	TIME [epoch: 11.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4700612453393429		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.4700612453393429 | validation: 0.42807980629864545]
	TIME [epoch: 11.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39442296485903056		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.39442296485903056 | validation: 0.32835101112279547]
	TIME [epoch: 11.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34588057656025056		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.34588057656025056 | validation: 0.2883753390540019]
	TIME [epoch: 11.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3072558819300727		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.3072558819300727 | validation: 0.26579587299325425]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_288.pth
	Model improved!!!
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.326015490596487		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.326015490596487 | validation: 0.4940966209888857]
	TIME [epoch: 11.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44522651769580884		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.44522651769580884 | validation: 0.3731888462994553]
	TIME [epoch: 11.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34534160023043253		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.34534160023043253 | validation: 0.25560197576448435]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_291.pth
	Model improved!!!
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2693020697371941		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.2693020697371941 | validation: 0.27597564431486327]
	TIME [epoch: 11.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2919297691230821		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.2919297691230821 | validation: 0.41025314026949405]
	TIME [epoch: 11.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6568532491564465		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.6568532491564465 | validation: 0.573863015623963]
	TIME [epoch: 11.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3921997864710946		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.3921997864710946 | validation: 0.27422822632788674]
	TIME [epoch: 11.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.318755710995247		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.318755710995247 | validation: 0.3015922492999006]
	TIME [epoch: 11.4 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30372053115302394		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.30372053115302394 | validation: 0.36138019904933827]
	TIME [epoch: 11.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33681357368774706		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.33681357368774706 | validation: 0.3393023619446863]
	TIME [epoch: 11.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3289061380738776		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.3289061380738776 | validation: 0.3860106372448284]
	TIME [epoch: 11.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4543941980792092		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.4543941980792092 | validation: 0.4059390653106621]
	TIME [epoch: 11.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4275904962308854		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.4275904962308854 | validation: 0.3214352085410302]
	TIME [epoch: 11.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.446202134913153		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.446202134913153 | validation: 0.6144776672670154]
	TIME [epoch: 11.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3886104126265308		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.3886104126265308 | validation: 0.32570297686966565]
	TIME [epoch: 11.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6264134396578461		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.6264134396578461 | validation: 0.31267294139968543]
	TIME [epoch: 11.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30113991283400177		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.30113991283400177 | validation: 0.3234100394648596]
	TIME [epoch: 11.5 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30875084395421615		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.30875084395421615 | validation: 0.5454251409531616]
	TIME [epoch: 11.5 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42103159780858607		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.42103159780858607 | validation: 0.37540328677761203]
	TIME [epoch: 11.5 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3402528166243228		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.3402528166243228 | validation: 0.30266564836343224]
	TIME [epoch: 11.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32084911089827595		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.32084911089827595 | validation: 0.35826027007082656]
	TIME [epoch: 11.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29022097254443513		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.29022097254443513 | validation: 0.28845184880999614]
	TIME [epoch: 11.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2733917396743429		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.2733917396743429 | validation: 0.2758695448191309]
	TIME [epoch: 11.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28589946821975687		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.28589946821975687 | validation: 0.49694286264829524]
	TIME [epoch: 11.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3154517006710557		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.3154517006710557 | validation: 0.47545843729214554]
	TIME [epoch: 11.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6563074816020643		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.6563074816020643 | validation: 0.27471069801217013]
	TIME [epoch: 11.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3217712739479189		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.3217712739479189 | validation: 0.34948638566187384]
	TIME [epoch: 11.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3498910876557488		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.3498910876557488 | validation: 0.4006391020649481]
	TIME [epoch: 11.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.327615712899933		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.327615712899933 | validation: 0.3088076900019456]
	TIME [epoch: 11.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3047317497810962		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.3047317497810962 | validation: 0.33705598309655244]
	TIME [epoch: 11.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31181160062583885		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.31181160062583885 | validation: 0.34934090989935984]
	TIME [epoch: 11.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3102038172626458		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.3102038172626458 | validation: 0.34592839786504415]
	TIME [epoch: 11.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3848404550214024		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.3848404550214024 | validation: 0.23871591403207298]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_321.pth
	Model improved!!!
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2948592786808151		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.2948592786808151 | validation: 0.36544358240648595]
	TIME [epoch: 11.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3122853303200732		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.3122853303200732 | validation: 0.3980221026498002]
	TIME [epoch: 11.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45503333533301155		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.45503333533301155 | validation: 0.45316492297652694]
	TIME [epoch: 11.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5562612069734816		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.5562612069734816 | validation: 0.35828676026664474]
	TIME [epoch: 11.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3080695953943352		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.3080695953943352 | validation: 0.39798667093237683]
	TIME [epoch: 11.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2858304814734084		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.2858304814734084 | validation: 0.2953869982121283]
	TIME [epoch: 11.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5689336315833473		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.5689336315833473 | validation: 1.0515375783994023]
	TIME [epoch: 11.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.567018122528942		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.567018122528942 | validation: 0.3356444076792478]
	TIME [epoch: 11.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5013463330520177		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.5013463330520177 | validation: 0.4905278620074326]
	TIME [epoch: 11.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3591314245740738		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.3591314245740738 | validation: 0.29883642682925216]
	TIME [epoch: 11.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.657322349549497		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.657322349549497 | validation: 1.2927059063506854]
	TIME [epoch: 11.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6706658897851495		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.6706658897851495 | validation: 0.35428979213697476]
	TIME [epoch: 11.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3211257491675925		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.3211257491675925 | validation: 0.28977211759508387]
	TIME [epoch: 11.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4064617276874216		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.4064617276874216 | validation: 0.3547350632886733]
	TIME [epoch: 11.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.408335161781469		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.408335161781469 | validation: 0.38899973096289536]
	TIME [epoch: 11.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4713876669189096		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.4713876669189096 | validation: 0.3379382553511917]
	TIME [epoch: 11.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37125363500869774		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.37125363500869774 | validation: 0.4767751102840302]
	TIME [epoch: 11.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6172421677774987		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.6172421677774987 | validation: 0.5654104867606117]
	TIME [epoch: 11.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3650723867885754		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.3650723867885754 | validation: 0.2984231819071999]
	TIME [epoch: 11.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28402209994036354		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.28402209994036354 | validation: 0.35289777853005155]
	TIME [epoch: 11.5 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30404140711809935		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.30404140711809935 | validation: 0.2897229012251142]
	TIME [epoch: 11.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4179393507352089		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.4179393507352089 | validation: 0.3326137531905893]
	TIME [epoch: 11.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3599187215139406		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.3599187215139406 | validation: 0.27703946661597156]
	TIME [epoch: 11.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2795744558833556		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.2795744558833556 | validation: 0.3379170153112808]
	TIME [epoch: 11.4 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.501605407598396		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.501605407598396 | validation: 0.3088342075860489]
	TIME [epoch: 11.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36872733960005344		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.36872733960005344 | validation: 0.31582765860568307]
	TIME [epoch: 11.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31593187380289295		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.31593187380289295 | validation: 0.34192908351401213]
	TIME [epoch: 11.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3970812964661299		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.3970812964661299 | validation: 0.3806404130351581]
	TIME [epoch: 11.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7346677910209913		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.7346677910209913 | validation: 0.5411718894080911]
	TIME [epoch: 11.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5465155584692069		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.5465155584692069 | validation: 0.498057352732148]
	TIME [epoch: 11.4 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3478021358047907		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.3478021358047907 | validation: 0.40036500604403447]
	TIME [epoch: 11.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43674766545321264		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.43674766545321264 | validation: 0.43293142616955765]
	TIME [epoch: 11.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37874559274503455		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.37874559274503455 | validation: 0.331341681320349]
	TIME [epoch: 11.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3321169097263411		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.3321169097263411 | validation: 0.30583552168283645]
	TIME [epoch: 11.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35726975338030265		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.35726975338030265 | validation: 0.3027036015816726]
	TIME [epoch: 11.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3221058432072967		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.3221058432072967 | validation: 0.29630183469985016]
	TIME [epoch: 11.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3559487988138321		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.3559487988138321 | validation: 0.5566541126103666]
	TIME [epoch: 11.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4233466993549979		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.4233466993549979 | validation: 0.45839063966665194]
	TIME [epoch: 11.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3348886477307632		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.3348886477307632 | validation: 0.3731474430825229]
	TIME [epoch: 11.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3516839923936418		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.3516839923936418 | validation: 0.31118716949200986]
	TIME [epoch: 11.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3765524982092182		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.3765524982092182 | validation: 0.9490574827670797]
	TIME [epoch: 11.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7600156783438056		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.7600156783438056 | validation: 0.4766890515783139]
	TIME [epoch: 11.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3706828416171009		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.3706828416171009 | validation: 0.3791827582660793]
	TIME [epoch: 11.4 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.327671731124246		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.327671731124246 | validation: 0.28746730083982586]
	TIME [epoch: 11.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2981236400870205		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.2981236400870205 | validation: 0.35967440282360746]
	TIME [epoch: 11.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3373643097480339		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.3373643097480339 | validation: 0.2944449590559391]
	TIME [epoch: 11.5 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3040202401763197		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.3040202401763197 | validation: 0.3136480100114118]
	TIME [epoch: 11.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26466351403824173		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.26466351403824173 | validation: 0.30485017378823914]
	TIME [epoch: 11.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2788726358911493		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.2788726358911493 | validation: 0.2723138979632849]
	TIME [epoch: 11.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2987949887609558		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.2987949887609558 | validation: 0.34993270870718135]
	TIME [epoch: 11.4 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31982328120116993		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.31982328120116993 | validation: 0.28079451083778273]
	TIME [epoch: 11.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3539464305364169		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.3539464305364169 | validation: 0.3142491365721702]
	TIME [epoch: 11.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27640678638292876		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.27640678638292876 | validation: 0.26515173715024026]
	TIME [epoch: 11.4 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3764860864625369		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.3764860864625369 | validation: 0.30353764186612614]
	TIME [epoch: 11.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31616417029388105		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.31616417029388105 | validation: 0.5050194342874673]
	TIME [epoch: 11.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46834961548245035		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.46834961548245035 | validation: 0.36445494045276505]
	TIME [epoch: 11.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27173657840652243		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.27173657840652243 | validation: 0.24051390299910924]
	TIME [epoch: 11.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24127153053758887		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.24127153053758887 | validation: 0.313646505582378]
	TIME [epoch: 11.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30741221364523924		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.30741221364523924 | validation: 0.30212929149550394]
	TIME [epoch: 11.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2716951362096758		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.2716951362096758 | validation: 0.2491835507584446]
	TIME [epoch: 11.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25617064898050257		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.25617064898050257 | validation: 0.3276606175805183]
	TIME [epoch: 11.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28635841712531174		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.28635841712531174 | validation: 0.2223705685476576]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_383.pth
	Model improved!!!
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32606266569595654		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.32606266569595654 | validation: 0.28700194655248484]
	TIME [epoch: 11.4 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6040753706226109		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.6040753706226109 | validation: 1.0473542483801377]
	TIME [epoch: 11.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5536273825286221		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.5536273825286221 | validation: 0.28904936069946247]
	TIME [epoch: 11.4 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26931666083866823		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.26931666083866823 | validation: 0.24895760126727737]
	TIME [epoch: 11.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2304397625895257		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.2304397625895257 | validation: 0.293947958105521]
	TIME [epoch: 11.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28712666121072283		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.28712666121072283 | validation: 0.4438539302874315]
	TIME [epoch: 11.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3145845113667179		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.3145845113667179 | validation: 0.30343658613692537]
	TIME [epoch: 11.4 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2538240663176376		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.2538240663176376 | validation: 0.2906989805825581]
	TIME [epoch: 11.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2655925974811861		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.2655925974811861 | validation: 0.4131619411899474]
	TIME [epoch: 11.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3456821483433351		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.3456821483433351 | validation: 0.2756363808537507]
	TIME [epoch: 11.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25133852813422763		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.25133852813422763 | validation: 0.32837607781874084]
	TIME [epoch: 11.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2868317045358776		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.2868317045358776 | validation: 0.24757436844468259]
	TIME [epoch: 11.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.257963919103755		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.257963919103755 | validation: 0.24740402973999437]
	TIME [epoch: 11.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2311665832915163		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.2311665832915163 | validation: 0.22768885585075438]
	TIME [epoch: 11.4 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2506313991268977		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.2506313991268977 | validation: 0.22888273668389747]
	TIME [epoch: 11.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2274512537512663		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.2274512537512663 | validation: 0.22940154058731427]
	TIME [epoch: 11.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2237955751704053		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.2237955751704053 | validation: 0.22738147960905358]
	TIME [epoch: 11.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2172206956373458		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.2172206956373458 | validation: 0.21862364017136388]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_401.pth
	Model improved!!!
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26495999879159615		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.26495999879159615 | validation: 0.2875433506885323]
	TIME [epoch: 11.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24176417290970267		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.24176417290970267 | validation: 0.20702574339663266]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_403.pth
	Model improved!!!
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22095598224894308		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.22095598224894308 | validation: 0.2594517425395803]
	TIME [epoch: 11.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27439819519502767		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.27439819519502767 | validation: 0.25144329232399376]
	TIME [epoch: 11.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23478310164890087		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.23478310164890087 | validation: 0.21724845723818034]
	TIME [epoch: 11.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2375747024106089		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.2375747024106089 | validation: 0.20755262334971167]
	TIME [epoch: 11.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20456579612768797		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.20456579612768797 | validation: 0.24338359968083687]
	TIME [epoch: 11.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3481956243346143		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.3481956243346143 | validation: 0.3920359024135003]
	TIME [epoch: 11.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3238639311527287		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.3238639311527287 | validation: 0.23898119351778824]
	TIME [epoch: 11.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2261536847716054		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.2261536847716054 | validation: 0.2422302935215233]
	TIME [epoch: 11.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23109822674504205		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.23109822674504205 | validation: 0.24827162505597605]
	TIME [epoch: 11.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24868386507290496		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.24868386507290496 | validation: 0.22498940013546673]
	TIME [epoch: 11.5 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22728143829364877		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.22728143829364877 | validation: 0.28360286685992364]
	TIME [epoch: 11.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3293405802484084		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.3293405802484084 | validation: 0.26240397672385163]
	TIME [epoch: 11.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28584359453667557		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.28584359453667557 | validation: 0.258967414477317]
	TIME [epoch: 11.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2302806411065513		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.2302806411065513 | validation: 0.2030451579592861]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_417.pth
	Model improved!!!
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24025535451804597		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.24025535451804597 | validation: 0.22265291955617567]
	TIME [epoch: 11.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26113505882015353		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.26113505882015353 | validation: 0.28398063929174333]
	TIME [epoch: 11.4 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2343928205546263		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.2343928205546263 | validation: 0.21371022196724923]
	TIME [epoch: 11.4 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21074049303743347		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.21074049303743347 | validation: 0.36954523356863933]
	TIME [epoch: 11.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35702184788490776		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.35702184788490776 | validation: 0.2414577106550427]
	TIME [epoch: 11.4 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23840875594437272		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.23840875594437272 | validation: 0.25631326077636557]
	TIME [epoch: 11.4 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35819145832841714		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.35819145832841714 | validation: 0.4357635221316938]
	TIME [epoch: 11.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41067557202842975		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.41067557202842975 | validation: 0.3356859338391657]
	TIME [epoch: 11.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27291244081768		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.27291244081768 | validation: 0.24846775333289564]
	TIME [epoch: 11.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25285911524525295		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.25285911524525295 | validation: 0.2386824754425351]
	TIME [epoch: 11.5 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2348617628791974		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.2348617628791974 | validation: 0.2164873873588968]
	TIME [epoch: 11.5 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21090384748828495		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.21090384748828495 | validation: 0.26808441484026174]
	TIME [epoch: 11.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4112270307963471		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.4112270307963471 | validation: 0.6298922104604413]
	TIME [epoch: 11.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5170187698376765		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.5170187698376765 | validation: 0.4179965257437599]
	TIME [epoch: 11.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39916217342873284		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.39916217342873284 | validation: 0.27951157683956007]
	TIME [epoch: 11.5 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33886604393751063		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.33886604393751063 | validation: 0.2935389390919152]
	TIME [epoch: 11.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2945744123731202		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.2945744123731202 | validation: 0.2440814811632623]
	TIME [epoch: 11.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23665619693031092		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.23665619693031092 | validation: 0.2665230032236778]
	TIME [epoch: 11.5 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26599723176302215		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.26599723176302215 | validation: 0.34588271536613785]
	TIME [epoch: 11.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5253799104429105		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.5253799104429105 | validation: 0.2593172418942308]
	TIME [epoch: 11.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3154813323169968		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.3154813323169968 | validation: 0.30756163665513203]
	TIME [epoch: 11.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2930295101543875		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.2930295101543875 | validation: 0.25162688971366315]
	TIME [epoch: 11.5 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2650965423826137		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.2650965423826137 | validation: 0.2860710209390655]
	TIME [epoch: 11.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23865474414568955		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.23865474414568955 | validation: 0.19531504684000772]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_441.pth
	Model improved!!!
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19371526456127897		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.19371526456127897 | validation: 0.2826686809458551]
	TIME [epoch: 11.5 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2998597644774512		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.2998597644774512 | validation: 0.27618294295865703]
	TIME [epoch: 11.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2819560079688913		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.2819560079688913 | validation: 0.2450396835282522]
	TIME [epoch: 11.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22510128028130297		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.22510128028130297 | validation: 0.20490633328440522]
	TIME [epoch: 11.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2053586463642957		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.2053586463642957 | validation: 0.32389848348751993]
	TIME [epoch: 11.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39593311163587686		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.39593311163587686 | validation: 0.2693871734795956]
	TIME [epoch: 11.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30517395737637226		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.30517395737637226 | validation: 0.28773355326051525]
	TIME [epoch: 11.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30552433169792814		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.30552433169792814 | validation: 0.22363112324363937]
	TIME [epoch: 11.5 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22736688441609226		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.22736688441609226 | validation: 0.240132029123188]
	TIME [epoch: 11.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21663158255659648		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.21663158255659648 | validation: 0.26542533626105985]
	TIME [epoch: 11.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3155954944628867		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.3155954944628867 | validation: 0.22188433173316807]
	TIME [epoch: 11.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2590996317500458		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.2590996317500458 | validation: 0.24858104989512536]
	TIME [epoch: 11.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20886297686110458		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.20886297686110458 | validation: 0.20159528997059137]
	TIME [epoch: 11.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20125010606166382		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.20125010606166382 | validation: 0.2627493113659621]
	TIME [epoch: 11.5 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2809952641661576		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.2809952641661576 | validation: 0.33456843155761745]
	TIME [epoch: 11.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2721260848763942		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.2721260848763942 | validation: 0.2464032937268874]
	TIME [epoch: 11.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23790011696108743		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.23790011696108743 | validation: 0.19218340206302395]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_458.pth
	Model improved!!!
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20843644033976644		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.20843644033976644 | validation: 0.23003569953801503]
	TIME [epoch: 11.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21910767446520066		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.21910767446520066 | validation: 0.19018670896655399]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_460.pth
	Model improved!!!
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23141978259487456		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.23141978259487456 | validation: 0.280432220692459]
	TIME [epoch: 11.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23574932504134252		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.23574932504134252 | validation: 0.2517365475426981]
	TIME [epoch: 11.5 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24198984123420086		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.24198984123420086 | validation: 0.2838693876832915]
	TIME [epoch: 11.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31600444912186204		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.31600444912186204 | validation: 0.28728409449164594]
	TIME [epoch: 11.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27537888545676054		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.27537888545676054 | validation: 0.3233056001718681]
	TIME [epoch: 11.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24962790626174575		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.24962790626174575 | validation: 0.22351745609627124]
	TIME [epoch: 11.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23475423667701403		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.23475423667701403 | validation: 0.22546104728129304]
	TIME [epoch: 11.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21938369663652998		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.21938369663652998 | validation: 0.25585861778726726]
	TIME [epoch: 11.5 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26850385590119247		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.26850385590119247 | validation: 0.37937283480072054]
	TIME [epoch: 11.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27143153468963416		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.27143153468963416 | validation: 0.22630443629186958]
	TIME [epoch: 11.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23453695906084543		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.23453695906084543 | validation: 0.3803283554397872]
	TIME [epoch: 11.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32136927229625223		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.32136927229625223 | validation: 0.2322162562194977]
	TIME [epoch: 11.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22131870531941758		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.22131870531941758 | validation: 0.19363684629518324]
	TIME [epoch: 11.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20435949360345373		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.20435949360345373 | validation: 0.18897052815105903]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_474.pth
	Model improved!!!
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20985840033626693		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.20985840033626693 | validation: 0.24815889675487313]
	TIME [epoch: 11.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22308556272210947		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.22308556272210947 | validation: 0.20053716030097476]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21776399137610586		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.21776399137610586 | validation: 0.20705107363464972]
	TIME [epoch: 11.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23376763626038416		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.23376763626038416 | validation: 0.27941185576832545]
	TIME [epoch: 11.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.282683185790968		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.282683185790968 | validation: 0.3136814384812649]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.304102261931609		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.304102261931609 | validation: 0.24417119834355647]
	TIME [epoch: 11.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29027911997459793		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.29027911997459793 | validation: 0.21370448284453175]
	TIME [epoch: 11.5 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21232480965274442		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.21232480965274442 | validation: 0.19179111385680273]
	TIME [epoch: 11.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21614361840974794		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.21614361840974794 | validation: 0.19321145622222805]
	TIME [epoch: 11.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1843335647011916		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.1843335647011916 | validation: 0.2776558276989513]
	TIME [epoch: 11.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23291969615404803		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.23291969615404803 | validation: 0.23073258121058624]
	TIME [epoch: 11.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25595312474324217		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.25595312474324217 | validation: 0.22872947459769377]
	TIME [epoch: 11.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2332332753506912		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.2332332753506912 | validation: 0.2755045417522905]
	TIME [epoch: 11.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.227089758051727		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.227089758051727 | validation: 0.19965031235456188]
	TIME [epoch: 11.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2389071243938387		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.2389071243938387 | validation: 0.2746179703955099]
	TIME [epoch: 11.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22592799523928364		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.22592799523928364 | validation: 0.21372298113252908]
	TIME [epoch: 11.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2373025857576887		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.2373025857576887 | validation: 0.49041561728968847]
	TIME [epoch: 11.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4448606425701057		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.4448606425701057 | validation: 0.4002867489180754]
	TIME [epoch: 11.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43851095428207487		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.43851095428207487 | validation: 0.543864849571165]
	TIME [epoch: 11.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4048004549086971		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.4048004549086971 | validation: 0.3132491706211701]
	TIME [epoch: 11.5 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27746268308197347		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.27746268308197347 | validation: 0.2914572518836232]
	TIME [epoch: 11.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22297874157875539		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.22297874157875539 | validation: 0.18583648007775622]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19299975840468825		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.19299975840468825 | validation: 0.20480250986153295]
	TIME [epoch: 11.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18859791056901082		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.18859791056901082 | validation: 0.1747158701496735]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_498.pth
	Model improved!!!
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16858657913663505		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.16858657913663505 | validation: 0.1584964306804664]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_499.pth
	Model improved!!!
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16554925874746035		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.16554925874746035 | validation: 0.16685479543968804]
	TIME [epoch: 11.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19247792016467374		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.19247792016467374 | validation: 0.28039969701524803]
	TIME [epoch: 11.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19184285887459038		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.19184285887459038 | validation: 0.15856343182422364]
	TIME [epoch: 11.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1635917556781618		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.1635917556781618 | validation: 0.21095931121971603]
	TIME [epoch: 11.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21875597875689515		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.21875597875689515 | validation: 0.1882973982682548]
	TIME [epoch: 11.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2168173062593566		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.2168173062593566 | validation: 0.21030982259937414]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2007721374589325		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.2007721374589325 | validation: 0.25346145423867333]
	TIME [epoch: 11.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2192790393092485		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.2192790393092485 | validation: 0.18174446833529198]
	TIME [epoch: 11.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22413653280032553		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.22413653280032553 | validation: 0.1975059601606712]
	TIME [epoch: 11.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1789365589847627		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.1789365589847627 | validation: 0.17451282799870765]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1778969831719004		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.1778969831719004 | validation: 0.23940283182647037]
	TIME [epoch: 11.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2212839702626939		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.2212839702626939 | validation: 0.19681565142450616]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1919957806497366		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.1919957806497366 | validation: 0.18359998995290552]
	TIME [epoch: 11.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2037000008745291		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.2037000008745291 | validation: 0.18126794975989444]
	TIME [epoch: 11.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21509776885371173		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.21509776885371173 | validation: 0.40309509190349524]
	TIME [epoch: 11.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.352124246352362		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.352124246352362 | validation: 0.2958995221678599]
	TIME [epoch: 11.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.252690200333857		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.252690200333857 | validation: 0.23621076616155104]
	TIME [epoch: 11.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2215065817262089		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.2215065817262089 | validation: 0.23436070142388654]
	TIME [epoch: 11.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22585471084714748		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.22585471084714748 | validation: 0.2199354587882737]
	TIME [epoch: 11.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2080543808858296		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.2080543808858296 | validation: 0.19192519314078996]
	TIME [epoch: 11.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34320721998482706		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.34320721998482706 | validation: 0.36497950226159986]
	TIME [epoch: 11.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29925056415731544		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.29925056415731544 | validation: 0.25498357751998013]
	TIME [epoch: 11.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22877460300432856		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.22877460300432856 | validation: 0.24514020494541086]
	TIME [epoch: 11.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2091797053232148		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.2091797053232148 | validation: 0.17230703857650287]
	TIME [epoch: 11.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1588917736964025		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.1588917736964025 | validation: 0.18712436129154347]
	TIME [epoch: 11.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.168005689279431		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.168005689279431 | validation: 0.17291305537449525]
	TIME [epoch: 11.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1528061493438864		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.1528061493438864 | validation: 0.18675686327888913]
	TIME [epoch: 11.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1769099652252618		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.1769099652252618 | validation: 0.1874019745493144]
	TIME [epoch: 11.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15877132245610515		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.15877132245610515 | validation: 0.15670744190618544]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_528.pth
	Model improved!!!
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15312014444072836		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.15312014444072836 | validation: 0.14533559764884005]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_529.pth
	Model improved!!!
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18237948423420103		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.18237948423420103 | validation: 0.17175393984673037]
	TIME [epoch: 11.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17365174151471205		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.17365174151471205 | validation: 0.19188494105233156]
	TIME [epoch: 11.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1619989042024164		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.1619989042024164 | validation: 0.15705934872465335]
	TIME [epoch: 11.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1479298931557088		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.1479298931557088 | validation: 0.1839430968112869]
	TIME [epoch: 11.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1756863709313342		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.1756863709313342 | validation: 0.18822493685345584]
	TIME [epoch: 11.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.201953650250839		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.201953650250839 | validation: 0.20065012478877697]
	TIME [epoch: 11.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20925940073726984		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.20925940073726984 | validation: 0.18973540003298164]
	TIME [epoch: 11.5 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1878896648084455		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.1878896648084455 | validation: 0.16229703113693641]
	TIME [epoch: 11.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15761050433201274		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.15761050433201274 | validation: 0.17309265410462651]
	TIME [epoch: 11.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17082343901949948		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.17082343901949948 | validation: 0.299583778571345]
	TIME [epoch: 11.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30997221595237295		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.30997221595237295 | validation: 0.24419183463271907]
	TIME [epoch: 11.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2645651045042771		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.2645651045042771 | validation: 0.2047411370948467]
	TIME [epoch: 11.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18509007624643609		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.18509007624643609 | validation: 0.15651919475397347]
	TIME [epoch: 11.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16958962838511124		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.16958962838511124 | validation: 0.22466282667117013]
	TIME [epoch: 11.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2124749433210603		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.2124749433210603 | validation: 0.18761184826268235]
	TIME [epoch: 11.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1844449730886787		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.1844449730886787 | validation: 0.1515985056047602]
	TIME [epoch: 11.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14458453191438578		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.14458453191438578 | validation: 0.15992332822738337]
	TIME [epoch: 11.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15715834780111457		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.15715834780111457 | validation: 0.20488820884060974]
	TIME [epoch: 11.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18308801586636012		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.18308801586636012 | validation: 0.18312675533576253]
	TIME [epoch: 11.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19455918826981589		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.19455918826981589 | validation: 0.21436744344797995]
	TIME [epoch: 11.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1966866270298882		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.1966866270298882 | validation: 0.152268842968082]
	TIME [epoch: 11.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17500319422489918		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.17500319422489918 | validation: 0.23729007145584394]
	TIME [epoch: 11.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20117149941207862		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.20117149941207862 | validation: 0.2844653530866769]
	TIME [epoch: 11.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24255917939152796		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.24255917939152796 | validation: 0.2016556922325237]
	TIME [epoch: 11.5 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18027216327296164		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.18027216327296164 | validation: 0.13896377845137955]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_554.pth
	Model improved!!!
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1360852941762904		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.1360852941762904 | validation: 0.13995518211042707]
	TIME [epoch: 11.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.164857968503976		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.164857968503976 | validation: 0.1864044251147325]
	TIME [epoch: 11.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15456845667009528		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.15456845667009528 | validation: 0.16906763089300816]
	TIME [epoch: 11.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14502199563645052		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.14502199563645052 | validation: 0.1708895456991298]
	TIME [epoch: 11.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14693843175020543		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.14693843175020543 | validation: 0.17386373407248876]
	TIME [epoch: 11.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1617601370232432		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.1617601370232432 | validation: 0.17377439397878777]
	TIME [epoch: 11.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14754896700110953		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.14754896700110953 | validation: 0.16809095743934158]
	TIME [epoch: 11.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1629833219159794		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.1629833219159794 | validation: 0.17724828004685914]
	TIME [epoch: 11.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20172513777898674		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.20172513777898674 | validation: 0.2086714872625074]
	TIME [epoch: 11.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1782919917854208		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.1782919917854208 | validation: 0.1775997041401935]
	TIME [epoch: 11.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3304779289287545		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.3304779289287545 | validation: 0.3759357018060991]
	TIME [epoch: 11.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29224479502361433		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.29224479502361433 | validation: 0.2222560336593203]
	TIME [epoch: 11.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2475995353815376		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.2475995353815376 | validation: 0.29176744562590584]
	TIME [epoch: 11.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3179885665569538		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.3179885665569538 | validation: 0.27028076027174536]
	TIME [epoch: 11.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2393174522381149		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.2393174522381149 | validation: 0.2613266286584405]
	TIME [epoch: 11.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2741761788884731		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.2741761788884731 | validation: 0.2409510070008493]
	TIME [epoch: 11.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19294379362083364		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.19294379362083364 | validation: 0.2190376339168358]
	TIME [epoch: 11.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19604845185359132		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.19604845185359132 | validation: 0.2682427332527974]
	TIME [epoch: 11.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2514784278124973		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.2514784278124973 | validation: 0.3144815398554998]
	TIME [epoch: 11.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2904784855839163		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.2904784855839163 | validation: 0.310006166518661]
	TIME [epoch: 11.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24673306148048357		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.24673306148048357 | validation: 0.2546849152860408]
	TIME [epoch: 11.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21369952106152457		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.21369952106152457 | validation: 0.23383044696126085]
	TIME [epoch: 11.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2045134384255475		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.2045134384255475 | validation: 0.18757832803781102]
	TIME [epoch: 11.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15761965249822568		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.15761965249822568 | validation: 0.16659695765951893]
	TIME [epoch: 11.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18087660451408158		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.18087660451408158 | validation: 0.3037420148223922]
	TIME [epoch: 11.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2377113610237031		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.2377113610237031 | validation: 0.15050442412520412]
	TIME [epoch: 11.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.144945548673002		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.144945548673002 | validation: 0.16282488256610955]
	TIME [epoch: 11.5 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15003744740612612		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.15003744740612612 | validation: 0.19550522486877298]
	TIME [epoch: 11.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15410532310694758		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.15410532310694758 | validation: 0.1663827479667847]
	TIME [epoch: 11.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16395953805507338		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.16395953805507338 | validation: 0.1990708012139774]
	TIME [epoch: 11.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25930808964752805		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.25930808964752805 | validation: 0.2721506558739059]
	TIME [epoch: 11.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2048590481772442		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.2048590481772442 | validation: 0.1565834797164394]
	TIME [epoch: 11.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16396820962267206		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.16396820962267206 | validation: 0.16311027842883008]
	TIME [epoch: 11.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13970301751422928		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.13970301751422928 | validation: 0.1749984146897063]
	TIME [epoch: 11.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15566066793722774		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.15566066793722774 | validation: 0.1799442122007103]
	TIME [epoch: 11.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14616076749275952		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.14616076749275952 | validation: 0.16072271758727585]
	TIME [epoch: 11.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1428245071260396		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.1428245071260396 | validation: 0.1927617252056022]
	TIME [epoch: 11.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15731275157126864		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.15731275157126864 | validation: 0.1598906216165402]
	TIME [epoch: 11.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1356488225982484		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.1356488225982484 | validation: 0.15618537476109182]
	TIME [epoch: 11.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13336506764869807		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.13336506764869807 | validation: 0.13817624982012267]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_594.pth
	Model improved!!!
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14171641487866166		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.14171641487866166 | validation: 0.19517388883874362]
	TIME [epoch: 11.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25694522784847496		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.25694522784847496 | validation: 0.192827823338044]
	TIME [epoch: 11.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16420078266137586		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.16420078266137586 | validation: 0.1453455846611405]
	TIME [epoch: 11.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1407990310622347		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.1407990310622347 | validation: 0.17013570823845037]
	TIME [epoch: 11.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14563841697945745		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.14563841697945745 | validation: 0.13801395806784195]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_599.pth
	Model improved!!!
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1309230084978204		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.1309230084978204 | validation: 0.13182631268541015]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_600.pth
	Model improved!!!
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14405222950366126		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.14405222950366126 | validation: 0.1736603922168349]
	TIME [epoch: 11.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16287481104802462		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.16287481104802462 | validation: 0.1712704250700465]
	TIME [epoch: 11.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16286229042465547		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.16286229042465547 | validation: 0.18162562649224345]
	TIME [epoch: 11.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15988167795071284		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.15988167795071284 | validation: 0.15762760598544182]
	TIME [epoch: 11.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16681119834471075		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.16681119834471075 | validation: 0.2185744322632935]
	TIME [epoch: 11.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22318375550408115		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.22318375550408115 | validation: 0.25104023452553514]
	TIME [epoch: 11.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22957513647368905		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.22957513647368905 | validation: 0.16409685599701326]
	TIME [epoch: 11.5 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.143536052052216		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.143536052052216 | validation: 0.17071197367412985]
	TIME [epoch: 11.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19547885237124205		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.19547885237124205 | validation: 0.1587132492664107]
	TIME [epoch: 11.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14456451652235763		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.14456451652235763 | validation: 0.16151866433264433]
	TIME [epoch: 11.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1458840528004745		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.1458840528004745 | validation: 0.20718712036959058]
	TIME [epoch: 11.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21285790823129036		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.21285790823129036 | validation: 0.16872263614872943]
	TIME [epoch: 11.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15653077125746923		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.15653077125746923 | validation: 0.1443072582069379]
	TIME [epoch: 11.5 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13114947150011275		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.13114947150011275 | validation: 0.135746857377999]
	TIME [epoch: 11.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13351177634894848		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.13351177634894848 | validation: 0.1689094800386084]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1452633057894181		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.1452633057894181 | validation: 0.1363131088975333]
	TIME [epoch: 11.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1439464666890714		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.1439464666890714 | validation: 0.1601420086837167]
	TIME [epoch: 11.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1565719467941134		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.1565719467941134 | validation: 0.16318576221336067]
	TIME [epoch: 11.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15129143485115243		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.15129143485115243 | validation: 0.14854689991814599]
	TIME [epoch: 11.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15637607781075286		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.15637607781075286 | validation: 0.19072779141128834]
	TIME [epoch: 11.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20951353454253818		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.20951353454253818 | validation: 0.265540127557164]
	TIME [epoch: 11.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2316562420809354		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.2316562420809354 | validation: 0.2074866035533777]
	TIME [epoch: 11.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670040057473636		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.1670040057473636 | validation: 0.17789631734329692]
	TIME [epoch: 11.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15433585450728346		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.15433585450728346 | validation: 0.13989645232449854]
	TIME [epoch: 11.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15861442244493015		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.15861442244493015 | validation: 0.1333405049988403]
	TIME [epoch: 11.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13681385034025226		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.13681385034025226 | validation: 0.14447198476229264]
	TIME [epoch: 11.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13985607581840198		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.13985607581840198 | validation: 0.1328939349459612]
	TIME [epoch: 11.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13675738360245596		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.13675738360245596 | validation: 0.14334041356720698]
	TIME [epoch: 11.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13181620503155786		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.13181620503155786 | validation: 0.17962048376187134]
	TIME [epoch: 11.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14632937015112985		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.14632937015112985 | validation: 0.1436840015375659]
	TIME [epoch: 11.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14862037499995776		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.14862037499995776 | validation: 0.1693022370771647]
	TIME [epoch: 11.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15271276785501078		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.15271276785501078 | validation: 0.1888720857500534]
	TIME [epoch: 11.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20353274496473592		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.20353274496473592 | validation: 0.23684442922584809]
	TIME [epoch: 11.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22827165355047652		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.22827165355047652 | validation: 0.20757051631932869]
	TIME [epoch: 11.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17288366382084708		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.17288366382084708 | validation: 0.17919239459714612]
	TIME [epoch: 11.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17752345262271307		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.17752345262271307 | validation: 0.17323702744577843]
	TIME [epoch: 11.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18199768544730008		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.18199768544730008 | validation: 0.24669942581475415]
	TIME [epoch: 11.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19354165299938975		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.19354165299938975 | validation: 0.24368467583709638]
	TIME [epoch: 11.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23780952503056244		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.23780952503056244 | validation: 0.1450142322587173]
	TIME [epoch: 11.5 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1440710096953395		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.1440710096953395 | validation: 0.13457862284393352]
	TIME [epoch: 11.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17463435582886222		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.17463435582886222 | validation: 0.23308561787088558]
	TIME [epoch: 11.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22705964260899672		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.22705964260899672 | validation: 0.17867555245446579]
	TIME [epoch: 11.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14967565786975856		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.14967565786975856 | validation: 0.1866347156904335]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18470600836956969		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.18470600836956969 | validation: 0.1625521126465366]
	TIME [epoch: 11.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15578727126430306		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.15578727126430306 | validation: 0.14892983213414446]
	TIME [epoch: 11.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1562138233264748		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.1562138233264748 | validation: 0.15670877919565535]
	TIME [epoch: 11.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1542116203973752		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.1542116203973752 | validation: 0.15373739109444548]
	TIME [epoch: 11.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23297645288356578		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.23297645288356578 | validation: 0.2611824906301328]
	TIME [epoch: 11.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20267338453149678		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.20267338453149678 | validation: 0.16910717768312605]
	TIME [epoch: 11.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15337547418856146		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.15337547418856146 | validation: 0.1316716407965686]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_650.pth
	Model improved!!!
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13406021758755304		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.13406021758755304 | validation: 0.13129604435844275]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_651.pth
	Model improved!!!
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13996107510358993		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.13996107510358993 | validation: 0.15997293242470365]
	TIME [epoch: 11.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18272362663083064		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.18272362663083064 | validation: 0.1519408992069141]
	TIME [epoch: 11.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1446005257176657		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.1446005257176657 | validation: 0.1529700779681373]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18557051861080315		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.18557051861080315 | validation: 0.1847091196150265]
	TIME [epoch: 11.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17275827427146168		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.17275827427146168 | validation: 0.20170179610052813]
	TIME [epoch: 11.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17498480662933474		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.17498480662933474 | validation: 0.18418636153495235]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17328392242995488		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.17328392242995488 | validation: 0.19391470950117332]
	TIME [epoch: 11.5 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19260681270057245		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.19260681270057245 | validation: 0.1954953915794876]
	TIME [epoch: 11.5 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18159131013678204		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.18159131013678204 | validation: 0.15803523666218666]
	TIME [epoch: 11.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15899852302132883		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.15899852302132883 | validation: 0.1775994625908534]
	TIME [epoch: 11.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18782075023059452		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.18782075023059452 | validation: 0.213421693412567]
	TIME [epoch: 11.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20850737573800007		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.20850737573800007 | validation: 0.19438847645335025]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17204859250914506		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.17204859250914506 | validation: 0.19518308240897964]
	TIME [epoch: 11.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17813089154108058		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.17813089154108058 | validation: 0.24065820766487278]
	TIME [epoch: 11.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21100938385664036		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.21100938385664036 | validation: 0.19995391444996918]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1674552276020616		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.1674552276020616 | validation: 0.19513821016819513]
	TIME [epoch: 11.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18235064582616403		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.18235064582616403 | validation: 0.21071666021589508]
	TIME [epoch: 11.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1712816625504879		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.1712816625504879 | validation: 0.16174294931517058]
	TIME [epoch: 11.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13533799595338916		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.13533799595338916 | validation: 0.15684442408006732]
	TIME [epoch: 11.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1550224603087997		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.1550224603087997 | validation: 0.13685908688609796]
	TIME [epoch: 11.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297220689574943		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.1297220689574943 | validation: 0.15214274723558685]
	TIME [epoch: 11.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13259006893942016		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.13259006893942016 | validation: 0.13563013100009572]
	TIME [epoch: 11.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.130862780425842		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.130862780425842 | validation: 0.14255973142705533]
	TIME [epoch: 11.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13254873252608107		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.13254873252608107 | validation: 0.14012608047695638]
	TIME [epoch: 11.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12772999131103213		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.12772999131103213 | validation: 0.1293023701202171]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_676.pth
	Model improved!!!
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13016402376604227		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.13016402376604227 | validation: 0.17626005102790857]
	TIME [epoch: 11.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15740866826803018		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.15740866826803018 | validation: 0.13140009071971306]
	TIME [epoch: 11.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1272567059209398		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.1272567059209398 | validation: 0.13270507433400008]
	TIME [epoch: 11.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12668113588245145		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.12668113588245145 | validation: 0.1362734615577157]
	TIME [epoch: 11.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13149820227963327		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.13149820227963327 | validation: 0.15521332077453817]
	TIME [epoch: 11.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12898084535874574		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.12898084535874574 | validation: 0.1511276354597799]
	TIME [epoch: 11.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16498534269478782		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.16498534269478782 | validation: 0.16937565953180503]
	TIME [epoch: 11.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1373809213895203		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.1373809213895203 | validation: 0.14393905362411233]
	TIME [epoch: 11.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1221534670732713		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.1221534670732713 | validation: 0.14265808600351254]
	TIME [epoch: 11.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14573255720139863		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.14573255720139863 | validation: 0.16924094788033067]
	TIME [epoch: 11.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17382452067443394		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.17382452067443394 | validation: 0.1411038127160973]
	TIME [epoch: 11.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13025070235920255		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.13025070235920255 | validation: 0.1649190458726968]
	TIME [epoch: 11.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.153333011473869		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.153333011473869 | validation: 0.17581107730558984]
	TIME [epoch: 11.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1488188917785754		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.1488188917785754 | validation: 0.16943699500409545]
	TIME [epoch: 11.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13538546127138384		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.13538546127138384 | validation: 0.1542007478307551]
	TIME [epoch: 11.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13995370067192567		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.13995370067192567 | validation: 0.1575316011020385]
	TIME [epoch: 11.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15727860901247534		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.15727860901247534 | validation: 0.18813948833327168]
	TIME [epoch: 11.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15571494602043137		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.15571494602043137 | validation: 0.16976563454237106]
	TIME [epoch: 11.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15847968842513865		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.15847968842513865 | validation: 0.19224845502212565]
	TIME [epoch: 11.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15941457217840593		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.15941457217840593 | validation: 0.24903485203366665]
	TIME [epoch: 11.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23672538943399088		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.23672538943399088 | validation: 0.27105200462586176]
	TIME [epoch: 11.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1985245257742087		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.1985245257742087 | validation: 0.15545447482387179]
	TIME [epoch: 11.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14275259693970138		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.14275259693970138 | validation: 0.1635494533347026]
	TIME [epoch: 11.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14897492279206714		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.14897492279206714 | validation: 0.14997803308813049]
	TIME [epoch: 11.5 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13384803279582003		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.13384803279582003 | validation: 0.1464931337401508]
	TIME [epoch: 11.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13074610870270664		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.13074610870270664 | validation: 0.14620583806260384]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13254493362819914		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.13254493362819914 | validation: 0.1392906895675175]
	TIME [epoch: 11.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15301354793826905		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.15301354793826905 | validation: 0.14790844218738008]
	TIME [epoch: 11.5 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17979781954811472		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.17979781954811472 | validation: 0.18630187566432505]
	TIME [epoch: 11.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1707683755468357		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.1707683755468357 | validation: 0.17421483012833122]
	TIME [epoch: 11.5 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15531730136939376		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.15531730136939376 | validation: 0.14150651429169994]
	TIME [epoch: 11.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13926175064973723		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.13926175064973723 | validation: 0.15656209049576278]
	TIME [epoch: 11.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14239907425534165		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.14239907425534165 | validation: 0.14322708170929885]
	TIME [epoch: 11.5 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1261715855465254		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.1261715855465254 | validation: 0.16208169364669303]
	TIME [epoch: 11.5 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13159570024248213		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.13159570024248213 | validation: 0.1424996407049538]
	TIME [epoch: 11.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1244529630581086		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.1244529630581086 | validation: 0.14554147076908583]
	TIME [epoch: 11.5 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342467472445477		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.1342467472445477 | validation: 0.13996831356725317]
	TIME [epoch: 11.5 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14500761786716726		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.14500761786716726 | validation: 0.143192414849956]
	TIME [epoch: 11.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12619738611236142		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.12619738611236142 | validation: 0.12573185666817746]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_715.pth
	Model improved!!!
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12432959709071832		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.12432959709071832 | validation: 0.13746984523772424]
	TIME [epoch: 11.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12268787745219015		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.12268787745219015 | validation: 0.1523795535047925]
	TIME [epoch: 11.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13353500512023203		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.13353500512023203 | validation: 0.1506976620008524]
	TIME [epoch: 11.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14557951691832466		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.14557951691832466 | validation: 0.1423718977726579]
	TIME [epoch: 11.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1482028171831891		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.1482028171831891 | validation: 0.17031559509538965]
	TIME [epoch: 11.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15741002336192428		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.15741002336192428 | validation: 0.1949377382683833]
	TIME [epoch: 11.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19023810523730772		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.19023810523730772 | validation: 0.14537432996619823]
	TIME [epoch: 11.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12935122821889997		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.12935122821889997 | validation: 0.1385874710980837]
	TIME [epoch: 11.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129829432889263		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.129829432889263 | validation: 0.15998928773015636]
	TIME [epoch: 11.5 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14778267962334607		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.14778267962334607 | validation: 0.15483965844537936]
	TIME [epoch: 11.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.149266919616754		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.149266919616754 | validation: 0.1651757605296946]
	TIME [epoch: 11.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1416942124352375		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.1416942124352375 | validation: 0.14392801368435557]
	TIME [epoch: 11.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1338527390909828		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.1338527390909828 | validation: 0.1258664474178411]
	TIME [epoch: 11.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12095245584273956		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.12095245584273956 | validation: 0.14349220622312142]
	TIME [epoch: 11.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1690750751799234		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.1690750751799234 | validation: 0.1794366137574722]
	TIME [epoch: 11.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1548330861524726		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.1548330861524726 | validation: 0.14216398590095938]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11732200119538135		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.11732200119538135 | validation: 0.11396919706723474]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_732.pth
	Model improved!!!
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1112335600951598		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.1112335600951598 | validation: 0.1347079282511734]
	TIME [epoch: 11.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13500677817458853		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.13500677817458853 | validation: 0.12769391645904718]
	TIME [epoch: 11.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12177015373723551		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.12177015373723551 | validation: 0.1257973703732145]
	TIME [epoch: 11.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14017568849721415		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.14017568849721415 | validation: 0.15745335957823736]
	TIME [epoch: 11.5 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14249645628228297		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.14249645628228297 | validation: 0.15370684472221285]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15313441493123123		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.15313441493123123 | validation: 0.15117240700597076]
	TIME [epoch: 11.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1285734143855053		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.1285734143855053 | validation: 0.1388446091797037]
	TIME [epoch: 11.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12552425716611731		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.12552425716611731 | validation: 0.14303686051091954]
	TIME [epoch: 11.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12997759514404783		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.12997759514404783 | validation: 0.14187620591903358]
	TIME [epoch: 11.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13000719342709885		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.13000719342709885 | validation: 0.13508490237178333]
	TIME [epoch: 11.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11418307163994736		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.11418307163994736 | validation: 0.11945225901505126]
	TIME [epoch: 11.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11317005592363898		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.11317005592363898 | validation: 0.11515720656634944]
	TIME [epoch: 11.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11149591013593435		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.11149591013593435 | validation: 0.19370228123261485]
	TIME [epoch: 11.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19469668218171127		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.19469668218171127 | validation: 0.16329959648417983]
	TIME [epoch: 11.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13287272811014456		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.13287272811014456 | validation: 0.11417021467818333]
	TIME [epoch: 11.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10713380225621955		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.10713380225621955 | validation: 0.13326211956281522]
	TIME [epoch: 11.5 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11447293009738554		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.11447293009738554 | validation: 0.11798383951669546]
	TIME [epoch: 11.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11715586085982779		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.11715586085982779 | validation: 0.11565138952969559]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11482536787020577		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.11482536787020577 | validation: 0.14718141372850496]
	TIME [epoch: 11.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13947734234893583		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.13947734234893583 | validation: 0.1440010332837511]
	TIME [epoch: 11.5 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13565625410691737		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.13565625410691737 | validation: 0.13748447670502612]
	TIME [epoch: 11.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11904909633988192		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.11904909633988192 | validation: 0.13627656616972936]
	TIME [epoch: 11.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10975180881999484		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.10975180881999484 | validation: 0.15060222787310493]
	TIME [epoch: 11.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12893122100513466		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.12893122100513466 | validation: 0.11805904184556058]
	TIME [epoch: 11.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12000431893173434		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.12000431893173434 | validation: 0.15375954097425656]
	TIME [epoch: 11.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12211786947677108		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.12211786947677108 | validation: 0.1338123973385977]
	TIME [epoch: 11.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10595905592827422		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.10595905592827422 | validation: 0.13440917841614006]
	TIME [epoch: 11.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13540923652762538		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.13540923652762538 | validation: 0.16821527259888328]
	TIME [epoch: 11.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1558746053029388		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.1558746053029388 | validation: 0.129752283113423]
	TIME [epoch: 11.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12055284252082604		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.12055284252082604 | validation: 0.15090852293412116]
	TIME [epoch: 11.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14775268297838365		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.14775268297838365 | validation: 0.14738845669449918]
	TIME [epoch: 11.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140616640591912		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.140616640591912 | validation: 0.12929590710036248]
	TIME [epoch: 11.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13626282029217318		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.13626282029217318 | validation: 0.12390053243050086]
	TIME [epoch: 11.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12104569688960817		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.12104569688960817 | validation: 0.13097701769157005]
	TIME [epoch: 11.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11527632905784017		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.11527632905784017 | validation: 0.13142916626368842]
	TIME [epoch: 11.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13134301342125643		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.13134301342125643 | validation: 0.13787613489564685]
	TIME [epoch: 11.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1169087279851472		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.1169087279851472 | validation: 0.1282324485030844]
	TIME [epoch: 11.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1262450755590192		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.1262450755590192 | validation: 0.1397153105886029]
	TIME [epoch: 11.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11500441128462956		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.11500441128462956 | validation: 0.12345129358794933]
	TIME [epoch: 11.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09562464652117476		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.09562464652117476 | validation: 0.11479042520052639]
	TIME [epoch: 11.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09371956222195588		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.09371956222195588 | validation: 0.13341440706523433]
	TIME [epoch: 11.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11754814503387893		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.11754814503387893 | validation: 0.12033502302790361]
	TIME [epoch: 11.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10511377426940781		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.10511377426940781 | validation: 0.12393121612283754]
	TIME [epoch: 11.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10867721672640301		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.10867721672640301 | validation: 0.14299471692043245]
	TIME [epoch: 11.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12170218822925943		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.12170218822925943 | validation: 0.1433961849982413]
	TIME [epoch: 11.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16188936553893377		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.16188936553893377 | validation: 0.17353963430398836]
	TIME [epoch: 11.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2292986034099313		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.2292986034099313 | validation: 0.20095980927102594]
	TIME [epoch: 11.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1907629711493893		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.1907629711493893 | validation: 0.1800308221946073]
	TIME [epoch: 11.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1860922167524872		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.1860922167524872 | validation: 0.15107496284671787]
	TIME [epoch: 11.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126605596226787		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.126605596226787 | validation: 0.14244133610504953]
	TIME [epoch: 11.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12299240089721866		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.12299240089721866 | validation: 0.14353150707932089]
	TIME [epoch: 11.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1493432398547549		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.1493432398547549 | validation: 0.20012047977126635]
	TIME [epoch: 11.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22224499874173625		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.22224499874173625 | validation: 0.1964072478013287]
	TIME [epoch: 11.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19009089847736502		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.19009089847736502 | validation: 0.16799665738482464]
	TIME [epoch: 11.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1594993724070634		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.1594993724070634 | validation: 0.14932503053571006]
	TIME [epoch: 11.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1400649209267731		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.1400649209267731 | validation: 0.15663493741019643]
	TIME [epoch: 11.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1525696068632865		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.1525696068632865 | validation: 0.14692826763772704]
	TIME [epoch: 11.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1302049499918225		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.1302049499918225 | validation: 0.147030592353547]
	TIME [epoch: 11.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15909775104682106		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.15909775104682106 | validation: 0.16653859922498612]
	TIME [epoch: 11.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357353314503675		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.1357353314503675 | validation: 0.15612452597258258]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13171309102054327		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.13171309102054327 | validation: 0.15689928685226157]
	TIME [epoch: 11.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1330177327704383		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.1330177327704383 | validation: 0.17400695512651673]
	TIME [epoch: 11.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314922181855303		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.1314922181855303 | validation: 0.14897120954314194]
	TIME [epoch: 11.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13580736128832324		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.13580736128832324 | validation: 0.1434829398879479]
	TIME [epoch: 11.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1170073724379032		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.1170073724379032 | validation: 0.14497688708807294]
	TIME [epoch: 11.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13817142732915924		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.13817142732915924 | validation: 0.15299422128395315]
	TIME [epoch: 11.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1464783658844076		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.1464783658844076 | validation: 0.18214923057545357]
	TIME [epoch: 11.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15747800332992876		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.15747800332992876 | validation: 0.1814784135980559]
	TIME [epoch: 11.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16091194263287525		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.16091194263287525 | validation: 0.13232767853667537]
	TIME [epoch: 11.5 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10950913192001029		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.10950913192001029 | validation: 0.12271428400121344]
	TIME [epoch: 11.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10336054548877861		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.10336054548877861 | validation: 0.13296711335471856]
	TIME [epoch: 11.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255578028148727		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.1255578028148727 | validation: 0.15462097469163102]
	TIME [epoch: 11.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12462149593525088		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.12462149593525088 | validation: 0.13554715305560158]
	TIME [epoch: 11.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13612016688988762		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.13612016688988762 | validation: 0.1524874436064622]
	TIME [epoch: 11.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1547275086104459		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.1547275086104459 | validation: 0.1699385821915142]
	TIME [epoch: 11.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16745021462397622		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.16745021462397622 | validation: 0.16453424143960713]
	TIME [epoch: 11.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18197401113091868		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.18197401113091868 | validation: 0.21161257306303718]
	TIME [epoch: 11.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19412830286093322		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.19412830286093322 | validation: 0.1794035840630619]
	TIME [epoch: 11.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1795887364172472		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.1795887364172472 | validation: 0.16887018106150742]
	TIME [epoch: 11.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14858235092291214		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.14858235092291214 | validation: 0.14482405978246107]
	TIME [epoch: 11.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12527612952986056		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.12527612952986056 | validation: 0.1272157406784859]
	TIME [epoch: 11.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11367632121077964		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.11367632121077964 | validation: 0.13714051785600112]
	TIME [epoch: 11.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11160094504228651		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.11160094504228651 | validation: 0.13452405738393453]
	TIME [epoch: 11.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10794793178708914		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.10794793178708914 | validation: 0.12732591945442057]
	TIME [epoch: 11.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11075178945829514		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.11075178945829514 | validation: 0.1339657338944241]
	TIME [epoch: 11.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12547125685139388		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.12547125685139388 | validation: 0.16029572749794033]
	TIME [epoch: 11.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11420722404709895		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.11420722404709895 | validation: 0.1360913875300371]
	TIME [epoch: 11.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1176814835267231		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.1176814835267231 | validation: 0.1270078159380657]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11060465759135765		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.11060465759135765 | validation: 0.13052440022612058]
	TIME [epoch: 11.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11673025362547675		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.11673025362547675 | validation: 0.13499879316557]
	TIME [epoch: 11.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11476133751127013		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.11476133751127013 | validation: 0.14051076496169596]
	TIME [epoch: 11.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11569962234545077		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.11569962234545077 | validation: 0.14280552081587541]
	TIME [epoch: 11.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11864348416724813		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.11864348416724813 | validation: 0.13755707532129108]
	TIME [epoch: 11.5 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10643391926938114		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.10643391926938114 | validation: 0.12070629061837375]
	TIME [epoch: 11.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1037353500842622		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.1037353500842622 | validation: 0.12515769947479113]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12028035588957894		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.12028035588957894 | validation: 0.1711967704478451]
	TIME [epoch: 11.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12711101374385295		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.12711101374385295 | validation: 0.12622006328918356]
	TIME [epoch: 11.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10413909517465347		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.10413909517465347 | validation: 0.11323636217356672]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_830.pth
	Model improved!!!
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12784358853662647		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.12784358853662647 | validation: 0.12459871279187994]
	TIME [epoch: 11.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10131045500221267		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.10131045500221267 | validation: 0.13465497809145724]
	TIME [epoch: 11.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11041076569218813		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.11041076569218813 | validation: 0.12761965606318504]
	TIME [epoch: 11.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09503109075760025		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.09503109075760025 | validation: 0.11784360620152344]
	TIME [epoch: 11.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09277907509130212		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.09277907509130212 | validation: 0.11447905949943663]
	TIME [epoch: 11.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09910125077000878		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.09910125077000878 | validation: 0.12764877189529478]
	TIME [epoch: 11.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10564081641070219		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.10564081641070219 | validation: 0.12660406843848118]
	TIME [epoch: 11.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10282967184578615		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.10282967184578615 | validation: 0.12534893277273143]
	TIME [epoch: 11.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10095109563086073		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.10095109563086073 | validation: 0.1254053602293794]
	TIME [epoch: 11.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09900988565257973		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.09900988565257973 | validation: 0.12012057255128451]
	TIME [epoch: 11.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10207019710845813		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.10207019710845813 | validation: 0.13646709915120098]
	TIME [epoch: 11.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09899225072740524		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.09899225072740524 | validation: 0.12919607631947172]
	TIME [epoch: 11.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12692191546352877		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.12692191546352877 | validation: 0.16641401634177588]
	TIME [epoch: 11.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12395568228783742		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.12395568228783742 | validation: 0.13145756259369884]
	TIME [epoch: 11.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11260588511732808		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.11260588511732808 | validation: 0.11875486180135131]
	TIME [epoch: 11.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10038610953574162		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.10038610953574162 | validation: 0.11865306576630094]
	TIME [epoch: 11.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10590954789793994		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.10590954789793994 | validation: 0.118743444201038]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10045064823403671		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.10045064823403671 | validation: 0.11938102845046626]
	TIME [epoch: 11.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09513219677545814		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.09513219677545814 | validation: 0.11255499655409806]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_849.pth
	Model improved!!!
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10518036128094566		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.10518036128094566 | validation: 0.12408218171480771]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11389875287762427		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.11389875287762427 | validation: 0.1276153764622396]
	TIME [epoch: 11.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0995102141425831		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.0995102141425831 | validation: 0.11092760939284073]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_852.pth
	Model improved!!!
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09763975721713818		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.09763975721713818 | validation: 0.11310369493506726]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10171792043817574		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.10171792043817574 | validation: 0.1017730995482382]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_854.pth
	Model improved!!!
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13015515119310211		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.13015515119310211 | validation: 0.15849544702158697]
	TIME [epoch: 11.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12683475499880076		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.12683475499880076 | validation: 0.10896444339343356]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09346415185074415		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.09346415185074415 | validation: 0.11153005612320092]
	TIME [epoch: 11.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0905887867392525		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.0905887867392525 | validation: 0.10879957947496706]
	TIME [epoch: 11.5 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08740202617734577		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.08740202617734577 | validation: 0.10046480869875019]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_859.pth
	Model improved!!!
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08922636246563007		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.08922636246563007 | validation: 0.0988964409319054]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_860.pth
	Model improved!!!
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11550156367003606		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.11550156367003606 | validation: 0.13971498357910803]
	TIME [epoch: 11.5 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11263986729310146		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.11263986729310146 | validation: 0.0961895015736037]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_862.pth
	Model improved!!!
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08251612709558435		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.08251612709558435 | validation: 0.09901651897148335]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09673133503475964		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.09673133503475964 | validation: 0.1272084151703367]
	TIME [epoch: 11.5 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11345473011199236		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.11345473011199236 | validation: 0.11776518922238301]
	TIME [epoch: 11.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10685134351994684		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.10685134351994684 | validation: 0.12425110466670537]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09352293933034682		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.09352293933034682 | validation: 0.10910920399339548]
	TIME [epoch: 11.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08983263292416888		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.08983263292416888 | validation: 0.11637443423651082]
	TIME [epoch: 11.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09327118051638109		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.09327118051638109 | validation: 0.09343060710923273]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_869.pth
	Model improved!!!
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09060715438426083		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.09060715438426083 | validation: 0.10447072787534145]
	TIME [epoch: 11.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1004989777913503		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.1004989777913503 | validation: 0.11995547798634748]
	TIME [epoch: 11.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10910831515889423		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.10910831515889423 | validation: 0.12143761748738748]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0952890526031662		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.0952890526031662 | validation: 0.0942807710186581]
	TIME [epoch: 11.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0902750967224008		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.0902750967224008 | validation: 0.13148285797136253]
	TIME [epoch: 11.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10803961352750086		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.10803961352750086 | validation: 0.12911164605587175]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.123803808986477		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.123803808986477 | validation: 0.15090279202588788]
	TIME [epoch: 11.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15680361060245362		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.15680361060245362 | validation: 0.2028608367607744]
	TIME [epoch: 11.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1452339483877611		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.1452339483877611 | validation: 0.13287614831972153]
	TIME [epoch: 11.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1104945707368255		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.1104945707368255 | validation: 0.11375031961004027]
	TIME [epoch: 11.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09991019407033769		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.09991019407033769 | validation: 0.11977847689918436]
	TIME [epoch: 11.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10118702875939083		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.10118702875939083 | validation: 0.10802914033370849]
	TIME [epoch: 11.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10093999563604233		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.10093999563604233 | validation: 0.11510429121119241]
	TIME [epoch: 11.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09571225176820336		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.09571225176820336 | validation: 0.10619019854278318]
	TIME [epoch: 11.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08452250925825064		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.08452250925825064 | validation: 0.10002795127612746]
	TIME [epoch: 11.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09294028639984017		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.09294028639984017 | validation: 0.09856183488923298]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.085375336604456		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.085375336604456 | validation: 0.10367621234452337]
	TIME [epoch: 11.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08460750369391161		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.08460750369391161 | validation: 0.1009110733115333]
	TIME [epoch: 11.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09016051296215641		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.09016051296215641 | validation: 0.0916320594364317]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_888.pth
	Model improved!!!
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09000109083765476		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.09000109083765476 | validation: 0.12345726404425379]
	TIME [epoch: 11.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09599236314260982		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.09599236314260982 | validation: 0.10273855475120787]
	TIME [epoch: 11.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08751904629432684		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.08751904629432684 | validation: 0.10054471211297643]
	TIME [epoch: 11.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08292330139071674		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.08292330139071674 | validation: 0.08979071019015822]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_892.pth
	Model improved!!!
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09799065196027809		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.09799065196027809 | validation: 0.09637001376085795]
	TIME [epoch: 11.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08274051208277201		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.08274051208277201 | validation: 0.10362882921245987]
	TIME [epoch: 11.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09046746150484652		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.09046746150484652 | validation: 0.12604342870176852]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09871960846592506		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.09871960846592506 | validation: 0.09963944198065562]
	TIME [epoch: 11.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11663441484622156		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.11663441484622156 | validation: 0.2007801600540304]
	TIME [epoch: 11.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14189859520936327		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.14189859520936327 | validation: 0.13441615622712388]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10271902196309414		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.10271902196309414 | validation: 0.11085453583142453]
	TIME [epoch: 11.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10081935301921402		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.10081935301921402 | validation: 0.11714458508924222]
	TIME [epoch: 11.5 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09875361458813325		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.09875361458813325 | validation: 0.10988862358597164]
	TIME [epoch: 11.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09824408600007403		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.09824408600007403 | validation: 0.12378952376312141]
	TIME [epoch: 11.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11273015529278302		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.11273015529278302 | validation: 0.11975091707156774]
	TIME [epoch: 11.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09814304246931443		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.09814304246931443 | validation: 0.10823731268129595]
	TIME [epoch: 11.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09626954645769646		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.09626954645769646 | validation: 0.1112987463683555]
	TIME [epoch: 11.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10964859077325562		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.10964859077325562 | validation: 0.1288367251006089]
	TIME [epoch: 11.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12215095278700736		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.12215095278700736 | validation: 0.11666182686794034]
	TIME [epoch: 11.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10795859680207387		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.10795859680207387 | validation: 0.11504524016330045]
	TIME [epoch: 11.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11126477081623504		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.11126477081623504 | validation: 0.11101879664674921]
	TIME [epoch: 11.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10048410602206345		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.10048410602206345 | validation: 0.1127287033520173]
	TIME [epoch: 11.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10223630638426162		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.10223630638426162 | validation: 0.10765549531684988]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1037563004308493		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.1037563004308493 | validation: 0.10740038449948763]
	TIME [epoch: 11.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09920424014455842		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.09920424014455842 | validation: 0.11435788849954992]
	TIME [epoch: 11.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11225663294677675		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.11225663294677675 | validation: 0.10808231383035896]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1100233261942754		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.1100233261942754 | validation: 0.10760337097360717]
	TIME [epoch: 11.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10088702105455673		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.10088702105455673 | validation: 0.10070138825393542]
	TIME [epoch: 11.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0902656653268728		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.0902656653268728 | validation: 0.10295696704676602]
	TIME [epoch: 11.5 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08891417169648588		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.08891417169648588 | validation: 0.09643457253019355]
	TIME [epoch: 11.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09352172588089186		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.09352172588089186 | validation: 0.10650360192262776]
	TIME [epoch: 11.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09441939880397981		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.09441939880397981 | validation: 0.10240648434228593]
	TIME [epoch: 11.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09291025101812103		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.09291025101812103 | validation: 0.09512921729111168]
	TIME [epoch: 11.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09165932370632313		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.09165932370632313 | validation: 0.10630124529920724]
	TIME [epoch: 11.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11517280041189602		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.11517280041189602 | validation: 0.10712639976078911]
	TIME [epoch: 11.5 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11167490205384807		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.11167490205384807 | validation: 0.12276340171099405]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10404196534236904		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.10404196534236904 | validation: 0.11322421535439542]
	TIME [epoch: 11.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11290113387468323		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.11290113387468323 | validation: 0.1051133286847987]
	TIME [epoch: 11.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10362711626516542		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.10362711626516542 | validation: 0.11150682515869581]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10408347874826927		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.10408347874826927 | validation: 0.11312127999358093]
	TIME [epoch: 11.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1066444836340917		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.1066444836340917 | validation: 0.1121523721883976]
	TIME [epoch: 11.5 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10951597384407737		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.10951597384407737 | validation: 0.1154644978481307]
	TIME [epoch: 11.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10217477702295753		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.10217477702295753 | validation: 0.11093683255267234]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09102052984792466		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.09102052984792466 | validation: 0.10045077801244791]
	TIME [epoch: 11.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09094022880893742		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.09094022880893742 | validation: 0.09876884491726397]
	TIME [epoch: 11.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0866705327304676		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.0866705327304676 | validation: 0.09022673232707318]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08832248319164172		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.08832248319164172 | validation: 0.10657036554767238]
	TIME [epoch: 11.5 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09365460181202236		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.09365460181202236 | validation: 0.10381429916660752]
	TIME [epoch: 11.5 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10197007831824405		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.10197007831824405 | validation: 0.10244737870326909]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09736631387211944		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.09736631387211944 | validation: 0.10083161185984581]
	TIME [epoch: 11.5 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09304326103301737		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.09304326103301737 | validation: 0.10032839454580675]
	TIME [epoch: 11.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09094705779273382		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.09094705779273382 | validation: 0.1092740663477316]
	TIME [epoch: 11.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09004214538623864		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.09004214538623864 | validation: 0.0872170043992707]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_941.pth
	Model improved!!!
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09170451971276619		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.09170451971276619 | validation: 0.09723198331449044]
	TIME [epoch: 11.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08777628234537149		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.08777628234537149 | validation: 0.10126801024138564]
	TIME [epoch: 11.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09547249229165924		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.09547249229165924 | validation: 0.10633059134380045]
	TIME [epoch: 11.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10175409206945552		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.10175409206945552 | validation: 0.1403872764997438]
	TIME [epoch: 11.5 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.134049336542659		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.134049336542659 | validation: 0.1658323406275197]
	TIME [epoch: 11.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1508747361720832		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.1508747361720832 | validation: 0.18775576219515416]
	TIME [epoch: 11.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17516671756733485		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.17516671756733485 | validation: 0.17198874641603862]
	TIME [epoch: 11.5 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16625956782042728		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.16625956782042728 | validation: 0.18373834998788519]
	TIME [epoch: 11.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1426313159430889		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.1426313159430889 | validation: 0.12599561174357152]
	TIME [epoch: 11.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10219177651981733		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.10219177651981733 | validation: 0.11425000836463835]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08617329390765069		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.08617329390765069 | validation: 0.0996451015606156]
	TIME [epoch: 11.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08428177690987168		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.08428177690987168 | validation: 0.08448369257336662]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_953.pth
	Model improved!!!
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08388975447833413		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.08388975447833413 | validation: 0.09619814986787266]
	TIME [epoch: 11.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09248122366298825		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.09248122366298825 | validation: 0.10268514294378431]
	TIME [epoch: 11.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08688425391317012		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.08688425391317012 | validation: 0.09746483722109121]
	TIME [epoch: 11.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08444665066118644		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.08444665066118644 | validation: 0.10173159203262212]
	TIME [epoch: 11.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09530574395888884		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.09530574395888884 | validation: 0.12023343375446349]
	TIME [epoch: 11.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12612995179405778		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.12612995179405778 | validation: 0.1319262336209326]
	TIME [epoch: 11.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10926565986078295		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.10926565986078295 | validation: 0.11660915590231109]
	TIME [epoch: 11.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0962478249093679		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.0962478249093679 | validation: 0.09752516138323188]
	TIME [epoch: 11.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08971999949879145		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.08971999949879145 | validation: 0.1073586967877737]
	TIME [epoch: 11.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08967651733866731		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.08967651733866731 | validation: 0.10135169358674945]
	TIME [epoch: 11.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0939425866363391		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.0939425866363391 | validation: 0.106568194239563]
	TIME [epoch: 11.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08739712783600484		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.08739712783600484 | validation: 0.08619946413025041]
	TIME [epoch: 11.5 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07857015976871908		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.07857015976871908 | validation: 0.09510748628104562]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08118313115026106		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.08118313115026106 | validation: 0.09761703372945377]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08327390050957498		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.08327390050957498 | validation: 0.09444625236635007]
	TIME [epoch: 11.5 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08025996834137289		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.08025996834137289 | validation: 0.08891014367002242]
	TIME [epoch: 11.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07653649434040724		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.07653649434040724 | validation: 0.08386139953158889]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_970.pth
	Model improved!!!
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.076870355134151		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.076870355134151 | validation: 0.09419197381816713]
	TIME [epoch: 11.5 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07942222841146994		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.07942222841146994 | validation: 0.10009031864481525]
	TIME [epoch: 11.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08597533875268852		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.08597533875268852 | validation: 0.09614224731905022]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0946328576778464		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.0946328576778464 | validation: 0.1069689409494881]
	TIME [epoch: 11.5 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10173266506632644		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.10173266506632644 | validation: 0.10968781059271844]
	TIME [epoch: 11.5 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08535728159256838		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.08535728159256838 | validation: 0.09457973111539629]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08721345411899037		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.08721345411899037 | validation: 0.10030464947217463]
	TIME [epoch: 11.5 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08262243928189007		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.08262243928189007 | validation: 0.10001293531227559]
	TIME [epoch: 11.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07639501295128565		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.07639501295128565 | validation: 0.08743949174159894]
	TIME [epoch: 11.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07411522656241651		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.07411522656241651 | validation: 0.08951872487404967]
	TIME [epoch: 11.5 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0829215030103657		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.0829215030103657 | validation: 0.09188123616150494]
	TIME [epoch: 11.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08553148518857709		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.08553148518857709 | validation: 0.09917656406515873]
	TIME [epoch: 11.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08220778346477614		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.08220778346477614 | validation: 0.09233114534660089]
	TIME [epoch: 11.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08143128907155442		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.08143128907155442 | validation: 0.09707332372354906]
	TIME [epoch: 11.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08380340520467251		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.08380340520467251 | validation: 0.12885606141336617]
	TIME [epoch: 11.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11144179145830335		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.11144179145830335 | validation: 0.11451466904956281]
	TIME [epoch: 11.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09462662624696787		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.09462662624696787 | validation: 0.10761048497529344]
	TIME [epoch: 11.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08896854373290192		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.08896854373290192 | validation: 0.12500323763740848]
	TIME [epoch: 11.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10563608298254129		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.10563608298254129 | validation: 0.10618764930686657]
	TIME [epoch: 11.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09713174979389591		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.09713174979389591 | validation: 0.11572234367077343]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11570136704505733		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.11570136704505733 | validation: 0.13882981575620354]
	TIME [epoch: 11.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10200271601055609		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.10200271601055609 | validation: 0.12281410931845738]
	TIME [epoch: 11.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09324538449732006		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.09324538449732006 | validation: 0.0987393796056356]
	TIME [epoch: 11.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08476015093912004		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.08476015093912004 | validation: 0.09460126161680958]
	TIME [epoch: 11.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08486111745618925		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.08486111745618925 | validation: 0.09661027544689935]
	TIME [epoch: 11.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09242275227912915		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.09242275227912915 | validation: 0.09884222071405097]
	TIME [epoch: 11.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08379380474054635		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.08379380474054635 | validation: 0.09560917683094382]
	TIME [epoch: 11.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08602873888357074		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.08602873888357074 | validation: 0.09119135337644588]
	TIME [epoch: 11.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07960386707821401		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.07960386707821401 | validation: 0.09798661895842241]
	TIME [epoch: 11.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08810215453742418		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.08810215453742418 | validation: 0.10913345608552305]
	TIME [epoch: 11.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09504267361330346		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.09504267361330346 | validation: 0.11597377784819315]
	TIME [epoch: 11.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09581621562971547		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.09581621562971547 | validation: 0.11531748191597557]
	TIME [epoch: 11.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11179631870477748		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.11179631870477748 | validation: 0.11360721793570726]
	TIME [epoch: 11.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09336931252447887		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.09336931252447887 | validation: 0.084286372203994]
	TIME [epoch: 11.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07965808985386622		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.07965808985386622 | validation: 0.08963801177257846]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08510917020689576		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.08510917020689576 | validation: 0.09818480491844774]
	TIME [epoch: 11.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08138418818365349		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.08138418818365349 | validation: 0.10004654937249756]
	TIME [epoch: 11.5 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0894197426732457		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.0894197426732457 | validation: 0.10250817111383409]
	TIME [epoch: 11.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10484961228342463		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.10484961228342463 | validation: 0.12446687365139976]
	TIME [epoch: 11.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09869504983036086		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.09869504983036086 | validation: 0.10450846156359102]
	TIME [epoch: 11.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09553545325124096		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.09553545325124096 | validation: 0.12097278846108937]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10618278432464215		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.10618278432464215 | validation: 0.12253798326615087]
	TIME [epoch: 11.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10412819205990023		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.10412819205990023 | validation: 0.10770361592713222]
	TIME [epoch: 11.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0896883805185321		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.0896883805185321 | validation: 0.10323214083650203]
	TIME [epoch: 11.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09262908511535509		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.09262908511535509 | validation: 0.10172995228426505]
	TIME [epoch: 11.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08920264186186314		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.08920264186186314 | validation: 0.09188364097353238]
	TIME [epoch: 11.5 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08654795184720789		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.08654795184720789 | validation: 0.09669390750626466]
	TIME [epoch: 11.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.084055551814317		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.084055551814317 | validation: 0.09274259710189987]
	TIME [epoch: 11.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07829770778824752		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.07829770778824752 | validation: 0.09391095435921148]
	TIME [epoch: 11.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07862687298848361		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.07862687298848361 | validation: 0.08684872996233081]
	TIME [epoch: 11.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07229994296525492		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.07229994296525492 | validation: 0.08488091173282371]
	TIME [epoch: 11.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07930619761422213		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.07930619761422213 | validation: 0.08502019940617883]
	TIME [epoch: 11.5 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08389058753025985		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.08389058753025985 | validation: 0.08806714517577557]
	TIME [epoch: 11.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08141668340978243		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.08141668340978243 | validation: 0.08817405524283058]
	TIME [epoch: 11.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07729599141999657		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.07729599141999657 | validation: 0.08910105034384888]
	TIME [epoch: 11.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08168634914485		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.08168634914485 | validation: 0.11079847589801232]
	TIME [epoch: 11.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09826546814463674		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.09826546814463674 | validation: 0.1458752382784649]
	TIME [epoch: 11.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10581924958310641		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.10581924958310641 | validation: 0.12553244834835448]
	TIME [epoch: 11.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11943379189781092		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.11943379189781092 | validation: 0.15779540520285665]
	TIME [epoch: 11.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353370100493347		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.1353370100493347 | validation: 0.16291794570579948]
	TIME [epoch: 11.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16747999545779618		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.16747999545779618 | validation: 0.18017297193167386]
	TIME [epoch: 11.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1351462127415833		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.1351462127415833 | validation: 0.13785273112368462]
	TIME [epoch: 11.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10380897025763748		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.10380897025763748 | validation: 0.1006983837952398]
	TIME [epoch: 11.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08883769811459019		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.08883769811459019 | validation: 0.11315345196716443]
	TIME [epoch: 11.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10360829345187868		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.10360829345187868 | validation: 0.11332684553229364]
	TIME [epoch: 11.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1018697332257383		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.1018697332257383 | validation: 0.09944894841152518]
	TIME [epoch: 11.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09356740913266526		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.09356740913266526 | validation: 0.10240725668101147]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08751116185109903		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.08751116185109903 | validation: 0.10203606407522152]
	TIME [epoch: 11.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08758709180075541		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.08758709180075541 | validation: 0.09632358337094399]
	TIME [epoch: 11.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08578106467922057		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.08578106467922057 | validation: 0.09791424767340744]
	TIME [epoch: 11.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09406879424385692		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.09406879424385692 | validation: 0.10970991010938747]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10686481042412935		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.10686481042412935 | validation: 0.13296059014260933]
	TIME [epoch: 11.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1221685643839404		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.1221685643839404 | validation: 0.12102058875346064]
	TIME [epoch: 11.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11435410902671922		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.11435410902671922 | validation: 0.11179230995883722]
	TIME [epoch: 11.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11043901073655354		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.11043901073655354 | validation: 0.09449210632210024]
	TIME [epoch: 11.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0933895686894936		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.0933895686894936 | validation: 0.09022051198458961]
	TIME [epoch: 11.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08519689211123338		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.08519689211123338 | validation: 0.09693334624288631]
	TIME [epoch: 11.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0802056205907975		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.0802056205907975 | validation: 0.09099785637144152]
	TIME [epoch: 11.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08508197384664326		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.08508197384664326 | validation: 0.09273643830356504]
	TIME [epoch: 11.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09550309008003166		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.09550309008003166 | validation: 0.09639524089250266]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09312562457868934		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.09312562457868934 | validation: 0.10899827820933958]
	TIME [epoch: 11.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10057584874123575		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.10057584874123575 | validation: 0.11064484264061143]
	TIME [epoch: 11.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09629407189533354		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.09629407189533354 | validation: 0.09785595714353583]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09197222270055909		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.09197222270055909 | validation: 0.10153226938218618]
	TIME [epoch: 11.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08745566299750979		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.08745566299750979 | validation: 0.08749148218067893]
	TIME [epoch: 11.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07561173849052102		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.07561173849052102 | validation: 0.08313276129350136]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_1056.pth
	Model improved!!!
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07623725045900748		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.07623725045900748 | validation: 0.08846552430924494]
	TIME [epoch: 11.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0729905564622113		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.0729905564622113 | validation: 0.09278721171874242]
	TIME [epoch: 11.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07399524686377718		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.07399524686377718 | validation: 0.0867850749724121]
	TIME [epoch: 11.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07473397231821766		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.07473397231821766 | validation: 0.08864768619221415]
	TIME [epoch: 11.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08312063037127251		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.08312063037127251 | validation: 0.10291053749322066]
	TIME [epoch: 11.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08920294009056431		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.08920294009056431 | validation: 0.10157127119178101]
	TIME [epoch: 11.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08358765562768068		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.08358765562768068 | validation: 0.09506131153122852]
	TIME [epoch: 11.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08680521503710555		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.08680521503710555 | validation: 0.10092594314273598]
	TIME [epoch: 11.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0872644869155701		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.0872644869155701 | validation: 0.0799947590889851]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_1065.pth
	Model improved!!!
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07714606388866754		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.07714606388866754 | validation: 0.08414768568886155]
	TIME [epoch: 11.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08342622015653865		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.08342622015653865 | validation: 0.10546504331637671]
	TIME [epoch: 11.5 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08895108833372446		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.08895108833372446 | validation: 0.09180082221249798]
	TIME [epoch: 11.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0751669639078562		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.0751669639078562 | validation: 0.09011033014092383]
	TIME [epoch: 11.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07661742617810856		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.07661742617810856 | validation: 0.09055657297887168]
	TIME [epoch: 11.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07325427283179317		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.07325427283179317 | validation: 0.08094531815408923]
	TIME [epoch: 11.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07764703568971705		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.07764703568971705 | validation: 0.09122466387267114]
	TIME [epoch: 11.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07604462165197658		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.07604462165197658 | validation: 0.0799493029517743]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_1073.pth
	Model improved!!!
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07517682534077282		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.07517682534077282 | validation: 0.08686907367598554]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07630528298096716		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.07630528298096716 | validation: 0.09295276260813637]
	TIME [epoch: 11.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0756478566590841		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.0756478566590841 | validation: 0.08038598894350624]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07344660721986157		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.07344660721986157 | validation: 0.08668466844448432]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07373473561947064		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.07373473561947064 | validation: 0.08363433658256178]
	TIME [epoch: 11.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07214561420942073		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.07214561420942073 | validation: 0.08705390694050212]
	TIME [epoch: 11.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07671194126103603		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.07671194126103603 | validation: 0.08579042154269616]
	TIME [epoch: 11.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08176835269992576		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.08176835269992576 | validation: 0.08286278578251607]
	TIME [epoch: 11.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08304503717137121		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.08304503717137121 | validation: 0.09477838336499424]
	TIME [epoch: 11.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08144978893179106		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.08144978893179106 | validation: 0.09212897912662277]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07556454302267113		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.07556454302267113 | validation: 0.08891393547227266]
	TIME [epoch: 11.5 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07844579685473689		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.07844579685473689 | validation: 0.08859725260108263]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08269248696708603		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.08269248696708603 | validation: 0.10335002348340981]
	TIME [epoch: 11.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09117789791929745		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.09117789791929745 | validation: 0.10121972783163603]
	TIME [epoch: 11.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08544027124663123		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.08544027124663123 | validation: 0.10751354004395972]
	TIME [epoch: 11.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09279039946922556		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.09279039946922556 | validation: 0.12061771202520082]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09839803786765024		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.09839803786765024 | validation: 0.12817708212241555]
	TIME [epoch: 11.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12703603277516218		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.12703603277516218 | validation: 0.13573132584823616]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1179048255055016		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.1179048255055016 | validation: 0.12042075097014486]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09004612998709746		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.09004612998709746 | validation: 0.10034616785419065]
	TIME [epoch: 11.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09395033642518556		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.09395033642518556 | validation: 0.10760700593937099]
	TIME [epoch: 11.5 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09186037850064929		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.09186037850064929 | validation: 0.11017459266295189]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08435663867883791		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.08435663867883791 | validation: 0.09684027889128956]
	TIME [epoch: 11.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07889081364362252		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.07889081364362252 | validation: 0.09686165115243599]
	TIME [epoch: 11.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0780094392134422		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.0780094392134422 | validation: 0.09552085963677684]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07869152935328697		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.07869152935328697 | validation: 0.10532786599803672]
	TIME [epoch: 11.5 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10696666553465281		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.10696666553465281 | validation: 0.14995551786026995]
	TIME [epoch: 11.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12594747849746885		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.12594747849746885 | validation: 0.11464687463875968]
	TIME [epoch: 11.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.098715752063372		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.098715752063372 | validation: 0.11817729350919612]
	TIME [epoch: 11.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09581313993631588		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.09581313993631588 | validation: 0.10775879203346697]
	TIME [epoch: 11.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08592943243863087		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.08592943243863087 | validation: 0.0922174955824615]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07675658078567314		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.07675658078567314 | validation: 0.08532882374421505]
	TIME [epoch: 11.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07500296449331499		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.07500296449331499 | validation: 0.09839304778931418]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08166229322124458		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.08166229322124458 | validation: 0.09685766215658646]
	TIME [epoch: 11.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08236995003770535		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.08236995003770535 | validation: 0.0964819446796601]
	TIME [epoch: 11.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0737385196766934		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.0737385196766934 | validation: 0.08765681900147473]
	TIME [epoch: 11.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07622178695419118		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.07622178695419118 | validation: 0.09271653341268817]
	TIME [epoch: 11.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07081332743328057		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.07081332743328057 | validation: 0.07914908310615477]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_1111.pth
	Model improved!!!
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07595253857769844		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.07595253857769844 | validation: 0.09159971577686492]
	TIME [epoch: 11.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08040325804022647		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.08040325804022647 | validation: 0.09457611850992781]
	TIME [epoch: 11.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07671946136385768		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.07671946136385768 | validation: 0.08780187549979607]
	TIME [epoch: 11.5 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07228037532376816		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.07228037532376816 | validation: 0.08724613246094091]
	TIME [epoch: 11.5 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0707208973367962		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.0707208973367962 | validation: 0.08537478715686783]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07621770609324247		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.07621770609324247 | validation: 0.08642785460607329]
	TIME [epoch: 11.5 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07047909908547725		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.07047909908547725 | validation: 0.08710298417670048]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07097493600993986		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.07097493600993986 | validation: 0.0858622535690592]
	TIME [epoch: 11.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07622650278062347		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.07622650278062347 | validation: 0.09327409832946552]
	TIME [epoch: 11.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0764706730004095		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.0764706730004095 | validation: 0.08601440741157017]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07895694076148158		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.07895694076148158 | validation: 0.0895291129788468]
	TIME [epoch: 11.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07421490207285397		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.07421490207285397 | validation: 0.08946535831022619]
	TIME [epoch: 11.5 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0709800470044399		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.0709800470044399 | validation: 0.08964713320469113]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07843866166097144		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.07843866166097144 | validation: 0.09104097945224837]
	TIME [epoch: 11.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08804467963494066		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.08804467963494066 | validation: 0.10629943534018406]
	TIME [epoch: 11.5 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09030089770866498		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.09030089770866498 | validation: 0.10291619272021828]
	TIME [epoch: 11.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08893114544451061		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.08893114544451061 | validation: 0.09893431497202493]
	TIME [epoch: 11.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09087554199290998		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.09087554199290998 | validation: 0.099827272788711]
	TIME [epoch: 11.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08277290944304341		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.08277290944304341 | validation: 0.09848481449458568]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08828675907119155		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.08828675907119155 | validation: 0.10151947020540035]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08280547038986484		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.08280547038986484 | validation: 0.10475505033855846]
	TIME [epoch: 11.5 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08553677516168257		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.08553677516168257 | validation: 0.08651626372841686]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07945840167779433		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.07945840167779433 | validation: 0.08636104743804371]
	TIME [epoch: 11.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07864849468903634		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.07864849468903634 | validation: 0.09781209263730245]
	TIME [epoch: 11.5 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07523057897092503		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.07523057897092503 | validation: 0.09338419998569536]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07194303952764769		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.07194303952764769 | validation: 0.08345634967170533]
	TIME [epoch: 11.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07231656140558594		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.07231656140558594 | validation: 0.09725226129701536]
	TIME [epoch: 11.5 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07592120746310549		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.07592120746310549 | validation: 0.08446805959978254]
	TIME [epoch: 11.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07394791303011035		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.07394791303011035 | validation: 0.08997334139179212]
	TIME [epoch: 11.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07888288914873143		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.07888288914873143 | validation: 0.09245275550365184]
	TIME [epoch: 11.5 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07878631814942766		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.07878631814942766 | validation: 0.09434033002712473]
	TIME [epoch: 11.5 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07837178429955956		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.07837178429955956 | validation: 0.08937466204061562]
	TIME [epoch: 11.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07484177722177987		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.07484177722177987 | validation: 0.09164134894083407]
	TIME [epoch: 11.5 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07886540566530081		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.07886540566530081 | validation: 0.09883433427319523]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08065130500294697		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.08065130500294697 | validation: 0.09301773124109687]
	TIME [epoch: 11.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07913380899097212		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.07913380899097212 | validation: 0.08866230183510887]
	TIME [epoch: 11.5 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07533070002567327		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.07533070002567327 | validation: 0.08469210128831424]
	TIME [epoch: 11.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07277311008258011		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.07277311008258011 | validation: 0.08810282978412357]
	TIME [epoch: 11.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0744443951346366		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.0744443951346366 | validation: 0.09088098450144357]
	TIME [epoch: 11.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06853354196477864		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.06853354196477864 | validation: 0.08877017713110384]
	TIME [epoch: 11.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06957182278852847		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.06957182278852847 | validation: 0.08077362895315904]
	TIME [epoch: 11.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07280295861464117		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.07280295861464117 | validation: 0.08920703721065237]
	TIME [epoch: 11.5 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07832487838373844		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.07832487838373844 | validation: 0.09670658650935986]
	TIME [epoch: 11.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08600488970004941		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.08600488970004941 | validation: 0.09208593103648909]
	TIME [epoch: 11.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07520315979400158		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.07520315979400158 | validation: 0.08631687885131058]
	TIME [epoch: 11.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07137545281002192		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.07137545281002192 | validation: 0.09064385729656341]
	TIME [epoch: 11.5 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07400668072123535		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.07400668072123535 | validation: 0.09968609465108243]
	TIME [epoch: 11.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07750450687052976		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.07750450687052976 | validation: 0.07757621859727612]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_1159.pth
	Model improved!!!
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06729168543763053		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.06729168543763053 | validation: 0.08132894750421758]
	TIME [epoch: 11.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0671679195407533		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.0671679195407533 | validation: 0.08049907333412312]
	TIME [epoch: 11.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06585428481016255		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.06585428481016255 | validation: 0.08513885048247208]
	TIME [epoch: 11.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06858818941366361		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.06858818941366361 | validation: 0.08077016476184434]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06912544452717855		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.06912544452717855 | validation: 0.07199062883842426]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_1164.pth
	Model improved!!!
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06559212814909009		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.06559212814909009 | validation: 0.08127817790169144]
	TIME [epoch: 11.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06564755750754968		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.06564755750754968 | validation: 0.08463629585320366]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06952981456645362		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.06952981456645362 | validation: 0.08105080297361082]
	TIME [epoch: 11.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06690757608863236		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.06690757608863236 | validation: 0.08420043043331951]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07239917070005407		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.07239917070005407 | validation: 0.07454959810768431]
	TIME [epoch: 11.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07317088759988884		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.07317088759988884 | validation: 0.08273204441808861]
	TIME [epoch: 11.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06934128688482241		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.06934128688482241 | validation: 0.07479408141045975]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06795740650792724		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.06795740650792724 | validation: 0.08200725098864062]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06935412700065552		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.06935412700065552 | validation: 0.07721259549586561]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06568467190189856		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.06568467190189856 | validation: 0.06533281371056218]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_1174.pth
	Model improved!!!
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06695359642237575		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.06695359642237575 | validation: 0.09423308629408615]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07273260792978975		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.07273260792978975 | validation: 0.08729470338115594]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06947672010272427		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.06947672010272427 | validation: 0.0796758085575883]
	TIME [epoch: 11.5 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0675444280046926		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.0675444280046926 | validation: 0.07851198071812766]
	TIME [epoch: 11.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06886277414704711		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.06886277414704711 | validation: 0.08301019723722963]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07256977755339465		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.07256977755339465 | validation: 0.0822408129669558]
	TIME [epoch: 11.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06978560398851638		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.06978560398851638 | validation: 0.08385472067793312]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07005638150343504		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.07005638150343504 | validation: 0.09081524071883561]
	TIME [epoch: 11.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07071481651969738		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.07071481651969738 | validation: 0.08708324261392424]
	TIME [epoch: 11.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07534154418768069		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.07534154418768069 | validation: 0.08600240773702575]
	TIME [epoch: 11.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07427066004756933		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.07427066004756933 | validation: 0.09112672514926493]
	TIME [epoch: 11.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07128884315240495		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.07128884315240495 | validation: 0.08215236530204041]
	TIME [epoch: 11.5 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0695081273954786		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.0695081273954786 | validation: 0.07998676818130476]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06714058954457586		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.06714058954457586 | validation: 0.08231753016042]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06963066573817074		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.06963066573817074 | validation: 0.08373105531479613]
	TIME [epoch: 11.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0683463450845153		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.0683463450845153 | validation: 0.07918289416353437]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0680435727552447		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.0680435727552447 | validation: 0.07929073635956144]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06819519787873472		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.06819519787873472 | validation: 0.08790809736364272]
	TIME [epoch: 11.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06741742654322469		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.06741742654322469 | validation: 0.0796464372953341]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06938100802346579		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.06938100802346579 | validation: 0.07557177432037217]
	TIME [epoch: 11.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0707892957586867		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.0707892957586867 | validation: 0.08130958088055312]
	TIME [epoch: 11.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07080854252295025		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.07080854252295025 | validation: 0.08018509957039566]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06734305123439423		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.06734305123439423 | validation: 0.08335549471532223]
	TIME [epoch: 11.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07182777777763343		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.07182777777763343 | validation: 0.07902869094310672]
	TIME [epoch: 11.5 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.070726399639445		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.070726399639445 | validation: 0.07463392319062896]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07167352335772299		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.07167352335772299 | validation: 0.08502242802911573]
	TIME [epoch: 11.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07792620976810213		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.07792620976810213 | validation: 0.07559235767234888]
	TIME [epoch: 11.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07477806811148502		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.07477806811148502 | validation: 0.08338539603747736]
	TIME [epoch: 11.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0747533456554153		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.0747533456554153 | validation: 0.08585611676524142]
	TIME [epoch: 11.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07666295125078147		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.07666295125078147 | validation: 0.100770936889239]
	TIME [epoch: 11.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0829755340731014		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.0829755340731014 | validation: 0.08678055826567826]
	TIME [epoch: 11.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07490833871853177		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.07490833871853177 | validation: 0.09399537162029077]
	TIME [epoch: 11.5 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07484580752833894		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.07484580752833894 | validation: 0.08452080083406413]
	TIME [epoch: 11.5 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07639448541401864		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.07639448541401864 | validation: 0.08481222988758574]
	TIME [epoch: 11.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07268408792771956		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.07268408792771956 | validation: 0.07826272851861699]
	TIME [epoch: 11.5 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06695848319046858		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.06695848319046858 | validation: 0.07147638663048593]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0681486422088806		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.0681486422088806 | validation: 0.08190080495298592]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06596232943472213		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.06596232943472213 | validation: 0.0748978309679542]
	TIME [epoch: 11.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06808393271647262		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.06808393271647262 | validation: 0.08192597027504907]
	TIME [epoch: 11.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06356568091577061		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.06356568091577061 | validation: 0.07808612768813743]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06758734997236471		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.06758734997236471 | validation: 0.0788931079327016]
	TIME [epoch: 11.5 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06268206919958934		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.06268206919958934 | validation: 0.08383655316542861]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06458129571413185		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.06458129571413185 | validation: 0.08768738231021832]
	TIME [epoch: 11.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06529954030000505		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.06529954030000505 | validation: 0.08006854185691097]
	TIME [epoch: 11.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06775566060131016		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.06775566060131016 | validation: 0.08550591709311484]
	TIME [epoch: 11.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06631033158737887		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.06631033158737887 | validation: 0.07469412760457671]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0667606053233851		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.0667606053233851 | validation: 0.07504493109969176]
	TIME [epoch: 11.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06279207954324087		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.06279207954324087 | validation: 0.07142538914708098]
	TIME [epoch: 11.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06925215773508794		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.06925215773508794 | validation: 0.0809111902492721]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07188172070895349		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.07188172070895349 | validation: 0.08469682848897783]
	TIME [epoch: 11.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0714636173911816		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.0714636173911816 | validation: 0.08921164997781732]
	TIME [epoch: 11.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08114264276796695		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.08114264276796695 | validation: 0.095380857204321]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08403424987062505		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.08403424987062505 | validation: 0.093184370311244]
	TIME [epoch: 11.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07624217745764905		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.07624217745764905 | validation: 0.07701298050322188]
	TIME [epoch: 11.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06847001972690801		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.06847001972690801 | validation: 0.08025405087338378]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06411411852612194		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.06411411852612194 | validation: 0.08446608561502844]
	TIME [epoch: 11.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06274241153000155		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.06274241153000155 | validation: 0.07901066875635189]
	TIME [epoch: 11.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07230025707016069		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.07230025707016069 | validation: 0.0849635825659932]
	TIME [epoch: 11.5 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06710516828101701		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.06710516828101701 | validation: 0.08316777658220632]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06716625202893049		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.06716625202893049 | validation: 0.07137833894866341]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06458267507130333		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.06458267507130333 | validation: 0.08374468612670015]
	TIME [epoch: 11.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06672736472983157		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.06672736472983157 | validation: 0.08346942829954047]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0637542096065509		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.0637542096065509 | validation: 0.07814576556725286]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06489017700972667		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.06489017700972667 | validation: 0.08645938004487232]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06734163975134087		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.06734163975134087 | validation: 0.08385480299945057]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06526333626821496		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.06526333626821496 | validation: 0.08132974100152116]
	TIME [epoch: 11.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06759257606493187		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.06759257606493187 | validation: 0.08282863489454487]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06506707446301119		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.06506707446301119 | validation: 0.08639300407621563]
	TIME [epoch: 11.5 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0682826900396209		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.0682826900396209 | validation: 0.08962304509092228]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07724508608351045		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.07724508608351045 | validation: 0.10249337412617653]
	TIME [epoch: 11.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07093698865639092		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.07093698865639092 | validation: 0.0713576918308999]
	TIME [epoch: 11.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061393340387363146		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.061393340387363146 | validation: 0.07591041673479085]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06442310605138182		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.06442310605138182 | validation: 0.07420003930987148]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06385387714722533		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.06385387714722533 | validation: 0.0797811522828821]
	TIME [epoch: 11.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06437007667085068		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.06437007667085068 | validation: 0.08307119110090494]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06555838770757648		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.06555838770757648 | validation: 0.07387092502819466]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06158823099590238		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.06158823099590238 | validation: 0.07013736145774811]
	TIME [epoch: 11.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06375208881305926		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.06375208881305926 | validation: 0.08178429457933838]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06633292251625039		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.06633292251625039 | validation: 0.08622084604767664]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06447042765433947		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.06447042765433947 | validation: 0.07810697295716262]
	TIME [epoch: 11.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06494596489762178		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.06494596489762178 | validation: 0.07004481797871838]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06435713884471207		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.06435713884471207 | validation: 0.0757612839580256]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06526591514404638		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.06526591514404638 | validation: 0.06980027550720325]
	TIME [epoch: 11.5 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06482214856231733		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.06482214856231733 | validation: 0.0770070569550838]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06463411969552596		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.06463411969552596 | validation: 0.07990801934809989]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07154956266120185		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.07154956266120185 | validation: 0.07766688261085296]
	TIME [epoch: 11.5 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07077905367763138		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.07077905367763138 | validation: 0.09970392211663008]
	TIME [epoch: 11.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07325040682709016		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.07325040682709016 | validation: 0.08374773012317224]
	TIME [epoch: 11.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0681552054205964		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.0681552054205964 | validation: 0.08196852225778532]
	TIME [epoch: 11.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06676354456500663		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.06676354456500663 | validation: 0.07627226140679377]
	TIME [epoch: 11.5 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06560570600861694		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.06560570600861694 | validation: 0.08080902764396296]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0629244250147297		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.0629244250147297 | validation: 0.08453109523009059]
	TIME [epoch: 11.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06013605829237531		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.06013605829237531 | validation: 0.07651955938228681]
	TIME [epoch: 11.5 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06279274722128662		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.06279274722128662 | validation: 0.07923797133912543]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06589904962958042		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.06589904962958042 | validation: 0.08131118820837681]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06623574634166839		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.06623574634166839 | validation: 0.07353777732657392]
	TIME [epoch: 11.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06891550640018816		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.06891550640018816 | validation: 0.0735942844350144]
	TIME [epoch: 11.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06518343365491847		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.06518343365491847 | validation: 0.07328281969591587]
	TIME [epoch: 11.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0681983478447366		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.0681983478447366 | validation: 0.07344624368472029]
	TIME [epoch: 11.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.065574488981912		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.065574488981912 | validation: 0.08234973819178588]
	TIME [epoch: 11.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0662558370718035		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.0662558370718035 | validation: 0.07514886283712277]
	TIME [epoch: 11.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06899609936061556		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.06899609936061556 | validation: 0.0848601320482195]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06751487815056717		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.06751487815056717 | validation: 0.0807566659162146]
	TIME [epoch: 11.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06862499193844292		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.06862499193844292 | validation: 0.08880391027657977]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07272425939319394		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.07272425939319394 | validation: 0.08097133231122676]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06402349078033907		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.06402349078033907 | validation: 0.0729380761076959]
	TIME [epoch: 11.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061055966887831034		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.061055966887831034 | validation: 0.08267390524296793]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06624541388550335		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.06624541388550335 | validation: 0.07883877913806073]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06711813707314351		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.06711813707314351 | validation: 0.07506119938426867]
	TIME [epoch: 11.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06407888413173243		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.06407888413173243 | validation: 0.07846448478339824]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06392310383913767		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.06392310383913767 | validation: 0.07657531386162221]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06501204887488019		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.06501204887488019 | validation: 0.07787214736348014]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06844614122636739		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.06844614122636739 | validation: 0.07924647639731021]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06479479585668886		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.06479479585668886 | validation: 0.07962975645784133]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06327123482550366		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.06327123482550366 | validation: 0.07406531222045667]
	TIME [epoch: 11.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06337083654506113		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.06337083654506113 | validation: 0.07260813397366206]
	TIME [epoch: 11.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06408916353448582		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.06408916353448582 | validation: 0.07687876278649818]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06619703082266525		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.06619703082266525 | validation: 0.08106618471879579]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06509015931034348		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.06509015931034348 | validation: 0.07291767026873683]
	TIME [epoch: 11.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06387873056059437		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.06387873056059437 | validation: 0.0742769064367517]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0680125218229837		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.0680125218229837 | validation: 0.07738770705978715]
	TIME [epoch: 11.5 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06863341738518469		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.06863341738518469 | validation: 0.07626783147888683]
	TIME [epoch: 11.5 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06791220308965859		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.06791220308965859 | validation: 0.07880411777359232]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0638442952509014		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.0638442952509014 | validation: 0.07977535667280754]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06777314621832653		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.06777314621832653 | validation: 0.07846995762353981]
	TIME [epoch: 11.5 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061663307420601055		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.061663307420601055 | validation: 0.07659388624131311]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06446375066094273		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.06446375066094273 | validation: 0.06977891645417658]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07132578817821764		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.07132578817821764 | validation: 0.07927339236516512]
	TIME [epoch: 11.5 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06909782528520614		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.06909782528520614 | validation: 0.07673700414091626]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06830676363139424		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.06830676363139424 | validation: 0.07965456504941316]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06528088304351418		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.06528088304351418 | validation: 0.07934687496186676]
	TIME [epoch: 11.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06486076138729768		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.06486076138729768 | validation: 0.0838948872274893]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0625157435895418		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.0625157435895418 | validation: 0.08294877446875593]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06570874618802268		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.06570874618802268 | validation: 0.07569113596880313]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06750750857199952		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.06750750857199952 | validation: 0.07514803688490806]
	TIME [epoch: 11.5 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06525343542399234		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.06525343542399234 | validation: 0.07140104792265528]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06281278589822961		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.06281278589822961 | validation: 0.07635469589251385]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06654708543240234		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.06654708543240234 | validation: 0.07553123804005848]
	TIME [epoch: 11.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06388182271531302		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.06388182271531302 | validation: 0.0794655536636595]
	TIME [epoch: 11.5 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06717682684024369		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.06717682684024369 | validation: 0.07041758353941881]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06386880947621613		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.06386880947621613 | validation: 0.07253751433214518]
	TIME [epoch: 11.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06556035282105668		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.06556035282105668 | validation: 0.07760657339886753]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0650688324184758		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.0650688324184758 | validation: 0.08610044710453782]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0676675035123516		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.0676675035123516 | validation: 0.08689940945978386]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06581648180541803		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.06581648180541803 | validation: 0.07401922781895341]
	TIME [epoch: 11.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.066863898262791		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.066863898262791 | validation: 0.07902256382063237]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0682701559895626		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.0682701559895626 | validation: 0.08008558227128695]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06574631492676189		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.06574631492676189 | validation: 0.08503280572626695]
	TIME [epoch: 11.5 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07081840023165586		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.07081840023165586 | validation: 0.08234522606981365]
	TIME [epoch: 11.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06858154395631272		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.06858154395631272 | validation: 0.08552836281956852]
	TIME [epoch: 11.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06978259450374333		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.06978259450374333 | validation: 0.0860821126260603]
	TIME [epoch: 11.5 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07038971232074714		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.07038971232074714 | validation: 0.08158306285754748]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06820937854557954		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.06820937854557954 | validation: 0.08263700873444309]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0662681256499759		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.0662681256499759 | validation: 0.06965204024249981]
	TIME [epoch: 11.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06416370796717612		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.06416370796717612 | validation: 0.07152066715354369]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06694860799088395		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.06694860799088395 | validation: 0.07515283726928976]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06361581321524395		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.06361581321524395 | validation: 0.06989782073477724]
	TIME [epoch: 11.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06406835478282183		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.06406835478282183 | validation: 0.07875145781741615]
	TIME [epoch: 11.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06389571899920375		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.06389571899920375 | validation: 0.07426360187266255]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06595218027846783		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.06595218027846783 | validation: 0.08381296464196009]
	TIME [epoch: 11.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0689463257639179		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.0689463257639179 | validation: 0.07668764283455501]
	TIME [epoch: 11.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062103785238864805		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.062103785238864805 | validation: 0.08514629228677643]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06390669318084873		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.06390669318084873 | validation: 0.07879557271111982]
	TIME [epoch: 11.5 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06619636458260272		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.06619636458260272 | validation: 0.08521635968306]
	TIME [epoch: 11.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06603218454476431		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.06603218454476431 | validation: 0.0735101199855195]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06330876114719886		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.06330876114719886 | validation: 0.06918255857590401]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061988918601381754		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.061988918601381754 | validation: 0.07885515826258076]
	TIME [epoch: 11.5 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06511626496705325		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.06511626496705325 | validation: 0.08354694848769632]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06319285241405256		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.06319285241405256 | validation: 0.08199900724647906]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06351501261554666		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.06351501261554666 | validation: 0.07488462349297859]
	TIME [epoch: 11.5 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06467096321225785		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.06467096321225785 | validation: 0.07731625345156369]
	TIME [epoch: 11.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0669888226599741		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.0669888226599741 | validation: 0.08249506143105022]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06465946314987837		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.06465946314987837 | validation: 0.07795621642527994]
	TIME [epoch: 11.5 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06474157296639449		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.06474157296639449 | validation: 0.07762359086977248]
	TIME [epoch: 11.5 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06671674824716188		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.06671674824716188 | validation: 0.07358938618489382]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05984621840761019		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.05984621840761019 | validation: 0.06945799166783113]
	TIME [epoch: 11.5 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06372923228225236		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.06372923228225236 | validation: 0.07598214570914871]
	TIME [epoch: 11.5 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06593024614601886		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.06593024614601886 | validation: 0.07696093271054291]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06536802646558552		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.06536802646558552 | validation: 0.07560954720458771]
	TIME [epoch: 11.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06602406521873687		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.06602406521873687 | validation: 0.07837454251325923]
	TIME [epoch: 11.5 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06529109786143368		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.06529109786143368 | validation: 0.07275488719864337]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06636124865188954		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.06636124865188954 | validation: 0.08362895790527695]
	TIME [epoch: 11.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06883235274557342		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.06883235274557342 | validation: 0.07491994105290556]
	TIME [epoch: 11.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06518757540389516		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.06518757540389516 | validation: 0.0757734475603012]
	TIME [epoch: 11.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07018488531196265		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.07018488531196265 | validation: 0.0808603435993628]
	TIME [epoch: 11.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06716237086485259		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.06716237086485259 | validation: 0.07559545744241222]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06352948307278226		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.06352948307278226 | validation: 0.0829302331895314]
	TIME [epoch: 11.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06555904148852217		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.06555904148852217 | validation: 0.07945407455899864]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061640334270004885		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.061640334270004885 | validation: 0.07676609562931376]
	TIME [epoch: 11.5 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0618089685473706		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.0618089685473706 | validation: 0.08325136794718034]
	TIME [epoch: 11.5 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06502739169483351		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.06502739169483351 | validation: 0.08374765492130007]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06865479679436841		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.06865479679436841 | validation: 0.08610344365397168]
	TIME [epoch: 11.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0686948528248217		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.0686948528248217 | validation: 0.08019693019325498]
	TIME [epoch: 11.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0647220788721323		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.0647220788721323 | validation: 0.07020045504482213]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0673758082122494		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.0673758082122494 | validation: 0.08097489764352092]
	TIME [epoch: 11.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0659349433961154		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.0659349433961154 | validation: 0.0784601233756249]
	TIME [epoch: 11.5 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06690622507914738		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.06690622507914738 | validation: 0.08377831678584771]
	TIME [epoch: 11.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06630950606258715		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.06630950606258715 | validation: 0.07581355882572034]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06563020559535705		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.06563020559535705 | validation: 0.08087518675723258]
	TIME [epoch: 11.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06508192294281662		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.06508192294281662 | validation: 0.07827780192255906]
	TIME [epoch: 11.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06257153156081033		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.06257153156081033 | validation: 0.07331791891581775]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06634742634093427		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.06634742634093427 | validation: 0.07965441543626044]
	TIME [epoch: 11.5 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0635487139544417		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.0635487139544417 | validation: 0.077482788233428]
	TIME [epoch: 11.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06947648445018664		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.06947648445018664 | validation: 0.08063205683598236]
	TIME [epoch: 11.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06851991914863818		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.06851991914863818 | validation: 0.07264209105649098]
	TIME [epoch: 11.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06722386288015933		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.06722386288015933 | validation: 0.07607898776846962]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06366958062626166		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.06366958062626166 | validation: 0.07232788105232282]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06959071409588717		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.06959071409588717 | validation: 0.06795049822435308]
	TIME [epoch: 11.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06780409706980994		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.06780409706980994 | validation: 0.07175063404707578]
	TIME [epoch: 11.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06593746418639386		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.06593746418639386 | validation: 0.07520740937997276]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06549887531292256		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.06549887531292256 | validation: 0.08304744732555867]
	TIME [epoch: 11.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06872936763208568		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.06872936763208568 | validation: 0.07945032049125511]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06395166051910461		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.06395166051910461 | validation: 0.0805479397868096]
	TIME [epoch: 11.5 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06589027174689417		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.06589027174689417 | validation: 0.07419857113968688]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06756221050112517		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.06756221050112517 | validation: 0.08087829423631876]
	TIME [epoch: 11.5 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06708793660453649		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.06708793660453649 | validation: 0.06953983610253099]
	TIME [epoch: 11.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06671740742819385		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.06671740742819385 | validation: 0.07714584143170086]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0666032524075678		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.0666032524075678 | validation: 0.07508589229550167]
	TIME [epoch: 11.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06308418629709481		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.06308418629709481 | validation: 0.07439024372348152]
	TIME [epoch: 11.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06888033072386258		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.06888033072386258 | validation: 0.08787531991052584]
	TIME [epoch: 11.5 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06644933221703522		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.06644933221703522 | validation: 0.08630926193339114]
	TIME [epoch: 11.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06909626601240787		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.06909626601240787 | validation: 0.08609221030884079]
	TIME [epoch: 11.5 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07354154766293153		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.07354154766293153 | validation: 0.07864426833774729]
	TIME [epoch: 11.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06888532872056351		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.06888532872056351 | validation: 0.07736747112855825]
	TIME [epoch: 11.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07254821317270876		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.07254821317270876 | validation: 0.09259238732891754]
	TIME [epoch: 11.5 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06531571692445032		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.06531571692445032 | validation: 0.08439547267963114]
	TIME [epoch: 11.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06893191822921348		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.06893191822921348 | validation: 0.08555066845395772]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07219485842342929		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.07219485842342929 | validation: 0.07810890486860173]
	TIME [epoch: 11.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06822454282132377		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.06822454282132377 | validation: 0.08076544084110647]
	TIME [epoch: 11.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0730999662249614		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.0730999662249614 | validation: 0.08448561212307737]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06975011636284052		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.06975011636284052 | validation: 0.07941316640991047]
	TIME [epoch: 11.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07017916134164534		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.07017916134164534 | validation: 0.08146250799780638]
	TIME [epoch: 11.5 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0748520629134672		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.0748520629134672 | validation: 0.08133782297379068]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07203883233731692		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.07203883233731692 | validation: 0.08041743301099173]
	TIME [epoch: 11.5 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06963261446977081		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.06963261446977081 | validation: 0.07613518731651026]
	TIME [epoch: 11.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06932245171114873		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.06932245171114873 | validation: 0.08472649282325666]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07027547567129433		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.07027547567129433 | validation: 0.07490096607584398]
	TIME [epoch: 11.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07253289891034406		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.07253289891034406 | validation: 0.08736214668951905]
	TIME [epoch: 11.5 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07268166171217873		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.07268166171217873 | validation: 0.08304241498888726]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07237014588946392		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.07237014588946392 | validation: 0.09472383367531537]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.072390399719862		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.072390399719862 | validation: 0.0793250834149594]
	TIME [epoch: 11.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07056548099005333		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.07056548099005333 | validation: 0.08137396650095836]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0705373439377309		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.0705373439377309 | validation: 0.08213859388722805]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0724775130357216		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.0724775130357216 | validation: 0.07720597564146096]
	TIME [epoch: 11.5 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06789331878525379		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.06789331878525379 | validation: 0.08735246315282748]
	TIME [epoch: 11.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06304599078791953		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.06304599078791953 | validation: 0.08362776606531583]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.064518462241562		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.064518462241562 | validation: 0.081901859981284]
	TIME [epoch: 11.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06888568599528305		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.06888568599528305 | validation: 0.08531830926799151]
	TIME [epoch: 11.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0717515258669539		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.0717515258669539 | validation: 0.08329782505257306]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.069133893583304		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.069133893583304 | validation: 0.09084557761724173]
	TIME [epoch: 11.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07107507747043763		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.07107507747043763 | validation: 0.08797085464296579]
	TIME [epoch: 11.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07174322285864668		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.07174322285864668 | validation: 0.08314156737623943]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07229090078011685		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.07229090078011685 | validation: 0.08394722594378488]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07323181166837603		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.07323181166837603 | validation: 0.08465020664211582]
	TIME [epoch: 11.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06854044895594857		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.06854044895594857 | validation: 0.08737428405317271]
	TIME [epoch: 11.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06496061830157393		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.06496061830157393 | validation: 0.08708740384642406]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06784779935343294		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.06784779935343294 | validation: 0.08135226083306588]
	TIME [epoch: 11.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06787214621172952		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.06787214621172952 | validation: 0.0824675722955392]
	TIME [epoch: 11.5 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06698726226652846		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.06698726226652846 | validation: 0.0737826182488579]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06462857633536848		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.06462857633536848 | validation: 0.07853195737049448]
	TIME [epoch: 11.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06689162869356968		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.06689162869356968 | validation: 0.07722565506321898]
	TIME [epoch: 11.5 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06617301762130146		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.06617301762130146 | validation: 0.08917466628782648]
	TIME [epoch: 11.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06762206926771912		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.06762206926771912 | validation: 0.07965717075195278]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06801321792268687		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.06801321792268687 | validation: 0.09287285999409779]
	TIME [epoch: 11.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06725060790092481		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.06725060790092481 | validation: 0.08545818649254634]
	TIME [epoch: 11.5 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07241450872180305		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.07241450872180305 | validation: 0.08236213322908259]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07035555381520077		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.07035555381520077 | validation: 0.08854937558443673]
	TIME [epoch: 11.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07071663490103225		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.07071663490103225 | validation: 0.08267269995466797]
	TIME [epoch: 11.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07162061480333715		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.07162061480333715 | validation: 0.08315383784274691]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06806762621795087		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.06806762621795087 | validation: 0.08604446859374804]
	TIME [epoch: 11.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0670107786453237		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.0670107786453237 | validation: 0.08834267472610656]
	TIME [epoch: 11.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06774829958900747		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.06774829958900747 | validation: 0.07500198483858576]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06633910368735677		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.06633910368735677 | validation: 0.0728621071588997]
	TIME [epoch: 11.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06755887488141671		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.06755887488141671 | validation: 0.08322910219291815]
	TIME [epoch: 11.5 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0659701545635947		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.0659701545635947 | validation: 0.08177528372202048]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0684391569387911		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.0684391569387911 | validation: 0.08063769161931073]
	TIME [epoch: 11.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06666724261048923		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.06666724261048923 | validation: 0.08281143308450797]
	TIME [epoch: 11.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0641507284682255		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.0641507284682255 | validation: 0.08448957012134298]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06580303853148736		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.06580303853148736 | validation: 0.0844066075313027]
	TIME [epoch: 11.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06419154429109358		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.06419154429109358 | validation: 0.08231315386183458]
	TIME [epoch: 11.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06380110621400333		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.06380110621400333 | validation: 0.07801530095906654]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06744636823099659		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.06744636823099659 | validation: 0.08306777672528945]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06102287807846105		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.06102287807846105 | validation: 0.08315380583176502]
	TIME [epoch: 11.5 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0654281723046367		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.0654281723046367 | validation: 0.07955138444471102]
	TIME [epoch: 11.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06300387536250156		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.06300387536250156 | validation: 0.07720688547524938]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06445916225354117		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.06445916225354117 | validation: 0.08392213176482265]
	TIME [epoch: 11.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0701600712338942		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.0701600712338942 | validation: 0.07481768337602693]
	TIME [epoch: 11.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06569264582519713		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.06569264582519713 | validation: 0.0725520467503151]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06757037338451884		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.06757037338451884 | validation: 0.07767830043594778]
	TIME [epoch: 11.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06650061493285384		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.06650061493285384 | validation: 0.06997204497042839]
	TIME [epoch: 11.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06297359056176807		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.06297359056176807 | validation: 0.07769131006806451]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06711575410770798		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.06711575410770798 | validation: 0.08059240731700484]
	TIME [epoch: 11.5 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0701489627431038		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.0701489627431038 | validation: 0.0776328539471884]
	TIME [epoch: 11.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06682774510527485		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.06682774510527485 | validation: 0.08219506418344123]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07190048126159881		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.07190048126159881 | validation: 0.08282893855038741]
	TIME [epoch: 11.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06737109752688983		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.06737109752688983 | validation: 0.08267466783755137]
	TIME [epoch: 11.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06846088702625627		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.06846088702625627 | validation: 0.08083393878751767]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06612075354881455		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.06612075354881455 | validation: 0.07763596324259385]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07078246400291452		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.07078246400291452 | validation: 0.0866818648229665]
	TIME [epoch: 11.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0737620703549516		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.0737620703549516 | validation: 0.07718819447468171]
	TIME [epoch: 11.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07687839639727567		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.07687839639727567 | validation: 0.09341579127288771]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.076076657858796		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.076076657858796 | validation: 0.09234573366260947]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0733425584607572		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.0733425584607572 | validation: 0.08026598781715073]
	TIME [epoch: 11.5 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07230277303961338		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.07230277303961338 | validation: 0.08085530604429654]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0682988910997061		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.0682988910997061 | validation: 0.07856168236888197]
	TIME [epoch: 11.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0678635912713408		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.0678635912713408 | validation: 0.0856312870949089]
	TIME [epoch: 11.5 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07053669561427572		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.07053669561427572 | validation: 0.07754843318692536]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07022671708470891		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.07022671708470891 | validation: 0.0881134791930635]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07187440282268148		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.07187440282268148 | validation: 0.07821444559213733]
	TIME [epoch: 11.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0712736529571372		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.0712736529571372 | validation: 0.0903839553774677]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06893967123272024		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.06893967123272024 | validation: 0.07589670379842525]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07300174183358914		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.07300174183358914 | validation: 0.0725757343853143]
	TIME [epoch: 11.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0711565821615207		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.0711565821615207 | validation: 0.07932559023891568]
	TIME [epoch: 11.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07052668541267115		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.07052668541267115 | validation: 0.07380212847342228]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06602340534580041		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.06602340534580041 | validation: 0.08177202301823652]
	TIME [epoch: 11.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06692177108163302		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.06692177108163302 | validation: 0.08872084183583258]
	TIME [epoch: 11.5 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07157180426096545		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.07157180426096545 | validation: 0.07442298731859227]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06437002528921143		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.06437002528921143 | validation: 0.07537009208494964]
	TIME [epoch: 11.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06682370339429036		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.06682370339429036 | validation: 0.07998178554603819]
	TIME [epoch: 11.5 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06950185943186066		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.06950185943186066 | validation: 0.07947201628331867]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0688254412227801		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.0688254412227801 | validation: 0.07761639154725739]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07100482511769546		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.07100482511769546 | validation: 0.07005386298995077]
	TIME [epoch: 11.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07017164017618911		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.07017164017618911 | validation: 0.08550642945651767]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07003527282108875		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.07003527282108875 | validation: 0.09241299184163093]
	TIME [epoch: 11.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07200310298329772		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.07200310298329772 | validation: 0.08565611776048393]
	TIME [epoch: 11.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07254707287204568		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.07254707287204568 | validation: 0.07345107586158743]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07076085369108026		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.07076085369108026 | validation: 0.08482710496763218]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07254933478691018		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.07254933478691018 | validation: 0.09125655299926556]
	TIME [epoch: 11.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06815067790641023		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.06815067790641023 | validation: 0.07914278483484796]
	TIME [epoch: 11.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06667762090838628		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.06667762090838628 | validation: 0.07660566889975769]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06822859956203985		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.06822859956203985 | validation: 0.07899552099670616]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06614314657034638		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.06614314657034638 | validation: 0.08288604598719328]
	TIME [epoch: 11.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07115372881899884		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.07115372881899884 | validation: 0.0740695289397104]
	TIME [epoch: 11.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06841049992246655		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.06841049992246655 | validation: 0.07650884055990648]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.065884849512519		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.065884849512519 | validation: 0.07929137505187944]
	TIME [epoch: 11.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06278215666475634		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.06278215666475634 | validation: 0.08114541004556833]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06593644784767733		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.06593644784767733 | validation: 0.07365227539163507]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06284376421220052		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.06284376421220052 | validation: 0.07397082829200055]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06610717159411086		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.06610717159411086 | validation: 0.07863668106918169]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06852620905617397		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.06852620905617397 | validation: 0.08388259618753414]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06624523661900245		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.06624523661900245 | validation: 0.07989113471225752]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06765116391644557		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.06765116391644557 | validation: 0.08386403716798611]
	TIME [epoch: 11.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06594733284708784		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.06594733284708784 | validation: 0.07913302237734376]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0692797647734689		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.0692797647734689 | validation: 0.0762581325714355]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07053334490528572		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.07053334490528572 | validation: 0.0955167373888163]
	TIME [epoch: 11.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0730718007102599		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.0730718007102599 | validation: 0.08269826947723813]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06900422319459322		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.06900422319459322 | validation: 0.08333629289669249]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06624981157811304		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.06624981157811304 | validation: 0.0762551273977291]
	TIME [epoch: 11.5 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06542454310747924		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.06542454310747924 | validation: 0.07238558727057144]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06467268710820506		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.06467268710820506 | validation: 0.0761675236012945]
	TIME [epoch: 11.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06457352466293585		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.06457352466293585 | validation: 0.08196968914109147]
	TIME [epoch: 11.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06636135420718253		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.06636135420718253 | validation: 0.07950037448480864]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06748718455673994		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.06748718455673994 | validation: 0.0842699178672564]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06958484591120842		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.06958484591120842 | validation: 0.08247935519276405]
	TIME [epoch: 11.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06895798809480862		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.06895798809480862 | validation: 0.08127392862313063]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06878631259144906		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.06878631259144906 | validation: 0.07810541105849086]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07086978650321177		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.07086978650321177 | validation: 0.07581407051221926]
	TIME [epoch: 11.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06884110091175093		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.06884110091175093 | validation: 0.08261294316985504]
	TIME [epoch: 11.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06986771412632035		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.06986771412632035 | validation: 0.0722916494866366]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07384471709958655		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.07384471709958655 | validation: 0.0823958728252547]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06838723471184938		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.06838723471184938 | validation: 0.07987165977486137]
	TIME [epoch: 11.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06843451646852591		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.06843451646852591 | validation: 0.08125140875268164]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06799919103580201		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.06799919103580201 | validation: 0.0743256809286729]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07126379156926481		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.07126379156926481 | validation: 0.07174072572990306]
	TIME [epoch: 11.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06259984495376646		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.06259984495376646 | validation: 0.08453523743226626]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06409750763318818		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.06409750763318818 | validation: 0.07493198059188305]
	TIME [epoch: 11.5 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0678624284281899		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.0678624284281899 | validation: 0.08238683065265803]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06656223488147506		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.06656223488147506 | validation: 0.0736319231888195]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06378832948127325		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.06378832948127325 | validation: 0.07555487539926228]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06318144866557965		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.06318144866557965 | validation: 0.09132208097011739]
	TIME [epoch: 11.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06629918469201916		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.06629918469201916 | validation: 0.07596181697298607]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06687340430413836		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.06687340430413836 | validation: 0.07940288146956602]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06456080581704811		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.06456080581704811 | validation: 0.08076537022188532]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06157386776845894		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.06157386776845894 | validation: 0.07571262972853955]
	TIME [epoch: 11.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06584622581521818		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.06584622581521818 | validation: 0.07531789539514847]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06808674367734538		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.06808674367734538 | validation: 0.07553928082402102]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06395199779427956		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.06395199779427956 | validation: 0.0844414399958948]
	TIME [epoch: 11.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06290383397428724		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.06290383397428724 | validation: 0.0780609944961354]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06769415041364377		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.06769415041364377 | validation: 0.08058207610199744]
	TIME [epoch: 11.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0638900899626118		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.0638900899626118 | validation: 0.0782594422859358]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06199596891282379		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.06199596891282379 | validation: 0.07586118073734668]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06783466174092956		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.06783466174092956 | validation: 0.07921155236644795]
	TIME [epoch: 11.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06313985399358706		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.06313985399358706 | validation: 0.0812354170590367]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06585281699261458		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.06585281699261458 | validation: 0.08680768033942014]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062919723404189		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.062919723404189 | validation: 0.07017797606207904]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06520544161670379		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.06520544161670379 | validation: 0.08218178066808993]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06506150887108733		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.06506150887108733 | validation: 0.08261380510212268]
	TIME [epoch: 11.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06560636874432199		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.06560636874432199 | validation: 0.08252117126849864]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06031573099117343		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.06031573099117343 | validation: 0.08357629629881995]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06413999901309071		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.06413999901309071 | validation: 0.08204921026062208]
	TIME [epoch: 11.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06425997332200892		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.06425997332200892 | validation: 0.07453910627505547]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06669113216474032		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.06669113216474032 | validation: 0.08472965592989422]
	TIME [epoch: 11.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07025139137792688		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.07025139137792688 | validation: 0.07741050172777289]
	TIME [epoch: 11.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06453700283968572		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.06453700283968572 | validation: 0.08445043498860319]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06407494377233294		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.06407494377233294 | validation: 0.0799120697499888]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06365791463013912		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.06365791463013912 | validation: 0.08101108115168247]
	TIME [epoch: 11.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06630183357504024		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.06630183357504024 | validation: 0.07757324922363354]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06481606052561122		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.06481606052561122 | validation: 0.07938323865609564]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06979733320732863		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.06979733320732863 | validation: 0.08412625349898516]
	TIME [epoch: 11.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06818256604487569		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.06818256604487569 | validation: 0.0849121507499115]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07172099548268536		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.07172099548268536 | validation: 0.09018611384938767]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0712394189284733		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.0712394189284733 | validation: 0.07674464482910265]
	TIME [epoch: 11.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07782591945027267		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.07782591945027267 | validation: 0.09166592149522469]
	TIME [epoch: 11.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07597704424212941		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.07597704424212941 | validation: 0.08829395274513299]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07250372502537147		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.07250372502537147 | validation: 0.09076385605096011]
	TIME [epoch: 11.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07375545763389627		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.07375545763389627 | validation: 0.07953692649670074]
	TIME [epoch: 11.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06852724316642052		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.06852724316642052 | validation: 0.07908398469211073]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06900960204932385		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.06900960204932385 | validation: 0.08669537520287779]
	TIME [epoch: 11.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0692915318987764		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.0692915318987764 | validation: 0.08873772936393663]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06963935469362044		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.06963935469362044 | validation: 0.08622702512135617]
	TIME [epoch: 11.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06645551969233482		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.06645551969233482 | validation: 0.08001533042691664]
	TIME [epoch: 11.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06964700931694202		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.06964700931694202 | validation: 0.08758848973833656]
	TIME [epoch: 11.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06566090506832599		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.06566090506832599 | validation: 0.0854433673747571]
	TIME [epoch: 11.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0698551975795418		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.0698551975795418 | validation: 0.08790591630024182]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07169824747976822		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.07169824747976822 | validation: 0.08423060486941886]
	TIME [epoch: 11.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07508514065232948		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.07508514065232948 | validation: 0.07736472466825955]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06805771751841222		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.06805771751841222 | validation: 0.07259542595472304]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06695036658664011		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.06695036658664011 | validation: 0.08095343936813101]
	TIME [epoch: 11.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06863277330572266		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.06863277330572266 | validation: 0.0793888954042524]
	TIME [epoch: 11.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06664609083142099		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.06664609083142099 | validation: 0.08707509902801736]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06551548050607256		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.06551548050607256 | validation: 0.0764899897028154]
	TIME [epoch: 11.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0657378807128903		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.0657378807128903 | validation: 0.08128523574882296]
	TIME [epoch: 11.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0659991278669141		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.0659991278669141 | validation: 0.0845125156116486]
	TIME [epoch: 11.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06650491335198142		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.06650491335198142 | validation: 0.08220644003404332]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06993717220081036		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.06993717220081036 | validation: 0.07966027180584989]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06684027888516253		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.06684027888516253 | validation: 0.0788234015432273]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06417837214407082		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.06417837214407082 | validation: 0.08525256097849171]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06302284951438708		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.06302284951438708 | validation: 0.0828397961404551]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06695887734220507		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.06695887734220507 | validation: 0.0809391472276536]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0661734240140249		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.0661734240140249 | validation: 0.08145543919759232]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0648620745333025		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.0648620745333025 | validation: 0.08065390025452596]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.063784122154217		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.063784122154217 | validation: 0.07789177886706782]
	TIME [epoch: 11.5 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061038350541509884		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.061038350541509884 | validation: 0.08470735367430937]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06324662252296287		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.06324662252296287 | validation: 0.06727691645221916]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06360464803669519		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.06360464803669519 | validation: 0.06920614683752899]
	TIME [epoch: 11.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06614256134734736		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.06614256134734736 | validation: 0.0776666491864509]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06201290425275845		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.06201290425275845 | validation: 0.07375768277277985]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06499659362197124		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.06499659362197124 | validation: 0.08190969469789842]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06286102165225661		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.06286102165225661 | validation: 0.07015686630070223]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06361662042355973		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.06361662042355973 | validation: 0.08927514887613096]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06339907827970973		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.06339907827970973 | validation: 0.07503259770071077]
	TIME [epoch: 11.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06325544208439529		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.06325544208439529 | validation: 0.08537465581882424]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06517310735929964		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.06517310735929964 | validation: 0.07662867629369138]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06365082669221085		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.06365082669221085 | validation: 0.08228650634119587]
	TIME [epoch: 11.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06242597454115683		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.06242597454115683 | validation: 0.08552740189145858]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062470704845572336		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.062470704845572336 | validation: 0.07325593275709315]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061867683362728895		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.061867683362728895 | validation: 0.08004624030309306]
	TIME [epoch: 11.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06546116172112376		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.06546116172112376 | validation: 0.07863525368199058]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06643936002712338		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.06643936002712338 | validation: 0.08387946108892351]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06386905414690058		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.06386905414690058 | validation: 0.07387744269899989]
	TIME [epoch: 11.5 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06307939646722996		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.06307939646722996 | validation: 0.08484145541253639]
	TIME [epoch: 11.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06431847774468896		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.06431847774468896 | validation: 0.07844508913081502]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062147067474385684		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.062147067474385684 | validation: 0.08032088786006437]
	TIME [epoch: 11.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060609758705363816		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.060609758705363816 | validation: 0.08297727288883947]
	TIME [epoch: 11.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06516190728816035		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.06516190728816035 | validation: 0.08663430829833711]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06373759649285282		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.06373759649285282 | validation: 0.08295961197399525]
	TIME [epoch: 11.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06378115186165664		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.06378115186165664 | validation: 0.08015355561985814]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06278817520925688		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.06278817520925688 | validation: 0.08095000350747414]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06400596412228611		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.06400596412228611 | validation: 0.07571323243772182]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06636604271743586		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.06636604271743586 | validation: 0.08198791330351433]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0634620904337409		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.0634620904337409 | validation: 0.07980515778532882]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06452710214576725		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.06452710214576725 | validation: 0.07217179470591749]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06511286346090628		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.06511286346090628 | validation: 0.08010578814507571]
	TIME [epoch: 11.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06298150498796898		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.06298150498796898 | validation: 0.07893897288879892]
	TIME [epoch: 11.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06636467803172652		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.06636467803172652 | validation: 0.08293888837881201]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06125875740289709		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.06125875740289709 | validation: 0.07731884511665613]
	TIME [epoch: 11.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06259878021511728		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.06259878021511728 | validation: 0.08027167298811351]
	TIME [epoch: 11.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060314912892565374		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.060314912892565374 | validation: 0.07747449360800093]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058682812566883805		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.058682812566883805 | validation: 0.07790702696431129]
	TIME [epoch: 11.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06422877474044232		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.06422877474044232 | validation: 0.0729986565133591]
	TIME [epoch: 11.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06551046377464506		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.06551046377464506 | validation: 0.08349055496399448]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06195581369609454		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.06195581369609454 | validation: 0.07765362080804107]
	TIME [epoch: 11.5 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06244487791480916		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.06244487791480916 | validation: 0.0725884771681228]
	TIME [epoch: 11.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06377760147622785		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.06377760147622785 | validation: 0.07366334698765138]
	TIME [epoch: 11.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06261582855455189		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.06261582855455189 | validation: 0.08052887288471858]
	TIME [epoch: 11.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06547967559275193		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.06547967559275193 | validation: 0.08496778075838343]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059571280918487644		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.059571280918487644 | validation: 0.0675423841068727]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0625579354719685		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.0625579354719685 | validation: 0.0824847788422352]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06281226959833776		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.06281226959833776 | validation: 0.08405445582621081]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06168141028008085		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.06168141028008085 | validation: 0.0874689606012267]
	TIME [epoch: 11.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05886701159266719		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.05886701159266719 | validation: 0.08681400529264796]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06192183258551294		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.06192183258551294 | validation: 0.0768637508658562]
	TIME [epoch: 11.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06521131932981455		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.06521131932981455 | validation: 0.0704829245467151]
	TIME [epoch: 11.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06196010270500031		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.06196010270500031 | validation: 0.08106469412209506]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06250806468960306		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.06250806468960306 | validation: 0.07445606223566024]
	TIME [epoch: 11.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06245316551265226		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.06245316551265226 | validation: 0.07626315168795049]
	TIME [epoch: 11.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06420516735344425		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.06420516735344425 | validation: 0.0754056030392957]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06312676067394836		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.06312676067394836 | validation: 0.07728220883215292]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06304458856213238		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.06304458856213238 | validation: 0.0800001808722731]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061339178145143315		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.061339178145143315 | validation: 0.0754367337061735]
	TIME [epoch: 11.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0647143095647351		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.0647143095647351 | validation: 0.07597245656371804]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06331543349414824		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.06331543349414824 | validation: 0.08009453586791437]
	TIME [epoch: 11.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06212192437996979		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.06212192437996979 | validation: 0.07594071084410253]
	TIME [epoch: 11.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06294129323213177		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.06294129323213177 | validation: 0.06793090440405537]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06596967200014994		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.06596967200014994 | validation: 0.08131982137975893]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0631847918621863		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.0631847918621863 | validation: 0.0815538263794281]
	TIME [epoch: 11.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06279270291333776		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.06279270291333776 | validation: 0.08148128985151203]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06201993728986977		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.06201993728986977 | validation: 0.08207125013356778]
	TIME [epoch: 11.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06294887355807736		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.06294887355807736 | validation: 0.07783584422937256]
	TIME [epoch: 11.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06304540377559953		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.06304540377559953 | validation: 0.08672012775403562]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.063799131068882		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.063799131068882 | validation: 0.07742508030720605]
	TIME [epoch: 11.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06661075115299958		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.06661075115299958 | validation: 0.07094979347588033]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06237604873702693		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.06237604873702693 | validation: 0.08694903976177008]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06935586418633202		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.06935586418633202 | validation: 0.07855302638617243]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06131510054301676		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.06131510054301676 | validation: 0.07451240196504803]
	TIME [epoch: 11.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06338521471525944		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.06338521471525944 | validation: 0.0730868359870346]
	TIME [epoch: 11.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06334800644953144		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.06334800644953144 | validation: 0.06948317233428437]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06413679132947255		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.06413679132947255 | validation: 0.08242828605944379]
	TIME [epoch: 11.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06331765118693802		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.06331765118693802 | validation: 0.07520777395457459]
	TIME [epoch: 11.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06356673441746538		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.06356673441746538 | validation: 0.07549892071691586]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062270266959970524		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.062270266959970524 | validation: 0.07727919840996236]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06257434592692612		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.06257434592692612 | validation: 0.07587858480094077]
	TIME [epoch: 11.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06058626251727642		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.06058626251727642 | validation: 0.0710916360308443]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06089491712617033		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.06089491712617033 | validation: 0.0763885345476332]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06280686388182137		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.06280686388182137 | validation: 0.08110418064738849]
	TIME [epoch: 11.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06414758176406815		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.06414758176406815 | validation: 0.07176002601810062]
	TIME [epoch: 11.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06522297487181518		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.06522297487181518 | validation: 0.08096235039736768]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06188302798024316		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.06188302798024316 | validation: 0.08853806220547657]
	TIME [epoch: 11.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06383958431937908		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.06383958431937908 | validation: 0.07632882772247587]
	TIME [epoch: 11.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05988146546032977		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.05988146546032977 | validation: 0.08436690819166096]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06226516981360952		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.06226516981360952 | validation: 0.07669478581456826]
	TIME [epoch: 11.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06438879327140663		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.06438879327140663 | validation: 0.08423478363962338]
	TIME [epoch: 11.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06162105727572535		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.06162105727572535 | validation: 0.07291607512481565]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0636508511226572		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.0636508511226572 | validation: 0.07844028844107688]
	TIME [epoch: 11.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0645672436863958		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.0645672436863958 | validation: 0.07475371593594622]
	TIME [epoch: 11.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0645489629311715		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.0645489629311715 | validation: 0.0790552619507516]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06047705350954755		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.06047705350954755 | validation: 0.07182206591773761]
	TIME [epoch: 11.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06226948175155482		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.06226948175155482 | validation: 0.08244313696870044]
	TIME [epoch: 11.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06026706205743163		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.06026706205743163 | validation: 0.07405430147749414]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06309789800096377		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.06309789800096377 | validation: 0.07838105988181218]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06381474483010062		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.06381474483010062 | validation: 0.08536460906236083]
	TIME [epoch: 11.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059695715141110654		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.059695715141110654 | validation: 0.07750267991028156]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06421386082391957		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.06421386082391957 | validation: 0.08454791196582286]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06626047006623689		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.06626047006623689 | validation: 0.08728515034624318]
	TIME [epoch: 11.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06304065926162586		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.06304065926162586 | validation: 0.07913605835285095]
	TIME [epoch: 11.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.065797481022498		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.065797481022498 | validation: 0.07704009594051338]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06246968127592222		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.06246968127592222 | validation: 0.07361861028248391]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06223613226211126		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.06223613226211126 | validation: 0.08037097263606219]
	TIME [epoch: 11.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06454830701385535		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.06454830701385535 | validation: 0.08443842983940353]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06056822554959307		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.06056822554959307 | validation: 0.0727934001918722]
	TIME [epoch: 11.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06543177277424068		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.06543177277424068 | validation: 0.08186145656552446]
	TIME [epoch: 11.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06089451863514443		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.06089451863514443 | validation: 0.07155450496375436]
	TIME [epoch: 11.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06574289216353071		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.06574289216353071 | validation: 0.06993383316253571]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06255943757320907		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.06255943757320907 | validation: 0.08024670593468948]
	TIME [epoch: 11.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062259645113880074		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.062259645113880074 | validation: 0.0736815125297193]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06358502831599538		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.06358502831599538 | validation: 0.08024885360245047]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06396176071445085		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.06396176071445085 | validation: 0.07138818891479815]
	TIME [epoch: 11.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060893214111784305		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.060893214111784305 | validation: 0.07145009095435138]
	TIME [epoch: 11.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06128993204104916		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.06128993204104916 | validation: 0.07336214528685772]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06184493498002825		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.06184493498002825 | validation: 0.07808017955523745]
	TIME [epoch: 11.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06111281531281486		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.06111281531281486 | validation: 0.0827575412578011]
	TIME [epoch: 11.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06500464626017406		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.06500464626017406 | validation: 0.07510755280925388]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06216543443703311		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.06216543443703311 | validation: 0.07249935605126709]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05994379708445084		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.05994379708445084 | validation: 0.0755831997449975]
	TIME [epoch: 11.5 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05978183258195369		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.05978183258195369 | validation: 0.07639033936285064]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061602150519211474		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.061602150519211474 | validation: 0.07397596889246709]
	TIME [epoch: 11.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06405844637541971		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.06405844637541971 | validation: 0.06558304974402329]
	TIME [epoch: 11.5 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061695971954937506		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.061695971954937506 | validation: 0.06739570395372488]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062495327017790564		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.062495327017790564 | validation: 0.07541446558655972]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06207766709030248		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.06207766709030248 | validation: 0.06803613731878758]
	TIME [epoch: 11.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05965735149880691		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.05965735149880691 | validation: 0.07764190802887598]
	TIME [epoch: 11.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06279751580676271		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.06279751580676271 | validation: 0.07505728383738122]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06345034762883671		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.06345034762883671 | validation: 0.0675949688618563]
	TIME [epoch: 11.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05771080200337299		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.05771080200337299 | validation: 0.07795972103069089]
	TIME [epoch: 11.5 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06034550055097587		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.06034550055097587 | validation: 0.0740296248957206]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06153863942376813		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.06153863942376813 | validation: 0.0848691399542014]
	TIME [epoch: 11.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062437704234341085		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.062437704234341085 | validation: 0.07409426015608178]
	TIME [epoch: 11.5 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06242408349618703		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.06242408349618703 | validation: 0.08201539377946912]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06220830346020718		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.06220830346020718 | validation: 0.07542612481505208]
	TIME [epoch: 11.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06434994240061104		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.06434994240061104 | validation: 0.08177925829225872]
	TIME [epoch: 11.5 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06467991404892087		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.06467991404892087 | validation: 0.07892101627388222]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060864537290335564		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.060864537290335564 | validation: 0.08182425111799686]
	TIME [epoch: 11.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06021432504582482		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.06021432504582482 | validation: 0.07063251880138849]
	TIME [epoch: 11.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06317510952815439		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.06317510952815439 | validation: 0.07341474361415826]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061524320459215645		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.061524320459215645 | validation: 0.07799136192757158]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06219921381432794		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.06219921381432794 | validation: 0.07229471776472522]
	TIME [epoch: 11.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06427338779442661		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.06427338779442661 | validation: 0.08047408925324598]
	TIME [epoch: 11.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058960831750531455		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.058960831750531455 | validation: 0.0762137739352438]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06409227903928011		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.06409227903928011 | validation: 0.07131349281056915]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06023547331391931		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.06023547331391931 | validation: 0.08122433496694387]
	TIME [epoch: 11.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06330845519387002		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.06330845519387002 | validation: 0.07773094615137775]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0636458968824619		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.0636458968824619 | validation: 0.08148921859920659]
	TIME [epoch: 11.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06012302778072651		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.06012302778072651 | validation: 0.08463636639631218]
	TIME [epoch: 11.5 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05959500005681507		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.05959500005681507 | validation: 0.07916298075710972]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059534055986523844		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.059534055986523844 | validation: 0.07936975499682389]
	TIME [epoch: 11.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061182135266428975		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.061182135266428975 | validation: 0.08012699349128666]
	TIME [epoch: 11.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061893878079570204		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.061893878079570204 | validation: 0.07879926102421583]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0617381893634629		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.0617381893634629 | validation: 0.08249033217789783]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06059699926487122		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.06059699926487122 | validation: 0.08153915948191015]
	TIME [epoch: 11.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060410194741493006		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.060410194741493006 | validation: 0.0743422111308523]
	TIME [epoch: 11.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06043814998722055		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.06043814998722055 | validation: 0.07852937856418885]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059169454967111616		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.059169454967111616 | validation: 0.07937608807241041]
	TIME [epoch: 11.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0627960098641534		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.0627960098641534 | validation: 0.07967593438192688]
	TIME [epoch: 11.5 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06344171182218832		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.06344171182218832 | validation: 0.07519134169482099]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06412237230315748		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.06412237230315748 | validation: 0.0692523795731675]
	TIME [epoch: 11.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059766330403940936		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.059766330403940936 | validation: 0.07978514828610055]
	TIME [epoch: 11.5 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06077191748665982		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.06077191748665982 | validation: 0.07733914207502368]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06619053300043773		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.06619053300043773 | validation: 0.07704937767695505]
	TIME [epoch: 11.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05996178877740735		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.05996178877740735 | validation: 0.08562715141298206]
	TIME [epoch: 11.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05857070663636445		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.05857070663636445 | validation: 0.07291953898691668]
	TIME [epoch: 11.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06367601136081597		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.06367601136081597 | validation: 0.07975068952641742]
	TIME [epoch: 11.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06244653138645929		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.06244653138645929 | validation: 0.07813751251338007]
	TIME [epoch: 11.5 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06108636751350404		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.06108636751350404 | validation: 0.08291506924656142]
	TIME [epoch: 11.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062150485845272545		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.062150485845272545 | validation: 0.0771271490877051]
	TIME [epoch: 11.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06113599613084869		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.06113599613084869 | validation: 0.07820448369000702]
	TIME [epoch: 11.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06215726885037135		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.06215726885037135 | validation: 0.07822770780015238]
	TIME [epoch: 11.5 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05699580479449188		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.05699580479449188 | validation: 0.07937997052109598]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06187083881978338		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.06187083881978338 | validation: 0.07360082182800175]
	TIME [epoch: 11.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06431101391380245		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.06431101391380245 | validation: 0.07985264222244273]
	TIME [epoch: 11.5 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0608700707239533		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.0608700707239533 | validation: 0.0802046484052464]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061677974725572175		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.061677974725572175 | validation: 0.0770079425456056]
	TIME [epoch: 11.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06180004888789129		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.06180004888789129 | validation: 0.0743902087440521]
	TIME [epoch: 11.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06434459660273353		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.06434459660273353 | validation: 0.08238943939431653]
	TIME [epoch: 11.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061114452884823756		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.061114452884823756 | validation: 0.07554825864644894]
	TIME [epoch: 11.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06259518519619801		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.06259518519619801 | validation: 0.07836818815447667]
	TIME [epoch: 11.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06566475934671567		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.06566475934671567 | validation: 0.0826790811881169]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06410615295629567		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.06410615295629567 | validation: 0.07287981663433976]
	TIME [epoch: 11.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06186255818405097		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.06186255818405097 | validation: 0.06835537735175]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06275584580958157		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.06275584580958157 | validation: 0.07720932502151925]
	TIME [epoch: 11.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06560249087250587		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.06560249087250587 | validation: 0.07179916048593311]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06361360234493843		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.06361360234493843 | validation: 0.07753642721316602]
	TIME [epoch: 11.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06494095916092092		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.06494095916092092 | validation: 0.07542144055676672]
	TIME [epoch: 11.5 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06048483534898863		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.06048483534898863 | validation: 0.07917532457054301]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06229332835939269		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.06229332835939269 | validation: 0.07747800761879996]
	TIME [epoch: 11.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05950270928034086		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.05950270928034086 | validation: 0.08056108762207254]
	TIME [epoch: 11.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06299246840077302		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.06299246840077302 | validation: 0.07927789678875251]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06312462583778654		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.06312462583778654 | validation: 0.07420155089635389]
	TIME [epoch: 11.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061457620498740456		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.061457620498740456 | validation: 0.07050490063729994]
	TIME [epoch: 11.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06018538666749892		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.06018538666749892 | validation: 0.08203239988102831]
	TIME [epoch: 11.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061976719718604155		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.061976719718604155 | validation: 0.07982129553078593]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06182636169562803		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.06182636169562803 | validation: 0.08032084096110241]
	TIME [epoch: 11.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061655822732388905		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.061655822732388905 | validation: 0.06691824648357461]
	TIME [epoch: 11.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06050780946155433		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.06050780946155433 | validation: 0.07183633029712932]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06480793966182861		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.06480793966182861 | validation: 0.07929386276001814]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0617238002423038		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.0617238002423038 | validation: 0.08395093911996075]
	TIME [epoch: 11.5 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06074721563435493		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.06074721563435493 | validation: 0.08094760076572839]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06337951357451616		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.06337951357451616 | validation: 0.08098942589101751]
	TIME [epoch: 11.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058996144836025534		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.058996144836025534 | validation: 0.07620470708566857]
	TIME [epoch: 11.5 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06281988160614134		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.06281988160614134 | validation: 0.07340692169766165]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06129426147157599		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.06129426147157599 | validation: 0.07651805871188551]
	TIME [epoch: 11.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059213874155393004		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.059213874155393004 | validation: 0.07364690412477318]
	TIME [epoch: 11.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06276022648286766		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.06276022648286766 | validation: 0.07533294576429608]
	TIME [epoch: 11.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062175785400480854		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.062175785400480854 | validation: 0.08083663092275459]
	TIME [epoch: 11.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058831236836228526		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.058831236836228526 | validation: 0.07525237001848485]
	TIME [epoch: 11.5 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060205484272589385		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.060205484272589385 | validation: 0.07763495690822259]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06256798595828664		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.06256798595828664 | validation: 0.07255625333590791]
	TIME [epoch: 11.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06621093850428326		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.06621093850428326 | validation: 0.07639022389078637]
	TIME [epoch: 11.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06316958264636677		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.06316958264636677 | validation: 0.069825969371637]
	TIME [epoch: 11.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06394833677251484		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.06394833677251484 | validation: 0.07766025790377239]
	TIME [epoch: 11.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06283401963118397		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.06283401963118397 | validation: 0.07666828773009433]
	TIME [epoch: 11.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06259050529470053		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.06259050529470053 | validation: 0.0778246808552744]
	TIME [epoch: 11.5 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06228990690507765		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.06228990690507765 | validation: 0.08533901334105828]
	TIME [epoch: 11.5 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06278346016101308		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.06278346016101308 | validation: 0.07767468135547538]
	TIME [epoch: 11.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06230621533986477		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.06230621533986477 | validation: 0.07122437403891065]
	TIME [epoch: 11.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0636373704053548		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.0636373704053548 | validation: 0.07397261410371753]
	TIME [epoch: 11.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06353913192789079		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.06353913192789079 | validation: 0.07813011354810719]
	TIME [epoch: 11.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06241616685368618		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.06241616685368618 | validation: 0.07620953633001852]
	TIME [epoch: 11.5 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05931621044583933		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.05931621044583933 | validation: 0.07813748660274382]
	TIME [epoch: 11.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06439403638844297		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.06439403638844297 | validation: 0.06933274139707613]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06308740351567901		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.06308740351567901 | validation: 0.07989208558289464]
	TIME [epoch: 11.5 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06369992161588287		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.06369992161588287 | validation: 0.08078103310563797]
	TIME [epoch: 11.5 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06484315992984498		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.06484315992984498 | validation: 0.07464322043480841]
	TIME [epoch: 11.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06092927160318877		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.06092927160318877 | validation: 0.07923495499874751]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0633314106329004		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.0633314106329004 | validation: 0.07902606996976079]
	TIME [epoch: 11.5 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06251872113534346		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.06251872113534346 | validation: 0.07576971055531896]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06086887042699753		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.06086887042699753 | validation: 0.06963453633089844]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06496135825865382		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.06496135825865382 | validation: 0.07450713675611934]
	TIME [epoch: 11.5 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061850756986280515		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.061850756986280515 | validation: 0.07336283288790253]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06385207596215403		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.06385207596215403 | validation: 0.07304110718738507]
	TIME [epoch: 11.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05865860280838779		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.05865860280838779 | validation: 0.07683322252482064]
	TIME [epoch: 11.5 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061622866155034664		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.061622866155034664 | validation: 0.07878510012836178]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05990233156908872		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.05990233156908872 | validation: 0.07837499935644603]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0621321044997928		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.0621321044997928 | validation: 0.07785325006677601]
	TIME [epoch: 11.5 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06115589551448932		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.06115589551448932 | validation: 0.06937808521484247]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060169232240351464		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.060169232240351464 | validation: 0.07683481609634565]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06354610043975298		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.06354610043975298 | validation: 0.07483426243136966]
	TIME [epoch: 11.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06093779655218171		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.06093779655218171 | validation: 0.07485779258682641]
	TIME [epoch: 11.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058519283526430294		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.058519283526430294 | validation: 0.07753648518614517]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06554321953912456		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.06554321953912456 | validation: 0.075621461585342]
	TIME [epoch: 11.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05749850489580802		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.05749850489580802 | validation: 0.08237351589500008]
	TIME [epoch: 11.5 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062065018556032574		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.062065018556032574 | validation: 0.08032273774814805]
	TIME [epoch: 11.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06015201370218071		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.06015201370218071 | validation: 0.07187215811646738]
	TIME [epoch: 11.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061174776811072556		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.061174776811072556 | validation: 0.07614650233625195]
	TIME [epoch: 11.5 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05937670782787318		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.05937670782787318 | validation: 0.07997759353541561]
	TIME [epoch: 11.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061290619387673884		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.061290619387673884 | validation: 0.08045283491272442]
	TIME [epoch: 11.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05915838995090352		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.05915838995090352 | validation: 0.07415567989362301]
	TIME [epoch: 11.5 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06173065715293331		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.06173065715293331 | validation: 0.08083671123504925]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06466518020565837		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.06466518020565837 | validation: 0.07026944203635768]
	TIME [epoch: 11.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06629951278956679		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.06629951278956679 | validation: 0.06843911477553467]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060774268672984535		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.060774268672984535 | validation: 0.07137335962694136]
	TIME [epoch: 11.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0612103645201464		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.0612103645201464 | validation: 0.06987300488304506]
	TIME [epoch: 11.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05992551320480655		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.05992551320480655 | validation: 0.07736935845938342]
	TIME [epoch: 11.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06276488179673409		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.06276488179673409 | validation: 0.07367792565507278]
	TIME [epoch: 11.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058968850584718534		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.058968850584718534 | validation: 0.08196595495823912]
	TIME [epoch: 11.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06430358306261522		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.06430358306261522 | validation: 0.07039040810524483]
	TIME [epoch: 11.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06155232394511495		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.06155232394511495 | validation: 0.07700101893760272]
	TIME [epoch: 11.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06027969533956096		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.06027969533956096 | validation: 0.07536510977110136]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06276632616999638		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.06276632616999638 | validation: 0.08339850018482915]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0631064626893271		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.0631064626893271 | validation: 0.07159585825092102]
	TIME [epoch: 11.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06229111568078417		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.06229111568078417 | validation: 0.07857285190043074]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06021907681564591		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.06021907681564591 | validation: 0.07108453006294548]
	TIME [epoch: 11.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06186992330728472		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.06186992330728472 | validation: 0.0779118930581229]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059546216846283376		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.059546216846283376 | validation: 0.07439830417499632]
	TIME [epoch: 11.5 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059620565145474244		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.059620565145474244 | validation: 0.07684665949587678]
	TIME [epoch: 11.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05873882994238148		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.05873882994238148 | validation: 0.06946319168007825]
	TIME [epoch: 11.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06496058863376043		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.06496058863376043 | validation: 0.07412716215220694]
	TIME [epoch: 11.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06170036387338276		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.06170036387338276 | validation: 0.0779900327593465]
	TIME [epoch: 11.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060979716508249		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.060979716508249 | validation: 0.0655972695886538]
	TIME [epoch: 11.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061251271826360525		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.061251271826360525 | validation: 0.06585733172783298]
	TIME [epoch: 11.5 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061851667934396684		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.061851667934396684 | validation: 0.07380732078616832]
	TIME [epoch: 11.5 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0618375183350384		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.0618375183350384 | validation: 0.06712808611603066]
	TIME [epoch: 11.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06145137593745156		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.06145137593745156 | validation: 0.07150232449587986]
	TIME [epoch: 11.5 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061427936907298045		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.061427936907298045 | validation: 0.08131099617579775]
	TIME [epoch: 11.5 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05994227348994173		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.05994227348994173 | validation: 0.07733297910821464]
	TIME [epoch: 11.5 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06281574547433813		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.06281574547433813 | validation: 0.07751433359243794]
	TIME [epoch: 11.5 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060268383267611504		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.060268383267611504 | validation: 0.0740089490956206]
	TIME [epoch: 11.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06570273531982387		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.06570273531982387 | validation: 0.07811002251891529]
	TIME [epoch: 11.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06685824131904011		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.06685824131904011 | validation: 0.07763439790122469]
	TIME [epoch: 11.5 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06019260023826559		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.06019260023826559 | validation: 0.07876836283652429]
	TIME [epoch: 11.5 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05631563881631489		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.05631563881631489 | validation: 0.07726447008982917]
	TIME [epoch: 11.5 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059349144302977636		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.059349144302977636 | validation: 0.06793554074058739]
	TIME [epoch: 11.5 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059421583636516576		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.059421583636516576 | validation: 0.08118064750386343]
	TIME [epoch: 11.5 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0632695577009322		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.0632695577009322 | validation: 0.06878702217670613]
	TIME [epoch: 11.5 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06038690615336457		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.06038690615336457 | validation: 0.07659522881192944]
	TIME [epoch: 11.5 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05625505291898006		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.05625505291898006 | validation: 0.07480620971758825]
	TIME [epoch: 11.5 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06220100757522106		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.06220100757522106 | validation: 0.07474819784501963]
	TIME [epoch: 11.5 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05887935548167437		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.05887935548167437 | validation: 0.0724556203946905]
	TIME [epoch: 11.5 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06255893316070987		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.06255893316070987 | validation: 0.06397211294196081]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240310_003029/states/model_tr_study4_1902.pth
	Model improved!!!
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06193493881359613		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.06193493881359613 | validation: 0.07258933114280847]
	TIME [epoch: 11.5 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06000009224846066		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.06000009224846066 | validation: 0.08430365073049778]
	TIME [epoch: 11.5 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06145851722486445		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.06145851722486445 | validation: 0.0694600580690633]
	TIME [epoch: 11.5 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061624173784262715		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.061624173784262715 | validation: 0.06932284998419688]
	TIME [epoch: 11.5 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05934603129622659		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.05934603129622659 | validation: 0.07444549855172096]
	TIME [epoch: 11.5 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06116091442627733		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.06116091442627733 | validation: 0.0768282337815428]
	TIME [epoch: 11.5 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05936980001343589		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.05936980001343589 | validation: 0.07236985519154752]
	TIME [epoch: 11.5 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06246695377639823		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.06246695377639823 | validation: 0.07577681759792754]
	TIME [epoch: 11.5 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062164879743051765		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.062164879743051765 | validation: 0.07303958165404958]
	TIME [epoch: 11.5 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06388246780248755		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.06388246780248755 | validation: 0.07426981181434046]
	TIME [epoch: 11.5 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0607838098046226		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.0607838098046226 | validation: 0.07526596206778244]
	TIME [epoch: 11.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058102389026951015		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.058102389026951015 | validation: 0.0778689651864568]
	TIME [epoch: 11.5 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06094386830825336		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.06094386830825336 | validation: 0.07725373996378122]
	TIME [epoch: 11.5 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06382739126261308		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.06382739126261308 | validation: 0.08110262757137633]
	TIME [epoch: 11.5 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059876063996793225		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.059876063996793225 | validation: 0.07179990759512832]
	TIME [epoch: 11.5 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06578716958286468		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.06578716958286468 | validation: 0.08225157849037437]
	TIME [epoch: 11.5 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06037535321185867		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.06037535321185867 | validation: 0.07144010001648754]
	TIME [epoch: 11.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06472571222932177		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.06472571222932177 | validation: 0.08259793624211968]
	TIME [epoch: 11.5 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059158749134708866		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.059158749134708866 | validation: 0.08152395955515836]
	TIME [epoch: 11.5 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05997476481963657		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.05997476481963657 | validation: 0.07115889105351364]
	TIME [epoch: 11.5 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06049778813207427		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.06049778813207427 | validation: 0.08128791987049393]
	TIME [epoch: 11.5 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06716798058780457		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.06716798058780457 | validation: 0.07899387279603153]
	TIME [epoch: 11.5 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06175343347082462		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.06175343347082462 | validation: 0.07324626832964108]
	TIME [epoch: 11.5 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05896302186768336		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.05896302186768336 | validation: 0.07164839675965631]
	TIME [epoch: 11.5 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05999763860217368		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.05999763860217368 | validation: 0.07815349009656476]
	TIME [epoch: 11.5 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06299396264240187		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.06299396264240187 | validation: 0.06760634866029826]
	TIME [epoch: 11.5 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05630148337409366		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.05630148337409366 | validation: 0.06857959561843627]
	TIME [epoch: 11.5 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06073832157757657		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.06073832157757657 | validation: 0.07796330371913596]
	TIME [epoch: 11.5 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0607270518604516		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.0607270518604516 | validation: 0.07636241879655567]
	TIME [epoch: 11.5 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06489992698139539		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.06489992698139539 | validation: 0.07130604398041826]
	TIME [epoch: 11.5 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06276175550538449		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.06276175550538449 | validation: 0.07791370152555464]
	TIME [epoch: 11.5 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05834954386359657		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.05834954386359657 | validation: 0.07607626343341545]
	TIME [epoch: 11.5 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06109410081294638		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.06109410081294638 | validation: 0.06997362894605876]
	TIME [epoch: 11.5 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06166888748771936		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.06166888748771936 | validation: 0.0678085024230018]
	TIME [epoch: 11.5 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06158333389864957		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.06158333389864957 | validation: 0.0696145390798442]
	TIME [epoch: 11.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06186821881641058		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.06186821881641058 | validation: 0.06563577041417329]
	TIME [epoch: 11.5 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06424124223522945		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.06424124223522945 | validation: 0.07431105856105258]
	TIME [epoch: 11.5 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06069800704514403		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.06069800704514403 | validation: 0.0764096767680036]
	TIME [epoch: 11.5 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06432058185600391		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.06432058185600391 | validation: 0.07804894721952259]
	TIME [epoch: 11.5 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06079981061176651		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.06079981061176651 | validation: 0.06596489791733887]
	TIME [epoch: 11.5 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0633760646246937		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.0633760646246937 | validation: 0.07739395051866313]
	TIME [epoch: 11.5 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06015667588466442		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.06015667588466442 | validation: 0.07867039765647742]
	TIME [epoch: 11.5 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05939806975128118		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.05939806975128118 | validation: 0.07729385570590028]
	TIME [epoch: 11.5 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06046890449329892		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.06046890449329892 | validation: 0.07407975325865533]
	TIME [epoch: 11.5 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0631130294877658		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.0631130294877658 | validation: 0.06792321857968292]
	TIME [epoch: 11.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06278887239222158		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.06278887239222158 | validation: 0.07112752896982659]
	TIME [epoch: 11.5 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06181626716991631		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.06181626716991631 | validation: 0.07833399117384017]
	TIME [epoch: 11.5 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06095393399271079		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.06095393399271079 | validation: 0.07193348410986176]
	TIME [epoch: 11.5 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06078608977528198		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.06078608977528198 | validation: 0.0673687846344098]
	TIME [epoch: 11.5 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0630986237820046		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.0630986237820046 | validation: 0.07892756375243436]
	TIME [epoch: 11.5 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061785420324493634		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.061785420324493634 | validation: 0.07346394894841848]
	TIME [epoch: 11.5 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06058179215247875		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.06058179215247875 | validation: 0.07154484441186956]
	TIME [epoch: 11.5 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057319170883825155		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.057319170883825155 | validation: 0.07854667307518988]
	TIME [epoch: 11.5 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05791438768237388		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.05791438768237388 | validation: 0.08636364935490065]
	TIME [epoch: 11.5 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05795737100823428		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.05795737100823428 | validation: 0.07017073933251376]
	TIME [epoch: 11.5 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06268620412788838		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.06268620412788838 | validation: 0.07632681140345764]
	TIME [epoch: 11.5 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060249023472828026		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.060249023472828026 | validation: 0.07663094689001004]
	TIME [epoch: 11.5 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06071631347071714		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.06071631347071714 | validation: 0.07608232339387294]
	TIME [epoch: 11.5 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056583790658493865		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.056583790658493865 | validation: 0.07873890220511093]
	TIME [epoch: 11.5 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06217395979315129		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.06217395979315129 | validation: 0.07339250586801274]
	TIME [epoch: 11.5 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0569588723434065		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.0569588723434065 | validation: 0.07366378950601155]
	TIME [epoch: 11.5 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0627722881724042		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.0627722881724042 | validation: 0.08145438003740457]
	TIME [epoch: 11.5 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061298592054094096		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.061298592054094096 | validation: 0.07846419712356084]
	TIME [epoch: 11.5 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05912830387216926		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.05912830387216926 | validation: 0.07369796074341768]
	TIME [epoch: 11.5 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0645699628446401		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.0645699628446401 | validation: 0.07429252565007154]
	TIME [epoch: 11.5 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05950110676441642		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.05950110676441642 | validation: 0.06815098181533692]
	TIME [epoch: 11.5 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05953750236298497		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.05953750236298497 | validation: 0.06775970109008331]
	TIME [epoch: 11.5 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0604160385784034		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.0604160385784034 | validation: 0.07309612388089665]
	TIME [epoch: 11.5 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06022128596237845		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.06022128596237845 | validation: 0.06905997894192836]
	TIME [epoch: 11.5 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06220468275356385		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.06220468275356385 | validation: 0.07505103434665299]
	TIME [epoch: 11.5 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06159981040203672		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.06159981040203672 | validation: 0.0748549627631634]
	TIME [epoch: 11.5 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06073515023650901		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.06073515023650901 | validation: 0.07326337002756288]
	TIME [epoch: 11.5 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06274812848111373		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.06274812848111373 | validation: 0.0780346762650277]
	TIME [epoch: 11.5 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059804212836108935		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.059804212836108935 | validation: 0.07393247281531524]
	TIME [epoch: 11.5 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06078245460655203		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.06078245460655203 | validation: 0.081261051761491]
	TIME [epoch: 11.5 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061069517939358664		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.061069517939358664 | validation: 0.07934239945598474]
	TIME [epoch: 11.5 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06031278293879273		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.06031278293879273 | validation: 0.07990152842585234]
	TIME [epoch: 11.5 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06096879599877489		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.06096879599877489 | validation: 0.07569918216921957]
	TIME [epoch: 11.5 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06160640907124212		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.06160640907124212 | validation: 0.08052957566971623]
	TIME [epoch: 11.5 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062525893689523		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.062525893689523 | validation: 0.07832344199717986]
	TIME [epoch: 11.5 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0630546786941548		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.0630546786941548 | validation: 0.07100500478193897]
	TIME [epoch: 11.5 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059338547298875235		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.059338547298875235 | validation: 0.08057750543599371]
	TIME [epoch: 11.5 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060994574523406425		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.060994574523406425 | validation: 0.08039334600804277]
	TIME [epoch: 11.5 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06040584555266461		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.06040584555266461 | validation: 0.08526323827312901]
	TIME [epoch: 11.5 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06160645741226173		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.06160645741226173 | validation: 0.0722163159064058]
	TIME [epoch: 11.5 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058413184368045615		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.058413184368045615 | validation: 0.07077328770387376]
	TIME [epoch: 11.5 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059238989577515645		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.059238989577515645 | validation: 0.07258805572190552]
	TIME [epoch: 11.5 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061346384206722115		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.061346384206722115 | validation: 0.07516752303893244]
	TIME [epoch: 11.5 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06572119929370639		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.06572119929370639 | validation: 0.07601384965172364]
	TIME [epoch: 11.5 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0611575518454416		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.0611575518454416 | validation: 0.0761555857593931]
	TIME [epoch: 11.5 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05865404471543506		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.05865404471543506 | validation: 0.08187778115613348]
	TIME [epoch: 11.5 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06151729915594348		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.06151729915594348 | validation: 0.08117960044482429]
	TIME [epoch: 11.5 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059111028649772		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.059111028649772 | validation: 0.0826932534296823]
	TIME [epoch: 11.5 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05882218862907636		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.05882218862907636 | validation: 0.07557244793515207]
	TIME [epoch: 11.5 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06198091591664405		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.06198091591664405 | validation: 0.07558154652193856]
	TIME [epoch: 11.5 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06064095971381027		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.06064095971381027 | validation: 0.07900907701172415]
	TIME [epoch: 11.5 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05981657429309548		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.05981657429309548 | validation: 0.07578830951807411]
	TIME [epoch: 11.5 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06071859666035892		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.06071859666035892 | validation: 0.07462024032307868]
	TIME [epoch: 11.5 sec]
Finished training in 23199.416 seconds.
