Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r0', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3580655372

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.921196811034033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.921196811034033 | validation: 8.635096902898281]
	TIME [epoch: 98.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.208674810830667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.208674810830667 | validation: 7.657685094944745]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.706211695124516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.706211695124516 | validation: 6.069457252664289]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.239951429651008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.239951429651008 | validation: 6.14337147101803]
	TIME [epoch: 11.6 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.389239823711861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.389239823711861 | validation: 5.598497573472518]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467882110910511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.467882110910511 | validation: 4.391577462145139]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3533072601059395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3533072601059395 | validation: 3.9573885371643884]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.608738929647662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.608738929647662 | validation: 3.935497115002539]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.72894092365165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.72894092365165 | validation: 4.409814511667621]
	TIME [epoch: 11.6 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.073297436430411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.073297436430411 | validation: 8.730930234222486]
	TIME [epoch: 11.6 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.31005532532679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.31005532532679 | validation: 4.462542448580221]
	TIME [epoch: 11.6 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.122625343763067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.122625343763067 | validation: 3.675088984556826]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5112959809771622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5112959809771622 | validation: 3.623418438846128]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.283654603047888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.283654603047888 | validation: 3.399021331364571]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6326707492705763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6326707492705763 | validation: 3.349306391754472]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1566172182475762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1566172182475762 | validation: 3.3141888895589977]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.177634939084702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.177634939084702 | validation: 3.762886810879651]
	TIME [epoch: 11.6 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.165459081230079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.165459081230079 | validation: 3.232434178748469]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.051567318203947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.051567318203947 | validation: 3.1808177921335163]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9448954305847934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9448954305847934 | validation: 3.3242828013594683]
	TIME [epoch: 11.6 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.922635889564741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.922635889564741 | validation: 3.1731204603814125]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9138412056820537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9138412056820537 | validation: 6.411536098405492]
	TIME [epoch: 11.6 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.377102936700365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.377102936700365 | validation: 3.187804080994719]
	TIME [epoch: 11.6 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.857109344492991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.857109344492991 | validation: 2.9814230535722555]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.859131154717459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.859131154717459 | validation: 2.985202525283758]
	TIME [epoch: 11.6 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6786128100602795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6786128100602795 | validation: 2.75720318520994]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.553822295735182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.553822295735182 | validation: 2.718401798422754]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.387807174761382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.387807174761382 | validation: 3.0010017614971845]
	TIME [epoch: 11.6 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.606307087613485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.606307087613485 | validation: 2.551158125934131]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.255033283712845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.255033283712845 | validation: 2.3217272312632873]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.005060365477372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.005060365477372 | validation: 2.369847085385581]
	TIME [epoch: 11.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5816308977364297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5816308977364297 | validation: 2.4540781544608774]
	TIME [epoch: 11.6 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.183507142860675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.183507142860675 | validation: 2.100082155747882]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.938905441528178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.938905441528178 | validation: 1.956121147896051]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8648706678446771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8648706678446771 | validation: 1.704662979512781]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7822556774899798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7822556774899798 | validation: 3.1088651259727103]
	TIME [epoch: 11.6 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9117347098925184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9117347098925184 | validation: 1.7213187845244269]
	TIME [epoch: 11.6 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5528559177721752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5528559177721752 | validation: 1.4060938459133272]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3764948361556884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3764948361556884 | validation: 1.610792083035558]
	TIME [epoch: 11.6 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6472982268375598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6472982268375598 | validation: 1.5994277796115461]
	TIME [epoch: 11.6 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.704440744480692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.704440744480692 | validation: 1.38753676520015]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230047453630393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.230047453630393 | validation: 1.076817050646923]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1901071308588231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1901071308588231 | validation: 1.2329398031083882]
	TIME [epoch: 11.6 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2803443009264677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2803443009264677 | validation: 1.9313002793789074]
	TIME [epoch: 11.6 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4780499784878058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4780499784878058 | validation: 0.9493989741933581]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9914586773820233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9914586773820233 | validation: 1.0404516397213297]
	TIME [epoch: 11.6 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9108098270729806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9108098270729806 | validation: 1.2608099885609074]
	TIME [epoch: 11.6 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8095436054335295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8095436054335295 | validation: 0.6375736256320795]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8587789554021376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8587789554021376 | validation: 0.5543321145009831]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0811339129868671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0811339129868671 | validation: 1.6888032844840646]
	TIME [epoch: 11.6 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2899847008354604		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.2899847008354604 | validation: 0.9127590953594101]
	TIME [epoch: 11.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.781368439629146		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.781368439629146 | validation: 0.7983013533140294]
	TIME [epoch: 11.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6985070938598837		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.6985070938598837 | validation: 0.5710061997137041]
	TIME [epoch: 11.6 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5461870155213506		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.5461870155213506 | validation: 0.667242097999252]
	TIME [epoch: 11.5 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6407173097754641		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.6407173097754641 | validation: 0.8271393643454141]
	TIME [epoch: 11.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8680087857063334		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.8680087857063334 | validation: 0.7018745345365358]
	TIME [epoch: 11.6 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6061953675553697		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.6061953675553697 | validation: 0.5231999151179345]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7016276324896124		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.7016276324896124 | validation: 0.6213791975782286]
	TIME [epoch: 11.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6275299477608001		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.6275299477608001 | validation: 0.4763140428545336]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5007730692494423		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.5007730692494423 | validation: 0.6946709782694785]
	TIME [epoch: 11.6 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5999917289536816		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.5999917289536816 | validation: 0.7285166787333103]
	TIME [epoch: 11.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6036121927200033		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.6036121927200033 | validation: 0.43536130762100234]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5464985118714404		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.5464985118714404 | validation: 0.8455484896990082]
	TIME [epoch: 11.6 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5317912112075157		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.5317912112075157 | validation: 0.7110429174009613]
	TIME [epoch: 11.6 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062892189504395		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.062892189504395 | validation: 0.730316748377067]
	TIME [epoch: 11.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8496117450477054		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.8496117450477054 | validation: 0.5434807397514401]
	TIME [epoch: 11.5 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5276778003020295		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.5276778003020295 | validation: 0.4462041826253757]
	TIME [epoch: 11.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1496931659939322		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.1496931659939322 | validation: 0.5100118390080377]
	TIME [epoch: 11.5 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4579726145317143		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.4579726145317143 | validation: 0.5024508734886588]
	TIME [epoch: 11.6 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6560464716091178		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.6560464716091178 | validation: 0.5834621952238408]
	TIME [epoch: 11.6 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5446697824929584		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.5446697824929584 | validation: 0.8968999355898128]
	TIME [epoch: 11.5 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7065465779346747		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.7065465779346747 | validation: 0.42866473534833205]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4517740894128785		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.4517740894128785 | validation: 0.5894632240643819]
	TIME [epoch: 11.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6997929797084088		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.6997929797084088 | validation: 0.857110789920429]
	TIME [epoch: 11.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6321115037661823		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.6321115037661823 | validation: 1.355628306846876]
	TIME [epoch: 11.5 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7460767023884938		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.7460767023884938 | validation: 0.9046122708131494]
	TIME [epoch: 11.6 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7102355596870876		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.7102355596870876 | validation: 0.5659927800946669]
	TIME [epoch: 11.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47110255057546		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.47110255057546 | validation: 0.6260317522859543]
	TIME [epoch: 11.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0722594109264674		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.0722594109264674 | validation: 0.5268003566805947]
	TIME [epoch: 11.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46617996160699665		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.46617996160699665 | validation: 0.42042496273790164]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5667218172180833		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.5667218172180833 | validation: 0.4259508397906805]
	TIME [epoch: 11.5 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5649821858879476		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.5649821858879476 | validation: 0.7778124569432676]
	TIME [epoch: 11.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2122798366854894		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.2122798366854894 | validation: 0.4890548586862555]
	TIME [epoch: 11.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.493730899883502		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.493730899883502 | validation: 0.5591789861813269]
	TIME [epoch: 11.5 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49445742332609854		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.49445742332609854 | validation: 0.5113516393509554]
	TIME [epoch: 11.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6596522075576565		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.6596522075576565 | validation: 0.7622706118571376]
	TIME [epoch: 11.5 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.682261395181769		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.682261395181769 | validation: 0.5279108007853257]
	TIME [epoch: 11.5 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4857200415835065		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.4857200415835065 | validation: 0.6785983532643072]
	TIME [epoch: 11.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6759059820090393		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.6759059820090393 | validation: 0.6619568264347231]
	TIME [epoch: 11.5 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207559494094584		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.7207559494094584 | validation: 0.7937329115653229]
	TIME [epoch: 11.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6938378799737904		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.6938378799737904 | validation: 0.66977941692143]
	TIME [epoch: 11.6 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.014836849579595		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.014836849579595 | validation: 1.7489968055954654]
	TIME [epoch: 11.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.03997908008598		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.03997908008598 | validation: 0.5854540883704421]
	TIME [epoch: 11.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6076173802997406		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.6076173802997406 | validation: 0.4990058825597316]
	TIME [epoch: 11.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8349776234783544		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.8349776234783544 | validation: 0.7302748204763253]
	TIME [epoch: 11.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142139802985753		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.142139802985753 | validation: 0.6580928205542941]
	TIME [epoch: 11.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6762178049755666		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.6762178049755666 | validation: 0.6910831681851449]
	TIME [epoch: 11.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6300109411275452		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.6300109411275452 | validation: 0.7613742542670778]
	TIME [epoch: 11.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7936086251807313		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.7936086251807313 | validation: 1.1993848129648579]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8038489631586307		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.8038489631586307 | validation: 0.6334246584582545]
	TIME [epoch: 11.6 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4992907628855675		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.4992907628855675 | validation: 0.5087580827482305]
	TIME [epoch: 11.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5037282038513665		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.5037282038513665 | validation: 0.5148226694356896]
	TIME [epoch: 11.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6373208156103164		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.6373208156103164 | validation: 0.9385298804744355]
	TIME [epoch: 11.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6729364001936207		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.6729364001936207 | validation: 0.8164489635809193]
	TIME [epoch: 11.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5427620915026309		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.5427620915026309 | validation: 0.5221922059877481]
	TIME [epoch: 11.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5071085765347481		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.5071085765347481 | validation: 2.1847805388478014]
	TIME [epoch: 11.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5130690515990435		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.5130690515990435 | validation: 0.8402416868741938]
	TIME [epoch: 11.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.625508170379054		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.625508170379054 | validation: 2.472004116648905]
	TIME [epoch: 11.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4499338490239455		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.4499338490239455 | validation: 0.610636890533947]
	TIME [epoch: 11.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5609270288492214		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.5609270288492214 | validation: 0.5511123934563947]
	TIME [epoch: 11.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6460015202405609		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.6460015202405609 | validation: 0.5615290483276314]
	TIME [epoch: 11.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47028273767697587		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.47028273767697587 | validation: 0.5135797619927365]
	TIME [epoch: 11.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6499538902373261		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.6499538902373261 | validation: 0.8028384445680818]
	TIME [epoch: 11.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5389586920825551		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.5389586920825551 | validation: 0.5250233028813651]
	TIME [epoch: 11.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5401448517104221		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.5401448517104221 | validation: 0.579117345662691]
	TIME [epoch: 11.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5253754049115305		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.5253754049115305 | validation: 0.48292999026095673]
	TIME [epoch: 11.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6286416592280224		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.6286416592280224 | validation: 0.5288706154167149]
	TIME [epoch: 11.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5273667523750829		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.5273667523750829 | validation: 0.6482857481292831]
	TIME [epoch: 11.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5507880759716584		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.5507880759716584 | validation: 0.4360191351484458]
	TIME [epoch: 11.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47237826609285566		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.47237826609285566 | validation: 0.5216163484885801]
	TIME [epoch: 11.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7462239264316904		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.7462239264316904 | validation: 0.7809380026781956]
	TIME [epoch: 11.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6555799975561286		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.6555799975561286 | validation: 0.5118079483140057]
	TIME [epoch: 11.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5492675114205984		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.5492675114205984 | validation: 0.5455360150773066]
	TIME [epoch: 11.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49038405423725584		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.49038405423725584 | validation: 0.4293200422791933]
	TIME [epoch: 11.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4709028734285609		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.4709028734285609 | validation: 0.44129525204124703]
	TIME [epoch: 11.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4435642426698683		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.4435642426698683 | validation: 0.6292505856766842]
	TIME [epoch: 11.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.556604161044299		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.556604161044299 | validation: 0.5429460020221943]
	TIME [epoch: 11.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4483565286082285		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.4483565286082285 | validation: 0.47699356910916363]
	TIME [epoch: 11.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5801804274254521		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.5801804274254521 | validation: 0.45431374837294497]
	TIME [epoch: 11.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4968854726807131		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.4968854726807131 | validation: 0.40141930812642423]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5225493991030596		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.5225493991030596 | validation: 0.4105540816278373]
	TIME [epoch: 11.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44103156030607094		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.44103156030607094 | validation: 0.643935221973192]
	TIME [epoch: 11.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5779123294276358		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.5779123294276358 | validation: 0.530498941827208]
	TIME [epoch: 11.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4670788053033699		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.4670788053033699 | validation: 0.4094196943765724]
	TIME [epoch: 11.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4338225639578144		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.4338225639578144 | validation: 0.6403841459112027]
	TIME [epoch: 11.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6909202155815766		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.6909202155815766 | validation: 0.49221677237047984]
	TIME [epoch: 11.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4021697492679559		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.4021697492679559 | validation: 0.5815070333616661]
	TIME [epoch: 11.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4911470357882168		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.4911470357882168 | validation: 0.7488815622309956]
	TIME [epoch: 11.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4650520357545705		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.4650520357545705 | validation: 0.6207772094607124]
	TIME [epoch: 11.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5416091769309521		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.5416091769309521 | validation: 0.5850530118787726]
	TIME [epoch: 11.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5738247365936986		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.5738247365936986 | validation: 0.4008309397019682]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7014313918848151		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.7014313918848151 | validation: 0.6093241607132451]
	TIME [epoch: 11.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4596918298873207		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.4596918298873207 | validation: 0.38049183515348406]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3742354310733348		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.3742354310733348 | validation: 0.39370776766720184]
	TIME [epoch: 11.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4396966726597415		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.4396966726597415 | validation: 0.6116439074190663]
	TIME [epoch: 11.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4886393288468083		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.4886393288468083 | validation: 0.602413310748682]
	TIME [epoch: 11.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5295375759321836		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.5295375759321836 | validation: 0.9358285136045553]
	TIME [epoch: 11.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6369766394898184		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.6369766394898184 | validation: 0.5008142212993311]
	TIME [epoch: 11.6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39738335778121214		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.39738335778121214 | validation: 0.46250494603406]
	TIME [epoch: 11.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.432101329582619		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.432101329582619 | validation: 0.481379212921035]
	TIME [epoch: 11.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6149868468903739		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.6149868468903739 | validation: 0.5096968349444145]
	TIME [epoch: 11.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5753753763214917		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.5753753763214917 | validation: 0.5041240310473323]
	TIME [epoch: 11.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4364709109874302		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.4364709109874302 | validation: 0.8017086255563911]
	TIME [epoch: 11.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5396240388937279		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.5396240388937279 | validation: 0.6204189628537319]
	TIME [epoch: 11.6 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5872592534751335		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.5872592534751335 | validation: 0.8218927110529174]
	TIME [epoch: 11.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5247085224464176		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.5247085224464176 | validation: 0.48184316482674194]
	TIME [epoch: 11.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4062234062199583		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.4062234062199583 | validation: 0.5024350026011465]
	TIME [epoch: 11.6 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5192391193139728		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.5192391193139728 | validation: 0.4692424198899085]
	TIME [epoch: 11.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41095780336863075		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.41095780336863075 | validation: 0.43049756610978085]
	TIME [epoch: 11.6 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5077847183835582		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.5077847183835582 | validation: 0.40223657342332586]
	TIME [epoch: 11.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3742907276461096		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.3742907276461096 | validation: 0.4658678010255395]
	TIME [epoch: 11.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49697001563365883		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.49697001563365883 | validation: 1.0456895682128997]
	TIME [epoch: 11.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7328571589809065		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.7328571589809065 | validation: 0.449713701820851]
	TIME [epoch: 11.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5166527705336177		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.5166527705336177 | validation: 0.5218371061328813]
	TIME [epoch: 11.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4745263083719917		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.4745263083719917 | validation: 0.421918714407301]
	TIME [epoch: 11.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4860708879721231		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.4860708879721231 | validation: 0.4076056071728905]
	TIME [epoch: 11.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6125449838108986		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.6125449838108986 | validation: 0.5570173311896316]
	TIME [epoch: 11.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41670542111576564		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.41670542111576564 | validation: 0.4454819648703503]
	TIME [epoch: 11.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4139934371043697		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.4139934371043697 | validation: 0.541635987696264]
	TIME [epoch: 11.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48720262045809615		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.48720262045809615 | validation: 0.3514550648933603]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3842868462591314		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.3842868462591314 | validation: 0.37806229264323266]
	TIME [epoch: 11.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38879882800140914		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.38879882800140914 | validation: 0.5024261038522074]
	TIME [epoch: 11.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4236425630412112		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.4236425630412112 | validation: 1.083885967817513]
	TIME [epoch: 11.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6635780643773028		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.6635780643773028 | validation: 0.47954158066897096]
	TIME [epoch: 11.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.383564941793462		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.383564941793462 | validation: 0.6512085396299275]
	TIME [epoch: 11.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5799364912914119		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.5799364912914119 | validation: 0.492806235458875]
	TIME [epoch: 11.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6122807383174972		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.6122807383174972 | validation: 0.8659813254324005]
	TIME [epoch: 11.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7732603678229228		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.7732603678229228 | validation: 1.0847326622167566]
	TIME [epoch: 11.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6607585389097259		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.6607585389097259 | validation: 0.4195017352001112]
	TIME [epoch: 11.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40962327950790484		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.40962327950790484 | validation: 0.3790966128011391]
	TIME [epoch: 11.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47853543157437484		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.47853543157437484 | validation: 3.458592397234745]
	TIME [epoch: 11.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.291864776753		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 4.291864776753 | validation: 3.3410508723474734]
	TIME [epoch: 11.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1950577525279735		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 4.1950577525279735 | validation: 3.357470545396676]
	TIME [epoch: 11.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1759797239979175		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 4.1759797239979175 | validation: 3.328249827836785]
	TIME [epoch: 11.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.16526767744224		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 4.16526767744224 | validation: 3.4122708108847126]
	TIME [epoch: 11.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2578804830560886		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 3.2578804830560886 | validation: 0.8290094049485935]
	TIME [epoch: 11.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7263719628599481		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.7263719628599481 | validation: 0.6795292250301265]
	TIME [epoch: 11.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5921949185943355		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.5921949185943355 | validation: 0.553604558090574]
	TIME [epoch: 11.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4259793533585419		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.4259793533585419 | validation: 0.4381689913267532]
	TIME [epoch: 11.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5354252345881214		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.5354252345881214 | validation: 0.5651156764824917]
	TIME [epoch: 11.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7054571129691916		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.7054571129691916 | validation: 0.4172836985001166]
	TIME [epoch: 11.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44581094608328753		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.44581094608328753 | validation: 0.521798846315375]
	TIME [epoch: 11.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45711781657185124		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.45711781657185124 | validation: 0.3934916344333733]
	TIME [epoch: 11.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42509481262013293		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.42509481262013293 | validation: 0.4140989155344514]
	TIME [epoch: 11.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4033209471059866		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.4033209471059866 | validation: 0.3761472412821546]
	TIME [epoch: 11.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34601145469691297		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.34601145469691297 | validation: 0.38860155049092165]
	TIME [epoch: 11.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3686699261945409		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.3686699261945409 | validation: 0.41836657678609307]
	TIME [epoch: 11.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5258812557474668		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.5258812557474668 | validation: 0.5645709460088295]
	TIME [epoch: 11.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47582741940163553		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.47582741940163553 | validation: 0.8426433765761323]
	TIME [epoch: 11.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48698131330873184		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.48698131330873184 | validation: 0.3973727956314083]
	TIME [epoch: 11.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4279837285438547		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.4279837285438547 | validation: 0.3556567064243603]
	TIME [epoch: 11.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4264154160277459		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.4264154160277459 | validation: 0.3960138141125045]
	TIME [epoch: 11.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4287589456527884		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.4287589456527884 | validation: 0.4318764457980385]
	TIME [epoch: 11.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4325682279113968		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.4325682279113968 | validation: 0.47000186961243673]
	TIME [epoch: 11.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42148832987782225		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.42148832987782225 | validation: 1.3996886711386387]
	TIME [epoch: 11.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6203845479543569		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.6203845479543569 | validation: 0.7416819154998643]
	TIME [epoch: 11.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49749530437618794		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.49749530437618794 | validation: 0.4055618125968461]
	TIME [epoch: 11.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4188028891144353		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.4188028891144353 | validation: 0.43469174980945524]
	TIME [epoch: 11.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4168796133636316		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.4168796133636316 | validation: 0.5044834829374231]
	TIME [epoch: 11.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6138017819050567		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.6138017819050567 | validation: 0.6282624076093699]
	TIME [epoch: 11.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5181845000649318		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.5181845000649318 | validation: 0.6990571406791729]
	TIME [epoch: 11.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4683528024269893		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.4683528024269893 | validation: 0.5108069656698202]
	TIME [epoch: 11.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41408538834540415		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.41408538834540415 | validation: 0.4788825446458565]
	TIME [epoch: 11.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40589929320883655		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.40589929320883655 | validation: 0.38733490144832483]
	TIME [epoch: 11.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38173850032077283		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.38173850032077283 | validation: 0.35993287034303445]
	TIME [epoch: 11.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3190370135095637		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.3190370135095637 | validation: 0.35176997377972824]
	TIME [epoch: 11.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36076171251564654		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.36076171251564654 | validation: 0.34926660147981614]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34745380943248416		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.34745380943248416 | validation: 0.38693854853080134]
	TIME [epoch: 11.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3520863371189854		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.3520863371189854 | validation: 0.35442434838354003]
	TIME [epoch: 11.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3692817153360915		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.3692817153360915 | validation: 0.4978725434245672]
	TIME [epoch: 11.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3632203343079524		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.3632203343079524 | validation: 0.41899074785108725]
	TIME [epoch: 11.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36668423626568347		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.36668423626568347 | validation: 0.9156991508807869]
	TIME [epoch: 11.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5946124330411637		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.5946124330411637 | validation: 0.650726111728724]
	TIME [epoch: 11.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9835010376755654		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.9835010376755654 | validation: 0.8807107904446134]
	TIME [epoch: 11.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.542181238783062		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.542181238783062 | validation: 0.3377876509687775]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_225.pth
	Model improved!!!
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31569439422269596		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.31569439422269596 | validation: 0.36309141486966445]
	TIME [epoch: 11.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33436930635028506		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.33436930635028506 | validation: 0.37442066485876674]
	TIME [epoch: 11.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.006177106305263		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.006177106305263 | validation: 0.38287567454653526]
	TIME [epoch: 11.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31370487595160185		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.31370487595160185 | validation: 0.46543278751429806]
	TIME [epoch: 11.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5317592247380627		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.5317592247380627 | validation: 0.4504460534553014]
	TIME [epoch: 11.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36982895714384845		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.36982895714384845 | validation: 0.29831531346496265]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2689415648225381		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.2689415648225381 | validation: 0.31709830414262175]
	TIME [epoch: 11.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4567831209281601		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.4567831209281601 | validation: 0.863975404595627]
	TIME [epoch: 11.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5107115030405663		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.5107115030405663 | validation: 0.4737455693833883]
	TIME [epoch: 11.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3356208271644877		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.3356208271644877 | validation: 0.2947713527174822]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32352310191217326		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.32352310191217326 | validation: 0.4396577874324252]
	TIME [epoch: 11.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3258797612443799		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.3258797612443799 | validation: 0.37626952768479255]
	TIME [epoch: 11.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31514124832840734		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.31514124832840734 | validation: 0.3595035477477768]
	TIME [epoch: 11.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3102010832156329		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.3102010832156329 | validation: 0.3142162163033641]
	TIME [epoch: 11.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2923603186405391		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.2923603186405391 | validation: 0.3905474451853284]
	TIME [epoch: 11.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3151779667381197		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.3151779667381197 | validation: 0.3157870594495432]
	TIME [epoch: 11.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3066277660331725		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.3066277660331725 | validation: 0.3931834783786057]
	TIME [epoch: 11.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30332207042047066		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.30332207042047066 | validation: 0.3400191347014133]
	TIME [epoch: 11.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29302451206069186		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.29302451206069186 | validation: 0.5565402414301152]
	TIME [epoch: 11.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3881525718995182		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.3881525718995182 | validation: 0.41598775284461953]
	TIME [epoch: 11.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.375280779836092		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.375280779836092 | validation: 0.3211176480456153]
	TIME [epoch: 11.6 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3427443210265912		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.3427443210265912 | validation: 0.3866111852222264]
	TIME [epoch: 11.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38547019204781274		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.38547019204781274 | validation: 0.3238671120475757]
	TIME [epoch: 11.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3177284258135533		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.3177284258135533 | validation: 0.629513856299305]
	TIME [epoch: 11.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.04124892312486		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.04124892312486 | validation: 0.5597324962532221]
	TIME [epoch: 11.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4378434933439453		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.4378434933439453 | validation: 0.33370342809640335]
	TIME [epoch: 11.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3319073407934594		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.3319073407934594 | validation: 0.7000677563592376]
	TIME [epoch: 11.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4916424870033129		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.4916424870033129 | validation: 0.40416417700555146]
	TIME [epoch: 11.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29502394184305675		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.29502394184305675 | validation: 0.3512456750950488]
	TIME [epoch: 11.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27576409755273823		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.27576409755273823 | validation: 0.5156068080804773]
	TIME [epoch: 11.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3585651141428729		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.3585651141428729 | validation: 0.2619940096390034]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2461412539138057		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.2461412539138057 | validation: 0.30140043171750036]
	TIME [epoch: 11.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2951443829645431		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.2951443829645431 | validation: 0.2776593155928177]
	TIME [epoch: 11.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2554601393508693		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.2554601393508693 | validation: 0.2610285504484324]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3061518720009995		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.3061518720009995 | validation: 0.3278662185960501]
	TIME [epoch: 11.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3146502199365499		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.3146502199365499 | validation: 0.3903815811560699]
	TIME [epoch: 11.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3534691681631694		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.3534691681631694 | validation: 0.3795900685446134]
	TIME [epoch: 11.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3389037044584099		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.3389037044584099 | validation: 0.28860561992095]
	TIME [epoch: 11.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34757200052481185		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.34757200052481185 | validation: 0.39316034035679975]
	TIME [epoch: 11.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1854158096670275		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.1854158096670275 | validation: 0.5657540819559346]
	TIME [epoch: 11.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32734376386238623		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.32734376386238623 | validation: 0.2807640209261563]
	TIME [epoch: 11.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30493601623063704		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.30493601623063704 | validation: 0.25132018301678716]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38404350038956214		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.38404350038956214 | validation: 0.7646326354910943]
	TIME [epoch: 11.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4578432758802635		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.4578432758802635 | validation: 0.37935352311934883]
	TIME [epoch: 11.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2917169921361744		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.2917169921361744 | validation: 0.3629174436236093]
	TIME [epoch: 11.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39551920272386465		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.39551920272386465 | validation: 0.3674755195943313]
	TIME [epoch: 11.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2855959161790408		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.2855959161790408 | validation: 0.3212508885186733]
	TIME [epoch: 11.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35306216241259		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.35306216241259 | validation: 0.3910059033540928]
	TIME [epoch: 11.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3087385438043443		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.3087385438043443 | validation: 0.308269007011215]
	TIME [epoch: 11.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27023162178586874		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.27023162178586874 | validation: 0.23325288287614868]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_275.pth
	Model improved!!!
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3293117785804268		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.3293117785804268 | validation: 0.5921021755766922]
	TIME [epoch: 11.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3345573736429732		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.3345573736429732 | validation: 0.2711665393898561]
	TIME [epoch: 11.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27732888765119135		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.27732888765119135 | validation: 0.346090023897558]
	TIME [epoch: 11.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2935850520817219		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.2935850520817219 | validation: 0.39317060089327144]
	TIME [epoch: 11.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31879985574849123		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.31879985574849123 | validation: 0.36660141453184425]
	TIME [epoch: 11.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27647938199141925		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.27647938199141925 | validation: 0.4165130047240382]
	TIME [epoch: 11.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3014208519180751		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.3014208519180751 | validation: 0.26312376824606615]
	TIME [epoch: 11.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2512874241396722		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.2512874241396722 | validation: 0.31496643900023635]
	TIME [epoch: 11.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3745268716297213		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.3745268716297213 | validation: 0.3818425092443667]
	TIME [epoch: 11.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30277463320034914		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.30277463320034914 | validation: 0.38560635560489515]
	TIME [epoch: 11.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28025357517637217		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.28025357517637217 | validation: 0.4389238133309861]
	TIME [epoch: 11.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3885747678305276		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.3885747678305276 | validation: 0.6477571882172442]
	TIME [epoch: 11.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.453865925658306		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.453865925658306 | validation: 0.45727611667267254]
	TIME [epoch: 11.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36815378995417536		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.36815378995417536 | validation: 0.42857027337603415]
	TIME [epoch: 11.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3122628971522198		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.3122628971522198 | validation: 0.5570234429308449]
	TIME [epoch: 11.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4371007820692785		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.4371007820692785 | validation: 0.2978640644390272]
	TIME [epoch: 11.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.274475607238336		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.274475607238336 | validation: 0.4174070509082378]
	TIME [epoch: 11.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3395507359207206		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.3395507359207206 | validation: 0.22687983387672106]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_293.pth
	Model improved!!!
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2563827887572149		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.2563827887572149 | validation: 0.2791903308390535]
	TIME [epoch: 11.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31284740971475344		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.31284740971475344 | validation: 0.2937019261501738]
	TIME [epoch: 11.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26943811747539537		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.26943811747539537 | validation: 0.2845890112595375]
	TIME [epoch: 11.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28939709643159506		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.28939709643159506 | validation: 0.40952532890884935]
	TIME [epoch: 11.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3088369521329901		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.3088369521329901 | validation: 0.24704836586768292]
	TIME [epoch: 11.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24915625884629472		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.24915625884629472 | validation: 0.40681010404866785]
	TIME [epoch: 11.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40652497623178063		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.40652497623178063 | validation: 0.31610124862834804]
	TIME [epoch: 11.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3087237086343983		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.3087237086343983 | validation: 0.2785087273956166]
	TIME [epoch: 11.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2873625051177226		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.2873625051177226 | validation: 0.26303717971123897]
	TIME [epoch: 11.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21994690206934578		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.21994690206934578 | validation: 0.3808214116807265]
	TIME [epoch: 11.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39817077578388244		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.39817077578388244 | validation: 0.29777014168985966]
	TIME [epoch: 11.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25831480919296096		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.25831480919296096 | validation: 0.23818858363364684]
	TIME [epoch: 11.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24869949342568654		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.24869949342568654 | validation: 0.2952641500080974]
	TIME [epoch: 11.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28068507750204286		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.28068507750204286 | validation: 0.2640131429407085]
	TIME [epoch: 11.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23181999880130993		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.23181999880130993 | validation: 0.20671454464664885]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_308.pth
	Model improved!!!
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22103008714776098		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.22103008714776098 | validation: 0.21799819144845958]
	TIME [epoch: 11.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2343931235792448		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.2343931235792448 | validation: 0.3678356686910964]
	TIME [epoch: 11.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3313269370692063		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.3313269370692063 | validation: 0.4145117916620228]
	TIME [epoch: 11.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27695090663029537		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.27695090663029537 | validation: 0.25555875702937647]
	TIME [epoch: 11.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34824756467283335		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.34824756467283335 | validation: 0.7140115051303749]
	TIME [epoch: 11.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4030131055151773		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.4030131055151773 | validation: 0.3470154060349158]
	TIME [epoch: 11.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2883835808894544		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.2883835808894544 | validation: 0.5682618845694706]
	TIME [epoch: 11.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.407761263416552		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.407761263416552 | validation: 0.2629092979472124]
	TIME [epoch: 11.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26129635150489333		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.26129635150489333 | validation: 0.5265670241668973]
	TIME [epoch: 11.6 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46066430913303563		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.46066430913303563 | validation: 0.45827792851109506]
	TIME [epoch: 11.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34976120374711833		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.34976120374711833 | validation: 0.2930749132022514]
	TIME [epoch: 11.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30533457565440386		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.30533457565440386 | validation: 0.393414186466898]
	TIME [epoch: 11.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3088956829456039		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.3088956829456039 | validation: 0.6585472703201863]
	TIME [epoch: 11.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38132165224463255		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.38132165224463255 | validation: 0.4059295439322531]
	TIME [epoch: 11.6 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2916446058040972		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.2916446058040972 | validation: 0.3663435995205199]
	TIME [epoch: 11.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29303060937875725		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.29303060937875725 | validation: 0.2976206128692689]
	TIME [epoch: 11.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22421346841116213		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.22421346841116213 | validation: 0.2503676023035519]
	TIME [epoch: 11.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23461744990330716		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.23461744990330716 | validation: 0.27168952964992765]
	TIME [epoch: 11.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33559927556306207		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.33559927556306207 | validation: 0.268509766576842]
	TIME [epoch: 11.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5222200172666266		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.5222200172666266 | validation: 0.6239345151230142]
	TIME [epoch: 11.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4279493764018608		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.4279493764018608 | validation: 0.35779309900155354]
	TIME [epoch: 11.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30900857095830514		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.30900857095830514 | validation: 0.8077793432569844]
	TIME [epoch: 11.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4726466286454081		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.4726466286454081 | validation: 0.30696071268467934]
	TIME [epoch: 11.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23707118201325833		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.23707118201325833 | validation: 0.21407429381251508]
	TIME [epoch: 11.6 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2299032966043221		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.2299032966043221 | validation: 0.3375079022866993]
	TIME [epoch: 11.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28380791244052955		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.28380791244052955 | validation: 0.23375693503173056]
	TIME [epoch: 11.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25316826826197253		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.25316826826197253 | validation: 0.2580597282998853]
	TIME [epoch: 11.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22231129253310145		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.22231129253310145 | validation: 0.1754703566893341]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1768740382057859		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.1768740382057859 | validation: 0.25876633371189295]
	TIME [epoch: 11.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44174036443383324		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.44174036443383324 | validation: 0.30407593140959427]
	TIME [epoch: 11.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3508745322850726		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.3508745322850726 | validation: 0.2919852265031481]
	TIME [epoch: 11.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22939033575430173		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.22939033575430173 | validation: 0.3403771021020184]
	TIME [epoch: 11.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3963065808818128		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.3963065808818128 | validation: 0.20480871292598543]
	TIME [epoch: 11.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20940932434916631		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.20940932434916631 | validation: 0.24673648021074834]
	TIME [epoch: 11.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22811593834950855		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.22811593834950855 | validation: 0.22618908651100952]
	TIME [epoch: 11.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26905381325038474		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.26905381325038474 | validation: 0.2722338663657443]
	TIME [epoch: 11.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26475275855554276		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.26475275855554276 | validation: 0.3546535748433609]
	TIME [epoch: 11.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4186397184871363		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.4186397184871363 | validation: 0.2960890288256249]
	TIME [epoch: 11.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23878839193485113		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.23878839193485113 | validation: 0.23750969129758637]
	TIME [epoch: 11.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22953235966320829		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.22953235966320829 | validation: 0.25560210312370557]
	TIME [epoch: 11.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24567453520885202		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.24567453520885202 | validation: 0.3048146712788078]
	TIME [epoch: 11.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3385797880793093		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.3385797880793093 | validation: 0.21398716719936253]
	TIME [epoch: 11.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2434458458855002		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.2434458458855002 | validation: 0.39941472682602125]
	TIME [epoch: 11.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4354735286405201		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.4354735286405201 | validation: 0.30012399736143436]
	TIME [epoch: 11.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31224131222445833		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.31224131222445833 | validation: 0.33548195315122104]
	TIME [epoch: 11.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24354051224403528		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.24354051224403528 | validation: 0.3277189829046037]
	TIME [epoch: 11.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2627235329752028		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.2627235329752028 | validation: 0.21584862740684074]
	TIME [epoch: 11.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18815527446745572		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.18815527446745572 | validation: 0.2680152310221267]
	TIME [epoch: 11.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2299120887996305		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.2299120887996305 | validation: 0.29785763521768394]
	TIME [epoch: 11.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3136713660620105		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.3136713660620105 | validation: 0.2884698541491897]
	TIME [epoch: 11.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3003833735920977		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.3003833735920977 | validation: 0.4170508652996526]
	TIME [epoch: 11.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27458941147969296		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.27458941147969296 | validation: 0.2656688926400046]
	TIME [epoch: 11.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22392281612608436		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.22392281612608436 | validation: 0.17499404521204986]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_361.pth
	Model improved!!!
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22724783009615787		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.22724783009615787 | validation: 0.34255160527920625]
	TIME [epoch: 11.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30453644361562154		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.30453644361562154 | validation: 0.24527249901901968]
	TIME [epoch: 11.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2477788847434353		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.2477788847434353 | validation: 0.3005427335513206]
	TIME [epoch: 11.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2195898633002486		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.2195898633002486 | validation: 0.23177705506182442]
	TIME [epoch: 11.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19519353628110067		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.19519353628110067 | validation: 0.23973202741029373]
	TIME [epoch: 11.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3007974476201723		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.3007974476201723 | validation: 0.21777584305894215]
	TIME [epoch: 11.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28378227818908897		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.28378227818908897 | validation: 0.25833329965778484]
	TIME [epoch: 11.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2085791751752518		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.2085791751752518 | validation: 0.2237034415319517]
	TIME [epoch: 11.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20300498975542802		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.20300498975542802 | validation: 0.22916931113934944]
	TIME [epoch: 11.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2044406354295305		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.2044406354295305 | validation: 0.17896897565809788]
	TIME [epoch: 11.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19081066804896255		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.19081066804896255 | validation: 0.2700657640014037]
	TIME [epoch: 11.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26579797907780006		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.26579797907780006 | validation: 0.1969481143099062]
	TIME [epoch: 11.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.279996187655736		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.279996187655736 | validation: 0.2763448661308457]
	TIME [epoch: 11.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22348384543245786		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.22348384543245786 | validation: 0.2656433576466563]
	TIME [epoch: 11.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20035598435204033		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.20035598435204033 | validation: 0.17175356098327182]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_376.pth
	Model improved!!!
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17986648340651556		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.17986648340651556 | validation: 0.2687688501093961]
	TIME [epoch: 11.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2853509041124879		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.2853509041124879 | validation: 0.2730637809711547]
	TIME [epoch: 11.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24383261128012929		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.24383261128012929 | validation: 0.23400359477671606]
	TIME [epoch: 11.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25741816345242013		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.25741816345242013 | validation: 0.22248465889428182]
	TIME [epoch: 11.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17417673326255545		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.17417673326255545 | validation: 0.2624058831826295]
	TIME [epoch: 11.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21588096782483748		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.21588096782483748 | validation: 0.24649621017541865]
	TIME [epoch: 11.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23292849334157562		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.23292849334157562 | validation: 0.3303488001546138]
	TIME [epoch: 11.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2300375798942944		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.2300375798942944 | validation: 0.40153331049231655]
	TIME [epoch: 11.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32155118613590994		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.32155118613590994 | validation: 0.24832800834753962]
	TIME [epoch: 11.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18732130072102926		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.18732130072102926 | validation: 0.20114607623726094]
	TIME [epoch: 11.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2006073349792786		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.2006073349792786 | validation: 0.6617551345315624]
	TIME [epoch: 11.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3103680531407274		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.3103680531407274 | validation: 0.2162053329737308]
	TIME [epoch: 11.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18610985575167577		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.18610985575167577 | validation: 0.20275197611712314]
	TIME [epoch: 11.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22090109255153045		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.22090109255153045 | validation: 0.1759402416079338]
	TIME [epoch: 11.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19443344521331196		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.19443344521331196 | validation: 0.2812549848343294]
	TIME [epoch: 11.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24203158971508051		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.24203158971508051 | validation: 0.24725514830278172]
	TIME [epoch: 11.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21378131542753243		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.21378131542753243 | validation: 0.21465052919131336]
	TIME [epoch: 11.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30069316164917514		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.30069316164917514 | validation: 0.41828659985751027]
	TIME [epoch: 11.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3181714361499209		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.3181714361499209 | validation: 0.23213348373949616]
	TIME [epoch: 11.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3458626105520789		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.3458626105520789 | validation: 0.30005312344671514]
	TIME [epoch: 11.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31385173420356294		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.31385173420356294 | validation: 0.3656687545218867]
	TIME [epoch: 11.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41447806148887845		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.41447806148887845 | validation: 0.2560771595026021]
	TIME [epoch: 11.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26866239401152925		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.26866239401152925 | validation: 0.32116311398867564]
	TIME [epoch: 11.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3982953310085456		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.3982953310085456 | validation: 0.2971194539799415]
	TIME [epoch: 11.6 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2908971769548202		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.2908971769548202 | validation: 0.2667303579463666]
	TIME [epoch: 11.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22036461214992842		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.22036461214992842 | validation: 0.20744310339106092]
	TIME [epoch: 11.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19910576048370043		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.19910576048370043 | validation: 0.23492696688677392]
	TIME [epoch: 11.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21031951354849898		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.21031951354849898 | validation: 0.36614267915578147]
	TIME [epoch: 11.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24837009013519842		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.24837009013519842 | validation: 0.18651677804214079]
	TIME [epoch: 11.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2783069397569108		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.2783069397569108 | validation: 0.20704869123602193]
	TIME [epoch: 11.6 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2516728603281571		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.2516728603281571 | validation: 0.3141519293565916]
	TIME [epoch: 11.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2387192887440671		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.2387192887440671 | validation: 0.20364420138112724]
	TIME [epoch: 11.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23157266882832506		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.23157266882832506 | validation: 0.39290449118341847]
	TIME [epoch: 11.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2877450300940437		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.2877450300940437 | validation: 0.2548651142784836]
	TIME [epoch: 11.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22986823061682857		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.22986823061682857 | validation: 0.24691042275767458]
	TIME [epoch: 11.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2325174971757069		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.2325174971757069 | validation: 0.28129865001067883]
	TIME [epoch: 11.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2429009916906158		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.2429009916906158 | validation: 0.2044951022711328]
	TIME [epoch: 11.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1914479443546122		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.1914479443546122 | validation: 0.1742646277165818]
	TIME [epoch: 11.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17695291240414524		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.17695291240414524 | validation: 0.22590528562867615]
	TIME [epoch: 11.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2293271151303778		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.2293271151303778 | validation: 0.4008764529789633]
	TIME [epoch: 11.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3421287054216822		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.3421287054216822 | validation: 0.2676529975658239]
	TIME [epoch: 11.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20627799293126178		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.20627799293126178 | validation: 0.1899139947155306]
	TIME [epoch: 11.6 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2122256949517805		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.2122256949517805 | validation: 0.1995575184905039]
	TIME [epoch: 11.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24818352125066817		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.24818352125066817 | validation: 0.2820366239030147]
	TIME [epoch: 11.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2538078932795978		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.2538078932795978 | validation: 0.2665500408026976]
	TIME [epoch: 11.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23032189870014258		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.23032189870014258 | validation: 0.2561305554860753]
	TIME [epoch: 11.5 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.201008666429978		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.201008666429978 | validation: 0.19106908839252196]
	TIME [epoch: 11.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15459670706405287		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.15459670706405287 | validation: 0.1824966857796039]
	TIME [epoch: 11.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18951976259577466		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.18951976259577466 | validation: 0.2004641701114782]
	TIME [epoch: 11.6 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20153457661710736		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.20153457661710736 | validation: 0.20915314343591518]
	TIME [epoch: 11.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1727543355672735		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.1727543355672735 | validation: 0.2097483188610969]
	TIME [epoch: 11.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20943384340988166		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.20943384340988166 | validation: 0.22080293301555162]
	TIME [epoch: 11.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21767756963217794		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.21767756963217794 | validation: 0.282459468805698]
	TIME [epoch: 11.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.218683192221816		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.218683192221816 | validation: 0.2557068791697386]
	TIME [epoch: 11.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19677583498710727		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.19677583498710727 | validation: 0.21161565014196448]
	TIME [epoch: 11.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20689964247613907		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.20689964247613907 | validation: 0.26463358901433726]
	TIME [epoch: 11.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22312073655748335		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.22312073655748335 | validation: 0.25710456878126264]
	TIME [epoch: 11.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1989748360450908		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.1989748360450908 | validation: 0.23253220111686063]
	TIME [epoch: 11.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24715419702430647		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.24715419702430647 | validation: 0.24381499495279296]
	TIME [epoch: 11.5 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23523439238241442		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.23523439238241442 | validation: 0.3053832741967788]
	TIME [epoch: 11.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2175295043158086		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.2175295043158086 | validation: 0.17765612426043167]
	TIME [epoch: 11.6 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549494161843541		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.1549494161843541 | validation: 0.19050746185561346]
	TIME [epoch: 11.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21084586544043998		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.21084586544043998 | validation: 0.24425396515954378]
	TIME [epoch: 11.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23142233667072898		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.23142233667072898 | validation: 0.234311298473109]
	TIME [epoch: 11.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19358637335729223		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.19358637335729223 | validation: 0.2168577805339914]
	TIME [epoch: 11.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670200341021043		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.1670200341021043 | validation: 0.2326376315207074]
	TIME [epoch: 11.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17917242569042222		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.17917242569042222 | validation: 0.21211067342635553]
	TIME [epoch: 11.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19298779474343236		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.19298779474343236 | validation: 0.19258910267154336]
	TIME [epoch: 11.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18022872213721863		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.18022872213721863 | validation: 0.20505359177894583]
	TIME [epoch: 11.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22525628442205975		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.22525628442205975 | validation: 0.25010057448309864]
	TIME [epoch: 11.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22214441797391515		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.22214441797391515 | validation: 0.20702661286434842]
	TIME [epoch: 11.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17742121580814346		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.17742121580814346 | validation: 0.21910960646410382]
	TIME [epoch: 11.6 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19450920131402943		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.19450920131402943 | validation: 0.25671377469256307]
	TIME [epoch: 11.5 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23749335195052235		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.23749335195052235 | validation: 0.20795976063845822]
	TIME [epoch: 11.6 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2730589388298676		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.2730589388298676 | validation: 0.23080388879109354]
	TIME [epoch: 11.6 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2099063978152158		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.2099063978152158 | validation: 0.20316793833778535]
	TIME [epoch: 11.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19062751079730567		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.19062751079730567 | validation: 0.21097621117486845]
	TIME [epoch: 11.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16636971634876643		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.16636971634876643 | validation: 0.16088299194742484]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_454.pth
	Model improved!!!
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1564442053464925		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.1564442053464925 | validation: 0.23972768705311162]
	TIME [epoch: 11.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21986136387971433		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.21986136387971433 | validation: 0.18999182724973854]
	TIME [epoch: 11.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20307608130301433		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.20307608130301433 | validation: 0.2462698260008968]
	TIME [epoch: 11.6 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1727940394700389		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.1727940394700389 | validation: 0.20840719971143076]
	TIME [epoch: 11.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1932411827988649		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.1932411827988649 | validation: 0.20760066425015325]
	TIME [epoch: 11.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2163476718509107		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.2163476718509107 | validation: 0.2315473055250869]
	TIME [epoch: 11.6 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2793100171411219		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.2793100171411219 | validation: 0.25793371056337877]
	TIME [epoch: 11.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2536113626194609		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.2536113626194609 | validation: 0.19944058140908516]
	TIME [epoch: 11.5 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16903460275741614		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.16903460275741614 | validation: 0.20367416650694192]
	TIME [epoch: 11.6 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20732055798507298		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.20732055798507298 | validation: 0.32260171459170806]
	TIME [epoch: 11.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2302436510696005		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.2302436510696005 | validation: 0.40030559132443655]
	TIME [epoch: 11.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23242721278074113		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.23242721278074113 | validation: 0.16412518950359115]
	TIME [epoch: 11.6 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1559813180348024		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.1559813180348024 | validation: 0.2443240185413346]
	TIME [epoch: 11.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21071303384291803		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.21071303384291803 | validation: 0.2372088099034785]
	TIME [epoch: 11.5 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17818132699073103		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.17818132699073103 | validation: 0.23670339773114663]
	TIME [epoch: 11.6 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20226266283768654		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.20226266283768654 | validation: 0.248920771219304]
	TIME [epoch: 11.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16455983307032984		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.16455983307032984 | validation: 0.19883172140974267]
	TIME [epoch: 11.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1505137075253385		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.1505137075253385 | validation: 0.19930447414618585]
	TIME [epoch: 11.6 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16524789852423705		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.16524789852423705 | validation: 0.2862412503470717]
	TIME [epoch: 11.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20119558135563437		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.20119558135563437 | validation: 0.18311714716803526]
	TIME [epoch: 11.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14251316954759682		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.14251316954759682 | validation: 0.19583587813397796]
	TIME [epoch: 11.6 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1568342886105071		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.1568342886105071 | validation: 0.2003206712224131]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18991258545664558		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.18991258545664558 | validation: 0.19655539228362112]
	TIME [epoch: 11.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17629741019095663		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.17629741019095663 | validation: 0.5315709218780169]
	TIME [epoch: 11.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48087420744620096		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.48087420744620096 | validation: 0.5001300959564438]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34733433859242335		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.34733433859242335 | validation: 0.32433223968297903]
	TIME [epoch: 11.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2562905256806907		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.2562905256806907 | validation: 0.2706263615444034]
	TIME [epoch: 11.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.254879832270706		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.254879832270706 | validation: 0.2554258509999881]
	TIME [epoch: 11.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2917609023358073		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.2917609023358073 | validation: 0.1670611843328141]
	TIME [epoch: 11.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19406163391573764		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.19406163391573764 | validation: 0.19752810175101432]
	TIME [epoch: 11.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30382694455855586		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.30382694455855586 | validation: 0.44852946792060183]
	TIME [epoch: 11.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23961990013180037		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.23961990013180037 | validation: 0.21701716534734394]
	TIME [epoch: 11.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17658787126100828		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.17658787126100828 | validation: 0.17639588136596565]
	TIME [epoch: 11.6 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2068850798394701		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.2068850798394701 | validation: 0.23376943414700727]
	TIME [epoch: 11.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18848326791653242		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.18848326791653242 | validation: 0.20972025261994895]
	TIME [epoch: 11.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18650465981040215		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.18650465981040215 | validation: 0.21680828235747396]
	TIME [epoch: 11.6 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20108278947890623		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.20108278947890623 | validation: 0.18385553507746275]
	TIME [epoch: 11.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1562211840003189		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.1562211840003189 | validation: 0.19267887650109466]
	TIME [epoch: 11.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19853574756034656		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.19853574756034656 | validation: 0.19959162865849897]
	TIME [epoch: 11.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16038320933310424		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.16038320933310424 | validation: 0.1591966325565366]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_494.pth
	Model improved!!!
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19957466128035561		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.19957466128035561 | validation: 0.2622560682764589]
	TIME [epoch: 11.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17663941231681696		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.17663941231681696 | validation: 0.16437017186051014]
	TIME [epoch: 11.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14167715290649752		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.14167715290649752 | validation: 0.17874962368850345]
	TIME [epoch: 11.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1580875026737756		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.1580875026737756 | validation: 0.2331268765899822]
	TIME [epoch: 11.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1637353837096331		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.1637353837096331 | validation: 0.1372038373733514]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_499.pth
	Model improved!!!
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21533031730932573		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.21533031730932573 | validation: 0.1846411726390575]
	TIME [epoch: 11.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1435874747354579		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.1435874747354579 | validation: 0.20778389173551723]
	TIME [epoch: 11.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16386763201784846		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.16386763201784846 | validation: 0.19302017103701882]
	TIME [epoch: 11.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18039875567092048		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.18039875567092048 | validation: 0.2314431907658831]
	TIME [epoch: 11.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18992850603044453		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.18992850603044453 | validation: 0.16569938557407654]
	TIME [epoch: 11.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20185325199208692		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.20185325199208692 | validation: 0.15108206616854453]
	TIME [epoch: 11.6 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13917950073093438		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.13917950073093438 | validation: 0.1581325928864137]
	TIME [epoch: 11.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14122149411255358		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.14122149411255358 | validation: 0.25961780518704874]
	TIME [epoch: 11.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16945579843114672		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.16945579843114672 | validation: 0.1752191320910152]
	TIME [epoch: 11.6 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15247815800814274		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.15247815800814274 | validation: 0.18166450660665104]
	TIME [epoch: 11.6 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20090577604534182		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.20090577604534182 | validation: 0.28928830229165486]
	TIME [epoch: 11.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20096810031640602		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.20096810031640602 | validation: 0.20568343421986846]
	TIME [epoch: 11.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27189487447528604		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.27189487447528604 | validation: 0.32552540089850385]
	TIME [epoch: 11.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26649994487030754		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.26649994487030754 | validation: 0.32228528101305404]
	TIME [epoch: 11.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20154729643711902		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.20154729643711902 | validation: 0.21891670789295023]
	TIME [epoch: 11.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15817543380047286		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.15817543380047286 | validation: 0.17248347929979957]
	TIME [epoch: 11.6 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15006928130689645		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.15006928130689645 | validation: 0.1701736843347558]
	TIME [epoch: 11.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1519357934024364		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.1519357934024364 | validation: 0.23089332823685219]
	TIME [epoch: 11.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1854954954182702		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.1854954954182702 | validation: 0.18612513016603566]
	TIME [epoch: 11.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1843354367736786		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.1843354367736786 | validation: 0.18954677152956148]
	TIME [epoch: 11.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24918961343469875		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.24918961343469875 | validation: 0.1924337156816925]
	TIME [epoch: 11.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16781874042396136		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.16781874042396136 | validation: 0.22932378812086754]
	TIME [epoch: 11.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18946017728032852		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.18946017728032852 | validation: 0.1944220076453702]
	TIME [epoch: 11.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14798121940139738		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.14798121940139738 | validation: 0.15439700143537397]
	TIME [epoch: 11.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14724912241002175		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.14724912241002175 | validation: 0.17428964734547578]
	TIME [epoch: 11.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1835300284900627		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.1835300284900627 | validation: 0.2392232607178823]
	TIME [epoch: 11.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17874121651272779		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.17874121651272779 | validation: 0.1517732822321712]
	TIME [epoch: 11.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17668797623241755		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.17668797623241755 | validation: 0.3181604248356952]
	TIME [epoch: 11.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22420082226649765		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.22420082226649765 | validation: 0.1551889416463841]
	TIME [epoch: 11.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16529951875310617		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.16529951875310617 | validation: 0.16472788429968918]
	TIME [epoch: 11.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13357072055437086		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.13357072055437086 | validation: 0.14808885772128413]
	TIME [epoch: 11.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11836597822527432		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.11836597822527432 | validation: 0.165481832603431]
	TIME [epoch: 11.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12469750222176314		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.12469750222176314 | validation: 0.14782563931054035]
	TIME [epoch: 11.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11716588218308793		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.11716588218308793 | validation: 0.142797480982404]
	TIME [epoch: 11.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1658026347718134		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.1658026347718134 | validation: 0.14672951515493915]
	TIME [epoch: 11.6 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15764127619997678		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.15764127619997678 | validation: 0.15610003657014626]
	TIME [epoch: 11.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16485674202483286		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.16485674202483286 | validation: 0.2144311364439492]
	TIME [epoch: 11.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.170197717765885		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.170197717765885 | validation: 0.1688034614587178]
	TIME [epoch: 11.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14543375713160364		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.14543375713160364 | validation: 0.12047922359760042]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_538.pth
	Model improved!!!
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10254286890398591		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.10254286890398591 | validation: 0.18154207216513732]
	TIME [epoch: 11.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1287256382149763		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.1287256382149763 | validation: 0.11891157231778317]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_540.pth
	Model improved!!!
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17480558818538772		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.17480558818538772 | validation: 0.2037877663979499]
	TIME [epoch: 11.6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16953394657451934		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.16953394657451934 | validation: 0.19387241697941293]
	TIME [epoch: 11.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1579903786654287		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.1579903786654287 | validation: 0.17368400171189508]
	TIME [epoch: 11.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1355653181047778		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.1355653181047778 | validation: 0.1411983970128077]
	TIME [epoch: 11.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11937652257417827		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.11937652257417827 | validation: 0.174892618607091]
	TIME [epoch: 11.6 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16565828937030364		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.16565828937030364 | validation: 0.22225024360368295]
	TIME [epoch: 11.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1847185817023439		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.1847185817023439 | validation: 0.19270890539605973]
	TIME [epoch: 11.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16530511460668043		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.16530511460668043 | validation: 0.1641419309836971]
	TIME [epoch: 11.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13592594765913552		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.13592594765913552 | validation: 0.15743718843843066]
	TIME [epoch: 11.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11456708872947732		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.11456708872947732 | validation: 0.16183257567349935]
	TIME [epoch: 11.6 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21026062174178017		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.21026062174178017 | validation: 0.2270122311736924]
	TIME [epoch: 11.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27387420168376897		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.27387420168376897 | validation: 0.30264490923071957]
	TIME [epoch: 11.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24830501284435905		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.24830501284435905 | validation: 0.35245106660939174]
	TIME [epoch: 11.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31213416873792843		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.31213416873792843 | validation: 0.3983980223693068]
	TIME [epoch: 11.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2880646242294128		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.2880646242294128 | validation: 0.27186318334679654]
	TIME [epoch: 11.6 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2328735343133806		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.2328735343133806 | validation: 0.27733606446461223]
	TIME [epoch: 11.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20670224139469529		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.20670224139469529 | validation: 0.2087413621983756]
	TIME [epoch: 11.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14745174892420138		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.14745174892420138 | validation: 0.2280280951705243]
	TIME [epoch: 11.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2622221152677947		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.2622221152677947 | validation: 0.37127190751725553]
	TIME [epoch: 11.6 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3447444469757144		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.3447444469757144 | validation: 0.3046572345874149]
	TIME [epoch: 11.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2444878762911178		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.2444878762911178 | validation: 0.2516355650883632]
	TIME [epoch: 11.6 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2986675607224135		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.2986675607224135 | validation: 0.4762728628271073]
	TIME [epoch: 11.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2966092538567365		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.2966092538567365 | validation: 0.28245944400001266]
	TIME [epoch: 11.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2374871974433302		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.2374871974433302 | validation: 0.2188758785617452]
	TIME [epoch: 11.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1417178742807751		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.1417178742807751 | validation: 0.13360143304182687]
	TIME [epoch: 11.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15649480732026566		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.15649480732026566 | validation: 0.19258062252993596]
	TIME [epoch: 11.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13429522667300334		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.13429522667300334 | validation: 0.17370229634379297]
	TIME [epoch: 11.6 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2586719226134874		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.2586719226134874 | validation: 0.2555140564600918]
	TIME [epoch: 11.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17184356983825963		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.17184356983825963 | validation: 0.1773366105505939]
	TIME [epoch: 11.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15961938426022182		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.15961938426022182 | validation: 0.14749278325030418]
	TIME [epoch: 11.6 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12786743640743145		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.12786743640743145 | validation: 0.16097407144571438]
	TIME [epoch: 11.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11927898104262528		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.11927898104262528 | validation: 0.20229707244763923]
	TIME [epoch: 11.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1614191655896608		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.1614191655896608 | validation: 0.13853243874797483]
	TIME [epoch: 11.6 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1208416036784457		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.1208416036784457 | validation: 0.16648197803628706]
	TIME [epoch: 11.6 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15489110836764725		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.15489110836764725 | validation: 0.1376687680348956]
	TIME [epoch: 11.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13667772998552663		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.13667772998552663 | validation: 0.1760902473177103]
	TIME [epoch: 11.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1672877922525851		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.1672877922525851 | validation: 0.1684655875478391]
	TIME [epoch: 11.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11875915607075528		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.11875915607075528 | validation: 0.09918555253413766]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_578.pth
	Model improved!!!
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10352255744271692		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.10352255744271692 | validation: 0.1183441316567367]
	TIME [epoch: 11.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08046844656467161		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.08046844656467161 | validation: 0.08342805769619181]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_580.pth
	Model improved!!!
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12090123070004288		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.12090123070004288 | validation: 0.2327327694378159]
	TIME [epoch: 11.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1787483087883882		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.1787483087883882 | validation: 0.1765735879205038]
	TIME [epoch: 11.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2208204873683386		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.2208204873683386 | validation: 0.3519336304502649]
	TIME [epoch: 11.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27445334003545624		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.27445334003545624 | validation: 0.2729631623729006]
	TIME [epoch: 11.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20826151687109376		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.20826151687109376 | validation: 0.18444813302114313]
	TIME [epoch: 11.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15018452662855167		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.15018452662855167 | validation: 0.16036001219994409]
	TIME [epoch: 11.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16033423718300363		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.16033423718300363 | validation: 0.1354079956575136]
	TIME [epoch: 11.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1393978563091087		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.1393978563091087 | validation: 0.18807550881940205]
	TIME [epoch: 11.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15855806418490853		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.15855806418490853 | validation: 0.17449784127254184]
	TIME [epoch: 11.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14090011422953772		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.14090011422953772 | validation: 0.2359933642958235]
	TIME [epoch: 11.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20748290206661424		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.20748290206661424 | validation: 0.2910887033203218]
	TIME [epoch: 11.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18640519528203206		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.18640519528203206 | validation: 0.12732523386336833]
	TIME [epoch: 11.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14292621409135842		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.14292621409135842 | validation: 0.13891225147269962]
	TIME [epoch: 11.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1170358772413102		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.1170358772413102 | validation: 0.1412221370691896]
	TIME [epoch: 11.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10433624558308931		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.10433624558308931 | validation: 0.12975123221951465]
	TIME [epoch: 11.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1032356264089385		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.1032356264089385 | validation: 0.09585230878348446]
	TIME [epoch: 11.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07816322006177584		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.07816322006177584 | validation: 0.11507595455800979]
	TIME [epoch: 11.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12489816661626645		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.12489816661626645 | validation: 0.08510370850499001]
	TIME [epoch: 11.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09478607520645144		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.09478607520645144 | validation: 0.12828251782361338]
	TIME [epoch: 11.6 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10508993306695769		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.10508993306695769 | validation: 0.20762181971086877]
	TIME [epoch: 11.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15844377477187885		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.15844377477187885 | validation: 0.2637667849320765]
	TIME [epoch: 11.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2040598627026501		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.2040598627026501 | validation: 0.1594953487057182]
	TIME [epoch: 11.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20379127687137683		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.20379127687137683 | validation: 0.13221008338112689]
	TIME [epoch: 11.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10538957011287176		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.10538957011287176 | validation: 0.0911693863445089]
	TIME [epoch: 11.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09389585025723286		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.09389585025723286 | validation: 0.13289817062350562]
	TIME [epoch: 11.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12873603656148605		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.12873603656148605 | validation: 0.1517779829095338]
	TIME [epoch: 11.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11269715825845208		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.11269715825845208 | validation: 0.10616499571930677]
	TIME [epoch: 11.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12176137226337261		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.12176137226337261 | validation: 0.11815245392615698]
	TIME [epoch: 11.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10326454284291985		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.10326454284291985 | validation: 0.10039349560365707]
	TIME [epoch: 11.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10617562102297609		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.10617562102297609 | validation: 0.10172331233062804]
	TIME [epoch: 11.6 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08347121034599869		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.08347121034599869 | validation: 0.15460100462637702]
	TIME [epoch: 11.6 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14394979629033164		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.14394979629033164 | validation: 0.13885162274215834]
	TIME [epoch: 11.6 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10191677795133218		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.10191677795133218 | validation: 0.1181160131756828]
	TIME [epoch: 11.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09983518111183207		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.09983518111183207 | validation: 0.16668364680988823]
	TIME [epoch: 11.6 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.127862945088457		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.127862945088457 | validation: 0.09976209706125982]
	TIME [epoch: 11.6 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07723844261868049		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.07723844261868049 | validation: 0.12628281690207124]
	TIME [epoch: 11.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1351941904177692		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.1351941904177692 | validation: 0.14103101451356376]
	TIME [epoch: 11.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11492736487144137		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.11492736487144137 | validation: 0.15515415955089215]
	TIME [epoch: 11.6 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10815269106955819		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.10815269106955819 | validation: 0.11916164169533794]
	TIME [epoch: 11.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.101521018552537		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.101521018552537 | validation: 0.11551961921856654]
	TIME [epoch: 11.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09744820275542962		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.09744820275542962 | validation: 0.11651291003919656]
	TIME [epoch: 11.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09769429215694082		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.09769429215694082 | validation: 0.09615495996090143]
	TIME [epoch: 11.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11294821702564381		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.11294821702564381 | validation: 0.10798266773735588]
	TIME [epoch: 11.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09780904922292881		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.09780904922292881 | validation: 0.12659006707823106]
	TIME [epoch: 11.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10971219488574932		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.10971219488574932 | validation: 0.08539761588210144]
	TIME [epoch: 11.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0791020615328735		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.0791020615328735 | validation: 0.06803623997670398]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_626.pth
	Model improved!!!
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06411226157990293		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.06411226157990293 | validation: 0.1593956035843385]
	TIME [epoch: 11.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15790019775820852		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.15790019775820852 | validation: 0.17043716887903343]
	TIME [epoch: 11.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1128964341827761		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.1128964341827761 | validation: 0.10212694606409117]
	TIME [epoch: 11.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08112460380138409		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.08112460380138409 | validation: 0.09245108672476374]
	TIME [epoch: 11.6 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08065876805914957		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.08065876805914957 | validation: 0.1042406540261957]
	TIME [epoch: 11.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08854811147448888		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.08854811147448888 | validation: 0.11719220234530262]
	TIME [epoch: 11.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09503413389922488		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.09503413389922488 | validation: 0.10498621771683489]
	TIME [epoch: 11.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12444300072266834		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.12444300072266834 | validation: 0.2031041672264171]
	TIME [epoch: 11.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15355198392341857		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.15355198392341857 | validation: 0.19274189918412915]
	TIME [epoch: 11.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14586455096900297		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.14586455096900297 | validation: 0.178995795265258]
	TIME [epoch: 11.6 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14564042047570275		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.14564042047570275 | validation: 0.18221325180422096]
	TIME [epoch: 11.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1460242721430095		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.1460242721430095 | validation: 0.15795829495760394]
	TIME [epoch: 11.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12549683111193638		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.12549683111193638 | validation: 0.18786869497011738]
	TIME [epoch: 11.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19004464079872402		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.19004464079872402 | validation: 0.10916066123271274]
	TIME [epoch: 11.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12103437591463001		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.12103437591463001 | validation: 0.1489990031528588]
	TIME [epoch: 11.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11043194444799428		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.11043194444799428 | validation: 0.10171917483470111]
	TIME [epoch: 11.6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1019714060949239		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.1019714060949239 | validation: 0.12985852357203462]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09257582838354358		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.09257582838354358 | validation: 0.11105055493945191]
	TIME [epoch: 11.6 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07736019342047165		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.07736019342047165 | validation: 0.11038145172195325]
	TIME [epoch: 11.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0905901830856608		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.0905901830856608 | validation: 0.09025371535671649]
	TIME [epoch: 11.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.067844797063836		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.067844797063836 | validation: 0.07738800828733239]
	TIME [epoch: 11.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07628287601531294		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.07628287601531294 | validation: 0.100562897092695]
	TIME [epoch: 11.6 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07536012521742932		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.07536012521742932 | validation: 0.09210416889322037]
	TIME [epoch: 11.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08360821393842084		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.08360821393842084 | validation: 0.16497565999729324]
	TIME [epoch: 11.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11835126150335269		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.11835126150335269 | validation: 0.20913581109308177]
	TIME [epoch: 11.6 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17306229335499165		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.17306229335499165 | validation: 0.09933544591308051]
	TIME [epoch: 11.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10260168767095756		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.10260168767095756 | validation: 0.13504522014049997]
	TIME [epoch: 11.6 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13653471528183247		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.13653471528183247 | validation: 0.18468183989971262]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12436938756284145		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.12436938756284145 | validation: 0.09729798262832988]
	TIME [epoch: 11.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08037623856606829		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.08037623856606829 | validation: 0.11565241321021445]
	TIME [epoch: 11.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1387755321609476		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.1387755321609476 | validation: 0.09254190300261382]
	TIME [epoch: 11.6 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08448600320190147		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.08448600320190147 | validation: 0.12000443496382833]
	TIME [epoch: 11.5 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10811493881027726		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.10811493881027726 | validation: 0.1084181249792625]
	TIME [epoch: 11.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09069256369800413		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.09069256369800413 | validation: 0.08676068333345555]
	TIME [epoch: 11.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07149290377429594		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.07149290377429594 | validation: 0.13038404037030485]
	TIME [epoch: 11.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0948257579048896		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.0948257579048896 | validation: 0.1573854398775328]
	TIME [epoch: 11.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14367994484764418		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.14367994484764418 | validation: 0.10316591398778592]
	TIME [epoch: 11.6 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10820261494692111		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.10820261494692111 | validation: 0.20006816336997235]
	TIME [epoch: 11.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14004354144707218		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.14004354144707218 | validation: 0.12730521567405642]
	TIME [epoch: 11.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13598620423875538		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.13598620423875538 | validation: 0.17129219071960955]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12571059752733815		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.12571059752733815 | validation: 0.13282737393342292]
	TIME [epoch: 11.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298628365543099		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.1298628365543099 | validation: 0.18711666410371983]
	TIME [epoch: 11.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23057695032611736		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.23057695032611736 | validation: 0.2355350739233046]
	TIME [epoch: 11.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1963946404985312		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.1963946404985312 | validation: 0.27994443773479555]
	TIME [epoch: 11.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18087807493207755		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.18087807493207755 | validation: 0.25593430871881895]
	TIME [epoch: 11.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24990122299612622		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.24990122299612622 | validation: 0.3545081034399175]
	TIME [epoch: 11.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19757014194984526		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.19757014194984526 | validation: 0.1250353360469422]
	TIME [epoch: 11.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11160646233853687		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.11160646233853687 | validation: 0.12183447309768188]
	TIME [epoch: 11.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10840633094895825		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.10840633094895825 | validation: 0.12838057824047125]
	TIME [epoch: 11.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09452896131235268		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.09452896131235268 | validation: 0.10222958876484665]
	TIME [epoch: 11.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08663525720033204		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.08663525720033204 | validation: 0.10033277001039405]
	TIME [epoch: 11.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06719643315994933		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.06719643315994933 | validation: 0.07714574763666582]
	TIME [epoch: 11.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07564574718861336		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.07564574718861336 | validation: 0.08309494772755809]
	TIME [epoch: 11.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07841295406168652		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.07841295406168652 | validation: 0.13250018111129663]
	TIME [epoch: 11.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15001334060517438		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.15001334060517438 | validation: 0.13662676419760988]
	TIME [epoch: 11.6 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08980082276626777		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.08980082276626777 | validation: 0.0951688981448797]
	TIME [epoch: 11.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08905012962377208		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.08905012962377208 | validation: 0.10365803041426568]
	TIME [epoch: 11.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11238788432542397		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.11238788432542397 | validation: 0.1669281784818267]
	TIME [epoch: 11.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18331917093986472		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.18331917093986472 | validation: 0.2880827346850823]
	TIME [epoch: 11.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21740354607413498		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.21740354607413498 | validation: 0.16163004026033329]
	TIME [epoch: 11.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12215987963995206		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.12215987963995206 | validation: 0.13810957077265493]
	TIME [epoch: 11.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17876312554641638		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.17876312554641638 | validation: 0.20590419560030807]
	TIME [epoch: 11.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17218225666753686		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.17218225666753686 | validation: 0.17763591406747217]
	TIME [epoch: 11.6 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16950320686091552		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.16950320686091552 | validation: 0.2763799951235368]
	TIME [epoch: 11.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22857174547858422		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.22857174547858422 | validation: 0.16522203834578114]
	TIME [epoch: 11.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1187075572022251		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.1187075572022251 | validation: 0.13415260479669314]
	TIME [epoch: 11.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12226172652531533		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.12226172652531533 | validation: 0.1428783037988358]
	TIME [epoch: 11.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10816992484314769		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.10816992484314769 | validation: 0.1370790438667121]
	TIME [epoch: 11.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12691607922572		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.12691607922572 | validation: 0.18346056442862996]
	TIME [epoch: 11.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15001400918053834		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.15001400918053834 | validation: 0.13396273228788416]
	TIME [epoch: 11.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1333929462617784		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.1333929462617784 | validation: 0.11234181850404486]
	TIME [epoch: 11.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07882483625512042		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.07882483625512042 | validation: 0.11135600988737338]
	TIME [epoch: 11.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07612031804059091		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.07612031804059091 | validation: 0.10113938276632603]
	TIME [epoch: 11.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0973560498473886		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.0973560498473886 | validation: 0.11376882749961642]
	TIME [epoch: 11.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1163607810811283		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.1163607810811283 | validation: 0.11918342021379105]
	TIME [epoch: 11.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0820654417312486		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.0820654417312486 | validation: 0.0822017451514666]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06936635505002414		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.06936635505002414 | validation: 0.08900397445437332]
	TIME [epoch: 11.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0760199036526825		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.0760199036526825 | validation: 0.0774273701279949]
	TIME [epoch: 11.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07673474381989051		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.07673474381989051 | validation: 0.10210592330333587]
	TIME [epoch: 11.6 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09342822604854042		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.09342822604854042 | validation: 0.13893832192605543]
	TIME [epoch: 11.5 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13676582872150578		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.13676582872150578 | validation: 0.2314451163816943]
	TIME [epoch: 11.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13194523230581148		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.13194523230581148 | validation: 0.1395471588066514]
	TIME [epoch: 11.6 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1250565197247812		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.1250565197247812 | validation: 0.1191593524656459]
	TIME [epoch: 11.5 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07519027826396521		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.07519027826396521 | validation: 0.08961742757218596]
	TIME [epoch: 11.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06897574050195668		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.06897574050195668 | validation: 0.09575029318246545]
	TIME [epoch: 11.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0740608262651868		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.0740608262651868 | validation: 0.10545901051441532]
	TIME [epoch: 11.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09280043693914777		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.09280043693914777 | validation: 0.12685134120645405]
	TIME [epoch: 11.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08424080367000736		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.08424080367000736 | validation: 0.10994145380630986]
	TIME [epoch: 11.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08943970433357291		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.08943970433357291 | validation: 0.07515903179232929]
	TIME [epoch: 11.5 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06620142149644678		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.06620142149644678 | validation: 0.11683209972071748]
	TIME [epoch: 11.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09679339256373207		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.09679339256373207 | validation: 0.09386372475052106]
	TIME [epoch: 11.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06440344580606042		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.06440344580606042 | validation: 0.0904232257299323]
	TIME [epoch: 11.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06678346159809781		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.06678346159809781 | validation: 0.09320199017659388]
	TIME [epoch: 11.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07144665815999647		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.07144665815999647 | validation: 0.07677085101375292]
	TIME [epoch: 11.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07142703629532811		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.07142703629532811 | validation: 0.09548361999549038]
	TIME [epoch: 11.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08145310981340603		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.08145310981340603 | validation: 0.13984252070000833]
	TIME [epoch: 11.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12036726352981678		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.12036726352981678 | validation: 0.15710811208253356]
	TIME [epoch: 11.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13901832968405878		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.13901832968405878 | validation: 0.08657473257702726]
	TIME [epoch: 11.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09122673582592994		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.09122673582592994 | validation: 0.10722175866837237]
	TIME [epoch: 11.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08539722987077591		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.08539722987077591 | validation: 0.07096987713382295]
	TIME [epoch: 11.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06145087659727763		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.06145087659727763 | validation: 0.07597358160338816]
	TIME [epoch: 11.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07097018268110265		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.07097018268110265 | validation: 0.09926067200272108]
	TIME [epoch: 11.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0844672069529894		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.0844672069529894 | validation: 0.0899205175226504]
	TIME [epoch: 11.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08572728225808374		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.08572728225808374 | validation: 0.11034520760554262]
	TIME [epoch: 11.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08508458075412817		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.08508458075412817 | validation: 0.10232391101668421]
	TIME [epoch: 11.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08732542388494231		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.08732542388494231 | validation: 0.1380007040071036]
	TIME [epoch: 11.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10320894536579014		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.10320894536579014 | validation: 0.12316727074970443]
	TIME [epoch: 11.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1197849861772861		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.1197849861772861 | validation: 0.15574314663469566]
	TIME [epoch: 11.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09117065016417916		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.09117065016417916 | validation: 0.10591150620042517]
	TIME [epoch: 11.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0835380595393738		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.0835380595393738 | validation: 0.06909677041428765]
	TIME [epoch: 11.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07421849687386925		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.07421849687386925 | validation: 0.11889007351047201]
	TIME [epoch: 11.6 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10271641387952532		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.10271641387952532 | validation: 0.11478038148593914]
	TIME [epoch: 11.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07123916554078667		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.07123916554078667 | validation: 0.10237061889090471]
	TIME [epoch: 11.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08105202840710231		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.08105202840710231 | validation: 0.08078907231378528]
	TIME [epoch: 11.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07357134359738327		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.07357134359738327 | validation: 0.12428880932455506]
	TIME [epoch: 11.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10114838816944866		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.10114838816944866 | validation: 0.12815522195496962]
	TIME [epoch: 11.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07455970783393664		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.07455970783393664 | validation: 0.09323083095352099]
	TIME [epoch: 11.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09183285021533727		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.09183285021533727 | validation: 0.14040917362722632]
	TIME [epoch: 11.6 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1161994593918319		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.1161994593918319 | validation: 0.0890342542209096]
	TIME [epoch: 11.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07419558334110044		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.07419558334110044 | validation: 0.1065791179562655]
	TIME [epoch: 11.6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07967264800054454		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.07967264800054454 | validation: 0.08161877304235578]
	TIME [epoch: 11.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07168907412874836		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.07168907412874836 | validation: 0.05813588048408283]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_748.pth
	Model improved!!!
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06235170663901221		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.06235170663901221 | validation: 0.09002323328791949]
	TIME [epoch: 11.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05285738590275009		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.05285738590275009 | validation: 0.06079251794887853]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05597165064491061		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.05597165064491061 | validation: 0.10913036420162499]
	TIME [epoch: 11.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09964068106045385		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.09964068106045385 | validation: 0.09203289949545976]
	TIME [epoch: 11.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0714114318055515		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.0714114318055515 | validation: 0.09742595369192221]
	TIME [epoch: 11.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0750530379829227		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.0750530379829227 | validation: 0.0625117744454545]
	TIME [epoch: 11.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053586381757257134		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.053586381757257134 | validation: 0.07940345575709241]
	TIME [epoch: 11.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056559067299157106		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.056559067299157106 | validation: 0.06969988189066928]
	TIME [epoch: 11.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04977831482818829		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.04977831482818829 | validation: 0.07246758964338955]
	TIME [epoch: 11.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05142114668464699		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.05142114668464699 | validation: 0.05686983269237329]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_758.pth
	Model improved!!!
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048174319819178135		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.048174319819178135 | validation: 0.08827281726499724]
	TIME [epoch: 11.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06331178652725236		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.06331178652725236 | validation: 0.08553747537861899]
	TIME [epoch: 11.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06545757250534431		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.06545757250534431 | validation: 0.10953620929621964]
	TIME [epoch: 11.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0824455032406339		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.0824455032406339 | validation: 0.10177835098724629]
	TIME [epoch: 11.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07237712502587647		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.07237712502587647 | validation: 0.0717126418447193]
	TIME [epoch: 11.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07297371769600261		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.07297371769600261 | validation: 0.10511895629659211]
	TIME [epoch: 11.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09998550462359625		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.09998550462359625 | validation: 0.07802771935766216]
	TIME [epoch: 11.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05539160684682924		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.05539160684682924 | validation: 0.05304845036893254]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_766.pth
	Model improved!!!
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06060210706015284		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.06060210706015284 | validation: 0.07680158381350877]
	TIME [epoch: 11.6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053160365101082664		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.053160365101082664 | validation: 0.06781692037605005]
	TIME [epoch: 11.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05312945892604634		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.05312945892604634 | validation: 0.07455845133241891]
	TIME [epoch: 11.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06765877855404065		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.06765877855404065 | validation: 0.08949105511196098]
	TIME [epoch: 11.6 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07948096246464609		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.07948096246464609 | validation: 0.1116238518445184]
	TIME [epoch: 11.6 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13514365080238883		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.13514365080238883 | validation: 0.18571379837110613]
	TIME [epoch: 11.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11877539680106113		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.11877539680106113 | validation: 0.14227296223983477]
	TIME [epoch: 11.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12647421108130344		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.12647421108130344 | validation: 0.11201082555691055]
	TIME [epoch: 11.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08910093950087539		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.08910093950087539 | validation: 0.10225189203634483]
	TIME [epoch: 11.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07248431737681807		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.07248431737681807 | validation: 0.08313654960714731]
	TIME [epoch: 11.6 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06262822958890472		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.06262822958890472 | validation: 0.09796882003570921]
	TIME [epoch: 11.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08357312318038937		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.08357312318038937 | validation: 0.13096782960130393]
	TIME [epoch: 11.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13600638036699408		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.13600638036699408 | validation: 0.2795981057831202]
	TIME [epoch: 11.6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19865445659545122		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.19865445659545122 | validation: 0.1952788157026256]
	TIME [epoch: 11.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140866168501428		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.140866168501428 | validation: 0.14752966143101945]
	TIME [epoch: 11.6 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11541136877633869		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.11541136877633869 | validation: 0.12335555606663551]
	TIME [epoch: 11.6 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09299284903159438		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.09299284903159438 | validation: 0.10918955192484266]
	TIME [epoch: 11.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09181854200495464		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.09181854200495464 | validation: 0.14448493694840372]
	TIME [epoch: 11.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11589972821223277		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.11589972821223277 | validation: 0.14899910844690742]
	TIME [epoch: 11.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12656626607260624		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.12656626607260624 | validation: 0.16791573554966657]
	TIME [epoch: 11.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1467664578213596		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.1467664578213596 | validation: 0.168477799450676]
	TIME [epoch: 11.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1147935741317065		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.1147935741317065 | validation: 0.08238567691224022]
	TIME [epoch: 11.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06659432751585848		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.06659432751585848 | validation: 0.07966317576853874]
	TIME [epoch: 11.6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06797872473739107		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.06797872473739107 | validation: 0.08363697957999548]
	TIME [epoch: 11.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05595400458111185		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.05595400458111185 | validation: 0.06054115476508926]
	TIME [epoch: 11.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06370608582122175		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.06370608582122175 | validation: 0.05830516472837711]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08374384241787561		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.08374384241787561 | validation: 0.09976041869226464]
	TIME [epoch: 11.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06414742964609965		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.06414742964609965 | validation: 0.07847521450802492]
	TIME [epoch: 11.6 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06280832109092277		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.06280832109092277 | validation: 0.07188391402826162]
	TIME [epoch: 11.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05722107165011506		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.05722107165011506 | validation: 0.07058732232121788]
	TIME [epoch: 11.6 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05916390233833472		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.05916390233833472 | validation: 0.09341198544733356]
	TIME [epoch: 11.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08381919813240421		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.08381919813240421 | validation: 0.08922771984535295]
	TIME [epoch: 11.6 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06727358852579388		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.06727358852579388 | validation: 0.07554015400668285]
	TIME [epoch: 11.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06817339986398654		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.06817339986398654 | validation: 0.0893642287233417]
	TIME [epoch: 11.6 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0689187040509685		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.0689187040509685 | validation: 0.04926099450821104]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_801.pth
	Model improved!!!
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03812142127619629		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.03812142127619629 | validation: 0.047222253480276095]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_802.pth
	Model improved!!!
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039071884255903716		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.039071884255903716 | validation: 0.039300876233723456]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_803.pth
	Model improved!!!
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09281157210261781		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.09281157210261781 | validation: 0.12221859414367366]
	TIME [epoch: 11.6 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10471445336711302		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.10471445336711302 | validation: 0.08576681130609742]
	TIME [epoch: 11.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06161914967070666		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.06161914967070666 | validation: 0.04896993276539423]
	TIME [epoch: 11.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07970896836736685		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.07970896836736685 | validation: 0.11490832880577086]
	TIME [epoch: 11.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07258910438117828		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.07258910438117828 | validation: 0.05095770240245806]
	TIME [epoch: 11.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045290146842959275		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.045290146842959275 | validation: 0.07969379293283295]
	TIME [epoch: 11.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08853400083726287		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.08853400083726287 | validation: 0.1049540795040516]
	TIME [epoch: 11.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07284708226923946		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.07284708226923946 | validation: 0.0546165469583794]
	TIME [epoch: 11.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04399438487396147		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.04399438487396147 | validation: 0.05728122066999186]
	TIME [epoch: 11.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04640174274940466		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.04640174274940466 | validation: 0.05071932347790617]
	TIME [epoch: 11.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047211955815313955		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.047211955815313955 | validation: 0.06764010658441726]
	TIME [epoch: 11.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06808346999860124		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.06808346999860124 | validation: 0.09120996238672367]
	TIME [epoch: 11.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10603752517129414		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.10603752517129414 | validation: 0.07911885578303256]
	TIME [epoch: 11.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10490286573754926		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.10490286573754926 | validation: 0.1123294481038184]
	TIME [epoch: 11.6 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09270013640957472		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.09270013640957472 | validation: 0.1367310325515852]
	TIME [epoch: 11.6 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09429325248848133		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.09429325248848133 | validation: 0.08525616937206738]
	TIME [epoch: 11.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07716808671137716		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.07716808671137716 | validation: 0.0935771703008565]
	TIME [epoch: 11.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07830955875408868		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.07830955875408868 | validation: 0.10878725120150418]
	TIME [epoch: 11.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07211537356343224		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.07211537356343224 | validation: 0.07475336478835394]
	TIME [epoch: 11.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05721651403684268		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.05721651403684268 | validation: 0.07955966034977172]
	TIME [epoch: 11.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06279022955865954		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.06279022955865954 | validation: 0.05472026371032007]
	TIME [epoch: 11.6 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04978161244028295		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.04978161244028295 | validation: 0.11779823342692099]
	TIME [epoch: 11.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09700508983891237		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.09700508983891237 | validation: 0.07500799063971336]
	TIME [epoch: 11.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05300874944265655		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.05300874944265655 | validation: 0.07517487427958253]
	TIME [epoch: 11.6 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07425652510395163		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.07425652510395163 | validation: 0.12268825072034341]
	TIME [epoch: 11.6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09844654213133013		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.09844654213133013 | validation: 0.12407207552778664]
	TIME [epoch: 11.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09953696007916651		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.09953696007916651 | validation: 0.11953552129926856]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11338609856799098		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.11338609856799098 | validation: 0.11998087232349364]
	TIME [epoch: 11.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1239354018139564		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.1239354018139564 | validation: 0.1375133803095621]
	TIME [epoch: 11.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09366965409548782		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.09366965409548782 | validation: 0.12800775817595703]
	TIME [epoch: 11.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08953567182139252		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.08953567182139252 | validation: 0.13104749739011717]
	TIME [epoch: 11.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11082918250367013		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.11082918250367013 | validation: 0.09918661710065192]
	TIME [epoch: 11.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08280182821051166		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.08280182821051166 | validation: 0.11555351360598541]
	TIME [epoch: 11.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0942503501457936		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.0942503501457936 | validation: 0.11200409751349284]
	TIME [epoch: 11.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10502977885855426		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.10502977885855426 | validation: 0.14409948905442654]
	TIME [epoch: 11.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10247934850116894		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.10247934850116894 | validation: 0.09035920692582183]
	TIME [epoch: 11.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06251232894614156		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.06251232894614156 | validation: 0.06688510990277621]
	TIME [epoch: 11.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049522985953653204		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.049522985953653204 | validation: 0.066654120270337]
	TIME [epoch: 11.6 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0659073552658444		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.0659073552658444 | validation: 0.060666370010023576]
	TIME [epoch: 11.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051544761651859256		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.051544761651859256 | validation: 0.07347362382987331]
	TIME [epoch: 11.6 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06282299730561448		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.06282299730561448 | validation: 0.07057638975367775]
	TIME [epoch: 11.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052662282005373956		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.052662282005373956 | validation: 0.056357847681043884]
	TIME [epoch: 11.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04939647146063168		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.04939647146063168 | validation: 0.08443369493291636]
	TIME [epoch: 11.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07093745533579192		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.07093745533579192 | validation: 0.06719876221286451]
	TIME [epoch: 11.6 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06218086116193125		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.06218086116193125 | validation: 0.07780419671952533]
	TIME [epoch: 11.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04605350319282882		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.04605350319282882 | validation: 0.055811574147158344]
	TIME [epoch: 11.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046113038805752224		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.046113038805752224 | validation: 0.05065646995362648]
	TIME [epoch: 11.6 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04444058525763557		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.04444058525763557 | validation: 0.06417181161636386]
	TIME [epoch: 11.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06163575464750889		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.06163575464750889 | validation: 0.05605734457907742]
	TIME [epoch: 11.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03995603082271874		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.03995603082271874 | validation: 0.045742658659891106]
	TIME [epoch: 11.6 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03449669036985145		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.03449669036985145 | validation: 0.06585925000028267]
	TIME [epoch: 11.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05448937063605354		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.05448937063605354 | validation: 0.05807467132600963]
	TIME [epoch: 11.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043798708101167816		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.043798708101167816 | validation: 0.06753922521100296]
	TIME [epoch: 11.6 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045895936096292854		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.045895936096292854 | validation: 0.04808595557428988]
	TIME [epoch: 11.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041645997129055125		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.041645997129055125 | validation: 0.05842424316596178]
	TIME [epoch: 11.5 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04265448785668429		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.04265448785668429 | validation: 0.0541312957033595]
	TIME [epoch: 11.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043459483746708556		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.043459483746708556 | validation: 0.05283261261183823]
	TIME [epoch: 11.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05003892002050929		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.05003892002050929 | validation: 0.14236802709156396]
	TIME [epoch: 11.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11267183414876963		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.11267183414876963 | validation: 0.07310756980894642]
	TIME [epoch: 11.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061004977010219855		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.061004977010219855 | validation: 0.09839446757590112]
	TIME [epoch: 11.6 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08017425575383488		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.08017425575383488 | validation: 0.08143534398854345]
	TIME [epoch: 11.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046377495503892155		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.046377495503892155 | validation: 0.05945142006662035]
	TIME [epoch: 11.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050170410748123354		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.050170410748123354 | validation: 0.057578799115252766]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05134033474115717		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.05134033474115717 | validation: 0.056736554928374296]
	TIME [epoch: 11.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0465291476783842		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.0465291476783842 | validation: 0.04836446310352554]
	TIME [epoch: 11.6 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042533039994936295		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.042533039994936295 | validation: 0.04933414297419402]
	TIME [epoch: 11.6 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07734195877478012		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.07734195877478012 | validation: 0.11205800114471956]
	TIME [epoch: 11.6 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10575864217145453		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.10575864217145453 | validation: 0.07251698055305383]
	TIME [epoch: 11.6 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054653468162550664		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.054653468162550664 | validation: 0.059934221174900555]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05281627931795406		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.05281627931795406 | validation: 0.06842399876439272]
	TIME [epoch: 11.6 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06477271268168469		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.06477271268168469 | validation: 0.06657448237146356]
	TIME [epoch: 11.6 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055369411900941565		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.055369411900941565 | validation: 0.043980092375977185]
	TIME [epoch: 11.6 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03145728809827959		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.03145728809827959 | validation: 0.046968328052808275]
	TIME [epoch: 11.6 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034974569775676534		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.034974569775676534 | validation: 0.05417714024483849]
	TIME [epoch: 11.6 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04558106500603851		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.04558106500603851 | validation: 0.05339860049345517]
	TIME [epoch: 11.6 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04002976028723832		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.04002976028723832 | validation: 0.062986147657917]
	TIME [epoch: 11.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05947044633997195		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.05947044633997195 | validation: 0.085734864801068]
	TIME [epoch: 11.6 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05538906516286043		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.05538906516286043 | validation: 0.05789294990259258]
	TIME [epoch: 11.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04317121990672941		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.04317121990672941 | validation: 0.049343082357261085]
	TIME [epoch: 11.6 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04974798257763366		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.04974798257763366 | validation: 0.04539884873260793]
	TIME [epoch: 11.6 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03760850515465301		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.03760850515465301 | validation: 0.053057663176109306]
	TIME [epoch: 11.6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04661106508810327		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.04661106508810327 | validation: 0.047360159041945175]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046321615353844596		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.046321615353844596 | validation: 0.06651066832290722]
	TIME [epoch: 11.6 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.068531848600434		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.068531848600434 | validation: 0.07535494323253288]
	TIME [epoch: 11.6 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06898777137717145		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.06898777137717145 | validation: 0.0951237165673037]
	TIME [epoch: 11.6 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05890639508703627		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.05890639508703627 | validation: 0.0485155945388851]
	TIME [epoch: 11.6 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04594522299436357		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.04594522299436357 | validation: 0.06644637681722883]
	TIME [epoch: 11.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041538360678834964		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.041538360678834964 | validation: 0.06611364659605162]
	TIME [epoch: 11.6 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05699781300550334		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.05699781300550334 | validation: 0.05484030614101085]
	TIME [epoch: 11.6 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04733662611532386		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.04733662611532386 | validation: 0.06671357176616825]
	TIME [epoch: 11.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05910362353198448		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.05910362353198448 | validation: 0.07952639014761351]
	TIME [epoch: 11.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06862593280608137		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.06862593280608137 | validation: 0.07180553485467618]
	TIME [epoch: 11.6 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04420386479908875		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.04420386479908875 | validation: 0.04811239765296425]
	TIME [epoch: 11.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05049580507209486		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.05049580507209486 | validation: 0.06999138282271564]
	TIME [epoch: 11.6 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04327260740372739		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.04327260740372739 | validation: 0.05746899193908184]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05502385482386253		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.05502385482386253 | validation: 0.07263380076085187]
	TIME [epoch: 11.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04474380914204295		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.04474380914204295 | validation: 0.07016415825660452]
	TIME [epoch: 11.6 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03960202997022462		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.03960202997022462 | validation: 0.04903950510776616]
	TIME [epoch: 11.6 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04807797775963646		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.04807797775963646 | validation: 0.0773878574714277]
	TIME [epoch: 11.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04973271818868635		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.04973271818868635 | validation: 0.051475421630063946]
	TIME [epoch: 11.6 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04210228906741818		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.04210228906741818 | validation: 0.05921782318647681]
	TIME [epoch: 11.6 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07551817755529205		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.07551817755529205 | validation: 0.08965957260548063]
	TIME [epoch: 11.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05947354467416688		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.05947354467416688 | validation: 0.07051524294226402]
	TIME [epoch: 11.6 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05340708921668475		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.05340708921668475 | validation: 0.05879474249592236]
	TIME [epoch: 11.6 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04927520787714444		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.04927520787714444 | validation: 0.07278884943707503]
	TIME [epoch: 11.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05935122846410426		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.05935122846410426 | validation: 0.06190907959535892]
	TIME [epoch: 11.6 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0461075355202617		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.0461075355202617 | validation: 0.09277453976794969]
	TIME [epoch: 11.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05306677659434164		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.05306677659434164 | validation: 0.0832239600957301]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06448485954381586		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.06448485954381586 | validation: 0.05780099389172522]
	TIME [epoch: 11.6 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0482496219474111		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.0482496219474111 | validation: 0.06161673501091395]
	TIME [epoch: 11.6 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053827882781175694		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.053827882781175694 | validation: 0.0686029653851043]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06143407104888007		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.06143407104888007 | validation: 0.08085303920490604]
	TIME [epoch: 11.6 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07669135903959576		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.07669135903959576 | validation: 0.10135336700244056]
	TIME [epoch: 11.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08054877046038769		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.08054877046038769 | validation: 0.11192208140041415]
	TIME [epoch: 11.6 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08651796636268204		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.08651796636268204 | validation: 0.1045285888891641]
	TIME [epoch: 11.6 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07704722463266739		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.07704722463266739 | validation: 0.09020615312308511]
	TIME [epoch: 11.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05814118312596904		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.05814118312596904 | validation: 0.06699762994088636]
	TIME [epoch: 11.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0502759909482769		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.0502759909482769 | validation: 0.07573395781521812]
	TIME [epoch: 11.6 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05489551567472745		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.05489551567472745 | validation: 0.07334619806739298]
	TIME [epoch: 11.6 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06287557941861513		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.06287557941861513 | validation: 0.09833242989386368]
	TIME [epoch: 11.5 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09831936108809025		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.09831936108809025 | validation: 0.11211462989055943]
	TIME [epoch: 11.6 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0813522480196019		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.0813522480196019 | validation: 0.1028405645273098]
	TIME [epoch: 11.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0959384958378915		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.0959384958378915 | validation: 0.075380673721437]
	TIME [epoch: 11.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06306357858376013		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.06306357858376013 | validation: 0.07033408854525405]
	TIME [epoch: 11.6 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06727643027835287		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.06727643027835287 | validation: 0.10763730939612604]
	TIME [epoch: 11.6 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09110240109778416		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.09110240109778416 | validation: 0.07754756151420743]
	TIME [epoch: 11.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0700990231088371		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.0700990231088371 | validation: 0.07997202871774386]
	TIME [epoch: 11.6 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0699754902870261		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.0699754902870261 | validation: 0.06427973495851666]
	TIME [epoch: 11.6 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.068096847449086		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.068096847449086 | validation: 0.09456648914172001]
	TIME [epoch: 11.6 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08166007510940529		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.08166007510940529 | validation: 0.08134759103865634]
	TIME [epoch: 11.6 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05406914188668108		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.05406914188668108 | validation: 0.05462003039123319]
	TIME [epoch: 11.6 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0391273056671433		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.0391273056671433 | validation: 0.053453672252882216]
	TIME [epoch: 11.5 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04082678652905611		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.04082678652905611 | validation: 0.06982842812331846]
	TIME [epoch: 11.6 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05932750047359801		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.05932750047359801 | validation: 0.055553561589689]
	TIME [epoch: 11.6 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0392659507930369		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.0392659507930369 | validation: 0.03765234441148167]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_938.pth
	Model improved!!!
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039360772913400933		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.039360772913400933 | validation: 0.04663032171862581]
	TIME [epoch: 11.6 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033531131630880964		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.033531131630880964 | validation: 0.054996100602286935]
	TIME [epoch: 11.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031991776953037905		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.031991776953037905 | validation: 0.05685933146670441]
	TIME [epoch: 11.6 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04713321155344688		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.04713321155344688 | validation: 0.06260830345180306]
	TIME [epoch: 11.6 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04356313217697167		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.04356313217697167 | validation: 0.059844439509324804]
	TIME [epoch: 11.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04406030783976146		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.04406030783976146 | validation: 0.0486742183897154]
	TIME [epoch: 11.6 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04017318184654836		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.04017318184654836 | validation: 0.059956458376215424]
	TIME [epoch: 11.6 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0659132788047383		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.0659132788047383 | validation: 0.051483320774331855]
	TIME [epoch: 11.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056625188463259465		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.056625188463259465 | validation: 0.07788323141966362]
	TIME [epoch: 11.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06529234225260386		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.06529234225260386 | validation: 0.04066729045341397]
	TIME [epoch: 11.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03991516661039704		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.03991516661039704 | validation: 0.04678140974949953]
	TIME [epoch: 11.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045790237803367766		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.045790237803367766 | validation: 0.05399545500910538]
	TIME [epoch: 11.6 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04035051094773198		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.04035051094773198 | validation: 0.04057627130540249]
	TIME [epoch: 11.6 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041231825145874375		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.041231825145874375 | validation: 0.06706689100169602]
	TIME [epoch: 11.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055397337787779055		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.055397337787779055 | validation: 0.059471883631763464]
	TIME [epoch: 11.6 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038941987204568845		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.038941987204568845 | validation: 0.06180120137426865]
	TIME [epoch: 11.6 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04828446538442138		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.04828446538442138 | validation: 0.050036009840188245]
	TIME [epoch: 11.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04441524576828005		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.04441524576828005 | validation: 0.05236888055036553]
	TIME [epoch: 11.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04069644303721265		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.04069644303721265 | validation: 0.05807978605898303]
	TIME [epoch: 11.6 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051289183974162156		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.051289183974162156 | validation: 0.10585734932676008]
	TIME [epoch: 11.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08490865521888802		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.08490865521888802 | validation: 0.06617803296329902]
	TIME [epoch: 11.6 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04697862767722396		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.04697862767722396 | validation: 0.061782131569069296]
	TIME [epoch: 11.6 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051310033502633		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.051310033502633 | validation: 0.03674951605371959]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_961.pth
	Model improved!!!
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03876112478663753		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.03876112478663753 | validation: 0.05715841821996698]
	TIME [epoch: 11.6 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042600806353915506		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.042600806353915506 | validation: 0.045131388967906506]
	TIME [epoch: 11.6 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04145904998338354		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.04145904998338354 | validation: 0.0587167864711919]
	TIME [epoch: 11.6 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04068511572882583		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.04068511572882583 | validation: 0.045794538801128985]
	TIME [epoch: 11.5 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031128114691787882		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.031128114691787882 | validation: 0.050915073632577905]
	TIME [epoch: 11.6 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03086745611246637		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.03086745611246637 | validation: 0.03637476535584898]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_967.pth
	Model improved!!!
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02969391175323076		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.02969391175323076 | validation: 0.05983214049132584]
	TIME [epoch: 11.5 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051284508937616304		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.051284508937616304 | validation: 0.05004147711595875]
	TIME [epoch: 11.6 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0328915261798248		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.0328915261798248 | validation: 0.04637009398893987]
	TIME [epoch: 11.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034245767101073736		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.034245767101073736 | validation: 0.04867327132961978]
	TIME [epoch: 11.6 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03533677604030534		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.03533677604030534 | validation: 0.043638417328326615]
	TIME [epoch: 11.6 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04501402955902891		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.04501402955902891 | validation: 0.05682213471977754]
	TIME [epoch: 11.6 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040955019922006584		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.040955019922006584 | validation: 0.06270077188804304]
	TIME [epoch: 11.6 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044658855790385026		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.044658855790385026 | validation: 0.040022468949968214]
	TIME [epoch: 11.6 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031403442870031606		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.031403442870031606 | validation: 0.039808134402011905]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02588411572395548		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.02588411572395548 | validation: 0.041037953025666506]
	TIME [epoch: 11.6 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039844433873529206		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.039844433873529206 | validation: 0.049332178265282675]
	TIME [epoch: 11.6 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03178856638519293		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.03178856638519293 | validation: 0.03552056841129876]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_979.pth
	Model improved!!!
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036901416590734676		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.036901416590734676 | validation: 0.038235366772674986]
	TIME [epoch: 11.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031831429225053595		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.031831429225053595 | validation: 0.03833819547526187]
	TIME [epoch: 11.6 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032564210851516416		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.032564210851516416 | validation: 0.04552622663158825]
	TIME [epoch: 11.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03491956125438779		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.03491956125438779 | validation: 0.04633689685390797]
	TIME [epoch: 11.6 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03272534459660975		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.03272534459660975 | validation: 0.038911352863240094]
	TIME [epoch: 11.6 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03174130626064069		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.03174130626064069 | validation: 0.052967664354805793]
	TIME [epoch: 11.6 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04043906655415583		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.04043906655415583 | validation: 0.051179795243443564]
	TIME [epoch: 11.6 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03808586901539131		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.03808586901539131 | validation: 0.04252118823380323]
	TIME [epoch: 11.6 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039173648642485945		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.039173648642485945 | validation: 0.07095690692467901]
	TIME [epoch: 11.6 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05314823329058502		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.05314823329058502 | validation: 0.039711994500613614]
	TIME [epoch: 11.6 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033424965573725214		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.033424965573725214 | validation: 0.04468263634524993]
	TIME [epoch: 11.6 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039246207249327425		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.039246207249327425 | validation: 0.07014912274646759]
	TIME [epoch: 11.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06766341862910798		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.06766341862910798 | validation: 0.10315721725252405]
	TIME [epoch: 11.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07726398379888355		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.07726398379888355 | validation: 0.062171165890965635]
	TIME [epoch: 11.6 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04758483965610018		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.04758483965610018 | validation: 0.05993385262022078]
	TIME [epoch: 11.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04415855222917332		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.04415855222917332 | validation: 0.06483758709779]
	TIME [epoch: 11.6 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0563285025783018		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.0563285025783018 | validation: 0.07527758349853145]
	TIME [epoch: 11.6 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056812651810382246		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.056812651810382246 | validation: 0.04726214013444099]
	TIME [epoch: 11.6 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041583003176144856		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.041583003176144856 | validation: 0.04995669872950315]
	TIME [epoch: 11.6 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05424526714651296		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.05424526714651296 | validation: 0.06252101683477342]
	TIME [epoch: 11.6 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043889196547919555		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.043889196547919555 | validation: 0.06390794084010817]
	TIME [epoch: 11.6 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05791439870692483		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.05791439870692483 | validation: 0.048619293940024184]
	TIME [epoch: 11.6 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04658341725879666		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.04658341725879666 | validation: 0.07495949108548895]
	TIME [epoch: 11.6 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058926721068083034		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.058926721068083034 | validation: 0.06266835815036735]
	TIME [epoch: 11.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04353282309930065		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.04353282309930065 | validation: 0.0593360783580395]
	TIME [epoch: 11.6 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060750903939626066		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.060750903939626066 | validation: 0.09708746432921948]
	TIME [epoch: 11.6 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08365928460243517		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.08365928460243517 | validation: 0.07297364827303457]
	TIME [epoch: 11.6 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059065808928402075		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.059065808928402075 | validation: 0.07939341210874196]
	TIME [epoch: 11.6 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06678563848195554		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.06678563848195554 | validation: 0.058643889964504745]
	TIME [epoch: 11.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04782662027991766		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.04782662027991766 | validation: 0.05105661905384523]
	TIME [epoch: 11.6 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04044001823578984		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.04044001823578984 | validation: 0.06013629664462414]
	TIME [epoch: 11.6 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046778331374864666		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.046778331374864666 | validation: 0.05397649544306733]
	TIME [epoch: 11.6 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05277044109576982		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.05277044109576982 | validation: 0.07166187396098748]
	TIME [epoch: 11.6 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04624764117826244		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.04624764117826244 | validation: 0.05653536535755127]
	TIME [epoch: 11.6 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0514243681423138		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.0514243681423138 | validation: 0.0726633671549682]
	TIME [epoch: 11.6 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06066130009351739		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.06066130009351739 | validation: 0.061150138745664065]
	TIME [epoch: 11.6 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05850908391688715		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.05850908391688715 | validation: 0.059727833779446134]
	TIME [epoch: 11.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04500144507290615		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.04500144507290615 | validation: 0.06855733705599613]
	TIME [epoch: 11.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06871878010507834		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.06871878010507834 | validation: 0.07076666903722419]
	TIME [epoch: 11.6 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049023943683669025		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.049023943683669025 | validation: 0.05448944388770466]
	TIME [epoch: 11.6 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04442263252664526		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.04442263252664526 | validation: 0.06315921843128489]
	TIME [epoch: 11.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06431037561792217		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.06431037561792217 | validation: 0.07065817349453361]
	TIME [epoch: 11.6 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0618258018249734		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.0618258018249734 | validation: 0.05921682941353359]
	TIME [epoch: 11.6 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05189299183567095		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.05189299183567095 | validation: 0.07503763748188924]
	TIME [epoch: 11.6 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07435531251171225		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.07435531251171225 | validation: 0.08338532561695654]
	TIME [epoch: 11.6 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09495568093174683		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.09495568093174683 | validation: 0.08484227724530805]
	TIME [epoch: 11.6 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05315893951132237		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.05315893951132237 | validation: 0.06431717767298707]
	TIME [epoch: 11.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04775712868318932		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.04775712868318932 | validation: 0.061677168230719275]
	TIME [epoch: 11.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055822181202832194		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.055822181202832194 | validation: 0.06059918294702234]
	TIME [epoch: 11.6 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04971703851312533		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.04971703851312533 | validation: 0.06588637773369033]
	TIME [epoch: 11.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06497915315499316		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.06497915315499316 | validation: 0.061487443413531725]
	TIME [epoch: 11.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05087937528868987		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.05087937528868987 | validation: 0.05116208236979178]
	TIME [epoch: 11.6 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04612470910725437		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.04612470910725437 | validation: 0.05238464911158971]
	TIME [epoch: 11.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04602910915528414		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.04602910915528414 | validation: 0.05427576297926116]
	TIME [epoch: 11.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04032693021886798		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.04032693021886798 | validation: 0.05420638161977042]
	TIME [epoch: 11.6 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04118144636945358		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.04118144636945358 | validation: 0.04685867287872353]
	TIME [epoch: 11.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03574495488329257		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.03574495488329257 | validation: 0.061451276232431504]
	TIME [epoch: 11.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061397588697283484		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.061397588697283484 | validation: 0.07031703930610142]
	TIME [epoch: 11.6 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07719655049445787		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.07719655049445787 | validation: 0.06962630156363286]
	TIME [epoch: 11.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05666828304205299		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.05666828304205299 | validation: 0.06151119068059584]
	TIME [epoch: 11.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05228649676760457		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.05228649676760457 | validation: 0.07253513164309713]
	TIME [epoch: 11.6 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07923452879020816		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.07923452879020816 | validation: 0.07338807694902133]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05162654574775143		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.05162654574775143 | validation: 0.04845681951125668]
	TIME [epoch: 11.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04307253712552883		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.04307253712552883 | validation: 0.05031823304318246]
	TIME [epoch: 11.6 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03664436696694525		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.03664436696694525 | validation: 0.06580097706379061]
	TIME [epoch: 11.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05873861994655668		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.05873861994655668 | validation: 0.08237807369847878]
	TIME [epoch: 11.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06160931373663003		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.06160931373663003 | validation: 0.07553253586743634]
	TIME [epoch: 11.6 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04787776742224045		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.04787776742224045 | validation: 0.0611042321187503]
	TIME [epoch: 11.6 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05680726901476706		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.05680726901476706 | validation: 0.07407423141252455]
	TIME [epoch: 11.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06611268326914485		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.06611268326914485 | validation: 0.06621883196481734]
	TIME [epoch: 11.6 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0536378553735327		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.0536378553735327 | validation: 0.0604087384213794]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04763693649209176		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.04763693649209176 | validation: 0.056844045741827824]
	TIME [epoch: 11.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04663399238043713		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.04663399238043713 | validation: 0.057927932064424675]
	TIME [epoch: 11.6 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041716596702761816		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.041716596702761816 | validation: 0.043553972385992894]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038027166348070005		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.038027166348070005 | validation: 0.06730087868576753]
	TIME [epoch: 11.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06451591386633881		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.06451591386633881 | validation: 0.08299375273651703]
	TIME [epoch: 11.6 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05046166286421433		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.05046166286421433 | validation: 0.058164825554448546]
	TIME [epoch: 11.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04379623548829896		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.04379623548829896 | validation: 0.05335699714271499]
	TIME [epoch: 11.6 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040188078619631896		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.040188078619631896 | validation: 0.04708495157789713]
	TIME [epoch: 11.6 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04161102995777164		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.04161102995777164 | validation: 0.04586005893486951]
	TIME [epoch: 11.6 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037724787723274644		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.037724787723274644 | validation: 0.05221544523083374]
	TIME [epoch: 11.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036243232370066644		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.036243232370066644 | validation: 0.05731045054132432]
	TIME [epoch: 11.6 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048411366597434086		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.048411366597434086 | validation: 0.06799729947920218]
	TIME [epoch: 11.6 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035493699671065256		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.035493699671065256 | validation: 0.048889209976220926]
	TIME [epoch: 11.6 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03702266320095172		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.03702266320095172 | validation: 0.039146190783289785]
	TIME [epoch: 11.6 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029158803714032046		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.029158803714032046 | validation: 0.03862572722011172]
	TIME [epoch: 11.6 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027134159367062344		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.027134159367062344 | validation: 0.04164792192316269]
	TIME [epoch: 11.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0336780427731096		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.0336780427731096 | validation: 0.05180281179535694]
	TIME [epoch: 11.6 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04912437008561159		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.04912437008561159 | validation: 0.04056413128105734]
	TIME [epoch: 11.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034837221387181525		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.034837221387181525 | validation: 0.034553908633419124]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_1069.pth
	Model improved!!!
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02745006647193774		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.02745006647193774 | validation: 0.03882357024285842]
	TIME [epoch: 11.6 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03310583520833511		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.03310583520833511 | validation: 0.043421701122873115]
	TIME [epoch: 11.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028505462842869533		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.028505462842869533 | validation: 0.03768357010017222]
	TIME [epoch: 11.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02862366026257957		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.02862366026257957 | validation: 0.044111561731041755]
	TIME [epoch: 11.6 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04179721844713798		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.04179721844713798 | validation: 0.04859007284166761]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04147029307867046		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.04147029307867046 | validation: 0.03955645365499762]
	TIME [epoch: 11.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037915200855925535		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.037915200855925535 | validation: 0.04160089475197143]
	TIME [epoch: 11.6 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04229118335953311		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.04229118335953311 | validation: 0.043712857503026614]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03688641555659911		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.03688641555659911 | validation: 0.04564641743860843]
	TIME [epoch: 11.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03473912443918821		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.03473912443918821 | validation: 0.0438168753365105]
	TIME [epoch: 11.6 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028374644372972962		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.028374644372972962 | validation: 0.047056122514209736]
	TIME [epoch: 11.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025326852728415714		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.025326852728415714 | validation: 0.03352275724565306]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_1081.pth
	Model improved!!!
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028239606094106653		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.028239606094106653 | validation: 0.03368029668233856]
	TIME [epoch: 11.6 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03604143019575595		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.03604143019575595 | validation: 0.03693598014993936]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02903745931832438		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.02903745931832438 | validation: 0.03575483738181876]
	TIME [epoch: 11.5 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031001686576535917		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.031001686576535917 | validation: 0.03792846745954145]
	TIME [epoch: 11.6 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026368259100872725		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.026368259100872725 | validation: 0.05192996584066439]
	TIME [epoch: 11.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04259622535448037		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.04259622535448037 | validation: 0.05332994026169125]
	TIME [epoch: 11.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032209388006379534		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.032209388006379534 | validation: 0.03145709639840603]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_1088.pth
	Model improved!!!
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028107832892464713		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.028107832892464713 | validation: 0.03363026948970264]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028794391342084915		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.028794391342084915 | validation: 0.04272151689984646]
	TIME [epoch: 11.6 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03373850310797574		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.03373850310797574 | validation: 0.043544363817051124]
	TIME [epoch: 11.6 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03853889609210109		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.03853889609210109 | validation: 0.04116985996398771]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02959137686302597		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.02959137686302597 | validation: 0.048061372557772854]
	TIME [epoch: 11.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03179206710902779		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.03179206710902779 | validation: 0.0576970067519119]
	TIME [epoch: 11.6 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06212855155600405		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.06212855155600405 | validation: 0.07612045026985029]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08559068522024059		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.08559068522024059 | validation: 0.08741991054310744]
	TIME [epoch: 11.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06555396808077123		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.06555396808077123 | validation: 0.05330685471792351]
	TIME [epoch: 11.6 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044105071708762815		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.044105071708762815 | validation: 0.056860225920703056]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04667869100266574		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.04667869100266574 | validation: 0.05433669141716432]
	TIME [epoch: 11.5 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04032575810633313		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.04032575810633313 | validation: 0.04753265116836976]
	TIME [epoch: 11.6 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03519368747841998		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.03519368747841998 | validation: 0.04285234698743973]
	TIME [epoch: 11.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03966666070248139		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.03966666070248139 | validation: 0.04239974565247052]
	TIME [epoch: 11.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02689226753055349		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.02689226753055349 | validation: 0.04203753119886497]
	TIME [epoch: 11.6 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027506672048503916		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.027506672048503916 | validation: 0.037879882343209374]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030923040825586508		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.030923040825586508 | validation: 0.03840813530580742]
	TIME [epoch: 11.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027602114261808232		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.027602114261808232 | validation: 0.03896205711137128]
	TIME [epoch: 11.6 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028950080472783503		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.028950080472783503 | validation: 0.04175241723813348]
	TIME [epoch: 11.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033435455608950906		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.033435455608950906 | validation: 0.037230254013858065]
	TIME [epoch: 11.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026506350976007374		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.026506350976007374 | validation: 0.034599712863513425]
	TIME [epoch: 11.6 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03949835601747289		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.03949835601747289 | validation: 0.059046547114152866]
	TIME [epoch: 11.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05031968313726833		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.05031968313726833 | validation: 0.05823959981759625]
	TIME [epoch: 11.5 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047838229019439266		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.047838229019439266 | validation: 0.05155476391824323]
	TIME [epoch: 11.6 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03246014619370654		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.03246014619370654 | validation: 0.038570830411631056]
	TIME [epoch: 11.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0502107993307117		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.0502107993307117 | validation: 0.05138826363611384]
	TIME [epoch: 11.5 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0373864769714808		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.0373864769714808 | validation: 0.043288827247843394]
	TIME [epoch: 11.6 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030142902374102973		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.030142902374102973 | validation: 0.04459843849088514]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04707579108722458		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.04707579108722458 | validation: 0.05401668975570861]
	TIME [epoch: 11.6 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04775559574456058		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.04775559574456058 | validation: 0.04579936528886584]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037329311422526004		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.037329311422526004 | validation: 0.04826303405064995]
	TIME [epoch: 11.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0383902622954223		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.0383902622954223 | validation: 0.04798258510240868]
	TIME [epoch: 11.6 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03975096369384581		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.03975096369384581 | validation: 0.04125461301715945]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04259248200667616		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.04259248200667616 | validation: 0.03866359826085586]
	TIME [epoch: 11.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039417511086403956		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.039417511086403956 | validation: 0.0548193371667367]
	TIME [epoch: 11.6 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04269225834350246		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.04269225834350246 | validation: 0.05019811734056626]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04339567484284024		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.04339567484284024 | validation: 0.05098537231216238]
	TIME [epoch: 11.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04244539554502322		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.04244539554502322 | validation: 0.052908872564200016]
	TIME [epoch: 11.6 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04351520334134774		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.04351520334134774 | validation: 0.06713741816041177]
	TIME [epoch: 11.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05507676813158024		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.05507676813158024 | validation: 0.06444584210836847]
	TIME [epoch: 11.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0427312960647597		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.0427312960647597 | validation: 0.049165543954684074]
	TIME [epoch: 11.6 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03936614521636056		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.03936614521636056 | validation: 0.050708869678799805]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04185852795488998		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.04185852795488998 | validation: 0.05647209232694512]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039610865595256096		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.039610865595256096 | validation: 0.050854954856843035]
	TIME [epoch: 11.6 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044586450436487686		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.044586450436487686 | validation: 0.05549374675634189]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04921753185347685		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.04921753185347685 | validation: 0.05938696184347077]
	TIME [epoch: 11.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04153655185046453		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.04153655185046453 | validation: 0.05007089807061853]
	TIME [epoch: 11.6 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050114107561648885		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.050114107561648885 | validation: 0.06472335127706956]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051252017567686416		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.051252017567686416 | validation: 0.05283520600028526]
	TIME [epoch: 11.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035247814709887006		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.035247814709887006 | validation: 0.0553900982031324]
	TIME [epoch: 11.6 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05048179611374097		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.05048179611374097 | validation: 0.0571905337481565]
	TIME [epoch: 11.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046697944150268844		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.046697944150268844 | validation: 0.050631265329584084]
	TIME [epoch: 11.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036352754912872834		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.036352754912872834 | validation: 0.050729455754390335]
	TIME [epoch: 11.6 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03149125928116137		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.03149125928116137 | validation: 0.0408644740222954]
	TIME [epoch: 11.5 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027873017106819074		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.027873017106819074 | validation: 0.04717110836814047]
	TIME [epoch: 11.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03399915510141433		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.03399915510141433 | validation: 0.038959449564280685]
	TIME [epoch: 11.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038338275497302184		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.038338275497302184 | validation: 0.04683428356566866]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03718059235926097		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.03718059235926097 | validation: 0.040696043652357065]
	TIME [epoch: 11.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033585175701826606		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.033585175701826606 | validation: 0.04193076998178618]
	TIME [epoch: 11.6 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028864496519631272		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.028864496519631272 | validation: 0.04233376272126425]
	TIME [epoch: 11.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029635179800279195		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.029635179800279195 | validation: 0.03606070592024098]
	TIME [epoch: 11.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03004700554338891		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.03004700554338891 | validation: 0.03637007928176358]
	TIME [epoch: 11.6 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02907052795738986		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.02907052795738986 | validation: 0.03825720036072464]
	TIME [epoch: 11.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02514258728865163		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.02514258728865163 | validation: 0.03356398554414345]
	TIME [epoch: 11.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02943918927982694		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.02943918927982694 | validation: 0.03915119313969905]
	TIME [epoch: 11.6 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03224398299975544		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.03224398299975544 | validation: 0.0526698943285046]
	TIME [epoch: 11.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03845009027927417		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.03845009027927417 | validation: 0.0360753267056917]
	TIME [epoch: 11.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029605196260074775		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.029605196260074775 | validation: 0.04875589447106347]
	TIME [epoch: 11.6 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039815097139850805		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.039815097139850805 | validation: 0.050124203649808886]
	TIME [epoch: 11.5 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0389168999632664		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.0389168999632664 | validation: 0.04768754143755867]
	TIME [epoch: 11.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03258709243675461		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.03258709243675461 | validation: 0.04036033033882948]
	TIME [epoch: 11.6 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03297208241181025		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.03297208241181025 | validation: 0.04538610742112984]
	TIME [epoch: 11.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03823365785889325		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.03823365785889325 | validation: 0.05049599084427443]
	TIME [epoch: 11.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04655868944552505		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.04655868944552505 | validation: 0.062352151206157384]
	TIME [epoch: 11.6 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0417269068433679		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.0417269068433679 | validation: 0.05164207840844581]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04475106990817082		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.04475106990817082 | validation: 0.05247732351555495]
	TIME [epoch: 11.5 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04566607130251926		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.04566607130251926 | validation: 0.054202837096576854]
	TIME [epoch: 11.6 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04743796932952907		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.04743796932952907 | validation: 0.06537977641285558]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05039936100440179		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.05039936100440179 | validation: 0.05060090101247089]
	TIME [epoch: 11.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06509921697774058		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.06509921697774058 | validation: 0.07169836224660454]
	TIME [epoch: 11.6 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051699089880683405		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.051699089880683405 | validation: 0.05919844459522206]
	TIME [epoch: 11.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04026991810606663		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.04026991810606663 | validation: 0.0454438703684145]
	TIME [epoch: 11.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033224474019848606		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.033224474019848606 | validation: 0.03272798411371297]
	TIME [epoch: 11.6 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035267172367975524		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.035267172367975524 | validation: 0.04135430173346636]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033120578015923725		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.033120578015923725 | validation: 0.05634843779201807]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03999680806970597		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.03999680806970597 | validation: 0.04621682379867874]
	TIME [epoch: 11.6 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03785330804049478		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.03785330804049478 | validation: 0.04974379361521475]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03368780669228566		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.03368780669228566 | validation: 0.05038960081133496]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03626083359275991		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.03626083359275991 | validation: 0.0383042619154956]
	TIME [epoch: 11.6 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03394278515874374		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.03394278515874374 | validation: 0.041267170763073596]
	TIME [epoch: 11.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02939223157133833		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.02939223157133833 | validation: 0.043183232494498215]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02963503046143088		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.02963503046143088 | validation: 0.04315857850371441]
	TIME [epoch: 11.6 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031415853624332975		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.031415853624332975 | validation: 0.04841041085048077]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032206377858310806		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.032206377858310806 | validation: 0.03991184251009134]
	TIME [epoch: 11.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032285480212078374		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.032285480212078374 | validation: 0.04151584400397452]
	TIME [epoch: 11.6 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0313151755157828		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.0313151755157828 | validation: 0.04058733392496894]
	TIME [epoch: 11.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030449214322554055		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.030449214322554055 | validation: 0.04054466857632012]
	TIME [epoch: 11.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033729655384909824		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.033729655384909824 | validation: 0.03815248424872056]
	TIME [epoch: 11.6 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028573158144232502		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.028573158144232502 | validation: 0.040503948326736074]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031949729688035826		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.031949729688035826 | validation: 0.034680093458412095]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031077825993458177		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.031077825993458177 | validation: 0.0385898470698968]
	TIME [epoch: 11.6 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02768487861255137		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.02768487861255137 | validation: 0.04370923797397879]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034147803435824145		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.034147803435824145 | validation: 0.03995414384424992]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032072567592699525		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.032072567592699525 | validation: 0.03770248628556202]
	TIME [epoch: 11.6 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02738216271744408		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.02738216271744408 | validation: 0.03494704303642517]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027504921309952215		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.027504921309952215 | validation: 0.04376171838390459]
	TIME [epoch: 11.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02718099582012403		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.02718099582012403 | validation: 0.03909734428257543]
	TIME [epoch: 11.6 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027989701045521554		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.027989701045521554 | validation: 0.035747865289149826]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029686381320455382		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.029686381320455382 | validation: 0.046557579724640016]
	TIME [epoch: 11.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0285347427848261		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.0285347427848261 | validation: 0.038881256534569426]
	TIME [epoch: 11.6 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033257745411776465		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.033257745411776465 | validation: 0.043578807281276506]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03625886038864506		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.03625886038864506 | validation: 0.040092419463602764]
	TIME [epoch: 11.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02686883540687469		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.02686883540687469 | validation: 0.03538822573441639]
	TIME [epoch: 11.6 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027863932381989233		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.027863932381989233 | validation: 0.04122180093769217]
	TIME [epoch: 11.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03558945165066517		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.03558945165066517 | validation: 0.0372772494136268]
	TIME [epoch: 11.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026155919858494556		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.026155919858494556 | validation: 0.032915497040400366]
	TIME [epoch: 11.6 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02545848982223802		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.02545848982223802 | validation: 0.0354100506775461]
	TIME [epoch: 11.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03297425326576975		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.03297425326576975 | validation: 0.03677904921211741]
	TIME [epoch: 11.5 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03025077294100263		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.03025077294100263 | validation: 0.03687150880088606]
	TIME [epoch: 11.6 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024194946098952654		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.024194946098952654 | validation: 0.03716116223657121]
	TIME [epoch: 11.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027530867410230836		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.027530867410230836 | validation: 0.027121343377058817]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_1209.pth
	Model improved!!!
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019622389153432507		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.019622389153432507 | validation: 0.027729362256050757]
	TIME [epoch: 11.6 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024151596729089467		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.024151596729089467 | validation: 0.036224117145100834]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03349206515341809		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.03349206515341809 | validation: 0.043218511107920216]
	TIME [epoch: 11.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03332574632540598		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.03332574632540598 | validation: 0.025114978983416185]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_1213.pth
	Model improved!!!
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024351636600664826		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.024351636600664826 | validation: 0.03482031930080749]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028331553955129395		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.028331553955129395 | validation: 0.021547380912091147]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_1215.pth
	Model improved!!!
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022400005500877472		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.022400005500877472 | validation: 0.02179516238726656]
	TIME [epoch: 11.6 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02473936715186565		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.02473936715186565 | validation: 0.03676352710329267]
	TIME [epoch: 11.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024468933561262986		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.024468933561262986 | validation: 0.02603491516939304]
	TIME [epoch: 11.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022886190733695903		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.022886190733695903 | validation: 0.03416716587021807]
	TIME [epoch: 11.6 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030316460245174606		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.030316460245174606 | validation: 0.03999693330618254]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027293503575577235		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.027293503575577235 | validation: 0.03712574328899086]
	TIME [epoch: 11.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02619566367481589		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.02619566367481589 | validation: 0.0323961975943424]
	TIME [epoch: 11.6 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023873162705294656		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.023873162705294656 | validation: 0.03133225628095468]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019686475445137457		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.019686475445137457 | validation: 0.022564800583213054]
	TIME [epoch: 11.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020267046243968294		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.020267046243968294 | validation: 0.03331346281448186]
	TIME [epoch: 11.6 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0245039973495942		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.0245039973495942 | validation: 0.034264127397936404]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022814783629481625		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.022814783629481625 | validation: 0.024976532100742795]
	TIME [epoch: 11.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019629986903944553		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.019629986903944553 | validation: 0.03435269282510583]
	TIME [epoch: 11.6 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024153675778564542		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.024153675778564542 | validation: 0.0357758501279331]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03285681338313675		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.03285681338313675 | validation: 0.037182279880265415]
	TIME [epoch: 11.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025738837393343122		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.025738837393343122 | validation: 0.028099512898078105]
	TIME [epoch: 11.6 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020123754387307076		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.020123754387307076 | validation: 0.027601989516969072]
	TIME [epoch: 11.5 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02266672033588935		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.02266672033588935 | validation: 0.029666108212787364]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026663723398946043		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.026663723398946043 | validation: 0.03807003795001895]
	TIME [epoch: 11.6 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0225175068051483		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.0225175068051483 | validation: 0.036959468851036265]
	TIME [epoch: 11.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029616029502389167		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.029616029502389167 | validation: 0.043685417561219436]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039677461986055845		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.039677461986055845 | validation: 0.04597757789223719]
	TIME [epoch: 11.6 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035452260186362536		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.035452260186362536 | validation: 0.036980782282701935]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03293494465189897		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.03293494465189897 | validation: 0.04496838985286871]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03336761471887546		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.03336761471887546 | validation: 0.047196533570807254]
	TIME [epoch: 11.6 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03549959962432871		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.03549959962432871 | validation: 0.049594669042867266]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04384423044546289		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.04384423044546289 | validation: 0.043510347646619894]
	TIME [epoch: 11.6 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032114922635957575		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.032114922635957575 | validation: 0.03885500880848321]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03177276408433896		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.03177276408433896 | validation: 0.030978707866738883]
	TIME [epoch: 11.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030894087714783525		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.030894087714783525 | validation: 0.04415644224424079]
	TIME [epoch: 11.6 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0362548264671		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.0362548264671 | validation: 0.03944269916935905]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035601266328863346		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.035601266328863346 | validation: 0.04197302253822871]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03336709946752836		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.03336709946752836 | validation: 0.039158346302548865]
	TIME [epoch: 11.6 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0357855096697863		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.0357855096697863 | validation: 0.04220517438924906]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030184527280333794		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.030184527280333794 | validation: 0.03174034301662048]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026339644679553405		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.026339644679553405 | validation: 0.037149135307282956]
	TIME [epoch: 11.6 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028155147539410716		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.028155147539410716 | validation: 0.03962707586927611]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030392230817040865		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.030392230817040865 | validation: 0.04354729236952173]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027449017035345462		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.027449017035345462 | validation: 0.027601313569432295]
	TIME [epoch: 11.6 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02654338729145793		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.02654338729145793 | validation: 0.04026407843904844]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02806457388111573		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.02806457388111573 | validation: 0.02937268202323045]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02266852238008843		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.02266852238008843 | validation: 0.03367900648732486]
	TIME [epoch: 11.6 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024053587365298335		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.024053587365298335 | validation: 0.034840686950289586]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02555617554026069		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.02555617554026069 | validation: 0.03175351862235295]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02391714106786847		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.02391714106786847 | validation: 0.03278279054041446]
	TIME [epoch: 11.6 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031940981192638086		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.031940981192638086 | validation: 0.03692506150856193]
	TIME [epoch: 11.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03595700164666713		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.03595700164666713 | validation: 0.04951343511223316]
	TIME [epoch: 11.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040488306149596864		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.040488306149596864 | validation: 0.042177982538309566]
	TIME [epoch: 11.6 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03747634028744244		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.03747634028744244 | validation: 0.04103222791672053]
	TIME [epoch: 11.5 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03248305302501457		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.03248305302501457 | validation: 0.0449934710246694]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03541291523014552		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.03541291523014552 | validation: 0.046648500264316745]
	TIME [epoch: 11.6 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03002242494010391		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.03002242494010391 | validation: 0.028464520753796362]
	TIME [epoch: 11.5 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0282321950609423		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.0282321950609423 | validation: 0.03451744635539576]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029916024212226118		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.029916024212226118 | validation: 0.03219580282455897]
	TIME [epoch: 11.6 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02932001744802715		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.02932001744802715 | validation: 0.037721598262913804]
	TIME [epoch: 11.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02632965331532198		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.02632965331532198 | validation: 0.03081753266619548]
	TIME [epoch: 11.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029789136863937513		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.029789136863937513 | validation: 0.044398416103722645]
	TIME [epoch: 11.6 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03345762647581615		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.03345762647581615 | validation: 0.051120447501027955]
	TIME [epoch: 11.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04468980470776755		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.04468980470776755 | validation: 0.05145207568614646]
	TIME [epoch: 11.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03907295231220327		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.03907295231220327 | validation: 0.04073454886132396]
	TIME [epoch: 11.6 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033830043946190734		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.033830043946190734 | validation: 0.03913410196791198]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029689154340764065		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.029689154340764065 | validation: 0.03411114906188023]
	TIME [epoch: 11.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030687293458662022		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.030687293458662022 | validation: 0.04088759880284366]
	TIME [epoch: 11.6 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037261705979072204		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.037261705979072204 | validation: 0.042335858457729365]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034561573212125905		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.034561573212125905 | validation: 0.033505115339485074]
	TIME [epoch: 11.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029454551163287726		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.029454551163287726 | validation: 0.04711491440984327]
	TIME [epoch: 11.6 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03334983237958214		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.03334983237958214 | validation: 0.0409233252008223]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039371203834489416		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.039371203834489416 | validation: 0.05557915930373809]
	TIME [epoch: 11.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04478072384680214		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.04478072384680214 | validation: 0.04633787900889606]
	TIME [epoch: 11.6 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034231572619692945		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.034231572619692945 | validation: 0.032061396951262415]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024130068010019084		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.024130068010019084 | validation: 0.031490437685586944]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030589329380630144		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.030589329380630144 | validation: 0.038459984739615656]
	TIME [epoch: 11.6 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028878856712204203		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.028878856712204203 | validation: 0.03282749311667492]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025409835515897757		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.025409835515897757 | validation: 0.03128879482600849]
	TIME [epoch: 11.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022951170712473167		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.022951170712473167 | validation: 0.03301314166202733]
	TIME [epoch: 11.6 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02740922045221723		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.02740922045221723 | validation: 0.035333073295902476]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0266364638552481		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.0266364638552481 | validation: 0.028735814833094384]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023144082138057555		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.023144082138057555 | validation: 0.03258764630161126]
	TIME [epoch: 11.6 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04180860858945596		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.04180860858945596 | validation: 0.048392870064134445]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036917031977054884		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.036917031977054884 | validation: 0.04360694674484757]
	TIME [epoch: 11.5 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036239907592991054		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.036239907592991054 | validation: 0.045297577184667065]
	TIME [epoch: 11.6 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037288234794009494		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.037288234794009494 | validation: 0.033801643879881]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03421911757552611		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.03421911757552611 | validation: 0.042561734439757026]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027369977758845854		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.027369977758845854 | validation: 0.03243557241994335]
	TIME [epoch: 11.6 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023452781372875455		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.023452781372875455 | validation: 0.028492534102608113]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02197039859325451		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.02197039859325451 | validation: 0.04184942554734212]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022862380019407512		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.022862380019407512 | validation: 0.03708594473841843]
	TIME [epoch: 11.6 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027210145017008656		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.027210145017008656 | validation: 0.032244640443644564]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023276791681941942		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.023276791681941942 | validation: 0.030953457631691612]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02281466145122467		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.02281466145122467 | validation: 0.032298237408423545]
	TIME [epoch: 11.6 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020565247774612376		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.020565247774612376 | validation: 0.028534805953905788]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023535436436953515		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.023535436436953515 | validation: 0.03172192899376987]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02231365729824559		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.02231365729824559 | validation: 0.03931330213856249]
	TIME [epoch: 11.6 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02402747830594609		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.02402747830594609 | validation: 0.04113545662726331]
	TIME [epoch: 11.5 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028763622887623172		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.028763622887623172 | validation: 0.04271076845876284]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02477301588937458		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.02477301588937458 | validation: 0.027721449791092947]
	TIME [epoch: 11.6 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021835421238314803		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.021835421238314803 | validation: 0.034253315115256075]
	TIME [epoch: 11.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02418922795234742		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.02418922795234742 | validation: 0.034812551701662676]
	TIME [epoch: 11.5 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02277113405936277		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.02277113405936277 | validation: 0.03146451156621544]
	TIME [epoch: 11.6 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022710890066652202		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.022710890066652202 | validation: 0.03109141117638209]
	TIME [epoch: 11.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030082831662204053		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.030082831662204053 | validation: 0.030585532115483493]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026266206934720197		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.026266206934720197 | validation: 0.020694747778819637]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_1317.pth
	Model improved!!!
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017126627628065844		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.017126627628065844 | validation: 0.028858627664686443]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021048180833002268		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.021048180833002268 | validation: 0.025386880378794014]
	TIME [epoch: 11.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021437873932237846		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.021437873932237846 | validation: 0.028359847664584818]
	TIME [epoch: 11.6 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02537072196854385		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.02537072196854385 | validation: 0.03480920895510348]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02837913646070174		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.02837913646070174 | validation: 0.039058830620755346]
	TIME [epoch: 11.5 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02794526125546524		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.02794526125546524 | validation: 0.03457133255565347]
	TIME [epoch: 11.6 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017070072298811047		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.017070072298811047 | validation: 0.030376238398952125]
	TIME [epoch: 11.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024485895629238565		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.024485895629238565 | validation: 0.03530111069583047]
	TIME [epoch: 11.5 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024749424038775662		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.024749424038775662 | validation: 0.030708150846591092]
	TIME [epoch: 11.6 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021982598818248173		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.021982598818248173 | validation: 0.032506859949769165]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02261447771674137		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.02261447771674137 | validation: 0.03194243422538879]
	TIME [epoch: 11.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019341744824587954		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.019341744824587954 | validation: 0.02353712388001699]
	TIME [epoch: 11.6 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0254678421738811		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.0254678421738811 | validation: 0.03213565310980136]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028082051929869165		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.028082051929869165 | validation: 0.03481205694896388]
	TIME [epoch: 11.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02736540660660613		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.02736540660660613 | validation: 0.02973717671963722]
	TIME [epoch: 11.6 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024420626975535653		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.024420626975535653 | validation: 0.03321685296805539]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025634998023364816		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.025634998023364816 | validation: 0.03057212759257445]
	TIME [epoch: 11.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028585014634550585		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.028585014634550585 | validation: 0.03506312873504896]
	TIME [epoch: 11.6 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02481140631534556		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.02481140631534556 | validation: 0.023309425853300994]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017490474914050067		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.017490474914050067 | validation: 0.02899969480139629]
	TIME [epoch: 11.5 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01901329643078645		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.01901329643078645 | validation: 0.027679420688488516]
	TIME [epoch: 11.6 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02166814961116917		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.02166814961116917 | validation: 0.03323061318667689]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020848777224581106		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.020848777224581106 | validation: 0.02848367079029737]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023625363286337686		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.023625363286337686 | validation: 0.03141180548148974]
	TIME [epoch: 11.6 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029191075138920365		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.029191075138920365 | validation: 0.03222936666074304]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02723471700915068		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.02723471700915068 | validation: 0.034767168100109325]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026740472419944917		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.026740472419944917 | validation: 0.029102696464402424]
	TIME [epoch: 11.6 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02095302196093644		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.02095302196093644 | validation: 0.027807285620542157]
	TIME [epoch: 11.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023252214859455465		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.023252214859455465 | validation: 0.03137964788669182]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022515729873477712		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.022515729873477712 | validation: 0.018229016228088108]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_1347.pth
	Model improved!!!
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023433975775455192		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.023433975775455192 | validation: 0.028958789196369957]
	TIME [epoch: 11.5 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023023110403704847		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.023023110403704847 | validation: 0.031884139930559594]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022966483624406796		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.022966483624406796 | validation: 0.019551949513006154]
	TIME [epoch: 11.6 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012452084355033682		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.012452084355033682 | validation: 0.02804900861822059]
	TIME [epoch: 11.5 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02048078779363176		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.02048078779363176 | validation: 0.03610970925083498]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02523136464977005		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.02523136464977005 | validation: 0.030564418544025165]
	TIME [epoch: 11.6 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021202124447288608		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.021202124447288608 | validation: 0.02570745171519725]
	TIME [epoch: 11.5 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015691641131173682		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.015691641131173682 | validation: 0.020876038744150574]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013710400446742252		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.013710400446742252 | validation: 0.03875141402591633]
	TIME [epoch: 11.6 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023285588306090208		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.023285588306090208 | validation: 0.03323768560285406]
	TIME [epoch: 11.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022965363533997852		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.022965363533997852 | validation: 0.023211158233924563]
	TIME [epoch: 11.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016595265937648873		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.016595265937648873 | validation: 0.024786255711767537]
	TIME [epoch: 11.6 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0202514293057133		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.0202514293057133 | validation: 0.029471247056846766]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019878197075738978		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.019878197075738978 | validation: 0.029881956801838347]
	TIME [epoch: 11.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017105578708872585		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.017105578708872585 | validation: 0.023738330419614415]
	TIME [epoch: 11.6 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0191134183087785		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.0191134183087785 | validation: 0.02733307839553088]
	TIME [epoch: 11.5 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017599519977594142		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.017599519977594142 | validation: 0.030287005391378203]
	TIME [epoch: 11.5 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020402819267008935		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.020402819267008935 | validation: 0.020499586265847684]
	TIME [epoch: 11.6 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02121892437722095		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.02121892437722095 | validation: 0.02818541901196242]
	TIME [epoch: 11.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017992843419058942		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.017992843419058942 | validation: 0.030625299349720372]
	TIME [epoch: 11.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021224094526887675		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.021224094526887675 | validation: 0.030924106656323114]
	TIME [epoch: 11.6 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02451822188533017		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.02451822188533017 | validation: 0.03658304184864583]
	TIME [epoch: 11.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025951120058727208		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.025951120058727208 | validation: 0.0355387865112923]
	TIME [epoch: 11.5 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03241074918440723		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.03241074918440723 | validation: 0.04091999790160255]
	TIME [epoch: 11.6 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027209601765087656		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.027209601765087656 | validation: 0.024389978180990354]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025188960326180912		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.025188960326180912 | validation: 0.036358253341637545]
	TIME [epoch: 11.6 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02002763613145893		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.02002763613145893 | validation: 0.037821889605208624]
	TIME [epoch: 11.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021767242005777246		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.021767242005777246 | validation: 0.031018849049316153]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02078968291899113		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.02078968291899113 | validation: 0.029029029314046648]
	TIME [epoch: 11.6 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02222434508662294		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.02222434508662294 | validation: 0.03677742722144808]
	TIME [epoch: 11.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03327829303706516		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.03327829303706516 | validation: 0.037493474918513466]
	TIME [epoch: 11.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02871079899593127		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.02871079899593127 | validation: 0.03438305318794858]
	TIME [epoch: 11.6 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02311298400805776		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.02311298400805776 | validation: 0.027890144483798052]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02555562379886795		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.02555562379886795 | validation: 0.02967658091275407]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022156399910614487		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.022156399910614487 | validation: 0.028731717780584247]
	TIME [epoch: 11.6 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01704224394984075		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.01704224394984075 | validation: 0.02919905697835101]
	TIME [epoch: 11.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01924022244621506		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.01924022244621506 | validation: 0.03605801766935717]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024691489856854862		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.024691489856854862 | validation: 0.025700533356502537]
	TIME [epoch: 11.6 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020562180485044435		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.020562180485044435 | validation: 0.025815667593379468]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018057114453082272		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.018057114453082272 | validation: 0.02345384079311248]
	TIME [epoch: 11.5 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017779484699596206		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.017779484699596206 | validation: 0.02691014913920978]
	TIME [epoch: 11.6 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020596703585284697		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.020596703585284697 | validation: 0.03189260633518056]
	TIME [epoch: 11.5 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01874621665510233		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.01874621665510233 | validation: 0.027647192793544707]
	TIME [epoch: 11.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01918539238926984		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.01918539238926984 | validation: 0.026811733025057016]
	TIME [epoch: 11.6 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018142989461170097		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.018142989461170097 | validation: 0.01657582063541427]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_1392.pth
	Model improved!!!
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016362432258087867		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.016362432258087867 | validation: 0.028385897334454]
	TIME [epoch: 11.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0210285820614725		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.0210285820614725 | validation: 0.03959624967363448]
	TIME [epoch: 11.6 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02305445346177102		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.02305445346177102 | validation: 0.03180898142223457]
	TIME [epoch: 11.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023645581761475187		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.023645581761475187 | validation: 0.023997585483705574]
	TIME [epoch: 11.5 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020837464793465404		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.020837464793465404 | validation: 0.03812596072610699]
	TIME [epoch: 11.6 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022920915620600342		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.022920915620600342 | validation: 0.02445996891870509]
	TIME [epoch: 11.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02039050482955729		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.02039050482955729 | validation: 0.02326106609252122]
	TIME [epoch: 11.5 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019154982789205476		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.019154982789205476 | validation: 0.030127222724201312]
	TIME [epoch: 11.6 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014300257743126073		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.014300257743126073 | validation: 0.02492007050780155]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01473475106352745		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.01473475106352745 | validation: 0.02594873815388195]
	TIME [epoch: 11.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01888475211136046		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.01888475211136046 | validation: 0.02696443644842548]
	TIME [epoch: 11.6 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0145486432093048		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.0145486432093048 | validation: 0.024794960722810018]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020997755065363014		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.020997755065363014 | validation: 0.024012591857215326]
	TIME [epoch: 11.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017149125349378173		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.017149125349378173 | validation: 0.022393629251495354]
	TIME [epoch: 11.6 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015861816888258783		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.015861816888258783 | validation: 0.02984703003462709]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019286231778362785		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.019286231778362785 | validation: 0.03352624294853924]
	TIME [epoch: 11.5 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019169233550532905		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.019169233550532905 | validation: 0.024451924744262967]
	TIME [epoch: 11.6 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022571508473645384		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.022571508473645384 | validation: 0.029025012623793773]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0197899481296294		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.0197899481296294 | validation: 0.028711308919211635]
	TIME [epoch: 11.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019452509667735682		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.019452509667735682 | validation: 0.033554792414447934]
	TIME [epoch: 11.6 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018352778738323042		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.018352778738323042 | validation: 0.02223937880106303]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019663723373632137		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.019663723373632137 | validation: 0.025224550169369024]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021337832779054638		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.021337832779054638 | validation: 0.024102071341563863]
	TIME [epoch: 11.6 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01324162691488812		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.01324162691488812 | validation: 0.03259255364831061]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021639783773997088		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.021639783773997088 | validation: 0.02959935052236463]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02148816959280863		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.02148816959280863 | validation: 0.02306114389409162]
	TIME [epoch: 11.6 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01971233673251195		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.01971233673251195 | validation: 0.024943785009628128]
	TIME [epoch: 11.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022684772913344524		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.022684772913344524 | validation: 0.0385910552206661]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018380067532308256		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.018380067532308256 | validation: 0.03151686647897339]
	TIME [epoch: 11.6 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02060520325102621		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.02060520325102621 | validation: 0.03530071990321162]
	TIME [epoch: 11.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02743529938029705		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.02743529938029705 | validation: 0.04182823046284776]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030237927704639955		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.030237927704639955 | validation: 0.04003676434179182]
	TIME [epoch: 11.6 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023343265128705524		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.023343265128705524 | validation: 0.024219583099677273]
	TIME [epoch: 11.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017749171274629882		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.017749171274629882 | validation: 0.026744269453044932]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020411606657210823		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.020411606657210823 | validation: 0.023937748930654385]
	TIME [epoch: 11.6 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020657520045237965		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.020657520045237965 | validation: 0.02046315322467724]
	TIME [epoch: 11.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02073037520024166		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.02073037520024166 | validation: 0.02905880288586749]
	TIME [epoch: 11.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020731760512247614		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.020731760512247614 | validation: 0.018553163915439545]
	TIME [epoch: 11.6 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02451665866657145		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.02451665866657145 | validation: 0.034981055604019824]
	TIME [epoch: 11.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021025626933077298		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.021025626933077298 | validation: 0.029867929272985594]
	TIME [epoch: 11.5 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02194708715894151		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.02194708715894151 | validation: 0.026184104058163796]
	TIME [epoch: 11.6 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023166401986788383		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.023166401986788383 | validation: 0.03728176704662565]
	TIME [epoch: 11.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020764896750573233		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.020764896750573233 | validation: 0.033909166320326485]
	TIME [epoch: 11.5 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026777695705886707		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.026777695705886707 | validation: 0.030316063017637083]
	TIME [epoch: 11.6 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023882604386712823		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.023882604386712823 | validation: 0.03000511132346599]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024136640991915113		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.024136640991915113 | validation: 0.03762844310779156]
	TIME [epoch: 11.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023147739758135572		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.023147739758135572 | validation: 0.03349379471744328]
	TIME [epoch: 11.6 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02170808522154837		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.02170808522154837 | validation: 0.02291060114234905]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01845821739567293		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.01845821739567293 | validation: 0.032235884714093624]
	TIME [epoch: 11.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02127465850961057		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.02127465850961057 | validation: 0.023678103068226975]
	TIME [epoch: 11.6 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018074443730912177		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.018074443730912177 | validation: 0.018884420858671848]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01960625418459662		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.01960625418459662 | validation: 0.029423360095271668]
	TIME [epoch: 11.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018952985864577453		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.018952985864577453 | validation: 0.034606516534454304]
	TIME [epoch: 11.6 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02255688363305329		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.02255688363305329 | validation: 0.03224029865406316]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01860437917190231		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.01860437917190231 | validation: 0.024093417302838906]
	TIME [epoch: 11.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016355429261845206		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.016355429261845206 | validation: 0.027662602495395622]
	TIME [epoch: 11.6 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017295954496412448		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.017295954496412448 | validation: 0.027303254569755575]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01754503361523834		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.01754503361523834 | validation: 0.02257873676659481]
	TIME [epoch: 11.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020365303637894763		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.020365303637894763 | validation: 0.025515062490566384]
	TIME [epoch: 11.6 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02147144356099601		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.02147144356099601 | validation: 0.02444779054928163]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01846696474347335		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.01846696474347335 | validation: 0.029534314034033393]
	TIME [epoch: 11.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017754294979718113		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.017754294979718113 | validation: 0.025572899985731565]
	TIME [epoch: 11.6 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018262454921752824		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.018262454921752824 | validation: 0.035936845857459224]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021461017806118962		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.021461017806118962 | validation: 0.030602607607332955]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018365184294031618		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.018365184294031618 | validation: 0.02610834860167798]
	TIME [epoch: 11.6 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02240492252279716		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.02240492252279716 | validation: 0.028911143994367085]
	TIME [epoch: 11.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025766694281283645		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.025766694281283645 | validation: 0.03783417113481414]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028460519198529037		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.028460519198529037 | validation: 0.03626252892647031]
	TIME [epoch: 11.6 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027133475033533302		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.027133475033533302 | validation: 0.040797603327868526]
	TIME [epoch: 11.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02000128466026986		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.02000128466026986 | validation: 0.029709931785911147]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01964997192728988		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.01964997192728988 | validation: 0.02393796603671036]
	TIME [epoch: 11.6 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021183025274804188		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.021183025274804188 | validation: 0.034459227283032856]
	TIME [epoch: 11.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019066711682383348		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.019066711682383348 | validation: 0.02481435749553385]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019661433693873437		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.019661433693873437 | validation: 0.03091088812738498]
	TIME [epoch: 11.6 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02164318420644163		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.02164318420644163 | validation: 0.03136500484657083]
	TIME [epoch: 11.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014792947548067578		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.014792947548067578 | validation: 0.018812270702048862]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022315014492746626		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.022315014492746626 | validation: 0.019585523321509098]
	TIME [epoch: 11.6 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0203338243382336		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.0203338243382336 | validation: 0.031942295702767985]
	TIME [epoch: 11.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017940455589808738		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.017940455589808738 | validation: 0.031012689691147736]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019107779198251115		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.019107779198251115 | validation: 0.0274179917640625]
	TIME [epoch: 11.6 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014666740924852801		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.014666740924852801 | validation: 0.030060071115940893]
	TIME [epoch: 11.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017432757828528263		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.017432757828528263 | validation: 0.027036290280786916]
	TIME [epoch: 11.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017244841693915734		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.017244841693915734 | validation: 0.012696425962838438]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_1475.pth
	Model improved!!!
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018592021629441863		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.018592021629441863 | validation: 0.03471622397525914]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020984722578512055		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.020984722578512055 | validation: 0.02568615508368908]
	TIME [epoch: 11.5 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02349769821938775		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.02349769821938775 | validation: 0.02928940846545772]
	TIME [epoch: 11.6 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023635365000355114		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.023635365000355114 | validation: 0.03191581316534186]
	TIME [epoch: 11.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021785237131921705		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.021785237131921705 | validation: 0.026267599461991253]
	TIME [epoch: 11.5 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016295226837572185		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.016295226837572185 | validation: 0.019906051680493565]
	TIME [epoch: 11.6 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01971471474174507		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.01971471474174507 | validation: 0.023781290458074592]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021000592393710597		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.021000592393710597 | validation: 0.025062877113672763]
	TIME [epoch: 11.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018907566977076205		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.018907566977076205 | validation: 0.028441241366163307]
	TIME [epoch: 11.6 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019609170244746062		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.019609170244746062 | validation: 0.030154589368523003]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016899520793956395		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.016899520793956395 | validation: 0.028146952537851756]
	TIME [epoch: 11.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025337747621811485		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.025337747621811485 | validation: 0.028962442325601648]
	TIME [epoch: 11.6 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018448334262653368		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.018448334262653368 | validation: 0.027447329180496766]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02207036596607667		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.02207036596607667 | validation: 0.018085056402628204]
	TIME [epoch: 11.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02204950978174548		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.02204950978174548 | validation: 0.028077894899724933]
	TIME [epoch: 11.6 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023267237362870955		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.023267237362870955 | validation: 0.03199850751525269]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02048398337777184		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.02048398337777184 | validation: 0.024482914019147747]
	TIME [epoch: 11.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024011734705283443		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.024011734705283443 | validation: 0.023817501271678043]
	TIME [epoch: 11.6 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021654010271597735		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.021654010271597735 | validation: 0.034579853196491074]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028952382023424515		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.028952382023424515 | validation: 0.03925781355242762]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023385241695978866		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.023385241695978866 | validation: 0.020515021174940824]
	TIME [epoch: 11.6 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015384135814005922		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.015384135814005922 | validation: 0.027569331643700436]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015852049505631134		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.015852049505631134 | validation: 0.017395767913325696]
	TIME [epoch: 11.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016950138249156584		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.016950138249156584 | validation: 0.01981256995059152]
	TIME [epoch: 11.6 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014686710957757875		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.014686710957757875 | validation: 0.03235222703765432]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01563373310642634		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.01563373310642634 | validation: 0.019158741989007744]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017205495475021038		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.017205495475021038 | validation: 0.029751171226360583]
	TIME [epoch: 11.6 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012364483040924171		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.012364483040924171 | validation: 0.020018707292271783]
	TIME [epoch: 11.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013853749509128476		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.013853749509128476 | validation: 0.022289898070878934]
	TIME [epoch: 11.6 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011930039988190939		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.011930039988190939 | validation: 0.020187714224938737]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01299834545833468		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.01299834545833468 | validation: 0.023921732309295254]
	TIME [epoch: 11.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01400570880639205		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.01400570880639205 | validation: 0.029148436000383155]
	TIME [epoch: 11.6 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018154334905108444		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.018154334905108444 | validation: 0.02792352992253419]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017734990331173112		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.017734990331173112 | validation: 0.02625244006579286]
	TIME [epoch: 11.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015672883396012725		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.015672883396012725 | validation: 0.02156393829448339]
	TIME [epoch: 11.6 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016427315883697214		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.016427315883697214 | validation: 0.017395947028382704]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013896739450265646		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.013896739450265646 | validation: 0.027378352207776274]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016474849322279862		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.016474849322279862 | validation: 0.02823258337264805]
	TIME [epoch: 11.6 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01960953210434993		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.01960953210434993 | validation: 0.031363836593761886]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02116966845611442		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.02116966845611442 | validation: 0.03434593549111374]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02130484322966733		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.02130484322966733 | validation: 0.014776760390315051]
	TIME [epoch: 11.6 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01973127823371735		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.01973127823371735 | validation: 0.0293201501331705]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01894936211457111		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.01894936211457111 | validation: 0.02216290115111592]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01757503026429078		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.01757503026429078 | validation: 0.024112812567793372]
	TIME [epoch: 11.6 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01352998930561735		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.01352998930561735 | validation: 0.026771855711637933]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015284690529722842		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.015284690529722842 | validation: 0.024156338168802156]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015753252494205814		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.015753252494205814 | validation: 0.026429137994719742]
	TIME [epoch: 11.6 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017908132247795975		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.017908132247795975 | validation: 0.025002026695387248]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01575114604978109		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.01575114604978109 | validation: 0.026644386677595375]
	TIME [epoch: 11.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017125899894303007		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.017125899894303007 | validation: 0.02109523733988258]
	TIME [epoch: 11.6 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015690370263682744		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.015690370263682744 | validation: 0.01931060814364159]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012685609309546715		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.012685609309546715 | validation: 0.0235580323315249]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011085894652275276		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.011085894652275276 | validation: 0.02555163590168679]
	TIME [epoch: 11.6 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016479838919268516		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.016479838919268516 | validation: 0.03322698377392892]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01344095816751099		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.01344095816751099 | validation: 0.019105232046684777]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014865301101035424		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.014865301101035424 | validation: 0.021880401861683847]
	TIME [epoch: 11.6 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015260030711292727		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.015260030711292727 | validation: 0.03221027979594205]
	TIME [epoch: 11.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016004946838331466		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.016004946838331466 | validation: 0.020895204259609407]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015192833927557783		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.015192833927557783 | validation: 0.023650158201979538]
	TIME [epoch: 11.6 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01394722215934191		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.01394722215934191 | validation: 0.02417594059841445]
	TIME [epoch: 11.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01767695808442736		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.01767695808442736 | validation: 0.017170655465770228]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018060862666446423		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.018060862666446423 | validation: 0.031623930571127765]
	TIME [epoch: 11.6 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01406542656732426		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.01406542656732426 | validation: 0.02241088004441191]
	TIME [epoch: 11.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017005674714226756		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.017005674714226756 | validation: 0.03401596947506688]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016672207127402833		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.016672207127402833 | validation: 0.030199945064342284]
	TIME [epoch: 11.6 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015692820867217024		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.015692820867217024 | validation: 0.026799237683844596]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015194133690073518		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.015194133690073518 | validation: 0.015934802996516964]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016530844177633303		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.016530844177633303 | validation: 0.019956840605275968]
	TIME [epoch: 11.6 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020101569650864404		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.020101569650864404 | validation: 0.026222969704066356]
	TIME [epoch: 11.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014877870540876182		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.014877870540876182 | validation: 0.024545988649109254]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016361439028177986		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.016361439028177986 | validation: 0.03269149267206703]
	TIME [epoch: 11.6 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01503055293698112		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.01503055293698112 | validation: 0.022614253032971404]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019202795490841695		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.019202795490841695 | validation: 0.028302576839640624]
	TIME [epoch: 11.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020325997399979017		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.020325997399979017 | validation: 0.028880791054368304]
	TIME [epoch: 11.6 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017651286711703428		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.017651286711703428 | validation: 0.020871089561996865]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015606850702541994		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.015606850702541994 | validation: 0.024108273961717244]
	TIME [epoch: 11.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01634570037167375		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.01634570037167375 | validation: 0.01964724083543762]
	TIME [epoch: 11.6 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01843563945046974		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.01843563945046974 | validation: 0.020412875454066684]
	TIME [epoch: 11.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018243592233588152		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.018243592233588152 | validation: 0.029977568220104826]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02798266372679529		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.02798266372679529 | validation: 0.030466123752913417]
	TIME [epoch: 11.6 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02561740623287822		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.02561740623287822 | validation: 0.02752556353247601]
	TIME [epoch: 11.6 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021427367508739296		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.021427367508739296 | validation: 0.024856269007403668]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019418013461961637		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.019418013461961637 | validation: 0.03755151979772845]
	TIME [epoch: 11.6 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01770809703624036		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.01770809703624036 | validation: 0.022643157631531647]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020411228191558765		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.020411228191558765 | validation: 0.021658651447544027]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017324152162042902		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.017324152162042902 | validation: 0.026843147420847382]
	TIME [epoch: 11.6 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018443200024444606		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.018443200024444606 | validation: 0.030289458479129325]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020074245649661735		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.020074245649661735 | validation: 0.026226593563747642]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016163304485556737		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.016163304485556737 | validation: 0.03230303253460919]
	TIME [epoch: 11.6 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01637687201736296		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.01637687201736296 | validation: 0.028710762234506127]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01683488721783169		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.01683488721783169 | validation: 0.02270867260048517]
	TIME [epoch: 11.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015879488129653608		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.015879488129653608 | validation: 0.02581965861244017]
	TIME [epoch: 11.6 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018868849547571526		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.018868849547571526 | validation: 0.028973556823201206]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015767957900898844		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.015767957900898844 | validation: 0.021929895674367518]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013005576374448338		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.013005576374448338 | validation: 0.022218756134768435]
	TIME [epoch: 11.6 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011259759775747984		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.011259759775747984 | validation: 0.026341513155532455]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016832616883611973		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.016832616883611973 | validation: 0.019365476570839615]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01735646052915249		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.01735646052915249 | validation: 0.019818355001002274]
	TIME [epoch: 11.6 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012847091221001654		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.012847091221001654 | validation: 0.02525415539096561]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014305273015708327		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.014305273015708327 | validation: 0.021329294532624173]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014341816328884052		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.014341816328884052 | validation: 0.02477658891932198]
	TIME [epoch: 11.6 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014815279712038951		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.014815279712038951 | validation: 0.024519195580004167]
	TIME [epoch: 11.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0154971809828754		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.0154971809828754 | validation: 0.01851546908949462]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01688147823746378		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.01688147823746378 | validation: 0.02324507609842291]
	TIME [epoch: 11.6 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015491677035858825		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.015491677035858825 | validation: 0.02146840390328821]
	TIME [epoch: 11.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014912482472390272		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.014912482472390272 | validation: 0.024112206808039143]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01643206294593377		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.01643206294593377 | validation: 0.02358187183744655]
	TIME [epoch: 11.6 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01718242371631677		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.01718242371631677 | validation: 0.02222336532829389]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01612810630127338		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.01612810630127338 | validation: 0.03019697529275468]
	TIME [epoch: 11.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014722029590595154		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.014722029590595154 | validation: 0.01946955322125722]
	TIME [epoch: 11.6 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01965213038642717		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.01965213038642717 | validation: 0.026501072969659974]
	TIME [epoch: 11.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01943286841814563		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.01943286841814563 | validation: 0.01861079651899363]
	TIME [epoch: 11.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01604996389134146		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.01604996389134146 | validation: 0.02295566813160579]
	TIME [epoch: 11.6 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015999678097059905		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.015999678097059905 | validation: 0.01993057348146131]
	TIME [epoch: 11.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016851079600027196		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.016851079600027196 | validation: 0.026915573639612556]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015778788596535396		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.015778788596535396 | validation: 0.022405507504217693]
	TIME [epoch: 11.6 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012837552634684089		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.012837552634684089 | validation: 0.02531428830261449]
	TIME [epoch: 11.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015176962960572677		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.015176962960572677 | validation: 0.024575086313900832]
	TIME [epoch: 11.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01638485618247713		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.01638485618247713 | validation: 0.026501430648281442]
	TIME [epoch: 11.6 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018957333496924817		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.018957333496924817 | validation: 0.023380357182711597]
	TIME [epoch: 11.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01950511026801919		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.01950511026801919 | validation: 0.018260537315865168]
	TIME [epoch: 11.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015119671120773018		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.015119671120773018 | validation: 0.027899830225043463]
	TIME [epoch: 11.6 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01721235432231009		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.01721235432231009 | validation: 0.02292505909588485]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014578215364487637		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.014578215364487637 | validation: 0.019778750139377733]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02237569259928269		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.02237569259928269 | validation: 0.022751504824509685]
	TIME [epoch: 11.6 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01528304166351257		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.01528304166351257 | validation: 0.018190771679891055]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021068851874414683		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.021068851874414683 | validation: 0.025603917768673146]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01911954072298314		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.01911954072298314 | validation: 0.026777424058109157]
	TIME [epoch: 11.6 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017680993456265788		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.017680993456265788 | validation: 0.022220526661116326]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014926081085293046		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.014926081085293046 | validation: 0.029372641565363546]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01710029839495609		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.01710029839495609 | validation: 0.022824829103043592]
	TIME [epoch: 11.6 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01667938580072053		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.01667938580072053 | validation: 0.030204696803527418]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01889519631823008		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.01889519631823008 | validation: 0.026241385653116886]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016510069658527242		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.016510069658527242 | validation: 0.03686721074547133]
	TIME [epoch: 11.6 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01772769304736418		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.01772769304736418 | validation: 0.022088409675983946]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014266672796768522		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.014266672796768522 | validation: 0.019406167539668864]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019679591144164378		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.019679591144164378 | validation: 0.023843536479878986]
	TIME [epoch: 11.6 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01845033947665143		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.01845033947665143 | validation: 0.02788603076257033]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01503831153817002		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.01503831153817002 | validation: 0.022757045930844048]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013248306395618196		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.013248306395618196 | validation: 0.028962204759773746]
	TIME [epoch: 11.6 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016652672212741512		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.016652672212741512 | validation: 0.02652201953325463]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018003216662759936		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.018003216662759936 | validation: 0.025719268711453323]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01825743421591973		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.01825743421591973 | validation: 0.02473497430615176]
	TIME [epoch: 11.6 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016542896448580056		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.016542896448580056 | validation: 0.019847419139585838]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020581648757235723		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.020581648757235723 | validation: 0.02630868214647435]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01861398463270772		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.01861398463270772 | validation: 0.02504087547455516]
	TIME [epoch: 11.6 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01326362506386938		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.01326362506386938 | validation: 0.02854063759808348]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018648010568551587		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.018648010568551587 | validation: 0.018734587495638853]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016151305261840724		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.016151305261840724 | validation: 0.017829858189121812]
	TIME [epoch: 11.6 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019869286745068618		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.019869286745068618 | validation: 0.022212102831564204]
	TIME [epoch: 11.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015776104867340702		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.015776104867340702 | validation: 0.02874850729272173]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015095235546718147		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.015095235546718147 | validation: 0.018674237575734554]
	TIME [epoch: 11.6 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017049652645228133		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.017049652645228133 | validation: 0.021743911797315548]
	TIME [epoch: 11.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015789519921655608		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.015789519921655608 | validation: 0.02078215290628692]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014395334581595028		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.014395334581595028 | validation: 0.020143625786127536]
	TIME [epoch: 11.6 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015421663595028353		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.015421663595028353 | validation: 0.027305052827788896]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01739372934440914		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.01739372934440914 | validation: 0.018491107896188595]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01880472938611975		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.01880472938611975 | validation: 0.02809383348261713]
	TIME [epoch: 11.6 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019520812364870563		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.019520812364870563 | validation: 0.025432628610014513]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015800977336632438		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.015800977336632438 | validation: 0.02064406226607002]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015410840826131486		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.015410840826131486 | validation: 0.020370801532663203]
	TIME [epoch: 11.6 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013739019386933175		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.013739019386933175 | validation: 0.027255385235113984]
	TIME [epoch: 11.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01795523808595466		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.01795523808595466 | validation: 0.023936570068023435]
	TIME [epoch: 11.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015168545539045144		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.015168545539045144 | validation: 0.02202205775850307]
	TIME [epoch: 11.6 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013717885048715196		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.013717885048715196 | validation: 0.021081710605702356]
	TIME [epoch: 11.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016775543161273557		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.016775543161273557 | validation: 0.01946464736778686]
	TIME [epoch: 11.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014644415190872211		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.014644415190872211 | validation: 0.024452728246918562]
	TIME [epoch: 11.6 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017850319179171566		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.017850319179171566 | validation: 0.016897210833165387]
	TIME [epoch: 11.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014384447657861532		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.014384447657861532 | validation: 0.023556021719740316]
	TIME [epoch: 11.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01523880209808032		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.01523880209808032 | validation: 0.02264850161814029]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01864388856407352		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.01864388856407352 | validation: 0.021503469129900497]
	TIME [epoch: 11.5 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015108409742489429		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.015108409742489429 | validation: 0.02641558716781755]
	TIME [epoch: 11.6 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0158011636330478		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.0158011636330478 | validation: 0.030804945670111935]
	TIME [epoch: 11.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016778745792975714		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.016778745792975714 | validation: 0.024387983549968312]
	TIME [epoch: 11.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015788406370292878		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.015788406370292878 | validation: 0.019778947019857634]
	TIME [epoch: 11.6 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014084316399493277		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.014084316399493277 | validation: 0.023819540659778492]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016952192388567888		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.016952192388567888 | validation: 0.02706452336108245]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015550867041339086		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.015550867041339086 | validation: 0.0226558267378418]
	TIME [epoch: 11.6 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014643270378531336		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.014643270378531336 | validation: 0.021229630543992135]
	TIME [epoch: 11.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013452968661398843		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.013452968661398843 | validation: 0.022496770125376625]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015509979664103701		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.015509979664103701 | validation: 0.023102588573914118]
	TIME [epoch: 11.6 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018032157416471555		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.018032157416471555 | validation: 0.02759507911214852]
	TIME [epoch: 11.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01699542841431566		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.01699542841431566 | validation: 0.02730923788255102]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01440368183099109		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.01440368183099109 | validation: 0.02798577107166183]
	TIME [epoch: 11.6 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015292022549496517		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.015292022549496517 | validation: 0.01976446664867816]
	TIME [epoch: 11.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012260845272578738		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.012260845272578738 | validation: 0.023995248654923158]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017946290989131048		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.017946290989131048 | validation: 0.023831895565840394]
	TIME [epoch: 11.6 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01429544550364054		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.01429544550364054 | validation: 0.020599574815623935]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017110441155209266		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.017110441155209266 | validation: 0.01804681853425682]
	TIME [epoch: 11.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01044106367424805		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.01044106367424805 | validation: 0.024932130121589218]
	TIME [epoch: 11.6 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012927989149250139		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.012927989149250139 | validation: 0.018174706170897097]
	TIME [epoch: 11.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015896347150484783		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.015896347150484783 | validation: 0.02570869673104752]
	TIME [epoch: 11.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011585675550446848		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.011585675550446848 | validation: 0.019786431129827125]
	TIME [epoch: 11.6 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01459553709614753		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.01459553709614753 | validation: 0.028100538779864702]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016753992396910805		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.016753992396910805 | validation: 0.01643246228761763]
	TIME [epoch: 11.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016102744037851092		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.016102744037851092 | validation: 0.02303393375097224]
	TIME [epoch: 11.6 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01225056957583883		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.01225056957583883 | validation: 0.023051285319881116]
	TIME [epoch: 11.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012383234126467323		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.012383234126467323 | validation: 0.024530509150236978]
	TIME [epoch: 11.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010752612103897802		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.010752612103897802 | validation: 0.01843701220016464]
	TIME [epoch: 11.6 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014204896037945341		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.014204896037945341 | validation: 0.01971252179070418]
	TIME [epoch: 11.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014702395740498381		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.014702395740498381 | validation: 0.01853697389827604]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015286834700566132		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.015286834700566132 | validation: 0.022994153262165046]
	TIME [epoch: 11.6 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013811155060238074		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.013811155060238074 | validation: 0.022061185592240334]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013303556523321065		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.013303556523321065 | validation: 0.024548277264537958]
	TIME [epoch: 11.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013196511696342483		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.013196511696342483 | validation: 0.02608057526100307]
	TIME [epoch: 11.6 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012633847149727347		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.012633847149727347 | validation: 0.02288458179694947]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015142081595513428		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.015142081595513428 | validation: 0.022908278321233926]
	TIME [epoch: 11.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014348649234077485		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.014348649234077485 | validation: 0.016690747440076665]
	TIME [epoch: 11.6 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01096731220118832		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.01096731220118832 | validation: 0.01866512293593476]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014099810737849092		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.014099810737849092 | validation: 0.015464243305241258]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012491566632136476		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.012491566632136476 | validation: 0.022095397340942124]
	TIME [epoch: 11.6 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0146422422210907		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.0146422422210907 | validation: 0.02000800628106952]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010762942057602929		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.010762942057602929 | validation: 0.019518761641727368]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01769524712372892		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.01769524712372892 | validation: 0.021086921612131368]
	TIME [epoch: 11.6 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015930348015660924		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.015930348015660924 | validation: 0.019270050711501004]
	TIME [epoch: 11.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01801472175673761		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.01801472175673761 | validation: 0.02501213823943929]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01427154124198146		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.01427154124198146 | validation: 0.02824505744018524]
	TIME [epoch: 11.6 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016247397703804442		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.016247397703804442 | validation: 0.025062085130165043]
	TIME [epoch: 11.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014486320162277227		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.014486320162277227 | validation: 0.021035889334323668]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018671198233394137		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.018671198233394137 | validation: 0.02313439437349565]
	TIME [epoch: 11.6 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015464788185545253		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.015464788185545253 | validation: 0.02665946044468608]
	TIME [epoch: 11.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012953052115094319		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.012953052115094319 | validation: 0.025747986904386653]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016656266147299262		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.016656266147299262 | validation: 0.019960044493339626]
	TIME [epoch: 11.6 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012123241909432283		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.012123241909432283 | validation: 0.02702862761332595]
	TIME [epoch: 11.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015406379030577524		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.015406379030577524 | validation: 0.019053934913170787]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0149447504628558		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.0149447504628558 | validation: 0.027361183098029575]
	TIME [epoch: 11.6 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016217574787440778		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.016217574787440778 | validation: 0.015286135041323761]
	TIME [epoch: 11.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013760357871516648		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.013760357871516648 | validation: 0.020824913358220152]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013712316666516362		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.013712316666516362 | validation: 0.019502928191556638]
	TIME [epoch: 11.6 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013804984490788244		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.013804984490788244 | validation: 0.03019120024147839]
	TIME [epoch: 11.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012226391269166874		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.012226391269166874 | validation: 0.015131818169408052]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014603809307968903		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.014603809307968903 | validation: 0.024802989344655843]
	TIME [epoch: 11.6 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01924297108943292		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.01924297108943292 | validation: 0.027496755464321683]
	TIME [epoch: 11.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015884249420614702		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.015884249420614702 | validation: 0.01839416412307046]
	TIME [epoch: 11.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019472735801486642		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.019472735801486642 | validation: 0.032232450286188034]
	TIME [epoch: 11.6 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014337836019162362		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.014337836019162362 | validation: 0.01566221424932885]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011908765676364322		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.011908765676364322 | validation: 0.020956650265401704]
	TIME [epoch: 11.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016201368519692512		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.016201368519692512 | validation: 0.027351738800452913]
	TIME [epoch: 11.6 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01399855884226283		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.01399855884226283 | validation: 0.021003103561460748]
	TIME [epoch: 11.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00949052431022427		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.00949052431022427 | validation: 0.027083804375234225]
	TIME [epoch: 11.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01632125643043872		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.01632125643043872 | validation: 0.01821138771827874]
	TIME [epoch: 11.6 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016733855939081787		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.016733855939081787 | validation: 0.030207077120004713]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015521837630187794		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.015521837630187794 | validation: 0.02177101001124279]
	TIME [epoch: 11.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013160860004992208		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.013160860004992208 | validation: 0.009689909441583192]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_1719.pth
	Model improved!!!
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013749824173913062		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.013749824173913062 | validation: 0.03146627292074813]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017061059853138803		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.017061059853138803 | validation: 0.02491727084766672]
	TIME [epoch: 11.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01646110137396269		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.01646110137396269 | validation: 0.022433143455095034]
	TIME [epoch: 11.6 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0147670004755292		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.0147670004755292 | validation: 0.023752067660430278]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016800805295278165		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.016800805295278165 | validation: 0.015274750290906348]
	TIME [epoch: 11.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012378060309090458		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.012378060309090458 | validation: 0.02517799312951742]
	TIME [epoch: 11.6 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014972628008927551		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.014972628008927551 | validation: 0.01887572880106624]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010756743898956613		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.010756743898956613 | validation: 0.028081286867983828]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01287918942605593		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.01287918942605593 | validation: 0.02357644910229492]
	TIME [epoch: 11.6 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013748338925534117		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.013748338925534117 | validation: 0.03066463559074912]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013227084086634392		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.013227084086634392 | validation: 0.020621271664428807]
	TIME [epoch: 11.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013319010064006646		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.013319010064006646 | validation: 0.020658584869230542]
	TIME [epoch: 11.6 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016331928772715602		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.016331928772715602 | validation: 0.019002471638410286]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012768203094411422		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.012768203094411422 | validation: 0.028185310356027983]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01772284325009009		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.01772284325009009 | validation: 0.02870723810972852]
	TIME [epoch: 11.6 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01631549935699654		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.01631549935699654 | validation: 0.02774714025926337]
	TIME [epoch: 11.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01334664502193918		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.01334664502193918 | validation: 0.02529505682964563]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01367613644096495		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.01367613644096495 | validation: 0.011906502336067935]
	TIME [epoch: 11.6 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015489593534259981		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.015489593534259981 | validation: 0.023953808037274454]
	TIME [epoch: 11.5 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014805880123919842		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.014805880123919842 | validation: 0.030132268211644855]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019124465004792437		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.019124465004792437 | validation: 0.031079183750106765]
	TIME [epoch: 11.6 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013857899225854649		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.013857899225854649 | validation: 0.02732402569352513]
	TIME [epoch: 11.5 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02063575428701066		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.02063575428701066 | validation: 0.019160323726676524]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013691131114129207		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.013691131114129207 | validation: 0.024096053742245518]
	TIME [epoch: 11.6 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016624802607459063		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.016624802607459063 | validation: 0.02326586700166634]
	TIME [epoch: 11.5 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017003727766592314		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.017003727766592314 | validation: 0.016804470079041057]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013125412497908991		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.013125412497908991 | validation: 0.028720809827563393]
	TIME [epoch: 11.6 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015723637623781456		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.015723637623781456 | validation: 0.0290542591030992]
	TIME [epoch: 11.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014820380272842531		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.014820380272842531 | validation: 0.020563701166560155]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01489022593361583		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.01489022593361583 | validation: 0.015686873364343004]
	TIME [epoch: 11.6 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013965690622568448		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.013965690622568448 | validation: 0.028638895716226447]
	TIME [epoch: 11.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014971065774021453		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.014971065774021453 | validation: 0.022645741224577885]
	TIME [epoch: 11.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014951976703903047		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.014951976703903047 | validation: 0.023960530683947705]
	TIME [epoch: 11.6 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013923443700045859		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.013923443700045859 | validation: 0.02651679913555793]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015338347239962982		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.015338347239962982 | validation: 0.022535369143664098]
	TIME [epoch: 11.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015353216241562172		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.015353216241562172 | validation: 0.02679500434162659]
	TIME [epoch: 11.6 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015754273936927892		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.015754273936927892 | validation: 0.026864533449343742]
	TIME [epoch: 11.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01468922405886279		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.01468922405886279 | validation: 0.023999185285519312]
	TIME [epoch: 11.5 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012837933675694142		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.012837933675694142 | validation: 0.02045932296315445]
	TIME [epoch: 11.6 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015475902415055042		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.015475902415055042 | validation: 0.021887786696849203]
	TIME [epoch: 11.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014925838535677095		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.014925838535677095 | validation: 0.02357426290085645]
	TIME [epoch: 11.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015761423532986187		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.015761423532986187 | validation: 0.025771911177201578]
	TIME [epoch: 11.6 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018885145356068396		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.018885145356068396 | validation: 0.0212673233122967]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015996192621892995		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.015996192621892995 | validation: 0.01953174585773707]
	TIME [epoch: 11.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016945984766382302		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.016945984766382302 | validation: 0.023468736810702304]
	TIME [epoch: 11.6 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016543900048950993		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.016543900048950993 | validation: 0.020695085305342746]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013854911110419766		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.013854911110419766 | validation: 0.02753024497945708]
	TIME [epoch: 11.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016384780473671055		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.016384780473671055 | validation: 0.01858010246526613]
	TIME [epoch: 11.6 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01761103009797215		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.01761103009797215 | validation: 0.02381459596298411]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01321583820733944		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.01321583820733944 | validation: 0.02259498394474911]
	TIME [epoch: 11.6 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014032759619185606		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.014032759619185606 | validation: 0.021741772915117093]
	TIME [epoch: 11.6 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015940865382233497		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.015940865382233497 | validation: 0.017619756320638256]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014979915660938349		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.014979915660938349 | validation: 0.02448159480371091]
	TIME [epoch: 11.6 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01484457669501624		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.01484457669501624 | validation: 0.022889837992372996]
	TIME [epoch: 11.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014138261250097307		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.014138261250097307 | validation: 0.021111803854031996]
	TIME [epoch: 11.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015680783992592755		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.015680783992592755 | validation: 0.023273476822187843]
	TIME [epoch: 11.6 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013983935154831637		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.013983935154831637 | validation: 0.021250499567300987]
	TIME [epoch: 11.5 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01237466537695257		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.01237466537695257 | validation: 0.023528668852445575]
	TIME [epoch: 11.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01565993516738553		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.01565993516738553 | validation: 0.028354993829798402]
	TIME [epoch: 11.6 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010815129215506059		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.010815129215506059 | validation: 0.02831327196821011]
	TIME [epoch: 11.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01447191217337436		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.01447191217337436 | validation: 0.01858377763000615]
	TIME [epoch: 11.5 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013887095864336608		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.013887095864336608 | validation: 0.02502739496599978]
	TIME [epoch: 11.6 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01398886634175312		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.01398886634175312 | validation: 0.026821895110819876]
	TIME [epoch: 11.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01254965306701893		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.01254965306701893 | validation: 0.02564154743319576]
	TIME [epoch: 11.5 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0156367154928779		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.0156367154928779 | validation: 0.02726113429867868]
	TIME [epoch: 11.6 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014949126979756151		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.014949126979756151 | validation: 0.028443564123646042]
	TIME [epoch: 11.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010540927388689725		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.010540927388689725 | validation: 0.02088369337485837]
	TIME [epoch: 11.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01583033779375278		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.01583033779375278 | validation: 0.017821743625902102]
	TIME [epoch: 11.6 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01105571952833887		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.01105571952833887 | validation: 0.025376419032406283]
	TIME [epoch: 11.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014641121372104658		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.014641121372104658 | validation: 0.022791617027754577]
	TIME [epoch: 11.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012840867899073597		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.012840867899073597 | validation: 0.01845909271185623]
	TIME [epoch: 11.6 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013279388222638024		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.013279388222638024 | validation: 0.028047360179262404]
	TIME [epoch: 11.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011007532096928112		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.011007532096928112 | validation: 0.028004089748962]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01361852399549758		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.01361852399549758 | validation: 0.02272785564689534]
	TIME [epoch: 11.6 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012258853593088129		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.012258853593088129 | validation: 0.027644893894309703]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01246449243683921		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.01246449243683921 | validation: 0.021191520997795248]
	TIME [epoch: 11.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013582375003958893		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.013582375003958893 | validation: 0.02348667946766752]
	TIME [epoch: 11.6 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014549026167770004		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.014549026167770004 | validation: 0.025040105392192164]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013073723840952947		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.013073723840952947 | validation: 0.029719920988724953]
	TIME [epoch: 11.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015129092592889519		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.015129092592889519 | validation: 0.018857473225912424]
	TIME [epoch: 11.6 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010676426869787413		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.010676426869787413 | validation: 0.024702410910985143]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01918532550448366		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.01918532550448366 | validation: 0.01582137384278607]
	TIME [epoch: 11.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016602733742131788		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.016602733742131788 | validation: 0.023211833160511813]
	TIME [epoch: 11.6 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011365541143118406		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.011365541143118406 | validation: 0.014532209305229207]
	TIME [epoch: 11.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01261367698973358		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.01261367698973358 | validation: 0.021188019182418843]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015143109352742896		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.015143109352742896 | validation: 0.01859228402420421]
	TIME [epoch: 11.6 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010514708144355811		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.010514708144355811 | validation: 0.019873773571502308]
	TIME [epoch: 11.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01491480402454317		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.01491480402454317 | validation: 0.01736104970603786]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016332600401789604		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.016332600401789604 | validation: 0.01640125322559435]
	TIME [epoch: 11.6 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015667580360204665		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.015667580360204665 | validation: 0.013065596885390567]
	TIME [epoch: 11.5 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013073403308167158		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.013073403308167158 | validation: 0.0239448353932366]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012095798846476267		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.012095798846476267 | validation: 0.015714989006984724]
	TIME [epoch: 11.6 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014992620795738678		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.014992620795738678 | validation: 0.02259616634092971]
	TIME [epoch: 11.5 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01199021318606371		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.01199021318606371 | validation: 0.021748867876440394]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013473045462647769		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.013473045462647769 | validation: 0.019186114180785113]
	TIME [epoch: 11.6 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01588195173781446		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.01588195173781446 | validation: 0.022876455597614066]
	TIME [epoch: 11.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010749675640327557		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.010749675640327557 | validation: 0.0279893842153737]
	TIME [epoch: 11.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013800601491315265		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.013800601491315265 | validation: 0.025048486509605405]
	TIME [epoch: 11.6 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010401421901630578		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.010401421901630578 | validation: 0.02643419084602392]
	TIME [epoch: 11.5 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010871295592713128		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.010871295592713128 | validation: 0.01836531841459651]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011202075664488536		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.011202075664488536 | validation: 0.022710203378659966]
	TIME [epoch: 11.6 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014743862035081478		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.014743862035081478 | validation: 0.01986547550134404]
	TIME [epoch: 11.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015754082371632474		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.015754082371632474 | validation: 0.02167951847114835]
	TIME [epoch: 11.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00905066719846241		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.00905066719846241 | validation: 0.03358964780963292]
	TIME [epoch: 11.6 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00985463614349438		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.00985463614349438 | validation: 0.018382937426482983]
	TIME [epoch: 11.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013908002890907413		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.013908002890907413 | validation: 0.020880161936143324]
	TIME [epoch: 11.5 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015300931327436842		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.015300931327436842 | validation: 0.01826491444474789]
	TIME [epoch: 11.6 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013823157517126296		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.013823157517126296 | validation: 0.027262007081077365]
	TIME [epoch: 11.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011733570150221058		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.011733570150221058 | validation: 0.025021395571786696]
	TIME [epoch: 11.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015956440519863377		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.015956440519863377 | validation: 0.014674175392052433]
	TIME [epoch: 11.6 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013818915419355182		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.013818915419355182 | validation: 0.02347083910304537]
	TIME [epoch: 11.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016222066939589108		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.016222066939589108 | validation: 0.022932098246101908]
	TIME [epoch: 11.5 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01086572482339132		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.01086572482339132 | validation: 0.012289694233914707]
	TIME [epoch: 11.6 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01406581196039369		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.01406581196039369 | validation: 0.021456163392262625]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01208682889850211		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.01208682889850211 | validation: 0.013133408977126462]
	TIME [epoch: 11.5 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013010779189078114		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.013010779189078114 | validation: 0.01715450501566076]
	TIME [epoch: 11.6 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016651695380780235		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.016651695380780235 | validation: 0.023861838726336508]
	TIME [epoch: 11.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015585163670882153		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.015585163670882153 | validation: 0.022302282434436785]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015831800945270296		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.015831800945270296 | validation: 0.01656427731439413]
	TIME [epoch: 11.6 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017352516995860535		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.017352516995860535 | validation: 0.02289720392266944]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015594415252071238		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.015594415252071238 | validation: 0.01780383901879296]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013132054159628094		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.013132054159628094 | validation: 0.024948134865500304]
	TIME [epoch: 11.6 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010413027879149755		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.010413027879149755 | validation: 0.022694086452995164]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016823741680873618		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.016823741680873618 | validation: 0.02188987265274051]
	TIME [epoch: 11.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010686513683944857		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.010686513683944857 | validation: 0.028739316172272638]
	TIME [epoch: 11.6 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013138666320724694		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.013138666320724694 | validation: 0.020308556599298463]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01866757124904926		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.01866757124904926 | validation: 0.031768887456990746]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014487232321750379		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.014487232321750379 | validation: 0.024773063565551336]
	TIME [epoch: 11.6 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017956483893794783		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.017956483893794783 | validation: 0.02102347651159435]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01355525875531767		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.01355525875531767 | validation: 0.024462153784914537]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014336908332647214		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.014336908332647214 | validation: 0.019416453119700833]
	TIME [epoch: 11.6 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011587194233257873		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.011587194233257873 | validation: 0.022188626461039595]
	TIME [epoch: 11.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00998391736951488		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.00998391736951488 | validation: 0.02120534923418555]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01539860021003839		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.01539860021003839 | validation: 0.011604039851420675]
	TIME [epoch: 11.6 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015016311619268054		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.015016311619268054 | validation: 0.023135392144350383]
	TIME [epoch: 11.5 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01342156904492094		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.01342156904492094 | validation: 0.019986518563197667]
	TIME [epoch: 11.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01557811358202874		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.01557811358202874 | validation: 0.02018534966306598]
	TIME [epoch: 11.6 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015046501404795819		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.015046501404795819 | validation: 0.021112318979217868]
	TIME [epoch: 11.5 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016338803716332426		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.016338803716332426 | validation: 0.01881556142830823]
	TIME [epoch: 11.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015613821607505072		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.015613821607505072 | validation: 0.029605978561691712]
	TIME [epoch: 11.6 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012681970963091555		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.012681970963091555 | validation: 0.025530460161351604]
	TIME [epoch: 11.5 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012033831106345098		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.012033831106345098 | validation: 0.015453738354545981]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013122864335865625		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.013122864335865625 | validation: 0.01587874454934298]
	TIME [epoch: 11.6 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01610176750133581		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.01610176750133581 | validation: 0.01584825322499775]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011159394649162283		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.011159394649162283 | validation: 0.02251713165600301]
	TIME [epoch: 11.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014332804910462456		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.014332804910462456 | validation: 0.021315271666116457]
	TIME [epoch: 11.6 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011833742178692357		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.011833742178692357 | validation: 0.01825627549367369]
	TIME [epoch: 11.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014517747704296249		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.014517747704296249 | validation: 0.01596265155877411]
	TIME [epoch: 11.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012498456374221598		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.012498456374221598 | validation: 0.019135220281995057]
	TIME [epoch: 11.6 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016496418972572337		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.016496418972572337 | validation: 0.02068166583288398]
	TIME [epoch: 11.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015159145510366456		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.015159145510366456 | validation: 0.026173564510222874]
	TIME [epoch: 11.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016943326941988766		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.016943326941988766 | validation: 0.01818368040725948]
	TIME [epoch: 11.6 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014491874445629174		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.014491874445629174 | validation: 0.03306892651844219]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01668460259971375		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.01668460259971375 | validation: 0.02343884352744384]
	TIME [epoch: 11.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01773604655642836		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.01773604655642836 | validation: 0.015012866600223594]
	TIME [epoch: 11.6 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014013960662520475		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.014013960662520475 | validation: 0.024894485841991165]
	TIME [epoch: 11.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014425603990455149		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.014425603990455149 | validation: 0.025277459398852592]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014726357274209775		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.014726357274209775 | validation: 0.02216251359585364]
	TIME [epoch: 11.6 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014430216840636579		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.014430216840636579 | validation: 0.016529486392014705]
	TIME [epoch: 11.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011791709232633318		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.011791709232633318 | validation: 0.015640678489993478]
	TIME [epoch: 11.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013805948877541552		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.013805948877541552 | validation: 0.018445686096043693]
	TIME [epoch: 11.6 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012565303682111048		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.012565303682111048 | validation: 0.020280536040579347]
	TIME [epoch: 11.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011112902890088486		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.011112902890088486 | validation: 0.021882287592283067]
	TIME [epoch: 11.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01645972288412097		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.01645972288412097 | validation: 0.023422799626773214]
	TIME [epoch: 11.6 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012896913053942879		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.012896913053942879 | validation: 0.024019453939217617]
	TIME [epoch: 11.5 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012229784351472211		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.012229784351472211 | validation: 0.02552478633635584]
	TIME [epoch: 11.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01423176085558947		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.01423176085558947 | validation: 0.018718226863712842]
	TIME [epoch: 11.6 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016205916556624747		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.016205916556624747 | validation: 0.02626973253961124]
	TIME [epoch: 11.5 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010169559489886884		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.010169559489886884 | validation: 0.02158303782435272]
	TIME [epoch: 11.5 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013829983413422495		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.013829983413422495 | validation: 0.020784253166496774]
	TIME [epoch: 11.6 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012871823863477204		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.012871823863477204 | validation: 0.021956662080938646]
	TIME [epoch: 11.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01426798233294825		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.01426798233294825 | validation: 0.01740712132505742]
	TIME [epoch: 11.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012257063675385114		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.012257063675385114 | validation: 0.02566895724843099]
	TIME [epoch: 11.6 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017076341291914585		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.017076341291914585 | validation: 0.022312410651217588]
	TIME [epoch: 11.5 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011464493251072823		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.011464493251072823 | validation: 0.022428809477515133]
	TIME [epoch: 11.6 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01615393197778037		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.01615393197778037 | validation: 0.02467426225586593]
	TIME [epoch: 11.5 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01470991138614515		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.01470991138614515 | validation: 0.019860148431937872]
	TIME [epoch: 11.5 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014545621309626444		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.014545621309626444 | validation: 0.01724961941391156]
	TIME [epoch: 11.6 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011207503916217455		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.011207503916217455 | validation: 0.026044535167084725]
	TIME [epoch: 11.5 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017581287206353505		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.017581287206353505 | validation: 0.02632007049137096]
	TIME [epoch: 11.5 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015179793409828068		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.015179793409828068 | validation: 0.020861649847018795]
	TIME [epoch: 11.6 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014535826116044079		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.014535826116044079 | validation: 0.020947862243520403]
	TIME [epoch: 11.5 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014834894580490766		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.014834894580490766 | validation: 0.016751554639004154]
	TIME [epoch: 11.5 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014440108069351061		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.014440108069351061 | validation: 0.029365974424144098]
	TIME [epoch: 11.6 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013743617786532731		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.013743617786532731 | validation: 0.025505871698010302]
	TIME [epoch: 11.5 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013547499265636587		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.013547499265636587 | validation: 0.01868482938012669]
	TIME [epoch: 11.5 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014646877085510754		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.014646877085510754 | validation: 0.023139208735084932]
	TIME [epoch: 11.6 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013300834822571725		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.013300834822571725 | validation: 0.013667884798561705]
	TIME [epoch: 11.5 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012388685913857828		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.012388685913857828 | validation: 0.02408335645607818]
	TIME [epoch: 11.5 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012245701158797936		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.012245701158797936 | validation: 0.022650244340282972]
	TIME [epoch: 11.6 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011404211627056245		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.011404211627056245 | validation: 0.010669881324153098]
	TIME [epoch: 11.5 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012881198176465068		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.012881198176465068 | validation: 0.020243154161061722]
	TIME [epoch: 11.5 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015104405615388013		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.015104405615388013 | validation: 0.02626596656316519]
	TIME [epoch: 11.6 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015021802295769129		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.015021802295769129 | validation: 0.031900981422494895]
	TIME [epoch: 11.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01268220874497899		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.01268220874497899 | validation: 0.02297092565729339]
	TIME [epoch: 11.5 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012004743217354808		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.012004743217354808 | validation: 0.01933900343325709]
	TIME [epoch: 11.6 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014961490982719686		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.014961490982719686 | validation: 0.022001196029461295]
	TIME [epoch: 11.5 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015047643338892257		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.015047643338892257 | validation: 0.01996863643390294]
	TIME [epoch: 11.5 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01393649500768291		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.01393649500768291 | validation: 0.014269912219086774]
	TIME [epoch: 11.6 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01778567543868307		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.01778567543868307 | validation: 0.027169143451848652]
	TIME [epoch: 11.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013021223456035071		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.013021223456035071 | validation: 0.015015029560466457]
	TIME [epoch: 11.5 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01185278889089585		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.01185278889089585 | validation: 0.019756701715924765]
	TIME [epoch: 11.6 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01096148142105774		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.01096148142105774 | validation: 0.027110677200231352]
	TIME [epoch: 11.5 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01581163493550795		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.01581163493550795 | validation: 0.019995110554988836]
	TIME [epoch: 11.5 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01416337257786768		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.01416337257786768 | validation: 0.025249048444575685]
	TIME [epoch: 11.6 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014941358618080451		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.014941358618080451 | validation: 0.013805125993126959]
	TIME [epoch: 11.5 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012211855978985258		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.012211855978985258 | validation: 0.018599437866075312]
	TIME [epoch: 11.5 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01530070815856497		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.01530070815856497 | validation: 0.01753964834537733]
	TIME [epoch: 11.6 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012746143654915266		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.012746143654915266 | validation: 0.023361764475828366]
	TIME [epoch: 11.5 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016100903838909622		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.016100903838909622 | validation: 0.023783693287368034]
	TIME [epoch: 11.5 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011018323489617253		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.011018323489617253 | validation: 0.021423866520974805]
	TIME [epoch: 11.6 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01264459453394345		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.01264459453394345 | validation: 0.015866115655427292]
	TIME [epoch: 11.5 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014114462513605118		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.014114462513605118 | validation: 0.023448770055711103]
	TIME [epoch: 11.5 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013734703931192823		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.013734703931192823 | validation: 0.018135643511272562]
	TIME [epoch: 11.6 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01597683964273596		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.01597683964273596 | validation: 0.02570186495679376]
	TIME [epoch: 11.5 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012448261397360378		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.012448261397360378 | validation: 0.015838076512290224]
	TIME [epoch: 11.5 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014757102804198688		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.014757102804198688 | validation: 0.017437382273076608]
	TIME [epoch: 11.6 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01538864624742828		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.01538864624742828 | validation: 0.023573877714762746]
	TIME [epoch: 11.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014866782132496106		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.014866782132496106 | validation: 0.030269680948563728]
	TIME [epoch: 11.5 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01812648539150289		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.01812648539150289 | validation: 0.0259328813143304]
	TIME [epoch: 11.6 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013326330452247832		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.013326330452247832 | validation: 0.024123184019450142]
	TIME [epoch: 11.5 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014460726510627546		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.014460726510627546 | validation: 0.02234964439930733]
	TIME [epoch: 11.5 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0189175036911945		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.0189175036911945 | validation: 0.026331074472033675]
	TIME [epoch: 11.6 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01739616989154078		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.01739616989154078 | validation: 0.023785545708075728]
	TIME [epoch: 11.5 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013959113124684381		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.013959113124684381 | validation: 0.01836248124002142]
	TIME [epoch: 11.5 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017725600593621382		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.017725600593621382 | validation: 0.01900544089482844]
	TIME [epoch: 11.6 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019261535217361323		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.019261535217361323 | validation: 0.026174872755070286]
	TIME [epoch: 11.5 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01895776658473841		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.01895776658473841 | validation: 0.02186818589278673]
	TIME [epoch: 11.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01852214924913346		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.01852214924913346 | validation: 0.023094162930625314]
	TIME [epoch: 11.6 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015449431989692812		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.015449431989692812 | validation: 0.027168105315329]
	TIME [epoch: 11.5 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01615762088780028		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.01615762088780028 | validation: 0.03205275926193817]
	TIME [epoch: 11.5 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01737302428484303		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.01737302428484303 | validation: 0.022553970910758673]
	TIME [epoch: 11.6 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01026025425248299		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.01026025425248299 | validation: 0.017925224850539313]
	TIME [epoch: 11.5 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01835992435528563		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.01835992435528563 | validation: 0.0197345006341327]
	TIME [epoch: 11.5 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01559198545896483		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.01559198545896483 | validation: 0.019038249473922915]
	TIME [epoch: 11.6 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014588242341440155		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.014588242341440155 | validation: 0.02036532378820987]
	TIME [epoch: 11.5 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015325179178430142		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.015325179178430142 | validation: 0.020337207441231922]
	TIME [epoch: 11.5 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007254166854657795		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.007254166854657795 | validation: 0.022814212424663482]
	TIME [epoch: 11.6 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01338265179764684		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.01338265179764684 | validation: 0.02156699153996362]
	TIME [epoch: 11.5 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007458954933554229		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.007458954933554229 | validation: 0.01945065466610274]
	TIME [epoch: 11.5 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013544866451312126		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.013544866451312126 | validation: 0.019297510815717133]
	TIME [epoch: 11.6 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016189857224679853		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.016189857224679853 | validation: 0.02090418728628157]
	TIME [epoch: 11.5 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013579320091637911		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.013579320091637911 | validation: 0.023658669129556182]
	TIME [epoch: 11.5 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01348040373257997		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.01348040373257997 | validation: 0.023983965013689428]
	TIME [epoch: 11.6 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015036035219812033		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.015036035219812033 | validation: 0.019284362586257032]
	TIME [epoch: 11.5 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015310431684304437		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.015310431684304437 | validation: 0.021347204743147625]
	TIME [epoch: 11.5 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014696607636394887		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.014696607636394887 | validation: 0.016868768761912015]
	TIME [epoch: 11.6 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014795192622109786		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.014795192622109786 | validation: 0.02615664588193535]
	TIME [epoch: 11.5 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015392859675788465		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.015392859675788465 | validation: 0.01860252251985779]
	TIME [epoch: 11.5 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01467160972522807		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.01467160972522807 | validation: 0.02303565926184175]
	TIME [epoch: 11.6 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013355792443753909		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.013355792443753909 | validation: 0.01709558586143174]
	TIME [epoch: 11.5 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015017461164028403		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.015017461164028403 | validation: 0.028119625593501008]
	TIME [epoch: 11.5 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014733835508604628		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.014733835508604628 | validation: 0.025873727600556232]
	TIME [epoch: 11.6 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012283018857290781		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.012283018857290781 | validation: 0.02830769283759842]
	TIME [epoch: 11.5 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014751717450059746		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.014751717450059746 | validation: 0.023701917047709457]
	TIME [epoch: 11.5 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012921287399468965		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.012921287399468965 | validation: 0.024139003488170364]
	TIME [epoch: 11.6 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01133206917287839		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.01133206917287839 | validation: 0.020262624039914405]
	TIME [epoch: 11.5 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015346093921221358		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.015346093921221358 | validation: 0.024297148295625345]
	TIME [epoch: 11.5 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013631622653622173		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.013631622653622173 | validation: 0.02337602083005999]
	TIME [epoch: 11.6 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01038724882715641		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.01038724882715641 | validation: 0.021332648869147316]
	TIME [epoch: 11.5 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015720730570473893		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.015720730570473893 | validation: 0.016778779051837837]
	TIME [epoch: 11.5 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013191757222764337		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.013191757222764337 | validation: 0.025440833225438088]
	TIME [epoch: 11.6 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01630623991607407		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.01630623991607407 | validation: 0.030491631294218557]
	TIME [epoch: 11.5 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01621380158959977		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.01621380158959977 | validation: 0.020518109248565387]
	TIME [epoch: 11.5 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013757315138424148		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.013757315138424148 | validation: 0.02781862602462113]
	TIME [epoch: 11.6 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013802848467508688		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.013802848467508688 | validation: 0.017315242602452575]
	TIME [epoch: 11.5 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01366150680177268		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.01366150680177268 | validation: 0.022412304779500937]
	TIME [epoch: 11.5 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014931618250254871		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.014931618250254871 | validation: 0.032284187833532645]
	TIME [epoch: 11.6 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015601895434263083		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.015601895434263083 | validation: 0.025653520393515043]
	TIME [epoch: 11.5 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018012773504782403		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.018012773504782403 | validation: 0.0298628884216205]
	TIME [epoch: 11.5 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014397291335291218		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.014397291335291218 | validation: 0.019187567352524703]
	TIME [epoch: 11.6 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010749450243738934		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.010749450243738934 | validation: 0.023841850644398237]
	TIME [epoch: 11.5 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014194781531812164		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.014194781531812164 | validation: 0.0230725679740443]
	TIME [epoch: 11.5 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012434748488731835		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.012434748488731835 | validation: 0.007066753452676081]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240310_003030/states/model_tr_study4_1993.pth
	Model improved!!!
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014353050589607067		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.014353050589607067 | validation: 0.01858832798939685]
	TIME [epoch: 11.5 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011063412413789279		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.011063412413789279 | validation: 0.025135986333774007]
	TIME [epoch: 11.5 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012657433397155813		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.012657433397155813 | validation: 0.019083303079726655]
	TIME [epoch: 11.6 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0119877568122503		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.0119877568122503 | validation: 0.01423743550969143]
	TIME [epoch: 11.5 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013550115743516623		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.013550115743516623 | validation: 0.0187181429955427]
	TIME [epoch: 11.5 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01511424425777801		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.01511424425777801 | validation: 0.02252984330556648]
	TIME [epoch: 11.6 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015058755760934413		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.015058755760934413 | validation: 0.019158511575086044]
	TIME [epoch: 11.5 sec]
Finished training in 23321.217 seconds.
