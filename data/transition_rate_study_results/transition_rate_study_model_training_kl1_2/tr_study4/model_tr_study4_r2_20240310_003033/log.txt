Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r2', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 937292539

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.595946387658797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.595946387658797 | validation: 9.076116718009507]
	TIME [epoch: 101 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.828174375812987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.828174375812987 | validation: 5.48860993721004]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.019654921151235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.019654921151235 | validation: 5.024519515700289]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.592622983232402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.592622983232402 | validation: 4.474328113075369]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.157910932994064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.157910932994064 | validation: 4.145412192329629]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9159831872278437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9159831872278437 | validation: 3.831905820850254]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5496441093765267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5496441093765267 | validation: 3.1177233754869507]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6254557211244576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6254557211244576 | validation: 3.129961868257238]
	TIME [epoch: 11.5 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.24143507209892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.24143507209892 | validation: 3.130914422581351]
	TIME [epoch: 11.5 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1016980413818365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1016980413818365 | validation: 3.0422454128036875]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.157475343857556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.157475343857556 | validation: 2.8379869165179947]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0361247343741544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0361247343741544 | validation: 2.6673790537461337]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8105181857326067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8105181857326067 | validation: 2.9198245682215056]
	TIME [epoch: 11.5 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8711703446281707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8711703446281707 | validation: 2.780242471010565]
	TIME [epoch: 11.5 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.865821439205084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.865821439205084 | validation: 2.6118769874561414]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.656213233115122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.656213233115122 | validation: 2.552291804726375]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6096233119328143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6096233119328143 | validation: 2.280629186707864]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7233373596016652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7233373596016652 | validation: 2.6470443846167164]
	TIME [epoch: 11.5 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7315721199896412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7315721199896412 | validation: 2.410356206162917]
	TIME [epoch: 11.5 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8978184826236135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8978184826236135 | validation: 2.1461524227153155]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.312100781573707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.312100781573707 | validation: 2.159628615947824]
	TIME [epoch: 11.5 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2522421639815176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2522421639815176 | validation: 2.253244306056282]
	TIME [epoch: 11.5 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.182408521919699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.182408521919699 | validation: 2.1348522803932526]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1234467511520627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1234467511520627 | validation: 2.86309528659629]
	TIME [epoch: 11.5 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4377871382201466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4377871382201466 | validation: 1.6929703409604853]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.934973376950545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.934973376950545 | validation: 2.0103921156126527]
	TIME [epoch: 11.5 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.974632250016636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.974632250016636 | validation: 1.8487930084164854]
	TIME [epoch: 11.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.130287465854768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.130287465854768 | validation: 1.5837569827046258]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.896806444516138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.896806444516138 | validation: 1.5149378664635427]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7564483682783663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7564483682783663 | validation: 1.5457843579988093]
	TIME [epoch: 11.5 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5681074973465525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5681074973465525 | validation: 1.6365246825724882]
	TIME [epoch: 11.5 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9570256472301708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9570256472301708 | validation: 4.3078114422191085]
	TIME [epoch: 11.5 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4427927143907042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4427927143907042 | validation: 1.296315117505006]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3484838322619415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3484838322619415 | validation: 1.2492728180270893]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.36214465029322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.36214465029322 | validation: 1.1550907557936416]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.003038156467273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.003038156467273 | validation: 2.9284846950054635]
	TIME [epoch: 11.5 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7251952985897643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7251952985897643 | validation: 1.2654460387266528]
	TIME [epoch: 11.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.374295579523097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.374295579523097 | validation: 1.2278790021459949]
	TIME [epoch: 11.5 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2735432350723779		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2735432350723779 | validation: 0.9076450857363804]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4399355491120938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4399355491120938 | validation: 1.1250073551109712]
	TIME [epoch: 11.5 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.102375480887964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.102375480887964 | validation: 1.4197064265581743]
	TIME [epoch: 11.5 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1479344470354904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1479344470354904 | validation: 1.3087954272669038]
	TIME [epoch: 11.5 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2270684138652215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2270684138652215 | validation: 1.8204033767420391]
	TIME [epoch: 11.5 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.535166977665745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.535166977665745 | validation: 0.9853542965001196]
	TIME [epoch: 11.5 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.753485526807786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.753485526807786 | validation: 1.2626793396578064]
	TIME [epoch: 11.5 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2056805285653514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2056805285653514 | validation: 1.4622498707473017]
	TIME [epoch: 11.5 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2510316982196907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2510316982196907 | validation: 0.9807800476132655]
	TIME [epoch: 11.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1402952173109493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1402952173109493 | validation: 0.8738244937283974]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059925424643637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.059925424643637 | validation: 0.8897821478993424]
	TIME [epoch: 11.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0043292795781584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0043292795781584 | validation: 1.0295748627876375]
	TIME [epoch: 11.5 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4103790559837166		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.4103790559837166 | validation: 1.522970127800792]
	TIME [epoch: 11.5 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1184639764851934		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.1184639764851934 | validation: 1.6558559894233356]
	TIME [epoch: 11.5 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4809960899651733		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.4809960899651733 | validation: 1.4742278884518971]
	TIME [epoch: 11.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2488129623758533		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.2488129623758533 | validation: 0.9605449781564886]
	TIME [epoch: 11.5 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9618433091920783		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.9618433091920783 | validation: 0.9982738710263853]
	TIME [epoch: 11.5 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9951278415402937		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.9951278415402937 | validation: 0.7903458963141771]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8464233326279376		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.8464233326279376 | validation: 0.8362478168165308]
	TIME [epoch: 11.5 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1732992583772117		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.1732992583772117 | validation: 1.9632930916968168]
	TIME [epoch: 11.5 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.33233883721366		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.33233883721366 | validation: 1.1554410741200318]
	TIME [epoch: 11.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0434300728448007		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.0434300728448007 | validation: 0.8692240507433396]
	TIME [epoch: 11.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7798008831476267		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.7798008831476267 | validation: 1.1128492695967205]
	TIME [epoch: 11.5 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.167734548636779		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.167734548636779 | validation: 0.6295063470786489]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7615503627109583		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.7615503627109583 | validation: 0.8605803287924184]
	TIME [epoch: 11.5 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7613691996211164		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.7613691996211164 | validation: 0.770129275818502]
	TIME [epoch: 11.5 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7200542811245823		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.7200542811245823 | validation: 0.7502078155356494]
	TIME [epoch: 11.4 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8025973880463577		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.8025973880463577 | validation: 1.0647635291796038]
	TIME [epoch: 11.5 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9312445955977904		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.9312445955977904 | validation: 0.7491316562569148]
	TIME [epoch: 11.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7287566399676776		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.7287566399676776 | validation: 1.096310286206241]
	TIME [epoch: 11.5 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8225340877699366		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.8225340877699366 | validation: 0.6224175992869464]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8253653784811132		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.8253653784811132 | validation: 0.7997366535625545]
	TIME [epoch: 11.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7861130555203217		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.7861130555203217 | validation: 0.6200862883317668]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7466691504445343		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.7466691504445343 | validation: 0.6084803841676717]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8424765598518231		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.8424765598518231 | validation: 0.6100319894072052]
	TIME [epoch: 11.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.158976639780143		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.158976639780143 | validation: 1.271524373805565]
	TIME [epoch: 11.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9054193860481798		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.9054193860481798 | validation: 1.4488731907710781]
	TIME [epoch: 11.5 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.983823095297335		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.983823095297335 | validation: 1.0205288470980372]
	TIME [epoch: 11.5 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8014222553897035		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.8014222553897035 | validation: 0.6112404124309195]
	TIME [epoch: 11.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9988675661888736		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.9988675661888736 | validation: 0.8223347030444284]
	TIME [epoch: 11.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7726857314312		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.7726857314312 | validation: 0.7782461010575072]
	TIME [epoch: 11.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7268692179504372		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.7268692179504372 | validation: 0.6291826030583119]
	TIME [epoch: 11.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6988563493093823		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.6988563493093823 | validation: 0.5706922309400708]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.80188558829003		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.80188558829003 | validation: 0.6689807146612392]
	TIME [epoch: 11.5 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7799232504683197		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.7799232504683197 | validation: 0.8641991542025413]
	TIME [epoch: 11.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8392596393929883		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.8392596393929883 | validation: 1.0568153073409732]
	TIME [epoch: 11.5 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8052251091804097		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.8052251091804097 | validation: 0.539404829847747]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7675034009962929		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.7675034009962929 | validation: 0.8227916845911495]
	TIME [epoch: 11.5 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7534748486020286		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.7534748486020286 | validation: 0.7462704171359807]
	TIME [epoch: 11.5 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9172520761402323		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.9172520761402323 | validation: 0.9460407034339244]
	TIME [epoch: 11.5 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7456624710733663		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.7456624710733663 | validation: 0.8779462597381341]
	TIME [epoch: 11.5 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2080403079914168		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.2080403079914168 | validation: 0.5957174367282915]
	TIME [epoch: 11.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6455621498527215		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.6455621498527215 | validation: 0.5215572369491827]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7015154155909809		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.7015154155909809 | validation: 0.621381723697954]
	TIME [epoch: 11.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8216215748266595		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.8216215748266595 | validation: 0.7620777176701754]
	TIME [epoch: 11.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6472879728631239		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.6472879728631239 | validation: 0.5684935399821075]
	TIME [epoch: 11.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6680758022472782		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.6680758022472782 | validation: 0.7127056935494992]
	TIME [epoch: 11.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8806654422032789		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.8806654422032789 | validation: 0.8943433926492731]
	TIME [epoch: 11.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6562026239343581		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.6562026239343581 | validation: 0.7195227636492817]
	TIME [epoch: 11.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6346497050088025		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.6346497050088025 | validation: 0.8037796365535246]
	TIME [epoch: 11.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7757699752954472		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.7757699752954472 | validation: 0.6033377646880949]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5999109448330824		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.5999109448330824 | validation: 0.5510136464368327]
	TIME [epoch: 11.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6556874819003654		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.6556874819003654 | validation: 0.5769033993102507]
	TIME [epoch: 11.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6199158334100107		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.6199158334100107 | validation: 1.6103291873571197]
	TIME [epoch: 11.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1197561077294913		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.1197561077294913 | validation: 0.7282885055535823]
	TIME [epoch: 11.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8902347156306609		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.8902347156306609 | validation: 0.7947917223316412]
	TIME [epoch: 11.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6644248466647069		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.6644248466647069 | validation: 0.5481979367834254]
	TIME [epoch: 11.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6550318325050222		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.6550318325050222 | validation: 0.5717988268431282]
	TIME [epoch: 11.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.742060281344881		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.742060281344881 | validation: 0.5904646549062224]
	TIME [epoch: 11.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6317770786315298		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.6317770786315298 | validation: 0.5187359417103911]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5404343134493076		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.5404343134493076 | validation: 0.46924897259624315]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46872851658393355		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.46872851658393355 | validation: 0.43427925001015466]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5652580855979517		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.5652580855979517 | validation: 0.5514803907187052]
	TIME [epoch: 11.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5377210279704979		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.5377210279704979 | validation: 0.44550125695164505]
	TIME [epoch: 11.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6864549648612095		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.6864549648612095 | validation: 1.1230655770970142]
	TIME [epoch: 11.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7696392920150846		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.7696392920150846 | validation: 0.5276095403450296]
	TIME [epoch: 11.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.56322652502874		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.56322652502874 | validation: 0.5381571902186056]
	TIME [epoch: 11.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5746297800601212		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.5746297800601212 | validation: 0.5238785895910274]
	TIME [epoch: 11.4 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5611405133826814		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.5611405133826814 | validation: 1.2381890400754458]
	TIME [epoch: 11.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9833503984144267		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.9833503984144267 | validation: 0.44176715915620507]
	TIME [epoch: 11.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5034128766793764		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.5034128766793764 | validation: 0.5997486767239548]
	TIME [epoch: 11.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5386557699495136		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.5386557699495136 | validation: 0.890433302359181]
	TIME [epoch: 11.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7735925535448115		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.7735925535448115 | validation: 0.49214229822382194]
	TIME [epoch: 11.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6701381548338725		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.6701381548338725 | validation: 0.41904815047637856]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.52398981264991		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.52398981264991 | validation: 0.5496714634461882]
	TIME [epoch: 11.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5203087291655873		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.5203087291655873 | validation: 0.3820415015576184]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5642722724086838		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.5642722724086838 | validation: 0.515743446225544]
	TIME [epoch: 11.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5121535522500165		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.5121535522500165 | validation: 0.41806177081400775]
	TIME [epoch: 11.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5940537018324088		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.5940537018324088 | validation: 0.7359844144583662]
	TIME [epoch: 11.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7081338655884706		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.7081338655884706 | validation: 0.5556763468878313]
	TIME [epoch: 11.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5261665112464042		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.5261665112464042 | validation: 0.45248864347050854]
	TIME [epoch: 11.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5135636896540646		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.5135636896540646 | validation: 0.41503690712041086]
	TIME [epoch: 11.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8061388069572253		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.8061388069572253 | validation: 0.7877796715931826]
	TIME [epoch: 11.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7173316785742113		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.7173316785742113 | validation: 0.43751488402238836]
	TIME [epoch: 11.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46848338774205756		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.46848338774205756 | validation: 0.414748186825999]
	TIME [epoch: 11.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.043507453283199		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.043507453283199 | validation: 0.479804218879393]
	TIME [epoch: 11.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7413419842387379		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.7413419842387379 | validation: 0.6894202633764988]
	TIME [epoch: 11.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6651024148804966		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.6651024148804966 | validation: 0.8614508063573088]
	TIME [epoch: 11.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6807739256348571		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.6807739256348571 | validation: 0.5227245333145417]
	TIME [epoch: 11.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5032216644144564		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.5032216644144564 | validation: 0.5294949889940455]
	TIME [epoch: 11.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.613323604830182		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.613323604830182 | validation: 0.8638603055406566]
	TIME [epoch: 11.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6269717179200878		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.6269717179200878 | validation: 0.4789030683008675]
	TIME [epoch: 11.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44344588589512085		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.44344588589512085 | validation: 0.46142198606207485]
	TIME [epoch: 11.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5127056054815954		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.5127056054815954 | validation: 0.4803894126750791]
	TIME [epoch: 11.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7809710689994446		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.7809710689994446 | validation: 0.43751844760702]
	TIME [epoch: 11.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8057914172355352		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.8057914172355352 | validation: 0.6627450788642253]
	TIME [epoch: 11.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7947619226045055		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.7947619226045055 | validation: 0.7971656730653166]
	TIME [epoch: 11.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6424323992640284		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.6424323992640284 | validation: 0.4639641937038276]
	TIME [epoch: 11.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5377430576559232		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.5377430576559232 | validation: 0.540756325573305]
	TIME [epoch: 11.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5133659294353468		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.5133659294353468 | validation: 0.4327512169999655]
	TIME [epoch: 11.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684387730441443		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.684387730441443 | validation: 0.7168842875556036]
	TIME [epoch: 11.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5923622628889855		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.5923622628889855 | validation: 0.39942283922979754]
	TIME [epoch: 11.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.425670145513799		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.425670145513799 | validation: 0.6616576454563827]
	TIME [epoch: 11.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5175223731890883		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.5175223731890883 | validation: 0.46633899085744573]
	TIME [epoch: 11.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5273422339765846		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.5273422339765846 | validation: 0.39542445558006384]
	TIME [epoch: 11.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5028306508192287		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.5028306508192287 | validation: 0.406826928000425]
	TIME [epoch: 11.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4171211937612528		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.4171211937612528 | validation: 0.41555325546193006]
	TIME [epoch: 11.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49510306243899704		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.49510306243899704 | validation: 0.5086593204249636]
	TIME [epoch: 11.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.598637329340672		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.598637329340672 | validation: 0.5431976873076344]
	TIME [epoch: 11.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5064498371168824		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.5064498371168824 | validation: 0.396435312475368]
	TIME [epoch: 11.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48679944118483853		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.48679944118483853 | validation: 0.4663526225001934]
	TIME [epoch: 11.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46534589822660116		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.46534589822660116 | validation: 0.4532043902825389]
	TIME [epoch: 11.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4691111749014702		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.4691111749014702 | validation: 0.3988639688143196]
	TIME [epoch: 11.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44448709950684306		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.44448709950684306 | validation: 0.42249730647086026]
	TIME [epoch: 11.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4632334952680579		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.4632334952680579 | validation: 0.47853171816159223]
	TIME [epoch: 11.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5070806572515274		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.5070806572515274 | validation: 0.4365959874905625]
	TIME [epoch: 11.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44966678362124823		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.44966678362124823 | validation: 0.43664706163921696]
	TIME [epoch: 11.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45692608988313466		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.45692608988313466 | validation: 0.41782733727932764]
	TIME [epoch: 11.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4736811351328518		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.4736811351328518 | validation: 0.5379868617817845]
	TIME [epoch: 11.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6725817937733277		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.6725817937733277 | validation: 0.48959791242530215]
	TIME [epoch: 11.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5692490530058136		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.5692490530058136 | validation: 0.38924925885655376]
	TIME [epoch: 11.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42809802411163855		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.42809802411163855 | validation: 0.4323617229842147]
	TIME [epoch: 11.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43084341720394365		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.43084341720394365 | validation: 0.3612661069979274]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5078893650728986		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.5078893650728986 | validation: 0.4311665564850689]
	TIME [epoch: 11.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.611063616789602		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.611063616789602 | validation: 0.5381483738938867]
	TIME [epoch: 11.4 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5318382805139363		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.5318382805139363 | validation: 0.6112547179410798]
	TIME [epoch: 11.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6806384729351787		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.6806384729351787 | validation: 0.6238307546014593]
	TIME [epoch: 11.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47987685447576345		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.47987685447576345 | validation: 0.3706013230657601]
	TIME [epoch: 11.4 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5826319616339035		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.5826319616339035 | validation: 0.6342338442222277]
	TIME [epoch: 11.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7335832867608985		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.7335832867608985 | validation: 0.4377103901495004]
	TIME [epoch: 11.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.462389853055717		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.462389853055717 | validation: 0.3800508932948759]
	TIME [epoch: 11.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4643360866265483		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.4643360866265483 | validation: 0.4674764082518466]
	TIME [epoch: 11.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48332822848923745		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.48332822848923745 | validation: 0.4590589437489335]
	TIME [epoch: 11.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45610617061739733		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.45610617061739733 | validation: 2.1266923456229354]
	TIME [epoch: 11.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2168315932989835		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.2168315932989835 | validation: 0.5433791773857124]
	TIME [epoch: 11.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5024932555488744		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.5024932555488744 | validation: 0.44714119810927044]
	TIME [epoch: 11.5 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4345995650360757		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.4345995650360757 | validation: 0.5531251691319345]
	TIME [epoch: 11.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4773861836835114		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.4773861836835114 | validation: 0.3963414647769217]
	TIME [epoch: 11.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6733724358315649		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.6733724358315649 | validation: 0.6439645702383402]
	TIME [epoch: 11.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5458229713294485		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.5458229713294485 | validation: 0.5896181030547981]
	TIME [epoch: 11.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6983381886610471		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.6983381886610471 | validation: 0.5423272807919974]
	TIME [epoch: 11.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5564286446113886		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.5564286446113886 | validation: 0.48543881260247573]
	TIME [epoch: 11.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.522769284719805		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.522769284719805 | validation: 0.6617605913577006]
	TIME [epoch: 11.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5838796390344358		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.5838796390344358 | validation: 0.49834315287706527]
	TIME [epoch: 11.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44057758590261076		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.44057758590261076 | validation: 0.4056613411327969]
	TIME [epoch: 11.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44097027834919117		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.44097027834919117 | validation: 0.40875715510297184]
	TIME [epoch: 11.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44559691357396347		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.44559691357396347 | validation: 0.44974724814001493]
	TIME [epoch: 11.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4235378513887098		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.4235378513887098 | validation: 0.4229849400891942]
	TIME [epoch: 11.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4059677054762374		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.4059677054762374 | validation: 0.3412609285615429]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4237975184642304		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.4237975184642304 | validation: 0.43127675409976685]
	TIME [epoch: 11.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.408833110891056		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.408833110891056 | validation: 0.33919022158166817]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3570446051431996		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.3570446051431996 | validation: 0.3593581116865722]
	TIME [epoch: 11.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3689570971805197		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.3689570971805197 | validation: 0.33531640767285154]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4726274948277315		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.4726274948277315 | validation: 0.387941958820027]
	TIME [epoch: 11.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.380522367643751		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.380522367643751 | validation: 0.34217973957770864]
	TIME [epoch: 11.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6897733569169484		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.6897733569169484 | validation: 0.4505652200816317]
	TIME [epoch: 11.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4551761857038155		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.4551761857038155 | validation: 0.47649653438543726]
	TIME [epoch: 11.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48299033062373214		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.48299033062373214 | validation: 0.6576294231396603]
	TIME [epoch: 11.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5141206093656308		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.5141206093656308 | validation: 0.4608797300984414]
	TIME [epoch: 11.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.54668685725031		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.54668685725031 | validation: 0.35954912224594654]
	TIME [epoch: 11.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41472731773203053		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.41472731773203053 | validation: 0.504411685149592]
	TIME [epoch: 11.5 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4467193727473119		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.4467193727473119 | validation: 0.36102222307964893]
	TIME [epoch: 11.5 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4224804599854401		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.4224804599854401 | validation: 0.43098361214799724]
	TIME [epoch: 11.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42953691533113314		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.42953691533113314 | validation: 0.3887644058467737]
	TIME [epoch: 11.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5665464894424925		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.5665464894424925 | validation: 0.5340207519634192]
	TIME [epoch: 11.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5500975878999385		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.5500975878999385 | validation: 0.3996081464706611]
	TIME [epoch: 11.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42396396727766916		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.42396396727766916 | validation: 0.37915437709258215]
	TIME [epoch: 11.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4077965650639721		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.4077965650639721 | validation: 0.32657584639784276]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35870782489644826		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.35870782489644826 | validation: 0.2576948004620094]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3043855349027496		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.3043855349027496 | validation: 0.25548861298425685]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_218.pth
	Model improved!!!
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3642239499664244		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.3642239499664244 | validation: 0.2774526849051184]
	TIME [epoch: 11.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36765630326549853		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.36765630326549853 | validation: 0.2970792252059835]
	TIME [epoch: 11.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3414955550530891		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.3414955550530891 | validation: 0.35146664668204636]
	TIME [epoch: 11.5 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33248089288903027		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.33248089288903027 | validation: 0.4794275869608773]
	TIME [epoch: 11.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3860256110767598		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.3860256110767598 | validation: 0.30605327652696096]
	TIME [epoch: 11.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3528566030803512		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.3528566030803512 | validation: 0.6288366499092198]
	TIME [epoch: 11.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5173995171692117		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.5173995171692117 | validation: 0.314599317280771]
	TIME [epoch: 11.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40041964266729224		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.40041964266729224 | validation: 0.2634819203133409]
	TIME [epoch: 11.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2849123114956694		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.2849123114956694 | validation: 0.2895436922414749]
	TIME [epoch: 11.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32229650237345664		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.32229650237345664 | validation: 0.39745513403535115]
	TIME [epoch: 11.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4505436718831104		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.4505436718831104 | validation: 0.30300365297769]
	TIME [epoch: 11.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4707314027482138		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.4707314027482138 | validation: 0.33513239509338605]
	TIME [epoch: 11.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34825653378747834		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.34825653378747834 | validation: 0.28008276544958305]
	TIME [epoch: 11.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39321361940455896		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.39321361940455896 | validation: 0.4117527867869846]
	TIME [epoch: 11.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37691010855003027		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.37691010855003027 | validation: 0.33744622591335316]
	TIME [epoch: 11.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3448699241279958		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.3448699241279958 | validation: 0.38365734568325666]
	TIME [epoch: 11.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36942222909425027		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.36942222909425027 | validation: 0.3846829432710506]
	TIME [epoch: 11.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34971418125187526		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.34971418125187526 | validation: 0.311824252980536]
	TIME [epoch: 11.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3188013766664005		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.3188013766664005 | validation: 0.31484799081833537]
	TIME [epoch: 11.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3110778539889415		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.3110778539889415 | validation: 0.5285975573009457]
	TIME [epoch: 11.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4735681082616409		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.4735681082616409 | validation: 0.3657110400451488]
	TIME [epoch: 11.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31191976377861486		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.31191976377861486 | validation: 0.31088291140810836]
	TIME [epoch: 11.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4348278467355051		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.4348278467355051 | validation: 0.29153524761303645]
	TIME [epoch: 11.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.440460119483888		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.440460119483888 | validation: 0.943799191350694]
	TIME [epoch: 11.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6034286183366838		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.6034286183366838 | validation: 0.23458119270013778]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2876943992316972		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.2876943992316972 | validation: 0.20804396252695004]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29183577295649826		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.29183577295649826 | validation: 0.24779153097781678]
	TIME [epoch: 11.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24888474148503015		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.24888474148503015 | validation: 0.36612614811421496]
	TIME [epoch: 11.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2761016171733418		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.2761016171733418 | validation: 0.27235315593429826]
	TIME [epoch: 11.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29649840468164024		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.29649840468164024 | validation: 0.30970634203207503]
	TIME [epoch: 11.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2929194666388758		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.2929194666388758 | validation: 0.24290929903327219]
	TIME [epoch: 11.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2970949642331446		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.2970949642331446 | validation: 0.2509703867018445]
	TIME [epoch: 11.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27166060364908823		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.27166060364908823 | validation: 0.24667449047770038]
	TIME [epoch: 11.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29350596723807815		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.29350596723807815 | validation: 0.26572157565628474]
	TIME [epoch: 11.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45117034002313094		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.45117034002313094 | validation: 0.4821226689039383]
	TIME [epoch: 11.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3918491496320428		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.3918491496320428 | validation: 0.28375556636907934]
	TIME [epoch: 11.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3555309349408957		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.3555309349408957 | validation: 0.2864869652601814]
	TIME [epoch: 11.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3125338211869931		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.3125338211869931 | validation: 0.21780962117910874]
	TIME [epoch: 11.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4553269090112549		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.4553269090112549 | validation: 0.6486650437736037]
	TIME [epoch: 11.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.541890716768639		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.541890716768639 | validation: 0.28981535677000425]
	TIME [epoch: 11.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2799494244701969		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.2799494244701969 | validation: 0.2182884124076066]
	TIME [epoch: 11.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33789710807563705		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.33789710807563705 | validation: 0.26179126920989554]
	TIME [epoch: 11.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3319910048361947		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.3319910048361947 | validation: 0.35195466070625286]
	TIME [epoch: 11.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31937017958331093		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.31937017958331093 | validation: 0.3079098430587679]
	TIME [epoch: 11.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29922279937694146		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.29922279937694146 | validation: 0.24098450273452857]
	TIME [epoch: 11.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3077458824144304		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.3077458824144304 | validation: 0.25183408742919533]
	TIME [epoch: 11.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3135835588502812		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.3135835588502812 | validation: 0.24696268249988065]
	TIME [epoch: 11.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29397137036238097		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.29397137036238097 | validation: 0.2790244240028826]
	TIME [epoch: 11.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36282924576521824		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.36282924576521824 | validation: 0.3497282306178509]
	TIME [epoch: 11.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41395254888427957		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.41395254888427957 | validation: 0.27027134966957833]
	TIME [epoch: 11.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3199926806033949		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.3199926806033949 | validation: 0.3290369991133723]
	TIME [epoch: 11.5 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48349597954540896		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.48349597954540896 | validation: 0.2299361799121084]
	TIME [epoch: 11.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24928481804559505		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.24928481804559505 | validation: 0.2437970892623865]
	TIME [epoch: 11.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28930059524501545		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.28930059524501545 | validation: 0.2513577416338881]
	TIME [epoch: 11.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3291666919309645		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.3291666919309645 | validation: 0.2712152181536157]
	TIME [epoch: 11.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26111234591252314		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.26111234591252314 | validation: 0.18013613546182528]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21651168918796662		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.21651168918796662 | validation: 0.30875934269082833]
	TIME [epoch: 11.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2820111901534152		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.2820111901534152 | validation: 0.1965381380536529]
	TIME [epoch: 11.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28659044470602		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.28659044470602 | validation: 0.30107938756792485]
	TIME [epoch: 11.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27326518687373846		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.27326518687373846 | validation: 0.24941504233306633]
	TIME [epoch: 11.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2978395391969762		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.2978395391969762 | validation: 0.2207472211198751]
	TIME [epoch: 11.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23938595645343566		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.23938595645343566 | validation: 0.3187880762120364]
	TIME [epoch: 11.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3864803605501529		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.3864803605501529 | validation: 0.5612667759515947]
	TIME [epoch: 11.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39908668393665153		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.39908668393665153 | validation: 0.25191590153735866]
	TIME [epoch: 11.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26115252594328703		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.26115252594328703 | validation: 0.21491993266836973]
	TIME [epoch: 11.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25590142599240756		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.25590142599240756 | validation: 0.23898431127353337]
	TIME [epoch: 11.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2719610559145806		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.2719610559145806 | validation: 0.4324852250061469]
	TIME [epoch: 11.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46266735729035485		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.46266735729035485 | validation: 0.3323855665617988]
	TIME [epoch: 11.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37758669466992406		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.37758669466992406 | validation: 0.3630213809726179]
	TIME [epoch: 11.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3676838329856794		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.3676838329856794 | validation: 0.431321361302346]
	TIME [epoch: 11.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3736773871135218		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.3736773871135218 | validation: 0.3986434194045536]
	TIME [epoch: 11.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3619211571697041		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.3619211571697041 | validation: 0.4390147067304843]
	TIME [epoch: 11.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32971289269552345		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.32971289269552345 | validation: 0.23973968166634102]
	TIME [epoch: 11.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3138552034951579		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.3138552034951579 | validation: 0.3712225345480987]
	TIME [epoch: 11.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37513265235209076		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.37513265235209076 | validation: 0.26332136552592156]
	TIME [epoch: 11.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.319382098221336		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.319382098221336 | validation: 0.27993240420479043]
	TIME [epoch: 11.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38604494266707134		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.38604494266707134 | validation: 0.3071048234662686]
	TIME [epoch: 11.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35651761480672556		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.35651761480672556 | validation: 0.28273965597979234]
	TIME [epoch: 11.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3225397556291427		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.3225397556291427 | validation: 0.30828765475025605]
	TIME [epoch: 11.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32498656477375165		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.32498656477375165 | validation: 0.24000200512055872]
	TIME [epoch: 11.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28614383705885055		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.28614383705885055 | validation: 0.37144371244117663]
	TIME [epoch: 11.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35712394209190923		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.35712394209190923 | validation: 0.33532976629426375]
	TIME [epoch: 11.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3113742129819603		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.3113742129819603 | validation: 0.2373329794356959]
	TIME [epoch: 11.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3006971339539397		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.3006971339539397 | validation: 0.31486431750500776]
	TIME [epoch: 11.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3338183774493041		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.3338183774493041 | validation: 0.3342334195448565]
	TIME [epoch: 11.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3410574224785991		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.3410574224785991 | validation: 0.31027195493695187]
	TIME [epoch: 11.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4554844702874222		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.4554844702874222 | validation: 0.3149122994526331]
	TIME [epoch: 11.5 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3715033039957511		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.3715033039957511 | validation: 0.4145091535466176]
	TIME [epoch: 11.5 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36870553532495726		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.36870553532495726 | validation: 0.29533042691862754]
	TIME [epoch: 11.5 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38201155838996625		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.38201155838996625 | validation: 0.30328293486972124]
	TIME [epoch: 11.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3692608873188979		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.3692608873188979 | validation: 0.31387245145024434]
	TIME [epoch: 11.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3102557885195563		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.3102557885195563 | validation: 0.2557373190547299]
	TIME [epoch: 11.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30298756258438553		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.30298756258438553 | validation: 0.29021160991837547]
	TIME [epoch: 11.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3271513579074524		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.3271513579074524 | validation: 0.25345732643750674]
	TIME [epoch: 11.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32019691945942713		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.32019691945942713 | validation: 0.32589138148355207]
	TIME [epoch: 11.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37716697589961695		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.37716697589961695 | validation: 0.3249254271566271]
	TIME [epoch: 11.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31069487643746996		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.31069487643746996 | validation: 0.23016437771069598]
	TIME [epoch: 11.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2885563565504132		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.2885563565504132 | validation: 0.24754224856959045]
	TIME [epoch: 11.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.313143029640531		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.313143029640531 | validation: 0.3890846178635718]
	TIME [epoch: 11.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.335909351078879		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.335909351078879 | validation: 0.24464205254507293]
	TIME [epoch: 11.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.297608245907246		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.297608245907246 | validation: 0.21030288584386647]
	TIME [epoch: 11.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25777320817370425		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.25777320817370425 | validation: 0.2450252284420054]
	TIME [epoch: 11.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32356012395339323		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.32356012395339323 | validation: 0.2479684394836155]
	TIME [epoch: 11.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35456254593091463		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.35456254593091463 | validation: 0.27289764009814316]
	TIME [epoch: 11.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3054619486907418		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.3054619486907418 | validation: 0.2512425826525901]
	TIME [epoch: 11.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2915572784415307		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.2915572784415307 | validation: 0.4972813226474008]
	TIME [epoch: 11.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4305837619126466		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.4305837619126466 | validation: 0.34391884585427335]
	TIME [epoch: 11.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33468553674921625		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.33468553674921625 | validation: 0.2630419264675467]
	TIME [epoch: 11.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32393983897963863		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.32393983897963863 | validation: 0.2726424746896253]
	TIME [epoch: 11.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3055812286460873		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.3055812286460873 | validation: 0.350196964952725]
	TIME [epoch: 11.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39448786295854926		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.39448786295854926 | validation: 0.44305238521362156]
	TIME [epoch: 11.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36998858008808666		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.36998858008808666 | validation: 0.27208116466278753]
	TIME [epoch: 11.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3402303751310767		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.3402303751310767 | validation: 0.23960968843309935]
	TIME [epoch: 11.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33897446492547884		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.33897446492547884 | validation: 0.29367360301093137]
	TIME [epoch: 11.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3685789274929558		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.3685789274929558 | validation: 0.27828324054281905]
	TIME [epoch: 11.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33041177673303046		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.33041177673303046 | validation: 0.29754292131045396]
	TIME [epoch: 11.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3426043688148827		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.3426043688148827 | validation: 0.31617037239019924]
	TIME [epoch: 11.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35854339004621877		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.35854339004621877 | validation: 0.2793806314152051]
	TIME [epoch: 11.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2911277449498228		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.2911277449498228 | validation: 0.2654394730235228]
	TIME [epoch: 11.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36809719166156174		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.36809719166156174 | validation: 0.2802881891496421]
	TIME [epoch: 11.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33706674854595214		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.33706674854595214 | validation: 0.23888468142425862]
	TIME [epoch: 11.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33880496370539953		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.33880496370539953 | validation: 0.2958526848368742]
	TIME [epoch: 11.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3184158691788859		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.3184158691788859 | validation: 0.3246318467247075]
	TIME [epoch: 11.5 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3040938111807388		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.3040938111807388 | validation: 0.24662172598077475]
	TIME [epoch: 11.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28138040921013147		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.28138040921013147 | validation: 0.2424355085996385]
	TIME [epoch: 11.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43659859459090167		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.43659859459090167 | validation: 0.2979254169380407]
	TIME [epoch: 11.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32643834932626437		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.32643834932626437 | validation: 0.23190409657734626]
	TIME [epoch: 11.5 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.305341041043875		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.305341041043875 | validation: 0.24494283105741424]
	TIME [epoch: 11.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3151883714138249		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.3151883714138249 | validation: 0.3108998493378257]
	TIME [epoch: 11.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2971654626067485		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.2971654626067485 | validation: 0.2540019650797396]
	TIME [epoch: 11.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3064812000212936		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.3064812000212936 | validation: 0.2635538154920137]
	TIME [epoch: 11.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3655308534798896		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.3655308534798896 | validation: 0.2415234038367769]
	TIME [epoch: 11.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32487623712754693		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.32487623712754693 | validation: 0.22304480302695176]
	TIME [epoch: 11.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28354469377157954		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.28354469377157954 | validation: 0.22746753029177538]
	TIME [epoch: 11.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29901202452864983		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.29901202452864983 | validation: 0.26452149398941693]
	TIME [epoch: 11.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3571253120910809		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.3571253120910809 | validation: 0.29473793506789014]
	TIME [epoch: 11.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29488452517941366		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.29488452517941366 | validation: 0.22465795946375355]
	TIME [epoch: 11.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25789534801442787		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.25789534801442787 | validation: 0.2206395915630265]
	TIME [epoch: 11.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2468331269002588		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.2468331269002588 | validation: 0.2094989584095561]
	TIME [epoch: 11.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27555802011153463		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.27555802011153463 | validation: 0.23289713039049564]
	TIME [epoch: 11.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24064941625005679		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.24064941625005679 | validation: 0.21119356715945478]
	TIME [epoch: 11.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3118047061803354		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.3118047061803354 | validation: 0.36202099195277937]
	TIME [epoch: 11.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31533726646579496		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.31533726646579496 | validation: 0.20562739045974873]
	TIME [epoch: 11.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2531247935583125		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.2531247935583125 | validation: 0.20352913610117396]
	TIME [epoch: 11.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4206675330360895		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.4206675330360895 | validation: 0.5470427987882642]
	TIME [epoch: 11.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4288006803964203		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.4288006803964203 | validation: 0.22122048902395425]
	TIME [epoch: 11.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24036708504418222		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.24036708504418222 | validation: 0.19153320498492946]
	TIME [epoch: 11.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.285650774462582		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.285650774462582 | validation: 0.2716363408342605]
	TIME [epoch: 11.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3363866362558772		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.3363866362558772 | validation: 0.3403829788030548]
	TIME [epoch: 11.5 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6202671731307569		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.6202671731307569 | validation: 0.3335959504359738]
	TIME [epoch: 11.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31501616252126075		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.31501616252126075 | validation: 0.24914875468537429]
	TIME [epoch: 11.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6360225644457449		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.6360225644457449 | validation: 0.48629738707499476]
	TIME [epoch: 11.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43633575389509166		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.43633575389509166 | validation: 0.3029544456972256]
	TIME [epoch: 11.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3308128897449249		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.3308128897449249 | validation: 0.29547228987695]
	TIME [epoch: 11.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30220052149237897		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.30220052149237897 | validation: 0.22148308955263438]
	TIME [epoch: 11.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.284047998894322		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.284047998894322 | validation: 0.3355707785398671]
	TIME [epoch: 11.5 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41383432904924344		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.41383432904924344 | validation: 0.26848314061662254]
	TIME [epoch: 11.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3306286035998699		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.3306286035998699 | validation: 0.23339307359581285]
	TIME [epoch: 11.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25247157543141324		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.25247157543141324 | validation: 0.2188208672224148]
	TIME [epoch: 11.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2655456332497356		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.2655456332497356 | validation: 0.2840406429095377]
	TIME [epoch: 11.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2912033657805474		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.2912033657805474 | validation: 0.2666091241228024]
	TIME [epoch: 11.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24823852681127687		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.24823852681127687 | validation: 0.22791831620356223]
	TIME [epoch: 11.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30187103339202287		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.30187103339202287 | validation: 0.2143010441405059]
	TIME [epoch: 11.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22288447962611468		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.22288447962611468 | validation: 0.22249483104872758]
	TIME [epoch: 11.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25377987213198866		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.25377987213198866 | validation: 0.406688447044716]
	TIME [epoch: 11.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41364425505204483		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.41364425505204483 | validation: 0.371221532480856]
	TIME [epoch: 11.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35534336751342477		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.35534336751342477 | validation: 0.2366534472634619]
	TIME [epoch: 11.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26013596587228566		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.26013596587228566 | validation: 0.24064404696610198]
	TIME [epoch: 11.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2349068069881603		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.2349068069881603 | validation: 0.28270798152796317]
	TIME [epoch: 11.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2486975310448527		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.2486975310448527 | validation: 0.22356328132094638]
	TIME [epoch: 11.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3305607473889606		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.3305607473889606 | validation: 0.1832024465535795]
	TIME [epoch: 11.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22017053933228742		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.22017053933228742 | validation: 0.2567204647487103]
	TIME [epoch: 11.5 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2248535698657787		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.2248535698657787 | validation: 0.2338724267553439]
	TIME [epoch: 11.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26547624808707315		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.26547624808707315 | validation: 0.26779937330258224]
	TIME [epoch: 11.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2798591879353853		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.2798591879353853 | validation: 0.23654413814908953]
	TIME [epoch: 11.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21858027723803028		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.21858027723803028 | validation: 0.19513536401353868]
	TIME [epoch: 11.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21106282986605182		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.21106282986605182 | validation: 0.2128055040286184]
	TIME [epoch: 11.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.226711021373141		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.226711021373141 | validation: 0.20308269329788595]
	TIME [epoch: 11.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21408797601763005		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.21408797601763005 | validation: 0.3382497520082261]
	TIME [epoch: 11.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27067023460399925		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.27067023460399925 | validation: 0.16945770956298054]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_398.pth
	Model improved!!!
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1915607866693964		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.1915607866693964 | validation: 0.18047373100219058]
	TIME [epoch: 11.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28657322009780234		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.28657322009780234 | validation: 0.23506146744215264]
	TIME [epoch: 11.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2742382280510225		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.2742382280510225 | validation: 0.21454501128197495]
	TIME [epoch: 11.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22591661327805784		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.22591661327805784 | validation: 0.2292354902201169]
	TIME [epoch: 11.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3362152160717914		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.3362152160717914 | validation: 0.1883264287096063]
	TIME [epoch: 11.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2078997962915972		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.2078997962915972 | validation: 0.20737750130844945]
	TIME [epoch: 11.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22916741679247793		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.22916741679247793 | validation: 0.3570993343429829]
	TIME [epoch: 11.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3378920873769508		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.3378920873769508 | validation: 0.19716175431070931]
	TIME [epoch: 11.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22117552650221686		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.22117552650221686 | validation: 0.2471888553139661]
	TIME [epoch: 11.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26338239759326976		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.26338239759326976 | validation: 0.2494356417811479]
	TIME [epoch: 11.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2568769855376368		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.2568769855376368 | validation: 0.21271288268320754]
	TIME [epoch: 11.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20040042792284712		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.20040042792284712 | validation: 0.1671335504993838]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_410.pth
	Model improved!!!
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3049254458786571		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.3049254458786571 | validation: 0.3833121435584448]
	TIME [epoch: 11.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2748948226684065		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.2748948226684065 | validation: 0.2125971802323398]
	TIME [epoch: 11.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.251944017416969		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.251944017416969 | validation: 0.2713988336732545]
	TIME [epoch: 11.5 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24909884577650415		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.24909884577650415 | validation: 0.3084596396083474]
	TIME [epoch: 11.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2607054938255192		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.2607054938255192 | validation: 0.1708679489383144]
	TIME [epoch: 11.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20343267975295687		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.20343267975295687 | validation: 0.17051450607445037]
	TIME [epoch: 11.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22094256539526208		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.22094256539526208 | validation: 0.17016900257060982]
	TIME [epoch: 11.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27491469446047323		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.27491469446047323 | validation: 0.30139541914687734]
	TIME [epoch: 11.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2586616650018539		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.2586616650018539 | validation: 0.2705566747553635]
	TIME [epoch: 11.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3669884183380232		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.3669884183380232 | validation: 0.29175300300315954]
	TIME [epoch: 11.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3139844808806569		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.3139844808806569 | validation: 0.2460076361979543]
	TIME [epoch: 11.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23006656306464718		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.23006656306464718 | validation: 0.3496887224283385]
	TIME [epoch: 11.5 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37854808950278007		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.37854808950278007 | validation: 0.23057497182871906]
	TIME [epoch: 11.5 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24541017363337883		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.24541017363337883 | validation: 0.2307601775488127]
	TIME [epoch: 11.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2804443590500427		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.2804443590500427 | validation: 0.25905563428671835]
	TIME [epoch: 11.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23346852051529665		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.23346852051529665 | validation: 0.2030551001518223]
	TIME [epoch: 11.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18128890661828695		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.18128890661828695 | validation: 0.18843054381157992]
	TIME [epoch: 11.5 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20983754976552385		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.20983754976552385 | validation: 0.1824612333115485]
	TIME [epoch: 11.5 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21197166919993338		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.21197166919993338 | validation: 0.2097908196708214]
	TIME [epoch: 11.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3673732333587554		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.3673732333587554 | validation: 0.18176699968634638]
	TIME [epoch: 11.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23470845499056447		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.23470845499056447 | validation: 0.1849709008863615]
	TIME [epoch: 11.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26298081287696345		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.26298081287696345 | validation: 0.39433859179514985]
	TIME [epoch: 11.5 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3425599364015294		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.3425599364015294 | validation: 0.18262595342373567]
	TIME [epoch: 11.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19435562809123483		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.19435562809123483 | validation: 0.16768602440419592]
	TIME [epoch: 11.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2642123404491378		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.2642123404491378 | validation: 0.578337987557921]
	TIME [epoch: 11.5 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49687154390787264		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.49687154390787264 | validation: 0.29191767810093316]
	TIME [epoch: 11.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32831569731225907		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.32831569731225907 | validation: 0.3165236435492997]
	TIME [epoch: 11.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24692232673042772		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.24692232673042772 | validation: 0.20525596390915204]
	TIME [epoch: 11.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23729339479505288		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.23729339479505288 | validation: 0.25621919457972003]
	TIME [epoch: 11.5 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3403144498032151		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.3403144498032151 | validation: 0.30661657493588296]
	TIME [epoch: 11.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3108183152699425		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.3108183152699425 | validation: 0.24888037461161078]
	TIME [epoch: 11.5 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29060331272445006		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.29060331272445006 | validation: 0.22773303573384027]
	TIME [epoch: 11.5 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29302476227118035		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.29302476227118035 | validation: 0.30439970062741323]
	TIME [epoch: 11.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2637059393988031		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.2637059393988031 | validation: 0.21522270247743025]
	TIME [epoch: 11.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22402605296951256		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.22402605296951256 | validation: 0.1705803348924829]
	TIME [epoch: 11.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17098331418748214		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.17098331418748214 | validation: 0.17053446155623397]
	TIME [epoch: 11.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1992379852917417		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.1992379852917417 | validation: 0.14965624949776493]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_447.pth
	Model improved!!!
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18723566600964697		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.18723566600964697 | validation: 0.5247333170149289]
	TIME [epoch: 11.4 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44273962104181397		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.44273962104181397 | validation: 0.1930346096725688]
	TIME [epoch: 11.4 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2349518662003508		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.2349518662003508 | validation: 0.1579086030492643]
	TIME [epoch: 11.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19816197997352367		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.19816197997352367 | validation: 0.24418394516910724]
	TIME [epoch: 11.4 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25161073049821936		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.25161073049821936 | validation: 0.20880341370582328]
	TIME [epoch: 11.4 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21790883528540966		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.21790883528540966 | validation: 0.251086419518986]
	TIME [epoch: 11.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25964372314571266		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.25964372314571266 | validation: 0.1613682963578788]
	TIME [epoch: 11.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2533770362146713		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.2533770362146713 | validation: 0.14931731117795985]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_455.pth
	Model improved!!!
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1821234085415938		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.1821234085415938 | validation: 0.13107304639231304]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_456.pth
	Model improved!!!
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17795274620055956		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.17795274620055956 | validation: 0.17325913335867996]
	TIME [epoch: 11.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17128830391259176		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.17128830391259176 | validation: 0.20963087295192429]
	TIME [epoch: 11.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20918292909465047		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.20918292909465047 | validation: 0.19441383789147065]
	TIME [epoch: 11.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17968815984017528		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.17968815984017528 | validation: 0.1349434719760547]
	TIME [epoch: 11.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1963582024227268		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.1963582024227268 | validation: 0.18028344614092526]
	TIME [epoch: 11.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18815882356037608		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.18815882356037608 | validation: 0.1527170736164682]
	TIME [epoch: 11.5 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14976143737117736		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.14976143737117736 | validation: 0.133992172195022]
	TIME [epoch: 11.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2674763654390425		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.2674763654390425 | validation: 0.29021122085929124]
	TIME [epoch: 11.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4306459275283139		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.4306459275283139 | validation: 0.4094205904965728]
	TIME [epoch: 11.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3120219537106771		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.3120219537106771 | validation: 0.19896547667613046]
	TIME [epoch: 11.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22111795348313815		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.22111795348313815 | validation: 0.17905167167381264]
	TIME [epoch: 11.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21326802509025888		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.21326802509025888 | validation: 0.21806082369234575]
	TIME [epoch: 11.5 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2303510581244459		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.2303510581244459 | validation: 0.21595624714862857]
	TIME [epoch: 11.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19638473704427734		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.19638473704427734 | validation: 0.14573767977162103]
	TIME [epoch: 11.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15841106304828884		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.15841106304828884 | validation: 0.17912561704661556]
	TIME [epoch: 11.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19020101952245477		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.19020101952245477 | validation: 0.1926561419079647]
	TIME [epoch: 11.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17391425523666812		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.17391425523666812 | validation: 0.16934010002334154]
	TIME [epoch: 11.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1730817863283749		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.1730817863283749 | validation: 0.13397153208152943]
	TIME [epoch: 11.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18145430358114611		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.18145430358114611 | validation: 0.153574837814853]
	TIME [epoch: 11.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15632229418121255		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.15632229418121255 | validation: 0.13836157229318916]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16468823272778682		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.16468823272778682 | validation: 0.2076040276728569]
	TIME [epoch: 11.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2089667324753558		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.2089667324753558 | validation: 0.1239159157599524]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_478.pth
	Model improved!!!
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16346947347864435		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.16346947347864435 | validation: 0.1336081656988755]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.146248033028557		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.146248033028557 | validation: 0.165282900408167]
	TIME [epoch: 11.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1617912933835061		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.1617912933835061 | validation: 0.15096710115343695]
	TIME [epoch: 11.5 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15860684391411173		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.15860684391411173 | validation: 0.1670799079380854]
	TIME [epoch: 11.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26072250330829183		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.26072250330829183 | validation: 0.30381152823731505]
	TIME [epoch: 11.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2778541051317005		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.2778541051317005 | validation: 0.37273060934682056]
	TIME [epoch: 11.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3466912878927533		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.3466912878927533 | validation: 0.16340432789963985]
	TIME [epoch: 11.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18104775547221585		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.18104775547221585 | validation: 0.20069839409288928]
	TIME [epoch: 11.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2384377478872127		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.2384377478872127 | validation: 0.16856487034264359]
	TIME [epoch: 11.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23439504084069324		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.23439504084069324 | validation: 0.17429195837930667]
	TIME [epoch: 11.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23353459898776152		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.23353459898776152 | validation: 0.15376428063983302]
	TIME [epoch: 11.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1614564944046517		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.1614564944046517 | validation: 0.1376867597153831]
	TIME [epoch: 11.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15577334093087475		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.15577334093087475 | validation: 0.19613111462583596]
	TIME [epoch: 11.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20851992214161155		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.20851992214161155 | validation: 0.23620754417956855]
	TIME [epoch: 11.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29914217698152407		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.29914217698152407 | validation: 0.1749156390635239]
	TIME [epoch: 11.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1758242151298475		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.1758242151298475 | validation: 0.12258329678600649]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_494.pth
	Model improved!!!
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1795029346202993		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.1795029346202993 | validation: 0.24522547227304695]
	TIME [epoch: 11.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2034622444409355		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.2034622444409355 | validation: 0.10401034563270356]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13545502669909612		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.13545502669909612 | validation: 0.12116655082317249]
	TIME [epoch: 11.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18194515290592442		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.18194515290592442 | validation: 0.10690245738097472]
	TIME [epoch: 11.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13672697949398976		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.13672697949398976 | validation: 0.17230294718788655]
	TIME [epoch: 11.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17942970317221277		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.17942970317221277 | validation: 0.169703531015579]
	TIME [epoch: 11.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18897373749009022		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.18897373749009022 | validation: 0.1334218354349215]
	TIME [epoch: 11.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15533493934738954		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.15533493934738954 | validation: 0.26524228467843336]
	TIME [epoch: 11.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24715419756637244		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.24715419756637244 | validation: 0.14985305515030212]
	TIME [epoch: 11.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20624206914083076		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.20624206914083076 | validation: 0.22455466306750999]
	TIME [epoch: 11.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25406163584119845		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.25406163584119845 | validation: 0.1724883590812821]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17881718213962372		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.17881718213962372 | validation: 0.16172077561482348]
	TIME [epoch: 11.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.282763368465474		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.282763368465474 | validation: 0.23778885994431986]
	TIME [epoch: 11.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28606315816213435		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.28606315816213435 | validation: 0.2514552057262813]
	TIME [epoch: 11.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20612021007123127		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.20612021007123127 | validation: 0.1730949616158987]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20753104665639704		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.20753104665639704 | validation: 0.1807212396552789]
	TIME [epoch: 11.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1829017552527985		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.1829017552527985 | validation: 0.15491262335658065]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1832125792112713		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.1832125792112713 | validation: 0.14710851086947574]
	TIME [epoch: 11.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17720087610394744		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.17720087610394744 | validation: 0.19789642168572136]
	TIME [epoch: 11.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1701389947453068		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.1701389947453068 | validation: 0.16540543217469356]
	TIME [epoch: 11.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20041750703442532		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.20041750703442532 | validation: 0.17784057433203856]
	TIME [epoch: 11.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23880939670325854		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.23880939670325854 | validation: 0.25874310221945984]
	TIME [epoch: 11.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20101495400932545		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.20101495400932545 | validation: 0.13719506286565877]
	TIME [epoch: 11.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15521843917808945		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.15521843917808945 | validation: 0.13338360113507058]
	TIME [epoch: 11.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15568709188743285		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.15568709188743285 | validation: 0.14631429899330634]
	TIME [epoch: 11.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15518893041467016		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.15518893041467016 | validation: 0.14208386341110038]
	TIME [epoch: 11.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24368880313599195		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.24368880313599195 | validation: 0.16928475058077894]
	TIME [epoch: 11.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2120138049642734		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.2120138049642734 | validation: 0.2709015385303604]
	TIME [epoch: 11.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3015112712092938		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.3015112712092938 | validation: 0.18049723287565037]
	TIME [epoch: 11.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16158106995007923		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.16158106995007923 | validation: 0.16756650195307563]
	TIME [epoch: 11.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21239570183659637		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.21239570183659637 | validation: 0.11728147556857055]
	TIME [epoch: 11.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13555632336865187		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.13555632336865187 | validation: 0.17741657342884323]
	TIME [epoch: 11.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21587365547553516		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.21587365547553516 | validation: 0.2579051919448292]
	TIME [epoch: 11.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2181337212974572		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.2181337212974572 | validation: 0.13669579644779437]
	TIME [epoch: 11.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14984431464893833		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.14984431464893833 | validation: 0.11636935857370272]
	TIME [epoch: 11.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16491767877370747		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.16491767877370747 | validation: 0.14023157637237219]
	TIME [epoch: 11.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379716616999035		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.1379716616999035 | validation: 0.11800652803995561]
	TIME [epoch: 11.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13022608667420765		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.13022608667420765 | validation: 0.13818799850531524]
	TIME [epoch: 11.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16800757281957296		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.16800757281957296 | validation: 0.14633912152572817]
	TIME [epoch: 11.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21141712128652565		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.21141712128652565 | validation: 0.1605358416557063]
	TIME [epoch: 11.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16407469166132305		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.16407469166132305 | validation: 0.14526400814492307]
	TIME [epoch: 11.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23258503642274633		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.23258503642274633 | validation: 0.1970299212908077]
	TIME [epoch: 11.5 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19957650499303514		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.19957650499303514 | validation: 0.16757985018071617]
	TIME [epoch: 11.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1904337050899903		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.1904337050899903 | validation: 0.19592297799383687]
	TIME [epoch: 11.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17114713007168625		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.17114713007168625 | validation: 0.12783638687494053]
	TIME [epoch: 11.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16912522166080055		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.16912522166080055 | validation: 0.1211207986380456]
	TIME [epoch: 11.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12523131310473595		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.12523131310473595 | validation: 0.11110692615998907]
	TIME [epoch: 11.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12062311309479004		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.12062311309479004 | validation: 0.13216031241250686]
	TIME [epoch: 11.4 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1231498535772801		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.1231498535772801 | validation: 0.13583118598736654]
	TIME [epoch: 11.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1665910896076152		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.1665910896076152 | validation: 0.13934942406816453]
	TIME [epoch: 11.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15071882480775456		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.15071882480775456 | validation: 0.138000920039391]
	TIME [epoch: 11.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14597557983427087		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.14597557983427087 | validation: 0.11152823470938117]
	TIME [epoch: 11.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12213770712706902		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.12213770712706902 | validation: 0.1184430053782939]
	TIME [epoch: 11.4 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12212776976040852		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.12212776976040852 | validation: 0.11122119453685785]
	TIME [epoch: 11.4 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13037134526361105		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.13037134526361105 | validation: 0.13750619128855665]
	TIME [epoch: 11.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15183592824414713		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.15183592824414713 | validation: 0.1534123831689813]
	TIME [epoch: 11.4 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.183127612651668		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.183127612651668 | validation: 0.2488080072483135]
	TIME [epoch: 11.4 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3101020527086138		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.3101020527086138 | validation: 0.19040763406791972]
	TIME [epoch: 11.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19047998659246118		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.19047998659246118 | validation: 0.16520031763653556]
	TIME [epoch: 11.4 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21188009260388868		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.21188009260388868 | validation: 0.19111542272532694]
	TIME [epoch: 11.4 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20822192482695717		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.20822192482695717 | validation: 0.16334404357549423]
	TIME [epoch: 11.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16997632847442756		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.16997632847442756 | validation: 0.1441611873438186]
	TIME [epoch: 11.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20849813762651598		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.20849813762651598 | validation: 0.33440478255745]
	TIME [epoch: 11.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3240751700948969		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.3240751700948969 | validation: 0.1870007024415456]
	TIME [epoch: 11.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19301284033923294		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.19301284033923294 | validation: 0.18373272509857339]
	TIME [epoch: 11.4 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2538189207444266		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.2538189207444266 | validation: 0.22466756034212992]
	TIME [epoch: 11.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2031434561221814		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.2031434561221814 | validation: 0.190981989297382]
	TIME [epoch: 11.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35208081455094387		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.35208081455094387 | validation: 0.41810344908270564]
	TIME [epoch: 11.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3225861696128375		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.3225861696128375 | validation: 0.2584615752851807]
	TIME [epoch: 11.4 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2420169924972868		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.2420169924972868 | validation: 0.14229337926374647]
	TIME [epoch: 11.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14673983945047017		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.14673983945047017 | validation: 0.18945934784917812]
	TIME [epoch: 11.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21058366545241147		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.21058366545241147 | validation: 0.20534211939548033]
	TIME [epoch: 11.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22825006587006058		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.22825006587006058 | validation: 0.1811219470982323]
	TIME [epoch: 11.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1891556225924144		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.1891556225924144 | validation: 0.16364335774452143]
	TIME [epoch: 11.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19131122807914175		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.19131122807914175 | validation: 0.28266864809800113]
	TIME [epoch: 11.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36231054746193314		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.36231054746193314 | validation: 0.23917611056615748]
	TIME [epoch: 11.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2243249244427547		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.2243249244427547 | validation: 0.2578062434974917]
	TIME [epoch: 11.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20344493372833525		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.20344493372833525 | validation: 0.13831476049783112]
	TIME [epoch: 11.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2234658611388048		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.2234658611388048 | validation: 0.24970496546103121]
	TIME [epoch: 11.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27062255662327456		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.27062255662327456 | validation: 0.22731966130266462]
	TIME [epoch: 11.4 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23231049269572848		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.23231049269572848 | validation: 0.17848919006827926]
	TIME [epoch: 11.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1791223681963875		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.1791223681963875 | validation: 0.1550693759670479]
	TIME [epoch: 11.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17559524166502855		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.17559524166502855 | validation: 0.12676075371526152]
	TIME [epoch: 11.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1589693889361147		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.1589693889361147 | validation: 0.19120598918529885]
	TIME [epoch: 11.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18424271162790404		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.18424271162790404 | validation: 0.1496362505812308]
	TIME [epoch: 11.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18820284051299024		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.18820284051299024 | validation: 0.15759222380359092]
	TIME [epoch: 11.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1972217723449681		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.1972217723449681 | validation: 0.19098891585769956]
	TIME [epoch: 11.5 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2527762363338365		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.2527762363338365 | validation: 0.2602845188654955]
	TIME [epoch: 11.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.406262665664403		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.406262665664403 | validation: 0.34648970503833]
	TIME [epoch: 11.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2853836380915651		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.2853836380915651 | validation: 0.19832072199072742]
	TIME [epoch: 11.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20732913024216054		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.20732913024216054 | validation: 0.16205362073465768]
	TIME [epoch: 11.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17703779557484237		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.17703779557484237 | validation: 0.14408477380975426]
	TIME [epoch: 11.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16736258454717853		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.16736258454717853 | validation: 0.18098789844996382]
	TIME [epoch: 11.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17100153321693157		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.17100153321693157 | validation: 0.1303987971050004]
	TIME [epoch: 11.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13533859886506872		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.13533859886506872 | validation: 0.12470717019816213]
	TIME [epoch: 11.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16518753265899383		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.16518753265899383 | validation: 0.12683406729520807]
	TIME [epoch: 11.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.134864012455707		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.134864012455707 | validation: 0.10694865964418376]
	TIME [epoch: 11.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13031016103366289		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.13031016103366289 | validation: 0.11135433927967643]
	TIME [epoch: 11.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2174741680357032		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.2174741680357032 | validation: 0.3297064221551554]
	TIME [epoch: 11.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33985423690344746		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.33985423690344746 | validation: 0.28914776116494817]
	TIME [epoch: 11.5 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33518513070102984		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.33518513070102984 | validation: 0.19979041526019536]
	TIME [epoch: 11.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19651239677313043		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.19651239677313043 | validation: 0.18474040764754557]
	TIME [epoch: 11.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16911363803192042		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.16911363803192042 | validation: 0.11162324183292738]
	TIME [epoch: 11.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12871338158110357		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.12871338158110357 | validation: 0.10095016257888272]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_598.pth
	Model improved!!!
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11352559214576033		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.11352559214576033 | validation: 0.08966011195570601]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_599.pth
	Model improved!!!
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1114531009679763		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.1114531009679763 | validation: 0.10492950671122785]
	TIME [epoch: 11.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2546239703835381		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.2546239703835381 | validation: 0.2925637414101687]
	TIME [epoch: 11.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22591487439913982		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.22591487439913982 | validation: 0.13587539790095246]
	TIME [epoch: 11.4 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1689542972406582		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.1689542972406582 | validation: 0.17284784683794258]
	TIME [epoch: 11.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16178294784172004		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.16178294784172004 | validation: 0.12737954236550558]
	TIME [epoch: 11.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13960141081594335		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.13960141081594335 | validation: 0.11051512135056886]
	TIME [epoch: 11.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1310006231638359		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.1310006231638359 | validation: 0.11826981544792327]
	TIME [epoch: 11.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14239459880589136		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.14239459880589136 | validation: 0.11129436836505359]
	TIME [epoch: 11.4 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1481842519610699		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.1481842519610699 | validation: 0.14350255656084882]
	TIME [epoch: 11.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15511301075098935		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.15511301075098935 | validation: 0.11730310668776092]
	TIME [epoch: 11.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1643898183230797		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.1643898183230797 | validation: 0.15849129004172524]
	TIME [epoch: 11.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1435689306372984		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.1435689306372984 | validation: 0.13434698055037192]
	TIME [epoch: 11.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13540983973792875		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.13540983973792875 | validation: 0.1425674867926158]
	TIME [epoch: 11.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1389330223013937		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.1389330223013937 | validation: 0.12076967211959694]
	TIME [epoch: 11.5 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12185133047509268		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.12185133047509268 | validation: 0.09644210932027203]
	TIME [epoch: 11.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12787408669276415		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.12787408669276415 | validation: 0.11042348862257559]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10764506871834535		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.10764506871834535 | validation: 0.07996846240580735]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_616.pth
	Model improved!!!
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11572752324243427		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.11572752324243427 | validation: 0.1501512625621237]
	TIME [epoch: 11.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1769219756331241		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.1769219756331241 | validation: 0.17901540703874974]
	TIME [epoch: 11.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1557693858539318		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.1557693858539318 | validation: 0.12053009751639589]
	TIME [epoch: 11.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11595029954569791		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.11595029954569791 | validation: 0.13206892395538322]
	TIME [epoch: 11.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1702646624209878		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.1702646624209878 | validation: 0.11611960321638991]
	TIME [epoch: 11.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11339123417512112		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.11339123417512112 | validation: 0.09516634622644495]
	TIME [epoch: 11.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12098855368439197		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.12098855368439197 | validation: 0.13728422332539195]
	TIME [epoch: 11.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13719399318499545		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.13719399318499545 | validation: 0.1262693589626383]
	TIME [epoch: 11.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13173489393899523		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.13173489393899523 | validation: 0.10520290227850755]
	TIME [epoch: 11.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13384757998619393		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.13384757998619393 | validation: 0.18589045806093005]
	TIME [epoch: 11.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1891039022651615		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.1891039022651615 | validation: 0.14665439770141922]
	TIME [epoch: 11.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13442557330969226		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.13442557330969226 | validation: 0.11841332935637663]
	TIME [epoch: 11.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1500643558660471		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.1500643558660471 | validation: 0.1848937434200071]
	TIME [epoch: 11.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18730364150310752		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.18730364150310752 | validation: 0.13292244810034518]
	TIME [epoch: 11.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1683121418402128		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.1683121418402128 | validation: 0.18079961377571813]
	TIME [epoch: 11.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15528762124320644		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.15528762124320644 | validation: 0.11454575659586137]
	TIME [epoch: 11.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1356431364144946		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.1356431364144946 | validation: 0.13508121909608758]
	TIME [epoch: 11.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1570619305852105		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.1570619305852105 | validation: 0.13974842146259214]
	TIME [epoch: 11.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19163816942797862		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.19163816942797862 | validation: 0.19321677712074356]
	TIME [epoch: 11.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20027885337495227		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.20027885337495227 | validation: 0.15545044128960642]
	TIME [epoch: 11.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16854985933322345		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.16854985933322345 | validation: 0.19564595409231939]
	TIME [epoch: 11.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20215367562063286		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.20215367562063286 | validation: 0.1534684177862749]
	TIME [epoch: 11.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15945746746425923		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.15945746746425923 | validation: 0.13157456546971918]
	TIME [epoch: 11.5 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18730200065057453		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.18730200065057453 | validation: 0.1631447008065859]
	TIME [epoch: 11.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19128582768349478		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.19128582768349478 | validation: 0.21107245131972552]
	TIME [epoch: 11.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22039734702726466		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.22039734702726466 | validation: 0.18851780335105883]
	TIME [epoch: 11.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19745729065194673		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.19745729065194673 | validation: 0.14180686747367305]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19243945303788662		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.19243945303788662 | validation: 0.16417699918855472]
	TIME [epoch: 11.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.188701967894553		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.188701967894553 | validation: 0.1696676700310853]
	TIME [epoch: 11.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19763612811200218		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.19763612811200218 | validation: 0.18507324489628119]
	TIME [epoch: 11.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18920321405777177		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.18920321405777177 | validation: 0.15674464936708687]
	TIME [epoch: 11.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17055731200341007		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.17055731200341007 | validation: 0.1635857131952322]
	TIME [epoch: 11.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20655634358815148		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.20655634358815148 | validation: 0.16403900237595964]
	TIME [epoch: 11.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2106002591223997		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.2106002591223997 | validation: 0.191037021429022]
	TIME [epoch: 11.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2032868111639498		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.2032868111639498 | validation: 0.12661351641826882]
	TIME [epoch: 11.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15153196666027394		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.15153196666027394 | validation: 0.1491495812227963]
	TIME [epoch: 11.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1532654245150789		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.1532654245150789 | validation: 0.12596288111633358]
	TIME [epoch: 11.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14901526160407916		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.14901526160407916 | validation: 0.14155557845006253]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15300394627237207		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.15300394627237207 | validation: 0.12936604781698896]
	TIME [epoch: 11.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16407771516195607		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.16407771516195607 | validation: 0.1601745113803892]
	TIME [epoch: 11.4 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1610479206196147		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.1610479206196147 | validation: 0.1290785356867832]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1475784584953278		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.1475784584953278 | validation: 0.1252580190004307]
	TIME [epoch: 11.5 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13654346719761667		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.13654346719761667 | validation: 0.12425486822088196]
	TIME [epoch: 11.4 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14769699882208498		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.14769699882208498 | validation: 0.1454531389916768]
	TIME [epoch: 11.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14690417001693298		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.14690417001693298 | validation: 0.12398096061713218]
	TIME [epoch: 11.4 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13208348537647932		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.13208348537647932 | validation: 0.10827331589740734]
	TIME [epoch: 11.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1483925365238777		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.1483925365238777 | validation: 0.14025012868030104]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15790712952805042		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.15790712952805042 | validation: 0.10659060430657125]
	TIME [epoch: 11.4 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12802456748676522		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.12802456748676522 | validation: 0.13241245209344304]
	TIME [epoch: 11.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15881350187092574		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.15881350187092574 | validation: 0.145435358834335]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15702027223096704		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.15702027223096704 | validation: 0.12103478421930308]
	TIME [epoch: 11.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12873067948505912		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.12873067948505912 | validation: 0.10410328036244203]
	TIME [epoch: 11.4 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12283403107981904		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.12283403107981904 | validation: 0.10300639325416362]
	TIME [epoch: 11.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10837693751006172		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.10837693751006172 | validation: 0.09526417558086497]
	TIME [epoch: 11.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10728319361053978		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.10728319361053978 | validation: 0.08800185691531201]
	TIME [epoch: 11.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16423865138869792		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.16423865138869792 | validation: 0.1914831573633669]
	TIME [epoch: 11.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22655940789938306		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.22655940789938306 | validation: 0.18423962250794926]
	TIME [epoch: 11.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20126652895315372		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.20126652895315372 | validation: 0.12431655076276416]
	TIME [epoch: 11.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1387450356480521		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.1387450356480521 | validation: 0.12021457310318112]
	TIME [epoch: 11.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12553339929839596		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.12553339929839596 | validation: 0.09076535870578478]
	TIME [epoch: 11.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11421454381783713		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.11421454381783713 | validation: 0.10908169821347898]
	TIME [epoch: 11.4 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1364363053293422		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.1364363053293422 | validation: 0.11464346250698729]
	TIME [epoch: 11.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15765420661472104		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.15765420661472104 | validation: 0.1101121588607088]
	TIME [epoch: 11.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12459400800425416		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.12459400800425416 | validation: 0.14846669177438662]
	TIME [epoch: 11.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16060926203534423		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.16060926203534423 | validation: 0.13275259718620266]
	TIME [epoch: 11.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14717348878056935		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.14717348878056935 | validation: 0.18985059541685054]
	TIME [epoch: 11.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17911827841215835		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.17911827841215835 | validation: 0.12692505267382315]
	TIME [epoch: 11.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1377169006425766		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.1377169006425766 | validation: 0.11315051830471347]
	TIME [epoch: 11.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15729329933427771		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.15729329933427771 | validation: 0.1418183888722634]
	TIME [epoch: 11.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15742653939210344		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.15742653939210344 | validation: 0.1334870634247582]
	TIME [epoch: 11.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1745163227943328		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.1745163227943328 | validation: 0.13684331763545213]
	TIME [epoch: 11.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16912915643996454		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.16912915643996454 | validation: 0.20529747041140667]
	TIME [epoch: 11.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26531767137177287		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.26531767137177287 | validation: 0.2638659453505212]
	TIME [epoch: 11.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2757891079894656		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.2757891079894656 | validation: 0.23207244026838744]
	TIME [epoch: 11.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2215380912364242		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.2215380912364242 | validation: 0.15961136543619106]
	TIME [epoch: 11.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1677277555288049		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.1677277555288049 | validation: 0.1411500548397688]
	TIME [epoch: 11.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13883411629807976		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.13883411629807976 | validation: 0.12296106129861789]
	TIME [epoch: 11.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15625928622668794		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.15625928622668794 | validation: 0.16041300956616705]
	TIME [epoch: 11.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2168625517198663		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.2168625517198663 | validation: 0.21741403879391652]
	TIME [epoch: 11.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19272082956890496		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.19272082956890496 | validation: 0.11760477371346394]
	TIME [epoch: 11.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11848152236517479		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.11848152236517479 | validation: 0.1164132995859965]
	TIME [epoch: 11.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12320102855205381		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.12320102855205381 | validation: 0.09163564873459105]
	TIME [epoch: 11.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11047956796154809		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.11047956796154809 | validation: 0.10575991357517808]
	TIME [epoch: 11.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12305337808039248		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.12305337808039248 | validation: 0.11768083964223934]
	TIME [epoch: 11.4 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14965635003559763		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.14965635003559763 | validation: 0.1613076627415714]
	TIME [epoch: 11.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18693596243114574		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.18693596243114574 | validation: 0.2066760673197921]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21926086746245818		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.21926086746245818 | validation: 0.17898455308626435]
	TIME [epoch: 11.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20629077166049953		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.20629077166049953 | validation: 0.18682388838508424]
	TIME [epoch: 11.5 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1911616587313413		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.1911616587313413 | validation: 0.14652322200290052]
	TIME [epoch: 11.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1815100495359361		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.1815100495359361 | validation: 0.12101413199507782]
	TIME [epoch: 11.5 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14035427495238867		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.14035427495238867 | validation: 0.11410128706184028]
	TIME [epoch: 11.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12620629641789324		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.12620629641789324 | validation: 0.10075163094158468]
	TIME [epoch: 11.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13379577817172478		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.13379577817172478 | validation: 0.14149085497069686]
	TIME [epoch: 11.5 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15144242510829553		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.15144242510829553 | validation: 0.11567940139672406]
	TIME [epoch: 11.5 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1512324925597784		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.1512324925597784 | validation: 0.11273506443817415]
	TIME [epoch: 11.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12775354133495478		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.12775354133495478 | validation: 0.11028401063963784]
	TIME [epoch: 11.5 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11986144036762111		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.11986144036762111 | validation: 0.09963869333198648]
	TIME [epoch: 11.5 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12022746110632945		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.12022746110632945 | validation: 0.08697942159126183]
	TIME [epoch: 11.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1128840644653914		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.1128840644653914 | validation: 0.09160681574394534]
	TIME [epoch: 11.5 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13890395148023482		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.13890395148023482 | validation: 0.14405054320855207]
	TIME [epoch: 11.4 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17067014004098233		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.17067014004098233 | validation: 0.11709585434644826]
	TIME [epoch: 11.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13297455344735462		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.13297455344735462 | validation: 0.09151670143370307]
	TIME [epoch: 11.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13334624356254315		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.13334624356254315 | validation: 0.12121785045749942]
	TIME [epoch: 11.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11854795980657337		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.11854795980657337 | validation: 0.07512142099064761]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_720.pth
	Model improved!!!
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1034687413548607		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.1034687413548607 | validation: 0.06831238968450479]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_721.pth
	Model improved!!!
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11902577851555646		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.11902577851555646 | validation: 0.15304314762653123]
	TIME [epoch: 11.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2336237120852534		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.2336237120852534 | validation: 0.1332878822517381]
	TIME [epoch: 11.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522095722785214		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.1522095722785214 | validation: 0.11937331786658405]
	TIME [epoch: 11.5 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13528634852792695		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.13528634852792695 | validation: 0.15051943035482623]
	TIME [epoch: 11.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14243904666546603		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.14243904666546603 | validation: 0.09712796321143755]
	TIME [epoch: 11.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11472685509882169		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.11472685509882169 | validation: 0.08509094226351975]
	TIME [epoch: 11.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1065872532538249		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.1065872532538249 | validation: 0.08688361555909677]
	TIME [epoch: 11.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09610517648090082		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.09610517648090082 | validation: 0.07603267533366757]
	TIME [epoch: 11.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10088748197674374		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.10088748197674374 | validation: 0.06374450278437015]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_730.pth
	Model improved!!!
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14294843171959518		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.14294843171959518 | validation: 0.1599490248774617]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14820791757481622		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.14820791757481622 | validation: 0.11237866990966726]
	TIME [epoch: 11.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12529050523420596		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.12529050523420596 | validation: 0.08927745059183781]
	TIME [epoch: 11.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09853025210232355		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.09853025210232355 | validation: 0.09019472370051075]
	TIME [epoch: 11.4 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10268037684899566		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.10268037684899566 | validation: 0.10723905534315879]
	TIME [epoch: 11.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13507362523289862		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.13507362523289862 | validation: 0.07740888351697976]
	TIME [epoch: 11.5 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11892027956566747		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.11892027956566747 | validation: 0.13521315490211186]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1410987160061427		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.1410987160061427 | validation: 0.08961078819871349]
	TIME [epoch: 11.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12734498637247307		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.12734498637247307 | validation: 0.12449089420866048]
	TIME [epoch: 11.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14267334211713242		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.14267334211713242 | validation: 0.10962977649618463]
	TIME [epoch: 11.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11412102381046735		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.11412102381046735 | validation: 0.08785599642960974]
	TIME [epoch: 11.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11864062733374983		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.11864062733374983 | validation: 0.1122362246060663]
	TIME [epoch: 11.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11133237707626055		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.11133237707626055 | validation: 0.10262514095823191]
	TIME [epoch: 11.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10518214032486548		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.10518214032486548 | validation: 0.09809442428362149]
	TIME [epoch: 11.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11607927299312192		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.11607927299312192 | validation: 0.11104940672902647]
	TIME [epoch: 11.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12481168396256742		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.12481168396256742 | validation: 0.08324298898372706]
	TIME [epoch: 11.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11544225201243777		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.11544225201243777 | validation: 0.10604872259976754]
	TIME [epoch: 11.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1275477986290532		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.1275477986290532 | validation: 0.12003653178118316]
	TIME [epoch: 11.5 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15395434037351724		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.15395434037351724 | validation: 0.16043585575240712]
	TIME [epoch: 11.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16401078942819414		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.16401078942819414 | validation: 0.14192868333807973]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1471020026823874		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.1471020026823874 | validation: 0.10347852007649913]
	TIME [epoch: 11.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13718293487765945		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.13718293487765945 | validation: 0.1312356509389943]
	TIME [epoch: 11.5 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1448652861143207		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.1448652861143207 | validation: 0.127056812069152]
	TIME [epoch: 11.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15763294331276473		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.15763294331276473 | validation: 0.12905789098582696]
	TIME [epoch: 11.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15662242364474988		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.15662242364474988 | validation: 0.15263770108741254]
	TIME [epoch: 11.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16500685175265772		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.16500685175265772 | validation: 0.1350970940807969]
	TIME [epoch: 11.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15578968316482533		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.15578968316482533 | validation: 0.15743735056671285]
	TIME [epoch: 11.4 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17986649841247782		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.17986649841247782 | validation: 0.1418041715403201]
	TIME [epoch: 11.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15763638018488274		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.15763638018488274 | validation: 0.12320884763774743]
	TIME [epoch: 11.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14702292267890021		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.14702292267890021 | validation: 0.11542148074922742]
	TIME [epoch: 11.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13904411592330113		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.13904411592330113 | validation: 0.11926604706634136]
	TIME [epoch: 11.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14218123014286077		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.14218123014286077 | validation: 0.1247388288675828]
	TIME [epoch: 11.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13227819296403676		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.13227819296403676 | validation: 0.09137716223168024]
	TIME [epoch: 11.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11648211855971159		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.11648211855971159 | validation: 0.10483199850539902]
	TIME [epoch: 11.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314935796489147		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.1314935796489147 | validation: 0.13779810252836028]
	TIME [epoch: 11.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15400073862459046		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.15400073862459046 | validation: 0.10951483550230258]
	TIME [epoch: 11.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12460486336048793		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.12460486336048793 | validation: 0.10364134087380573]
	TIME [epoch: 11.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268465576464319		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.1268465576464319 | validation: 0.10328492656532878]
	TIME [epoch: 11.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1376800886404031		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.1376800886404031 | validation: 0.11324625555503764]
	TIME [epoch: 11.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13881299868773062		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.13881299868773062 | validation: 0.09883916812901809]
	TIME [epoch: 11.4 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11622688532433807		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.11622688532433807 | validation: 0.10009963147348322]
	TIME [epoch: 11.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1316528325520058		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.1316528325520058 | validation: 0.10328520012235828]
	TIME [epoch: 11.4 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126949525410532		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.126949525410532 | validation: 0.09219344466314913]
	TIME [epoch: 11.4 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12142821682267861		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.12142821682267861 | validation: 0.10184917306214444]
	TIME [epoch: 11.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1145954098987919		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.1145954098987919 | validation: 0.1031805799669478]
	TIME [epoch: 11.4 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12764052537862053		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.12764052537862053 | validation: 0.0892640288448151]
	TIME [epoch: 11.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11680728686613165		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.11680728686613165 | validation: 0.08229880177270193]
	TIME [epoch: 11.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11142728193976117		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.11142728193976117 | validation: 0.12580184069618203]
	TIME [epoch: 11.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14531136612072063		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.14531136612072063 | validation: 0.10420473492611514]
	TIME [epoch: 11.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11329902918164875		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.11329902918164875 | validation: 0.10215610960276073]
	TIME [epoch: 11.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1245407975502445		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.1245407975502445 | validation: 0.09717024220688529]
	TIME [epoch: 11.4 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12664867654205142		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.12664867654205142 | validation: 0.11033920228065952]
	TIME [epoch: 11.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11017053118202555		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.11017053118202555 | validation: 0.07851611483846611]
	TIME [epoch: 11.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10909879336507326		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.10909879336507326 | validation: 0.10370402554763308]
	TIME [epoch: 11.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12719873020254177		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.12719873020254177 | validation: 0.09595282798492713]
	TIME [epoch: 11.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12293823867006907		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.12293823867006907 | validation: 0.10913684095226044]
	TIME [epoch: 11.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12081891415271098		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.12081891415271098 | validation: 0.10520731743824539]
	TIME [epoch: 11.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1182809126800248		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.1182809126800248 | validation: 0.07449096167925577]
	TIME [epoch: 11.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.102464403435409		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.102464403435409 | validation: 0.0828301697291758]
	TIME [epoch: 11.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11987981947757057		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.11987981947757057 | validation: 0.11582212074601751]
	TIME [epoch: 11.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15511829106357738		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.15511829106357738 | validation: 0.11272464740930736]
	TIME [epoch: 11.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12882358341143735		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.12882358341143735 | validation: 0.10505339264136257]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12848219597817154		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.12848219597817154 | validation: 0.11407148042406448]
	TIME [epoch: 11.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13211908372524028		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.13211908372524028 | validation: 0.08575917195562863]
	TIME [epoch: 11.4 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11240117710975132		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.11240117710975132 | validation: 0.10101272524911643]
	TIME [epoch: 11.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13027748717988527		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.13027748717988527 | validation: 0.11268301517860241]
	TIME [epoch: 11.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11411794307948761		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.11411794307948761 | validation: 0.07604528673695875]
	TIME [epoch: 11.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09829052728588145		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.09829052728588145 | validation: 0.09079602229651981]
	TIME [epoch: 11.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10858842922538793		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.10858842922538793 | validation: 0.09113439603893862]
	TIME [epoch: 11.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11035883775546684		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.11035883775546684 | validation: 0.09179813154158784]
	TIME [epoch: 11.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10031003766506238		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.10031003766506238 | validation: 0.08526448192008981]
	TIME [epoch: 11.5 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10773596327911043		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.10773596327911043 | validation: 0.09351104574960342]
	TIME [epoch: 11.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11855054022355911		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.11855054022355911 | validation: 0.09543783975879151]
	TIME [epoch: 11.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12620364860805378		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.12620364860805378 | validation: 0.09339909082765674]
	TIME [epoch: 11.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12828816656950345		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.12828816656950345 | validation: 0.09233721642154015]
	TIME [epoch: 11.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1043757406217468		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.1043757406217468 | validation: 0.09383400197004356]
	TIME [epoch: 11.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10913855300432937		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.10913855300432937 | validation: 0.0785454646295005]
	TIME [epoch: 11.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09514157436241628		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.09514157436241628 | validation: 0.08039107537600076]
	TIME [epoch: 11.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09436087111950524		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.09436087111950524 | validation: 0.0975368929961986]
	TIME [epoch: 11.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11298694586688915		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.11298694586688915 | validation: 0.08597673982563528]
	TIME [epoch: 11.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10675518066744763		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.10675518066744763 | validation: 0.0812824442848765]
	TIME [epoch: 11.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09133740888102389		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.09133740888102389 | validation: 0.07671997517908646]
	TIME [epoch: 11.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1305093548232662		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.1305093548232662 | validation: 0.13690601145402215]
	TIME [epoch: 11.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14511439769327253		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.14511439769327253 | validation: 0.08842492305155257]
	TIME [epoch: 11.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08917391162752665		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.08917391162752665 | validation: 0.06273458153803216]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_815.pth
	Model improved!!!
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10098361823371427		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.10098361823371427 | validation: 0.0752759942226956]
	TIME [epoch: 11.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08372534599591988		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.08372534599591988 | validation: 0.0570343346571294]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_817.pth
	Model improved!!!
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08991700757489296		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.08991700757489296 | validation: 0.08348529017186035]
	TIME [epoch: 11.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.098149156384022		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.098149156384022 | validation: 0.07148437362786375]
	TIME [epoch: 11.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08919971965431961		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.08919971965431961 | validation: 0.08613640220894814]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09097897963043311		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.09097897963043311 | validation: 0.0680262393335329]
	TIME [epoch: 11.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08371013714953121		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.08371013714953121 | validation: 0.07529583335502511]
	TIME [epoch: 11.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0951346649015065		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.0951346649015065 | validation: 0.08864855390797818]
	TIME [epoch: 11.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11472220708729355		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.11472220708729355 | validation: 0.06810615603899675]
	TIME [epoch: 11.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08616598895730815		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.08616598895730815 | validation: 0.05935943271546832]
	TIME [epoch: 11.5 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09599671657637292		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.09599671657637292 | validation: 0.1416849280021107]
	TIME [epoch: 11.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1584445203402411		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.1584445203402411 | validation: 0.09077208857461802]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0984045708300508		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.0984045708300508 | validation: 0.07163433037920634]
	TIME [epoch: 11.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08959845610420777		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.08959845610420777 | validation: 0.06957585169981145]
	TIME [epoch: 11.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0993313957408238		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.0993313957408238 | validation: 0.07305445154473833]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08678940269464272		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.08678940269464272 | validation: 0.08052810908633891]
	TIME [epoch: 11.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08702920313577545		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.08702920313577545 | validation: 0.07839126838397834]
	TIME [epoch: 11.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08843646368722224		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.08843646368722224 | validation: 0.07787239589861869]
	TIME [epoch: 11.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09558061443408813		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.09558061443408813 | validation: 0.06242515833906051]
	TIME [epoch: 11.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0867843629119355		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.0867843629119355 | validation: 0.07771092115470238]
	TIME [epoch: 11.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09446982570661996		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.09446982570661996 | validation: 0.07929673595502307]
	TIME [epoch: 11.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0960324102869399		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.0960324102869399 | validation: 0.07921820817658311]
	TIME [epoch: 11.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09730990377960184		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.09730990377960184 | validation: 0.07291523144995006]
	TIME [epoch: 11.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0913640010474224		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.0913640010474224 | validation: 0.0842166508382363]
	TIME [epoch: 11.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09934849394691564		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.09934849394691564 | validation: 0.08944642508084119]
	TIME [epoch: 11.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10894717627483719		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.10894717627483719 | validation: 0.08312655197237721]
	TIME [epoch: 11.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.098024376369818		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.098024376369818 | validation: 0.09410748443210648]
	TIME [epoch: 11.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09639070152525298		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.09639070152525298 | validation: 0.07621496965557885]
	TIME [epoch: 11.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09223444885636975		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.09223444885636975 | validation: 0.07769538255806868]
	TIME [epoch: 11.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08576854887407476		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.08576854887407476 | validation: 0.06715017635474574]
	TIME [epoch: 11.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09129282843744525		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.09129282843744525 | validation: 0.1010721050897265]
	TIME [epoch: 11.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10748806333835395		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.10748806333835395 | validation: 0.06466867814665113]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0827082560092169		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.0827082560092169 | validation: 0.06390451956627381]
	TIME [epoch: 11.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08841895745949264		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.08841895745949264 | validation: 0.07399778454054462]
	TIME [epoch: 11.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09399687157125783		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.09399687157125783 | validation: 0.06316520981084384]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08984227789553745		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.08984227789553745 | validation: 0.07291382859172871]
	TIME [epoch: 11.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09340819669814748		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.09340819669814748 | validation: 0.07425324111629236]
	TIME [epoch: 11.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0987595270269814		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.0987595270269814 | validation: 0.07533502867979483]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0880612276166034		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.0880612276166034 | validation: 0.0620921672230543]
	TIME [epoch: 11.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09661809557824858		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.09661809557824858 | validation: 0.10672147480438587]
	TIME [epoch: 11.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10109894238466292		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.10109894238466292 | validation: 0.0601878623660934]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08446785613360364		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.08446785613360364 | validation: 0.06969961923044192]
	TIME [epoch: 11.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09744773888771545		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.09744773888771545 | validation: 0.09837900461272525]
	TIME [epoch: 11.5 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13310642272104828		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.13310642272104828 | validation: 0.09544811440886353]
	TIME [epoch: 11.5 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11646195431608342		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.11646195431608342 | validation: 0.10125610004802131]
	TIME [epoch: 11.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11678237656320115		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.11678237656320115 | validation: 0.07548712836638269]
	TIME [epoch: 11.5 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08950754093024524		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.08950754093024524 | validation: 0.06250003705339104]
	TIME [epoch: 11.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0789725970751503		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.0789725970751503 | validation: 0.07168921018539891]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08745798280540866		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.08745798280540866 | validation: 0.07721014358637952]
	TIME [epoch: 11.5 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08265407559659103		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.08265407559659103 | validation: 0.06196209231410553]
	TIME [epoch: 11.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07800348052302856		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.07800348052302856 | validation: 0.06842090266139231]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08680763455875978		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.08680763455875978 | validation: 0.07871975709041969]
	TIME [epoch: 11.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1037080295442382		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.1037080295442382 | validation: 0.08569797580183217]
	TIME [epoch: 11.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0964664464911596		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.0964664464911596 | validation: 0.06395168778034177]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08348574663039023		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.08348574663039023 | validation: 0.07218519608038927]
	TIME [epoch: 11.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09367023288442107		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.09367023288442107 | validation: 0.06806155910839631]
	TIME [epoch: 11.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.092327135664824		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.092327135664824 | validation: 0.07826283448722447]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11245738488262133		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.11245738488262133 | validation: 0.08809984803827327]
	TIME [epoch: 11.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11587356354794057		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.11587356354794057 | validation: 0.1384814327645508]
	TIME [epoch: 11.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15682380080990146		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.15682380080990146 | validation: 0.10361319502003671]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13196283411646564		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.13196283411646564 | validation: 0.10172550871677917]
	TIME [epoch: 11.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12346960280015498		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.12346960280015498 | validation: 0.07930743422594243]
	TIME [epoch: 11.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09643923866086435		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.09643923866086435 | validation: 0.07448955225490934]
	TIME [epoch: 11.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.093741660203955		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.093741660203955 | validation: 0.06568499474157675]
	TIME [epoch: 11.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09228005682836218		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.09228005682836218 | validation: 0.07029869877318536]
	TIME [epoch: 11.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09089015505276068		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.09089015505276068 | validation: 0.07608815669443213]
	TIME [epoch: 11.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08705674088996464		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.08705674088996464 | validation: 0.06418207811624806]
	TIME [epoch: 11.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08020066436682223		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.08020066436682223 | validation: 0.0730226538059314]
	TIME [epoch: 11.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08123494783892161		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.08123494783892161 | validation: 0.05251662109916008]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_884.pth
	Model improved!!!
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07705337746870974		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.07705337746870974 | validation: 0.057988211275108184]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09567346193912692		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.09567346193912692 | validation: 0.08510556861408716]
	TIME [epoch: 11.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09909131839026962		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.09909131839026962 | validation: 0.08262636926780535]
	TIME [epoch: 11.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08450612175822209		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.08450612175822209 | validation: 0.059213807673384966]
	TIME [epoch: 11.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07869856384822654		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.07869856384822654 | validation: 0.05729402041936107]
	TIME [epoch: 11.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07901218109829235		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.07901218109829235 | validation: 0.06251150382574687]
	TIME [epoch: 11.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08106972422509467		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.08106972422509467 | validation: 0.07486001344489099]
	TIME [epoch: 11.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10130564324166726		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.10130564324166726 | validation: 0.08985163063689082]
	TIME [epoch: 11.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09933331803313		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.09933331803313 | validation: 0.07697593365640311]
	TIME [epoch: 11.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09704110944817068		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.09704110944817068 | validation: 0.08246335954836705]
	TIME [epoch: 11.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11183669713953692		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.11183669713953692 | validation: 0.10872492562312527]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12097944233085486		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.12097944233085486 | validation: 0.08450074697657364]
	TIME [epoch: 11.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10207850293657711		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.10207850293657711 | validation: 0.08475936726401219]
	TIME [epoch: 11.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11267272072196616		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.11267272072196616 | validation: 0.12150015269292257]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487881197389745		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.1487881197389745 | validation: 0.117111099485281]
	TIME [epoch: 11.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11778551775285322		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.11778551775285322 | validation: 0.08154226746724867]
	TIME [epoch: 11.5 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09566760283864716		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.09566760283864716 | validation: 0.0681949788715436]
	TIME [epoch: 11.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09351136406398756		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.09351136406398756 | validation: 0.08520197558166087]
	TIME [epoch: 11.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09994109544606022		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.09994109544606022 | validation: 0.07353155051878588]
	TIME [epoch: 11.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1195707053442791		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.1195707053442791 | validation: 0.15442449916083878]
	TIME [epoch: 11.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15371848747908382		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.15371848747908382 | validation: 0.0778481989591901]
	TIME [epoch: 11.4 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10300482227710409		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.10300482227710409 | validation: 0.08582762650598096]
	TIME [epoch: 11.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11334909019864167		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.11334909019864167 | validation: 0.09592046793204048]
	TIME [epoch: 11.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12597618902555305		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.12597618902555305 | validation: 0.12129843212469205]
	TIME [epoch: 11.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12466439615933354		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.12466439615933354 | validation: 0.08310307825911921]
	TIME [epoch: 11.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10072626033500036		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.10072626033500036 | validation: 0.08302527900226192]
	TIME [epoch: 11.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09648907169159728		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.09648907169159728 | validation: 0.08472522994912421]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10543488422296701		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.10543488422296701 | validation: 0.07686581121262272]
	TIME [epoch: 11.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10474881522665488		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.10474881522665488 | validation: 0.08327802135513256]
	TIME [epoch: 11.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11591398950153871		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.11591398950153871 | validation: 0.08896968014228804]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1046399655622212		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.1046399655622212 | validation: 0.07995743271949607]
	TIME [epoch: 11.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10108746724686309		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.10108746724686309 | validation: 0.08822534626481801]
	TIME [epoch: 11.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1067185679693349		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.1067185679693349 | validation: 0.08783053768105263]
	TIME [epoch: 11.5 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1049291045781992		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.1049291045781992 | validation: 0.07766065573421102]
	TIME [epoch: 11.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.085966141363866		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.085966141363866 | validation: 0.07549910541105698]
	TIME [epoch: 11.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08379181558203694		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.08379181558203694 | validation: 0.06551244851971086]
	TIME [epoch: 11.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0819148414064478		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.0819148414064478 | validation: 0.0557920701885797]
	TIME [epoch: 11.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08314815250316245		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.08314815250316245 | validation: 0.06772908681008072]
	TIME [epoch: 11.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08924451600562605		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.08924451600562605 | validation: 0.07499102627633164]
	TIME [epoch: 11.5 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08568974991793563		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.08568974991793563 | validation: 0.0640436752436373]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07448191170891748		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.07448191170891748 | validation: 0.06337296121913406]
	TIME [epoch: 11.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08738574674263419		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.08738574674263419 | validation: 0.061761773856724204]
	TIME [epoch: 11.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08260117548458466		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.08260117548458466 | validation: 0.06201889464741406]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07599779687438331		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.07599779687438331 | validation: 0.06699901437614757]
	TIME [epoch: 11.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08436339077277907		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.08436339077277907 | validation: 0.05882572382273905]
	TIME [epoch: 11.5 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08198995637152176		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.08198995637152176 | validation: 0.052131564063080144]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_930.pth
	Model improved!!!
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07226231667368249		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.07226231667368249 | validation: 0.05810868880826938]
	TIME [epoch: 11.4 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0712139790162189		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.0712139790162189 | validation: 0.05191510962370954]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_932.pth
	Model improved!!!
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06850643601698761		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.06850643601698761 | validation: 0.06302156153459867]
	TIME [epoch: 11.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07947436826714413		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.07947436826714413 | validation: 0.05278012180192227]
	TIME [epoch: 11.4 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07197186671453959		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.07197186671453959 | validation: 0.07405050878476759]
	TIME [epoch: 11.5 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08924282592256566		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.08924282592256566 | validation: 0.07672048399044379]
	TIME [epoch: 11.5 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09352835457889609		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.09352835457889609 | validation: 0.09565672743070844]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09820271477024284		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.09820271477024284 | validation: 0.07304149737046593]
	TIME [epoch: 11.5 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09328962833275233		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.09328962833275233 | validation: 0.06507771802843167]
	TIME [epoch: 11.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08488531690265942		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.08488531690265942 | validation: 0.06410770004899422]
	TIME [epoch: 11.4 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08183111181865678		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.08183111181865678 | validation: 0.05929627636211052]
	TIME [epoch: 11.4 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07026359617420747		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.07026359617420747 | validation: 0.052000209285813795]
	TIME [epoch: 11.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07491226653129887		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.07491226653129887 | validation: 0.06016412128025435]
	TIME [epoch: 11.4 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0780298526059271		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.0780298526059271 | validation: 0.05730950367183274]
	TIME [epoch: 11.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07639494256236137		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.07639494256236137 | validation: 0.06274331629678065]
	TIME [epoch: 11.5 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09209825795498519		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.09209825795498519 | validation: 0.07439364221423794]
	TIME [epoch: 11.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09168540166737618		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.09168540166737618 | validation: 0.08451585135483565]
	TIME [epoch: 11.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10670027333084121		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.10670027333084121 | validation: 0.10010962470416299]
	TIME [epoch: 11.5 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12417014852715172		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.12417014852715172 | validation: 0.10450314790792362]
	TIME [epoch: 11.4 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12559977298250213		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.12559977298250213 | validation: 0.09621325948574044]
	TIME [epoch: 11.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11005033695778166		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.11005033695778166 | validation: 0.08082522938769475]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0992253191467967		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.0992253191467967 | validation: 0.0781276054169501]
	TIME [epoch: 11.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08817923163918441		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.08817923163918441 | validation: 0.06138824315593347]
	TIME [epoch: 11.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08214315435791542		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.08214315435791542 | validation: 0.06426139116794483]
	TIME [epoch: 11.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07896580314749832		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.07896580314749832 | validation: 0.056395654782868405]
	TIME [epoch: 11.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07102629990953536		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.07102629990953536 | validation: 0.06443158082949514]
	TIME [epoch: 11.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06865334842425819		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.06865334842425819 | validation: 0.0554049369799231]
	TIME [epoch: 11.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07072534367543362		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.07072534367543362 | validation: 0.05700504194133126]
	TIME [epoch: 11.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07765227590153523		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.07765227590153523 | validation: 0.06620015068037274]
	TIME [epoch: 11.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10642424416985205		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.10642424416985205 | validation: 0.10622410962430862]
	TIME [epoch: 11.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12130473367698143		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.12130473367698143 | validation: 0.11662813442147747]
	TIME [epoch: 11.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12733898487014342		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.12733898487014342 | validation: 0.0845718433576461]
	TIME [epoch: 11.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09481815384125186		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.09481815384125186 | validation: 0.06463895972330289]
	TIME [epoch: 11.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07591369807578593		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.07591369807578593 | validation: 0.055205653211288175]
	TIME [epoch: 11.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06431364101276393		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.06431364101276393 | validation: 0.05325095411323322]
	TIME [epoch: 11.5 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07129567064173391		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.07129567064173391 | validation: 0.06686350959428113]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0812303328770916		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.0812303328770916 | validation: 0.06076536393780655]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08140272561417272		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.08140272561417272 | validation: 0.057325581445111025]
	TIME [epoch: 11.5 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07126386063272566		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.07126386063272566 | validation: 0.0702975963721744]
	TIME [epoch: 11.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08027728034698456		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.08027728034698456 | validation: 0.06372869702787196]
	TIME [epoch: 11.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07672143203516898		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.07672143203516898 | validation: 0.07110121656760986]
	TIME [epoch: 11.4 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08369364796187041		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.08369364796187041 | validation: 0.054431050265891553]
	TIME [epoch: 11.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06785807054717136		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.06785807054717136 | validation: 0.06344961808443415]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07755681855386806		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.07755681855386806 | validation: 0.0670071370769898]
	TIME [epoch: 11.5 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08388657037025875		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.08388657037025875 | validation: 0.06962900566216844]
	TIME [epoch: 11.5 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08368965967381173		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.08368965967381173 | validation: 0.04775740753612064]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_976.pth
	Model improved!!!
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06494368891283965		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.06494368891283965 | validation: 0.046941000095848236]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_977.pth
	Model improved!!!
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0683743356037265		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.0683743356037265 | validation: 0.053530304404891524]
	TIME [epoch: 11.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06968242525410062		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.06968242525410062 | validation: 0.0662712303504847]
	TIME [epoch: 11.4 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07195285151328856		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.07195285151328856 | validation: 0.05278357940493614]
	TIME [epoch: 11.5 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0670520673719413		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.0670520673719413 | validation: 0.048978180071087465]
	TIME [epoch: 11.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07062488871143915		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.07062488871143915 | validation: 0.0560427905921765]
	TIME [epoch: 11.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07933163556709312		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.07933163556709312 | validation: 0.0784456599675048]
	TIME [epoch: 11.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10301120064500072		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.10301120064500072 | validation: 0.10014604525556824]
	TIME [epoch: 11.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1048979379118755		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.1048979379118755 | validation: 0.06274135068526623]
	TIME [epoch: 11.4 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08012512501181		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.08012512501181 | validation: 0.061284776808604544]
	TIME [epoch: 11.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07607648139247095		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.07607648139247095 | validation: 0.05331108500574159]
	TIME [epoch: 11.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07876349084780108		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.07876349084780108 | validation: 0.06083276668985715]
	TIME [epoch: 11.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06798044084074939		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.06798044084074939 | validation: 0.0518549884870723]
	TIME [epoch: 11.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0813088118322727		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.0813088118322727 | validation: 0.07024257690118627]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08783429806192959		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.08783429806192959 | validation: 0.06340745806940024]
	TIME [epoch: 11.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07738000130942436		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.07738000130942436 | validation: 0.056670335631554436]
	TIME [epoch: 11.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07103813166807671		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.07103813166807671 | validation: 0.054442635225389564]
	TIME [epoch: 11.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07202012089351492		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.07202012089351492 | validation: 0.06510600257755342]
	TIME [epoch: 11.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07062505434885083		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.07062505434885083 | validation: 0.05469752473814476]
	TIME [epoch: 11.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07542965390682732		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.07542965390682732 | validation: 0.07545655838901998]
	TIME [epoch: 11.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09848697821663453		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.09848697821663453 | validation: 0.07749743781101914]
	TIME [epoch: 11.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09083098811131543		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.09083098811131543 | validation: 0.08535324319597276]
	TIME [epoch: 11.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10289121340514917		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.10289121340514917 | validation: 0.07236085774351098]
	TIME [epoch: 11.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07911074379269563		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.07911074379269563 | validation: 0.049663152574749445]
	TIME [epoch: 11.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0720238393344895		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.0720238393344895 | validation: 0.05473448242251958]
	TIME [epoch: 11.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06859658690224527		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.06859658690224527 | validation: 0.047507845472418764]
	TIME [epoch: 11.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07582840995397275		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.07582840995397275 | validation: 0.057388542711813775]
	TIME [epoch: 11.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07665460475463196		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.07665460475463196 | validation: 0.0546891874237453]
	TIME [epoch: 11.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07750211120890706		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.07750211120890706 | validation: 0.0633534646230268]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07490784552444998		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.07490784552444998 | validation: 0.07126767710999939]
	TIME [epoch: 11.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0787155435638253		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.0787155435638253 | validation: 0.052395032937254137]
	TIME [epoch: 11.5 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06496428491530569		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.06496428491530569 | validation: 0.05894571457473041]
	TIME [epoch: 11.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06732751638487094		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.06732751638487094 | validation: 0.05542971094519439]
	TIME [epoch: 11.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0691806730987357		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.0691806730987357 | validation: 0.05174553837605645]
	TIME [epoch: 11.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07571475235111376		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.07571475235111376 | validation: 0.07775588899711791]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08542896180271886		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.08542896180271886 | validation: 0.07247389383756668]
	TIME [epoch: 11.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07367838697730392		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.07367838697730392 | validation: 0.06242874790425248]
	TIME [epoch: 11.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07798899361980344		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.07798899361980344 | validation: 0.05943235149792784]
	TIME [epoch: 11.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07310980281956996		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.07310980281956996 | validation: 0.05592659630040347]
	TIME [epoch: 11.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08191831139377215		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.08191831139377215 | validation: 0.07223107033794796]
	TIME [epoch: 11.5 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07610985333040785		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.07610985333040785 | validation: 0.04155414236766104]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_1017.pth
	Model improved!!!
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07057776525281123		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.07057776525281123 | validation: 0.06422368459781194]
	TIME [epoch: 11.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07850675962538711		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.07850675962538711 | validation: 0.06670811681433496]
	TIME [epoch: 11.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08221539779691826		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.08221539779691826 | validation: 0.07090374430118039]
	TIME [epoch: 11.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08517588805973769		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.08517588805973769 | validation: 0.07789300470602875]
	TIME [epoch: 11.4 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08681204959148145		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.08681204959148145 | validation: 0.07735575851259817]
	TIME [epoch: 11.5 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08107055686793568		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.08107055686793568 | validation: 0.05979791374311954]
	TIME [epoch: 11.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07786338943221076		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.07786338943221076 | validation: 0.06643327562339446]
	TIME [epoch: 11.4 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07310245622718163		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.07310245622718163 | validation: 0.0635186545780886]
	TIME [epoch: 11.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07813227710655801		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.07813227710655801 | validation: 0.0715521104165874]
	TIME [epoch: 11.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06977779694339273		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.06977779694339273 | validation: 0.0493711928825549]
	TIME [epoch: 11.4 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0692235725151201		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.0692235725151201 | validation: 0.057286849851023995]
	TIME [epoch: 11.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07042416785120935		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.07042416785120935 | validation: 0.052682598319401974]
	TIME [epoch: 11.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06900417614406748		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.06900417614406748 | validation: 0.05183627196702605]
	TIME [epoch: 11.4 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07477817627052516		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.07477817627052516 | validation: 0.06285819114369062]
	TIME [epoch: 11.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07654520527278759		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.07654520527278759 | validation: 0.05895133507197201]
	TIME [epoch: 11.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07933605950664888		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.07933605950664888 | validation: 0.056161897123396684]
	TIME [epoch: 11.4 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07258326201406629		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.07258326201406629 | validation: 0.05172772332433556]
	TIME [epoch: 11.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06442886847057058		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.06442886847057058 | validation: 0.05676906954414745]
	TIME [epoch: 11.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07002638420967454		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.07002638420967454 | validation: 0.0786436142360191]
	TIME [epoch: 11.4 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08546758228428503		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.08546758228428503 | validation: 0.07337551825833712]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08030550067323733		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.08030550067323733 | validation: 0.05586174918520509]
	TIME [epoch: 11.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06717212762768919		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.06717212762768919 | validation: 0.06091749794643287]
	TIME [epoch: 11.4 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0710403379131886		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.0710403379131886 | validation: 0.04443372083067434]
	TIME [epoch: 11.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06699422128188491		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.06699422128188491 | validation: 0.0497572192418928]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06530558301390865		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.06530558301390865 | validation: 0.04688489677462135]
	TIME [epoch: 11.4 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06493809645652718		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.06493809645652718 | validation: 0.054867061621016455]
	TIME [epoch: 11.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07192589636723705		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.07192589636723705 | validation: 0.04319670634436121]
	TIME [epoch: 11.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06771874752954746		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.06771874752954746 | validation: 0.0496114423869974]
	TIME [epoch: 11.4 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07021866635467965		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.07021866635467965 | validation: 0.05551193559335821]
	TIME [epoch: 11.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07947500418311272		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.07947500418311272 | validation: 0.06682099947956122]
	TIME [epoch: 11.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10309611342190526		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.10309611342190526 | validation: 0.0970529280263536]
	TIME [epoch: 11.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09964512023437372		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.09964512023437372 | validation: 0.06561597487438062]
	TIME [epoch: 11.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06944998758564534		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.06944998758564534 | validation: 0.062340677166733145]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07257258908308907		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.07257258908308907 | validation: 0.06234299354395699]
	TIME [epoch: 11.4 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07115025432054385		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.07115025432054385 | validation: 0.06481918624789523]
	TIME [epoch: 11.4 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06991373621351975		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.06991373621351975 | validation: 0.06389700153245671]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0728312049137021		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.0728312049137021 | validation: 0.0709732098764141]
	TIME [epoch: 11.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08720375755769498		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.08720375755769498 | validation: 0.06834001233529177]
	TIME [epoch: 11.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07524194505044177		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.07524194505044177 | validation: 0.05010294544954213]
	TIME [epoch: 11.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07334683352740705		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.07334683352740705 | validation: 0.05565078709920278]
	TIME [epoch: 11.4 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07049957364013254		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.07049957364013254 | validation: 0.07390258543944324]
	TIME [epoch: 11.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08068012182626769		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.08068012182626769 | validation: 0.07164607361370387]
	TIME [epoch: 11.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09264394632722618		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.09264394632722618 | validation: 0.08144397391011993]
	TIME [epoch: 11.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08684728460975119		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.08684728460975119 | validation: 0.08526217171147042]
	TIME [epoch: 11.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08990586342084751		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.08990586342084751 | validation: 0.06226660043438347]
	TIME [epoch: 11.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07602227058726682		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.07602227058726682 | validation: 0.05389734002045074]
	TIME [epoch: 11.4 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07206431976631156		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.07206431976631156 | validation: 0.053003555675974]
	TIME [epoch: 11.4 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06612429606520998		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.06612429606520998 | validation: 0.05835311651312999]
	TIME [epoch: 11.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06621894088360147		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.06621894088360147 | validation: 0.049393665769612176]
	TIME [epoch: 11.4 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06704297559239264		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.06704297559239264 | validation: 0.05529870683127607]
	TIME [epoch: 11.5 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06402135717920551		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.06402135717920551 | validation: 0.05242617171910432]
	TIME [epoch: 11.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06800331733354822		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.06800331733354822 | validation: 0.053505111199987326]
	TIME [epoch: 11.4 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06693965717198104		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.06693965717198104 | validation: 0.04830624801915489]
	TIME [epoch: 11.4 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06641870294809912		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.06641870294809912 | validation: 0.047361010247428975]
	TIME [epoch: 11.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06628766038652825		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.06628766038652825 | validation: 0.045202868845401305]
	TIME [epoch: 11.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06726426466297178		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.06726426466297178 | validation: 0.05762431413535794]
	TIME [epoch: 11.5 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06529181700192668		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.06529181700192668 | validation: 0.052062721894164284]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06688041201691844		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.06688041201691844 | validation: 0.0551374687032135]
	TIME [epoch: 11.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06328719621613083		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.06328719621613083 | validation: 0.04898247087935034]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0642396237306357		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.0642396237306357 | validation: 0.04605403009612357]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0631251265197726		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.0631251265197726 | validation: 0.04929041444948878]
	TIME [epoch: 11.4 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0654175078516572		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.0654175078516572 | validation: 0.04818883776872401]
	TIME [epoch: 11.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06205506353256944		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.06205506353256944 | validation: 0.04595003926283193]
	TIME [epoch: 11.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06286996148940634		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.06286996148940634 | validation: 0.05401352295427364]
	TIME [epoch: 11.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07030877418358182		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.07030877418358182 | validation: 0.05322404667680404]
	TIME [epoch: 11.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07002105587070685		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.07002105587070685 | validation: 0.06738723271271127]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08281328316835593		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.08281328316835593 | validation: 0.06130082009105865]
	TIME [epoch: 11.4 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07457316596889066		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.07457316596889066 | validation: 0.05745213171387803]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06194125416873465		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.06194125416873465 | validation: 0.053837811670873544]
	TIME [epoch: 11.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0639310453173604		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.0639310453173604 | validation: 0.05268293872011454]
	TIME [epoch: 11.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06407258924862128		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.06407258924862128 | validation: 0.05729219925416889]
	TIME [epoch: 11.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07521263265105112		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.07521263265105112 | validation: 0.07156498449122288]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0878327449181872		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.0878327449181872 | validation: 0.06467151670050282]
	TIME [epoch: 11.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06412972611755581		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.06412972611755581 | validation: 0.05125348211237686]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059636937398089104		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.059636937398089104 | validation: 0.05744150060229865]
	TIME [epoch: 12.4 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06824376356222916		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.06824376356222916 | validation: 0.05341591676790703]
	TIME [epoch: 11.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0707618970579584		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.0707618970579584 | validation: 0.05493433147497591]
	TIME [epoch: 11.5 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07659287704836451		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.07659287704836451 | validation: 0.07182031712032597]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07877357890453279		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.07877357890453279 | validation: 0.06225495756180699]
	TIME [epoch: 11.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0771298998050188		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.0771298998050188 | validation: 0.06292927381511752]
	TIME [epoch: 11.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0773809888039962		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.0773809888039962 | validation: 0.054648940614262786]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06904036494260309		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.06904036494260309 | validation: 0.043585870894318667]
	TIME [epoch: 11.5 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06829852267345417		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.06829852267345417 | validation: 0.05575028717705165]
	TIME [epoch: 11.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07592583043482037		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.07592583043482037 | validation: 0.062056168878436645]
	TIME [epoch: 11.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0833278089530343		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.0833278089530343 | validation: 0.07319797450422738]
	TIME [epoch: 11.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08002970043002292		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.08002970043002292 | validation: 0.0687182096069506]
	TIME [epoch: 11.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08705651086850807		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.08705651086850807 | validation: 0.0788870272547216]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08301322661391412		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.08301322661391412 | validation: 0.06387864195831734]
	TIME [epoch: 11.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07578844612700189		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.07578844612700189 | validation: 0.054599847841328215]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06872598002207303		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.06872598002207303 | validation: 0.06166952437005947]
	TIME [epoch: 11.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07143130730785124		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.07143130730785124 | validation: 0.05791031494089834]
	TIME [epoch: 11.4 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0713086683899411		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.0713086683899411 | validation: 0.058412578588415524]
	TIME [epoch: 11.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07877881446637806		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.07877881446637806 | validation: 0.06030550626295883]
	TIME [epoch: 11.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06755295102108194		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.06755295102108194 | validation: 0.052177832828977415]
	TIME [epoch: 11.5 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06161897670050155		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.06161897670050155 | validation: 0.056596283413574054]
	TIME [epoch: 11.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06566456659170877		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.06566456659170877 | validation: 0.04362753055254331]
	TIME [epoch: 11.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05960810354134277		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.05960810354134277 | validation: 0.05261400761249129]
	TIME [epoch: 11.5 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06763435963051831		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.06763435963051831 | validation: 0.048317264131846435]
	TIME [epoch: 11.5 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06642803462484972		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.06642803462484972 | validation: 0.059631888025119685]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0611167898281868		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.0611167898281868 | validation: 0.04871739254905842]
	TIME [epoch: 11.5 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06668266730967688		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.06668266730967688 | validation: 0.05412284869937642]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06174744880319705		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.06174744880319705 | validation: 0.04762501709238727]
	TIME [epoch: 11.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06541888150788762		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.06541888150788762 | validation: 0.05219839861274094]
	TIME [epoch: 11.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.069327860471818		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.069327860471818 | validation: 0.05172292848275249]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07129618489452115		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.07129618489452115 | validation: 0.053847434168737995]
	TIME [epoch: 11.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06678795563397937		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.06678795563397937 | validation: 0.054761156857096295]
	TIME [epoch: 11.5 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06607045873893577		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.06607045873893577 | validation: 0.05251415639776141]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07033704346480292		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.07033704346480292 | validation: 0.056754323016065804]
	TIME [epoch: 11.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07382588590757183		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.07382588590757183 | validation: 0.047375515500502806]
	TIME [epoch: 11.5 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07107268473062728		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.07107268473062728 | validation: 0.050694161638123826]
	TIME [epoch: 11.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06847787461569221		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.06847787461569221 | validation: 0.05215342833978988]
	TIME [epoch: 11.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06208017252975556		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.06208017252975556 | validation: 0.04929390449741616]
	TIME [epoch: 11.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06489123411961173		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.06489123411961173 | validation: 0.053925049359549684]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06447751143631464		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.06447751143631464 | validation: 0.05556716214914582]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06388219695888273		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.06388219695888273 | validation: 0.04976343345336758]
	TIME [epoch: 11.4 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06665843354140186		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.06665843354140186 | validation: 0.05454737857614804]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06944862307947976		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.06944862307947976 | validation: 0.05009090256660733]
	TIME [epoch: 11.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06772269787494552		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.06772269787494552 | validation: 0.05717693834906425]
	TIME [epoch: 11.5 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06579950811191118		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.06579950811191118 | validation: 0.056786421277644994]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06627241990801024		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.06627241990801024 | validation: 0.041631101682338266]
	TIME [epoch: 11.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06288242038139608		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.06288242038139608 | validation: 0.05040576892009154]
	TIME [epoch: 11.5 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06910818336402894		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.06910818336402894 | validation: 0.0547685301456214]
	TIME [epoch: 11.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08402336116685222		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.08402336116685222 | validation: 0.062213410096654195]
	TIME [epoch: 11.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08716001257038986		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.08716001257038986 | validation: 0.07064313407244024]
	TIME [epoch: 11.5 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08726427591286848		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.08726427591286848 | validation: 0.06759862582079423]
	TIME [epoch: 11.5 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08278455143668338		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.08278455143668338 | validation: 0.06228503910040281]
	TIME [epoch: 11.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07455814955669993		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.07455814955669993 | validation: 0.05637378329057631]
	TIME [epoch: 11.5 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07467491649773733		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.07467491649773733 | validation: 0.06215530617274895]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08236474373558683		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.08236474373558683 | validation: 0.06626355257987233]
	TIME [epoch: 11.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08371239615151024		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.08371239615151024 | validation: 0.05919318967982935]
	TIME [epoch: 11.5 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07347267654311314		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.07347267654311314 | validation: 0.05082704947437899]
	TIME [epoch: 11.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07351554999867298		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.07351554999867298 | validation: 0.049758888341756145]
	TIME [epoch: 11.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07002485057116338		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.07002485057116338 | validation: 0.057486066881387875]
	TIME [epoch: 11.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07298628558318046		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.07298628558318046 | validation: 0.05798571789127957]
	TIME [epoch: 11.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08020546994103679		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.08020546994103679 | validation: 0.061162456774775914]
	TIME [epoch: 11.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0773373335268697		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.0773373335268697 | validation: 0.05917968415924173]
	TIME [epoch: 11.5 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07698034654546157		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.07698034654546157 | validation: 0.056355222247216175]
	TIME [epoch: 11.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07693144156805534		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.07693144156805534 | validation: 0.06107740969311459]
	TIME [epoch: 11.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07936122339843098		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.07936122339843098 | validation: 0.05562762455128636]
	TIME [epoch: 11.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07208458432736546		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.07208458432736546 | validation: 0.054420835770673026]
	TIME [epoch: 11.5 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06895402997055536		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.06895402997055536 | validation: 0.06441663879529648]
	TIME [epoch: 11.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07652038676128836		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.07652038676128836 | validation: 0.05912715850648361]
	TIME [epoch: 11.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07279633503758433		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.07279633503758433 | validation: 0.059704637519298026]
	TIME [epoch: 11.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06996165303245844		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.06996165303245844 | validation: 0.054470840614588366]
	TIME [epoch: 11.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07063236018079722		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.07063236018079722 | validation: 0.050102513840337794]
	TIME [epoch: 11.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0679480948237336		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.0679480948237336 | validation: 0.05441101455065247]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06728711104153622		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.06728711104153622 | validation: 0.04513456488681545]
	TIME [epoch: 11.5 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06487017338824919		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.06487017338824919 | validation: 0.05344904059222202]
	TIME [epoch: 11.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06700251940265112		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.06700251940265112 | validation: 0.051951104300894495]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06626947513346967		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.06626947513346967 | validation: 0.04959228313075032]
	TIME [epoch: 11.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06538311458607389		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.06538311458607389 | validation: 0.05055490692859133]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06598372982537794		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.06598372982537794 | validation: 0.04844538323863844]
	TIME [epoch: 11.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07379237272747732		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.07379237272747732 | validation: 0.050758095492491495]
	TIME [epoch: 11.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0693970578609662		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.0693970578609662 | validation: 0.051003324419055134]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06511898195363691		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.06511898195363691 | validation: 0.05542747446682595]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06720548549360846		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.06720548549360846 | validation: 0.046839472404808354]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06790846420837214		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.06790846420837214 | validation: 0.0493658410691072]
	TIME [epoch: 11.5 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07292795913131181		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.07292795913131181 | validation: 0.06153555215399047]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07996253071714308		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.07996253071714308 | validation: 0.07311147031629904]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07203261965410533		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.07203261965410533 | validation: 0.05052369582705232]
	TIME [epoch: 11.5 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06714971582014337		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.06714971582014337 | validation: 0.04613217832499276]
	TIME [epoch: 11.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06605821706048112		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.06605821706048112 | validation: 0.04715769177260462]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0635538457475027		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.0635538457475027 | validation: 0.04748421839461373]
	TIME [epoch: 11.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06367312084040659		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.06367312084040659 | validation: 0.04978861038638243]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0670892260524664		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.0670892260524664 | validation: 0.04736088305518412]
	TIME [epoch: 11.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0731778672617234		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.0731778672617234 | validation: 0.06652005228375675]
	TIME [epoch: 11.4 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07868427685799526		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.07868427685799526 | validation: 0.07303115430654758]
	TIME [epoch: 11.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08140788141696635		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.08140788141696635 | validation: 0.06684195110030061]
	TIME [epoch: 11.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07689979142479632		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.07689979142479632 | validation: 0.05422536955163659]
	TIME [epoch: 11.4 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06572808389970652		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.06572808389970652 | validation: 0.044881616320681876]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058880810278597595		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.058880810278597595 | validation: 0.04655678493550143]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06093007640269786		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.06093007640269786 | validation: 0.04544128418076026]
	TIME [epoch: 11.4 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06063484788174238		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.06063484788174238 | validation: 0.04432547464800167]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06337202809204753		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.06337202809204753 | validation: 0.058373271381542836]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08658600973486981		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.08658600973486981 | validation: 0.07675373805024875]
	TIME [epoch: 11.4 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08374380616104193		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.08374380616104193 | validation: 0.06453523462726643]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0792108991327122		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.0792108991327122 | validation: 0.06672187347957169]
	TIME [epoch: 11.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0768272203335174		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.0768272203335174 | validation: 0.05674933480852834]
	TIME [epoch: 11.4 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07718509248579608		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.07718509248579608 | validation: 0.05472421163657121]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07024833000149623		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.07024833000149623 | validation: 0.059500228647071066]
	TIME [epoch: 11.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07465999990687743		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.07465999990687743 | validation: 0.05792149390380943]
	TIME [epoch: 11.4 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07753819759261245		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.07753819759261245 | validation: 0.07173893521466534]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08179902930060207		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.08179902930060207 | validation: 0.07449365541439752]
	TIME [epoch: 11.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07768028363434733		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.07768028363434733 | validation: 0.062351519330692086]
	TIME [epoch: 11.4 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07842119259586139		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.07842119259586139 | validation: 0.06106235725827769]
	TIME [epoch: 11.4 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0753234634149553		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.0753234634149553 | validation: 0.05468979920671041]
	TIME [epoch: 11.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07312901581175191		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.07312901581175191 | validation: 0.052431698662730584]
	TIME [epoch: 11.4 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06860683487789143		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.06860683487789143 | validation: 0.04472148657176383]
	TIME [epoch: 11.4 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06884954708264492		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.06884954708264492 | validation: 0.05646538847496701]
	TIME [epoch: 11.5 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06702592943307156		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.06702592943307156 | validation: 0.04733997334726643]
	TIME [epoch: 11.5 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06689080062818126		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.06689080062818126 | validation: 0.05425957560565629]
	TIME [epoch: 11.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0620699532474766		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.0620699532474766 | validation: 0.03949647786853527]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_1209.pth
	Model improved!!!
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061915022997128		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.061915022997128 | validation: 0.047936784329301575]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06308653516307		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.06308653516307 | validation: 0.04826174771346702]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06313390685139285		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.06313390685139285 | validation: 0.044417337364981775]
	TIME [epoch: 11.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06363755781186894		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.06363755781186894 | validation: 0.048955401885906476]
	TIME [epoch: 11.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06809223989666122		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.06809223989666122 | validation: 0.055420974094041356]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05975167193610659		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.05975167193610659 | validation: 0.04766136696782066]
	TIME [epoch: 11.5 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06476257495624031		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.06476257495624031 | validation: 0.044866527930003106]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06159133514053025		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.06159133514053025 | validation: 0.057899080425578155]
	TIME [epoch: 11.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0667882964686299		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.0667882964686299 | validation: 0.0609828540812863]
	TIME [epoch: 11.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0668098601194957		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.0668098601194957 | validation: 0.05756058227057232]
	TIME [epoch: 11.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07224319785876304		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.07224319785876304 | validation: 0.05751640580302725]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06983587505018483		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.06983587505018483 | validation: 0.04846761770780033]
	TIME [epoch: 11.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06916187531274114		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.06916187531274114 | validation: 0.05883631313519164]
	TIME [epoch: 11.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0674266078053104		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.0674266078053104 | validation: 0.04800472535500909]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0642401541433012		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.0642401541433012 | validation: 0.04797682015123427]
	TIME [epoch: 11.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06707756391310904		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.06707756391310904 | validation: 0.048379351504629325]
	TIME [epoch: 11.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06354258132969898		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.06354258132969898 | validation: 0.04958213541357122]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058899704808601974		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.058899704808601974 | validation: 0.04625959719185345]
	TIME [epoch: 11.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06498201001623571		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.06498201001623571 | validation: 0.05619910448310948]
	TIME [epoch: 11.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06211017201253961		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.06211017201253961 | validation: 0.04732862359471522]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05923932874051376		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.05923932874051376 | validation: 0.05710064656518517]
	TIME [epoch: 11.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06078461110767826		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.06078461110767826 | validation: 0.050698245096881936]
	TIME [epoch: 11.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06098290599274388		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.06098290599274388 | validation: 0.03835293641475195]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_1232.pth
	Model improved!!!
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06377727329548953		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.06377727329548953 | validation: 0.04807544906328978]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05846604378888999		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.05846604378888999 | validation: 0.049843182393605974]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06139672297589729		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.06139672297589729 | validation: 0.04720158025402754]
	TIME [epoch: 11.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05716298439041084		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.05716298439041084 | validation: 0.05266296644128323]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05832743911670732		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.05832743911670732 | validation: 0.05027113358377022]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05831679645223024		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.05831679645223024 | validation: 0.043128037432365415]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060614093407757766		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.060614093407757766 | validation: 0.03994730701201426]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057156880923365724		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.057156880923365724 | validation: 0.04812753050536009]
	TIME [epoch: 11.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0592643282940611		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.0592643282940611 | validation: 0.04096254141125469]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06039288231549663		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.06039288231549663 | validation: 0.053461875666037065]
	TIME [epoch: 11.5 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05954978941823102		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.05954978941823102 | validation: 0.048755750353917215]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05528168667239399		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.05528168667239399 | validation: 0.057022595444407395]
	TIME [epoch: 11.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06489402570771766		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.06489402570771766 | validation: 0.04464812132055273]
	TIME [epoch: 11.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059666873027538224		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.059666873027538224 | validation: 0.04306875855370434]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06452450602910448		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.06452450602910448 | validation: 0.03949527432416641]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0623893825874567		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.0623893825874567 | validation: 0.05308728115112334]
	TIME [epoch: 11.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06320413060068208		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.06320413060068208 | validation: 0.04745583803538835]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07147244870107788		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.07147244870107788 | validation: 0.058666305309154246]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07270151253263527		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.07270151253263527 | validation: 0.04608640772222798]
	TIME [epoch: 11.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06561689545983676		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.06561689545983676 | validation: 0.04680589323295561]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06767509474586134		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.06767509474586134 | validation: 0.052679781801259554]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0608401931685552		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.0608401931685552 | validation: 0.05245756943042484]
	TIME [epoch: 11.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06116139146282945		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.06116139146282945 | validation: 0.0410987460267973]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05964675124566063		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.05964675124566063 | validation: 0.04866076300436606]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06479211315814913		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.06479211315814913 | validation: 0.061614555112331056]
	TIME [epoch: 11.5 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06067787274027119		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.06067787274027119 | validation: 0.04808114794957634]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06454225922328831		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.06454225922328831 | validation: 0.04524378760242108]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06463677836078334		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.06463677836078334 | validation: 0.05387010253162926]
	TIME [epoch: 11.5 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06502104113594548		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.06502104113594548 | validation: 0.058922092881529706]
	TIME [epoch: 11.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06433448799611774		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.06433448799611774 | validation: 0.04809364077657595]
	TIME [epoch: 11.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06715421311973255		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.06715421311973255 | validation: 0.054395317062912646]
	TIME [epoch: 11.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06628973469080987		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.06628973469080987 | validation: 0.04910836308294499]
	TIME [epoch: 11.5 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06437735130765866		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.06437735130765866 | validation: 0.04629294335608159]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06365803365990375		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.06365803365990375 | validation: 0.043743596885333885]
	TIME [epoch: 11.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0629896741675082		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.0629896741675082 | validation: 0.04338991604341068]
	TIME [epoch: 11.5 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060644037544123605		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.060644037544123605 | validation: 0.0401220270951254]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058390220172617344		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.058390220172617344 | validation: 0.047887107726617986]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05498830710276591		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.05498830710276591 | validation: 0.04671310908470231]
	TIME [epoch: 11.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060893331172814036		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.060893331172814036 | validation: 0.042941095591812826]
	TIME [epoch: 11.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056348929197940156		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.056348929197940156 | validation: 0.038167280881635395]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_1272.pth
	Model improved!!!
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06111895293356572		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.06111895293356572 | validation: 0.046870649001071955]
	TIME [epoch: 11.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06124531493146776		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.06124531493146776 | validation: 0.05258615795769435]
	TIME [epoch: 11.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06127022067093155		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.06127022067093155 | validation: 0.04278236302595811]
	TIME [epoch: 11.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06059278612821311		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.06059278612821311 | validation: 0.048583904917053715]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06014313296663448		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.06014313296663448 | validation: 0.04686265024368954]
	TIME [epoch: 11.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07303322191068728		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.07303322191068728 | validation: 0.05991843382170453]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0786014571154267		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.0786014571154267 | validation: 0.06218753847973308]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07867588230579517		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.07867588230579517 | validation: 0.06020082427833388]
	TIME [epoch: 11.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07730961730032582		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.07730961730032582 | validation: 0.06872582708903599]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0711385108644256		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.0711385108644256 | validation: 0.05089772252721955]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06539908367950921		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.06539908367950921 | validation: 0.050698456086766]
	TIME [epoch: 11.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06492872138188258		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.06492872138188258 | validation: 0.04690568838348326]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061806338565866356		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.061806338565866356 | validation: 0.045438412270893506]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059681613416063525		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.059681613416063525 | validation: 0.043492460597741596]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05605632190229564		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.05605632190229564 | validation: 0.044008959578516686]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05657142962280303		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.05657142962280303 | validation: 0.042982586271902344]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058135394642358285		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.058135394642358285 | validation: 0.051507984534715875]
	TIME [epoch: 11.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06300538458122348		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.06300538458122348 | validation: 0.04938986377675546]
	TIME [epoch: 11.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06707768583954078		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.06707768583954078 | validation: 0.05250862294113695]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0673137169683084		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.0673137169683084 | validation: 0.050024763634565636]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06812487420875796		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.06812487420875796 | validation: 0.056535075621199214]
	TIME [epoch: 11.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06579681855085312		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.06579681855085312 | validation: 0.04664403696291835]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06324173162964926		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.06324173162964926 | validation: 0.05762572057839334]
	TIME [epoch: 11.5 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0666591817819781		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.0666591817819781 | validation: 0.05228667757568504]
	TIME [epoch: 11.5 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06556640007238758		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.06556640007238758 | validation: 0.046872214914797684]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05949219784692193		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.05949219784692193 | validation: 0.041071032598251456]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060977113358026164		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.060977113358026164 | validation: 0.03947400384475821]
	TIME [epoch: 11.5 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06202791512472418		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.06202791512472418 | validation: 0.03992334481533828]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06436956804244195		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.06436956804244195 | validation: 0.04332658072500302]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06366089213704718		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.06366089213704718 | validation: 0.049199972498056715]
	TIME [epoch: 11.5 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06228368516663893		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.06228368516663893 | validation: 0.04593982953548556]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06247778698570712		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.06247778698570712 | validation: 0.04696343751170131]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0700878852634199		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.0700878852634199 | validation: 0.04382391865430318]
	TIME [epoch: 11.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07042010763941187		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.07042010763941187 | validation: 0.0493753703445514]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06131653007253633		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.06131653007253633 | validation: 0.04672340263934368]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059981519397082454		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.059981519397082454 | validation: 0.042195159947175584]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06029816558746535		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.06029816558746535 | validation: 0.03866971420414069]
	TIME [epoch: 11.5 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057807040120744904		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.057807040120744904 | validation: 0.03768317186101559]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_1310.pth
	Model improved!!!
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061760256599518226		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.061760256599518226 | validation: 0.04089198258360084]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05706522467678192		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.05706522467678192 | validation: 0.045896051538991234]
	TIME [epoch: 11.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06236745465001821		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.06236745465001821 | validation: 0.04265110994229775]
	TIME [epoch: 11.5 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0577302707702953		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.0577302707702953 | validation: 0.04386755195936137]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053484337435316914		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.053484337435316914 | validation: 0.05304588482119896]
	TIME [epoch: 11.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057727921684178764		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.057727921684178764 | validation: 0.03833403852466028]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05954071787725182		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.05954071787725182 | validation: 0.048320919610180334]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05674939508862297		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.05674939508862297 | validation: 0.045555451420276165]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059809800356433865		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.059809800356433865 | validation: 0.040598958865191784]
	TIME [epoch: 11.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05776346061047519		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.05776346061047519 | validation: 0.04855197080254083]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06344451289991342		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.06344451289991342 | validation: 0.056244331158006554]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06185240336798385		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.06185240336798385 | validation: 0.052917298926216536]
	TIME [epoch: 11.5 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0679670517785481		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.0679670517785481 | validation: 0.051757873132170645]
	TIME [epoch: 11.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06034907478168421		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.06034907478168421 | validation: 0.04402781629352408]
	TIME [epoch: 11.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06018638275463109		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.06018638275463109 | validation: 0.04399437103214588]
	TIME [epoch: 11.5 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060607738509507125		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.060607738509507125 | validation: 0.04654363144494664]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06388076769662054		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.06388076769662054 | validation: 0.039599617386323276]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061689733104244866		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.061689733104244866 | validation: 0.05031553330378891]
	TIME [epoch: 11.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061805038561963066		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.061805038561963066 | validation: 0.04646697791512586]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06514747936448742		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.06514747936448742 | validation: 0.0445686416336348]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06202829951440138		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.06202829951440138 | validation: 0.05083015771545787]
	TIME [epoch: 11.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06592236431425356		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.06592236431425356 | validation: 0.05297548687746615]
	TIME [epoch: 11.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06345391213542853		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.06345391213542853 | validation: 0.05200914789427632]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06703399983918837		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.06703399983918837 | validation: 0.04971205122899198]
	TIME [epoch: 11.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06299359547457617		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.06299359547457617 | validation: 0.04153120340067055]
	TIME [epoch: 11.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06415801349322757		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.06415801349322757 | validation: 0.049248677800114625]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05981880340735371		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.05981880340735371 | validation: 0.04092731658442542]
	TIME [epoch: 11.5 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05734565918261947		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.05734565918261947 | validation: 0.0449044543379587]
	TIME [epoch: 11.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056695951916247045		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.056695951916247045 | validation: 0.049054330201277016]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06426067264542273		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.06426067264542273 | validation: 0.04605283466388329]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05761320069273923		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.05761320069273923 | validation: 0.051648622863871944]
	TIME [epoch: 11.5 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059307222808139735		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.059307222808139735 | validation: 0.04075282532940966]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0582547843840865		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.0582547843840865 | validation: 0.04861655764128768]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058494685134922036		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.058494685134922036 | validation: 0.050701150269121115]
	TIME [epoch: 11.5 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06112081043912545		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.06112081043912545 | validation: 0.03889203421589078]
	TIME [epoch: 11.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0585639179402683		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.0585639179402683 | validation: 0.039403779601766414]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059793068565237716		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.059793068565237716 | validation: 0.04689479688304919]
	TIME [epoch: 11.5 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06221491412043754		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.06221491412043754 | validation: 0.04580021913205895]
	TIME [epoch: 11.5 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057254229191799774		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.057254229191799774 | validation: 0.03326322996780764]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_1349.pth
	Model improved!!!
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05863819455251773		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.05863819455251773 | validation: 0.038655458053640436]
	TIME [epoch: 11.5 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05800693010153008		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.05800693010153008 | validation: 0.04197244248185367]
	TIME [epoch: 11.5 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062382879900436256		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.062382879900436256 | validation: 0.045931436181752314]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05812866004332959		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.05812866004332959 | validation: 0.04276719935377133]
	TIME [epoch: 11.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05622292453256934		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.05622292453256934 | validation: 0.04272619728403715]
	TIME [epoch: 11.5 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05879660464534797		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.05879660464534797 | validation: 0.04410802627722703]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057504200428806905		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.057504200428806905 | validation: 0.050521795282231406]
	TIME [epoch: 11.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05797228111728012		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.05797228111728012 | validation: 0.04091426986413378]
	TIME [epoch: 11.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06277173082047054		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.06277173082047054 | validation: 0.05158685355936189]
	TIME [epoch: 11.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061519641531767165		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.061519641531767165 | validation: 0.04383317925409197]
	TIME [epoch: 11.4 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0597034138749508		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.0597034138749508 | validation: 0.04949524575226603]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06499433519715903		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.06499433519715903 | validation: 0.06339625329913785]
	TIME [epoch: 11.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06746530948383737		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.06746530948383737 | validation: 0.04456027518627869]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06493710657808657		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.06493710657808657 | validation: 0.05282849194649356]
	TIME [epoch: 11.4 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06329213111347418		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.06329213111347418 | validation: 0.0482547333130454]
	TIME [epoch: 11.5 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06190624443535463		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.06190624443535463 | validation: 0.04912257429574999]
	TIME [epoch: 11.4 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06430870384405914		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.06430870384405914 | validation: 0.051775201242309735]
	TIME [epoch: 11.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06038094977149401		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.06038094977149401 | validation: 0.05267855679118595]
	TIME [epoch: 11.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059864314976469456		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.059864314976469456 | validation: 0.043992778798545566]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06275233998833565		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.06275233998833565 | validation: 0.0447955902024154]
	TIME [epoch: 11.4 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05941441024016029		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.05941441024016029 | validation: 0.05032570967027733]
	TIME [epoch: 11.5 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057276024448319855		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.057276024448319855 | validation: 0.04465491056346013]
	TIME [epoch: 11.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06017486215331835		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.06017486215331835 | validation: 0.03969499460589913]
	TIME [epoch: 11.4 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057281599141975906		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.057281599141975906 | validation: 0.04519991373025062]
	TIME [epoch: 11.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057646859288732186		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.057646859288732186 | validation: 0.038085198045352514]
	TIME [epoch: 11.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05860838801431424		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.05860838801431424 | validation: 0.05162988660541345]
	TIME [epoch: 11.4 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06318585070231666		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.06318585070231666 | validation: 0.04836331090687558]
	TIME [epoch: 11.5 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05539630459496151		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.05539630459496151 | validation: 0.04640949113974541]
	TIME [epoch: 11.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06295093079181577		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.06295093079181577 | validation: 0.051572166814090215]
	TIME [epoch: 11.4 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062042558501401134		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.062042558501401134 | validation: 0.05439082415471868]
	TIME [epoch: 11.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0592285392782978		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.0592285392782978 | validation: 0.04242399570006098]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06147222941409759		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.06147222941409759 | validation: 0.046969165375704204]
	TIME [epoch: 11.4 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0589845325097625		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.0589845325097625 | validation: 0.044357697448183256]
	TIME [epoch: 11.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05804872955659913		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.05804872955659913 | validation: 0.05291404220696063]
	TIME [epoch: 11.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061289366159463635		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.061289366159463635 | validation: 0.04907285281565683]
	TIME [epoch: 11.4 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06335966944310514		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.06335966944310514 | validation: 0.05619084733903303]
	TIME [epoch: 11.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06412364661542315		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.06412364661542315 | validation: 0.049341776803776806]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06283352845370795		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.06283352845370795 | validation: 0.04196621575072273]
	TIME [epoch: 11.5 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05837911649162947		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.05837911649162947 | validation: 0.04062616948726353]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05777578409007875		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.05777578409007875 | validation: 0.045788293592544285]
	TIME [epoch: 11.5 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05950438396540685		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.05950438396540685 | validation: 0.04914633054470475]
	TIME [epoch: 11.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057361253118820815		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.057361253118820815 | validation: 0.05026976120797125]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060505483297334045		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.060505483297334045 | validation: 0.04545194609123181]
	TIME [epoch: 11.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06024467575679315		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.06024467575679315 | validation: 0.043557577412115495]
	TIME [epoch: 11.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06332697778811872		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.06332697778811872 | validation: 0.033214587658298135]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_1394.pth
	Model improved!!!
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05715976841217426		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.05715976841217426 | validation: 0.052026615709005526]
	TIME [epoch: 11.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0595416296052213		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.0595416296052213 | validation: 0.0438708030987538]
	TIME [epoch: 11.4 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06303114806827126		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.06303114806827126 | validation: 0.04310515419928028]
	TIME [epoch: 11.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061580767477690805		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.061580767477690805 | validation: 0.042096627320790406]
	TIME [epoch: 11.4 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056391567000251344		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.056391567000251344 | validation: 0.04228041722568676]
	TIME [epoch: 11.4 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05551125379446334		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.05551125379446334 | validation: 0.035657698615928095]
	TIME [epoch: 11.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05646659997168174		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.05646659997168174 | validation: 0.04812831896422771]
	TIME [epoch: 11.4 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057873167383991		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.057873167383991 | validation: 0.03530812497716999]
	TIME [epoch: 11.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05898919898679473		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.05898919898679473 | validation: 0.04930665809200825]
	TIME [epoch: 11.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05723020174164436		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.05723020174164436 | validation: 0.04093585455484337]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06072546303355786		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.06072546303355786 | validation: 0.04760602506268896]
	TIME [epoch: 11.4 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05710947638643137		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.05710947638643137 | validation: 0.04363156562890461]
	TIME [epoch: 11.5 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05729331947540362		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.05729331947540362 | validation: 0.04345517445579631]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05978265241227711		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.05978265241227711 | validation: 0.04083153594237925]
	TIME [epoch: 11.5 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06202244209655375		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.06202244209655375 | validation: 0.03926855263997316]
	TIME [epoch: 11.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0613920486325578		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.0613920486325578 | validation: 0.03401483281309004]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058477773752957804		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.058477773752957804 | validation: 0.043247498140005246]
	TIME [epoch: 11.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06108118987697395		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.06108118987697395 | validation: 0.04935559958794596]
	TIME [epoch: 11.5 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06168154410001365		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.06168154410001365 | validation: 0.04646659997730937]
	TIME [epoch: 11.4 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06275466334612431		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.06275466334612431 | validation: 0.04751563717131104]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0634879833648726		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.0634879833648726 | validation: 0.0343288349291787]
	TIME [epoch: 11.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05985797210207905		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.05985797210207905 | validation: 0.04611309909835926]
	TIME [epoch: 11.4 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062485528651484136		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.062485528651484136 | validation: 0.04124690195642172]
	TIME [epoch: 11.4 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06662870111147647		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.06662870111147647 | validation: 0.04979784673311403]
	TIME [epoch: 11.5 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06484113748236134		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.06484113748236134 | validation: 0.03811941050873778]
	TIME [epoch: 11.4 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06258238216557095		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.06258238216557095 | validation: 0.04635833348033392]
	TIME [epoch: 11.4 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0633969055884211		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.0633969055884211 | validation: 0.04537433122772324]
	TIME [epoch: 11.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06078236715046409		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.06078236715046409 | validation: 0.05073897325054743]
	TIME [epoch: 11.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06089849597610222		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.06089849597610222 | validation: 0.04110880311706516]
	TIME [epoch: 11.4 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05888067728693598		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.05888067728693598 | validation: 0.04184657297850877]
	TIME [epoch: 11.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060393778960656744		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.060393778960656744 | validation: 0.03887085658261476]
	TIME [epoch: 11.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06273733101809448		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.06273733101809448 | validation: 0.048304266870357986]
	TIME [epoch: 11.4 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0587505475007809		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.0587505475007809 | validation: 0.04671977327354115]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06041966284165634		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.06041966284165634 | validation: 0.05169441909900652]
	TIME [epoch: 11.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060026315089575594		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.060026315089575594 | validation: 0.04747613366216033]
	TIME [epoch: 11.4 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058658810504467765		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.058658810504467765 | validation: 0.04026427062886812]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06234190181830393		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.06234190181830393 | validation: 0.04198900404445047]
	TIME [epoch: 11.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060023137130140895		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.060023137130140895 | validation: 0.053806172846357615]
	TIME [epoch: 11.4 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06285260629537269		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.06285260629537269 | validation: 0.04839795558037031]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06229467656493991		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.06229467656493991 | validation: 0.050706888045542485]
	TIME [epoch: 11.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06520102428918143		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.06520102428918143 | validation: 0.046218909434574344]
	TIME [epoch: 11.4 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06303228951924521		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.06303228951924521 | validation: 0.05003101485979288]
	TIME [epoch: 11.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06131032840051216		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.06131032840051216 | validation: 0.04874833711925951]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061138823891384884		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.061138823891384884 | validation: 0.046196375599421025]
	TIME [epoch: 11.4 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059511955142391416		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.059511955142391416 | validation: 0.040679486016824334]
	TIME [epoch: 11.5 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05874320924560546		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.05874320924560546 | validation: 0.05609621569862089]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05866266079452258		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.05866266079452258 | validation: 0.042969558988554694]
	TIME [epoch: 11.4 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05568056064484272		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.05568056064484272 | validation: 0.040986027697785546]
	TIME [epoch: 11.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06277528722009162		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.06277528722009162 | validation: 0.04638194146156107]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062407018600754094		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.062407018600754094 | validation: 0.038872212907283536]
	TIME [epoch: 11.4 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05715953340324755		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.05715953340324755 | validation: 0.04265408052806986]
	TIME [epoch: 11.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060152109239483526		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.060152109239483526 | validation: 0.033953123728592854]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057996460011595335		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.057996460011595335 | validation: 0.043544108772810154]
	TIME [epoch: 11.4 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05896546491186871		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.05896546491186871 | validation: 0.037465961879513635]
	TIME [epoch: 11.5 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05896453583597382		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.05896453583597382 | validation: 0.038557499514163346]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05783913947620674		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.05783913947620674 | validation: 0.0395196184116402]
	TIME [epoch: 11.4 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05985727817216319		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.05985727817216319 | validation: 0.043521683536272296]
	TIME [epoch: 11.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054884002246825506		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.054884002246825506 | validation: 0.04860914723207523]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0578233461160535		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.0578233461160535 | validation: 0.035424351687835205]
	TIME [epoch: 11.4 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05714960567978371		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.05714960567978371 | validation: 0.05436969231264083]
	TIME [epoch: 11.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06255640437397832		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.06255640437397832 | validation: 0.04620510036545965]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05730083463366967		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.05730083463366967 | validation: 0.049436297942664895]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05991060601062674		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.05991060601062674 | validation: 0.053200126029187736]
	TIME [epoch: 11.5 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056241209571100036		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.056241209571100036 | validation: 0.0492891114538611]
	TIME [epoch: 11.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05813896060417585		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.05813896060417585 | validation: 0.031694111477413384]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_1459.pth
	Model improved!!!
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05783811274192875		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.05783811274192875 | validation: 0.04465886706240846]
	TIME [epoch: 11.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0570812603687596		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.0570812603687596 | validation: 0.04458024847729714]
	TIME [epoch: 11.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060135023538807376		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.060135023538807376 | validation: 0.03985087721563141]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05852427038114324		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.05852427038114324 | validation: 0.04796766072892487]
	TIME [epoch: 11.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05596864950908738		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.05596864950908738 | validation: 0.049291011969999764]
	TIME [epoch: 11.4 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0606167514142908		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.0606167514142908 | validation: 0.03891568462199732]
	TIME [epoch: 11.4 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057038565029942395		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.057038565029942395 | validation: 0.04103830907541111]
	TIME [epoch: 11.5 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059849330433805276		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.059849330433805276 | validation: 0.04159921866390406]
	TIME [epoch: 11.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05917756265778809		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.05917756265778809 | validation: 0.0482353166037022]
	TIME [epoch: 11.4 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061492699770459895		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.061492699770459895 | validation: 0.04500700744084583]
	TIME [epoch: 11.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06297841070851552		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.06297841070851552 | validation: 0.045043868709895636]
	TIME [epoch: 11.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05768457858970584		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.05768457858970584 | validation: 0.039376671705839875]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056494134322105635		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.056494134322105635 | validation: 0.044874450343602004]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0606108317353295		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.0606108317353295 | validation: 0.042792431120031775]
	TIME [epoch: 11.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059692342127243496		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.059692342127243496 | validation: 0.047889474867975707]
	TIME [epoch: 11.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05820647038543866		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.05820647038543866 | validation: 0.03778007104458661]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05725527291239871		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.05725527291239871 | validation: 0.04638480434331129]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056441473224955		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.056441473224955 | validation: 0.04768484242976928]
	TIME [epoch: 11.5 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057973558189875055		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.057973558189875055 | validation: 0.052001234106422434]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05505362407564604		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.05505362407564604 | validation: 0.05031185887297149]
	TIME [epoch: 11.4 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05685765457688367		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.05685765457688367 | validation: 0.04438396637624273]
	TIME [epoch: 11.4 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059403418834026056		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.059403418834026056 | validation: 0.04304189557976428]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0558882997339374		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.0558882997339374 | validation: 0.03896761714702245]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06062446613902733		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.06062446613902733 | validation: 0.04585424410717456]
	TIME [epoch: 11.4 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057649363955765684		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.057649363955765684 | validation: 0.04320068335225189]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05856148765266021		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.05856148765266021 | validation: 0.040957710506923796]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057351429015964656		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.057351429015964656 | validation: 0.034040224406586134]
	TIME [epoch: 11.4 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05521597066780748		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.05521597066780748 | validation: 0.0415791096686414]
	TIME [epoch: 11.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05567561136958168		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.05567561136958168 | validation: 0.044969487709596745]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06043085153822517		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.06043085153822517 | validation: 0.041971455770371924]
	TIME [epoch: 11.4 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05537250925161229		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.05537250925161229 | validation: 0.050117342671948555]
	TIME [epoch: 11.5 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06629428754313517		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.06629428754313517 | validation: 0.04766446061135715]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057315245129485964		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.057315245129485964 | validation: 0.042102916253356056]
	TIME [epoch: 11.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056531036182702527		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.056531036182702527 | validation: 0.03558462392142572]
	TIME [epoch: 11.5 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05889249905075783		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.05889249905075783 | validation: 0.050213671961968784]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056301931269884364		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.056301931269884364 | validation: 0.045053518173536936]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0635295834333679		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.0635295834333679 | validation: 0.042676905845574854]
	TIME [epoch: 11.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06004892478132583		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.06004892478132583 | validation: 0.051462362687270655]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060364805093035996		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.060364805093035996 | validation: 0.04287812905650916]
	TIME [epoch: 11.4 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05966898007223075		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.05966898007223075 | validation: 0.03796315920009742]
	TIME [epoch: 11.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05285948677186113		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.05285948677186113 | validation: 0.048660503026030505]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06031240454657491		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.06031240454657491 | validation: 0.051539561712946436]
	TIME [epoch: 11.4 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061344755358040175		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.061344755358040175 | validation: 0.04574790689023209]
	TIME [epoch: 11.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058743786469060276		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.058743786469060276 | validation: 0.04714569809300603]
	TIME [epoch: 11.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05857025833139737		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.05857025833139737 | validation: 0.040083089942495355]
	TIME [epoch: 11.4 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0580620181475775		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.0580620181475775 | validation: 0.04604655551891064]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06211038605262771		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.06211038605262771 | validation: 0.0460173045643363]
	TIME [epoch: 11.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060435896740030984		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.060435896740030984 | validation: 0.04650098700823458]
	TIME [epoch: 11.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05969973273614295		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.05969973273614295 | validation: 0.039045419979920594]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060626673382889004		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.060626673382889004 | validation: 0.049560231789520584]
	TIME [epoch: 11.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058669288478597606		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.058669288478597606 | validation: 0.044972223748858065]
	TIME [epoch: 11.4 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05913216542267048		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.05913216542267048 | validation: 0.04615979176687356]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05551234356377993		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.05551234356377993 | validation: 0.04150931918561875]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056398366610643125		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.056398366610643125 | validation: 0.04280678096265575]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057980912352172		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.057980912352172 | validation: 0.040049122723855975]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05523759950097928		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.05523759950097928 | validation: 0.03677504108522345]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06319023034296317		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.06319023034296317 | validation: 0.05332223286062779]
	TIME [epoch: 11.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058954110903944285		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.058954110903944285 | validation: 0.04246769003902826]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05893277071781999		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.05893277071781999 | validation: 0.04666445727725052]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061003696369758525		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.061003696369758525 | validation: 0.04210235969889106]
	TIME [epoch: 11.4 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06097188590347189		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.06097188590347189 | validation: 0.04308352472883604]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05565693159561793		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.05565693159561793 | validation: 0.04046746279566373]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05789445659001472		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.05789445659001472 | validation: 0.045014166249067955]
	TIME [epoch: 11.4 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05600616503252494		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.05600616503252494 | validation: 0.04293130168784858]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058627385714642946		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.058627385714642946 | validation: 0.043948352303519504]
	TIME [epoch: 11.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057712410830634		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.057712410830634 | validation: 0.040485312079476955]
	TIME [epoch: 11.4 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060001125358154155		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.060001125358154155 | validation: 0.04063421156929788]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05636576484434354		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.05636576484434354 | validation: 0.034211063932518264]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05849036264662069		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.05849036264662069 | validation: 0.046661482678850515]
	TIME [epoch: 11.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062165878523858284		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.062165878523858284 | validation: 0.04269620534651434]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05834663356876203		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.05834663356876203 | validation: 0.044399165294443106]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05920922592926296		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.05920922592926296 | validation: 0.05401982050003648]
	TIME [epoch: 11.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06011529514658074		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.06011529514658074 | validation: 0.04247992206022262]
	TIME [epoch: 11.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06265393221221749		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.06265393221221749 | validation: 0.04111361626379534]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05573277499533038		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.05573277499533038 | validation: 0.04537350869822898]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05743065378691558		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.05743065378691558 | validation: 0.039082537355191044]
	TIME [epoch: 11.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05858223013355568		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.05858223013355568 | validation: 0.056612148743882554]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0644598953733178		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.0644598953733178 | validation: 0.04503453670749293]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06129789201895153		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.06129789201895153 | validation: 0.04516628589965737]
	TIME [epoch: 11.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05616221030496424		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.05616221030496424 | validation: 0.05112557331803526]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05911867657448376		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.05911867657448376 | validation: 0.05142551571652458]
	TIME [epoch: 11.5 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05871566300787283		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.05871566300787283 | validation: 0.04161596723813945]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05768637915395642		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.05768637915395642 | validation: 0.049020724843482175]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05889338215556442		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.05889338215556442 | validation: 0.0448630112356572]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05963268398438244		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.05963268398438244 | validation: 0.052352549241168556]
	TIME [epoch: 11.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05776144406905414		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.05776144406905414 | validation: 0.046745301021137414]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058231765076873894		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.058231765076873894 | validation: 0.03834708948488472]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05887926507723314		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.05887926507723314 | validation: 0.039417258977632125]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05921613538761469		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.05921613538761469 | validation: 0.04573402965291937]
	TIME [epoch: 11.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053624062126954225		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.053624062126954225 | validation: 0.038242192390059215]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05767615227941533		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.05767615227941533 | validation: 0.04493591954750047]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05998896490136859		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.05998896490136859 | validation: 0.04835518278957382]
	TIME [epoch: 11.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05598506705741363		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.05598506705741363 | validation: 0.04891317949145632]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05536680270684208		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.05536680270684208 | validation: 0.04905224013646964]
	TIME [epoch: 11.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05971893107436987		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.05971893107436987 | validation: 0.04482065093582993]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059344436186794795		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.059344436186794795 | validation: 0.04308456651148311]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05707568505132242		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.05707568505132242 | validation: 0.04416762672510341]
	TIME [epoch: 11.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05959464287193718		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.05959464287193718 | validation: 0.04142508378868569]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05756500124754621		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.05756500124754621 | validation: 0.03910496029858486]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05475500595341731		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.05475500595341731 | validation: 0.04531381378186495]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05795844683054937		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.05795844683054937 | validation: 0.040757962626826814]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05693625915829183		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.05693625915829183 | validation: 0.03946118852589763]
	TIME [epoch: 11.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05984528238334737		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.05984528238334737 | validation: 0.04753804757342749]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05441637094342185		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.05441637094342185 | validation: 0.04840847452425872]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056845438698648214		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.056845438698648214 | validation: 0.04763015757651589]
	TIME [epoch: 11.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057415628845801765		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.057415628845801765 | validation: 0.036872887182398235]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05911805041166046		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.05911805041166046 | validation: 0.04133210606386161]
	TIME [epoch: 11.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05652806316732724		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.05652806316732724 | validation: 0.04084572608290463]
	TIME [epoch: 11.4 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058360199577824505		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.058360199577824505 | validation: 0.04190897466350947]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057313719055938406		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.057313719055938406 | validation: 0.041343932822064985]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056564139324537716		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.056564139324537716 | validation: 0.040743377134015886]
	TIME [epoch: 11.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05839252695281179		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.05839252695281179 | validation: 0.03867679486867135]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05601207653524635		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.05601207653524635 | validation: 0.04474788764738266]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05686850891152218		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.05686850891152218 | validation: 0.047208422607113165]
	TIME [epoch: 11.4 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057919873039611595		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.057919873039611595 | validation: 0.0375375115842347]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05400415166503758		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.05400415166503758 | validation: 0.039567360810263436]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05809976582080006		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.05809976582080006 | validation: 0.049237297051631136]
	TIME [epoch: 11.4 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0548875426930657		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.0548875426930657 | validation: 0.04302463082104265]
	TIME [epoch: 11.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0583431071558445		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.0583431071558445 | validation: 0.044932822924115656]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05752859100243822		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.05752859100243822 | validation: 0.04542187757120291]
	TIME [epoch: 11.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0620749879268353		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.0620749879268353 | validation: 0.047965142356783654]
	TIME [epoch: 11.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05897308977362605		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.05897308977362605 | validation: 0.04293092204988134]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057745758598968445		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.057745758598968445 | validation: 0.0393589233657847]
	TIME [epoch: 11.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06020850143609068		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.06020850143609068 | validation: 0.04662409815801315]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06185695010434876		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.06185695010434876 | validation: 0.04064989683608316]
	TIME [epoch: 11.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05828774082849819		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.05828774082849819 | validation: 0.04169803890937211]
	TIME [epoch: 11.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05650001345992274		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.05650001345992274 | validation: 0.044523982850258846]
	TIME [epoch: 11.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059530632314501467		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.059530632314501467 | validation: 0.04322719287986196]
	TIME [epoch: 11.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06484982357249774		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.06484982357249774 | validation: 0.04362335401277836]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06156947901881784		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.06156947901881784 | validation: 0.04393293183953385]
	TIME [epoch: 11.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059750806293304926		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.059750806293304926 | validation: 0.04476860040638298]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057755194983977694		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.057755194983977694 | validation: 0.04779464820372864]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055855213009947606		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.055855213009947606 | validation: 0.04754181755981285]
	TIME [epoch: 11.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0562999501897457		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.0562999501897457 | validation: 0.048381670162207416]
	TIME [epoch: 11.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059422124376562475		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.059422124376562475 | validation: 0.047129517016424226]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05864692953938948		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.05864692953938948 | validation: 0.0379446206873315]
	TIME [epoch: 11.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05846468561831388		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.05846468561831388 | validation: 0.045128399762412716]
	TIME [epoch: 11.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05838889284884709		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.05838889284884709 | validation: 0.040128027815472415]
	TIME [epoch: 11.4 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054080814516135924		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.054080814516135924 | validation: 0.042184232784078644]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060848190738015596		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.060848190738015596 | validation: 0.04840725334263762]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05759491159769564		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.05759491159769564 | validation: 0.04373679579781593]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05629159445672743		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.05629159445672743 | validation: 0.04705378049201821]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05813480343186611		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.05813480343186611 | validation: 0.050793777938925276]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06085672612007037		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.06085672612007037 | validation: 0.037525752043380205]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05889645206163464		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.05889645206163464 | validation: 0.0421482076019968]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05753628857702383		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.05753628857702383 | validation: 0.04431346894571988]
	TIME [epoch: 11.4 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0579237810009806		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.0579237810009806 | validation: 0.03844683173791505]
	TIME [epoch: 11.4 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05820190286529155		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.05820190286529155 | validation: 0.04594059050773759]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059191930839128534		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.059191930839128534 | validation: 0.03705450951369486]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05985617783478085		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.05985617783478085 | validation: 0.04173583858039434]
	TIME [epoch: 11.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06168075697793385		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.06168075697793385 | validation: 0.03316645201977511]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05891263368016138		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.05891263368016138 | validation: 0.04226776788493062]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05987107225278526		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.05987107225278526 | validation: 0.04738870826231395]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056362667181145215		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.056362667181145215 | validation: 0.041609223261426305]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05921809812414325		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.05921809812414325 | validation: 0.03497877517525061]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05862566822516909		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.05862566822516909 | validation: 0.03829977568938446]
	TIME [epoch: 11.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05834309872168532		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.05834309872168532 | validation: 0.043397222302499046]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05948252250781918		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.05948252250781918 | validation: 0.04271026859571553]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05543560314279017		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.05543560314279017 | validation: 0.04091766453880906]
	TIME [epoch: 11.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059613783995639325		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.059613783995639325 | validation: 0.0412945691615138]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056158456737657854		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.056158456737657854 | validation: 0.04456954997031785]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05726225537450694		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.05726225537450694 | validation: 0.0440446009697027]
	TIME [epoch: 11.4 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0571150201070159		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.0571150201070159 | validation: 0.04448980686905182]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05676615786364985		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.05676615786364985 | validation: 0.04647567686211245]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05773117541003463		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.05773117541003463 | validation: 0.05000095041852553]
	TIME [epoch: 11.4 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0590812173962263		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.0590812173962263 | validation: 0.039468701666027874]
	TIME [epoch: 11.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056580061222670466		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.056580061222670466 | validation: 0.04506175767312902]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05358462292473912		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.05358462292473912 | validation: 0.04138348053597115]
	TIME [epoch: 11.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05640643481714866		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.05640643481714866 | validation: 0.04018006649901061]
	TIME [epoch: 11.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05579388175142266		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.05579388175142266 | validation: 0.0403108779061913]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05579897283834895		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.05579897283834895 | validation: 0.0454522405096548]
	TIME [epoch: 11.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06023758746513186		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.06023758746513186 | validation: 0.04087830013245694]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055899209508986566		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.055899209508986566 | validation: 0.044291935124878584]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05770523664007397		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.05770523664007397 | validation: 0.03873597006965098]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05700254059814693		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.05700254059814693 | validation: 0.04597066555702857]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057157272729306804		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.057157272729306804 | validation: 0.040895570555036585]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05620610498414363		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.05620610498414363 | validation: 0.042398709965176]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05780911330284236		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.05780911330284236 | validation: 0.03630670392999629]
	TIME [epoch: 11.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05469594795313301		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.05469594795313301 | validation: 0.03701632246312491]
	TIME [epoch: 11.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05976161104992312		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.05976161104992312 | validation: 0.04188645592560703]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05545038847821995		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.05545038847821995 | validation: 0.04623466426540162]
	TIME [epoch: 11.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05488651281478057		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.05488651281478057 | validation: 0.043344125769682884]
	TIME [epoch: 11.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0593740731258187		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.0593740731258187 | validation: 0.04260176176814961]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055487433248511284		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.055487433248511284 | validation: 0.04252151572969303]
	TIME [epoch: 11.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05580550445081192		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.05580550445081192 | validation: 0.045237178529856086]
	TIME [epoch: 11.4 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054572108679333604		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.054572108679333604 | validation: 0.05048184877618967]
	TIME [epoch: 11.4 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05709380862588275		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.05709380862588275 | validation: 0.033935520441634254]
	TIME [epoch: 11.5 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058153147806149566		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.058153147806149566 | validation: 0.03939435115263145]
	TIME [epoch: 11.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057643195139169406		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.057643195139169406 | validation: 0.045411195132210105]
	TIME [epoch: 11.4 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059364057583585136		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.059364057583585136 | validation: 0.040341882416670194]
	TIME [epoch: 11.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055867547682044175		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.055867547682044175 | validation: 0.04007136519508255]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054537660459909466		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.054537660459909466 | validation: 0.0412308580981154]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05696376255390806		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.05696376255390806 | validation: 0.04287859707649689]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05619898312829405		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.05619898312829405 | validation: 0.03423526886207608]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05681468767859419		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.05681468767859419 | validation: 0.048702898060095166]
	TIME [epoch: 11.4 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056860732224242025		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.056860732224242025 | validation: 0.04878711096083371]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05648084315298765		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.05648084315298765 | validation: 0.046735663337310066]
	TIME [epoch: 11.4 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05524107368586604		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.05524107368586604 | validation: 0.043895332354634505]
	TIME [epoch: 11.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060029704744785146		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.060029704744785146 | validation: 0.044560538847283775]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05647664783091651		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.05647664783091651 | validation: 0.04219850249326843]
	TIME [epoch: 11.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05547643339480808		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.05547643339480808 | validation: 0.04036905414817489]
	TIME [epoch: 11.4 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05873359398952149		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.05873359398952149 | validation: 0.04582804434559237]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05447259590045212		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.05447259590045212 | validation: 0.03347712348407324]
	TIME [epoch: 11.4 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057570581839498765		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.057570581839498765 | validation: 0.036849389518339486]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05174389388713442		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.05174389388713442 | validation: 0.035455272039755494]
	TIME [epoch: 11.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05635603476177695		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.05635603476177695 | validation: 0.048307822052449614]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05670044448555474		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.05670044448555474 | validation: 0.03915421470756834]
	TIME [epoch: 11.4 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058229245258167445		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.058229245258167445 | validation: 0.039551999946677324]
	TIME [epoch: 11.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0591264862418337		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.0591264862418337 | validation: 0.0498208956765952]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053541970308124076		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.053541970308124076 | validation: 0.03923187449593963]
	TIME [epoch: 11.4 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05966475343978822		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.05966475343978822 | validation: 0.03906751580469557]
	TIME [epoch: 11.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055608557354308266		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.055608557354308266 | validation: 0.03459685788391237]
	TIME [epoch: 11.4 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058202640928591814		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.058202640928591814 | validation: 0.054649014761748306]
	TIME [epoch: 11.4 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05730831818427089		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.05730831818427089 | validation: 0.04560924432237608]
	TIME [epoch: 11.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05445198073508709		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.05445198073508709 | validation: 0.032621826407932965]
	TIME [epoch: 11.4 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053483031158364405		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.053483031158364405 | validation: 0.04646927594665099]
	TIME [epoch: 11.4 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05643581618778801		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.05643581618778801 | validation: 0.04098595449716332]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05478928650201494		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.05478928650201494 | validation: 0.04391750082585995]
	TIME [epoch: 11.4 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05921817145482793		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.05921817145482793 | validation: 0.04428574384669942]
	TIME [epoch: 11.4 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05417715413378348		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.05417715413378348 | validation: 0.040713495935382246]
	TIME [epoch: 11.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05808577087997853		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.05808577087997853 | validation: 0.042913537790890854]
	TIME [epoch: 11.4 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05293960779566528		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.05293960779566528 | validation: 0.0403103474697195]
	TIME [epoch: 11.4 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05451908440789318		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.05451908440789318 | validation: 0.04651246252402109]
	TIME [epoch: 11.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0565648416197193		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.0565648416197193 | validation: 0.04670133452757589]
	TIME [epoch: 11.4 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05388156340100449		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.05388156340100449 | validation: 0.045386791845842406]
	TIME [epoch: 11.4 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05675846657458788		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.05675846657458788 | validation: 0.0398180609346606]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05696450436397854		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.05696450436397854 | validation: 0.044538072654416005]
	TIME [epoch: 11.4 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059801857640706974		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.059801857640706974 | validation: 0.042978824496406144]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057215874303975275		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.057215874303975275 | validation: 0.043980285831361314]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0574871587923004		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.0574871587923004 | validation: 0.043426763701263964]
	TIME [epoch: 11.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05341648989994183		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.05341648989994183 | validation: 0.04752632525783621]
	TIME [epoch: 11.4 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054084581318375444		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.054084581318375444 | validation: 0.039946667432049596]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055531447218257965		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.055531447218257965 | validation: 0.04712159524789697]
	TIME [epoch: 11.4 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05569038428798253		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.05569038428798253 | validation: 0.05149012767254865]
	TIME [epoch: 11.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05784604097565524		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.05784604097565524 | validation: 0.04516113960330804]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060220773584675924		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.060220773584675924 | validation: 0.04708492985638122]
	TIME [epoch: 11.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05586125416125822		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.05586125416125822 | validation: 0.037333897072333484]
	TIME [epoch: 11.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05532802326565041		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.05532802326565041 | validation: 0.04134510788803904]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05691440944969467		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.05691440944969467 | validation: 0.03625226963512756]
	TIME [epoch: 11.4 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05554599200978854		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.05554599200978854 | validation: 0.04559585567181651]
	TIME [epoch: 11.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054904685606908823		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.054904685606908823 | validation: 0.03685930017201365]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0551375032175086		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.0551375032175086 | validation: 0.03112235150712601]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_1701.pth
	Model improved!!!
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0525610829198041		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.0525610829198041 | validation: 0.04433360189775982]
	TIME [epoch: 11.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055571958772547406		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.055571958772547406 | validation: 0.04633406606652415]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052987006195744715		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.052987006195744715 | validation: 0.03860536087124581]
	TIME [epoch: 11.4 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057035346244167534		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.057035346244167534 | validation: 0.04426326979796448]
	TIME [epoch: 11.4 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06060212958195821		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.06060212958195821 | validation: 0.04597724069659415]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056180296440542336		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.056180296440542336 | validation: 0.04243395919122056]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05558044561310852		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.05558044561310852 | validation: 0.043506522669408555]
	TIME [epoch: 11.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05787408677306388		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.05787408677306388 | validation: 0.03594245666374076]
	TIME [epoch: 11.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05676512075921699		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.05676512075921699 | validation: 0.04165983391080326]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05641970584120647		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.05641970584120647 | validation: 0.038587776542680106]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055128508432818135		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.055128508432818135 | validation: 0.04621196446145622]
	TIME [epoch: 11.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054123099427512075		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.054123099427512075 | validation: 0.04145942977501612]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051686551954619506		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.051686551954619506 | validation: 0.027840171373457484]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240310_003033/states/model_tr_study4_1714.pth
	Model improved!!!
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054279966636396296		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.054279966636396296 | validation: 0.04258519131547384]
	TIME [epoch: 11.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05448001852942405		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.05448001852942405 | validation: 0.044618335364247294]
	TIME [epoch: 11.4 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05605501547010863		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.05605501547010863 | validation: 0.04486212301784004]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057108133820455556		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.057108133820455556 | validation: 0.04077465304811693]
	TIME [epoch: 11.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05700188217336199		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.05700188217336199 | validation: 0.0416345977945944]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053953220220027485		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.053953220220027485 | validation: 0.0450341486032592]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053754571005822954		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.053754571005822954 | validation: 0.04479661391017961]
	TIME [epoch: 11.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05581122492654747		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.05581122492654747 | validation: 0.044334011142212186]
	TIME [epoch: 11.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05311716658137283		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.05311716658137283 | validation: 0.043456071362648604]
	TIME [epoch: 11.4 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05948200517870228		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.05948200517870228 | validation: 0.03534846303426999]
	TIME [epoch: 11.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057845945210640265		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.057845945210640265 | validation: 0.04475423735193103]
	TIME [epoch: 11.4 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05476167639517293		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.05476167639517293 | validation: 0.04036933089874044]
	TIME [epoch: 11.4 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05543345028716284		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.05543345028716284 | validation: 0.03359503139504025]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05773212978994015		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.05773212978994015 | validation: 0.048118424856658175]
	TIME [epoch: 11.4 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057752533020054425		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.057752533020054425 | validation: 0.04492361337553668]
	TIME [epoch: 11.4 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05456925525923706		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.05456925525923706 | validation: 0.03629382936848626]
	TIME [epoch: 11.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0568870377231641		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.0568870377231641 | validation: 0.028510803903853837]
	TIME [epoch: 11.4 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054260379870001436		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.054260379870001436 | validation: 0.0422745639085016]
	TIME [epoch: 11.4 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05621264421948681		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.05621264421948681 | validation: 0.0429543008158752]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056315387839248394		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.056315387839248394 | validation: 0.03794220684102056]
	TIME [epoch: 11.4 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0563857058526495		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.0563857058526495 | validation: 0.042813151278686984]
	TIME [epoch: 11.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0572027333458233		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.0572027333458233 | validation: 0.04148669781089117]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05707050865284442		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.05707050865284442 | validation: 0.04379001785954161]
	TIME [epoch: 11.4 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05938395590610366		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.05938395590610366 | validation: 0.04036825750861563]
	TIME [epoch: 11.5 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05531888877520688		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.05531888877520688 | validation: 0.050957136869493456]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0555547824410271		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.0555547824410271 | validation: 0.04455195271946535]
	TIME [epoch: 11.4 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05336463796189396		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.05336463796189396 | validation: 0.04240537410871129]
	TIME [epoch: 11.5 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05798163300093523		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.05798163300093523 | validation: 0.04040772455943923]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05557064972419401		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.05557064972419401 | validation: 0.04427111868326808]
	TIME [epoch: 11.4 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05533321119107744		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.05533321119107744 | validation: 0.04231355396934743]
	TIME [epoch: 11.4 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05806157918581699		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.05806157918581699 | validation: 0.0366008548427312]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060150998798996706		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.060150998798996706 | validation: 0.04119662372148378]
	TIME [epoch: 11.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05593487032179737		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.05593487032179737 | validation: 0.042980698497859376]
	TIME [epoch: 11.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05946724474696678		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.05946724474696678 | validation: 0.042229476335883157]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058748887967862054		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.058748887967862054 | validation: 0.054340022892143784]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05164252428593184		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.05164252428593184 | validation: 0.039889438109918726]
	TIME [epoch: 11.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05477496512016762		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.05477496512016762 | validation: 0.050632435463727234]
	TIME [epoch: 11.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05333108447571376		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.05333108447571376 | validation: 0.04302114426720816]
	TIME [epoch: 11.4 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05629023563077609		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.05629023563077609 | validation: 0.038629308281758104]
	TIME [epoch: 11.4 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05987045386390587		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.05987045386390587 | validation: 0.05072177677187206]
	TIME [epoch: 11.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05804441076520706		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.05804441076520706 | validation: 0.04342886773103186]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05524573156787371		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.05524573156787371 | validation: 0.046212095324425655]
	TIME [epoch: 11.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0564783526451399		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.0564783526451399 | validation: 0.04496447571117058]
	TIME [epoch: 11.5 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05887502619556857		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.05887502619556857 | validation: 0.04468480757345436]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05532878473515371		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.05532878473515371 | validation: 0.047210239307479515]
	TIME [epoch: 11.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053759895137896536		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.053759895137896536 | validation: 0.0522992727913155]
	TIME [epoch: 11.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05523283831686886		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.05523283831686886 | validation: 0.0450502569630926]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053109807116019384		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.053109807116019384 | validation: 0.036534921900892615]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05791464677873877		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.05791464677873877 | validation: 0.039959490491090856]
	TIME [epoch: 11.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05772758402211507		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.05772758402211507 | validation: 0.04123533194614649]
	TIME [epoch: 11.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05724628032383915		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.05724628032383915 | validation: 0.03776276735593362]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054342789892088114		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.054342789892088114 | validation: 0.044412759170664014]
	TIME [epoch: 11.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054683070473069695		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.054683070473069695 | validation: 0.04927167353552054]
	TIME [epoch: 11.5 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055126285808195584		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.055126285808195584 | validation: 0.04470350182351176]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05678008382149418		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.05678008382149418 | validation: 0.043470752374311694]
	TIME [epoch: 11.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05858263987114454		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.05858263987114454 | validation: 0.04509946157969173]
	TIME [epoch: 11.5 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05337785709774914		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.05337785709774914 | validation: 0.04598235606830489]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06072093514260091		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.06072093514260091 | validation: 0.03823515475068121]
	TIME [epoch: 11.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053935416093010724		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.053935416093010724 | validation: 0.03840802121106951]
	TIME [epoch: 11.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05908876013561057		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.05908876013561057 | validation: 0.03679728036294458]
	TIME [epoch: 11.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056303183521094945		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.056303183521094945 | validation: 0.040457803556537345]
	TIME [epoch: 11.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05676043537404675		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.05676043537404675 | validation: 0.040056568013389686]
	TIME [epoch: 11.5 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05416005927526451		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.05416005927526451 | validation: 0.03664523539459185]
	TIME [epoch: 11.4 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05153744038790502		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.05153744038790502 | validation: 0.047520447079833605]
	TIME [epoch: 11.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05431296847734565		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.05431296847734565 | validation: 0.03935531196010904]
	TIME [epoch: 11.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05512813822223134		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.05512813822223134 | validation: 0.03617042122432199]
	TIME [epoch: 11.4 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05716357865564282		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.05716357865564282 | validation: 0.03388501508789764]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05972061867103243		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.05972061867103243 | validation: 0.038822726026844806]
	TIME [epoch: 11.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05422160103193921		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.05422160103193921 | validation: 0.04390915253682766]
	TIME [epoch: 11.5 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05695302180031997		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.05695302180031997 | validation: 0.04177606840810258]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054930913436267326		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.054930913436267326 | validation: 0.036970711635364854]
	TIME [epoch: 11.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056318342433529664		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.056318342433529664 | validation: 0.03970511019356749]
	TIME [epoch: 11.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05548346639724977		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.05548346639724977 | validation: 0.03956772670307366]
	TIME [epoch: 11.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053901919929031705		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.053901919929031705 | validation: 0.041725951336823545]
	TIME [epoch: 11.4 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05411831545390727		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.05411831545390727 | validation: 0.049369887906729824]
	TIME [epoch: 11.4 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052603161830049434		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.052603161830049434 | validation: 0.04297588682029024]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0574291606640145		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.0574291606640145 | validation: 0.03532068929475742]
	TIME [epoch: 11.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055596636490337026		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.055596636490337026 | validation: 0.03835139271873647]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054134724812981164		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.054134724812981164 | validation: 0.04060930686223958]
	TIME [epoch: 11.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05743942550414731		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.05743942550414731 | validation: 0.045248452393335005]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0554331788286195		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.0554331788286195 | validation: 0.03805097041448104]
	TIME [epoch: 11.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05786653141935832		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.05786653141935832 | validation: 0.038237225412668885]
	TIME [epoch: 11.5 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05095217767935499		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.05095217767935499 | validation: 0.04209064820210779]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05491411887569918		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.05491411887569918 | validation: 0.04566098469298319]
	TIME [epoch: 11.4 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056879534594167676		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.056879534594167676 | validation: 0.04082359724198688]
	TIME [epoch: 11.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05346579233231004		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.05346579233231004 | validation: 0.0381420694782423]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056467095696371164		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.056467095696371164 | validation: 0.02999196271542248]
	TIME [epoch: 11.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05326940622287729		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.05326940622287729 | validation: 0.04290504713960074]
	TIME [epoch: 11.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05335418000481387		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.05335418000481387 | validation: 0.035509022401753805]
	TIME [epoch: 11.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059857700749584845		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.059857700749584845 | validation: 0.043876726580564254]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05453023878579275		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.05453023878579275 | validation: 0.041249677549602994]
	TIME [epoch: 11.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054485494508553806		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.054485494508553806 | validation: 0.04374085797427828]
	TIME [epoch: 11.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05345486516882364		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.05345486516882364 | validation: 0.04402715928820339]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05627606813728792		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.05627606813728792 | validation: 0.03843597169966461]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055553312994762266		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.055553312994762266 | validation: 0.0423351752562977]
	TIME [epoch: 11.5 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05558172243264366		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.05558172243264366 | validation: 0.03990365106608843]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055902442073477304		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.055902442073477304 | validation: 0.03670666425887605]
	TIME [epoch: 11.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057934258635653144		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.057934258635653144 | validation: 0.038699833570747036]
	TIME [epoch: 11.5 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05717198934839085		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.05717198934839085 | validation: 0.03007920414166375]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05919069308335314		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.05919069308335314 | validation: 0.04549547041275174]
	TIME [epoch: 11.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05844142532001893		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.05844142532001893 | validation: 0.03936180492809592]
	TIME [epoch: 11.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05796919855052678		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.05796919855052678 | validation: 0.036204944785886484]
	TIME [epoch: 11.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05418771517839285		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.05418771517839285 | validation: 0.03698394954705481]
	TIME [epoch: 11.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05318643625874964		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.05318643625874964 | validation: 0.04005287751562462]
	TIME [epoch: 11.5 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05677817859485146		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.05677817859485146 | validation: 0.04261952502494411]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05853182547629946		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.05853182547629946 | validation: 0.04316117699611434]
	TIME [epoch: 11.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057852321231517484		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.057852321231517484 | validation: 0.03993879794676362]
	TIME [epoch: 11.4 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059233067968624445		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.059233067968624445 | validation: 0.032046073419358015]
	TIME [epoch: 11.4 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055706881435404136		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.055706881435404136 | validation: 0.04066658833134456]
	TIME [epoch: 11.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05770196455049243		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.05770196455049243 | validation: 0.04914021498054019]
	TIME [epoch: 11.4 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05406099639888486		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.05406099639888486 | validation: 0.03919279015397039]
	TIME [epoch: 11.5 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057245085218185804		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.057245085218185804 | validation: 0.04011075552828306]
	TIME [epoch: 11.5 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05655220083724477		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.05655220083724477 | validation: 0.04444365493496125]
	TIME [epoch: 11.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05726700512632266		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.05726700512632266 | validation: 0.039821971602633885]
	TIME [epoch: 11.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057481594412660465		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.057481594412660465 | validation: 0.04480406575392073]
	TIME [epoch: 11.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05670810980742954		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.05670810980742954 | validation: 0.040557060816417315]
	TIME [epoch: 11.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056468998853143715		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.056468998853143715 | validation: 0.03760988625823097]
	TIME [epoch: 11.4 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05298628486836483		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.05298628486836483 | validation: 0.038082570088798916]
	TIME [epoch: 11.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05330075870595622		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.05330075870595622 | validation: 0.045585867324686384]
	TIME [epoch: 11.4 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05765538810106527		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.05765538810106527 | validation: 0.04499667263279374]
	TIME [epoch: 11.4 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05776743808881096		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.05776743808881096 | validation: 0.03826320842701338]
	TIME [epoch: 11.5 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055721303287288346		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.055721303287288346 | validation: 0.04146964631206009]
	TIME [epoch: 11.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05312206925162345		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.05312206925162345 | validation: 0.043540874239512355]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056523755478454486		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.056523755478454486 | validation: 0.04358569178020641]
	TIME [epoch: 11.5 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055981342981749886		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.055981342981749886 | validation: 0.038275535309497406]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056701975482132135		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.056701975482132135 | validation: 0.04676563651004505]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052101876454738086		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.052101876454738086 | validation: 0.042717459996726284]
	TIME [epoch: 11.5 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05732852873700948		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.05732852873700948 | validation: 0.04018926750362976]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05698832946792899		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.05698832946792899 | validation: 0.04108671680304803]
	TIME [epoch: 11.4 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057381591011839955		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.057381591011839955 | validation: 0.0400736931485744]
	TIME [epoch: 11.5 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05382798011186614		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.05382798011186614 | validation: 0.04214252254215329]
	TIME [epoch: 11.4 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05691886656625607		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.05691886656625607 | validation: 0.037996809369905876]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05195843685584094		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.05195843685584094 | validation: 0.039735327814796426]
	TIME [epoch: 11.5 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05540866938950223		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.05540866938950223 | validation: 0.042313008692672814]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05508052256964324		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.05508052256964324 | validation: 0.05201414003063487]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052449535066060676		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.052449535066060676 | validation: 0.03954249138598605]
	TIME [epoch: 11.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055680357872545744		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.055680357872545744 | validation: 0.0456955071814779]
	TIME [epoch: 11.4 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05511331077447989		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.05511331077447989 | validation: 0.039286483043859115]
	TIME [epoch: 11.4 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05491185430864641		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.05491185430864641 | validation: 0.041935675535080714]
	TIME [epoch: 11.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05735196304193495		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.05735196304193495 | validation: 0.03855614844141329]
	TIME [epoch: 11.4 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05447013989297244		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.05447013989297244 | validation: 0.044091740155917096]
	TIME [epoch: 11.4 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05372339404058451		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.05372339404058451 | validation: 0.03890987167383956]
	TIME [epoch: 11.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05525819249434163		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.05525819249434163 | validation: 0.050621511222083915]
	TIME [epoch: 11.5 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0570196159051361		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.0570196159051361 | validation: 0.043831417491420686]
	TIME [epoch: 11.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05326263863037295		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.05326263863037295 | validation: 0.04601965350527929]
	TIME [epoch: 11.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05677568597697578		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.05677568597697578 | validation: 0.04840686969837342]
	TIME [epoch: 11.5 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05325884813577643		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.05325884813577643 | validation: 0.04202084502190579]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0556027040573518		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.0556027040573518 | validation: 0.04237425852098554]
	TIME [epoch: 11.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05564933804557751		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.05564933804557751 | validation: 0.039567534574608446]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05632676032219069		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.05632676032219069 | validation: 0.043007523466906686]
	TIME [epoch: 11.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057825724017074816		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.057825724017074816 | validation: 0.04596660914168155]
	TIME [epoch: 11.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05456092472350433		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.05456092472350433 | validation: 0.03427267158433312]
	TIME [epoch: 11.4 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05468658760028764		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.05468658760028764 | validation: 0.043418175633776916]
	TIME [epoch: 11.4 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05405474505182461		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.05405474505182461 | validation: 0.04405553005687301]
	TIME [epoch: 11.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059134244786404444		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.059134244786404444 | validation: 0.042955261430240005]
	TIME [epoch: 11.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054425605166561385		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.054425605166561385 | validation: 0.03569993482663113]
	TIME [epoch: 11.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059373148746904116		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.059373148746904116 | validation: 0.05140726377729042]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055668075810345184		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.055668075810345184 | validation: 0.043138385593597624]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053386160108276515		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.053386160108276515 | validation: 0.04186584843845575]
	TIME [epoch: 11.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05662445241315779		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.05662445241315779 | validation: 0.047046707027564916]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05796988622516693		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.05796988622516693 | validation: 0.04077117730632049]
	TIME [epoch: 11.4 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05671936918528182		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.05671936918528182 | validation: 0.032874862743328646]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05900310405543177		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.05900310405543177 | validation: 0.039488646432913575]
	TIME [epoch: 11.5 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05635532093195782		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.05635532093195782 | validation: 0.04567177340513047]
	TIME [epoch: 11.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054482596993907506		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.054482596993907506 | validation: 0.04905046929029227]
	TIME [epoch: 11.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058735189629714565		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.058735189629714565 | validation: 0.041760289136689284]
	TIME [epoch: 11.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05463165969213481		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.05463165969213481 | validation: 0.04112095939006366]
	TIME [epoch: 11.4 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05534825747272309		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.05534825747272309 | validation: 0.0364143341156333]
	TIME [epoch: 11.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05830237110079314		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.05830237110079314 | validation: 0.04081760906507345]
	TIME [epoch: 11.5 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05576968440604031		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.05576968440604031 | validation: 0.042235604009013085]
	TIME [epoch: 11.4 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05429466331549642		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.05429466331549642 | validation: 0.04436127431266172]
	TIME [epoch: 11.4 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056438265421905054		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.056438265421905054 | validation: 0.05179122492591537]
	TIME [epoch: 11.5 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05579144727465218		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.05579144727465218 | validation: 0.035571778359093614]
	TIME [epoch: 11.5 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05254525996404517		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.05254525996404517 | validation: 0.037930379190576534]
	TIME [epoch: 11.5 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05470289141184985		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.05470289141184985 | validation: 0.039703408127777826]
	TIME [epoch: 11.5 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05494717639587519		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.05494717639587519 | validation: 0.04601122776352405]
	TIME [epoch: 11.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057304499151043777		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.057304499151043777 | validation: 0.04056340517180396]
	TIME [epoch: 11.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05579299418378846		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.05579299418378846 | validation: 0.038033827655574504]
	TIME [epoch: 11.5 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05510693124851992		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.05510693124851992 | validation: 0.046965815437398244]
	TIME [epoch: 11.5 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05303212895857368		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.05303212895857368 | validation: 0.03882997584218062]
	TIME [epoch: 11.5 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05441457938145909		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.05441457938145909 | validation: 0.04362498677018823]
	TIME [epoch: 11.5 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055564358045396806		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.055564358045396806 | validation: 0.041737789318986085]
	TIME [epoch: 11.5 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05657426041329816		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.05657426041329816 | validation: 0.04669986084404832]
	TIME [epoch: 11.4 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0571892417497219		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.0571892417497219 | validation: 0.04263949565349433]
	TIME [epoch: 11.5 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05661994949905241		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.05661994949905241 | validation: 0.0521697247202828]
	TIME [epoch: 11.5 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05159453762432911		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.05159453762432911 | validation: 0.039221206375484166]
	TIME [epoch: 11.5 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054363730194710316		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.054363730194710316 | validation: 0.044884832927883526]
	TIME [epoch: 11.5 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05689308337244965		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.05689308337244965 | validation: 0.04333580750944698]
	TIME [epoch: 11.5 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05836847801998014		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.05836847801998014 | validation: 0.034726050920421477]
	TIME [epoch: 11.4 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056412787304887586		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.056412787304887586 | validation: 0.04669446617085688]
	TIME [epoch: 11.5 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0562099482747995		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.0562099482747995 | validation: 0.04092838686800141]
	TIME [epoch: 11.5 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060331426686953814		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.060331426686953814 | validation: 0.041313967017950856]
	TIME [epoch: 11.4 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0599036348583211		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.0599036348583211 | validation: 0.0454407512362995]
	TIME [epoch: 11.5 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05884596625461339		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.05884596625461339 | validation: 0.03365162890325983]
	TIME [epoch: 11.5 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05641268987383791		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.05641268987383791 | validation: 0.050442125558268595]
	TIME [epoch: 11.5 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05938600687603759		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.05938600687603759 | validation: 0.04812803912665027]
	TIME [epoch: 11.5 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057085863704030126		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.057085863704030126 | validation: 0.0360544119583098]
	TIME [epoch: 11.4 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06106733555075146		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.06106733555075146 | validation: 0.04678686234911743]
	TIME [epoch: 11.5 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0578684864339961		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.0578684864339961 | validation: 0.04953515772471476]
	TIME [epoch: 11.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05379362664701277		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.05379362664701277 | validation: 0.0461934980379678]
	TIME [epoch: 11.5 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05493307230246634		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.05493307230246634 | validation: 0.04469931835282181]
	TIME [epoch: 11.5 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0557307039704108		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.0557307039704108 | validation: 0.0474620686832821]
	TIME [epoch: 11.5 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05947820911363695		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.05947820911363695 | validation: 0.03900334204801989]
	TIME [epoch: 11.5 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0544977016029425		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.0544977016029425 | validation: 0.03776078897164482]
	TIME [epoch: 11.5 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05423558859381028		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.05423558859381028 | validation: 0.0467486518197491]
	TIME [epoch: 11.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054445543564584135		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.054445543564584135 | validation: 0.03555312013828939]
	TIME [epoch: 11.5 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05672597094142318		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.05672597094142318 | validation: 0.04488019936103298]
	TIME [epoch: 11.5 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05759239904772971		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.05759239904772971 | validation: 0.0332428933829772]
	TIME [epoch: 11.5 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05533824525317445		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.05533824525317445 | validation: 0.03766675789488522]
	TIME [epoch: 11.4 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05567037418034655		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.05567037418034655 | validation: 0.04414904568522199]
	TIME [epoch: 11.4 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05343469975298524		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.05343469975298524 | validation: 0.04316749558438989]
	TIME [epoch: 11.5 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05612872625819491		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.05612872625819491 | validation: 0.03866459721410901]
	TIME [epoch: 11.5 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05497782607410976		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.05497782607410976 | validation: 0.042330119512183434]
	TIME [epoch: 11.4 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05631167182689483		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.05631167182689483 | validation: 0.04437446309398852]
	TIME [epoch: 11.5 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0559995773592108		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.0559995773592108 | validation: 0.03742640139346584]
	TIME [epoch: 11.4 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05629385381767371		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.05629385381767371 | validation: 0.03898010359334148]
	TIME [epoch: 11.5 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055021570795886855		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.055021570795886855 | validation: 0.03996999419251661]
	TIME [epoch: 11.5 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05869369123032418		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.05869369123032418 | validation: 0.04250405081741509]
	TIME [epoch: 11.5 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06017088101663578		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.06017088101663578 | validation: 0.032445169054430116]
	TIME [epoch: 11.4 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05508467446833241		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.05508467446833241 | validation: 0.044570420071289495]
	TIME [epoch: 11.5 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058622841764512545		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.058622841764512545 | validation: 0.037476567793760095]
	TIME [epoch: 11.4 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053728211411170665		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.053728211411170665 | validation: 0.04586273873787009]
	TIME [epoch: 11.5 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05510114575737868		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.05510114575737868 | validation: 0.03562403822371613]
	TIME [epoch: 11.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05321180390240893		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.05321180390240893 | validation: 0.04762104350376282]
	TIME [epoch: 11.5 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05981661591696712		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.05981661591696712 | validation: 0.034575326729242385]
	TIME [epoch: 11.4 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054067266637247154		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.054067266637247154 | validation: 0.03959174390532886]
	TIME [epoch: 11.5 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05242669141623051		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.05242669141623051 | validation: 0.039619688098422395]
	TIME [epoch: 11.5 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049317714040754794		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.049317714040754794 | validation: 0.0392630584540202]
	TIME [epoch: 11.5 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05559369530975973		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.05559369530975973 | validation: 0.03883696392807019]
	TIME [epoch: 11.5 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05713685214168716		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.05713685214168716 | validation: 0.04692261519311062]
	TIME [epoch: 11.5 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0567733371066641		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.0567733371066641 | validation: 0.04351585404351768]
	TIME [epoch: 11.5 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05585400021843648		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.05585400021843648 | validation: 0.041373207825922784]
	TIME [epoch: 11.5 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050867513799864136		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.050867513799864136 | validation: 0.04381922581526102]
	TIME [epoch: 11.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05463041290089734		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.05463041290089734 | validation: 0.041401033653431354]
	TIME [epoch: 11.5 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056934831672430845		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.056934831672430845 | validation: 0.03896963436384067]
	TIME [epoch: 11.5 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053144531401495526		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.053144531401495526 | validation: 0.0476987858835873]
	TIME [epoch: 11.5 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05356267581691054		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.05356267581691054 | validation: 0.03785566641994069]
	TIME [epoch: 11.4 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05566386618529473		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.05566386618529473 | validation: 0.04450987815615931]
	TIME [epoch: 11.5 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05621003909068476		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.05621003909068476 | validation: 0.03607842471102645]
	TIME [epoch: 11.4 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05785832057375708		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.05785832057375708 | validation: 0.03740934197568972]
	TIME [epoch: 11.4 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05510896434616042		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.05510896434616042 | validation: 0.0435800255773021]
	TIME [epoch: 11.5 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05476090007732258		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.05476090007732258 | validation: 0.044367758897992673]
	TIME [epoch: 11.5 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05427462131115811		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.05427462131115811 | validation: 0.03781002953370644]
	TIME [epoch: 11.5 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05613182588596001		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.05613182588596001 | validation: 0.03761699535422356]
	TIME [epoch: 11.5 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05141858552799322		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.05141858552799322 | validation: 0.03726391018221135]
	TIME [epoch: 11.5 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05515513058653633		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.05515513058653633 | validation: 0.038440737318747156]
	TIME [epoch: 11.5 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05529909985313412		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.05529909985313412 | validation: 0.04096021741878084]
	TIME [epoch: 11.5 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055194556200331986		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.055194556200331986 | validation: 0.041846401108793715]
	TIME [epoch: 11.5 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056335828794820325		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.056335828794820325 | validation: 0.04877563554013817]
	TIME [epoch: 11.5 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05119693754758551		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.05119693754758551 | validation: 0.03918334165869597]
	TIME [epoch: 11.5 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055063015867899995		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.055063015867899995 | validation: 0.03487798721281295]
	TIME [epoch: 11.5 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05225800023436123		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.05225800023436123 | validation: 0.03812349352331512]
	TIME [epoch: 11.4 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056055420203264594		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.056055420203264594 | validation: 0.04089802447094905]
	TIME [epoch: 11.5 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055452474919769845		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.055452474919769845 | validation: 0.0294828156193868]
	TIME [epoch: 11.5 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05990054657884605		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.05990054657884605 | validation: 0.04201149020581882]
	TIME [epoch: 11.5 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057032019725422864		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.057032019725422864 | validation: 0.036678303105518555]
	TIME [epoch: 11.5 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055176595787499		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.055176595787499 | validation: 0.04558658656976098]
	TIME [epoch: 11.5 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05654052379065933		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.05654052379065933 | validation: 0.04546422340909764]
	TIME [epoch: 11.5 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059373407476208714		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.059373407476208714 | validation: 0.04215511538045215]
	TIME [epoch: 11.5 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05364431640234762		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.05364431640234762 | validation: 0.03585920930194308]
	TIME [epoch: 11.5 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05592379943615412		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.05592379943615412 | validation: 0.04149199954592264]
	TIME [epoch: 11.4 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057969808941926514		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.057969808941926514 | validation: 0.03997940596885099]
	TIME [epoch: 11.5 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055599487865117515		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.055599487865117515 | validation: 0.04295221679998244]
	TIME [epoch: 11.4 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05583039545410668		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.05583039545410668 | validation: 0.03653508044093621]
	TIME [epoch: 11.5 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055348284977833305		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.055348284977833305 | validation: 0.04203946708416158]
	TIME [epoch: 11.5 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053513572756761274		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.053513572756761274 | validation: 0.042697225310563774]
	TIME [epoch: 11.5 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05715503044951333		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.05715503044951333 | validation: 0.03819766947093231]
	TIME [epoch: 11.5 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054968676063721106		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.054968676063721106 | validation: 0.039617140133084976]
	TIME [epoch: 11.5 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05617792537420377		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.05617792537420377 | validation: 0.049154742906345666]
	TIME [epoch: 11.5 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05589742254447812		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.05589742254447812 | validation: 0.03968868948052661]
	TIME [epoch: 11.5 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05194985532937762		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.05194985532937762 | validation: 0.044300820193717096]
	TIME [epoch: 11.5 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056958211628941796		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.056958211628941796 | validation: 0.05070642063096077]
	TIME [epoch: 11.5 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05381182306971752		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.05381182306971752 | validation: 0.04048908549848328]
	TIME [epoch: 11.5 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05480134023187172		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.05480134023187172 | validation: 0.037574837241564005]
	TIME [epoch: 11.5 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054526872460178344		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.054526872460178344 | validation: 0.04135032249017018]
	TIME [epoch: 11.4 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05364711577895842		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.05364711577895842 | validation: 0.03809108251587056]
	TIME [epoch: 11.4 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05449144848407879		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.05449144848407879 | validation: 0.03663597138111463]
	TIME [epoch: 11.5 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05461537009082773		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.05461537009082773 | validation: 0.033226072733657845]
	TIME [epoch: 11.4 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053674561694566705		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.053674561694566705 | validation: 0.03955011087492827]
	TIME [epoch: 11.4 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055706998888543656		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.055706998888543656 | validation: 0.034014140636098276]
	TIME [epoch: 11.5 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053093646986072315		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.053093646986072315 | validation: 0.040458171437646066]
	TIME [epoch: 11.5 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056017245313079576		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.056017245313079576 | validation: 0.04616059715291738]
	TIME [epoch: 11.5 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053295488838222195		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.053295488838222195 | validation: 0.03923101330909926]
	TIME [epoch: 11.5 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056434937336858004		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.056434937336858004 | validation: 0.0504310877619775]
	TIME [epoch: 11.5 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05658237182697427		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.05658237182697427 | validation: 0.039152755211544335]
	TIME [epoch: 11.5 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05338387346018364		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.05338387346018364 | validation: 0.03990914307008268]
	TIME [epoch: 11.5 sec]
Finished training in 23163.256 seconds.
