Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r3', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 242886967

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/20] avg loss: 8.31920604511989		[learning rate: 0.01]
		[batch 20/20] avg loss: 7.703603737173561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.011404891146725 | validation: 6.706060111783819]
	TIME [epoch: 78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/20] avg loss: 6.048432805819049		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.873839513494843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.961136159656946 | validation: 5.780969355868535]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/20] avg loss: 5.008941498491941		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.3897167656975755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.699329132094759 | validation: 6.247300367066596]
	TIME [epoch: 8.32 sec]
EPOCH 4/1000:
	Training over batches...
		[batch 10/20] avg loss: 4.33168196258038		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.7224336488209735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.027057805700677 | validation: 4.248181687521866]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.9625328117072764		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.420831211962873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6916820118350753 | validation: 2.628889857018239]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.2161041425204475		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.869637607955514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0428708752379814 | validation: 1.4834992258009767]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.7774777328536864		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.9147529324569583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8461153326553223 | validation: 1.5659465802254522]
	TIME [epoch: 8.31 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5842761682892557		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5878632703000175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5860697192946365 | validation: 3.1585169190622198]
	TIME [epoch: 8.31 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.6434126564239182		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6153208057512036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6293667310875606 | validation: 1.2441838827171285]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2458940182395368		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3526724270525203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.299283222646029 | validation: 1.661134866309666]
	TIME [epoch: 8.33 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3768424648698603		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8814960466999985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.129169255784929 | validation: 0.6083624890326931]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5377424293127568		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9159307807436784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2268366050282176 | validation: 0.8596510512471033]
	TIME [epoch: 8.32 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9285225081074918		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9848154819027639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9566689950051279 | validation: 0.8820878884638431]
	TIME [epoch: 8.32 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8911002870501795		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8102672761137656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8506837815819726 | validation: 1.4563267753440687]
	TIME [epoch: 8.35 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8745462548212058		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9619495353522185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9182478950867121 | validation: 0.602343999152004]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7521687315177882		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9087276942145532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8304482128661708 | validation: 0.7093382358197786]
	TIME [epoch: 8.33 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.778541925738736		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6784109198175917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7284764227781639 | validation: 1.5103631692565411]
	TIME [epoch: 8.31 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0228384305884954		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7714166550921547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8971275428403251 | validation: 0.4330615940143022]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.66873912140724		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7097639763802839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6892515488937618 | validation: 1.0511850173195416]
	TIME [epoch: 8.32 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6663497900568205		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7484090598665194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7073794249616701 | validation: 0.5841784875956318]
	TIME [epoch: 8.31 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6600653497969989		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8406749527519193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7503701512744592 | validation: 0.4053806852963562]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6777993795142162		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6532956614338362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6655475204740262 | validation: 0.5607891716570381]
	TIME [epoch: 8.34 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6555638874371079		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6369647890307695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6462643382339387 | validation: 0.41657091242625244]
	TIME [epoch: 8.32 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.643411013869097		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9596877755878654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8015493947284813 | validation: 0.4682553938441899]
	TIME [epoch: 8.3 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7414012281210092		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5851692835667629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.663285255843886 | validation: 0.5607769391836732]
	TIME [epoch: 8.3 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6340990426198769		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6573717696568256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6457354061383512 | validation: 0.4292926736493385]
	TIME [epoch: 8.3 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6651914833873628		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6738466919181942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6695190876527783 | validation: 0.43307063800996004]
	TIME [epoch: 8.33 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6525193006818153		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7047905817043901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6786549411931027 | validation: 0.4749597092722819]
	TIME [epoch: 8.3 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6585969835865636		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6855271802302487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.672062081908406 | validation: 0.45456824917124455]
	TIME [epoch: 8.3 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5943326765566268		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6910105036891909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.642671590122909 | validation: 0.47658156201581736]
	TIME [epoch: 8.3 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6387533312833259		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7214729065875012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6801131189354136 | validation: 0.7451334416363092]
	TIME [epoch: 8.33 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6071247763592218		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5394259246344424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5732753504968322 | validation: 0.382084714891971]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6144882390402076		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6621032125357649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6382957257879862 | validation: 0.8748785278590255]
	TIME [epoch: 8.31 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6678055426345078		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8167991926318834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7423023676331957 | validation: 0.4490615243677833]
	TIME [epoch: 8.31 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7070650692842054		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5288013316130282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6179332004486168 | validation: 0.4432208399105513]
	TIME [epoch: 8.33 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6365488849919257		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6586687084576685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.647608796724797 | validation: 0.4796141753525809]
	TIME [epoch: 8.31 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6410930123918546		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8384573063427221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7397751593672883 | validation: 0.4788607954119235]
	TIME [epoch: 8.31 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5916531182871528		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6617775666135062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6267153424503297 | validation: 0.32128782127079136]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_38.pth
	Model improved!!!
EPOCH 39/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5150184621474624		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5313708112776723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5231946367125673 | validation: 0.4213269577037305]
	TIME [epoch: 8.3 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7301879824936612		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5936574316615982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6619227070776298 | validation: 0.5936952179245987]
	TIME [epoch: 8.34 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5857927793825202		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6251437039156624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6054682416490913 | validation: 0.3980290061768117]
	TIME [epoch: 8.3 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6745441208582414		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6586144721831131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6665792965206773 | validation: 0.3339337357561829]
	TIME [epoch: 8.3 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6070152134859269		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.827276846303626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7171460298947763 | validation: 0.3414503707041472]
	TIME [epoch: 8.3 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5591248676383686		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7914034782335742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6752641729359713 | validation: 0.3416257980810897]
	TIME [epoch: 8.33 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5426166398693839		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5884644541226286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5655405469960063 | validation: 0.43924257507995124]
	TIME [epoch: 8.31 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5380509768244037		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6044215763579199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5712362765911617 | validation: 0.3468677794254279]
	TIME [epoch: 8.3 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6024610469848842		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.54263428255981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5725476647723471 | validation: 0.5538055462633298]
	TIME [epoch: 8.31 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5828778621829449		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5793001092706775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5810889857268111 | validation: 0.8879170732948305]
	TIME [epoch: 8.31 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5931264226482684		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5596709984825246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5763987105653965 | validation: 0.39223031682409204]
	TIME [epoch: 8.32 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.589509406985866		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8894136409458089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7394615239658373 | validation: 0.5304900130848066]
	TIME [epoch: 8.31 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6533190389104158		[learning rate: 0.0099782]
		[batch 20/20] avg loss: 0.7328217338924018		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 0.6930703864014087 | validation: 0.4931024238105771]
	TIME [epoch: 8.31 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7427965530164847		[learning rate: 0.00993]
		[batch 20/20] avg loss: 0.6245153533873661		[learning rate: 0.0099059]
	Learning Rate: 0.00990592
	LOSS [training: 0.6836559532019254 | validation: 0.531162054647937]
	TIME [epoch: 8.32 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7985683757541386		[learning rate: 0.0098819]
		[batch 20/20] avg loss: 0.7547605520326713		[learning rate: 0.009858]
	Learning Rate: 0.00985801
	LOSS [training: 0.7766644638934053 | validation: 0.40094201717774836]
	TIME [epoch: 8.33 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7270761964194392		[learning rate: 0.0098341]
		[batch 20/20] avg loss: 0.6103360761956694		[learning rate: 0.0098103]
	Learning Rate: 0.00981034
	LOSS [training: 0.6687061363075543 | validation: 0.5396743007519923]
	TIME [epoch: 8.31 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6332022337991838		[learning rate: 0.0097866]
		[batch 20/20] avg loss: 0.5450580372860013		[learning rate: 0.0097629]
	Learning Rate: 0.0097629
	LOSS [training: 0.5891301355425925 | validation: 0.3611365599526616]
	TIME [epoch: 8.32 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5582193824456647		[learning rate: 0.0097393]
		[batch 20/20] avg loss: 0.5657604920938101		[learning rate: 0.0097157]
	Learning Rate: 0.00971569
	LOSS [training: 0.5619899372697373 | validation: 0.5047432589546569]
	TIME [epoch: 8.31 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7703099453194662		[learning rate: 0.0096922]
		[batch 20/20] avg loss: 0.6624639942069759		[learning rate: 0.0096687]
	Learning Rate: 0.00966871
	LOSS [training: 0.716386969763221 | validation: 0.34005255139860685]
	TIME [epoch: 8.33 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7027735616454359		[learning rate: 0.0096453]
		[batch 20/20] avg loss: 0.5895995440611442		[learning rate: 0.009622]
	Learning Rate: 0.00962195
	LOSS [training: 0.6461865528532901 | validation: 0.39758342214892106]
	TIME [epoch: 8.32 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5321531915194034		[learning rate: 0.0095987]
		[batch 20/20] avg loss: 0.7368372210051306		[learning rate: 0.0095754]
	Learning Rate: 0.00957542
	LOSS [training: 0.6344952062622671 | validation: 0.4877244351399398]
	TIME [epoch: 8.32 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5404337570619135		[learning rate: 0.0095522]
		[batch 20/20] avg loss: 0.46575429674381724		[learning rate: 0.0095291]
	Learning Rate: 0.00952912
	LOSS [training: 0.5030940269028654 | validation: 0.49149857305390315]
	TIME [epoch: 8.32 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.843615697370567		[learning rate: 0.009506]
		[batch 20/20] avg loss: 0.9298140349036181		[learning rate: 0.009483]
	Learning Rate: 0.00948303
	LOSS [training: 0.8867148661370926 | validation: 0.6944192698302872]
	TIME [epoch: 8.33 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5803049915776665		[learning rate: 0.0094601]
		[batch 20/20] avg loss: 0.5677476665149952		[learning rate: 0.0094372]
	Learning Rate: 0.00943718
	LOSS [training: 0.574026329046331 | validation: 0.4481246626878679]
	TIME [epoch: 8.34 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.556433601252128		[learning rate: 0.0094143]
		[batch 20/20] avg loss: 0.4867841338971218		[learning rate: 0.0093915]
	Learning Rate: 0.00939154
	LOSS [training: 0.5216088675746249 | validation: 0.37251482468727715]
	TIME [epoch: 8.32 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4780214284946078		[learning rate: 0.0093688]
		[batch 20/20] avg loss: 0.5141187360398812		[learning rate: 0.0093461]
	Learning Rate: 0.00934612
	LOSS [training: 0.49607008226724447 | validation: 0.3523792945611987]
	TIME [epoch: 8.32 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3842221135522372		[learning rate: 0.0093235]
		[batch 20/20] avg loss: 0.623771609018578		[learning rate: 0.0093009]
	Learning Rate: 0.00930093
	LOSS [training: 0.5039968612854075 | validation: 0.9690722694660046]
	TIME [epoch: 8.32 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5389302655738969		[learning rate: 0.0092784]
		[batch 20/20] avg loss: 0.48210827064722295		[learning rate: 0.009256]
	Learning Rate: 0.00925595
	LOSS [training: 0.51051926811056 | validation: 0.6752692201060444]
	TIME [epoch: 8.35 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4953963236825448		[learning rate: 0.0092335]
		[batch 20/20] avg loss: 0.49609100811191614		[learning rate: 0.0092112]
	Learning Rate: 0.00921119
	LOSS [training: 0.49574366589723046 | validation: 1.0115912702088063]
	TIME [epoch: 8.32 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5224382728263544		[learning rate: 0.0091889]
		[batch 20/20] avg loss: 0.44593279509647255		[learning rate: 0.0091666]
	Learning Rate: 0.00916665
	LOSS [training: 0.48418553396141356 | validation: 0.288168089247036]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_68.pth
	Model improved!!!
EPOCH 69/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3922954657037335		[learning rate: 0.0091445]
		[batch 20/20] avg loss: 0.48870055652120703		[learning rate: 0.0091223]
	Learning Rate: 0.00912232
	LOSS [training: 0.44049801111247044 | validation: 0.7588923978540306]
	TIME [epoch: 8.3 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.412630874046888		[learning rate: 0.0091002]
		[batch 20/20] avg loss: 0.535312236884959		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 0.4739715554659235 | validation: 0.9741634686990629]
	TIME [epoch: 8.35 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5225112634470845		[learning rate: 0.0090562]
		[batch 20/20] avg loss: 0.5394941240634632		[learning rate: 0.0090343]
	Learning Rate: 0.0090343
	LOSS [training: 0.5310026937552739 | validation: 0.33368682338954025]
	TIME [epoch: 8.32 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4453317730681407		[learning rate: 0.0090124]
		[batch 20/20] avg loss: 0.40465251270070207		[learning rate: 0.0089906]
	Learning Rate: 0.00899062
	LOSS [training: 0.4249921428844214 | validation: 0.5505032809391568]
	TIME [epoch: 8.32 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.432662604532131		[learning rate: 0.0089689]
		[batch 20/20] avg loss: 0.3083854401986014		[learning rate: 0.0089471]
	Learning Rate: 0.00894714
	LOSS [training: 0.3705240223653662 | validation: 0.2585001454028138]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_73.pth
	Model improved!!!
EPOCH 74/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.44844168387883004		[learning rate: 0.0089255]
		[batch 20/20] avg loss: 0.3747005706812489		[learning rate: 0.0089039]
	Learning Rate: 0.00890387
	LOSS [training: 0.4115711272800395 | validation: 0.311032718654922]
	TIME [epoch: 8.34 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4665785915737798		[learning rate: 0.0088823]
		[batch 20/20] avg loss: 0.40531645229284124		[learning rate: 0.0088608]
	Learning Rate: 0.00886082
	LOSS [training: 0.43594752193331054 | validation: 0.8683789163388606]
	TIME [epoch: 8.33 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4382929197160662		[learning rate: 0.0088394]
		[batch 20/20] avg loss: 0.39862751088251547		[learning rate: 0.008818]
	Learning Rate: 0.00881797
	LOSS [training: 0.4184602152992907 | validation: 0.30513276652217]
	TIME [epoch: 8.32 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4058071458393816		[learning rate: 0.0087966]
		[batch 20/20] avg loss: 0.3836702529046417		[learning rate: 0.0087753]
	Learning Rate: 0.00877532
	LOSS [training: 0.39473869937201156 | validation: 0.44374216244334397]
	TIME [epoch: 8.33 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4212831722281349		[learning rate: 0.0087541]
		[batch 20/20] avg loss: 0.35663060287353926		[learning rate: 0.0087329]
	Learning Rate: 0.00873289
	LOSS [training: 0.388956887550837 | validation: 0.5772616436897464]
	TIME [epoch: 8.32 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.35523411657899934		[learning rate: 0.0087117]
		[batch 20/20] avg loss: 0.4606875444407844		[learning rate: 0.0086907]
	Learning Rate: 0.00869066
	LOSS [training: 0.4079608305098919 | validation: 0.29410834866922747]
	TIME [epoch: 8.35 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4984027493916724		[learning rate: 0.0086696]
		[batch 20/20] avg loss: 0.35373742370829053		[learning rate: 0.0086486]
	Learning Rate: 0.00864863
	LOSS [training: 0.42607008654998146 | validation: 0.4487487480425763]
	TIME [epoch: 8.32 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.46331356759197684		[learning rate: 0.0086277]
		[batch 20/20] avg loss: 0.5042082034766817		[learning rate: 0.0086068]
	Learning Rate: 0.00860681
	LOSS [training: 0.4837608855343293 | validation: 0.192088538147418]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_81.pth
	Model improved!!!
EPOCH 82/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.324150623980212		[learning rate: 0.008586]
		[batch 20/20] avg loss: 0.4529019723758377		[learning rate: 0.0085652]
	Learning Rate: 0.00856519
	LOSS [training: 0.38852629817802475 | validation: 0.20775121485952694]
	TIME [epoch: 8.32 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3655827072067503		[learning rate: 0.0085445]
		[batch 20/20] avg loss: 0.41542836841491093		[learning rate: 0.0085238]
	Learning Rate: 0.00852377
	LOSS [training: 0.39050553781083064 | validation: 0.1799130518735803]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_83.pth
	Model improved!!!
EPOCH 84/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4403706686894628		[learning rate: 0.0085031]
		[batch 20/20] avg loss: 0.3617119505749255		[learning rate: 0.0084825]
	Learning Rate: 0.00848255
	LOSS [training: 0.40104130963219414 | validation: 0.23578982851572894]
	TIME [epoch: 8.33 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3479646624003936		[learning rate: 0.008462]
		[batch 20/20] avg loss: 0.3410729106456996		[learning rate: 0.0084415]
	Learning Rate: 0.00844153
	LOSS [training: 0.34451878652304646 | validation: 0.22525104452388467]
	TIME [epoch: 8.32 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3690788688406744		[learning rate: 0.0084211]
		[batch 20/20] avg loss: 0.36116671788097904		[learning rate: 0.0084007]
	Learning Rate: 0.00840071
	LOSS [training: 0.3651227933608268 | validation: 0.36865477577160044]
	TIME [epoch: 8.32 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3532619133418222		[learning rate: 0.0083804]
		[batch 20/20] avg loss: 0.412440121299295		[learning rate: 0.0083601]
	Learning Rate: 0.00836008
	LOSS [training: 0.38285101732055854 | validation: 0.36923393802583077]
	TIME [epoch: 8.33 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.35531270851124735		[learning rate: 0.0083398]
		[batch 20/20] avg loss: 0.33421798217818005		[learning rate: 0.0083197]
	Learning Rate: 0.00831965
	LOSS [training: 0.34476534534471365 | validation: 0.24426392588177398]
	TIME [epoch: 8.33 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.412952656849184		[learning rate: 0.0082995]
		[batch 20/20] avg loss: 0.42830380097260007		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 0.42062822891089197 | validation: 0.43654075513116536]
	TIME [epoch: 8.32 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36761697430546		[learning rate: 0.0082594]
		[batch 20/20] avg loss: 0.4652884414468857		[learning rate: 0.0082394]
	Learning Rate: 0.00823938
	LOSS [training: 0.4164527078761727 | validation: 0.323862198363832]
	TIME [epoch: 8.32 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4097590510070777		[learning rate: 0.0082194]
		[batch 20/20] avg loss: 0.4286594481559594		[learning rate: 0.0081995]
	Learning Rate: 0.00819954
	LOSS [training: 0.4192092495815186 | validation: 0.2031931723680366]
	TIME [epoch: 8.32 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2867330952198815		[learning rate: 0.0081797]
		[batch 20/20] avg loss: 0.3582845079066675		[learning rate: 0.0081599]
	Learning Rate: 0.00815989
	LOSS [training: 0.3225088015632745 | validation: 0.20192961022934147]
	TIME [epoch: 8.34 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3511221903399083		[learning rate: 0.0081401]
		[batch 20/20] avg loss: 0.4204169484172738		[learning rate: 0.0081204]
	Learning Rate: 0.00812043
	LOSS [training: 0.385769569378591 | validation: 0.8773489592770667]
	TIME [epoch: 8.32 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.42346743488740335		[learning rate: 0.0081008]
		[batch 20/20] avg loss: 0.2862196801788187		[learning rate: 0.0080812]
	Learning Rate: 0.00808116
	LOSS [training: 0.354843557533111 | validation: 0.4551121376292676]
	TIME [epoch: 8.32 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.45995941733320383		[learning rate: 0.0080616]
		[batch 20/20] avg loss: 0.37510717891573814		[learning rate: 0.0080421]
	Learning Rate: 0.00804208
	LOSS [training: 0.41753329812447104 | validation: 0.323855760982201]
	TIME [epoch: 8.32 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.34595639766047515		[learning rate: 0.0080226]
		[batch 20/20] avg loss: 0.39860611081592356		[learning rate: 0.0080032]
	Learning Rate: 0.00800319
	LOSS [training: 0.3722812542381993 | validation: 0.43961801716356874]
	TIME [epoch: 8.35 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4796537868271997		[learning rate: 0.0079838]
		[batch 20/20] avg loss: 0.2870007740703015		[learning rate: 0.0079645]
	Learning Rate: 0.00796449
	LOSS [training: 0.3833272804487507 | validation: 0.43822133740690017]
	TIME [epoch: 8.33 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4204789635525364		[learning rate: 0.0079452]
		[batch 20/20] avg loss: 0.358981301423982		[learning rate: 0.007926]
	Learning Rate: 0.00792597
	LOSS [training: 0.3897301324882592 | validation: 0.38689982666639045]
	TIME [epoch: 8.32 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.46661957011109545		[learning rate: 0.0079068]
		[batch 20/20] avg loss: 0.32032931333925607		[learning rate: 0.0078876]
	Learning Rate: 0.00788765
	LOSS [training: 0.39347444172517576 | validation: 0.21552951544330393]
	TIME [epoch: 8.32 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29628353105427674		[learning rate: 0.0078685]
		[batch 20/20] avg loss: 0.5183335262015799		[learning rate: 0.0078495]
	Learning Rate: 0.0078495
	LOSS [training: 0.40730852862792827 | validation: 0.2822629820706326]
	TIME [epoch: 8.32 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29575357945160907		[learning rate: 0.0078305]
		[batch 20/20] avg loss: 0.634419760073836		[learning rate: 0.0078115]
	Learning Rate: 0.00781154
	LOSS [training: 0.46508666976272267 | validation: 0.32493529256345965]
	TIME [epoch: 8.35 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3971096551067619		[learning rate: 0.0077926]
		[batch 20/20] avg loss: 0.5406242922503174		[learning rate: 0.0077738]
	Learning Rate: 0.00777377
	LOSS [training: 0.46886697367853963 | validation: 0.1947032816437228]
	TIME [epoch: 8.32 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36895816808061144		[learning rate: 0.0077549]
		[batch 20/20] avg loss: 0.3550752204725779		[learning rate: 0.0077362]
	Learning Rate: 0.00773618
	LOSS [training: 0.36201669427659466 | validation: 1.2235014026423925]
	TIME [epoch: 8.32 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.399550864253951		[learning rate: 0.0077174]
		[batch 20/20] avg loss: 0.274882548988235		[learning rate: 0.0076988]
	Learning Rate: 0.00769876
	LOSS [training: 0.33721670662109293 | validation: 0.23207558048401128]
	TIME [epoch: 8.32 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30725125674887266		[learning rate: 0.0076801]
		[batch 20/20] avg loss: 0.3483383303656601		[learning rate: 0.0076615]
	Learning Rate: 0.00766153
	LOSS [training: 0.3277947935572664 | validation: 0.18430521128009508]
	TIME [epoch: 8.35 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2864402861222737		[learning rate: 0.007643]
		[batch 20/20] avg loss: 0.46989128838970534		[learning rate: 0.0076245]
	Learning Rate: 0.00762449
	LOSS [training: 0.3781657872559895 | validation: 0.5124356102469041]
	TIME [epoch: 8.32 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.42479314050910577		[learning rate: 0.007606]
		[batch 20/20] avg loss: 0.27578387614777794		[learning rate: 0.0075876]
	Learning Rate: 0.00758761
	LOSS [training: 0.3502885083284418 | validation: 0.28691157787246907]
	TIME [epoch: 8.32 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3715463445843829		[learning rate: 0.0075692]
		[batch 20/20] avg loss: 0.24467589402564313		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 0.308111119305013 | validation: 0.30544873808570266]
	TIME [epoch: 8.32 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.47797136848675537		[learning rate: 0.0075326]
		[batch 20/20] avg loss: 0.33023457053238925		[learning rate: 0.0075144]
	Learning Rate: 0.00751441
	LOSS [training: 0.4041029695095723 | validation: 0.16005299163243025]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_109.pth
	Model improved!!!
EPOCH 110/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2898400153431405		[learning rate: 0.0074962]
		[batch 20/20] avg loss: 0.39173574935710953		[learning rate: 0.0074781]
	Learning Rate: 0.00747807
	LOSS [training: 0.340787882350125 | validation: 0.2735075651339149]
	TIME [epoch: 8.31 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2894514830398154		[learning rate: 0.00746]
		[batch 20/20] avg loss: 0.2591517771612743		[learning rate: 0.0074419]
	Learning Rate: 0.00744191
	LOSS [training: 0.27430163010054487 | validation: 0.26147023079878773]
	TIME [epoch: 8.31 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30467796736230657		[learning rate: 0.0074239]
		[batch 20/20] avg loss: 0.31535829440784713		[learning rate: 0.0074059]
	Learning Rate: 0.00740592
	LOSS [training: 0.3100181308850768 | validation: 0.3081538578017673]
	TIME [epoch: 8.31 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4822753246811506		[learning rate: 0.007388]
		[batch 20/20] avg loss: 0.42713061091487664		[learning rate: 0.0073701]
	Learning Rate: 0.00737011
	LOSS [training: 0.4547029677980136 | validation: 0.42227723928486205]
	TIME [epoch: 8.32 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2852989145242374		[learning rate: 0.0073523]
		[batch 20/20] avg loss: 0.32974472356827644		[learning rate: 0.0073345]
	Learning Rate: 0.00733446
	LOSS [training: 0.307521819046257 | validation: 0.43079124797360846]
	TIME [epoch: 8.34 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30136164892577033		[learning rate: 0.0073167]
		[batch 20/20] avg loss: 0.3313950044417652		[learning rate: 0.007299]
	Learning Rate: 0.007299
	LOSS [training: 0.3163783266837678 | validation: 0.1837207923094455]
	TIME [epoch: 8.31 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.361207067932055		[learning rate: 0.0072813]
		[batch 20/20] avg loss: 0.3410617105462216		[learning rate: 0.0072637]
	Learning Rate: 0.0072637
	LOSS [training: 0.3511343892391382 | validation: 0.4369496328174691]
	TIME [epoch: 8.32 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30626376235843866		[learning rate: 0.0072461]
		[batch 20/20] avg loss: 0.34053806696030214		[learning rate: 0.0072286]
	Learning Rate: 0.00722857
	LOSS [training: 0.3234009146593705 | validation: 0.22095891750224386]
	TIME [epoch: 8.32 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3428352471288065		[learning rate: 0.0072111]
		[batch 20/20] avg loss: 0.34217553764023395		[learning rate: 0.0071936]
	Learning Rate: 0.00719362
	LOSS [training: 0.34250539238452016 | validation: 0.3825894857243043]
	TIME [epoch: 8.34 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3178416256704481		[learning rate: 0.0071762]
		[batch 20/20] avg loss: 0.4019759437449101		[learning rate: 0.0071588]
	Learning Rate: 0.00715883
	LOSS [training: 0.3599087847076791 | validation: 0.19537615022481658]
	TIME [epoch: 8.32 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28567297743045994		[learning rate: 0.0071415]
		[batch 20/20] avg loss: 0.40061256242215426		[learning rate: 0.0071242]
	Learning Rate: 0.00712421
	LOSS [training: 0.3431427699263071 | validation: 0.2066590149077375]
	TIME [epoch: 8.32 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3236461992548457		[learning rate: 0.007107]
		[batch 20/20] avg loss: 0.37246744618153216		[learning rate: 0.0070898]
	Learning Rate: 0.00708976
	LOSS [training: 0.34805682271818894 | validation: 0.3734171448266782]
	TIME [epoch: 8.31 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2902919265134451		[learning rate: 0.0070726]
		[batch 20/20] avg loss: 0.2623796821471786		[learning rate: 0.0070555]
	Learning Rate: 0.00705548
	LOSS [training: 0.27633580433031185 | validation: 0.3888570499594538]
	TIME [epoch: 8.35 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2989260278486593		[learning rate: 0.0070384]
		[batch 20/20] avg loss: 0.3725588085031827		[learning rate: 0.0070214]
	Learning Rate: 0.00702136
	LOSS [training: 0.33574241817592093 | validation: 0.48099121110151666]
	TIME [epoch: 8.32 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3069837174778404		[learning rate: 0.0070044]
		[batch 20/20] avg loss: 0.29569647834185325		[learning rate: 0.0069874]
	Learning Rate: 0.0069874
	LOSS [training: 0.3013400979098468 | validation: 0.34681641067471003]
	TIME [epoch: 8.32 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2525619031421261		[learning rate: 0.0069705]
		[batch 20/20] avg loss: 0.26886452853050474		[learning rate: 0.0069536]
	Learning Rate: 0.00695361
	LOSS [training: 0.2607132158363154 | validation: 0.3380121258674099]
	TIME [epoch: 8.31 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2959642613387037		[learning rate: 0.0069368]
		[batch 20/20] avg loss: 0.34542038492004656		[learning rate: 0.00692]
	Learning Rate: 0.00691999
	LOSS [training: 0.3206923231293751 | validation: 0.1766009505791637]
	TIME [epoch: 8.32 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.34400982930580126		[learning rate: 0.0069032]
		[batch 20/20] avg loss: 0.278888374817445		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 0.31144910206162313 | validation: 0.23459962787494174]
	TIME [epoch: 8.34 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24091871622214156		[learning rate: 0.0068699]
		[batch 20/20] avg loss: 0.35730161944943517		[learning rate: 0.0068532]
	Learning Rate: 0.00685322
	LOSS [training: 0.29911016783578837 | validation: 0.19757953687636978]
	TIME [epoch: 8.32 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36430685047050754		[learning rate: 0.0068366]
		[batch 20/20] avg loss: 0.3104237237657666		[learning rate: 0.0068201]
	Learning Rate: 0.00682008
	LOSS [training: 0.33736528711813707 | validation: 0.23816173528993853]
	TIME [epoch: 8.31 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.39315717939948486		[learning rate: 0.0068036]
		[batch 20/20] avg loss: 0.3667317079962894		[learning rate: 0.0067871]
	Learning Rate: 0.0067871
	LOSS [training: 0.37994444369788716 | validation: 0.20580817040454852]
	TIME [epoch: 8.32 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2801814479868573		[learning rate: 0.0067707]
		[batch 20/20] avg loss: 0.36134916393649563		[learning rate: 0.0067543]
	Learning Rate: 0.00675428
	LOSS [training: 0.3207653059616764 | validation: 0.42515152342901796]
	TIME [epoch: 8.35 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29915500745351076		[learning rate: 0.0067379]
		[batch 20/20] avg loss: 0.2992046577958116		[learning rate: 0.0067216]
	Learning Rate: 0.00672162
	LOSS [training: 0.2991798326246612 | validation: 0.18198197460037302]
	TIME [epoch: 8.31 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20241815545690667		[learning rate: 0.0067053]
		[batch 20/20] avg loss: 0.3273615631816735		[learning rate: 0.0066891]
	Learning Rate: 0.00668911
	LOSS [training: 0.26488985931929004 | validation: 0.2301652046548667]
	TIME [epoch: 8.32 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2765615418530424		[learning rate: 0.0066729]
		[batch 20/20] avg loss: 0.22383557185861308		[learning rate: 0.0066568]
	Learning Rate: 0.00665676
	LOSS [training: 0.2501985568558277 | validation: 0.23471739276070996]
	TIME [epoch: 8.32 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3004012579728072		[learning rate: 0.0066406]
		[batch 20/20] avg loss: 0.37516174471775143		[learning rate: 0.0066246]
	Learning Rate: 0.00662457
	LOSS [training: 0.3377815013452793 | validation: 0.15846817773743277]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_135.pth
	Model improved!!!
EPOCH 136/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3231098195946201		[learning rate: 0.0066085]
		[batch 20/20] avg loss: 0.2470517485211193		[learning rate: 0.0065925]
	Learning Rate: 0.00659254
	LOSS [training: 0.2850807840578697 | validation: 0.15485440040408371]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_136.pth
	Model improved!!!
EPOCH 137/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.329273201068111		[learning rate: 0.0065766]
		[batch 20/20] avg loss: 0.2953360589919457		[learning rate: 0.0065607]
	Learning Rate: 0.00656066
	LOSS [training: 0.31230463003002834 | validation: 0.5126705950331827]
	TIME [epoch: 8.32 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2431130837303289		[learning rate: 0.0065448]
		[batch 20/20] avg loss: 0.3225422998012174		[learning rate: 0.0065289]
	Learning Rate: 0.00652893
	LOSS [training: 0.2828276917657732 | validation: 0.303286008624304]
	TIME [epoch: 8.32 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.31674429297865786		[learning rate: 0.0065131]
		[batch 20/20] avg loss: 0.31111152635598727		[learning rate: 0.0064974]
	Learning Rate: 0.00649736
	LOSS [training: 0.3139279096673226 | validation: 0.4222990165455446]
	TIME [epoch: 8.31 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3646476177993121		[learning rate: 0.0064816]
		[batch 20/20] avg loss: 0.31648143803795664		[learning rate: 0.0064659]
	Learning Rate: 0.00646594
	LOSS [training: 0.3405645279186344 | validation: 0.3887604815879051]
	TIME [epoch: 8.34 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.278023488291225		[learning rate: 0.0064503]
		[batch 20/20] avg loss: 0.2906563379517243		[learning rate: 0.0064347]
	Learning Rate: 0.00643467
	LOSS [training: 0.28433991312147466 | validation: 1.1342793087071472]
	TIME [epoch: 8.31 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.37456784350487476		[learning rate: 0.0064191]
		[batch 20/20] avg loss: 0.3321838816257473		[learning rate: 0.0064036]
	Learning Rate: 0.00640355
	LOSS [training: 0.35337586256531106 | validation: 0.2195191138556185]
	TIME [epoch: 8.31 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28395460615240636		[learning rate: 0.0063881]
		[batch 20/20] avg loss: 0.34166381109555205		[learning rate: 0.0063726]
	Learning Rate: 0.00637259
	LOSS [training: 0.3128092086239792 | validation: 0.5090081909357397]
	TIME [epoch: 8.31 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2796054537776122		[learning rate: 0.0063572]
		[batch 20/20] avg loss: 0.29742360542223184		[learning rate: 0.0063418]
	Learning Rate: 0.00634177
	LOSS [training: 0.2885145295999221 | validation: 0.25576960620594535]
	TIME [epoch: 8.34 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.325671114181982		[learning rate: 0.0063264]
		[batch 20/20] avg loss: 0.2595875499936274		[learning rate: 0.0063111]
	Learning Rate: 0.0063111
	LOSS [training: 0.2926293320878047 | validation: 0.15272492578661181]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_145.pth
	Model improved!!!
EPOCH 146/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18268780480699642		[learning rate: 0.0062958]
		[batch 20/20] avg loss: 0.29952216156478817		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 0.24110498318589224 | validation: 0.33102675473024634]
	TIME [epoch: 8.31 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27703784301077133		[learning rate: 0.0062654]
		[batch 20/20] avg loss: 0.3125032531474258		[learning rate: 0.0062502]
	Learning Rate: 0.00625021
	LOSS [training: 0.2947705480790985 | validation: 0.3388215338326077]
	TIME [epoch: 8.31 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27097256575008755		[learning rate: 0.0062351]
		[batch 20/20] avg loss: 0.19501853863412766		[learning rate: 0.00622]
	Learning Rate: 0.00621999
	LOSS [training: 0.23299555219210757 | validation: 0.5638550714145809]
	TIME [epoch: 8.33 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.304578394411613		[learning rate: 0.0062049]
		[batch 20/20] avg loss: 0.27078623782772404		[learning rate: 0.0061899]
	Learning Rate: 0.00618991
	LOSS [training: 0.2876823161196685 | validation: 0.1563762628115884]
	TIME [epoch: 8.31 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3357307929270224		[learning rate: 0.0061749]
		[batch 20/20] avg loss: 0.3194978909716103		[learning rate: 0.00616]
	Learning Rate: 0.00615997
	LOSS [training: 0.32761434194931627 | validation: 0.14725675656168072]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_150.pth
	Model improved!!!
EPOCH 151/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2622862686795094		[learning rate: 0.0061451]
		[batch 20/20] avg loss: 0.25327551424205913		[learning rate: 0.0061302]
	Learning Rate: 0.00613019
	LOSS [training: 0.25778089146078426 | validation: 0.3188224293488192]
	TIME [epoch: 8.31 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24569426107951423		[learning rate: 0.0061153]
		[batch 20/20] avg loss: 0.2480970096171174		[learning rate: 0.0061005]
	Learning Rate: 0.00610054
	LOSS [training: 0.24689563534831577 | validation: 0.3558891067006492]
	TIME [epoch: 8.31 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.32432594746732857		[learning rate: 0.0060858]
		[batch 20/20] avg loss: 0.30352086181788046		[learning rate: 0.006071]
	Learning Rate: 0.00607104
	LOSS [training: 0.3139234046426045 | validation: 0.2221021420196969]
	TIME [epoch: 8.33 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1803178645524333		[learning rate: 0.0060563]
		[batch 20/20] avg loss: 0.36835252179392175		[learning rate: 0.0060417]
	Learning Rate: 0.00604168
	LOSS [training: 0.27433519317317745 | validation: 0.393878459172601]
	TIME [epoch: 8.3 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2986453929935958		[learning rate: 0.0060271]
		[batch 20/20] avg loss: 0.2778508288952676		[learning rate: 0.0060125]
	Learning Rate: 0.00601247
	LOSS [training: 0.2882481109444317 | validation: 0.4407143307739594]
	TIME [epoch: 8.3 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27766739525083556		[learning rate: 0.0059979]
		[batch 20/20] avg loss: 0.23149371761553628		[learning rate: 0.0059834]
	Learning Rate: 0.00598339
	LOSS [training: 0.25458055643318594 | validation: 0.15018835654113613]
	TIME [epoch: 8.3 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22157488397726474		[learning rate: 0.0059689]
		[batch 20/20] avg loss: 0.31086588886178096		[learning rate: 0.0059545]
	Learning Rate: 0.00595446
	LOSS [training: 0.26622038641952284 | validation: 0.38033630145604563]
	TIME [epoch: 8.33 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23762034914923952		[learning rate: 0.00594]
		[batch 20/20] avg loss: 0.20910839770248493		[learning rate: 0.0059257]
	Learning Rate: 0.00592566
	LOSS [training: 0.2233643734258622 | validation: 0.23574704604949206]
	TIME [epoch: 8.31 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19431753926484002		[learning rate: 0.0059113]
		[batch 20/20] avg loss: 0.25493471222583974		[learning rate: 0.005897]
	Learning Rate: 0.00589701
	LOSS [training: 0.2246261257453399 | validation: 0.24029282947586578]
	TIME [epoch: 8.3 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2406039518653098		[learning rate: 0.0058827]
		[batch 20/20] avg loss: 0.25607052161360516		[learning rate: 0.0058685]
	Learning Rate: 0.00586849
	LOSS [training: 0.24833723673945746 | validation: 0.1840286351738801]
	TIME [epoch: 8.3 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2752944225784111		[learning rate: 0.0058543]
		[batch 20/20] avg loss: 0.3566935108403187		[learning rate: 0.0058401]
	Learning Rate: 0.00584011
	LOSS [training: 0.3159939667093649 | validation: 0.17486921224109533]
	TIME [epoch: 8.34 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20433642662482604		[learning rate: 0.005826]
		[batch 20/20] avg loss: 0.21848648257231487		[learning rate: 0.0058119]
	Learning Rate: 0.00581187
	LOSS [training: 0.21141145459857044 | validation: 0.13938517297178593]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_162.pth
	Model improved!!!
EPOCH 163/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29687553331081595		[learning rate: 0.0057978]
		[batch 20/20] avg loss: 0.24938187096341444		[learning rate: 0.0057838]
	Learning Rate: 0.00578376
	LOSS [training: 0.2731287021371152 | validation: 0.12010474533743373]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_163.pth
	Model improved!!!
EPOCH 164/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24169631423087573		[learning rate: 0.0057698]
		[batch 20/20] avg loss: 0.2960506694229		[learning rate: 0.0057558]
	Learning Rate: 0.00575579
	LOSS [training: 0.2688734918268879 | validation: 0.15798135144976744]
	TIME [epoch: 8.3 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19077108505037793		[learning rate: 0.0057419]
		[batch 20/20] avg loss: 0.30465030674083265		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 0.2477106958956053 | validation: 0.3300493877409647]
	TIME [epoch: 8.3 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2593875451724668		[learning rate: 0.0057141]
		[batch 20/20] avg loss: 0.23375328471616022		[learning rate: 0.0057003]
	Learning Rate: 0.00570026
	LOSS [training: 0.24657041494431348 | validation: 0.13108399779602734]
	TIME [epoch: 8.32 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26281288167269873		[learning rate: 0.0056865]
		[batch 20/20] avg loss: 0.25496477649625704		[learning rate: 0.0056727]
	Learning Rate: 0.0056727
	LOSS [training: 0.2588888290844779 | validation: 0.2749782262930833]
	TIME [epoch: 8.3 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29839381020444244		[learning rate: 0.005659]
		[batch 20/20] avg loss: 0.2626665529794484		[learning rate: 0.0056453]
	Learning Rate: 0.00564526
	LOSS [training: 0.2805301815919454 | validation: 0.18661104602827705]
	TIME [epoch: 8.3 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23365658229029912		[learning rate: 0.0056316]
		[batch 20/20] avg loss: 0.30842437736485356		[learning rate: 0.005618]
	Learning Rate: 0.00561796
	LOSS [training: 0.2710404798275764 | validation: 0.294254844031125]
	TIME [epoch: 8.29 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2428297349310266		[learning rate: 0.0056044]
		[batch 20/20] avg loss: 0.24326221258199898		[learning rate: 0.0055908]
	Learning Rate: 0.0055908
	LOSS [training: 0.24304597375651277 | validation: 0.23094430908783808]
	TIME [epoch: 8.32 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.245907279146207		[learning rate: 0.0055773]
		[batch 20/20] avg loss: 0.25622674170632065		[learning rate: 0.0055638]
	Learning Rate: 0.00556376
	LOSS [training: 0.2510670104262639 | validation: 0.3179277767517194]
	TIME [epoch: 8.3 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25683145905329713		[learning rate: 0.0055503]
		[batch 20/20] avg loss: 0.22517327386094813		[learning rate: 0.0055369]
	Learning Rate: 0.00553685
	LOSS [training: 0.24100236645712267 | validation: 0.2721329182622191]
	TIME [epoch: 8.3 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28004769284306286		[learning rate: 0.0055235]
		[batch 20/20] avg loss: 0.2743589533809192		[learning rate: 0.0055101]
	Learning Rate: 0.00551008
	LOSS [training: 0.277203323111991 | validation: 0.14028817050340664]
	TIME [epoch: 8.3 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23523607574945454		[learning rate: 0.0054967]
		[batch 20/20] avg loss: 0.28924928548171636		[learning rate: 0.0054834]
	Learning Rate: 0.00548343
	LOSS [training: 0.2622426806155855 | validation: 0.2125475600093582]
	TIME [epoch: 8.33 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21120399551086416		[learning rate: 0.0054702]
		[batch 20/20] avg loss: 0.25994687068969397		[learning rate: 0.0054569]
	Learning Rate: 0.00545692
	LOSS [training: 0.23557543310027906 | validation: 0.10031790652692626]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_175.pth
	Model improved!!!
EPOCH 176/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18597138878831646		[learning rate: 0.0054437]
		[batch 20/20] avg loss: 0.23974053642528853		[learning rate: 0.0054305]
	Learning Rate: 0.00543053
	LOSS [training: 0.21285596260680245 | validation: 0.21545933007270457]
	TIME [epoch: 8.3 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23957012130308106		[learning rate: 0.0054174]
		[batch 20/20] avg loss: 0.27350650106067753		[learning rate: 0.0054043]
	Learning Rate: 0.00540427
	LOSS [training: 0.25653831118187925 | validation: 0.533411833578871]
	TIME [epoch: 8.3 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3201381350731517		[learning rate: 0.0053912]
		[batch 20/20] avg loss: 0.16614362029826873		[learning rate: 0.0053781]
	Learning Rate: 0.00537813
	LOSS [training: 0.2431408776857103 | validation: 0.06932101888216194]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_178.pth
	Model improved!!!
EPOCH 179/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22467304865349833		[learning rate: 0.0053651]
		[batch 20/20] avg loss: 0.2348379646092103		[learning rate: 0.0053521]
	Learning Rate: 0.00535213
	LOSS [training: 0.2297555066313543 | validation: 0.2514838579583405]
	TIME [epoch: 8.34 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5090172291091568		[learning rate: 0.0053392]
		[batch 20/20] avg loss: 0.2826655929402887		[learning rate: 0.0053262]
	Learning Rate: 0.00532624
	LOSS [training: 0.3958414110247227 | validation: 0.21202955140696486]
	TIME [epoch: 8.3 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17784586628790677		[learning rate: 0.0053133]
		[batch 20/20] avg loss: 0.2153328778012858		[learning rate: 0.0053005]
	Learning Rate: 0.00530049
	LOSS [training: 0.19658937204459628 | validation: 0.5484754963699392]
	TIME [epoch: 8.31 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22133716451910074		[learning rate: 0.0052877]
		[batch 20/20] avg loss: 0.2533453063427408		[learning rate: 0.0052749]
	Learning Rate: 0.00527485
	LOSS [training: 0.2373412354309207 | validation: 0.08389379208696275]
	TIME [epoch: 8.3 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23766075060723696		[learning rate: 0.0052621]
		[batch 20/20] avg loss: 0.20601102746033595		[learning rate: 0.0052493]
	Learning Rate: 0.00524935
	LOSS [training: 0.22183588903378645 | validation: 0.30675860525202064]
	TIME [epoch: 8.33 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28093766074039395		[learning rate: 0.0052366]
		[batch 20/20] avg loss: 0.3023934311114654		[learning rate: 0.005224]
	Learning Rate: 0.00522396
	LOSS [training: 0.2916655459259297 | validation: 0.07899423016794323]
	TIME [epoch: 8.31 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2621011858821535		[learning rate: 0.0052113]
		[batch 20/20] avg loss: 0.18410064347917407		[learning rate: 0.0051987]
	Learning Rate: 0.0051987
	LOSS [training: 0.22310091468066387 | validation: 0.268758855403469]
	TIME [epoch: 8.31 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22928506913414162		[learning rate: 0.0051861]
		[batch 20/20] avg loss: 0.2037773497207916		[learning rate: 0.0051736]
	Learning Rate: 0.00517356
	LOSS [training: 0.2165312094274666 | validation: 0.13063786300981217]
	TIME [epoch: 8.31 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2158459637689007		[learning rate: 0.005161]
		[batch 20/20] avg loss: 0.19165502038578663		[learning rate: 0.0051485]
	Learning Rate: 0.00514854
	LOSS [training: 0.20375049207734364 | validation: 0.21658868002365064]
	TIME [epoch: 8.34 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.323994923381274		[learning rate: 0.0051361]
		[batch 20/20] avg loss: 0.19821901077028267		[learning rate: 0.0051236]
	Learning Rate: 0.00512364
	LOSS [training: 0.26110696707577835 | validation: 0.09719845400430112]
	TIME [epoch: 8.32 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18981778153032575		[learning rate: 0.0051112]
		[batch 20/20] avg loss: 0.25427078216961274		[learning rate: 0.0050989]
	Learning Rate: 0.00509887
	LOSS [training: 0.22204428184996922 | validation: 0.9451194572649415]
	TIME [epoch: 8.31 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4003779826583053		[learning rate: 0.0050865]
		[batch 20/20] avg loss: 0.29064802446746413		[learning rate: 0.0050742]
	Learning Rate: 0.00507421
	LOSS [training: 0.3455130035628847 | validation: 0.1792152260867203]
	TIME [epoch: 8.31 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19914109291255516		[learning rate: 0.0050619]
		[batch 20/20] avg loss: 0.19168111193003184		[learning rate: 0.0050497]
	Learning Rate: 0.00504967
	LOSS [training: 0.1954111024212935 | validation: 0.10955761966977429]
	TIME [epoch: 8.32 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22706536187259058		[learning rate: 0.0050374]
		[batch 20/20] avg loss: 0.2916791144494913		[learning rate: 0.0050253]
	Learning Rate: 0.00502525
	LOSS [training: 0.25937223816104094 | validation: 0.35642669116067527]
	TIME [epoch: 8.34 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21858170910931593		[learning rate: 0.0050131]
		[batch 20/20] avg loss: 0.26502648095181575		[learning rate: 0.005001]
	Learning Rate: 0.00500095
	LOSS [training: 0.24180409503056582 | validation: 0.2847048533173773]
	TIME [epoch: 8.32 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3188972528109084		[learning rate: 0.0049888]
		[batch 20/20] avg loss: 0.2187738356357786		[learning rate: 0.0049768]
	Learning Rate: 0.00497677
	LOSS [training: 0.26883554422334355 | validation: 0.16320791633505258]
	TIME [epoch: 8.31 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23933933700760054		[learning rate: 0.0049647]
		[batch 20/20] avg loss: 0.15254401257072872		[learning rate: 0.0049527]
	Learning Rate: 0.0049527
	LOSS [training: 0.1959416747891647 | validation: 0.14143445676488758]
	TIME [epoch: 8.31 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24406778933694304		[learning rate: 0.0049407]
		[batch 20/20] avg loss: 0.24347493551730798		[learning rate: 0.0049288]
	Learning Rate: 0.00492875
	LOSS [training: 0.24377136242712552 | validation: 0.0912144867451864]
	TIME [epoch: 8.35 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.172415731322561		[learning rate: 0.0049168]
		[batch 20/20] avg loss: 0.19170553166608478		[learning rate: 0.0049049]
	Learning Rate: 0.00490492
	LOSS [training: 0.18206063149432286 | validation: 0.3438646900389365]
	TIME [epoch: 8.31 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19225478355886283		[learning rate: 0.004893]
		[batch 20/20] avg loss: 0.18397360905310273		[learning rate: 0.0048812]
	Learning Rate: 0.0048812
	LOSS [training: 0.18811419630598278 | validation: 0.07347739216691536]
	TIME [epoch: 8.32 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2051290589870828		[learning rate: 0.0048694]
		[batch 20/20] avg loss: 0.13498412593445816		[learning rate: 0.0048576]
	Learning Rate: 0.00485759
	LOSS [training: 0.17005659246077048 | validation: 0.40529245493907773]
	TIME [epoch: 8.32 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26948996767031386		[learning rate: 0.0048458]
		[batch 20/20] avg loss: 0.20596943570776255		[learning rate: 0.0048341]
	Learning Rate: 0.0048341
	LOSS [training: 0.2377297016890382 | validation: 0.44701745062203607]
	TIME [epoch: 8.33 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29229231614723306		[learning rate: 0.0048224]
		[batch 20/20] avg loss: 0.2428728131838705		[learning rate: 0.0048107]
	Learning Rate: 0.00481072
	LOSS [training: 0.26758256466555175 | validation: 0.3250090562299193]
	TIME [epoch: 8.33 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1839112690276455		[learning rate: 0.0047991]
		[batch 20/20] avg loss: 0.24587428203564218		[learning rate: 0.0047875]
	Learning Rate: 0.00478746
	LOSS [training: 0.21489277553164388 | validation: 0.17064785120630588]
	TIME [epoch: 8.32 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2019807821108957		[learning rate: 0.0047759]
		[batch 20/20] avg loss: 0.19430810430372958		[learning rate: 0.0047643]
	Learning Rate: 0.00476431
	LOSS [training: 0.19814444320731264 | validation: 0.09886716077158682]
	TIME [epoch: 8.31 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23068582952191458		[learning rate: 0.0047528]
		[batch 20/20] avg loss: 0.16121561233900647		[learning rate: 0.0047413]
	Learning Rate: 0.00474127
	LOSS [training: 0.1959507209304605 | validation: 0.1389221060484948]
	TIME [epoch: 8.32 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16076330215380524		[learning rate: 0.0047298]
		[batch 20/20] avg loss: 0.17824712076493102		[learning rate: 0.0047183]
	Learning Rate: 0.00471834
	LOSS [training: 0.16950521145936814 | validation: 0.11097952822615546]
	TIME [epoch: 8.34 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2054976130215101		[learning rate: 0.0047069]
		[batch 20/20] avg loss: 0.21669660030730803		[learning rate: 0.0046955]
	Learning Rate: 0.00469553
	LOSS [training: 0.21109710666440903 | validation: 0.26736863741808087]
	TIME [epoch: 8.33 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2220933364836169		[learning rate: 0.0046842]
		[batch 20/20] avg loss: 0.2806412150644125		[learning rate: 0.0046728]
	Learning Rate: 0.00467282
	LOSS [training: 0.2513672757740147 | validation: 0.08741946569745018]
	TIME [epoch: 8.31 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15312574234850845		[learning rate: 0.0046615]
		[batch 20/20] avg loss: 0.22727410751135174		[learning rate: 0.0046502]
	Learning Rate: 0.00465022
	LOSS [training: 0.19019992492993013 | validation: 0.15635445628550393]
	TIME [epoch: 8.32 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.213058718858581		[learning rate: 0.004639]
		[batch 20/20] avg loss: 0.20520529827964581		[learning rate: 0.0046277]
	Learning Rate: 0.00462773
	LOSS [training: 0.20913200856911343 | validation: 0.27202111295871045]
	TIME [epoch: 8.35 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2291961504150108		[learning rate: 0.0046165]
		[batch 20/20] avg loss: 0.18439656481689215		[learning rate: 0.0046054]
	Learning Rate: 0.00460536
	LOSS [training: 0.20679635761595144 | validation: 0.10935561378706031]
	TIME [epoch: 8.32 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18448649708331627		[learning rate: 0.0045942]
		[batch 20/20] avg loss: 0.16093657197303793		[learning rate: 0.0045831]
	Learning Rate: 0.00458308
	LOSS [training: 0.1727115345281771 | validation: 0.22576529878982465]
	TIME [epoch: 8.32 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15194157568108746		[learning rate: 0.004572]
		[batch 20/20] avg loss: 0.19834099369767194		[learning rate: 0.0045609]
	Learning Rate: 0.00456092
	LOSS [training: 0.17514128468937967 | validation: 0.09711987945861654]
	TIME [epoch: 8.31 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19261357413114993		[learning rate: 0.0045499]
		[batch 20/20] avg loss: 0.1677928092445187		[learning rate: 0.0045389]
	Learning Rate: 0.00453887
	LOSS [training: 0.18020319168783433 | validation: 0.3992942363295479]
	TIME [epoch: 8.32 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24490154669182346		[learning rate: 0.0045279]
		[batch 20/20] avg loss: 0.22354591882688438		[learning rate: 0.0045169]
	Learning Rate: 0.00451692
	LOSS [training: 0.23422373275935388 | validation: 0.06790447710471834]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_214.pth
	Model improved!!!
EPOCH 215/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19551867792925043		[learning rate: 0.004506]
		[batch 20/20] avg loss: 0.18020638744379444		[learning rate: 0.0044951]
	Learning Rate: 0.00449507
	LOSS [training: 0.18786253268652245 | validation: 0.4332354533160513]
	TIME [epoch: 8.31 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3073945879610915		[learning rate: 0.0044842]
		[batch 20/20] avg loss: 0.26317151920369486		[learning rate: 0.0044733]
	Learning Rate: 0.00447334
	LOSS [training: 0.28528305358239314 | validation: 0.07902006068585679]
	TIME [epoch: 8.31 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17790062194603246		[learning rate: 0.0044625]
		[batch 20/20] avg loss: 0.20420762409816717		[learning rate: 0.0044517]
	Learning Rate: 0.0044517
	LOSS [training: 0.19105412302209981 | validation: 0.38265396091732873]
	TIME [epoch: 8.32 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26319561442469624		[learning rate: 0.0044409]
		[batch 20/20] avg loss: 0.21597997795732704		[learning rate: 0.0044302]
	Learning Rate: 0.00443018
	LOSS [training: 0.23958779619101164 | validation: 0.10212152518321244]
	TIME [epoch: 8.34 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17939354549791228		[learning rate: 0.0044195]
		[batch 20/20] avg loss: 0.2367436740092216		[learning rate: 0.0044088]
	Learning Rate: 0.00440875
	LOSS [training: 0.2080686097535669 | validation: 0.1501072033202074]
	TIME [epoch: 8.32 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14776570031270753		[learning rate: 0.0043981]
		[batch 20/20] avg loss: 0.24060342213459318		[learning rate: 0.0043874]
	Learning Rate: 0.00438743
	LOSS [training: 0.19418456122365038 | validation: 0.22437582310385407]
	TIME [epoch: 8.31 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2138177615503069		[learning rate: 0.0043768]
		[batch 20/20] avg loss: 0.1865196184540152		[learning rate: 0.0043662]
	Learning Rate: 0.00436622
	LOSS [training: 0.2001686900021611 | validation: 0.14068460704411506]
	TIME [epoch: 8.32 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14455845931808362		[learning rate: 0.0043556]
		[batch 20/20] avg loss: 0.24328971962259976		[learning rate: 0.0043451]
	Learning Rate: 0.0043451
	LOSS [training: 0.19392408947034168 | validation: 0.05769785302511416]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_222.pth
	Model improved!!!
EPOCH 223/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21350503288067166		[learning rate: 0.0043346]
		[batch 20/20] avg loss: 0.16179137745683583		[learning rate: 0.0043241]
	Learning Rate: 0.00432409
	LOSS [training: 0.18764820516875375 | validation: 0.40398232534175565]
	TIME [epoch: 8.31 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19260914895528014		[learning rate: 0.0043136]
		[batch 20/20] avg loss: 0.2699594307684012		[learning rate: 0.0043032]
	Learning Rate: 0.00430318
	LOSS [training: 0.23128428986184066 | validation: 0.2061969254381538]
	TIME [epoch: 8.32 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1790501505127779		[learning rate: 0.0042928]
		[batch 20/20] avg loss: 0.21177001322928768		[learning rate: 0.0042824]
	Learning Rate: 0.00428237
	LOSS [training: 0.19541008187103276 | validation: 0.12381168474495505]
	TIME [epoch: 8.31 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18399697262690812		[learning rate: 0.004272]
		[batch 20/20] avg loss: 0.1995739299707876		[learning rate: 0.0042617]
	Learning Rate: 0.00426166
	LOSS [training: 0.19178545129884783 | validation: 0.18726746463373145]
	TIME [epoch: 8.32 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14995881499822858		[learning rate: 0.0042513]
		[batch 20/20] avg loss: 0.209827719420335		[learning rate: 0.0042411]
	Learning Rate: 0.00424105
	LOSS [training: 0.17989326720928184 | validation: 0.11398242360160069]
	TIME [epoch: 8.34 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19180944897761673		[learning rate: 0.0042308]
		[batch 20/20] avg loss: 0.27459961741692707		[learning rate: 0.0042205]
	Learning Rate: 0.00422054
	LOSS [training: 0.23320453319727194 | validation: 0.11543802940979511]
	TIME [epoch: 8.31 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16824122849054238		[learning rate: 0.0042103]
		[batch 20/20] avg loss: 0.2026546912978477		[learning rate: 0.0042001]
	Learning Rate: 0.00420013
	LOSS [training: 0.18544795989419505 | validation: 0.08006987023074791]
	TIME [epoch: 8.31 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16067198723444945		[learning rate: 0.00419]
		[batch 20/20] avg loss: 0.14808657552956245		[learning rate: 0.0041798]
	Learning Rate: 0.00417982
	LOSS [training: 0.1543792813820059 | validation: 0.07137771663777255]
	TIME [epoch: 8.32 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18002046115423087		[learning rate: 0.0041697]
		[batch 20/20] avg loss: 0.2081244496455262		[learning rate: 0.0041596]
	Learning Rate: 0.00415961
	LOSS [training: 0.19407245539987855 | validation: 0.18236897159349522]
	TIME [epoch: 8.34 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2744692523784861		[learning rate: 0.0041495]
		[batch 20/20] avg loss: 0.13979727816802576		[learning rate: 0.0041395]
	Learning Rate: 0.0041395
	LOSS [training: 0.20713326527325598 | validation: 0.4435319887062964]
	TIME [epoch: 8.33 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2629462468321334		[learning rate: 0.0041295]
		[batch 20/20] avg loss: 0.20041174081409602		[learning rate: 0.0041195]
	Learning Rate: 0.00411948
	LOSS [training: 0.23167899382311466 | validation: 0.24087682439136637]
	TIME [epoch: 8.32 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21187745150379317		[learning rate: 0.0041095]
		[batch 20/20] avg loss: 0.18583302370593438		[learning rate: 0.0040996]
	Learning Rate: 0.00409956
	LOSS [training: 0.19885523760486376 | validation: 0.12344318512290008]
	TIME [epoch: 8.31 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1884176425807748		[learning rate: 0.0040896]
		[batch 20/20] avg loss: 0.2205205108577782		[learning rate: 0.0040797]
	Learning Rate: 0.00407973
	LOSS [training: 0.2044690767192765 | validation: 0.0801776324440809]
	TIME [epoch: 8.35 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17743441276242602		[learning rate: 0.0040699]
		[batch 20/20] avg loss: 0.2099595036894529		[learning rate: 0.00406]
	Learning Rate: 0.00406
	LOSS [training: 0.1936969582259395 | validation: 0.13628962774764322]
	TIME [epoch: 8.32 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23930244591801894		[learning rate: 0.0040502]
		[batch 20/20] avg loss: 0.19955724130492353		[learning rate: 0.0040404]
	Learning Rate: 0.00404037
	LOSS [training: 0.21942984361147128 | validation: 0.26633585477941013]
	TIME [epoch: 8.31 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18878681204027128		[learning rate: 0.0040306]
		[batch 20/20] avg loss: 0.1996963128723133		[learning rate: 0.0040208]
	Learning Rate: 0.00402083
	LOSS [training: 0.1942415624562923 | validation: 0.15491632384595183]
	TIME [epoch: 8.31 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15513513236923474		[learning rate: 0.0040111]
		[batch 20/20] avg loss: 0.1566997154481645		[learning rate: 0.0040014]
	Learning Rate: 0.00400139
	LOSS [training: 0.1559174239086996 | validation: 0.06694913362867146]
	TIME [epoch: 8.32 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16312926788951262		[learning rate: 0.0039917]
		[batch 20/20] avg loss: 0.2035022072454414		[learning rate: 0.003982]
	Learning Rate: 0.00398204
	LOSS [training: 0.18331573756747704 | validation: 0.14841774520306086]
	TIME [epoch: 8.34 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.197117648384083		[learning rate: 0.0039724]
		[batch 20/20] avg loss: 0.17642343110155695		[learning rate: 0.0039628]
	Learning Rate: 0.00396278
	LOSS [training: 0.18677053974281993 | validation: 0.09412852038581587]
	TIME [epoch: 8.31 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14187426632152728		[learning rate: 0.0039532]
		[batch 20/20] avg loss: 0.17173345460260978		[learning rate: 0.0039436]
	Learning Rate: 0.00394362
	LOSS [training: 0.1568038604620685 | validation: 0.06022961546383694]
	TIME [epoch: 8.3 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19493754618401377		[learning rate: 0.0039341]
		[batch 20/20] avg loss: 0.168881864958809		[learning rate: 0.0039245]
	Learning Rate: 0.00392455
	LOSS [training: 0.1819097055714114 | validation: 0.11829148099706677]
	TIME [epoch: 8.3 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29638517680094223		[learning rate: 0.003915]
		[batch 20/20] avg loss: 0.1484116385621286		[learning rate: 0.0039056]
	Learning Rate: 0.00390557
	LOSS [training: 0.22239840768153543 | validation: 0.1529995680820821]
	TIME [epoch: 8.33 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1617206932791503		[learning rate: 0.0038961]
		[batch 20/20] avg loss: 0.22251015096070859		[learning rate: 0.0038867]
	Learning Rate: 0.00388668
	LOSS [training: 0.19211542211992944 | validation: 0.6989486031479781]
	TIME [epoch: 8.3 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2017055985559968		[learning rate: 0.0038773]
		[batch 20/20] avg loss: 0.1233794289478928		[learning rate: 0.0038679]
	Learning Rate: 0.00386789
	LOSS [training: 0.16254251375194478 | validation: 0.15335224362801297]
	TIME [epoch: 8.3 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15952016183166046		[learning rate: 0.0038585]
		[batch 20/20] avg loss: 0.11187836768610933		[learning rate: 0.0038492]
	Learning Rate: 0.00384918
	LOSS [training: 0.13569926475888489 | validation: 0.12652503159671624]
	TIME [epoch: 8.3 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26942748528422117		[learning rate: 0.0038399]
		[batch 20/20] avg loss: 0.21946248704283242		[learning rate: 0.0038306]
	Learning Rate: 0.00383057
	LOSS [training: 0.2444449861635268 | validation: 0.32269141650914446]
	TIME [epoch: 8.32 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21086504721481164		[learning rate: 0.0038213]
		[batch 20/20] avg loss: 0.22507134515387342		[learning rate: 0.003812]
	Learning Rate: 0.00381204
	LOSS [training: 0.2179681961843425 | validation: 0.04398588844956012]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_249.pth
	Model improved!!!
EPOCH 250/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1365011148711429		[learning rate: 0.0038028]
		[batch 20/20] avg loss: 0.2209670811200773		[learning rate: 0.0037936]
	Learning Rate: 0.00379361
	LOSS [training: 0.1787340979956101 | validation: 0.19200675864696834]
	TIME [epoch: 8.29 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22221395398939237		[learning rate: 0.0037844]
		[batch 20/20] avg loss: 0.1761926687549953		[learning rate: 0.0037753]
	Learning Rate: 0.00377526
	LOSS [training: 0.19920331137219388 | validation: 0.20354990096115244]
	TIME [epoch: 8.3 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16443155172968493		[learning rate: 0.0037661]
		[batch 20/20] avg loss: 0.1733953064252814		[learning rate: 0.003757]
	Learning Rate: 0.00375701
	LOSS [training: 0.16891342907748316 | validation: 0.05181472408938932]
	TIME [epoch: 8.29 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14314123302609863		[learning rate: 0.0037479]
		[batch 20/20] avg loss: 0.1435080990432908		[learning rate: 0.0037388]
	Learning Rate: 0.00373884
	LOSS [training: 0.14332466603469468 | validation: 0.20490290088354773]
	TIME [epoch: 8.31 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1352498985108747		[learning rate: 0.0037298]
		[batch 20/20] avg loss: 0.1444316638354096		[learning rate: 0.0037208]
	Learning Rate: 0.00372076
	LOSS [training: 0.13984078117314216 | validation: 0.07777578280712327]
	TIME [epoch: 8.29 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1757754932505536		[learning rate: 0.0037118]
		[batch 20/20] avg loss: 0.11490357599187714		[learning rate: 0.0037028]
	Learning Rate: 0.00370277
	LOSS [training: 0.14533953462121538 | validation: 0.13273524912459098]
	TIME [epoch: 8.28 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09838159963306443		[learning rate: 0.0036938]
		[batch 20/20] avg loss: 0.15668132268765236		[learning rate: 0.0036849]
	Learning Rate: 0.00368486
	LOSS [training: 0.12753146116035838 | validation: 0.06987874284480151]
	TIME [epoch: 8.29 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14430668635386718		[learning rate: 0.0036759]
		[batch 20/20] avg loss: 0.17656848225321836		[learning rate: 0.003667]
	Learning Rate: 0.00366704
	LOSS [training: 0.16043758430354277 | validation: 0.17769418700881548]
	TIME [epoch: 8.32 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19859579241082267		[learning rate: 0.0036582]
		[batch 20/20] avg loss: 0.16308900458631925		[learning rate: 0.0036493]
	Learning Rate: 0.00364931
	LOSS [training: 0.18084239849857095 | validation: 0.15605961982715666]
	TIME [epoch: 8.29 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17305015920915245		[learning rate: 0.0036405]
		[batch 20/20] avg loss: 0.16566923996064709		[learning rate: 0.0036317]
	Learning Rate: 0.00363166
	LOSS [training: 0.16935969958489977 | validation: 0.23001298088089278]
	TIME [epoch: 8.29 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15987628390404163		[learning rate: 0.0036229]
		[batch 20/20] avg loss: 0.16408444759828328		[learning rate: 0.0036141]
	Learning Rate: 0.0036141
	LOSS [training: 0.1619803657511624 | validation: 0.11416392206875076]
	TIME [epoch: 8.28 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15716216800140026		[learning rate: 0.0036053]
		[batch 20/20] avg loss: 0.1140683083125346		[learning rate: 0.0035966]
	Learning Rate: 0.00359662
	LOSS [training: 0.13561523815696747 | validation: 0.05128956594115891]
	TIME [epoch: 8.31 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1686915749102988		[learning rate: 0.0035879]
		[batch 20/20] avg loss: 0.154766805987708		[learning rate: 0.0035792]
	Learning Rate: 0.00357923
	LOSS [training: 0.16172919044900336 | validation: 0.17855102550167232]
	TIME [epoch: 8.29 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19149015977746		[learning rate: 0.0035706]
		[batch 20/20] avg loss: 0.14015104458816502		[learning rate: 0.0035619]
	Learning Rate: 0.00356192
	LOSS [training: 0.16582060218281253 | validation: 0.1144808803775779]
	TIME [epoch: 8.28 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30827249777690147		[learning rate: 0.0035533]
		[batch 20/20] avg loss: 0.1885947198987132		[learning rate: 0.0035447]
	Learning Rate: 0.0035447
	LOSS [training: 0.24843360883780735 | validation: 0.06410777451809734]
	TIME [epoch: 8.28 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1612877637869487		[learning rate: 0.0035361]
		[batch 20/20] avg loss: 0.2268205170741898		[learning rate: 0.0035276]
	Learning Rate: 0.00352755
	LOSS [training: 0.19405414043056923 | validation: 0.059530003402502224]
	TIME [epoch: 8.28 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1536867052013172		[learning rate: 0.003519]
		[batch 20/20] avg loss: 0.1431242226117032		[learning rate: 0.0035105]
	Learning Rate: 0.0035105
	LOSS [training: 0.14840546390651022 | validation: 0.04021941349274526]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_266.pth
	Model improved!!!
EPOCH 267/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13475453014702077		[learning rate: 0.003502]
		[batch 20/20] avg loss: 0.14581949346818784		[learning rate: 0.0034935]
	Learning Rate: 0.00349352
	LOSS [training: 0.14028701180760428 | validation: 0.06963605542851174]
	TIME [epoch: 8.28 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.211070176979479		[learning rate: 0.0034851]
		[batch 20/20] avg loss: 0.11593977816704268		[learning rate: 0.0034766]
	Learning Rate: 0.00347663
	LOSS [training: 0.16350497757326082 | validation: 0.16812333146274114]
	TIME [epoch: 8.28 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1561787809395799		[learning rate: 0.0034682]
		[batch 20/20] avg loss: 0.13650609102441552		[learning rate: 0.0034598]
	Learning Rate: 0.00345981
	LOSS [training: 0.14634243598199775 | validation: 0.08487880958011773]
	TIME [epoch: 8.28 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17968611238441748		[learning rate: 0.0034514]
		[batch 20/20] avg loss: 0.1698009408676974		[learning rate: 0.0034431]
	Learning Rate: 0.00344308
	LOSS [training: 0.17474352662605744 | validation: 0.0996951189669015]
	TIME [epoch: 8.32 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1412687962304709		[learning rate: 0.0034347]
		[batch 20/20] avg loss: 0.18286867581291302		[learning rate: 0.0034264]
	Learning Rate: 0.00342643
	LOSS [training: 0.16206873602169197 | validation: 0.1957040764832312]
	TIME [epoch: 8.28 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15456356948170566		[learning rate: 0.0034181]
		[batch 20/20] avg loss: 0.15107095124268505		[learning rate: 0.0034099]
	Learning Rate: 0.00340986
	LOSS [training: 0.15281726036219537 | validation: 0.1535611744184766]
	TIME [epoch: 8.28 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16638257405806983		[learning rate: 0.0034016]
		[batch 20/20] avg loss: 0.15876555161977446		[learning rate: 0.0033934]
	Learning Rate: 0.00339337
	LOSS [training: 0.16257406283892212 | validation: 0.13291253160140268]
	TIME [epoch: 8.28 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17634312812154923		[learning rate: 0.0033852]
		[batch 20/20] avg loss: 0.2243122884261036		[learning rate: 0.003377]
	Learning Rate: 0.00337696
	LOSS [training: 0.2003277082738264 | validation: 0.08656941650220276]
	TIME [epoch: 8.3 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16682774887204976		[learning rate: 0.0033688]
		[batch 20/20] avg loss: 0.14847932036023656		[learning rate: 0.0033606]
	Learning Rate: 0.00336063
	LOSS [training: 0.15765353461614312 | validation: 0.2057266629728286]
	TIME [epoch: 8.29 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1714705678136346		[learning rate: 0.0033525]
		[batch 20/20] avg loss: 0.25240282223565974		[learning rate: 0.0033444]
	Learning Rate: 0.00334438
	LOSS [training: 0.21193669502464715 | validation: 0.21183037879971567]
	TIME [epoch: 8.28 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12279605959648598		[learning rate: 0.0033363]
		[batch 20/20] avg loss: 0.21120287640925345		[learning rate: 0.0033282]
	Learning Rate: 0.00332821
	LOSS [training: 0.16699946800286972 | validation: 0.07438939906754839]
	TIME [epoch: 8.29 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1930964393349115		[learning rate: 0.0033202]
		[batch 20/20] avg loss: 0.2098334595501791		[learning rate: 0.0033121]
	Learning Rate: 0.00331211
	LOSS [training: 0.20146494944254528 | validation: 0.07322743618567565]
	TIME [epoch: 8.29 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21441323210355953		[learning rate: 0.0033041]
		[batch 20/20] avg loss: 0.16044274502240946		[learning rate: 0.0032961]
	Learning Rate: 0.0032961
	LOSS [training: 0.18742798856298448 | validation: 0.24289535387994676]
	TIME [epoch: 8.31 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1445297156340778		[learning rate: 0.0032881]
		[batch 20/20] avg loss: 0.14977377205473613		[learning rate: 0.0032802]
	Learning Rate: 0.00328016
	LOSS [training: 0.14715174384440693 | validation: 0.14133791884127153]
	TIME [epoch: 8.3 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20352994565058186		[learning rate: 0.0032722]
		[batch 20/20] avg loss: 0.1850537036700937		[learning rate: 0.0032643]
	Learning Rate: 0.0032643
	LOSS [training: 0.19429182466033776 | validation: 0.06892458862796873]
	TIME [epoch: 8.3 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1889288276961225		[learning rate: 0.0032564]
		[batch 20/20] avg loss: 0.17686302210710017		[learning rate: 0.0032485]
	Learning Rate: 0.00324851
	LOSS [training: 0.18289592490161127 | validation: 0.11393540646139294]
	TIME [epoch: 8.29 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13643550144248806		[learning rate: 0.0032406]
		[batch 20/20] avg loss: 0.2083363423420616		[learning rate: 0.0032328]
	Learning Rate: 0.0032328
	LOSS [training: 0.1723859218922748 | validation: 0.14352972337681713]
	TIME [epoch: 8.32 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13171549669945473		[learning rate: 0.003225]
		[batch 20/20] avg loss: 0.1513987920145114		[learning rate: 0.0032172]
	Learning Rate: 0.00321717
	LOSS [training: 0.14155714435698305 | validation: 0.05332860582940306]
	TIME [epoch: 8.3 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22508477340878835		[learning rate: 0.0032094]
		[batch 20/20] avg loss: 0.1732152085805564		[learning rate: 0.0032016]
	Learning Rate: 0.00320161
	LOSS [training: 0.19914999099467237 | validation: 0.05526617601089227]
	TIME [epoch: 8.28 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11439599605355606		[learning rate: 0.0031939]
		[batch 20/20] avg loss: 0.17105569428254114		[learning rate: 0.0031861]
	Learning Rate: 0.00318613
	LOSS [training: 0.1427258451680486 | validation: 0.06267161161412027]
	TIME [epoch: 8.29 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16204450208474308		[learning rate: 0.0031784]
		[batch 20/20] avg loss: 0.1724009411452172		[learning rate: 0.0031707]
	Learning Rate: 0.00317072
	LOSS [training: 0.16722272161498014 | validation: 0.1414883248913628]
	TIME [epoch: 8.29 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15321155359022412		[learning rate: 0.003163]
		[batch 20/20] avg loss: 0.14885549956242689		[learning rate: 0.0031554]
	Learning Rate: 0.00315539
	LOSS [training: 0.1510335265763255 | validation: 0.07469179165662476]
	TIME [epoch: 8.3 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13586527843519394		[learning rate: 0.0031477]
		[batch 20/20] avg loss: 0.14797989029041386		[learning rate: 0.0031401]
	Learning Rate: 0.00314013
	LOSS [training: 0.14192258436280392 | validation: 0.08398912857358586]
	TIME [epoch: 8.28 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17651762059795667		[learning rate: 0.0031325]
		[batch 20/20] avg loss: 0.16168673675829587		[learning rate: 0.0031249]
	Learning Rate: 0.00312494
	LOSS [training: 0.1691021786781263 | validation: 0.12650283078003322]
	TIME [epoch: 8.3 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21674889744087023		[learning rate: 0.0031174]
		[batch 20/20] avg loss: 0.11788211337722823		[learning rate: 0.0031098]
	Learning Rate: 0.00310983
	LOSS [training: 0.16731550540904921 | validation: 0.09656670432331786]
	TIME [epoch: 8.29 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12034177267909536		[learning rate: 0.0031023]
		[batch 20/20] avg loss: 0.11336363531161046		[learning rate: 0.0030948]
	Learning Rate: 0.00309479
	LOSS [training: 0.11685270399535293 | validation: 0.08201670802286054]
	TIME [epoch: 8.32 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12470468050692651		[learning rate: 0.0030873]
		[batch 20/20] avg loss: 0.1271369979216513		[learning rate: 0.0030798]
	Learning Rate: 0.00307983
	LOSS [training: 0.12592083921428893 | validation: 0.12487151703689352]
	TIME [epoch: 8.29 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14743180237451176		[learning rate: 0.0030724]
		[batch 20/20] avg loss: 0.14695477526823306		[learning rate: 0.0030649]
	Learning Rate: 0.00306493
	LOSS [training: 0.14719328882137245 | validation: 0.10349156983475438]
	TIME [epoch: 8.28 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11857943767603205		[learning rate: 0.0030575]
		[batch 20/20] avg loss: 0.12482472576425627		[learning rate: 0.0030501]
	Learning Rate: 0.00305011
	LOSS [training: 0.12170208172014414 | validation: 0.19152652246553742]
	TIME [epoch: 8.29 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1669821980073966		[learning rate: 0.0030427]
		[batch 20/20] avg loss: 0.1405498593214075		[learning rate: 0.0030354]
	Learning Rate: 0.00303536
	LOSS [training: 0.15376602866440206 | validation: 0.09362877525238672]
	TIME [epoch: 8.31 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14615184954682828		[learning rate: 0.003028]
		[batch 20/20] avg loss: 0.2398537731679339		[learning rate: 0.0030207]
	Learning Rate: 0.00302068
	LOSS [training: 0.19300281135738112 | validation: 0.2466443055244722]
	TIME [epoch: 8.3 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14226224822422368		[learning rate: 0.0030134]
		[batch 20/20] avg loss: 0.1584856025237723		[learning rate: 0.0030061]
	Learning Rate: 0.00300608
	LOSS [training: 0.150373925373998 | validation: 0.09586117161465016]
	TIME [epoch: 8.28 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16015463976737795		[learning rate: 0.0029988]
		[batch 20/20] avg loss: 0.14234596720293094		[learning rate: 0.0029915]
	Learning Rate: 0.00299154
	LOSS [training: 0.15125030348515445 | validation: 0.22479233481344868]
	TIME [epoch: 8.29 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15709735934042582		[learning rate: 0.0029843]
		[batch 20/20] avg loss: 0.11844705916542317		[learning rate: 0.0029771]
	Learning Rate: 0.00297707
	LOSS [training: 0.1377722092529245 | validation: 0.09961311175053644]
	TIME [epoch: 8.29 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13616887898091806		[learning rate: 0.0029699]
		[batch 20/20] avg loss: 0.14334984308230636		[learning rate: 0.0029627]
	Learning Rate: 0.00296268
	LOSS [training: 0.13975936103161218 | validation: 0.16521833013698517]
	TIME [epoch: 8.31 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21966139947845703		[learning rate: 0.0029555]
		[batch 20/20] avg loss: 0.1349555929559514		[learning rate: 0.0029483]
	Learning Rate: 0.00294835
	LOSS [training: 0.1773084962172042 | validation: 0.06367894646021283]
	TIME [epoch: 8.28 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14659592444287306		[learning rate: 0.0029412]
		[batch 20/20] avg loss: 0.19145704160868907		[learning rate: 0.0029341]
	Learning Rate: 0.00293409
	LOSS [training: 0.16902648302578105 | validation: 0.06322936787136076]
	TIME [epoch: 8.29 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1611009045947262		[learning rate: 0.002927]
		[batch 20/20] avg loss: 0.1054957422166273		[learning rate: 0.0029199]
	Learning Rate: 0.0029199
	LOSS [training: 0.13329832340567677 | validation: 0.07585573055342025]
	TIME [epoch: 8.29 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13162651713219548		[learning rate: 0.0029128]
		[batch 20/20] avg loss: 0.14691865260090292		[learning rate: 0.0029058]
	Learning Rate: 0.00290578
	LOSS [training: 0.1392725848665492 | validation: 0.10492031452530698]
	TIME [epoch: 8.31 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14770824711822564		[learning rate: 0.0028987]
		[batch 20/20] avg loss: 0.17594859455027465		[learning rate: 0.0028917]
	Learning Rate: 0.00289173
	LOSS [training: 0.16182842083425014 | validation: 0.08761816853644103]
	TIME [epoch: 8.3 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17790896575444212		[learning rate: 0.0028847]
		[batch 20/20] avg loss: 0.13751566406001767		[learning rate: 0.0028777]
	Learning Rate: 0.00287775
	LOSS [training: 0.15771231490722992 | validation: 0.06422469205432396]
	TIME [epoch: 8.28 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18131779193550443		[learning rate: 0.0028708]
		[batch 20/20] avg loss: 0.18993917125761997		[learning rate: 0.0028638]
	Learning Rate: 0.00286383
	LOSS [training: 0.1856284815965622 | validation: 0.05386000533915725]
	TIME [epoch: 8.29 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1348820682687962		[learning rate: 0.0028569]
		[batch 20/20] avg loss: 0.12943189542974037		[learning rate: 0.00285]
	Learning Rate: 0.00284998
	LOSS [training: 0.1321569818492683 | validation: 0.18896783988039612]
	TIME [epoch: 8.3 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18657733410552882		[learning rate: 0.0028431]
		[batch 20/20] avg loss: 0.21788616560485682		[learning rate: 0.0028362]
	Learning Rate: 0.0028362
	LOSS [training: 0.2022317498551928 | validation: 0.2224146528167613]
	TIME [epoch: 8.3 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1083413884269564		[learning rate: 0.0028293]
		[batch 20/20] avg loss: 0.12374882948360184		[learning rate: 0.0028225]
	Learning Rate: 0.00282248
	LOSS [training: 0.11604510895527913 | validation: 0.24837932510528204]
	TIME [epoch: 8.3 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1620306968506791		[learning rate: 0.0028157]
		[batch 20/20] avg loss: 0.19851265745345015		[learning rate: 0.0028088]
	Learning Rate: 0.00280884
	LOSS [training: 0.18027167715206463 | validation: 0.0886260111422003]
	TIME [epoch: 8.29 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11260706887164311		[learning rate: 0.002802]
		[batch 20/20] avg loss: 0.11076887069398286		[learning rate: 0.0027953]
	Learning Rate: 0.00279525
	LOSS [training: 0.11168796978281299 | validation: 0.049759502955878325]
	TIME [epoch: 8.29 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15886096595948823		[learning rate: 0.0027885]
		[batch 20/20] avg loss: 0.1836624420507204		[learning rate: 0.0027817]
	Learning Rate: 0.00278174
	LOSS [training: 0.17126170400510438 | validation: 0.05682998778454365]
	TIME [epoch: 8.31 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13357254206279248		[learning rate: 0.002775]
		[batch 20/20] avg loss: 0.16927477184896347		[learning rate: 0.0027683]
	Learning Rate: 0.00276828
	LOSS [training: 0.15142365695587795 | validation: 0.092640607818059]
	TIME [epoch: 8.29 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11340307080337746		[learning rate: 0.0027616]
		[batch 20/20] avg loss: 0.09553000991457566		[learning rate: 0.0027549]
	Learning Rate: 0.0027549
	LOSS [training: 0.10446654035897658 | validation: 0.3624153608200238]
	TIME [epoch: 8.29 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13081192557042845		[learning rate: 0.0027482]
		[batch 20/20] avg loss: 0.14663644522943653		[learning rate: 0.0027416]
	Learning Rate: 0.00274157
	LOSS [training: 0.13872418539993253 | validation: 0.061938815051840006]
	TIME [epoch: 8.3 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15863110024064403		[learning rate: 0.0027349]
		[batch 20/20] avg loss: 0.14003267551474302		[learning rate: 0.0027283]
	Learning Rate: 0.00272832
	LOSS [training: 0.14933188787769353 | validation: 0.0566648240955531]
	TIME [epoch: 8.32 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1079625806501245		[learning rate: 0.0027217]
		[batch 20/20] avg loss: 0.17039009002107003		[learning rate: 0.0027151]
	Learning Rate: 0.00271512
	LOSS [training: 0.13917633533559723 | validation: 0.13888171084527032]
	TIME [epoch: 8.29 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12582893445352367		[learning rate: 0.0027086]
		[batch 20/20] avg loss: 0.1326992917009155		[learning rate: 0.002702]
	Learning Rate: 0.00270199
	LOSS [training: 0.12926411307721958 | validation: 0.09822204418090337]
	TIME [epoch: 8.29 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15755573138854945		[learning rate: 0.0026955]
		[batch 20/20] avg loss: 0.12801180887533953		[learning rate: 0.0026889]
	Learning Rate: 0.00268893
	LOSS [training: 0.1427837701319445 | validation: 0.08044144900710257]
	TIME [epoch: 8.3 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11539790229485511		[learning rate: 0.0026824]
		[batch 20/20] avg loss: 0.15326306465217576		[learning rate: 0.0026759]
	Learning Rate: 0.00267592
	LOSS [training: 0.13433048347351545 | validation: 0.12421277524486686]
	TIME [epoch: 8.29 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17470900090406488		[learning rate: 0.0026694]
		[batch 20/20] avg loss: 0.14935693776211206		[learning rate: 0.002663]
	Learning Rate: 0.00266298
	LOSS [training: 0.16203296933308853 | validation: 0.05326482566377774]
	TIME [epoch: 8.32 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14403855492004455		[learning rate: 0.0026565]
		[batch 20/20] avg loss: 0.18849246541822348		[learning rate: 0.0026501]
	Learning Rate: 0.00265011
	LOSS [training: 0.16626551016913407 | validation: 0.09225298657114367]
	TIME [epoch: 8.29 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12359658753241301		[learning rate: 0.0026437]
		[batch 20/20] avg loss: 0.14518346507956476		[learning rate: 0.0026373]
	Learning Rate: 0.00263729
	LOSS [training: 0.13439002630598887 | validation: 0.038238962580562856]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_325.pth
	Model improved!!!
EPOCH 326/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14688013204012745		[learning rate: 0.0026309]
		[batch 20/20] avg loss: 0.10679445896772621		[learning rate: 0.0026245]
	Learning Rate: 0.00262454
	LOSS [training: 0.1268372955039268 | validation: 0.11977073563243648]
	TIME [epoch: 8.29 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2688002325449641		[learning rate: 0.0026182]
		[batch 20/20] avg loss: 0.17450564290211254		[learning rate: 0.0026118]
	Learning Rate: 0.00261184
	LOSS [training: 0.22165293772353833 | validation: 0.0689822120155255]
	TIME [epoch: 8.31 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1312901132226091		[learning rate: 0.0026055]
		[batch 20/20] avg loss: 0.10501845341002465		[learning rate: 0.0025992]
	Learning Rate: 0.00259921
	LOSS [training: 0.11815428331631687 | validation: 0.08759177138078095]
	TIME [epoch: 8.28 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18123875475882992		[learning rate: 0.0025929]
		[batch 20/20] avg loss: 0.12490171321490799		[learning rate: 0.0025866]
	Learning Rate: 0.00258664
	LOSS [training: 0.15307023398686898 | validation: 0.24201169653382956]
	TIME [epoch: 8.28 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11961469755551427		[learning rate: 0.0025804]
		[batch 20/20] avg loss: 0.1353841075870921		[learning rate: 0.0025741]
	Learning Rate: 0.00257414
	LOSS [training: 0.12749940257130318 | validation: 0.08647728598152077]
	TIME [epoch: 8.28 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1531862960467601		[learning rate: 0.0025679]
		[batch 20/20] avg loss: 0.187457658293542		[learning rate: 0.0025617]
	Learning Rate: 0.00256169
	LOSS [training: 0.17032197717015105 | validation: 0.046413144962851975]
	TIME [epoch: 8.31 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14575395015146564		[learning rate: 0.0025555]
		[batch 20/20] avg loss: 0.19857755227255958		[learning rate: 0.0025493]
	Learning Rate: 0.0025493
	LOSS [training: 0.1721657512120126 | validation: 0.18155649079334607]
	TIME [epoch: 8.29 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14468671331357713		[learning rate: 0.0025431]
		[batch 20/20] avg loss: 0.4403127405440032		[learning rate: 0.002537]
	Learning Rate: 0.00253697
	LOSS [training: 0.2924997269287902 | validation: 0.2588934022761593]
	TIME [epoch: 8.29 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16962839454742223		[learning rate: 0.0025308]
		[batch 20/20] avg loss: 0.15813284805123573		[learning rate: 0.0025247]
	Learning Rate: 0.0025247
	LOSS [training: 0.16388062129932898 | validation: 0.16644890474786325]
	TIME [epoch: 8.28 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15892840675701403		[learning rate: 0.0025186]
		[batch 20/20] avg loss: 0.15332047962120407		[learning rate: 0.0025125]
	Learning Rate: 0.0025125
	LOSS [training: 0.15612444318910906 | validation: 0.07089146697479234]
	TIME [epoch: 8.29 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1299511433673075		[learning rate: 0.0025064]
		[batch 20/20] avg loss: 0.15746254504539325		[learning rate: 0.0025003]
	Learning Rate: 0.00250035
	LOSS [training: 0.14370684420635038 | validation: 0.3110531863683385]
	TIME [epoch: 8.31 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18859313377973		[learning rate: 0.0024943]
		[batch 20/20] avg loss: 0.16872692370288922		[learning rate: 0.0024883]
	Learning Rate: 0.00248825
	LOSS [training: 0.1786600287413096 | validation: 0.05645068245596222]
	TIME [epoch: 8.28 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18825973740717972		[learning rate: 0.0024822]
		[batch 20/20] avg loss: 0.16626692122310555		[learning rate: 0.0024762]
	Learning Rate: 0.00247622
	LOSS [training: 0.1772633293151426 | validation: 0.08178254739725055]
	TIME [epoch: 8.28 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22143784351324408		[learning rate: 0.0024702]
		[batch 20/20] avg loss: 0.23122025545170274		[learning rate: 0.0024642]
	Learning Rate: 0.00246425
	LOSS [training: 0.2263290494824734 | validation: 0.08215554962358435]
	TIME [epoch: 8.28 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15697503384570793		[learning rate: 0.0024583]
		[batch 20/20] avg loss: 0.2258057590767734		[learning rate: 0.0024523]
	Learning Rate: 0.00245233
	LOSS [training: 0.19139039646124065 | validation: 0.06809295011027801]
	TIME [epoch: 8.33 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24400467005464538		[learning rate: 0.0024464]
		[batch 20/20] avg loss: 0.16223114174020364		[learning rate: 0.0024405]
	Learning Rate: 0.00244047
	LOSS [training: 0.20311790589742448 | validation: 0.18944109690899236]
	TIME [epoch: 8.28 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13550051550802172		[learning rate: 0.0024346]
		[batch 20/20] avg loss: 0.19035970999010943		[learning rate: 0.0024287]
	Learning Rate: 0.00242867
	LOSS [training: 0.16293011274906555 | validation: 0.19915454247825376]
	TIME [epoch: 8.3 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12603776349836268		[learning rate: 0.0024228]
		[batch 20/20] avg loss: 0.19691367662544706		[learning rate: 0.0024169]
	Learning Rate: 0.00241693
	LOSS [training: 0.16147572006190486 | validation: 0.14013736320624964]
	TIME [epoch: 8.29 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14412733102164893		[learning rate: 0.0024111]
		[batch 20/20] avg loss: 0.1831293125825911		[learning rate: 0.0024052]
	Learning Rate: 0.00240524
	LOSS [training: 0.16362832180212 | validation: 0.10188921297035271]
	TIME [epoch: 8.31 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15726643215683594		[learning rate: 0.0023994]
		[batch 20/20] avg loss: 0.18196280306221838		[learning rate: 0.0023936]
	Learning Rate: 0.00239361
	LOSS [training: 0.16961461760952715 | validation: 0.1803258482877727]
	TIME [epoch: 8.29 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24876898498307248		[learning rate: 0.0023878]
		[batch 20/20] avg loss: 0.11154015801017376		[learning rate: 0.002382]
	Learning Rate: 0.00238203
	LOSS [training: 0.18015457149662312 | validation: 0.07588471195434895]
	TIME [epoch: 8.29 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11346771637155859		[learning rate: 0.0023763]
		[batch 20/20] avg loss: 0.14807738720197847		[learning rate: 0.0023705]
	Learning Rate: 0.00237051
	LOSS [training: 0.13077255178676855 | validation: 0.13238742688919394]
	TIME [epoch: 8.29 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12054333714833591		[learning rate: 0.0023648]
		[batch 20/20] avg loss: 0.14026958215808408		[learning rate: 0.002359]
	Learning Rate: 0.00235905
	LOSS [training: 0.13040645965321 | validation: 0.07248152159899893]
	TIME [epoch: 8.29 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1431234430270895		[learning rate: 0.0023533]
		[batch 20/20] avg loss: 0.14753603907642374		[learning rate: 0.0023476]
	Learning Rate: 0.00234764
	LOSS [training: 0.1453297410517566 | validation: 0.1775709456702083]
	TIME [epoch: 8.3 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13369677585208023		[learning rate: 0.002342]
		[batch 20/20] avg loss: 0.15665082094529564		[learning rate: 0.0023363]
	Learning Rate: 0.00233629
	LOSS [training: 0.1451737983986879 | validation: 0.10544893066222913]
	TIME [epoch: 8.27 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15958243813891376		[learning rate: 0.0023306]
		[batch 20/20] avg loss: 0.12634606309505894		[learning rate: 0.002325]
	Learning Rate: 0.00232499
	LOSS [training: 0.14296425061698637 | validation: 0.14120089722929796]
	TIME [epoch: 8.28 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13383220609955498		[learning rate: 0.0023194]
		[batch 20/20] avg loss: 0.12368994020484154		[learning rate: 0.0023137]
	Learning Rate: 0.00231375
	LOSS [training: 0.12876107315219826 | validation: 0.04387430833345975]
	TIME [epoch: 8.28 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16632611433103112		[learning rate: 0.0023081]
		[batch 20/20] avg loss: 0.1905623968095505		[learning rate: 0.0023026]
	Learning Rate: 0.00230256
	LOSS [training: 0.17844425557029078 | validation: 0.33724780046330277]
	TIME [epoch: 8.3 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13546703271674648		[learning rate: 0.002297]
		[batch 20/20] avg loss: 0.15743428112613997		[learning rate: 0.0022914]
	Learning Rate: 0.00229142
	LOSS [training: 0.1464506569214432 | validation: 0.10887420615523037]
	TIME [epoch: 8.28 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16849217453160636		[learning rate: 0.0022859]
		[batch 20/20] avg loss: 0.16467622588618408		[learning rate: 0.0022803]
	Learning Rate: 0.00228034
	LOSS [training: 0.16658420020889525 | validation: 0.25093235195909835]
	TIME [epoch: 8.28 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19424091900792365		[learning rate: 0.0022748]
		[batch 20/20] avg loss: 0.15706171236914968		[learning rate: 0.0022693]
	Learning Rate: 0.00226931
	LOSS [training: 0.17565131568853667 | validation: 0.16751376274434204]
	TIME [epoch: 8.28 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16965261770318477		[learning rate: 0.0022638]
		[batch 20/20] avg loss: 0.12176185780716262		[learning rate: 0.0022583]
	Learning Rate: 0.00225834
	LOSS [training: 0.1457072377551737 | validation: 0.24288721479600378]
	TIME [epoch: 8.29 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2009524962470966		[learning rate: 0.0022529]
		[batch 20/20] avg loss: 0.12619139405894364		[learning rate: 0.0022474]
	Learning Rate: 0.00224742
	LOSS [training: 0.1635719451530201 | validation: 0.20713631104867025]
	TIME [epoch: 8.3 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21468511585841027		[learning rate: 0.002242]
		[batch 20/20] avg loss: 0.13927431777062443		[learning rate: 0.0022366]
	Learning Rate: 0.00223655
	LOSS [training: 0.17697971681451732 | validation: 0.06654304557022521]
	TIME [epoch: 8.28 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17773844115383805		[learning rate: 0.0022311]
		[batch 20/20] avg loss: 0.11998374004045745		[learning rate: 0.0022257]
	Learning Rate: 0.00222574
	LOSS [training: 0.14886109059714775 | validation: 0.1271261591657699]
	TIME [epoch: 8.28 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14373823965991098		[learning rate: 0.0022203]
		[batch 20/20] avg loss: 0.1600374574614618		[learning rate: 0.002215]
	Learning Rate: 0.00221497
	LOSS [training: 0.1518878485606864 | validation: 0.07417629738138071]
	TIME [epoch: 8.28 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16151776819099087		[learning rate: 0.0022096]
		[batch 20/20] avg loss: 0.14888286773913834		[learning rate: 0.0022043]
	Learning Rate: 0.00220426
	LOSS [training: 0.15520031796506456 | validation: 0.12363155769692065]
	TIME [epoch: 8.3 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12124674925287685		[learning rate: 0.0021989]
		[batch 20/20] avg loss: 0.13087739689465958		[learning rate: 0.0021936]
	Learning Rate: 0.0021936
	LOSS [training: 0.1260620730737682 | validation: 0.10798848555819954]
	TIME [epoch: 8.28 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12347819360059727		[learning rate: 0.0021883]
		[batch 20/20] avg loss: 0.17468983580887681		[learning rate: 0.002183]
	Learning Rate: 0.00218299
	LOSS [training: 0.149084014704737 | validation: 0.1667027291689748]
	TIME [epoch: 8.28 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13611702823883415		[learning rate: 0.0021777]
		[batch 20/20] avg loss: 0.12852576510847274		[learning rate: 0.0021724]
	Learning Rate: 0.00217244
	LOSS [training: 0.13232139667365345 | validation: 0.16937502195483528]
	TIME [epoch: 8.28 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10350682892046008		[learning rate: 0.0021672]
		[batch 20/20] avg loss: 0.13809415738712702		[learning rate: 0.0021619]
	Learning Rate: 0.00216193
	LOSS [training: 0.12080049315379353 | validation: 0.0610985097362338]
	TIME [epoch: 8.3 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1252048991973085		[learning rate: 0.0021567]
		[batch 20/20] avg loss: 0.12718600738804797		[learning rate: 0.0021515]
	Learning Rate: 0.00215148
	LOSS [training: 0.12619545329267823 | validation: 0.07853486269248186]
	TIME [epoch: 8.28 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13236805419695905		[learning rate: 0.0021463]
		[batch 20/20] avg loss: 0.13035293038882118		[learning rate: 0.0021411]
	Learning Rate: 0.00214107
	LOSS [training: 0.13136049229289012 | validation: 0.11026191206253273]
	TIME [epoch: 8.28 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12124769101257349		[learning rate: 0.0021359]
		[batch 20/20] avg loss: 0.13470059271848875		[learning rate: 0.0021307]
	Learning Rate: 0.00213072
	LOSS [training: 0.1279741418655311 | validation: 0.23546878649252173]
	TIME [epoch: 8.28 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.150432433423458		[learning rate: 0.0021256]
		[batch 20/20] avg loss: 0.14323655475945454		[learning rate: 0.0021204]
	Learning Rate: 0.00212042
	LOSS [training: 0.14683449409145624 | validation: 0.10189198814811463]
	TIME [epoch: 8.28 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12598954305653307		[learning rate: 0.0021153]
		[batch 20/20] avg loss: 0.32575808865346845		[learning rate: 0.0021102]
	Learning Rate: 0.00211016
	LOSS [training: 0.22587381585500074 | validation: 0.07279018038310353]
	TIME [epoch: 8.31 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2545959330536844		[learning rate: 0.0021051]
		[batch 20/20] avg loss: 0.21801081584111565		[learning rate: 0.0021]
	Learning Rate: 0.00209996
	LOSS [training: 0.2363033744474 | validation: 0.12884872483204968]
	TIME [epoch: 8.28 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1320201847198369		[learning rate: 0.0020949]
		[batch 20/20] avg loss: 0.15458964372092096		[learning rate: 0.0020898]
	Learning Rate: 0.0020898
	LOSS [training: 0.14330491422037892 | validation: 0.06687015140874618]
	TIME [epoch: 8.28 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16813721987987137		[learning rate: 0.0020847]
		[batch 20/20] avg loss: 0.3536977871712654		[learning rate: 0.0020797]
	Learning Rate: 0.0020797
	LOSS [training: 0.26091750352556836 | validation: 0.2665185950937851]
	TIME [epoch: 8.28 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4564105855511807		[learning rate: 0.0020747]
		[batch 20/20] avg loss: 0.3141691694625732		[learning rate: 0.0020696]
	Learning Rate: 0.00206964
	LOSS [training: 0.38528987750687693 | validation: 0.5484785609878673]
	TIME [epoch: 8.3 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.32337404966260674		[learning rate: 0.0020646]
		[batch 20/20] avg loss: 0.18796925856667324		[learning rate: 0.0020596]
	Learning Rate: 0.00205963
	LOSS [training: 0.25567165411463993 | validation: 0.12061757430895387]
	TIME [epoch: 8.29 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20313335302105323		[learning rate: 0.0020546]
		[batch 20/20] avg loss: 0.1975794927373235		[learning rate: 0.0020497]
	Learning Rate: 0.00204967
	LOSS [training: 0.20035642287918837 | validation: 0.12519932708863415]
	TIME [epoch: 8.28 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18147801984200324		[learning rate: 0.0020447]
		[batch 20/20] avg loss: 0.26839949187202883		[learning rate: 0.0020398]
	Learning Rate: 0.00203976
	LOSS [training: 0.224938755857016 | validation: 0.37412282704533906]
	TIME [epoch: 8.28 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17725136222311794		[learning rate: 0.0020348]
		[batch 20/20] avg loss: 0.1850501147415618		[learning rate: 0.0020299]
	Learning Rate: 0.0020299
	LOSS [training: 0.1811507384823399 | validation: 0.28340252112338926]
	TIME [epoch: 8.3 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3683254487251285		[learning rate: 0.002025]
		[batch 20/20] avg loss: 0.19669130787043526		[learning rate: 0.0020201]
	Learning Rate: 0.00202008
	LOSS [training: 0.28250837829778186 | validation: 0.20696340231342508]
	TIME [epoch: 8.29 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30755768163383373		[learning rate: 0.0020152]
		[batch 20/20] avg loss: 0.32444593736922345		[learning rate: 0.0020103]
	Learning Rate: 0.00201031
	LOSS [training: 0.3160018095015287 | validation: 0.09607995727803305]
	TIME [epoch: 8.28 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13435615339781745		[learning rate: 0.0020054]
		[batch 20/20] avg loss: 0.26777304296564863		[learning rate: 0.0020006]
	Learning Rate: 0.00200059
	LOSS [training: 0.20106459818173303 | validation: 0.8936164254900135]
	TIME [epoch: 8.28 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2653068049918308		[learning rate: 0.0019957]
		[batch 20/20] avg loss: 0.3701149684436298		[learning rate: 0.0019909]
	Learning Rate: 0.00199091
	LOSS [training: 0.3177108867177303 | validation: 0.4965774059580153]
	TIME [epoch: 8.28 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.449551876870677		[learning rate: 0.0019861]
		[batch 20/20] avg loss: 0.37667112016199805		[learning rate: 0.0019813]
	Learning Rate: 0.00198129
	LOSS [training: 0.4131114985163376 | validation: 0.24133350936162604]
	TIME [epoch: 8.31 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20835426526513498		[learning rate: 0.0019765]
		[batch 20/20] avg loss: 0.17498673767097003		[learning rate: 0.0019717]
	Learning Rate: 0.00197171
	LOSS [training: 0.19167050146805248 | validation: 0.1952615663264946]
	TIME [epoch: 8.28 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22854583918360688		[learning rate: 0.0019669]
		[batch 20/20] avg loss: 0.28556193527967827		[learning rate: 0.0019622]
	Learning Rate: 0.00196217
	LOSS [training: 0.2570538872316425 | validation: 0.3284315266203157]
	TIME [epoch: 8.28 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3085718415701292		[learning rate: 0.0019574]
		[batch 20/20] avg loss: 0.4230075850807419		[learning rate: 0.0019527]
	Learning Rate: 0.00195268
	LOSS [training: 0.36578971332543553 | validation: 0.1407647929227196]
	TIME [epoch: 8.28 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3493897736226962		[learning rate: 0.001948]
		[batch 20/20] avg loss: 0.34150988716607716		[learning rate: 0.0019432]
	Learning Rate: 0.00194324
	LOSS [training: 0.34544983039438665 | validation: 0.14021742715003802]
	TIME [epoch: 8.31 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27343011654564525		[learning rate: 0.0019385]
		[batch 20/20] avg loss: 0.2483180117742994		[learning rate: 0.0019338]
	Learning Rate: 0.00193384
	LOSS [training: 0.2608740641599722 | validation: 0.19123972064388667]
	TIME [epoch: 8.28 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4458779459370505		[learning rate: 0.0019292]
		[batch 20/20] avg loss: 0.29753391328690315		[learning rate: 0.0019245]
	Learning Rate: 0.00192449
	LOSS [training: 0.37170592961197685 | validation: 0.454683659705982]
	TIME [epoch: 8.27 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2550222151030158		[learning rate: 0.0019198]
		[batch 20/20] avg loss: 0.26561624666396033		[learning rate: 0.0019152]
	Learning Rate: 0.00191518
	LOSS [training: 0.26031923088348813 | validation: 0.3049467833281593]
	TIME [epoch: 8.28 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19492634809159226		[learning rate: 0.0019105]
		[batch 20/20] avg loss: 0.22638388217405248		[learning rate: 0.0019059]
	Learning Rate: 0.00190592
	LOSS [training: 0.21065511513282237 | validation: 0.2703791411004224]
	TIME [epoch: 8.3 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3985506339539198		[learning rate: 0.0019013]
		[batch 20/20] avg loss: 0.308113272496801		[learning rate: 0.0018967]
	Learning Rate: 0.00189671
	LOSS [training: 0.3533319532253603 | validation: 0.4247270762758162]
	TIME [epoch: 8.3 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.41877994308511746		[learning rate: 0.0018921]
		[batch 20/20] avg loss: 0.4284868801293342		[learning rate: 0.0018875]
	Learning Rate: 0.00188753
	LOSS [training: 0.4236334116072258 | validation: 0.767858211570382]
	TIME [epoch: 8.28 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6026637847610334		[learning rate: 0.001883]
		[batch 20/20] avg loss: 0.32559342091107496		[learning rate: 0.0018784]
	Learning Rate: 0.00187841
	LOSS [training: 0.46412860283605417 | validation: 0.42410122830931213]
	TIME [epoch: 8.28 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6314348088591214		[learning rate: 0.0018739]
		[batch 20/20] avg loss: 0.32387876436685004		[learning rate: 0.0018693]
	Learning Rate: 0.00186932
	LOSS [training: 0.47765678661298566 | validation: 0.3116124107985052]
	TIME [epoch: 8.28 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3055432971663129		[learning rate: 0.0018648]
		[batch 20/20] avg loss: 0.20441951324867272		[learning rate: 0.0018603]
	Learning Rate: 0.00186028
	LOSS [training: 0.2549814052074928 | validation: 0.16965898248842193]
	TIME [epoch: 8.31 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18610401011684363		[learning rate: 0.0018558]
		[batch 20/20] avg loss: 0.435970566088283		[learning rate: 0.0018513]
	Learning Rate: 0.00185129
	LOSS [training: 0.3110372881025633 | validation: 0.24721212636778886]
	TIME [epoch: 8.29 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6497820560215046		[learning rate: 0.0018468]
		[batch 20/20] avg loss: 0.5308299809278527		[learning rate: 0.0018423]
	Learning Rate: 0.00184233
	LOSS [training: 0.5903060184746787 | validation: 0.26413633083772203]
	TIME [epoch: 8.28 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4154337136263312		[learning rate: 0.0018379]
		[batch 20/20] avg loss: 0.8384837670438559		[learning rate: 0.0018334]
	Learning Rate: 0.00183343
	LOSS [training: 0.6269587403350934 | validation: 0.42438349934055986]
	TIME [epoch: 8.28 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5352445296255688		[learning rate: 0.001829]
		[batch 20/20] avg loss: 0.5501265565035535		[learning rate: 0.0018246]
	Learning Rate: 0.00182456
	LOSS [training: 0.5426855430645611 | validation: 0.5943782302467753]
	TIME [epoch: 8.3 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7866174634363114		[learning rate: 0.0018201]
		[batch 20/20] avg loss: 0.4298843008065175		[learning rate: 0.0018157]
	Learning Rate: 0.00181574
	LOSS [training: 0.6082508821214145 | validation: 0.5765711208962264]
	TIME [epoch: 8.28 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5463945197936797		[learning rate: 0.0018113]
		[batch 20/20] avg loss: 0.8483959969957512		[learning rate: 0.001807]
	Learning Rate: 0.00180696
	LOSS [training: 0.6973952583947154 | validation: 0.4074686663146625]
	TIME [epoch: 8.28 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.43853810903309787		[learning rate: 0.0018026]
		[batch 20/20] avg loss: 0.8600934572019714		[learning rate: 0.0017982]
	Learning Rate: 0.00179822
	LOSS [training: 0.6493157831175347 | validation: 0.3542501095458331]
	TIME [epoch: 8.28 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4102266592355419		[learning rate: 0.0017939]
		[batch 20/20] avg loss: 0.5457472751529864		[learning rate: 0.0017895]
	Learning Rate: 0.00178952
	LOSS [training: 0.47798696719426426 | validation: 0.6624533654309839]
	TIME [epoch: 8.29 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3662833080480973		[learning rate: 0.0017852]
		[batch 20/20] avg loss: 0.2792862503204817		[learning rate: 0.0017809]
	Learning Rate: 0.00178087
	LOSS [training: 0.32278477918428944 | validation: 0.16692442804509713]
	TIME [epoch: 8.31 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4054037948709233		[learning rate: 0.0017766]
		[batch 20/20] avg loss: 0.28478869140027685		[learning rate: 0.0017723]
	Learning Rate: 0.00177226
	LOSS [training: 0.34509624313560006 | validation: 1.8245664144393405]
	TIME [epoch: 8.28 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5096761102562752		[learning rate: 0.001768]
		[batch 20/20] avg loss: 0.5134230134230044		[learning rate: 0.0017637]
	Learning Rate: 0.00176369
	LOSS [training: 0.5115495618396397 | validation: 0.39614291806813307]
	TIME [epoch: 8.28 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5533523874665984		[learning rate: 0.0017594]
		[batch 20/20] avg loss: 0.4695146351087039		[learning rate: 0.0017552]
	Learning Rate: 0.00175516
	LOSS [training: 0.5114335112876511 | validation: 0.38403374594195966]
	TIME [epoch: 8.29 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3655821340543635		[learning rate: 0.0017509]
		[batch 20/20] avg loss: 0.6280618550722799		[learning rate: 0.0017467]
	Learning Rate: 0.00174667
	LOSS [training: 0.49682199456332177 | validation: 0.28659564483814476]
	TIME [epoch: 8.32 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6674235159826999		[learning rate: 0.0017424]
		[batch 20/20] avg loss: 0.498727389007745		[learning rate: 0.0017382]
	Learning Rate: 0.00173822
	LOSS [training: 0.5830754524952225 | validation: 0.6533851632589174]
	TIME [epoch: 8.29 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.156880227900463		[learning rate: 0.001734]
		[batch 20/20] avg loss: 0.45687852785494876		[learning rate: 0.0017298]
	Learning Rate: 0.00172982
	LOSS [training: 0.806879377877706 | validation: 0.3249659967882328]
	TIME [epoch: 8.29 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.41912189482819107		[learning rate: 0.0017256]
		[batch 20/20] avg loss: 0.3741034206008074		[learning rate: 0.0017215]
	Learning Rate: 0.00172145
	LOSS [training: 0.3966126577144993 | validation: 0.3530128158439432]
	TIME [epoch: 8.29 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4343106241397591		[learning rate: 0.0017173]
		[batch 20/20] avg loss: 0.5033169884091828		[learning rate: 0.0017131]
	Learning Rate: 0.00171313
	LOSS [training: 0.468813806274471 | validation: 0.20838867611840495]
	TIME [epoch: 8.31 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23837804019691852		[learning rate: 0.001709]
		[batch 20/20] avg loss: 0.2905028996551995		[learning rate: 0.0017048]
	Learning Rate: 0.00170484
	LOSS [training: 0.2644404699260591 | validation: 0.15752574497587013]
	TIME [epoch: 8.28 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2494611477175476		[learning rate: 0.0017007]
		[batch 20/20] avg loss: 0.38192724419558444		[learning rate: 0.0016966]
	Learning Rate: 0.0016966
	LOSS [training: 0.315694195956566 | validation: 0.20503729018041328]
	TIME [epoch: 8.29 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3640870073024856		[learning rate: 0.0016925]
		[batch 20/20] avg loss: 0.649839057374163		[learning rate: 0.0016884]
	Learning Rate: 0.00168839
	LOSS [training: 0.5069630323383242 | validation: 0.4750358786073922]
	TIME [epoch: 8.29 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6259829529284451		[learning rate: 0.0016843]
		[batch 20/20] avg loss: 0.4278092001966157		[learning rate: 0.0016802]
	Learning Rate: 0.00168023
	LOSS [training: 0.5268960765625303 | validation: 0.7368028821587544]
	TIME [epoch: 8.29 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3033906622840622		[learning rate: 0.0016762]
		[batch 20/20] avg loss: 0.24249657224001692		[learning rate: 0.0016721]
	Learning Rate: 0.0016721
	LOSS [training: 0.27294361726203953 | validation: 0.9774593582692903]
	TIME [epoch: 8.31 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9385629565893201		[learning rate: 0.0016681]
		[batch 20/20] avg loss: 0.4767627978600526		[learning rate: 0.001664]
	Learning Rate: 0.00166402
	LOSS [training: 0.7076628772246862 | validation: 0.18944592854394338]
	TIME [epoch: 8.29 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23801182996889647		[learning rate: 0.00166]
		[batch 20/20] avg loss: 0.24459162600524778		[learning rate: 0.001656]
	Learning Rate: 0.00165597
	LOSS [training: 0.2413017279870721 | validation: 0.3801097679586071]
	TIME [epoch: 8.28 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6198478828169136		[learning rate: 0.001652]
		[batch 20/20] avg loss: 0.260782215701995		[learning rate: 0.001648]
	Learning Rate: 0.00164796
	LOSS [training: 0.4403150492594544 | validation: 0.384262297563635]
	TIME [epoch: 8.29 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4804433291222738		[learning rate: 0.001644]
		[batch 20/20] avg loss: 0.699715507847434		[learning rate: 0.00164]
	Learning Rate: 0.00163999
	LOSS [training: 0.5900794184848539 | validation: 0.24878191783979042]
	TIME [epoch: 8.32 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22939798721408672		[learning rate: 0.001636]
		[batch 20/20] avg loss: 0.3850446783356519		[learning rate: 0.0016321]
	Learning Rate: 0.00163206
	LOSS [training: 0.3072213327748693 | validation: 0.15240295252775052]
	TIME [epoch: 8.29 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13536615120332052		[learning rate: 0.0016281]
		[batch 20/20] avg loss: 0.15562745466188982		[learning rate: 0.0016242]
	Learning Rate: 0.00162417
	LOSS [training: 0.14549680293260514 | validation: 0.10380478816814792]
	TIME [epoch: 8.3 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18370811830146888		[learning rate: 0.0016202]
		[batch 20/20] avg loss: 0.35567955701879106		[learning rate: 0.0016163]
	Learning Rate: 0.00161632
	LOSS [training: 0.26969383766013 | validation: 0.5338182517067163]
	TIME [epoch: 8.29 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1932015936835918		[learning rate: 0.0016124]
		[batch 20/20] avg loss: 0.16263047629549107		[learning rate: 0.0016085]
	Learning Rate: 0.0016085
	LOSS [training: 0.1779160349895414 | validation: 0.13167717253928002]
	TIME [epoch: 8.31 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1565852667485328		[learning rate: 0.0016046]
		[batch 20/20] avg loss: 0.4090463356730085		[learning rate: 0.0016007]
	Learning Rate: 0.00160072
	LOSS [training: 0.28281580121077066 | validation: 0.20899245379367937]
	TIME [epoch: 8.29 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23467997281998096		[learning rate: 0.0015968]
		[batch 20/20] avg loss: 0.6619168222476216		[learning rate: 0.001593]
	Learning Rate: 0.00159298
	LOSS [training: 0.4482983975338013 | validation: 0.21080472492721897]
	TIME [epoch: 8.29 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.402870839896239		[learning rate: 0.0015891]
		[batch 20/20] avg loss: 0.7966192163298005		[learning rate: 0.0015853]
	Learning Rate: 0.00158528
	LOSS [training: 0.5997450281130198 | validation: 0.49083434960867456]
	TIME [epoch: 8.28 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3037573669165778		[learning rate: 0.0015814]
		[batch 20/20] avg loss: 0.44065152832648913		[learning rate: 0.0015776]
	Learning Rate: 0.00157761
	LOSS [training: 0.3722044476215335 | validation: 0.17077119103898128]
	TIME [epoch: 8.29 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.43170963647968685		[learning rate: 0.0015738]
		[batch 20/20] avg loss: 0.5899811469402453		[learning rate: 0.00157]
	Learning Rate: 0.00156998
	LOSS [training: 0.510845391709966 | validation: 0.718553827114794]
	TIME [epoch: 8.3 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4470938595174127		[learning rate: 0.0015662]
		[batch 20/20] avg loss: 0.29667903731295203		[learning rate: 0.0015624]
	Learning Rate: 0.00156239
	LOSS [training: 0.37188644841518237 | validation: 0.3793735071933386]
	TIME [epoch: 8.29 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2901280868616586		[learning rate: 0.0015586]
		[batch 20/20] avg loss: 0.44068621367671146		[learning rate: 0.0015548]
	Learning Rate: 0.00155483
	LOSS [training: 0.36540715026918497 | validation: 0.4548927336549019]
	TIME [epoch: 8.29 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.38056084626762543		[learning rate: 0.0015511]
		[batch 20/20] avg loss: 0.5770318723025817		[learning rate: 0.0015473]
	Learning Rate: 0.00154732
	LOSS [training: 0.4787963592851036 | validation: 0.2946993525635272]
	TIME [epoch: 8.28 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3047582332165867		[learning rate: 0.0015436]
		[batch 20/20] avg loss: 0.26938920565985564		[learning rate: 0.0015398]
	Learning Rate: 0.00153983
	LOSS [training: 0.2870737194382211 | validation: 0.3993632498502708]
	TIME [epoch: 8.31 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3714497304209684		[learning rate: 0.0015361]
		[batch 20/20] avg loss: 0.2752540331842436		[learning rate: 0.0015324]
	Learning Rate: 0.00153239
	LOSS [training: 0.323351881802606 | validation: 0.2064595749713983]
	TIME [epoch: 8.28 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6411931932702264		[learning rate: 0.0015287]
		[batch 20/20] avg loss: 0.19804273625173088		[learning rate: 0.001525]
	Learning Rate: 0.00152498
	LOSS [training: 0.4196179647609786 | validation: 0.19544234270463062]
	TIME [epoch: 8.28 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4218728350426379		[learning rate: 0.0015213]
		[batch 20/20] avg loss: 0.3332708946489227		[learning rate: 0.0015176]
	Learning Rate: 0.0015176
	LOSS [training: 0.37757186484578037 | validation: 0.6920889875091804]
	TIME [epoch: 8.29 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3223513398124913		[learning rate: 0.0015139]
		[batch 20/20] avg loss: 0.3047116834901491		[learning rate: 0.0015103]
	Learning Rate: 0.00151026
	LOSS [training: 0.3135315116513202 | validation: 0.18153699445126775]
	TIME [epoch: 8.29 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4237353796898941		[learning rate: 0.0015066]
		[batch 20/20] avg loss: 0.41989813893344685		[learning rate: 0.001503]
	Learning Rate: 0.00150296
	LOSS [training: 0.42181675931167045 | validation: 0.1621783638235459]
	TIME [epoch: 8.31 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5298534796497101		[learning rate: 0.0014993]
		[batch 20/20] avg loss: 0.2466668027147591		[learning rate: 0.0014957]
	Learning Rate: 0.00149569
	LOSS [training: 0.3882601411822345 | validation: 0.3116519336243606]
	TIME [epoch: 8.28 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2486262148695862		[learning rate: 0.0014921]
		[batch 20/20] avg loss: 0.24740571471569814		[learning rate: 0.0014885]
	Learning Rate: 0.00148846
	LOSS [training: 0.2480159647926421 | validation: 0.2305642071106767]
	TIME [epoch: 8.29 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8203714991872213		[learning rate: 0.0014849]
		[batch 20/20] avg loss: 0.33094225040470254		[learning rate: 0.0014813]
	Learning Rate: 0.00148126
	LOSS [training: 0.5756568747959618 | validation: 0.11831504015390773]
	TIME [epoch: 8.28 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27166157159840953		[learning rate: 0.0014777]
		[batch 20/20] avg loss: 0.27680870372385435		[learning rate: 0.0014741]
	Learning Rate: 0.0014741
	LOSS [training: 0.27423513766113194 | validation: 0.38107857342296736]
	TIME [epoch: 8.32 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2952508773165423		[learning rate: 0.0014705]
		[batch 20/20] avg loss: 0.21965988254197083		[learning rate: 0.001467]
	Learning Rate: 0.00146697
	LOSS [training: 0.2574553799292566 | validation: 0.1471428635697559]
	TIME [epoch: 8.29 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3406917790402114		[learning rate: 0.0014634]
		[batch 20/20] avg loss: 0.6178138376013688		[learning rate: 0.0014599]
	Learning Rate: 0.00145988
	LOSS [training: 0.4792528083207901 | validation: 0.1808254941916366]
	TIME [epoch: 8.29 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3485079722103665		[learning rate: 0.0014563]
		[batch 20/20] avg loss: 0.15594785745572523		[learning rate: 0.0014528]
	Learning Rate: 0.00145282
	LOSS [training: 0.2522279148330459 | validation: 0.13652911226150416]
	TIME [epoch: 8.29 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14926028056662083		[learning rate: 0.0014493]
		[batch 20/20] avg loss: 0.21718945735107803		[learning rate: 0.0014458]
	Learning Rate: 0.00144579
	LOSS [training: 0.18322486895884943 | validation: 0.1870108031360181]
	TIME [epoch: 8.31 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2884911522557408		[learning rate: 0.0014423]
		[batch 20/20] avg loss: 0.7784317775816376		[learning rate: 0.0014388]
	Learning Rate: 0.0014388
	LOSS [training: 0.5334614649186892 | validation: 0.25257978643704754]
	TIME [epoch: 8.29 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21133766497617074		[learning rate: 0.0014353]
		[batch 20/20] avg loss: 0.21433835075899652		[learning rate: 0.0014318]
	Learning Rate: 0.00143184
	LOSS [training: 0.21283800786758364 | validation: 0.10087012878765063]
	TIME [epoch: 8.28 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15844047261233185		[learning rate: 0.0014284]
		[batch 20/20] avg loss: 0.19323509261865313		[learning rate: 0.0014249]
	Learning Rate: 0.00142492
	LOSS [training: 0.17583778261549252 | validation: 0.12696340966322273]
	TIME [epoch: 8.29 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18953650260895946		[learning rate: 0.0014215]
		[batch 20/20] avg loss: 0.21100715079818172		[learning rate: 0.001418]
	Learning Rate: 0.00141803
	LOSS [training: 0.20027182670357058 | validation: 0.21562321305045762]
	TIME [epoch: 8.29 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2047110679522767		[learning rate: 0.0014146]
		[batch 20/20] avg loss: 0.2020843812341036		[learning rate: 0.0014112]
	Learning Rate: 0.00141117
	LOSS [training: 0.20339772459319017 | validation: 0.09395124874738936]
	TIME [epoch: 8.31 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17129129939297955		[learning rate: 0.0014078]
		[batch 20/20] avg loss: 0.1923319395055698		[learning rate: 0.0014043]
	Learning Rate: 0.00140434
	LOSS [training: 0.18181161944927465 | validation: 0.11557399587867008]
	TIME [epoch: 8.29 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14564905437757408		[learning rate: 0.0014009]
		[batch 20/20] avg loss: 0.17056148229654827		[learning rate: 0.0013976]
	Learning Rate: 0.00139755
	LOSS [training: 0.1581052683370612 | validation: 0.18522205352447474]
	TIME [epoch: 8.28 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20249420093601436		[learning rate: 0.0013942]
		[batch 20/20] avg loss: 0.4686033686087662		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.33554878477239025 | validation: 0.19984587077943056]
	TIME [epoch: 8.29 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18951015851569042		[learning rate: 0.0013874]
		[batch 20/20] avg loss: 0.36365134149960876		[learning rate: 0.0013841]
	Learning Rate: 0.00138407
	LOSS [training: 0.2765807500076496 | validation: 0.30001923189531987]
	TIME [epoch: 8.31 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3934378894511531		[learning rate: 0.0013807]
		[batch 20/20] avg loss: 0.6146838575576808		[learning rate: 0.0013774]
	Learning Rate: 0.00137738
	LOSS [training: 0.504060873504417 | validation: 2.508448148113639]
	TIME [epoch: 8.28 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.881088085054848		[learning rate: 0.001374]
		[batch 20/20] avg loss: 0.3069917744113912		[learning rate: 0.0013707]
	Learning Rate: 0.00137072
	LOSS [training: 0.5940399297331196 | validation: 0.4288087957479858]
	TIME [epoch: 8.27 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.33202322407658164		[learning rate: 0.0013674]
		[batch 20/20] avg loss: 1.0909865459601806		[learning rate: 0.0013641]
	Learning Rate: 0.00136409
	LOSS [training: 0.7115048850183812 | validation: 0.7034400493123794]
	TIME [epoch: 8.28 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5065182117210416		[learning rate: 0.0013608]
		[batch 20/20] avg loss: 0.3901904433840745		[learning rate: 0.0013575]
	Learning Rate: 0.00135749
	LOSS [training: 0.4483543275525581 | validation: 0.27900063378603246]
	TIME [epoch: 8.3 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24243884960433543		[learning rate: 0.0013542]
		[batch 20/20] avg loss: 0.2992074276205729		[learning rate: 0.0013509]
	Learning Rate: 0.00135093
	LOSS [training: 0.2708231386124543 | validation: 0.20810538196930373]
	TIME [epoch: 8.29 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6789878464456772		[learning rate: 0.0013477]
		[batch 20/20] avg loss: 0.23666288472411937		[learning rate: 0.0013444]
	Learning Rate: 0.00134439
	LOSS [training: 0.45782536558489817 | validation: 0.14910564586638994]
	TIME [epoch: 8.28 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20425267875860867		[learning rate: 0.0013411]
		[batch 20/20] avg loss: 0.6960080419553294		[learning rate: 0.0013379]
	Learning Rate: 0.00133789
	LOSS [training: 0.450130360356969 | validation: 0.18578291284269238]
	TIME [epoch: 8.28 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11961625271695275		[learning rate: 0.0013347]
		[batch 20/20] avg loss: 0.1778503589348599		[learning rate: 0.0013314]
	Learning Rate: 0.00133142
	LOSS [training: 0.1487333058259063 | validation: 0.2097922628980998]
	TIME [epoch: 8.29 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14412885966320282		[learning rate: 0.0013282]
		[batch 20/20] avg loss: 0.1879868076088625		[learning rate: 0.001325]
	Learning Rate: 0.00132498
	LOSS [training: 0.1660578336360327 | validation: 0.08706325851065405]
	TIME [epoch: 8.32 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2824564405777762		[learning rate: 0.0013218]
		[batch 20/20] avg loss: 0.17433822803520777		[learning rate: 0.0013186]
	Learning Rate: 0.00131858
	LOSS [training: 0.22839733430649195 | validation: 0.24246257439219746]
	TIME [epoch: 8.29 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24790628084165145		[learning rate: 0.0013154]
		[batch 20/20] avg loss: 0.20622502811607135		[learning rate: 0.0013122]
	Learning Rate: 0.0013122
	LOSS [training: 0.2270656544788614 | validation: 0.17367435303943698]
	TIME [epoch: 8.28 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5011590125777658		[learning rate: 0.001309]
		[batch 20/20] avg loss: 0.42455833041090585		[learning rate: 0.0013059]
	Learning Rate: 0.00130585
	LOSS [training: 0.4628586714943359 | validation: 0.6713411726256908]
	TIME [epoch: 8.29 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.48452821412388464		[learning rate: 0.0013027]
		[batch 20/20] avg loss: 0.20923135486600403		[learning rate: 0.0012995]
	Learning Rate: 0.00129954
	LOSS [training: 0.3468797844949444 | validation: 0.18166282557841257]
	TIME [epoch: 8.31 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30242600415191634		[learning rate: 0.0012964]
		[batch 20/20] avg loss: 0.20551811537815		[learning rate: 0.0012933]
	Learning Rate: 0.00129326
	LOSS [training: 0.2539720597650331 | validation: 0.15476389023102255]
	TIME [epoch: 8.29 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26426836310455587		[learning rate: 0.0012901]
		[batch 20/20] avg loss: 0.21313413747412668		[learning rate: 0.001287]
	Learning Rate: 0.001287
	LOSS [training: 0.2387012502893413 | validation: 0.2269266639908034]
	TIME [epoch: 8.29 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1653500840279499		[learning rate: 0.0012839]
		[batch 20/20] avg loss: 0.4466144312135302		[learning rate: 0.0012808]
	Learning Rate: 0.00128078
	LOSS [training: 0.3059822576207401 | validation: 0.7920037125789271]
	TIME [epoch: 8.28 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5141954299276945		[learning rate: 0.0012777]
		[batch 20/20] avg loss: 0.43829504567342725		[learning rate: 0.0012746]
	Learning Rate: 0.00127458
	LOSS [training: 0.4762452378005608 | validation: 1.1976130795722373]
	TIME [epoch: 8.29 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.44417249952273813		[learning rate: 0.0012715]
		[batch 20/20] avg loss: 0.25366655183743336		[learning rate: 0.0012684]
	Learning Rate: 0.00126842
	LOSS [training: 0.3489195256800857 | validation: 0.3127309010999092]
	TIME [epoch: 8.3 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4017562561597024		[learning rate: 0.0012653]
		[batch 20/20] avg loss: 0.6035311867688542		[learning rate: 0.0012623]
	Learning Rate: 0.00126229
	LOSS [training: 0.5026437214642783 | validation: 0.2150217125660836]
	TIME [epoch: 8.29 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21851884080814005		[learning rate: 0.0012592]
		[batch 20/20] avg loss: 0.1679976847388253		[learning rate: 0.0012562]
	Learning Rate: 0.00125618
	LOSS [training: 0.19325826277348263 | validation: 0.24467892639777925]
	TIME [epoch: 8.28 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20420058448053213		[learning rate: 0.0012531]
		[batch 20/20] avg loss: 0.736608200856309		[learning rate: 0.0012501]
	Learning Rate: 0.00125011
	LOSS [training: 0.47040439266842043 | validation: 0.5161324651269579]
	TIME [epoch: 8.28 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4646728534834108		[learning rate: 0.0012471]
		[batch 20/20] avg loss: 0.17480276771319975		[learning rate: 0.0012441]
	Learning Rate: 0.00124406
	LOSS [training: 0.31973781059830525 | validation: 0.12276991867552495]
	TIME [epoch: 8.3 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18872955872701686		[learning rate: 0.0012411]
		[batch 20/20] avg loss: 0.30716839960534753		[learning rate: 0.001238]
	Learning Rate: 0.00123805
	LOSS [training: 0.2479489791661822 | validation: 0.13668375316142906]
	TIME [epoch: 8.28 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14131793924080638		[learning rate: 0.001235]
		[batch 20/20] avg loss: 0.16098189750748224		[learning rate: 0.0012321]
	Learning Rate: 0.00123206
	LOSS [training: 0.15114991837414432 | validation: 0.08379641338896533]
	TIME [epoch: 8.28 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21515820903357086		[learning rate: 0.0012291]
		[batch 20/20] avg loss: 0.1473804443906058		[learning rate: 0.0012261]
	Learning Rate: 0.0012261
	LOSS [training: 0.18126932671208834 | validation: 0.1117623072583957]
	TIME [epoch: 8.29 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16129625840565787		[learning rate: 0.0012231]
		[batch 20/20] avg loss: 0.1392459001477302		[learning rate: 0.0012202]
	Learning Rate: 0.00122017
	LOSS [training: 0.15027107927669403 | validation: 0.18475760282632941]
	TIME [epoch: 8.3 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14783355977414428		[learning rate: 0.0012172]
		[batch 20/20] avg loss: 0.1766218024590926		[learning rate: 0.0012143]
	Learning Rate: 0.00121427
	LOSS [training: 0.1622276811166184 | validation: 0.13862651078467605]
	TIME [epoch: 8.29 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17391342370120333		[learning rate: 0.0012113]
		[batch 20/20] avg loss: 0.18583838246579995		[learning rate: 0.0012084]
	Learning Rate: 0.0012084
	LOSS [training: 0.17987590308350168 | validation: 0.25976146882231416]
	TIME [epoch: 8.28 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19983353111900834		[learning rate: 0.0012055]
		[batch 20/20] avg loss: 0.19948375971992963		[learning rate: 0.0012026]
	Learning Rate: 0.00120256
	LOSS [training: 0.199658645419469 | validation: 0.2436433413447237]
	TIME [epoch: 8.28 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1565934911293446		[learning rate: 0.0011996]
		[batch 20/20] avg loss: 0.15607177479653048		[learning rate: 0.0011967]
	Learning Rate: 0.00119674
	LOSS [training: 0.15633263296293756 | validation: 0.15333287427662773]
	TIME [epoch: 8.29 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1323036445668528		[learning rate: 0.0011938]
		[batch 20/20] avg loss: 0.11969643562155471		[learning rate: 0.001191]
	Learning Rate: 0.00119095
	LOSS [training: 0.1260000400942038 | validation: 0.3168932806059258]
	TIME [epoch: 8.3 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18151909271061323		[learning rate: 0.0011881]
		[batch 20/20] avg loss: 0.1957070908815573		[learning rate: 0.0011852]
	Learning Rate: 0.00118519
	LOSS [training: 0.18861309179608532 | validation: 0.17858051044474457]
	TIME [epoch: 8.29 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15777751497922185		[learning rate: 0.0011823]
		[batch 20/20] avg loss: 0.2682813998193422		[learning rate: 0.0011795]
	Learning Rate: 0.00117946
	LOSS [training: 0.213029457399282 | validation: 0.0986322828591843]
	TIME [epoch: 8.28 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1798530249197162		[learning rate: 0.0011766]
		[batch 20/20] avg loss: 0.1689562583135026		[learning rate: 0.0011738]
	Learning Rate: 0.00117376
	LOSS [training: 0.1744046416166094 | validation: 0.07268846594532333]
	TIME [epoch: 8.28 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1276803769578553		[learning rate: 0.0011709]
		[batch 20/20] avg loss: 0.20481219998115777		[learning rate: 0.0011681]
	Learning Rate: 0.00116808
	LOSS [training: 0.16624628846950656 | validation: 0.23727784380182987]
	TIME [epoch: 8.31 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17978218333985635		[learning rate: 0.0011653]
		[batch 20/20] avg loss: 0.1910086763768919		[learning rate: 0.0011624]
	Learning Rate: 0.00116243
	LOSS [training: 0.18539542985837415 | validation: 0.15148864337409376]
	TIME [epoch: 8.29 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14477769851835412		[learning rate: 0.0011596]
		[batch 20/20] avg loss: 0.13476628840862867		[learning rate: 0.0011568]
	Learning Rate: 0.00115681
	LOSS [training: 0.1397719934634914 | validation: 0.1457891392756122]
	TIME [epoch: 8.29 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14220528270544236		[learning rate: 0.001154]
		[batch 20/20] avg loss: 0.10416603691399		[learning rate: 0.0011512]
	Learning Rate: 0.00115122
	LOSS [training: 0.12318565980971619 | validation: 0.06417447672982413]
	TIME [epoch: 8.28 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10761524160158224		[learning rate: 0.0011484]
		[batch 20/20] avg loss: 0.12208379269761407		[learning rate: 0.0011457]
	Learning Rate: 0.00114565
	LOSS [training: 0.11484951714959817 | validation: 0.10075811316118882]
	TIME [epoch: 8.31 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16303465756875796		[learning rate: 0.0011429]
		[batch 20/20] avg loss: 0.10669317690846032		[learning rate: 0.0011401]
	Learning Rate: 0.00114011
	LOSS [training: 0.13486391723860913 | validation: 0.1607665006760873]
	TIME [epoch: 8.28 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1188120779936157		[learning rate: 0.0011374]
		[batch 20/20] avg loss: 0.12236468258369801		[learning rate: 0.0011346]
	Learning Rate: 0.0011346
	LOSS [training: 0.12058838028865689 | validation: 0.047287252545235456]
	TIME [epoch: 8.29 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10222856484401484		[learning rate: 0.0011319]
		[batch 20/20] avg loss: 0.15474156374066536		[learning rate: 0.0011291]
	Learning Rate: 0.00112911
	LOSS [training: 0.12848506429234013 | validation: 0.05134426718102981]
	TIME [epoch: 8.27 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10728929943207814		[learning rate: 0.0011264]
		[batch 20/20] avg loss: 0.10042864087874326		[learning rate: 0.0011237]
	Learning Rate: 0.00112365
	LOSS [training: 0.10385897015541071 | validation: 0.07321473021095912]
	TIME [epoch: 8.29 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15770189134732937		[learning rate: 0.0011209]
		[batch 20/20] avg loss: 0.18727838605288452		[learning rate: 0.0011182]
	Learning Rate: 0.00111822
	LOSS [training: 0.17249013870010696 | validation: 0.15967738336248757]
	TIME [epoch: 8.31 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17542525889807353		[learning rate: 0.0011155]
		[batch 20/20] avg loss: 0.15295406803791994		[learning rate: 0.0011128]
	Learning Rate: 0.00111281
	LOSS [training: 0.16418966346799677 | validation: 0.07195337894169591]
	TIME [epoch: 8.28 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4624124643400614		[learning rate: 0.0011101]
		[batch 20/20] avg loss: 0.26032925552116143		[learning rate: 0.0011074]
	Learning Rate: 0.00110743
	LOSS [training: 0.3613708599306114 | validation: 0.3504033389254967]
	TIME [epoch: 8.29 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2592129654423472		[learning rate: 0.0011047]
		[batch 20/20] avg loss: 0.12418058699389187		[learning rate: 0.0011021]
	Learning Rate: 0.00110207
	LOSS [training: 0.19169677621811956 | validation: 0.06838419757441544]
	TIME [epoch: 8.28 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17206652025936103		[learning rate: 0.0010994]
		[batch 20/20] avg loss: 0.13091911903454456		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.1514928196469528 | validation: 0.1938297776410902]
	TIME [epoch: 8.31 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2608505237957539		[learning rate: 0.0010941]
		[batch 20/20] avg loss: 0.24185191841560144		[learning rate: 0.0010914]
	Learning Rate: 0.00109144
	LOSS [training: 0.25135122110567765 | validation: 0.2302486508361344]
	TIME [epoch: 8.29 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18682914163842498		[learning rate: 0.0010888]
		[batch 20/20] avg loss: 0.14180891608634227		[learning rate: 0.0010862]
	Learning Rate: 0.00108616
	LOSS [training: 0.16431902886238364 | validation: 0.1479245451326812]
	TIME [epoch: 8.28 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15966831850875327		[learning rate: 0.0010835]
		[batch 20/20] avg loss: 0.17495323441234048		[learning rate: 0.0010809]
	Learning Rate: 0.00108091
	LOSS [training: 0.16731077646054687 | validation: 0.13603320514022488]
	TIME [epoch: 8.28 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5657184945488579		[learning rate: 0.0010783]
		[batch 20/20] avg loss: 0.3037469324532174		[learning rate: 0.0010757]
	Learning Rate: 0.00107568
	LOSS [training: 0.43473271350103754 | validation: 0.10270985072266164]
	TIME [epoch: 8.3 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26338004353441513		[learning rate: 0.0010731]
		[batch 20/20] avg loss: 0.3301604808698486		[learning rate: 0.0010705]
	Learning Rate: 0.00107048
	LOSS [training: 0.2967702622021319 | validation: 0.2405334789671428]
	TIME [epoch: 8.29 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18729471090229763		[learning rate: 0.0010679]
		[batch 20/20] avg loss: 0.25738148334889627		[learning rate: 0.0010653]
	Learning Rate: 0.0010653
	LOSS [training: 0.22233809712559696 | validation: 0.13354481892180145]
	TIME [epoch: 8.28 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16291086201489485		[learning rate: 0.0010627]
		[batch 20/20] avg loss: 0.1422258054205091		[learning rate: 0.0010602]
	Learning Rate: 0.00106015
	LOSS [training: 0.152568333717702 | validation: 0.1688594066666331]
	TIME [epoch: 8.28 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1731446756538416		[learning rate: 0.0010576]
		[batch 20/20] avg loss: 0.1359043332671661		[learning rate: 0.001055]
	Learning Rate: 0.00105503
	LOSS [training: 0.15452450446050386 | validation: 0.1699729114138933]
	TIME [epoch: 8.28 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18667262397364967		[learning rate: 0.0010525]
		[batch 20/20] avg loss: 0.16288687122490758		[learning rate: 0.0010499]
	Learning Rate: 0.00104992
	LOSS [training: 0.1747797475992786 | validation: 0.06929470790293396]
	TIME [epoch: 8.31 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25636059981353265		[learning rate: 0.0010474]
		[batch 20/20] avg loss: 0.34303860851013107		[learning rate: 0.0010448]
	Learning Rate: 0.00104485
	LOSS [training: 0.29969960416183183 | validation: 0.39030174530633427]
	TIME [epoch: 8.28 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2381515877279002		[learning rate: 0.0010423]
		[batch 20/20] avg loss: 1.129361069898749		[learning rate: 0.0010398]
	Learning Rate: 0.00103979
	LOSS [training: 0.6837563288133246 | validation: 0.20843690664637649]
	TIME [epoch: 8.28 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20188008380658803		[learning rate: 0.0010373]
		[batch 20/20] avg loss: 0.1518249093003933		[learning rate: 0.0010348]
	Learning Rate: 0.00103477
	LOSS [training: 0.17685249655349067 | validation: 0.11706487082020943]
	TIME [epoch: 8.28 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26106839197529896		[learning rate: 0.0010323]
		[batch 20/20] avg loss: 0.17639222778141053		[learning rate: 0.0010298]
	Learning Rate: 0.00102976
	LOSS [training: 0.21873030987835476 | validation: 0.164454784888672]
	TIME [epoch: 8.3 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26622739144367585		[learning rate: 0.0010273]
		[batch 20/20] avg loss: 0.2674728098470901		[learning rate: 0.0010248]
	Learning Rate: 0.00102478
	LOSS [training: 0.2668501006453829 | validation: 0.18600499671174822]
	TIME [epoch: 8.28 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6296499061300473		[learning rate: 0.0010223]
		[batch 20/20] avg loss: 0.6112114690999056		[learning rate: 0.0010198]
	Learning Rate: 0.00101983
	LOSS [training: 0.6204306876149762 | validation: 0.30561273428054214]
	TIME [epoch: 8.27 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6767534680595262		[learning rate: 0.0010174]
		[batch 20/20] avg loss: 0.6697053097555681		[learning rate: 0.0010149]
	Learning Rate: 0.00101489
	LOSS [training: 0.673229388907547 | validation: 0.4709096876769616]
	TIME [epoch: 8.28 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3576675592536375		[learning rate: 0.0010124]
		[batch 20/20] avg loss: 0.3460961093647239		[learning rate: 0.00101]
	Learning Rate: 0.00100999
	LOSS [training: 0.35188183430918074 | validation: 0.13104428987227362]
	TIME [epoch: 8.28 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2422598679737776		[learning rate: 0.0010075]
		[batch 20/20] avg loss: 0.3180252714635753		[learning rate: 0.0010051]
	Learning Rate: 0.0010051
	LOSS [training: 0.2801425697186764 | validation: 0.22940782301597945]
	TIME [epoch: 8.3 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19194718524745233		[learning rate: 0.0010027]
		[batch 20/20] avg loss: 0.17992512212577325		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.1859361536866128 | validation: 0.10530915400960923]
	TIME [epoch: 8.27 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16992715682754705		[learning rate: 0.00099782]
		[batch 20/20] avg loss: 0.15879396544335045		[learning rate: 0.00099541]
	Learning Rate: 0.000995405
	LOSS [training: 0.16436056113544875 | validation: 0.1652968808743383]
	TIME [epoch: 8.27 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1545921460151454		[learning rate: 0.000993]
		[batch 20/20] avg loss: 0.13155224979368607		[learning rate: 0.00099059]
	Learning Rate: 0.000990592
	LOSS [training: 0.14307219790441575 | validation: 0.07811060599735709]
	TIME [epoch: 8.27 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29759788952741884		[learning rate: 0.00098819]
		[batch 20/20] avg loss: 0.17076656363780282		[learning rate: 0.0009858]
	Learning Rate: 0.000985801
	LOSS [training: 0.23418222658261084 | validation: 0.1502313880594473]
	TIME [epoch: 8.3 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18421072396588115		[learning rate: 0.00098341]
		[batch 20/20] avg loss: 1.3457773820559755		[learning rate: 0.00098103]
	Learning Rate: 0.000981034
	LOSS [training: 0.7649940530109284 | validation: 0.6596093016608612]
	TIME [epoch: 8.27 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.0868605697462406		[learning rate: 0.00097866]
		[batch 20/20] avg loss: 2.517831060849764		[learning rate: 0.00097629]
	Learning Rate: 0.00097629
	LOSS [training: 2.302345815298002 | validation: 3.5692430848715517]
	TIME [epoch: 8.28 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8890218676863381		[learning rate: 0.00097393]
		[batch 20/20] avg loss: 0.16246198467782355		[learning rate: 0.00097157]
	Learning Rate: 0.000971569
	LOSS [training: 0.5257419261820809 | validation: 0.11029797258286646]
	TIME [epoch: 8.28 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13916183072048388		[learning rate: 0.00096922]
		[batch 20/20] avg loss: 0.12558884227752315		[learning rate: 0.00096687]
	Learning Rate: 0.000966871
	LOSS [training: 0.13237533649900354 | validation: 0.08242665132952073]
	TIME [epoch: 8.3 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.129937943491443		[learning rate: 0.00096453]
		[batch 20/20] avg loss: 0.23703513691202965		[learning rate: 0.00096219]
	Learning Rate: 0.000962195
	LOSS [training: 0.18348654020173633 | validation: 0.3788172759492453]
	TIME [epoch: 8.28 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1402428598973116		[learning rate: 0.00095987]
		[batch 20/20] avg loss: 0.12873156929879576		[learning rate: 0.00095754]
	Learning Rate: 0.000957542
	LOSS [training: 0.13448721459805366 | validation: 0.08454789760434164]
	TIME [epoch: 8.28 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13376578954644844		[learning rate: 0.00095522]
		[batch 20/20] avg loss: 0.1514771932784284		[learning rate: 0.00095291]
	Learning Rate: 0.000952912
	LOSS [training: 0.14262149141243846 | validation: 0.08577366939133255]
	TIME [epoch: 8.28 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20206578747283319		[learning rate: 0.0009506]
		[batch 20/20] avg loss: 0.10584296437057192		[learning rate: 0.0009483]
	Learning Rate: 0.000948304
	LOSS [training: 0.15395437592170252 | validation: 0.08677179767958262]
	TIME [epoch: 8.28 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14185868005309815		[learning rate: 0.00094601]
		[batch 20/20] avg loss: 0.48474246586411257		[learning rate: 0.00094372]
	Learning Rate: 0.000943718
	LOSS [training: 0.31330057295860536 | validation: 0.06584419906664538]
	TIME [epoch: 8.29 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2319010657777169		[learning rate: 0.00094143]
		[batch 20/20] avg loss: 0.2650676446732569		[learning rate: 0.00093915]
	Learning Rate: 0.000939154
	LOSS [training: 0.2484843552254869 | validation: 0.5165836537189391]
	TIME [epoch: 8.29 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16434732450091827		[learning rate: 0.00093688]
		[batch 20/20] avg loss: 0.1269400128480443		[learning rate: 0.00093461]
	Learning Rate: 0.000934613
	LOSS [training: 0.1456436686744813 | validation: 0.0924382775515426]
	TIME [epoch: 8.28 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10903364432480996		[learning rate: 0.00093235]
		[batch 20/20] avg loss: 0.30754704880447903		[learning rate: 0.00093009]
	Learning Rate: 0.000930093
	LOSS [training: 0.20829034656464449 | validation: 0.4362657774772552]
	TIME [epoch: 8.27 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24424438553619715		[learning rate: 0.00092784]
		[batch 20/20] avg loss: 0.13316583583910385		[learning rate: 0.0009256]
	Learning Rate: 0.000925595
	LOSS [training: 0.18870511068765047 | validation: 0.06016376120602879]
	TIME [epoch: 8.31 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1397165972077033		[learning rate: 0.00092335]
		[batch 20/20] avg loss: 0.14866518018696656		[learning rate: 0.00092112]
	Learning Rate: 0.000921119
	LOSS [training: 0.14419088869733493 | validation: 0.09371876548775811]
	TIME [epoch: 8.29 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11646082230045732		[learning rate: 0.00091889]
		[batch 20/20] avg loss: 0.12603143818897716		[learning rate: 0.00091666]
	Learning Rate: 0.000916665
	LOSS [training: 0.12124613024471724 | validation: 0.05779803529773289]
	TIME [epoch: 8.28 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1318737315731831		[learning rate: 0.00091445]
		[batch 20/20] avg loss: 0.12245919606724343		[learning rate: 0.00091223]
	Learning Rate: 0.000912232
	LOSS [training: 0.12716646382021327 | validation: 0.07314610599243579]
	TIME [epoch: 8.28 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12837106968068976		[learning rate: 0.00091002]
		[batch 20/20] avg loss: 0.20610362851776426		[learning rate: 0.00090782]
	Learning Rate: 0.000907821
	LOSS [training: 0.167237349099227 | validation: 0.2172582407844756]
	TIME [epoch: 8.3 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14152780766719059		[learning rate: 0.00090562]
		[batch 20/20] avg loss: 0.11652358764521668		[learning rate: 0.00090343]
	Learning Rate: 0.00090343
	LOSS [training: 0.12902569765620367 | validation: 0.07898035973958079]
	TIME [epoch: 8.29 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12500359467238725		[learning rate: 0.00090124]
		[batch 20/20] avg loss: 0.1242041043645945		[learning rate: 0.00089906]
	Learning Rate: 0.000899062
	LOSS [training: 0.12460384951849088 | validation: 0.07322594233787226]
	TIME [epoch: 8.28 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10120842848581464		[learning rate: 0.00089689]
		[batch 20/20] avg loss: 0.11608008642410203		[learning rate: 0.00089471]
	Learning Rate: 0.000894714
	LOSS [training: 0.10864425745495832 | validation: 0.1007671537790204]
	TIME [epoch: 8.28 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12964816414509708		[learning rate: 0.00089255]
		[batch 20/20] avg loss: 0.12669868693703018		[learning rate: 0.00089039]
	Learning Rate: 0.000890387
	LOSS [training: 0.12817342554106365 | validation: 0.07355412322816479]
	TIME [epoch: 8.28 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10578235131383076		[learning rate: 0.00088823]
		[batch 20/20] avg loss: 0.1204514677527125		[learning rate: 0.00088608]
	Learning Rate: 0.000886081
	LOSS [training: 0.11311690953327162 | validation: 1.8846959244830803]
	TIME [epoch: 8.3 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5005158569663456		[learning rate: 0.00088394]
		[batch 20/20] avg loss: 0.18509601124273925		[learning rate: 0.0008818]
	Learning Rate: 0.000881797
	LOSS [training: 0.34280593410454235 | validation: 0.5410632163616148]
	TIME [epoch: 8.28 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1784709225043865		[learning rate: 0.00087966]
		[batch 20/20] avg loss: 0.10830550345538423		[learning rate: 0.00087753]
	Learning Rate: 0.000877532
	LOSS [training: 0.14338821297988535 | validation: 0.05839848161152568]
	TIME [epoch: 8.28 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10875854863973407		[learning rate: 0.00087541]
		[batch 20/20] avg loss: 0.13138940110907887		[learning rate: 0.00087329]
	Learning Rate: 0.000873289
	LOSS [training: 0.12007397487440648 | validation: 0.07483849415550423]
	TIME [epoch: 8.28 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08505950943776902		[learning rate: 0.00087117]
		[batch 20/20] avg loss: 0.151445492090325		[learning rate: 0.00086907]
	Learning Rate: 0.000869066
	LOSS [training: 0.118252500764047 | validation: 0.04980927718898419]
	TIME [epoch: 8.3 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13384874308695696		[learning rate: 0.00086696]
		[batch 20/20] avg loss: 0.0751937643214564		[learning rate: 0.00086486]
	Learning Rate: 0.000864863
	LOSS [training: 0.10452125370420666 | validation: 0.08406637284099955]
	TIME [epoch: 8.29 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11093048699229606		[learning rate: 0.00086277]
		[batch 20/20] avg loss: 0.12379736558591783		[learning rate: 0.00086068]
	Learning Rate: 0.000860681
	LOSS [training: 0.11736392628910694 | validation: 0.06942696608041699]
	TIME [epoch: 8.27 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08387928890310722		[learning rate: 0.0008586]
		[batch 20/20] avg loss: 0.10777803579694008		[learning rate: 0.00085652]
	Learning Rate: 0.000856519
	LOSS [training: 0.09582866235002366 | validation: 0.27910000210214586]
	TIME [epoch: 8.28 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16206044495263888		[learning rate: 0.00085445]
		[batch 20/20] avg loss: 0.10436571099566476		[learning rate: 0.00085238]
	Learning Rate: 0.000852377
	LOSS [training: 0.13321307797415177 | validation: 0.11338247503793399]
	TIME [epoch: 8.28 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13424408615648076		[learning rate: 0.00085031]
		[batch 20/20] avg loss: 0.20277137487563252		[learning rate: 0.00084825]
	Learning Rate: 0.000848255
	LOSS [training: 0.16850773051605666 | validation: 0.2503290310655588]
	TIME [epoch: 8.31 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24071123220908333		[learning rate: 0.0008462]
		[batch 20/20] avg loss: 0.7738125349247419		[learning rate: 0.00084415]
	Learning Rate: 0.000844153
	LOSS [training: 0.5072618835669125 | validation: 0.4212585693936338]
	TIME [epoch: 8.27 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21713106215031514		[learning rate: 0.00084211]
		[batch 20/20] avg loss: 0.10019772946079095		[learning rate: 0.00084007]
	Learning Rate: 0.000840071
	LOSS [training: 0.15866439580555305 | validation: 0.09042725452993641]
	TIME [epoch: 8.27 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12023285540136472		[learning rate: 0.00083804]
		[batch 20/20] avg loss: 0.12070959310435854		[learning rate: 0.00083601]
	Learning Rate: 0.000836008
	LOSS [training: 0.12047122425286164 | validation: 0.12779216795120152]
	TIME [epoch: 8.27 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11502020010883596		[learning rate: 0.00083398]
		[batch 20/20] avg loss: 0.0995706212760475		[learning rate: 0.00083197]
	Learning Rate: 0.000831965
	LOSS [training: 0.10729541069244172 | validation: 0.07600529432856683]
	TIME [epoch: 8.31 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10851881173915767		[learning rate: 0.00082995]
		[batch 20/20] avg loss: 0.1359965365017682		[learning rate: 0.00082794]
	Learning Rate: 0.000827942
	LOSS [training: 0.12225767412046296 | validation: 0.133143735464825]
	TIME [epoch: 8.29 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13609888624361105		[learning rate: 0.00082594]
		[batch 20/20] avg loss: 0.1709823390793498		[learning rate: 0.00082394]
	Learning Rate: 0.000823938
	LOSS [training: 0.15354061266148042 | validation: 0.20995361559768735]
	TIME [epoch: 8.27 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22247548091995178		[learning rate: 0.00082194]
		[batch 20/20] avg loss: 0.28032883259323316		[learning rate: 0.00081995]
	Learning Rate: 0.000819954
	LOSS [training: 0.2514021567565925 | validation: 0.8460026150077691]
	TIME [epoch: 8.26 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36938261036711073		[learning rate: 0.00081797]
		[batch 20/20] avg loss: 0.3193620390268592		[learning rate: 0.00081599]
	Learning Rate: 0.000815989
	LOSS [training: 0.344372324696985 | validation: 0.17762587758390186]
	TIME [epoch: 8.3 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11580570597341389		[learning rate: 0.00081401]
		[batch 20/20] avg loss: 0.11632947457864802		[learning rate: 0.00081204]
	Learning Rate: 0.000812043
	LOSS [training: 0.11606759027603095 | validation: 0.08083503242380385]
	TIME [epoch: 8.27 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12455742540732298		[learning rate: 0.00081008]
		[batch 20/20] avg loss: 0.17808666871493734		[learning rate: 0.00080812]
	Learning Rate: 0.000808116
	LOSS [training: 0.15132204706113014 | validation: 0.07259915621603079]
	TIME [epoch: 8.26 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23681014323763216		[learning rate: 0.00080616]
		[batch 20/20] avg loss: 0.11262486354769888		[learning rate: 0.00080421]
	Learning Rate: 0.000804208
	LOSS [training: 0.1747175033926655 | validation: 0.0643848662359744]
	TIME [epoch: 8.28 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11944436530761082		[learning rate: 0.00080226]
		[batch 20/20] avg loss: 0.11201997987288123		[learning rate: 0.00080032]
	Learning Rate: 0.000800319
	LOSS [training: 0.11573217259024601 | validation: 0.08263995346049521]
	TIME [epoch: 8.28 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1451534092932671		[learning rate: 0.00079838]
		[batch 20/20] avg loss: 0.09688935137476234		[learning rate: 0.00079645]
	Learning Rate: 0.000796449
	LOSS [training: 0.1210213803340147 | validation: 0.11142270297744042]
	TIME [epoch: 8.28 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08725781220299797		[learning rate: 0.00079452]
		[batch 20/20] avg loss: 0.12879978727436028		[learning rate: 0.0007926]
	Learning Rate: 0.000792597
	LOSS [training: 0.10802879973867911 | validation: 0.0555359444897401]
	TIME [epoch: 8.27 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12258230904175178		[learning rate: 0.00079068]
		[batch 20/20] avg loss: 0.11262656523033124		[learning rate: 0.00078876]
	Learning Rate: 0.000788765
	LOSS [training: 0.11760443713604152 | validation: 0.16336201838304626]
	TIME [epoch: 8.27 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15980234646115915		[learning rate: 0.00078686]
		[batch 20/20] avg loss: 0.12741363478387474		[learning rate: 0.00078495]
	Learning Rate: 0.00078495
	LOSS [training: 0.1436079906225169 | validation: 0.14893693352800147]
	TIME [epoch: 8.26 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17428402456991093		[learning rate: 0.00078305]
		[batch 20/20] avg loss: 0.1329164635838051		[learning rate: 0.00078115]
	Learning Rate: 0.000781154
	LOSS [training: 0.153600244076858 | validation: 0.06709424699902684]
	TIME [epoch: 8.29 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14483860543070237		[learning rate: 0.00077926]
		[batch 20/20] avg loss: 0.13020857229411173		[learning rate: 0.00077738]
	Learning Rate: 0.000777377
	LOSS [training: 0.13752358886240706 | validation: 0.08066306687120851]
	TIME [epoch: 8.27 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09935909753394451		[learning rate: 0.00077549]
		[batch 20/20] avg loss: 0.12961113374710814		[learning rate: 0.00077362]
	Learning Rate: 0.000773618
	LOSS [training: 0.1144851156405263 | validation: 0.09108673563876815]
	TIME [epoch: 8.27 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10119782650425588		[learning rate: 0.00077174]
		[batch 20/20] avg loss: 0.09434088272242248		[learning rate: 0.00076988]
	Learning Rate: 0.000769877
	LOSS [training: 0.0977693546133392 | validation: 0.10200168418658966]
	TIME [epoch: 8.27 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13142530719568274		[learning rate: 0.00076801]
		[batch 20/20] avg loss: 0.10638616281342432		[learning rate: 0.00076615]
	Learning Rate: 0.000766154
	LOSS [training: 0.11890573500455355 | validation: 0.0750354052123797]
	TIME [epoch: 8.29 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10898077380193885		[learning rate: 0.0007643]
		[batch 20/20] avg loss: 0.08408837543439461		[learning rate: 0.00076245]
	Learning Rate: 0.000762448
	LOSS [training: 0.09653457461816675 | validation: 0.08621329308759304]
	TIME [epoch: 8.29 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10772359993772791		[learning rate: 0.0007606]
		[batch 20/20] avg loss: 0.09558507367490146		[learning rate: 0.00075876]
	Learning Rate: 0.000758761
	LOSS [training: 0.10165433680631468 | validation: 0.09364526362903627]
	TIME [epoch: 8.29 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1260851287979824		[learning rate: 0.00075692]
		[batch 20/20] avg loss: 0.12585841421355992		[learning rate: 0.00075509]
	Learning Rate: 0.000755092
	LOSS [training: 0.12597177150577119 | validation: 0.1010105782344953]
	TIME [epoch: 8.28 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09277801585669301		[learning rate: 0.00075326]
		[batch 20/20] avg loss: 0.10415293938569141		[learning rate: 0.00075144]
	Learning Rate: 0.000751441
	LOSS [training: 0.0984654776211922 | validation: 0.05632320885414399]
	TIME [epoch: 8.29 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08919742801478767		[learning rate: 0.00074962]
		[batch 20/20] avg loss: 0.08170819800980922		[learning rate: 0.00074781]
	Learning Rate: 0.000747807
	LOSS [training: 0.08545281301229844 | validation: 0.08269125425570276]
	TIME [epoch: 8.3 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18869980035499673		[learning rate: 0.000746]
		[batch 20/20] avg loss: 0.09748454123398144		[learning rate: 0.00074419]
	Learning Rate: 0.000744191
	LOSS [training: 0.14309217079448905 | validation: 0.09952043597704288]
	TIME [epoch: 8.29 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1399370527440031		[learning rate: 0.00074239]
		[batch 20/20] avg loss: 0.08965055597233715		[learning rate: 0.00074059]
	Learning Rate: 0.000740592
	LOSS [training: 0.11479380435817013 | validation: 0.0519660181450079]
	TIME [epoch: 8.28 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11214583761664787		[learning rate: 0.0007388]
		[batch 20/20] avg loss: 0.09780640424484843		[learning rate: 0.00073701]
	Learning Rate: 0.000737011
	LOSS [training: 0.10497612093074815 | validation: 0.05348657215282546]
	TIME [epoch: 8.28 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09593602217416723		[learning rate: 0.00073523]
		[batch 20/20] avg loss: 0.10752253779528424		[learning rate: 0.00073345]
	Learning Rate: 0.000733446
	LOSS [training: 0.10172927998472574 | validation: 0.07830156227580963]
	TIME [epoch: 8.31 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12037756119189798		[learning rate: 0.00073167]
		[batch 20/20] avg loss: 0.06890836394556848		[learning rate: 0.0007299]
	Learning Rate: 0.0007299
	LOSS [training: 0.09464296256873324 | validation: 0.05964026676437642]
	TIME [epoch: 8.28 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09495227157000886		[learning rate: 0.00072813]
		[batch 20/20] avg loss: 0.10023695478321411		[learning rate: 0.00072637]
	Learning Rate: 0.00072637
	LOSS [training: 0.09759461317661147 | validation: 0.07511443818723458]
	TIME [epoch: 8.29 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07919141090976875		[learning rate: 0.00072461]
		[batch 20/20] avg loss: 0.0744603341282712		[learning rate: 0.00072286]
	Learning Rate: 0.000722857
	LOSS [training: 0.07682587251901998 | validation: 0.06766637955713281]
	TIME [epoch: 8.28 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09641970833438131		[learning rate: 0.00072111]
		[batch 20/20] avg loss: 0.1164387113716013		[learning rate: 0.00071936]
	Learning Rate: 0.000719362
	LOSS [training: 0.10642920985299129 | validation: 0.07153334444094846]
	TIME [epoch: 8.28 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1098440098656479		[learning rate: 0.00071762]
		[batch 20/20] avg loss: 0.11938845394602597		[learning rate: 0.00071588]
	Learning Rate: 0.000715883
	LOSS [training: 0.11461623190583692 | validation: 0.11182673335313598]
	TIME [epoch: 8.3 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10588563004388865		[learning rate: 0.00071415]
		[batch 20/20] avg loss: 0.08800962105889445		[learning rate: 0.00071242]
	Learning Rate: 0.000712421
	LOSS [training: 0.09694762555139154 | validation: 0.05288496860853123]
	TIME [epoch: 8.28 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1329301127148244		[learning rate: 0.0007107]
		[batch 20/20] avg loss: 0.14502252300868784		[learning rate: 0.00070898]
	Learning Rate: 0.000708976
	LOSS [training: 0.13897631786175613 | validation: 0.09330343332682114]
	TIME [epoch: 8.29 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0992535749753448		[learning rate: 0.00070726]
		[batch 20/20] avg loss: 0.08776950464279586		[learning rate: 0.00070555]
	Learning Rate: 0.000705548
	LOSS [training: 0.0935115398090703 | validation: 0.06113819820276374]
	TIME [epoch: 8.29 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07811052656336599		[learning rate: 0.00070384]
		[batch 20/20] avg loss: 0.08159922139176022		[learning rate: 0.00070214]
	Learning Rate: 0.000702136
	LOSS [training: 0.07985487397756312 | validation: 0.06534564867295613]
	TIME [epoch: 8.3 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07377494869383826		[learning rate: 0.00070044]
		[batch 20/20] avg loss: 0.10520762026121058		[learning rate: 0.00069874]
	Learning Rate: 0.00069874
	LOSS [training: 0.08949128447752441 | validation: 0.1314181458621795]
	TIME [epoch: 8.28 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09178780569112216		[learning rate: 0.00069705]
		[batch 20/20] avg loss: 0.08378123845403986		[learning rate: 0.00069536]
	Learning Rate: 0.000695361
	LOSS [training: 0.087784522072581 | validation: 0.06216784599786217]
	TIME [epoch: 8.28 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08393295322833012		[learning rate: 0.00069368]
		[batch 20/20] avg loss: 0.09310817089764271		[learning rate: 0.000692]
	Learning Rate: 0.000691999
	LOSS [training: 0.08852056206298645 | validation: 0.1195099972706862]
	TIME [epoch: 8.28 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12245410770801415		[learning rate: 0.00069032]
		[batch 20/20] avg loss: 0.07270859295524917		[learning rate: 0.00068865]
	Learning Rate: 0.000688652
	LOSS [training: 0.09758135033163166 | validation: 0.06260899873074996]
	TIME [epoch: 8.31 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07351005591746519		[learning rate: 0.00068699]
		[batch 20/20] avg loss: 0.09288906468891242		[learning rate: 0.00068532]
	Learning Rate: 0.000685322
	LOSS [training: 0.0831995603031888 | validation: 0.09293555050132603]
	TIME [epoch: 8.28 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09446616494912921		[learning rate: 0.00068366]
		[batch 20/20] avg loss: 0.07027452874847666		[learning rate: 0.00068201]
	Learning Rate: 0.000682008
	LOSS [training: 0.08237034684880293 | validation: 0.11018154841259745]
	TIME [epoch: 8.29 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09064708374940195		[learning rate: 0.00068036]
		[batch 20/20] avg loss: 0.078848260514364		[learning rate: 0.00067871]
	Learning Rate: 0.00067871
	LOSS [training: 0.08474767213188297 | validation: 0.04894988986905078]
	TIME [epoch: 8.28 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08801430483908226		[learning rate: 0.00067707]
		[batch 20/20] avg loss: 0.10689429642480568		[learning rate: 0.00067543]
	Learning Rate: 0.000675428
	LOSS [training: 0.09745430063194396 | validation: 0.10592362722614064]
	TIME [epoch: 8.28 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09350045397517914		[learning rate: 0.00067379]
		[batch 20/20] avg loss: 0.11053103216954216		[learning rate: 0.00067216]
	Learning Rate: 0.000672162
	LOSS [training: 0.10201574307236068 | validation: 0.035492339027547185]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_607.pth
	Model improved!!!
EPOCH 608/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06351739931157449		[learning rate: 0.00067053]
		[batch 20/20] avg loss: 0.07854377973930363		[learning rate: 0.00066891]
	Learning Rate: 0.000668911
	LOSS [training: 0.07103058952543906 | validation: 0.08465221639956885]
	TIME [epoch: 8.28 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12043126896562403		[learning rate: 0.00066729]
		[batch 20/20] avg loss: 0.07113185119047338		[learning rate: 0.00066568]
	Learning Rate: 0.000665676
	LOSS [training: 0.0957815600780487 | validation: 0.06695171731329899]
	TIME [epoch: 8.27 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06387088458287227		[learning rate: 0.00066406]
		[batch 20/20] avg loss: 0.10201298803089325		[learning rate: 0.00066246]
	Learning Rate: 0.000662457
	LOSS [training: 0.08294193630688276 | validation: 0.028990711793608723]
	TIME [epoch: 8.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_610.pth
	Model improved!!!
EPOCH 611/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.061671209150176064		[learning rate: 0.00066085]
		[batch 20/20] avg loss: 0.07450276603048525		[learning rate: 0.00065925]
	Learning Rate: 0.000659254
	LOSS [training: 0.06808698759033066 | validation: 0.04517283433985364]
	TIME [epoch: 8.3 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0970688036457311		[learning rate: 0.00065766]
		[batch 20/20] avg loss: 0.09012196931507972		[learning rate: 0.00065607]
	Learning Rate: 0.000656066
	LOSS [training: 0.09359538648040541 | validation: 0.05499926858706759]
	TIME [epoch: 8.27 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10267169550538642		[learning rate: 0.00065448]
		[batch 20/20] avg loss: 0.10287270626800415		[learning rate: 0.00065289]
	Learning Rate: 0.000652893
	LOSS [training: 0.10277220088669528 | validation: 0.03700787625605592]
	TIME [epoch: 8.27 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07232487894380826		[learning rate: 0.00065131]
		[batch 20/20] avg loss: 0.08243222218121668		[learning rate: 0.00064974]
	Learning Rate: 0.000649736
	LOSS [training: 0.07737855056251247 | validation: 0.03906513933275197]
	TIME [epoch: 8.27 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0999029575621356		[learning rate: 0.00064816]
		[batch 20/20] avg loss: 0.10371220247560435		[learning rate: 0.00064659]
	Learning Rate: 0.000646594
	LOSS [training: 0.10180758001886998 | validation: 0.040355528065964]
	TIME [epoch: 8.28 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08365744483306321		[learning rate: 0.00064503]
		[batch 20/20] avg loss: 0.07177130011635803		[learning rate: 0.00064347]
	Learning Rate: 0.000643467
	LOSS [training: 0.07771437247471061 | validation: 0.033866829192258606]
	TIME [epoch: 8.28 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11835319245894918		[learning rate: 0.00064191]
		[batch 20/20] avg loss: 0.08627669294366003		[learning rate: 0.00064036]
	Learning Rate: 0.000640355
	LOSS [training: 0.10231494270130459 | validation: 0.07000682703851387]
	TIME [epoch: 8.27 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10339063692073056		[learning rate: 0.00063881]
		[batch 20/20] avg loss: 0.0794668906300135		[learning rate: 0.00063726]
	Learning Rate: 0.000637259
	LOSS [training: 0.09142876377537203 | validation: 0.02817090333495088]
	TIME [epoch: 8.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_618.pth
	Model improved!!!
EPOCH 619/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09270058444701242		[learning rate: 0.00063572]
		[batch 20/20] avg loss: 0.08332911597638425		[learning rate: 0.00063418]
	Learning Rate: 0.000634177
	LOSS [training: 0.08801485021169833 | validation: 0.1492745334055499]
	TIME [epoch: 8.28 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12357630827654387		[learning rate: 0.00063264]
		[batch 20/20] avg loss: 0.07052498417241207		[learning rate: 0.00063111]
	Learning Rate: 0.00063111
	LOSS [training: 0.09705064622447797 | validation: 0.10930956122750406]
	TIME [epoch: 8.31 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07536055826697524		[learning rate: 0.00062958]
		[batch 20/20] avg loss: 0.0865355288196328		[learning rate: 0.00062806]
	Learning Rate: 0.000628058
	LOSS [training: 0.08094804354330402 | validation: 0.029956978562813964]
	TIME [epoch: 8.28 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06337010835333542		[learning rate: 0.00062654]
		[batch 20/20] avg loss: 0.07144801746568091		[learning rate: 0.00062502]
	Learning Rate: 0.000625021
	LOSS [training: 0.06740906290950818 | validation: 0.051486589348297446]
	TIME [epoch: 8.28 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07692358604472536		[learning rate: 0.00062351]
		[batch 20/20] avg loss: 0.08750345264156131		[learning rate: 0.000622]
	Learning Rate: 0.000621999
	LOSS [training: 0.08221351934314335 | validation: 0.10732243685985621]
	TIME [epoch: 8.28 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10993659850766982		[learning rate: 0.00062049]
		[batch 20/20] avg loss: 0.08017580567907022		[learning rate: 0.00061899]
	Learning Rate: 0.000618991
	LOSS [training: 0.09505620209337003 | validation: 0.12490398720600412]
	TIME [epoch: 8.29 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10182771680463756		[learning rate: 0.00061749]
		[batch 20/20] avg loss: 0.07836867164028125		[learning rate: 0.000616]
	Learning Rate: 0.000615997
	LOSS [training: 0.09009819422245942 | validation: 0.07979002945101113]
	TIME [epoch: 8.28 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07985468142343896		[learning rate: 0.00061451]
		[batch 20/20] avg loss: 0.08975039114797852		[learning rate: 0.00061302]
	Learning Rate: 0.000613019
	LOSS [training: 0.08480253628570875 | validation: 0.17396102567245478]
	TIME [epoch: 8.28 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12602142292616425		[learning rate: 0.00061153]
		[batch 20/20] avg loss: 0.10501414347931562		[learning rate: 0.00061005]
	Learning Rate: 0.000610054
	LOSS [training: 0.11551778320273993 | validation: 0.04273919885247572]
	TIME [epoch: 8.28 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18307783973337127		[learning rate: 0.00060858]
		[batch 20/20] avg loss: 0.0754924917144039		[learning rate: 0.0006071]
	Learning Rate: 0.000607104
	LOSS [training: 0.12928516572388757 | validation: 0.04654549310971087]
	TIME [epoch: 8.28 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0910266578382609		[learning rate: 0.00060563]
		[batch 20/20] avg loss: 0.07989786317639877		[learning rate: 0.00060417]
	Learning Rate: 0.000604168
	LOSS [training: 0.08546226050732986 | validation: 0.026604996575478854]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_629.pth
	Model improved!!!
EPOCH 630/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05815594706611157		[learning rate: 0.00060271]
		[batch 20/20] avg loss: 0.07972987744345328		[learning rate: 0.00060125]
	Learning Rate: 0.000601247
	LOSS [training: 0.06894291225478241 | validation: 0.07183650097068639]
	TIME [epoch: 8.29 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06735787849246704		[learning rate: 0.00059979]
		[batch 20/20] avg loss: 0.12398273209169416		[learning rate: 0.00059834]
	Learning Rate: 0.000598339
	LOSS [training: 0.0956703052920806 | validation: 0.12084655556154647]
	TIME [epoch: 8.28 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09922167640611715		[learning rate: 0.00059689]
		[batch 20/20] avg loss: 0.08276523521729243		[learning rate: 0.00059545]
	Learning Rate: 0.000595446
	LOSS [training: 0.09099345581170479 | validation: 0.07554736211250306]
	TIME [epoch: 8.28 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07192271545600117		[learning rate: 0.000594]
		[batch 20/20] avg loss: 0.0712369523762291		[learning rate: 0.00059257]
	Learning Rate: 0.000592566
	LOSS [training: 0.07157983391611512 | validation: 0.040163372444703825]
	TIME [epoch: 8.3 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09883124764677717		[learning rate: 0.00059113]
		[batch 20/20] avg loss: 0.09658560997332925		[learning rate: 0.0005897]
	Learning Rate: 0.000589701
	LOSS [training: 0.09770842881005323 | validation: 0.03839680322265902]
	TIME [epoch: 8.27 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0814682637956317		[learning rate: 0.00058827]
		[batch 20/20] avg loss: 0.08622606914099212		[learning rate: 0.00058685]
	Learning Rate: 0.000586849
	LOSS [training: 0.08384716646831192 | validation: 0.06403200330431992]
	TIME [epoch: 8.27 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11629701606124032		[learning rate: 0.00058543]
		[batch 20/20] avg loss: 0.08861929681486011		[learning rate: 0.00058401]
	Learning Rate: 0.000584011
	LOSS [training: 0.10245815643805023 | validation: 0.058244178370744956]
	TIME [epoch: 8.27 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06572885702330489		[learning rate: 0.0005826]
		[batch 20/20] avg loss: 0.0890602171137406		[learning rate: 0.00058119]
	Learning Rate: 0.000581187
	LOSS [training: 0.07739453706852276 | validation: 0.07040717372269248]
	TIME [epoch: 8.29 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07182993189824444		[learning rate: 0.00057978]
		[batch 20/20] avg loss: 0.09379029413528199		[learning rate: 0.00057838]
	Learning Rate: 0.000578376
	LOSS [training: 0.0828101130167632 | validation: 0.040024854352410585]
	TIME [epoch: 8.28 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08949499975695716		[learning rate: 0.00057698]
		[batch 20/20] avg loss: 0.06577591784655262		[learning rate: 0.00057558]
	Learning Rate: 0.000575579
	LOSS [training: 0.0776354588017549 | validation: 0.05715190542760414]
	TIME [epoch: 8.26 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09330532343232349		[learning rate: 0.00057419]
		[batch 20/20] avg loss: 0.0917692743271502		[learning rate: 0.0005728]
	Learning Rate: 0.000572796
	LOSS [training: 0.09253729887973684 | validation: 0.05994901485800609]
	TIME [epoch: 8.28 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06699127522806364		[learning rate: 0.00057141]
		[batch 20/20] avg loss: 0.09068993873619625		[learning rate: 0.00057003]
	Learning Rate: 0.000570026
	LOSS [training: 0.07884060698212995 | validation: 0.1076219077600902]
	TIME [epoch: 8.27 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08081310643800979		[learning rate: 0.00056865]
		[batch 20/20] avg loss: 0.08057691822293274		[learning rate: 0.00056727]
	Learning Rate: 0.00056727
	LOSS [training: 0.08069501233047126 | validation: 0.036702277472605224]
	TIME [epoch: 8.29 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06576404887031405		[learning rate: 0.0005659]
		[batch 20/20] avg loss: 0.06494567316398259		[learning rate: 0.00056453]
	Learning Rate: 0.000564526
	LOSS [training: 0.06535486101714831 | validation: 0.05967067793451811]
	TIME [epoch: 8.27 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08156966449219487		[learning rate: 0.00056316]
		[batch 20/20] avg loss: 0.11148389386509941		[learning rate: 0.0005618]
	Learning Rate: 0.000561796
	LOSS [training: 0.09652677917864713 | validation: 0.10002116742984543]
	TIME [epoch: 8.28 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07626249467520338		[learning rate: 0.00056044]
		[batch 20/20] avg loss: 0.06366479141035628		[learning rate: 0.00055908]
	Learning Rate: 0.00055908
	LOSS [training: 0.06996364304277983 | validation: 0.033701167476419824]
	TIME [epoch: 8.27 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0835179448977332		[learning rate: 0.00055773]
		[batch 20/20] avg loss: 0.05741396981749488		[learning rate: 0.00055638]
	Learning Rate: 0.000556376
	LOSS [training: 0.07046595735761403 | validation: 0.03491007800864841]
	TIME [epoch: 8.3 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08416888035836476		[learning rate: 0.00055503]
		[batch 20/20] avg loss: 0.07701654958975089		[learning rate: 0.00055369]
	Learning Rate: 0.000553685
	LOSS [training: 0.08059271497405782 | validation: 0.05161972183289898]
	TIME [epoch: 8.28 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.084409110150622		[learning rate: 0.00055235]
		[batch 20/20] avg loss: 0.07616646048793548		[learning rate: 0.00055101]
	Learning Rate: 0.000551008
	LOSS [training: 0.08028778531927874 | validation: 0.032424545592496135]
	TIME [epoch: 8.27 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07911775446661888		[learning rate: 0.00054967]
		[batch 20/20] avg loss: 0.07395815440717253		[learning rate: 0.00054834]
	Learning Rate: 0.000548343
	LOSS [training: 0.07653795443689569 | validation: 0.2532552301614842]
	TIME [epoch: 8.28 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10162345884947173		[learning rate: 0.00054702]
		[batch 20/20] avg loss: 0.07907906978161203		[learning rate: 0.00054569]
	Learning Rate: 0.000545692
	LOSS [training: 0.09035126431554188 | validation: 0.04178868147752976]
	TIME [epoch: 8.29 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0946967784768243		[learning rate: 0.00054437]
		[batch 20/20] avg loss: 0.06503795462089099		[learning rate: 0.00054305]
	Learning Rate: 0.000543053
	LOSS [training: 0.07986736654885764 | validation: 0.04564113999721585]
	TIME [epoch: 8.27 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06794518233078022		[learning rate: 0.00054174]
		[batch 20/20] avg loss: 0.08795057073720687		[learning rate: 0.00054043]
	Learning Rate: 0.000540427
	LOSS [training: 0.07794787653399354 | validation: 0.07147832521958278]
	TIME [epoch: 8.27 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08151993959247114		[learning rate: 0.00053912]
		[batch 20/20] avg loss: 0.086580118985929		[learning rate: 0.00053781]
	Learning Rate: 0.000537813
	LOSS [training: 0.08405002928920006 | validation: 0.0527406908374843]
	TIME [epoch: 8.28 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06870038259266233		[learning rate: 0.00053651]
		[batch 20/20] avg loss: 0.09406544564032639		[learning rate: 0.00053521]
	Learning Rate: 0.000535213
	LOSS [training: 0.08138291411649434 | validation: 0.056266003429423575]
	TIME [epoch: 8.27 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07622053292710414		[learning rate: 0.00053392]
		[batch 20/20] avg loss: 0.09274294042245547		[learning rate: 0.00053262]
	Learning Rate: 0.000532624
	LOSS [training: 0.08448173667477979 | validation: 0.032524005393814094]
	TIME [epoch: 8.29 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0648518296193015		[learning rate: 0.00053134]
		[batch 20/20] avg loss: 0.08561732949902881		[learning rate: 0.00053005]
	Learning Rate: 0.000530049
	LOSS [training: 0.07523457955916515 | validation: 0.07408141014688482]
	TIME [epoch: 8.27 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11377858691280562		[learning rate: 0.00052877]
		[batch 20/20] avg loss: 0.09283621810405088		[learning rate: 0.00052749]
	Learning Rate: 0.000527485
	LOSS [training: 0.10330740250842829 | validation: 0.03593318403344921]
	TIME [epoch: 8.26 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06722453197896747		[learning rate: 0.00052621]
		[batch 20/20] avg loss: 0.0659699035666573		[learning rate: 0.00052493]
	Learning Rate: 0.000524935
	LOSS [training: 0.06659721777281238 | validation: 0.04977202531065996]
	TIME [epoch: 8.26 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0743481115552044		[learning rate: 0.00052366]
		[batch 20/20] avg loss: 0.07988934512869111		[learning rate: 0.0005224]
	Learning Rate: 0.000522396
	LOSS [training: 0.07711872834194776 | validation: 0.07631083516107649]
	TIME [epoch: 8.29 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07668431210871608		[learning rate: 0.00052113]
		[batch 20/20] avg loss: 0.06780913205386845		[learning rate: 0.00051987]
	Learning Rate: 0.00051987
	LOSS [training: 0.07224672208129228 | validation: 0.04742733067137614]
	TIME [epoch: 8.28 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06483078833383872		[learning rate: 0.00051861]
		[batch 20/20] avg loss: 0.07186527649604504		[learning rate: 0.00051736]
	Learning Rate: 0.000517356
	LOSS [training: 0.06834803241494188 | validation: 0.08259411022355582]
	TIME [epoch: 8.27 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07444891410493219		[learning rate: 0.0005161]
		[batch 20/20] avg loss: 0.059241945169162		[learning rate: 0.00051485]
	Learning Rate: 0.000514854
	LOSS [training: 0.06684542963704712 | validation: 0.07558206249521357]
	TIME [epoch: 8.27 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07317497117206506		[learning rate: 0.00051361]
		[batch 20/20] avg loss: 0.08252971730562886		[learning rate: 0.00051236]
	Learning Rate: 0.000512364
	LOSS [training: 0.07785234423884696 | validation: 0.04540637449822303]
	TIME [epoch: 8.29 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07661879132749386		[learning rate: 0.00051112]
		[batch 20/20] avg loss: 0.061373330277568784		[learning rate: 0.00050989]
	Learning Rate: 0.000509887
	LOSS [training: 0.06899606080253132 | validation: 0.08159882535367434]
	TIME [epoch: 8.28 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07198004351680351		[learning rate: 0.00050865]
		[batch 20/20] avg loss: 0.07336311349903905		[learning rate: 0.00050742]
	Learning Rate: 0.000507421
	LOSS [training: 0.0726715785079213 | validation: 0.06026732288979049]
	TIME [epoch: 8.27 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07845891991396133		[learning rate: 0.00050619]
		[batch 20/20] avg loss: 0.08635833667481999		[learning rate: 0.00050497]
	Learning Rate: 0.000504967
	LOSS [training: 0.08240862829439063 | validation: 0.032671303410339456]
	TIME [epoch: 8.27 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.056171131426972665		[learning rate: 0.00050374]
		[batch 20/20] avg loss: 0.07009160289885207		[learning rate: 0.00050253]
	Learning Rate: 0.000502525
	LOSS [training: 0.06313136716291237 | validation: 0.032239947162510114]
	TIME [epoch: 8.27 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07801986400857079		[learning rate: 0.00050131]
		[batch 20/20] avg loss: 0.062161309209796047		[learning rate: 0.0005001]
	Learning Rate: 0.000500095
	LOSS [training: 0.07009058660918341 | validation: 0.06071079649235458]
	TIME [epoch: 8.3 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.073640870253139		[learning rate: 0.00049888]
		[batch 20/20] avg loss: 0.08192479676261613		[learning rate: 0.00049768]
	Learning Rate: 0.000497677
	LOSS [training: 0.07778283350787757 | validation: 0.024274617023955454]
	TIME [epoch: 8.26 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_669.pth
	Model improved!!!
EPOCH 670/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07329816466420333		[learning rate: 0.00049647]
		[batch 20/20] avg loss: 0.06772830056455303		[learning rate: 0.00049527]
	Learning Rate: 0.00049527
	LOSS [training: 0.07051323261437818 | validation: 0.04636050060637242]
	TIME [epoch: 8.28 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06456087686129502		[learning rate: 0.00049407]
		[batch 20/20] avg loss: 0.08649561801089181		[learning rate: 0.00049288]
	Learning Rate: 0.000492875
	LOSS [training: 0.07552824743609342 | validation: 0.12411378534818446]
	TIME [epoch: 8.27 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1019841771745984		[learning rate: 0.00049168]
		[batch 20/20] avg loss: 0.0709423601318166		[learning rate: 0.00049049]
	Learning Rate: 0.000490492
	LOSS [training: 0.0864632686532075 | validation: 0.031326654431499845]
	TIME [epoch: 8.3 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08288622675166359		[learning rate: 0.0004893]
		[batch 20/20] avg loss: 0.06407246271582075		[learning rate: 0.00048812]
	Learning Rate: 0.00048812
	LOSS [training: 0.07347934473374215 | validation: 0.1268512489777197]
	TIME [epoch: 8.28 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10200861771434751		[learning rate: 0.00048694]
		[batch 20/20] avg loss: 0.06668743335936105		[learning rate: 0.00048576]
	Learning Rate: 0.000485759
	LOSS [training: 0.08434802553685428 | validation: 0.03825725629075301]
	TIME [epoch: 8.27 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0841396517736456		[learning rate: 0.00048458]
		[batch 20/20] avg loss: 0.06124559008020639		[learning rate: 0.00048341]
	Learning Rate: 0.00048341
	LOSS [training: 0.072692620926926 | validation: 0.20344101690143074]
	TIME [epoch: 8.27 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13496976299757468		[learning rate: 0.00048224]
		[batch 20/20] avg loss: 0.08981566938138016		[learning rate: 0.00048107]
	Learning Rate: 0.000481072
	LOSS [training: 0.11239271618947744 | validation: 0.058054600323960516]
	TIME [epoch: 8.29 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06859385024472467		[learning rate: 0.00047991]
		[batch 20/20] avg loss: 0.06521647355354347		[learning rate: 0.00047875]
	Learning Rate: 0.000478746
	LOSS [training: 0.06690516189913406 | validation: 0.036743495760144004]
	TIME [epoch: 8.3 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06725859432516833		[learning rate: 0.00047759]
		[batch 20/20] avg loss: 0.06790392206903802		[learning rate: 0.00047643]
	Learning Rate: 0.000476431
	LOSS [training: 0.06758125819710317 | validation: 0.08274512161166139]
	TIME [epoch: 8.27 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08217195727912255		[learning rate: 0.00047528]
		[batch 20/20] avg loss: 0.07720864480477843		[learning rate: 0.00047413]
	Learning Rate: 0.000474127
	LOSS [training: 0.07969030104195049 | validation: 0.049766594029712084]
	TIME [epoch: 8.28 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07032497799043029		[learning rate: 0.00047298]
		[batch 20/20] avg loss: 0.08773507895779589		[learning rate: 0.00047183]
	Learning Rate: 0.000471834
	LOSS [training: 0.07903002847411308 | validation: 0.054472207061083466]
	TIME [epoch: 8.28 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06846794350304836		[learning rate: 0.00047069]
		[batch 20/20] avg loss: 0.07148465508520505		[learning rate: 0.00046955]
	Learning Rate: 0.000469553
	LOSS [training: 0.06997629929412671 | validation: 0.04741189897358747]
	TIME [epoch: 8.3 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0662448103124713		[learning rate: 0.00046842]
		[batch 20/20] avg loss: 0.0922629664013995		[learning rate: 0.00046728]
	Learning Rate: 0.000467282
	LOSS [training: 0.07925388835693539 | validation: 0.036314404284242124]
	TIME [epoch: 8.29 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06938657051205277		[learning rate: 0.00046615]
		[batch 20/20] avg loss: 0.05873453641922163		[learning rate: 0.00046502]
	Learning Rate: 0.000465022
	LOSS [training: 0.0640605534656372 | validation: 0.07755013403170387]
	TIME [epoch: 8.28 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07675031943872665		[learning rate: 0.0004639]
		[batch 20/20] avg loss: 0.0913469501989759		[learning rate: 0.00046277]
	Learning Rate: 0.000462773
	LOSS [training: 0.08404863481885128 | validation: 0.030504079291926785]
	TIME [epoch: 8.29 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.062205871228953824		[learning rate: 0.00046165]
		[batch 20/20] avg loss: 0.09651083611496115		[learning rate: 0.00046054]
	Learning Rate: 0.000460536
	LOSS [training: 0.07935835367195747 | validation: 0.14851490656050625]
	TIME [epoch: 8.3 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09172979167770527		[learning rate: 0.00045942]
		[batch 20/20] avg loss: 0.062031489490178005		[learning rate: 0.00045831]
	Learning Rate: 0.000458309
	LOSS [training: 0.07688064058394165 | validation: 0.03634885787599934]
	TIME [epoch: 8.28 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08733121433987111		[learning rate: 0.0004572]
		[batch 20/20] avg loss: 0.07211932931535604		[learning rate: 0.00045609]
	Learning Rate: 0.000456092
	LOSS [training: 0.07972527182761359 | validation: 0.023378854087376052]
	TIME [epoch: 8.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_687.pth
	Model improved!!!
EPOCH 688/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07135490483604133		[learning rate: 0.00045499]
		[batch 20/20] avg loss: 0.07980527848287192		[learning rate: 0.00045389]
	Learning Rate: 0.000453887
	LOSS [training: 0.07558009165945663 | validation: 0.03400915771176932]
	TIME [epoch: 8.28 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0564619334463502		[learning rate: 0.00045279]
		[batch 20/20] avg loss: 0.07653490903580308		[learning rate: 0.00045169]
	Learning Rate: 0.000451692
	LOSS [training: 0.06649842124107663 | validation: 0.12323940768941673]
	TIME [epoch: 8.28 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09621530669650216		[learning rate: 0.0004506]
		[batch 20/20] avg loss: 0.05281933674961892		[learning rate: 0.00044951]
	Learning Rate: 0.000449507
	LOSS [training: 0.07451732172306053 | validation: 0.037080148439606324]
	TIME [epoch: 8.3 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06936614239184899		[learning rate: 0.00044842]
		[batch 20/20] avg loss: 0.05447171250193052		[learning rate: 0.00044733]
	Learning Rate: 0.000447334
	LOSS [training: 0.06191892744688976 | validation: 0.037348122016403175]
	TIME [epoch: 8.28 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06473065566619726		[learning rate: 0.00044625]
		[batch 20/20] avg loss: 0.054569386954970656		[learning rate: 0.00044517]
	Learning Rate: 0.00044517
	LOSS [training: 0.059650021310583945 | validation: 0.02709503965478859]
	TIME [epoch: 8.26 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08977389308912867		[learning rate: 0.00044409]
		[batch 20/20] avg loss: 0.08507897564529575		[learning rate: 0.00044302]
	Learning Rate: 0.000443018
	LOSS [training: 0.0874264343672122 | validation: 0.025719016063173235]
	TIME [epoch: 8.26 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10197560335619701		[learning rate: 0.00044195]
		[batch 20/20] avg loss: 0.09055483509855036		[learning rate: 0.00044088]
	Learning Rate: 0.000440875
	LOSS [training: 0.09626521922737367 | validation: 0.03944578123651942]
	TIME [epoch: 8.3 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09706154941284253		[learning rate: 0.00043981]
		[batch 20/20] avg loss: 0.07279105942125402		[learning rate: 0.00043874]
	Learning Rate: 0.000438743
	LOSS [training: 0.08492630441704828 | validation: 0.034756706230931314]
	TIME [epoch: 8.28 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0799662710111364		[learning rate: 0.00043768]
		[batch 20/20] avg loss: 0.07491354065858956		[learning rate: 0.00043662]
	Learning Rate: 0.000436622
	LOSS [training: 0.07743990583486297 | validation: 0.023564139574295172]
	TIME [epoch: 8.27 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06767552715592559		[learning rate: 0.00043556]
		[batch 20/20] avg loss: 0.057355264481899815		[learning rate: 0.00043451]
	Learning Rate: 0.00043451
	LOSS [training: 0.06251539581891272 | validation: 0.026588296532017084]
	TIME [epoch: 8.28 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08822924054535408		[learning rate: 0.00043346]
		[batch 20/20] avg loss: 0.18385703208905158		[learning rate: 0.00043241]
	Learning Rate: 0.000432409
	LOSS [training: 0.1360431363172028 | validation: 0.0342069211875037]
	TIME [epoch: 8.29 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.056028740770074414		[learning rate: 0.00043136]
		[batch 20/20] avg loss: 0.08956841137841669		[learning rate: 0.00043032]
	Learning Rate: 0.000430318
	LOSS [training: 0.07279857607424554 | validation: 0.026884241370461207]
	TIME [epoch: 8.29 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05753198370482977		[learning rate: 0.00042928]
		[batch 20/20] avg loss: 0.07224535941337634		[learning rate: 0.00042824]
	Learning Rate: 0.000428237
	LOSS [training: 0.06488867155910305 | validation: 0.04259567869178524]
	TIME [epoch: 8.28 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0764653655543468		[learning rate: 0.0004272]
		[batch 20/20] avg loss: 0.08115621163563158		[learning rate: 0.00042617]
	Learning Rate: 0.000426166
	LOSS [training: 0.07881078859498919 | validation: 0.06254155801495437]
	TIME [epoch: 8.27 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0725063303244253		[learning rate: 0.00042513]
		[batch 20/20] avg loss: 0.058478179957721456		[learning rate: 0.00042411]
	Learning Rate: 0.000424105
	LOSS [training: 0.06549225514107337 | validation: 0.04089351978434474]
	TIME [epoch: 8.27 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07903516751683602		[learning rate: 0.00042308]
		[batch 20/20] avg loss: 0.05991106239335344		[learning rate: 0.00042205]
	Learning Rate: 0.000422054
	LOSS [training: 0.06947311495509473 | validation: 0.02698626047532969]
	TIME [epoch: 8.31 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10170830281807575		[learning rate: 0.00042103]
		[batch 20/20] avg loss: 0.0550064584953132		[learning rate: 0.00042001]
	Learning Rate: 0.000420013
	LOSS [training: 0.07835738065669447 | validation: 0.03777303656369199]
	TIME [epoch: 8.27 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06678263924491341		[learning rate: 0.000419]
		[batch 20/20] avg loss: 0.05629061696003913		[learning rate: 0.00041798]
	Learning Rate: 0.000417982
	LOSS [training: 0.061536628102476267 | validation: 0.03844224311771714]
	TIME [epoch: 8.28 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.049623217803532675		[learning rate: 0.00041697]
		[batch 20/20] avg loss: 0.08295521695429249		[learning rate: 0.00041596]
	Learning Rate: 0.000415961
	LOSS [training: 0.0662892173789126 | validation: 0.1377006256840918]
	TIME [epoch: 8.28 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08497530190500205		[learning rate: 0.00041495]
		[batch 20/20] avg loss: 0.08100876318902188		[learning rate: 0.00041395]
	Learning Rate: 0.00041395
	LOSS [training: 0.08299203254701196 | validation: 0.05088216740609293]
	TIME [epoch: 8.3 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07243088937577141		[learning rate: 0.00041295]
		[batch 20/20] avg loss: 0.07032684664763153		[learning rate: 0.00041195]
	Learning Rate: 0.000411948
	LOSS [training: 0.07137886801170146 | validation: 0.05190880335383516]
	TIME [epoch: 8.27 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0661555161327323		[learning rate: 0.00041095]
		[batch 20/20] avg loss: 0.06850491333676469		[learning rate: 0.00040996]
	Learning Rate: 0.000409956
	LOSS [training: 0.06733021473474851 | validation: 0.033193594078696986]
	TIME [epoch: 8.28 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0519493556342455		[learning rate: 0.00040896]
		[batch 20/20] avg loss: 0.06868419759950094		[learning rate: 0.00040797]
	Learning Rate: 0.000407973
	LOSS [training: 0.0603167766168732 | validation: 0.026132257716106305]
	TIME [epoch: 8.28 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0651416316166792		[learning rate: 0.00040699]
		[batch 20/20] avg loss: 0.05994355381888884		[learning rate: 0.000406]
	Learning Rate: 0.000406
	LOSS [training: 0.062542592717784 | validation: 0.02695559089498929]
	TIME [epoch: 8.28 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0981845637743599		[learning rate: 0.00040502]
		[batch 20/20] avg loss: 0.083613531696454		[learning rate: 0.00040404]
	Learning Rate: 0.000404037
	LOSS [training: 0.09089904773540694 | validation: 0.024261220106174992]
	TIME [epoch: 8.3 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05680877815641766		[learning rate: 0.00040306]
		[batch 20/20] avg loss: 0.0788371420023448		[learning rate: 0.00040208]
	Learning Rate: 0.000402083
	LOSS [training: 0.06782296007938124 | validation: 0.06232976547613472]
	TIME [epoch: 8.27 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0679604986434933		[learning rate: 0.00040111]
		[batch 20/20] avg loss: 0.08616173190852343		[learning rate: 0.00040014]
	Learning Rate: 0.000400139
	LOSS [training: 0.07706111527600837 | validation: 0.0722402759025284]
	TIME [epoch: 8.27 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06774150448291849		[learning rate: 0.00039917]
		[batch 20/20] avg loss: 0.07212340471645431		[learning rate: 0.0003982]
	Learning Rate: 0.000398204
	LOSS [training: 0.06993245459968642 | validation: 0.029308490901686676]
	TIME [epoch: 8.27 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0678563190344001		[learning rate: 0.00039724]
		[batch 20/20] avg loss: 0.11860661875462838		[learning rate: 0.00039628]
	Learning Rate: 0.000396278
	LOSS [training: 0.09323146889451425 | validation: 0.08042550737411783]
	TIME [epoch: 8.3 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08166838460968275		[learning rate: 0.00039532]
		[batch 20/20] avg loss: 0.07673566034933228		[learning rate: 0.00039436]
	Learning Rate: 0.000394362
	LOSS [training: 0.07920202247950751 | validation: 0.030745503187839668]
	TIME [epoch: 8.27 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06929837642072866		[learning rate: 0.00039341]
		[batch 20/20] avg loss: 0.07968418628162863		[learning rate: 0.00039245]
	Learning Rate: 0.000392455
	LOSS [training: 0.07449128135117863 | validation: 0.03593077785542434]
	TIME [epoch: 8.28 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0667513474132734		[learning rate: 0.0003915]
		[batch 20/20] avg loss: 0.06164071334040969		[learning rate: 0.00039056]
	Learning Rate: 0.000390557
	LOSS [training: 0.06419603037684157 | validation: 0.06708648991042859]
	TIME [epoch: 8.27 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05867216214335726		[learning rate: 0.00038961]
		[batch 20/20] avg loss: 0.07287033901376143		[learning rate: 0.00038867]
	Learning Rate: 0.000388668
	LOSS [training: 0.06577125057855934 | validation: 0.04155857061316969]
	TIME [epoch: 8.28 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06354845148287531		[learning rate: 0.00038773]
		[batch 20/20] avg loss: 0.05312789739444949		[learning rate: 0.00038679]
	Learning Rate: 0.000386789
	LOSS [training: 0.05833817443866239 | validation: 0.036567440209539975]
	TIME [epoch: 8.28 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07006124252245655		[learning rate: 0.00038585]
		[batch 20/20] avg loss: 0.07396643517721734		[learning rate: 0.00038492]
	Learning Rate: 0.000384918
	LOSS [training: 0.07201383884983695 | validation: 0.04158512831471309]
	TIME [epoch: 8.27 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06854139230225581		[learning rate: 0.00038399]
		[batch 20/20] avg loss: 0.07003635802682844		[learning rate: 0.00038306]
	Learning Rate: 0.000383057
	LOSS [training: 0.06928887516454212 | validation: 0.032638007430329005]
	TIME [epoch: 8.28 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13318658160531371		[learning rate: 0.00038213]
		[batch 20/20] avg loss: 0.07221810304457298		[learning rate: 0.0003812]
	Learning Rate: 0.000381204
	LOSS [training: 0.10270234232494335 | validation: 0.028832722434310384]
	TIME [epoch: 8.27 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06290634444929806		[learning rate: 0.00038028]
		[batch 20/20] avg loss: 0.060368048860483324		[learning rate: 0.00037936]
	Learning Rate: 0.000379361
	LOSS [training: 0.06163719665489068 | validation: 0.03744597446456527]
	TIME [epoch: 8.3 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08489194936380774		[learning rate: 0.00037844]
		[batch 20/20] avg loss: 0.055187562413634164		[learning rate: 0.00037753]
	Learning Rate: 0.000377526
	LOSS [training: 0.07003975588872094 | validation: 0.05028668528786316]
	TIME [epoch: 8.27 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08847486648187798		[learning rate: 0.00037661]
		[batch 20/20] avg loss: 0.06339135605753651		[learning rate: 0.0003757]
	Learning Rate: 0.000375701
	LOSS [training: 0.07593311126970725 | validation: 0.059033615828189404]
	TIME [epoch: 8.27 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06894524948776808		[learning rate: 0.00037479]
		[batch 20/20] avg loss: 0.0731620689170033		[learning rate: 0.00037388]
	Learning Rate: 0.000373884
	LOSS [training: 0.07105365920238568 | validation: 0.04696827894405061]
	TIME [epoch: 8.27 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09399990387676735		[learning rate: 0.00037298]
		[batch 20/20] avg loss: 0.08219156138298091		[learning rate: 0.00037208]
	Learning Rate: 0.000372076
	LOSS [training: 0.08809573262987412 | validation: 0.023224875272464706]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_729.pth
	Model improved!!!
EPOCH 730/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07359462416344635		[learning rate: 0.00037118]
		[batch 20/20] avg loss: 0.06892081584108008		[learning rate: 0.00037028]
	Learning Rate: 0.000370277
	LOSS [training: 0.07125772000226319 | validation: 0.048952753175057824]
	TIME [epoch: 8.31 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.080320230087758		[learning rate: 0.00036938]
		[batch 20/20] avg loss: 0.07331339174929379		[learning rate: 0.00036849]
	Learning Rate: 0.000368486
	LOSS [training: 0.07681681091852591 | validation: 0.11128067261244466]
	TIME [epoch: 8.3 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09899158787643246		[learning rate: 0.00036759]
		[batch 20/20] avg loss: 0.06298730679964155		[learning rate: 0.0003667]
	Learning Rate: 0.000366704
	LOSS [training: 0.080989447338037 | validation: 0.034397782276084976]
	TIME [epoch: 8.3 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08147790873562838		[learning rate: 0.00036582]
		[batch 20/20] avg loss: 0.05895908131585058		[learning rate: 0.00036493]
	Learning Rate: 0.000364931
	LOSS [training: 0.07021849502573947 | validation: 0.05504838078263918]
	TIME [epoch: 8.31 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07869569310962539		[learning rate: 0.00036405]
		[batch 20/20] avg loss: 0.06016364596987721		[learning rate: 0.00036317]
	Learning Rate: 0.000363166
	LOSS [training: 0.0694296695397513 | validation: 0.10634909010423747]
	TIME [epoch: 8.31 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11053987082160018		[learning rate: 0.00036229]
		[batch 20/20] avg loss: 0.06859136862166185		[learning rate: 0.00036141]
	Learning Rate: 0.00036141
	LOSS [training: 0.08956561972163099 | validation: 0.13308480864825967]
	TIME [epoch: 8.3 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10754226195963013		[learning rate: 0.00036053]
		[batch 20/20] avg loss: 0.14457489386652805		[learning rate: 0.00035966]
	Learning Rate: 0.000359662
	LOSS [training: 0.1260585779130791 | validation: 0.06918038942023864]
	TIME [epoch: 8.3 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10052478172856942		[learning rate: 0.00035879]
		[batch 20/20] avg loss: 0.09230468856301144		[learning rate: 0.00035792]
	Learning Rate: 0.000357923
	LOSS [training: 0.09641473514579044 | validation: 0.056163215521082326]
	TIME [epoch: 8.3 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08555108433271903		[learning rate: 0.00035706]
		[batch 20/20] avg loss: 0.07901057254815372		[learning rate: 0.00035619]
	Learning Rate: 0.000356192
	LOSS [training: 0.0822808284404364 | validation: 0.07874523370298285]
	TIME [epoch: 8.32 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08532985137191676		[learning rate: 0.00035533]
		[batch 20/20] avg loss: 0.09857955926816936		[learning rate: 0.00035447]
	Learning Rate: 0.00035447
	LOSS [training: 0.09195470532004309 | validation: 0.1099618512756644]
	TIME [epoch: 8.3 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1528719556694339		[learning rate: 0.00035361]
		[batch 20/20] avg loss: 0.070004523187417		[learning rate: 0.00035276]
	Learning Rate: 0.000352755
	LOSS [training: 0.11143823942842543 | validation: 0.06180021991739591]
	TIME [epoch: 8.3 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09326768138316474		[learning rate: 0.0003519]
		[batch 20/20] avg loss: 0.0841333552741442		[learning rate: 0.00035105]
	Learning Rate: 0.00035105
	LOSS [training: 0.08870051832865446 | validation: 0.06024057959785659]
	TIME [epoch: 8.3 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08622776297246135		[learning rate: 0.0003502]
		[batch 20/20] avg loss: 0.05933073004195237		[learning rate: 0.00034935]
	Learning Rate: 0.000349352
	LOSS [training: 0.07277924650720687 | validation: 0.059411677339016464]
	TIME [epoch: 8.32 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0773258847136207		[learning rate: 0.00034851]
		[batch 20/20] avg loss: 0.05545754777797555		[learning rate: 0.00034766]
	Learning Rate: 0.000347663
	LOSS [training: 0.06639171624579812 | validation: 0.0357724614213589]
	TIME [epoch: 8.3 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07244193302153025		[learning rate: 0.00034682]
		[batch 20/20] avg loss: 0.09114101683697585		[learning rate: 0.00034598]
	Learning Rate: 0.000345981
	LOSS [training: 0.08179147492925307 | validation: 0.03645369243163417]
	TIME [epoch: 8.3 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06658661854622558		[learning rate: 0.00034514]
		[batch 20/20] avg loss: 0.06738100322424889		[learning rate: 0.00034431]
	Learning Rate: 0.000344308
	LOSS [training: 0.06698381088523725 | validation: 0.048918995615334415]
	TIME [epoch: 8.3 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07783014669191073		[learning rate: 0.00034347]
		[batch 20/20] avg loss: 0.06848053168588837		[learning rate: 0.00034264]
	Learning Rate: 0.000342643
	LOSS [training: 0.07315533918889955 | validation: 0.04211419843535509]
	TIME [epoch: 8.32 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0694228764628452		[learning rate: 0.00034181]
		[batch 20/20] avg loss: 0.08190286884995283		[learning rate: 0.00034099]
	Learning Rate: 0.000340986
	LOSS [training: 0.07566287265639901 | validation: 0.02927601682143138]
	TIME [epoch: 8.31 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.050672503651294255		[learning rate: 0.00034016]
		[batch 20/20] avg loss: 0.10540102155207978		[learning rate: 0.00033934]
	Learning Rate: 0.000339337
	LOSS [training: 0.07803676260168702 | validation: 0.05415041231346322]
	TIME [epoch: 8.3 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08277712368693166		[learning rate: 0.00033852]
		[batch 20/20] avg loss: 0.08588204115159606		[learning rate: 0.0003377]
	Learning Rate: 0.000337696
	LOSS [training: 0.08432958241926387 | validation: 0.08145843729829816]
	TIME [epoch: 8.29 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11716524639635315		[learning rate: 0.00033688]
		[batch 20/20] avg loss: 0.11126183999739789		[learning rate: 0.00033606]
	Learning Rate: 0.000336063
	LOSS [training: 0.11421354319687553 | validation: 0.12007979357658011]
	TIME [epoch: 8.3 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0960208956159205		[learning rate: 0.00033525]
		[batch 20/20] avg loss: 0.08364307583300752		[learning rate: 0.00033444]
	Learning Rate: 0.000334438
	LOSS [training: 0.08983198572446402 | validation: 0.1943004167967186]
	TIME [epoch: 8.32 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1418172503617501		[learning rate: 0.00033363]
		[batch 20/20] avg loss: 0.05813977464690369		[learning rate: 0.00033282]
	Learning Rate: 0.000332821
	LOSS [training: 0.09997851250432689 | validation: 0.03492006644801397]
	TIME [epoch: 8.3 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05821161993417334		[learning rate: 0.00033202]
		[batch 20/20] avg loss: 0.06546859388257724		[learning rate: 0.00033121]
	Learning Rate: 0.000331211
	LOSS [training: 0.06184010690837529 | validation: 0.07861654606697713]
	TIME [epoch: 8.3 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07488949986681578		[learning rate: 0.00033041]
		[batch 20/20] avg loss: 0.08753656313720659		[learning rate: 0.00032961]
	Learning Rate: 0.00032961
	LOSS [training: 0.0812130315020112 | validation: 0.06627454666416993]
	TIME [epoch: 8.3 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05732541461464576		[learning rate: 0.00032881]
		[batch 20/20] avg loss: 0.06235601664637097		[learning rate: 0.00032802]
	Learning Rate: 0.000328016
	LOSS [training: 0.05984071563050837 | validation: 0.058673322167619585]
	TIME [epoch: 8.32 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06899523983688714		[learning rate: 0.00032722]
		[batch 20/20] avg loss: 0.07671211289623935		[learning rate: 0.00032643]
	Learning Rate: 0.00032643
	LOSS [training: 0.07285367636656329 | validation: 0.04510725677295066]
	TIME [epoch: 8.3 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09522563394527482		[learning rate: 0.00032564]
		[batch 20/20] avg loss: 0.05462874816687382		[learning rate: 0.00032485]
	Learning Rate: 0.000324851
	LOSS [training: 0.0749271910560743 | validation: 0.0342291673544631]
	TIME [epoch: 8.3 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05524889785775633		[learning rate: 0.00032406]
		[batch 20/20] avg loss: 0.07731964209342751		[learning rate: 0.00032328]
	Learning Rate: 0.00032328
	LOSS [training: 0.06628426997559192 | validation: 0.034055551791746394]
	TIME [epoch: 8.3 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06384103731828451		[learning rate: 0.0003225]
		[batch 20/20] avg loss: 0.07007483608890251		[learning rate: 0.00032172]
	Learning Rate: 0.000321717
	LOSS [training: 0.06695793670359351 | validation: 0.04155456850095113]
	TIME [epoch: 8.31 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05891204116470923		[learning rate: 0.00032094]
		[batch 20/20] avg loss: 0.06270326627118628		[learning rate: 0.00032016]
	Learning Rate: 0.000320161
	LOSS [training: 0.06080765371794775 | validation: 0.024650551059869352]
	TIME [epoch: 8.31 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.050948594595047046		[learning rate: 0.00031939]
		[batch 20/20] avg loss: 0.06529703813033268		[learning rate: 0.00031861]
	Learning Rate: 0.000318613
	LOSS [training: 0.058122816362689865 | validation: 0.03911525100144687]
	TIME [epoch: 8.3 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06112376726995149		[learning rate: 0.00031784]
		[batch 20/20] avg loss: 0.08471497172922246		[learning rate: 0.00031707]
	Learning Rate: 0.000317072
	LOSS [training: 0.07291936949958698 | validation: 0.05162025598366109]
	TIME [epoch: 8.3 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06512620282100648		[learning rate: 0.0003163]
		[batch 20/20] avg loss: 0.06558618389700713		[learning rate: 0.00031554]
	Learning Rate: 0.000315539
	LOSS [training: 0.0653561933590068 | validation: 0.03197241898600535]
	TIME [epoch: 8.3 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07998298690640335		[learning rate: 0.00031477]
		[batch 20/20] avg loss: 0.07245021524863357		[learning rate: 0.00031401]
	Learning Rate: 0.000314013
	LOSS [training: 0.07621660107751846 | validation: 0.04570501342220948]
	TIME [epoch: 8.32 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06520233048289449		[learning rate: 0.00031325]
		[batch 20/20] avg loss: 0.07249111851974206		[learning rate: 0.00031249]
	Learning Rate: 0.000312494
	LOSS [training: 0.06884672450131826 | validation: 0.022603527633573494]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_765.pth
	Model improved!!!
EPOCH 766/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0513999009309287		[learning rate: 0.00031174]
		[batch 20/20] avg loss: 0.06559940238627324		[learning rate: 0.00031098]
	Learning Rate: 0.000310983
	LOSS [training: 0.05849965165860098 | validation: 0.02827159321520101]
	TIME [epoch: 8.31 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06406514958158527		[learning rate: 0.00031023]
		[batch 20/20] avg loss: 0.094657660148743		[learning rate: 0.00030948]
	Learning Rate: 0.000309479
	LOSS [training: 0.07936140486516416 | validation: 0.023573943151583444]
	TIME [epoch: 8.3 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08385962879643251		[learning rate: 0.00030873]
		[batch 20/20] avg loss: 0.054746024431964635		[learning rate: 0.00030798]
	Learning Rate: 0.000307983
	LOSS [training: 0.06930282661419856 | validation: 0.03755077137489464]
	TIME [epoch: 8.32 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07619093067982798		[learning rate: 0.00030724]
		[batch 20/20] avg loss: 0.058890031908393814		[learning rate: 0.00030649]
	Learning Rate: 0.000306493
	LOSS [training: 0.06754048129411092 | validation: 0.07959323514198655]
	TIME [epoch: 8.3 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.088241113559636		[learning rate: 0.00030575]
		[batch 20/20] avg loss: 0.09564279633880216		[learning rate: 0.00030501]
	Learning Rate: 0.000305011
	LOSS [training: 0.09194195494921908 | validation: 0.045938815939478087]
	TIME [epoch: 8.3 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04523053776482661		[learning rate: 0.00030427]
		[batch 20/20] avg loss: 0.06868512039155755		[learning rate: 0.00030354]
	Learning Rate: 0.000303536
	LOSS [training: 0.056957829078192065 | validation: 0.04208491125993408]
	TIME [epoch: 8.3 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0964644559266187		[learning rate: 0.0003028]
		[batch 20/20] avg loss: 0.05917981917146642		[learning rate: 0.00030207]
	Learning Rate: 0.000302068
	LOSS [training: 0.07782213754904255 | validation: 0.0619307616909934]
	TIME [epoch: 8.32 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06662407001294861		[learning rate: 0.00030134]
		[batch 20/20] avg loss: 0.057445901767173645		[learning rate: 0.00030061]
	Learning Rate: 0.000300608
	LOSS [training: 0.06203498589006114 | validation: 0.02909173565210301]
	TIME [epoch: 8.31 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.049093307563030875		[learning rate: 0.00029988]
		[batch 20/20] avg loss: 0.07028604364327755		[learning rate: 0.00029915]
	Learning Rate: 0.000299154
	LOSS [training: 0.059689675603154226 | validation: 0.04532749605697764]
	TIME [epoch: 8.3 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0668707263950939		[learning rate: 0.00029843]
		[batch 20/20] avg loss: 0.06017389673590734		[learning rate: 0.00029771]
	Learning Rate: 0.000297707
	LOSS [training: 0.0635223115655006 | validation: 0.06676444115849543]
	TIME [epoch: 8.3 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0824863470718021		[learning rate: 0.00029699]
		[batch 20/20] avg loss: 0.06521246975436518		[learning rate: 0.00029627]
	Learning Rate: 0.000296268
	LOSS [training: 0.07384940841308363 | validation: 0.021140379380845047]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_776.pth
	Model improved!!!
EPOCH 777/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06424989371447541		[learning rate: 0.00029555]
		[batch 20/20] avg loss: 0.0741190409913848		[learning rate: 0.00029483]
	Learning Rate: 0.000294835
	LOSS [training: 0.0691844673529301 | validation: 0.03641691886189383]
	TIME [epoch: 8.33 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07437849773130678		[learning rate: 0.00029412]
		[batch 20/20] avg loss: 0.06850942822440313		[learning rate: 0.00029341]
	Learning Rate: 0.000293409
	LOSS [training: 0.07144396297785496 | validation: 0.04451227082753706]
	TIME [epoch: 8.29 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07863907398569357		[learning rate: 0.0002927]
		[batch 20/20] avg loss: 0.06573277014440569		[learning rate: 0.00029199]
	Learning Rate: 0.00029199
	LOSS [training: 0.07218592206504965 | validation: 0.06804379091747216]
	TIME [epoch: 8.3 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06303200091776172		[learning rate: 0.00029128]
		[batch 20/20] avg loss: 0.07581408479844906		[learning rate: 0.00029058]
	Learning Rate: 0.000290578
	LOSS [training: 0.0694230428581054 | validation: 0.03451897121714034]
	TIME [epoch: 8.29 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0631269808733225		[learning rate: 0.00028987]
		[batch 20/20] avg loss: 0.05903735391136339		[learning rate: 0.00028917]
	Learning Rate: 0.000289173
	LOSS [training: 0.06108216739234294 | validation: 0.030776009850423967]
	TIME [epoch: 8.32 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07368398516197136		[learning rate: 0.00028847]
		[batch 20/20] avg loss: 0.09133509869367103		[learning rate: 0.00028777]
	Learning Rate: 0.000287775
	LOSS [training: 0.08250954192782119 | validation: 0.18097458988155546]
	TIME [epoch: 8.3 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13549388926597294		[learning rate: 0.00028708]
		[batch 20/20] avg loss: 0.07408577852399785		[learning rate: 0.00028638]
	Learning Rate: 0.000286383
	LOSS [training: 0.10478983389498538 | validation: 0.03748699104906731]
	TIME [epoch: 8.29 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0791407036645431		[learning rate: 0.00028569]
		[batch 20/20] avg loss: 0.0638340074904312		[learning rate: 0.000285]
	Learning Rate: 0.000284998
	LOSS [training: 0.07148735557748713 | validation: 0.030734324999763862]
	TIME [epoch: 8.3 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07416705001247227		[learning rate: 0.00028431]
		[batch 20/20] avg loss: 0.05887310372966169		[learning rate: 0.00028362]
	Learning Rate: 0.00028362
	LOSS [training: 0.06652007687106697 | validation: 0.04696662040456915]
	TIME [epoch: 8.3 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06480318601810313		[learning rate: 0.00028293]
		[batch 20/20] avg loss: 0.09014561284221637		[learning rate: 0.00028225]
	Learning Rate: 0.000282248
	LOSS [training: 0.07747439943015974 | validation: 0.0530770700282039]
	TIME [epoch: 8.31 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09035434860008945		[learning rate: 0.00028157]
		[batch 20/20] avg loss: 0.05978527568893873		[learning rate: 0.00028088]
	Learning Rate: 0.000280884
	LOSS [training: 0.07506981214451408 | validation: 0.037481782243075315]
	TIME [epoch: 8.29 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07308312545643396		[learning rate: 0.0002802]
		[batch 20/20] avg loss: 0.09427046659040368		[learning rate: 0.00027953]
	Learning Rate: 0.000279525
	LOSS [training: 0.08367679602341882 | validation: 0.10180678076986735]
	TIME [epoch: 8.3 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08445061979345234		[learning rate: 0.00027885]
		[batch 20/20] avg loss: 0.058814956787607495		[learning rate: 0.00027817]
	Learning Rate: 0.000278173
	LOSS [training: 0.07163278829052991 | validation: 0.07045390832344096]
	TIME [epoch: 8.29 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08052219131945368		[learning rate: 0.0002775]
		[batch 20/20] avg loss: 0.07501326269571967		[learning rate: 0.00027683]
	Learning Rate: 0.000276828
	LOSS [training: 0.07776772700758668 | validation: 0.03607231661843344]
	TIME [epoch: 8.31 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05838764193279185		[learning rate: 0.00027616]
		[batch 20/20] avg loss: 0.08314576815387197		[learning rate: 0.00027549]
	Learning Rate: 0.00027549
	LOSS [training: 0.07076670504333192 | validation: 0.04148309101260909]
	TIME [epoch: 8.29 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06432723097159518		[learning rate: 0.00027482]
		[batch 20/20] avg loss: 0.09342665159422507		[learning rate: 0.00027416]
	Learning Rate: 0.000274157
	LOSS [training: 0.07887694128291012 | validation: 0.046867002494617976]
	TIME [epoch: 8.29 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07796229258170952		[learning rate: 0.00027349]
		[batch 20/20] avg loss: 0.08135053948288291		[learning rate: 0.00027283]
	Learning Rate: 0.000272832
	LOSS [training: 0.07965641603229622 | validation: 0.08393460772949166]
	TIME [epoch: 8.29 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08546221844963073		[learning rate: 0.00027217]
		[batch 20/20] avg loss: 0.21442311515525656		[learning rate: 0.00027151]
	Learning Rate: 0.000271512
	LOSS [training: 0.14994266680244364 | validation: 0.03150317408888972]
	TIME [epoch: 8.31 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06861847414291772		[learning rate: 0.00027086]
		[batch 20/20] avg loss: 0.06810804899483489		[learning rate: 0.0002702]
	Learning Rate: 0.000270199
	LOSS [training: 0.06836326156887632 | validation: 0.03400707899023475]
	TIME [epoch: 8.31 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15455504402208975		[learning rate: 0.00026955]
		[batch 20/20] avg loss: 0.0805043683206093		[learning rate: 0.00026889]
	Learning Rate: 0.000268893
	LOSS [training: 0.11752970617134954 | validation: 0.03015285802175072]
	TIME [epoch: 8.29 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.058476497439847855		[learning rate: 0.00026824]
		[batch 20/20] avg loss: 0.07707309155297624		[learning rate: 0.00026759]
	Learning Rate: 0.000267592
	LOSS [training: 0.06777479449641205 | validation: 0.041720633704943874]
	TIME [epoch: 8.29 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06401581882796245		[learning rate: 0.00026694]
		[batch 20/20] avg loss: 0.06394831086404099		[learning rate: 0.0002663]
	Learning Rate: 0.000266298
	LOSS [training: 0.06398206484600172 | validation: 0.028125706769503673]
	TIME [epoch: 8.29 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05201577097836065		[learning rate: 0.00026565]
		[batch 20/20] avg loss: 0.09489001563854223		[learning rate: 0.00026501]
	Learning Rate: 0.000265011
	LOSS [training: 0.07345289330845144 | validation: 0.03109635838831429]
	TIME [epoch: 8.32 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05136570580664381		[learning rate: 0.00026437]
		[batch 20/20] avg loss: 0.06370482751730097		[learning rate: 0.00026373]
	Learning Rate: 0.000263729
	LOSS [training: 0.05753526666197238 | validation: 0.048621570443739236]
	TIME [epoch: 8.29 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.061570945394816876		[learning rate: 0.00026309]
		[batch 20/20] avg loss: 0.08059666987615892		[learning rate: 0.00026245]
	Learning Rate: 0.000262454
	LOSS [training: 0.07108380763548791 | validation: 0.031722870231807324]
	TIME [epoch: 8.29 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06230156982151058		[learning rate: 0.00026182]
		[batch 20/20] avg loss: 0.06000294250785758		[learning rate: 0.00026118]
	Learning Rate: 0.000261184
	LOSS [training: 0.061152256164684074 | validation: 0.07547340148581054]
	TIME [epoch: 8.29 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08106850984792151		[learning rate: 0.00026055]
		[batch 20/20] avg loss: 0.05944956679028947		[learning rate: 0.00025992]
	Learning Rate: 0.000259921
	LOSS [training: 0.07025903831910549 | validation: 0.09066683516015625]
	TIME [epoch: 8.32 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09674696002546607		[learning rate: 0.00025929]
		[batch 20/20] avg loss: 0.08797548939662689		[learning rate: 0.00025866]
	Learning Rate: 0.000258665
	LOSS [training: 0.09236122471104649 | validation: 0.036895330623888355]
	TIME [epoch: 8.29 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07029281785947825		[learning rate: 0.00025804]
		[batch 20/20] avg loss: 0.07848406269648385		[learning rate: 0.00025741]
	Learning Rate: 0.000257414
	LOSS [training: 0.07438844027798105 | validation: 0.02899093467031542]
	TIME [epoch: 8.29 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05873981563436189		[learning rate: 0.00025679]
		[batch 20/20] avg loss: 0.09837608086167317		[learning rate: 0.00025617]
	Learning Rate: 0.000256169
	LOSS [training: 0.07855794824801751 | validation: 0.025322667314795592]
	TIME [epoch: 8.3 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06122498859575587		[learning rate: 0.00025555]
		[batch 20/20] avg loss: 0.059570577890621965		[learning rate: 0.00025493]
	Learning Rate: 0.00025493
	LOSS [training: 0.06039778324318892 | validation: 0.030542110101575492]
	TIME [epoch: 8.3 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05357763935454133		[learning rate: 0.00025431]
		[batch 20/20] avg loss: 0.07262751355661973		[learning rate: 0.0002537]
	Learning Rate: 0.000253697
	LOSS [training: 0.06310257645558053 | validation: 0.06296043961750242]
	TIME [epoch: 8.31 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10344363907124605		[learning rate: 0.00025308]
		[batch 20/20] avg loss: 0.06801242737799848		[learning rate: 0.00025247]
	Learning Rate: 0.00025247
	LOSS [training: 0.08572803322462226 | validation: 0.036683426735740376]
	TIME [epoch: 8.29 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06241975218807864		[learning rate: 0.00025186]
		[batch 20/20] avg loss: 0.05919726184648044		[learning rate: 0.00025125]
	Learning Rate: 0.00025125
	LOSS [training: 0.060808507017279544 | validation: 0.03395873698491691]
	TIME [epoch: 8.29 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07884881751575315		[learning rate: 0.00025064]
		[batch 20/20] avg loss: 0.05311322877583652		[learning rate: 0.00025003]
	Learning Rate: 0.000250035
	LOSS [training: 0.06598102314579483 | validation: 0.05332006021357845]
	TIME [epoch: 8.3 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06702249426790077		[learning rate: 0.00024943]
		[batch 20/20] avg loss: 0.05502985148811381		[learning rate: 0.00024883]
	Learning Rate: 0.000248825
	LOSS [training: 0.06102617287800729 | validation: 0.0580866753865083]
	TIME [epoch: 8.32 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.064414144032561		[learning rate: 0.00024822]
		[batch 20/20] avg loss: 0.05406779625083162		[learning rate: 0.00024762]
	Learning Rate: 0.000247622
	LOSS [training: 0.05924097014169631 | validation: 0.04169919213478849]
	TIME [epoch: 8.3 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0604373597707009		[learning rate: 0.00024702]
		[batch 20/20] avg loss: 0.05517641178294341		[learning rate: 0.00024642]
	Learning Rate: 0.000246425
	LOSS [training: 0.05780688577682216 | validation: 0.029471827255628302]
	TIME [epoch: 8.29 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05460312670760155		[learning rate: 0.00024583]
		[batch 20/20] avg loss: 0.0602406476305396		[learning rate: 0.00024523]
	Learning Rate: 0.000245233
	LOSS [training: 0.057421887169070575 | validation: 0.027665186706305703]
	TIME [epoch: 8.29 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.051687881198220306		[learning rate: 0.00024464]
		[batch 20/20] avg loss: 0.06597433537971333		[learning rate: 0.00024405]
	Learning Rate: 0.000244047
	LOSS [training: 0.058831108288966816 | validation: 0.02975497167656037]
	TIME [epoch: 8.31 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.060351448791369035		[learning rate: 0.00024346]
		[batch 20/20] avg loss: 0.053255236314140385		[learning rate: 0.00024287]
	Learning Rate: 0.000242867
	LOSS [training: 0.05680334255275471 | validation: 0.03339155220972589]
	TIME [epoch: 8.3 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05152036253393324		[learning rate: 0.00024228]
		[batch 20/20] avg loss: 0.05477138979117169		[learning rate: 0.00024169]
	Learning Rate: 0.000241693
	LOSS [training: 0.05314587616255247 | validation: 0.05911570990222466]
	TIME [epoch: 8.31 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05871891463449347		[learning rate: 0.00024111]
		[batch 20/20] avg loss: 0.06368590774198227		[learning rate: 0.00024052]
	Learning Rate: 0.000240524
	LOSS [training: 0.06120241118823785 | validation: 0.02925831722702716]
	TIME [epoch: 8.29 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05906711977176475		[learning rate: 0.00023994]
		[batch 20/20] avg loss: 0.05511314516232717		[learning rate: 0.00023936]
	Learning Rate: 0.000239361
	LOSS [training: 0.05709013246704596 | validation: 0.028005538827190257]
	TIME [epoch: 8.31 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.044399521604408895		[learning rate: 0.00023878]
		[batch 20/20] avg loss: 0.0605603035498284		[learning rate: 0.0002382]
	Learning Rate: 0.000238203
	LOSS [training: 0.05247991257711866 | validation: 0.04233109245745861]
	TIME [epoch: 8.3 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06406136146720029		[learning rate: 0.00023763]
		[batch 20/20] avg loss: 0.052766759400355		[learning rate: 0.00023705]
	Learning Rate: 0.000237051
	LOSS [training: 0.05841406043377765 | validation: 0.052360296698715975]
	TIME [epoch: 8.29 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06236503313630859		[learning rate: 0.00023648]
		[batch 20/20] avg loss: 0.06513695898417524		[learning rate: 0.0002359]
	Learning Rate: 0.000235905
	LOSS [training: 0.0637509960602419 | validation: 0.028102179188609654]
	TIME [epoch: 8.29 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05153850576741521		[learning rate: 0.00023533]
		[batch 20/20] avg loss: 0.050630752154445756		[learning rate: 0.00023476]
	Learning Rate: 0.000234764
	LOSS [training: 0.05108462896093049 | validation: 0.06713824114967289]
	TIME [epoch: 8.29 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08587581230016669		[learning rate: 0.0002342]
		[batch 20/20] avg loss: 0.06681355531100971		[learning rate: 0.00023363]
	Learning Rate: 0.000233629
	LOSS [training: 0.0763446838055882 | validation: 0.036713835028347595]
	TIME [epoch: 8.32 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05978808941991901		[learning rate: 0.00023306]
		[batch 20/20] avg loss: 0.05827758204021255		[learning rate: 0.0002325]
	Learning Rate: 0.000232499
	LOSS [training: 0.05903283573006577 | validation: 0.04922863698001438]
	TIME [epoch: 8.29 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.050627712800358646		[learning rate: 0.00023194]
		[batch 20/20] avg loss: 0.061360599922559864		[learning rate: 0.00023137]
	Learning Rate: 0.000231375
	LOSS [training: 0.05599415636145925 | validation: 0.029557950122194296]
	TIME [epoch: 8.29 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06357312970525653		[learning rate: 0.00023081]
		[batch 20/20] avg loss: 0.04949693227538802		[learning rate: 0.00023026]
	Learning Rate: 0.000230256
	LOSS [training: 0.05653503099032227 | validation: 0.03127225803255583]
	TIME [epoch: 8.29 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05645746102166647		[learning rate: 0.0002297]
		[batch 20/20] avg loss: 0.06524547146963677		[learning rate: 0.00022914]
	Learning Rate: 0.000229142
	LOSS [training: 0.06085146624565162 | validation: 0.034447091697999345]
	TIME [epoch: 8.31 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05340010390334463		[learning rate: 0.00022859]
		[batch 20/20] avg loss: 0.05411998622136212		[learning rate: 0.00022803]
	Learning Rate: 0.000228034
	LOSS [training: 0.05376004506235338 | validation: 0.029872930605355563]
	TIME [epoch: 8.29 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04628105750463603		[learning rate: 0.00022748]
		[batch 20/20] avg loss: 0.05392555489584827		[learning rate: 0.00022693]
	Learning Rate: 0.000226931
	LOSS [training: 0.050103306200242156 | validation: 0.024856154672814088]
	TIME [epoch: 8.3 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04736242671632145		[learning rate: 0.00022638]
		[batch 20/20] avg loss: 0.06031899628026027		[learning rate: 0.00022583]
	Learning Rate: 0.000225834
	LOSS [training: 0.05384071149829087 | validation: 0.034614930565872726]
	TIME [epoch: 8.29 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.047022984057000394		[learning rate: 0.00022529]
		[batch 20/20] avg loss: 0.04821110771113914		[learning rate: 0.00022474]
	Learning Rate: 0.000224742
	LOSS [training: 0.047617045884069766 | validation: 0.03215641761998751]
	TIME [epoch: 8.31 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04906804018803447		[learning rate: 0.0002242]
		[batch 20/20] avg loss: 0.05172067081458396		[learning rate: 0.00022366]
	Learning Rate: 0.000223655
	LOSS [training: 0.05039435550130922 | validation: 0.026391261302269542]
	TIME [epoch: 8.31 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05961142079557226		[learning rate: 0.00022311]
		[batch 20/20] avg loss: 0.04246798224925599		[learning rate: 0.00022257]
	Learning Rate: 0.000222574
	LOSS [training: 0.051039701522414126 | validation: 0.03786063657175534]
	TIME [epoch: 8.29 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.052646831175065134		[learning rate: 0.00022203]
		[batch 20/20] avg loss: 0.06438244068290672		[learning rate: 0.0002215]
	Learning Rate: 0.000221497
	LOSS [training: 0.058514635928985925 | validation: 0.033360532018154115]
	TIME [epoch: 8.29 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06322421892270946		[learning rate: 0.00022096]
		[batch 20/20] avg loss: 0.04949514940069956		[learning rate: 0.00022043]
	Learning Rate: 0.000220426
	LOSS [training: 0.05635968416170452 | validation: 0.02829326801686502]
	TIME [epoch: 8.29 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.060353567109155716		[learning rate: 0.00021989]
		[batch 20/20] avg loss: 0.05575944295233446		[learning rate: 0.00021936]
	Learning Rate: 0.00021936
	LOSS [training: 0.05805650503074509 | validation: 0.023776635186306457]
	TIME [epoch: 8.32 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04798336436205395		[learning rate: 0.00021883]
		[batch 20/20] avg loss: 0.07431252535506475		[learning rate: 0.0002183]
	Learning Rate: 0.000218299
	LOSS [training: 0.061147944858559324 | validation: 0.05637362865088382]
	TIME [epoch: 8.29 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07145303668100236		[learning rate: 0.00021777]
		[batch 20/20] avg loss: 0.05227480275409043		[learning rate: 0.00021724]
	Learning Rate: 0.000217244
	LOSS [training: 0.0618639197175464 | validation: 0.03696481664948259]
	TIME [epoch: 8.3 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06800564515007265		[learning rate: 0.00021672]
		[batch 20/20] avg loss: 0.04364806270675645		[learning rate: 0.00021619]
	Learning Rate: 0.000216193
	LOSS [training: 0.055826853928414556 | validation: 0.02308747118993546]
	TIME [epoch: 8.29 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.054952480388930046		[learning rate: 0.00021567]
		[batch 20/20] avg loss: 0.0471431164027294		[learning rate: 0.00021515]
	Learning Rate: 0.000215148
	LOSS [training: 0.05104779839582972 | validation: 0.04835395790330581]
	TIME [epoch: 8.31 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05560961560846615		[learning rate: 0.00021463]
		[batch 20/20] avg loss: 0.07031377060278146		[learning rate: 0.00021411]
	Learning Rate: 0.000214107
	LOSS [training: 0.06296169310562381 | validation: 0.023180718336142905]
	TIME [epoch: 8.3 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.053446442374859925		[learning rate: 0.00021359]
		[batch 20/20] avg loss: 0.05132048736855802		[learning rate: 0.00021307]
	Learning Rate: 0.000213072
	LOSS [training: 0.05238346487170899 | validation: 0.03709633001724081]
	TIME [epoch: 8.3 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06495910057939831		[learning rate: 0.00021256]
		[batch 20/20] avg loss: 0.06574724128708417		[learning rate: 0.00021204]
	Learning Rate: 0.000212042
	LOSS [training: 0.06535317093324124 | validation: 0.028918925151181045]
	TIME [epoch: 8.29 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.054668167398124565		[learning rate: 0.00021153]
		[batch 20/20] avg loss: 0.07608316466865153		[learning rate: 0.00021102]
	Learning Rate: 0.000211016
	LOSS [training: 0.06537566603338804 | validation: 0.04560766007267775]
	TIME [epoch: 8.29 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.059713094433247495		[learning rate: 0.00021051]
		[batch 20/20] avg loss: 0.06369449409612502		[learning rate: 0.00021]
	Learning Rate: 0.000209996
	LOSS [training: 0.061703794264686265 | validation: 0.04812618653250184]
	TIME [epoch: 8.32 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06363441049766132		[learning rate: 0.00020949]
		[batch 20/20] avg loss: 0.04603242307730473		[learning rate: 0.00020898]
	Learning Rate: 0.00020898
	LOSS [training: 0.05483341678748303 | validation: 0.026087964466741696]
	TIME [epoch: 8.29 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04865847540964922		[learning rate: 0.00020847]
		[batch 20/20] avg loss: 0.07181320238290319		[learning rate: 0.00020797]
	Learning Rate: 0.00020797
	LOSS [training: 0.06023583889627619 | validation: 0.045700906915642305]
	TIME [epoch: 8.29 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05192662692807322		[learning rate: 0.00020747]
		[batch 20/20] avg loss: 0.049477126270374684		[learning rate: 0.00020696]
	Learning Rate: 0.000206964
	LOSS [training: 0.05070187659922395 | validation: 0.02836341520351631]
	TIME [epoch: 8.29 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06515986012104666		[learning rate: 0.00020646]
		[batch 20/20] avg loss: 0.05259534343909621		[learning rate: 0.00020596]
	Learning Rate: 0.000205963
	LOSS [training: 0.05887760178007144 | validation: 0.035455910979521395]
	TIME [epoch: 8.32 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05943231401422942		[learning rate: 0.00020546]
		[batch 20/20] avg loss: 0.05611120907818602		[learning rate: 0.00020497]
	Learning Rate: 0.000204967
	LOSS [training: 0.05777176154620774 | validation: 0.10426275699370934]
	TIME [epoch: 8.29 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06211170930466845		[learning rate: 0.00020447]
		[batch 20/20] avg loss: 0.05663568937023472		[learning rate: 0.00020398]
	Learning Rate: 0.000203976
	LOSS [training: 0.05937369933745158 | validation: 0.03413316479417209]
	TIME [epoch: 8.3 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04787238494145068		[learning rate: 0.00020348]
		[batch 20/20] avg loss: 0.05306708834523188		[learning rate: 0.00020299]
	Learning Rate: 0.00020299
	LOSS [training: 0.05046973664334128 | validation: 0.04797683738613011]
	TIME [epoch: 8.29 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05834247366996613		[learning rate: 0.0002025]
		[batch 20/20] avg loss: 0.052636660944437676		[learning rate: 0.00020201]
	Learning Rate: 0.000202008
	LOSS [training: 0.055489567307201906 | validation: 0.03254908205364485]
	TIME [epoch: 8.31 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.052499402810358795		[learning rate: 0.00020152]
		[batch 20/20] avg loss: 0.07195323440887337		[learning rate: 0.00020103]
	Learning Rate: 0.000201031
	LOSS [training: 0.06222631860961608 | validation: 0.0471167065492393]
	TIME [epoch: 8.3 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05288835998308441		[learning rate: 0.00020054]
		[batch 20/20] avg loss: 0.05537531060885657		[learning rate: 0.00020006]
	Learning Rate: 0.000200059
	LOSS [training: 0.05413183529597049 | validation: 0.02977806597371272]
	TIME [epoch: 8.29 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.050060238049515114		[learning rate: 0.00019957]
		[batch 20/20] avg loss: 0.054122048574410705		[learning rate: 0.00019909]
	Learning Rate: 0.000199091
	LOSS [training: 0.052091143311962906 | validation: 0.02215099943922462]
	TIME [epoch: 8.29 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04781411764013414		[learning rate: 0.00019861]
		[batch 20/20] avg loss: 0.047028764712801735		[learning rate: 0.00019813]
	Learning Rate: 0.000198129
	LOSS [training: 0.04742144117646794 | validation: 0.0276064000116093]
	TIME [epoch: 8.29 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05818751670768334		[learning rate: 0.00019765]
		[batch 20/20] avg loss: 0.05943045439163706		[learning rate: 0.00019717]
	Learning Rate: 0.000197171
	LOSS [training: 0.0588089855496602 | validation: 0.020446471879501674]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_860.pth
	Model improved!!!
EPOCH 861/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05616895729767024		[learning rate: 0.00019669]
		[batch 20/20] avg loss: 0.04765979921453303		[learning rate: 0.00019622]
	Learning Rate: 0.000196217
	LOSS [training: 0.051914378256101644 | validation: 0.030849552226111417]
	TIME [epoch: 8.29 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.059266164059773675		[learning rate: 0.00019574]
		[batch 20/20] avg loss: 0.05706022261187875		[learning rate: 0.00019527]
	Learning Rate: 0.000195268
	LOSS [training: 0.05816319333582622 | validation: 0.04564375132808805]
	TIME [epoch: 8.29 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06192182071579176		[learning rate: 0.0001948]
		[batch 20/20] avg loss: 0.04576751518483373		[learning rate: 0.00019432]
	Learning Rate: 0.000194324
	LOSS [training: 0.053844667950312744 | validation: 0.027429971248351233]
	TIME [epoch: 8.29 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06180025008750911		[learning rate: 0.00019385]
		[batch 20/20] avg loss: 0.048509551017068976		[learning rate: 0.00019338]
	Learning Rate: 0.000193384
	LOSS [training: 0.05515490055228904 | validation: 0.025375871142930117]
	TIME [epoch: 8.31 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05377989159584162		[learning rate: 0.00019292]
		[batch 20/20] avg loss: 0.0651997662433891		[learning rate: 0.00019245]
	Learning Rate: 0.000192449
	LOSS [training: 0.05948982891961537 | validation: 0.051563494065437525]
	TIME [epoch: 8.29 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.061269737871511666		[learning rate: 0.00019198]
		[batch 20/20] avg loss: 0.0523160550897915		[learning rate: 0.00019152]
	Learning Rate: 0.000191518
	LOSS [training: 0.056792896480651577 | validation: 0.034237670992387816]
	TIME [epoch: 8.28 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05191959706699757		[learning rate: 0.00019105]
		[batch 20/20] avg loss: 0.043061261742580764		[learning rate: 0.00019059]
	Learning Rate: 0.000190592
	LOSS [training: 0.04749042940478916 | validation: 0.02383567224428746]
	TIME [epoch: 8.29 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.053251814114808296		[learning rate: 0.00019013]
		[batch 20/20] avg loss: 0.052769134007755604		[learning rate: 0.00018967]
	Learning Rate: 0.000189671
	LOSS [training: 0.053010474061281954 | validation: 0.027511496505684366]
	TIME [epoch: 8.3 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05409079893434241		[learning rate: 0.00018921]
		[batch 20/20] avg loss: 0.05809303843532143		[learning rate: 0.00018875]
	Learning Rate: 0.000188753
	LOSS [training: 0.05609191868483192 | validation: 0.042531705144083595]
	TIME [epoch: 8.3 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05194008477667321		[learning rate: 0.0001883]
		[batch 20/20] avg loss: 0.06627760103551449		[learning rate: 0.00018784]
	Learning Rate: 0.000187841
	LOSS [training: 0.05910884290609385 | validation: 0.02629324248664221]
	TIME [epoch: 8.28 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05717396853561334		[learning rate: 0.00018739]
		[batch 20/20] avg loss: 0.057718599403772955		[learning rate: 0.00018693]
	Learning Rate: 0.000186932
	LOSS [training: 0.057446283969693146 | validation: 0.03275755066976791]
	TIME [epoch: 8.29 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.043033278159118844		[learning rate: 0.00018648]
		[batch 20/20] avg loss: 0.058180190046497514		[learning rate: 0.00018603]
	Learning Rate: 0.000186028
	LOSS [training: 0.05060673410280818 | validation: 0.033173353276684234]
	TIME [epoch: 8.29 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05179860693746312		[learning rate: 0.00018558]
		[batch 20/20] avg loss: 0.047343922972007145		[learning rate: 0.00018513]
	Learning Rate: 0.000185129
	LOSS [training: 0.04957126495473513 | validation: 0.05132759041476306]
	TIME [epoch: 8.31 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0606280000799278		[learning rate: 0.00018468]
		[batch 20/20] avg loss: 0.05950270967665786		[learning rate: 0.00018423]
	Learning Rate: 0.000184233
	LOSS [training: 0.06006535487829282 | validation: 0.027303841473067556]
	TIME [epoch: 8.29 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04870810051288284		[learning rate: 0.00018379]
		[batch 20/20] avg loss: 0.04871413305541634		[learning rate: 0.00018334]
	Learning Rate: 0.000183343
	LOSS [training: 0.04871111678414959 | validation: 0.029373367709114334]
	TIME [epoch: 8.28 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.048098127062435214		[learning rate: 0.0001829]
		[batch 20/20] avg loss: 0.05163284007993173		[learning rate: 0.00018246]
	Learning Rate: 0.000182456
	LOSS [training: 0.049865483571183464 | validation: 0.03872653777533469]
	TIME [epoch: 8.29 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.058541675955331066		[learning rate: 0.00018201]
		[batch 20/20] avg loss: 0.044819223413541984		[learning rate: 0.00018157]
	Learning Rate: 0.000181574
	LOSS [training: 0.05168044968443654 | validation: 0.03532686879642491]
	TIME [epoch: 8.31 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05792189907977972		[learning rate: 0.00018113]
		[batch 20/20] avg loss: 0.03953685378532214		[learning rate: 0.0001807]
	Learning Rate: 0.000180696
	LOSS [training: 0.04872937643255094 | validation: 0.02815547204103276]
	TIME [epoch: 8.29 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05004707465415418		[learning rate: 0.00018026]
		[batch 20/20] avg loss: 0.06807382510477913		[learning rate: 0.00017982]
	Learning Rate: 0.000179822
	LOSS [training: 0.05906044987946664 | validation: 0.047014619246559204]
	TIME [epoch: 8.28 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.060710485497449805		[learning rate: 0.00017939]
		[batch 20/20] avg loss: 0.06627600404516572		[learning rate: 0.00017895]
	Learning Rate: 0.000178952
	LOSS [training: 0.06349324477130777 | validation: 0.022556413770809913]
	TIME [epoch: 8.29 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04499341587326723		[learning rate: 0.00017852]
		[batch 20/20] avg loss: 0.051297298837596615		[learning rate: 0.00017809]
	Learning Rate: 0.000178087
	LOSS [training: 0.04814535735543193 | validation: 0.025197127205984084]
	TIME [epoch: 8.3 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05465718247861352		[learning rate: 0.00017766]
		[batch 20/20] avg loss: 0.05624011334765253		[learning rate: 0.00017723]
	Learning Rate: 0.000177226
	LOSS [training: 0.05544864791313302 | validation: 0.030825335669663632]
	TIME [epoch: 8.3 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.055657343050848906		[learning rate: 0.0001768]
		[batch 20/20] avg loss: 0.06121000390936184		[learning rate: 0.00017637]
	Learning Rate: 0.000176369
	LOSS [training: 0.058433673480105384 | validation: 0.026839041908157432]
	TIME [epoch: 8.29 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.048758225897468546		[learning rate: 0.00017594]
		[batch 20/20] avg loss: 0.06390876521942015		[learning rate: 0.00017552]
	Learning Rate: 0.000175516
	LOSS [training: 0.05633349555844436 | validation: 0.03552700668659596]
	TIME [epoch: 8.29 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04579009377720196		[learning rate: 0.00017509]
		[batch 20/20] avg loss: 0.05695725762297984		[learning rate: 0.00017467]
	Learning Rate: 0.000174667
	LOSS [training: 0.0513736757000909 | validation: 0.03912863942198863]
	TIME [epoch: 8.29 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05229907433637693		[learning rate: 0.00017424]
		[batch 20/20] avg loss: 0.05434331106357465		[learning rate: 0.00017382]
	Learning Rate: 0.000173822
	LOSS [training: 0.05332119269997578 | validation: 0.020697022607845016]
	TIME [epoch: 8.31 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04583522417331319		[learning rate: 0.0001734]
		[batch 20/20] avg loss: 0.05201320592139721		[learning rate: 0.00017298]
	Learning Rate: 0.000172982
	LOSS [training: 0.048924215047355196 | validation: 0.05407961947017603]
	TIME [epoch: 8.29 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04994799562088379		[learning rate: 0.00017256]
		[batch 20/20] avg loss: 0.05522458220406756		[learning rate: 0.00017215]
	Learning Rate: 0.000172145
	LOSS [training: 0.052586288912475666 | validation: 0.022347739553678275]
	TIME [epoch: 8.28 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05127741863153741		[learning rate: 0.00017173]
		[batch 20/20] avg loss: 0.05165205569034994		[learning rate: 0.00017131]
	Learning Rate: 0.000171313
	LOSS [training: 0.05146473716094367 | validation: 0.06557772784411653]
	TIME [epoch: 8.29 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.056057612183938496		[learning rate: 0.0001709]
		[batch 20/20] avg loss: 0.057583812978695456		[learning rate: 0.00017048]
	Learning Rate: 0.000170484
	LOSS [training: 0.056820712581316976 | validation: 0.0375591918447048]
	TIME [epoch: 8.31 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.045320209536937765		[learning rate: 0.00017007]
		[batch 20/20] avg loss: 0.06619651504758814		[learning rate: 0.00016966]
	Learning Rate: 0.00016966
	LOSS [training: 0.055758362292262956 | validation: 0.05336143473981428]
	TIME [epoch: 8.29 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.061550684103577204		[learning rate: 0.00016925]
		[batch 20/20] avg loss: 0.05381528126602906		[learning rate: 0.00016884]
	Learning Rate: 0.000168839
	LOSS [training: 0.05768298268480312 | validation: 0.0243441559250789]
	TIME [epoch: 8.29 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.049182929309752745		[learning rate: 0.00016843]
		[batch 20/20] avg loss: 0.048212153889893784		[learning rate: 0.00016802]
	Learning Rate: 0.000168023
	LOSS [training: 0.04869754159982326 | validation: 0.025995191920812184]
	TIME [epoch: 8.29 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.042512218850964505		[learning rate: 0.00016762]
		[batch 20/20] avg loss: 0.05998365762054765		[learning rate: 0.00016721]
	Learning Rate: 0.00016721
	LOSS [training: 0.05124793823575606 | validation: 0.023561859239146568]
	TIME [epoch: 8.3 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04276617773564428		[learning rate: 0.00016681]
		[batch 20/20] avg loss: 0.058394252112924185		[learning rate: 0.0001664]
	Learning Rate: 0.000166402
	LOSS [training: 0.05058021492428423 | validation: 0.023018250349081823]
	TIME [epoch: 8.31 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04529283988231329		[learning rate: 0.000166]
		[batch 20/20] avg loss: 0.05955020447718316		[learning rate: 0.0001656]
	Learning Rate: 0.000165597
	LOSS [training: 0.052421522179748235 | validation: 0.02758696103217079]
	TIME [epoch: 8.29 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04690104725167044		[learning rate: 0.0001652]
		[batch 20/20] avg loss: 0.048205522291904376		[learning rate: 0.0001648]
	Learning Rate: 0.000164796
	LOSS [training: 0.0475532847717874 | validation: 0.027087707356906188]
	TIME [epoch: 8.29 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05524381374765967		[learning rate: 0.0001644]
		[batch 20/20] avg loss: 0.03651865184996675		[learning rate: 0.000164]
	Learning Rate: 0.000163999
	LOSS [training: 0.04588123279881321 | validation: 0.047815852744825325]
	TIME [epoch: 8.29 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.052410588525758826		[learning rate: 0.0001636]
		[batch 20/20] avg loss: 0.055933414691411255		[learning rate: 0.00016321]
	Learning Rate: 0.000163206
	LOSS [training: 0.05417200160858503 | validation: 0.02209943293506359]
	TIME [epoch: 8.31 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.047814101929558886		[learning rate: 0.00016281]
		[batch 20/20] avg loss: 0.049030595576000244		[learning rate: 0.00016242]
	Learning Rate: 0.000162417
	LOSS [training: 0.04842234875277955 | validation: 0.02696017020987366]
	TIME [epoch: 8.29 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04360873709309157		[learning rate: 0.00016202]
		[batch 20/20] avg loss: 0.0654201872120382		[learning rate: 0.00016163]
	Learning Rate: 0.000161632
	LOSS [training: 0.05451446215256488 | validation: 0.030194887818709812]
	TIME [epoch: 8.29 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06511743208158807		[learning rate: 0.00016124]
		[batch 20/20] avg loss: 0.05126675419008325		[learning rate: 0.00016085]
	Learning Rate: 0.00016085
	LOSS [training: 0.058192093135835656 | validation: 0.029024454470171157]
	TIME [epoch: 8.29 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.047861366003476576		[learning rate: 0.00016046]
		[batch 20/20] avg loss: 0.05368379038118666		[learning rate: 0.00016007]
	Learning Rate: 0.000160072
	LOSS [training: 0.05077257819233162 | validation: 0.0312636845221019]
	TIME [epoch: 8.31 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.052888468971478475		[learning rate: 0.00015968]
		[batch 20/20] avg loss: 0.05376095207429402		[learning rate: 0.0001593]
	Learning Rate: 0.000159298
	LOSS [training: 0.05332471052288625 | validation: 0.03503074925589223]
	TIME [epoch: 8.29 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.045896716623692504		[learning rate: 0.00015891]
		[batch 20/20] avg loss: 0.06097584080234688		[learning rate: 0.00015853]
	Learning Rate: 0.000158528
	LOSS [training: 0.05343627871301969 | validation: 0.02837989495411861]
	TIME [epoch: 8.29 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05916303709451396		[learning rate: 0.00015814]
		[batch 20/20] avg loss: 0.05886752593532848		[learning rate: 0.00015776]
	Learning Rate: 0.000157761
	LOSS [training: 0.05901528151492121 | validation: 0.048606860610241255]
	TIME [epoch: 8.28 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05640137731750261		[learning rate: 0.00015738]
		[batch 20/20] avg loss: 0.05817958137659884		[learning rate: 0.000157]
	Learning Rate: 0.000156998
	LOSS [training: 0.05729047934705073 | validation: 0.039339025075802295]
	TIME [epoch: 8.29 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0466948763288994		[learning rate: 0.00015662]
		[batch 20/20] avg loss: 0.06797857308343676		[learning rate: 0.00015624]
	Learning Rate: 0.000156239
	LOSS [training: 0.057336724706168074 | validation: 0.03128888202710977]
	TIME [epoch: 8.31 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05024398213771377		[learning rate: 0.00015586]
		[batch 20/20] avg loss: 0.046351848478438755		[learning rate: 0.00015548]
	Learning Rate: 0.000155483
	LOSS [training: 0.04829791530807627 | validation: 0.022325155529412853]
	TIME [epoch: 8.29 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05288171175886186		[learning rate: 0.00015511]
		[batch 20/20] avg loss: 0.05933940998185104		[learning rate: 0.00015473]
	Learning Rate: 0.000154732
	LOSS [training: 0.056110560870356464 | validation: 0.03407198970326102]
	TIME [epoch: 8.29 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06478428878617229		[learning rate: 0.00015436]
		[batch 20/20] avg loss: 0.05752635600742203		[learning rate: 0.00015398]
	Learning Rate: 0.000153983
	LOSS [training: 0.06115532239679715 | validation: 0.025586110972531044]
	TIME [epoch: 8.29 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.059257119700531415		[learning rate: 0.00015361]
		[batch 20/20] avg loss: 0.046900261257320656		[learning rate: 0.00015324]
	Learning Rate: 0.000153239
	LOSS [training: 0.053078690478926036 | validation: 0.03455285551557662]
	TIME [epoch: 8.32 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.051763544214158255		[learning rate: 0.00015287]
		[batch 20/20] avg loss: 0.04165932344492952		[learning rate: 0.0001525]
	Learning Rate: 0.000152498
	LOSS [training: 0.04671143382954389 | validation: 0.02509074212350713]
	TIME [epoch: 8.29 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05088397396788612		[learning rate: 0.00015213]
		[batch 20/20] avg loss: 0.05676820111479619		[learning rate: 0.00015176]
	Learning Rate: 0.00015176
	LOSS [training: 0.05382608754134115 | validation: 0.028221656930412932]
	TIME [epoch: 8.29 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.052054309910345375		[learning rate: 0.00015139]
		[batch 20/20] avg loss: 0.05477174961395588		[learning rate: 0.00015103]
	Learning Rate: 0.000151026
	LOSS [training: 0.05341302976215062 | validation: 0.032464377819768644]
	TIME [epoch: 8.29 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0381437485391176		[learning rate: 0.00015066]
		[batch 20/20] avg loss: 0.061569290100926335		[learning rate: 0.0001503]
	Learning Rate: 0.000150296
	LOSS [training: 0.04985651932002196 | validation: 0.033583046815466325]
	TIME [epoch: 8.31 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.054765980340418366		[learning rate: 0.00014993]
		[batch 20/20] avg loss: 0.05341439807450944		[learning rate: 0.00014957]
	Learning Rate: 0.000149569
	LOSS [training: 0.054090189207463904 | validation: 0.02796578237224112]
	TIME [epoch: 8.3 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05063897101515193		[learning rate: 0.00014921]
		[batch 20/20] avg loss: 0.05557164997340073		[learning rate: 0.00014885]
	Learning Rate: 0.000148846
	LOSS [training: 0.05310531049427634 | validation: 0.03442216204467512]
	TIME [epoch: 8.29 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05447208253467074		[learning rate: 0.00014849]
		[batch 20/20] avg loss: 0.037642104656568254		[learning rate: 0.00014813]
	Learning Rate: 0.000148126
	LOSS [training: 0.0460570935956195 | validation: 0.027120913422201215]
	TIME [epoch: 8.29 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.057020517288634144		[learning rate: 0.00014777]
		[batch 20/20] avg loss: 0.05186730125704327		[learning rate: 0.00014741]
	Learning Rate: 0.00014741
	LOSS [training: 0.054443909272838695 | validation: 0.022519626814908506]
	TIME [epoch: 8.28 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04621842375606965		[learning rate: 0.00014705]
		[batch 20/20] avg loss: 0.05036719470903567		[learning rate: 0.0001467]
	Learning Rate: 0.000146697
	LOSS [training: 0.048292809232552664 | validation: 0.0315876834261169]
	TIME [epoch: 8.31 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.043474023582948385		[learning rate: 0.00014634]
		[batch 20/20] avg loss: 0.05582051075840468		[learning rate: 0.00014599]
	Learning Rate: 0.000145988
	LOSS [training: 0.04964726717067654 | validation: 0.02087127545566305]
	TIME [epoch: 8.28 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05892513764258152		[learning rate: 0.00014563]
		[batch 20/20] avg loss: 0.044292329801741095		[learning rate: 0.00014528]
	Learning Rate: 0.000145282
	LOSS [training: 0.051608733722161314 | validation: 0.04409772835083185]
	TIME [epoch: 8.29 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04286388112423557		[learning rate: 0.00014493]
		[batch 20/20] avg loss: 0.053964843500582504		[learning rate: 0.00014458]
	Learning Rate: 0.000144579
	LOSS [training: 0.04841436231240904 | validation: 0.06024304844031887]
	TIME [epoch: 8.28 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.044330407744342035		[learning rate: 0.00014423]
		[batch 20/20] avg loss: 0.05661932646235177		[learning rate: 0.00014388]
	Learning Rate: 0.00014388
	LOSS [training: 0.05047486710334691 | validation: 0.030015151192990162]
	TIME [epoch: 8.31 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0510267621046134		[learning rate: 0.00014353]
		[batch 20/20] avg loss: 0.05989821420696088		[learning rate: 0.00014318]
	Learning Rate: 0.000143184
	LOSS [training: 0.05546248815578715 | validation: 0.026793358260342945]
	TIME [epoch: 8.29 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.050508097167163556		[learning rate: 0.00014284]
		[batch 20/20] avg loss: 0.05371500868234932		[learning rate: 0.00014249]
	Learning Rate: 0.000142492
	LOSS [training: 0.052111552924756444 | validation: 0.027964425414807433]
	TIME [epoch: 8.29 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05174182600081889		[learning rate: 0.00014215]
		[batch 20/20] avg loss: 0.05396835673633451		[learning rate: 0.0001418]
	Learning Rate: 0.000141803
	LOSS [training: 0.052855091368576704 | validation: 0.03843112745989879]
	TIME [epoch: 8.3 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07364534619165192		[learning rate: 0.00014146]
		[batch 20/20] avg loss: 0.05191587643366978		[learning rate: 0.00014112]
	Learning Rate: 0.000141117
	LOSS [training: 0.06278061131266086 | validation: 0.023439058495201517]
	TIME [epoch: 8.3 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.048254415213710815		[learning rate: 0.00014078]
		[batch 20/20] avg loss: 0.045184946892729526		[learning rate: 0.00014043]
	Learning Rate: 0.000140434
	LOSS [training: 0.04671968105322018 | validation: 0.02659774478074758]
	TIME [epoch: 8.31 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04935725070443076		[learning rate: 0.00014009]
		[batch 20/20] avg loss: 0.046876606577723065		[learning rate: 0.00013976]
	Learning Rate: 0.000139755
	LOSS [training: 0.048116928641076924 | validation: 0.031000579408427372]
	TIME [epoch: 8.29 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04117286451203258		[learning rate: 0.00013942]
		[batch 20/20] avg loss: 0.05508243544019631		[learning rate: 0.00013908]
	Learning Rate: 0.00013908
	LOSS [training: 0.04812764997611445 | validation: 0.04614765353242837]
	TIME [epoch: 8.29 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06043747816127141		[learning rate: 0.00013874]
		[batch 20/20] avg loss: 0.05970027715123851		[learning rate: 0.00013841]
	Learning Rate: 0.000138407
	LOSS [training: 0.060068877656254974 | validation: 0.036083964642046384]
	TIME [epoch: 8.28 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04978926071501381		[learning rate: 0.00013807]
		[batch 20/20] avg loss: 0.05771377587691168		[learning rate: 0.00013774]
	Learning Rate: 0.000137738
	LOSS [training: 0.05375151829596274 | validation: 0.02968081388071591]
	TIME [epoch: 8.31 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05668163919007727		[learning rate: 0.0001374]
		[batch 20/20] avg loss: 0.058034175066200164		[learning rate: 0.00013707]
	Learning Rate: 0.000137072
	LOSS [training: 0.05735790712813871 | validation: 0.025160047061007575]
	TIME [epoch: 8.29 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04209920674527197		[learning rate: 0.00013674]
		[batch 20/20] avg loss: 0.050362673588639904		[learning rate: 0.00013641]
	Learning Rate: 0.000136409
	LOSS [training: 0.04623094016695593 | validation: 0.027131475480328782]
	TIME [epoch: 8.29 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.046493436303362855		[learning rate: 0.00013608]
		[batch 20/20] avg loss: 0.052282483058137465		[learning rate: 0.00013575]
	Learning Rate: 0.000135749
	LOSS [training: 0.04938795968075016 | validation: 0.025728171105779032]
	TIME [epoch: 8.29 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04447536754056931		[learning rate: 0.00013542]
		[batch 20/20] avg loss: 0.05170597751154218		[learning rate: 0.00013509]
	Learning Rate: 0.000135093
	LOSS [training: 0.04809067252605574 | validation: 0.03800143026406271]
	TIME [epoch: 8.3 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05447363064548573		[learning rate: 0.00013477]
		[batch 20/20] avg loss: 0.04955479684279202		[learning rate: 0.00013444]
	Learning Rate: 0.000134439
	LOSS [training: 0.05201421374413887 | validation: 0.03693774261024988]
	TIME [epoch: 8.3 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04753875345562174		[learning rate: 0.00013411]
		[batch 20/20] avg loss: 0.060538887285999474		[learning rate: 0.00013379]
	Learning Rate: 0.000133789
	LOSS [training: 0.054038820370810606 | validation: 0.025745941916531383]
	TIME [epoch: 8.28 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.051502239154595106		[learning rate: 0.00013347]
		[batch 20/20] avg loss: 0.0567700669561255		[learning rate: 0.00013314]
	Learning Rate: 0.000133142
	LOSS [training: 0.05413615305536029 | validation: 0.025305269661068767]
	TIME [epoch: 8.29 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.044013772288909375		[learning rate: 0.00013282]
		[batch 20/20] avg loss: 0.05193001930390549		[learning rate: 0.0001325]
	Learning Rate: 0.000132498
	LOSS [training: 0.047971895796407434 | validation: 0.02529242681468647]
	TIME [epoch: 8.29 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0474709046023042		[learning rate: 0.00013218]
		[batch 20/20] avg loss: 0.05087354158308054		[learning rate: 0.00013186]
	Learning Rate: 0.000131858
	LOSS [training: 0.04917222309269237 | validation: 0.03268684995449955]
	TIME [epoch: 8.31 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.039231454583187955		[learning rate: 0.00013154]
		[batch 20/20] avg loss: 0.061559495862051526		[learning rate: 0.00013122]
	Learning Rate: 0.00013122
	LOSS [training: 0.05039547522261974 | validation: 0.0442467296217399]
	TIME [epoch: 8.28 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05280311110476764		[learning rate: 0.0001309]
		[batch 20/20] avg loss: 0.05324400108398821		[learning rate: 0.00013059]
	Learning Rate: 0.000130585
	LOSS [training: 0.053023556094377935 | validation: 0.05859991862101592]
	TIME [epoch: 8.29 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05180807026085481		[learning rate: 0.00013027]
		[batch 20/20] avg loss: 0.060397177451025096		[learning rate: 0.00012995]
	Learning Rate: 0.000129954
	LOSS [training: 0.05610262385593995 | validation: 0.03779176258897654]
	TIME [epoch: 8.29 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05052985927998771		[learning rate: 0.00012964]
		[batch 20/20] avg loss: 0.05216845654721447		[learning rate: 0.00012933]
	Learning Rate: 0.000129326
	LOSS [training: 0.05134915791360108 | validation: 0.0251052033250724]
	TIME [epoch: 8.32 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04328408192519986		[learning rate: 0.00012901]
		[batch 20/20] avg loss: 0.05345084093488424		[learning rate: 0.0001287]
	Learning Rate: 0.0001287
	LOSS [training: 0.04836746143004205 | validation: 0.01708098053431782]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r3_20240217_161409/states/model_tr_study2_948.pth
	Model improved!!!
EPOCH 949/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04080884567514075		[learning rate: 0.00012839]
		[batch 20/20] avg loss: 0.06508563301371316		[learning rate: 0.00012808]
	Learning Rate: 0.000128078
	LOSS [training: 0.05294723934442695 | validation: 0.020022367720618266]
	TIME [epoch: 8.28 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.045053799940563646		[learning rate: 0.00012777]
		[batch 20/20] avg loss: 0.049280661779190604		[learning rate: 0.00012746]
	Learning Rate: 0.000127458
	LOSS [training: 0.047167230859877125 | validation: 0.03340956223994416]
	TIME [epoch: 8.3 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.052428738720428636		[learning rate: 0.00012715]
		[batch 20/20] avg loss: 0.05309554782177439		[learning rate: 0.00012684]
	Learning Rate: 0.000126842
	LOSS [training: 0.0527621432711015 | validation: 0.02722090475960319]
	TIME [epoch: 8.29 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.050462580977136164		[learning rate: 0.00012653]
		[batch 20/20] avg loss: 0.041093197660889855		[learning rate: 0.00012623]
	Learning Rate: 0.000126229
	LOSS [training: 0.045777889319013 | validation: 0.023903854831670315]
	TIME [epoch: 8.29 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05755971980166434		[learning rate: 0.00012592]
		[batch 20/20] avg loss: 0.0581624377014436		[learning rate: 0.00012562]
	Learning Rate: 0.000125618
	LOSS [training: 0.057861078751553975 | validation: 0.029673171602031007]
	TIME [epoch: 8.27 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04907219516348906		[learning rate: 0.00012531]
		[batch 20/20] avg loss: 0.04739305450517085		[learning rate: 0.00012501]
	Learning Rate: 0.000125011
	LOSS [training: 0.04823262483432996 | validation: 0.02643397245228742]
	TIME [epoch: 8.28 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05665664440764436		[learning rate: 0.00012471]
		[batch 20/20] avg loss: 0.04213464504097919		[learning rate: 0.00012441]
	Learning Rate: 0.000124406
	LOSS [training: 0.04939564472431178 | validation: 0.03535271778909463]
	TIME [epoch: 8.28 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05198042416896017		[learning rate: 0.00012411]
		[batch 20/20] avg loss: 0.03923220089675255		[learning rate: 0.0001238]
	Learning Rate: 0.000123805
	LOSS [training: 0.04560631253285636 | validation: 0.03525427029839767]
	TIME [epoch: 8.3 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05936980507654945		[learning rate: 0.0001235]
		[batch 20/20] avg loss: 0.045996305518961764		[learning rate: 0.00012321]
	Learning Rate: 0.000123206
	LOSS [training: 0.05268305529775561 | validation: 0.02509451970559693]
	TIME [epoch: 8.28 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04991001761217621		[learning rate: 0.00012291]
		[batch 20/20] avg loss: 0.05154318811713158		[learning rate: 0.00012261]
	Learning Rate: 0.00012261
	LOSS [training: 0.0507266028646539 | validation: 0.027777109209934477]
	TIME [epoch: 8.27 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05313417123720017		[learning rate: 0.00012231]
		[batch 20/20] avg loss: 0.0513019423284173		[learning rate: 0.00012202]
	Learning Rate: 0.000122017
	LOSS [training: 0.052218056782808754 | validation: 0.02565882961588073]
	TIME [epoch: 8.28 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05437173725742801		[learning rate: 0.00012172]
		[batch 20/20] avg loss: 0.0505873446303869		[learning rate: 0.00012143]
	Learning Rate: 0.000121427
	LOSS [training: 0.05247954094390744 | validation: 0.025339420535681403]
	TIME [epoch: 8.29 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03928028799183898		[learning rate: 0.00012113]
		[batch 20/20] avg loss: 0.06859332438563699		[learning rate: 0.00012084]
	Learning Rate: 0.00012084
	LOSS [training: 0.05393680618873799 | validation: 0.02010041497258589]
	TIME [epoch: 8.28 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06022338877811563		[learning rate: 0.00012055]
		[batch 20/20] avg loss: 0.03632767415163486		[learning rate: 0.00012026]
	Learning Rate: 0.000120256
	LOSS [training: 0.048275531464875246 | validation: 0.043278739119760136]
	TIME [epoch: 8.27 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07019643525572512		[learning rate: 0.00011996]
		[batch 20/20] avg loss: 0.05061552130609546		[learning rate: 0.00011967]
	Learning Rate: 0.000119674
	LOSS [training: 0.06040597828091028 | validation: 0.026317471417900133]
	TIME [epoch: 8.28 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05572279717339536		[learning rate: 0.00011938]
		[batch 20/20] avg loss: 0.04925121178203462		[learning rate: 0.0001191]
	Learning Rate: 0.000119095
	LOSS [training: 0.052487004477714996 | validation: 0.02333747310755073]
	TIME [epoch: 8.28 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.046891987041648334		[learning rate: 0.00011881]
		[batch 20/20] avg loss: 0.04595185398509266		[learning rate: 0.00011852]
	Learning Rate: 0.000118519
	LOSS [training: 0.046421920513370504 | validation: 0.026399823015775682]
	TIME [epoch: 8.28 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.059477541763302465		[learning rate: 0.00011823]
		[batch 20/20] avg loss: 0.037519740825846096		[learning rate: 0.00011795]
	Learning Rate: 0.000117946
	LOSS [training: 0.048498641294574284 | validation: 0.01920314303703877]
	TIME [epoch: 8.28 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04472150283320999		[learning rate: 0.00011766]
		[batch 20/20] avg loss: 0.060535585119245484		[learning rate: 0.00011738]
	Learning Rate: 0.000117376
	LOSS [training: 0.052628543976227724 | validation: 0.028053923459994322]
	TIME [epoch: 8.27 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04710775903630067		[learning rate: 0.00011709]
		[batch 20/20] avg loss: 0.044412138593273184		[learning rate: 0.00011681]
	Learning Rate: 0.000116808
	LOSS [training: 0.04575994881478693 | validation: 0.024213159854659983]
	TIME [epoch: 8.27 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.046594463222462475		[learning rate: 0.00011653]
		[batch 20/20] avg loss: 0.055569379946434336		[learning rate: 0.00011624]
	Learning Rate: 0.000116243
	LOSS [training: 0.05108192158444841 | validation: 0.03668896718409491]
	TIME [epoch: 8.29 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.050057580985051545		[learning rate: 0.00011596]
		[batch 20/20] avg loss: 0.05248322549668431		[learning rate: 0.00011568]
	Learning Rate: 0.000115681
	LOSS [training: 0.051270403240867936 | validation: 0.02485740955276363]
	TIME [epoch: 8.28 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.049399689950688094		[learning rate: 0.0001154]
		[batch 20/20] avg loss: 0.05131276499259128		[learning rate: 0.00011512]
	Learning Rate: 0.000115122
	LOSS [training: 0.05035622747163968 | validation: 0.02522876815299266]
	TIME [epoch: 8.27 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04658393047847087		[learning rate: 0.00011484]
		[batch 20/20] avg loss: 0.049751290981059924		[learning rate: 0.00011457]
	Learning Rate: 0.000114565
	LOSS [training: 0.0481676107297654 | validation: 0.036344447068069594]
	TIME [epoch: 8.27 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04659594465476912		[learning rate: 0.00011429]
		[batch 20/20] avg loss: 0.058331595851123484		[learning rate: 0.00011401]
	Learning Rate: 0.000114011
	LOSS [training: 0.05246377025294631 | validation: 0.03048368285074598]
	TIME [epoch: 8.29 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04553543660470288		[learning rate: 0.00011374]
		[batch 20/20] avg loss: 0.045445327087897586		[learning rate: 0.00011346]
	Learning Rate: 0.00011346
	LOSS [training: 0.04549038184630022 | validation: 0.03198851053951944]
	TIME [epoch: 8.28 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.054168236346504785		[learning rate: 0.00011319]
		[batch 20/20] avg loss: 0.056603981210045506		[learning rate: 0.00011291]
	Learning Rate: 0.000112911
	LOSS [training: 0.05538610877827514 | validation: 0.032216230854143164]
	TIME [epoch: 8.28 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04273906911323088		[learning rate: 0.00011264]
		[batch 20/20] avg loss: 0.05734893296653391		[learning rate: 0.00011237]
	Learning Rate: 0.000112365
	LOSS [training: 0.050044001039882394 | validation: 0.03781132122143778]
	TIME [epoch: 8.28 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06219427017728359		[learning rate: 0.00011209]
		[batch 20/20] avg loss: 0.03831461434547734		[learning rate: 0.00011182]
	Learning Rate: 0.000111822
	LOSS [training: 0.05025444226138045 | validation: 0.024608728864545508]
	TIME [epoch: 8.29 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.049447138768318376		[learning rate: 0.00011155]
		[batch 20/20] avg loss: 0.04619306571016503		[learning rate: 0.00011128]
	Learning Rate: 0.000111281
	LOSS [training: 0.0478201022392417 | validation: 0.03360310827163758]
	TIME [epoch: 8.3 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04975386767872254		[learning rate: 0.00011101]
		[batch 20/20] avg loss: 0.04347480377711549		[learning rate: 0.00011074]
	Learning Rate: 0.000110743
	LOSS [training: 0.046614335727919017 | validation: 0.05310927272958166]
	TIME [epoch: 8.29 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06144763042172422		[learning rate: 0.00011047]
		[batch 20/20] avg loss: 0.04104174232651113		[learning rate: 0.00011021]
	Learning Rate: 0.000110207
	LOSS [training: 0.05124468637411768 | validation: 0.02572716302804702]
	TIME [epoch: 8.27 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05868758259219312		[learning rate: 0.00010994]
		[batch 20/20] avg loss: 0.042887867807918915		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.05078772520005601 | validation: 0.036492372130768856]
	TIME [epoch: 8.27 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04799391756238205		[learning rate: 0.00010941]
		[batch 20/20] avg loss: 0.05254817024896813		[learning rate: 0.00010914]
	Learning Rate: 0.000109144
	LOSS [training: 0.05027104390567509 | validation: 0.02358335658922983]
	TIME [epoch: 8.29 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05223791869031267		[learning rate: 0.00010888]
		[batch 20/20] avg loss: 0.043467937069547546		[learning rate: 0.00010862]
	Learning Rate: 0.000108616
	LOSS [training: 0.047852927879930104 | validation: 0.02786501890173024]
	TIME [epoch: 8.27 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.052077777599622135		[learning rate: 0.00010835]
		[batch 20/20] avg loss: 0.04705802561929726		[learning rate: 0.00010809]
	Learning Rate: 0.000108091
	LOSS [training: 0.049567901609459696 | validation: 0.029668742599789695]
	TIME [epoch: 8.27 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04164760549717865		[learning rate: 0.00010783]
		[batch 20/20] avg loss: 0.05358714584993397		[learning rate: 0.00010757]
	Learning Rate: 0.000107568
	LOSS [training: 0.047617375673556304 | validation: 0.0293956335646382]
	TIME [epoch: 8.27 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05176354174939808		[learning rate: 0.00010731]
		[batch 20/20] avg loss: 0.04402291292004867		[learning rate: 0.00010705]
	Learning Rate: 0.000107048
	LOSS [training: 0.04789322733472337 | validation: 0.028934122023416504]
	TIME [epoch: 8.29 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.047049798806975254		[learning rate: 0.00010679]
		[batch 20/20] avg loss: 0.05079991760046285		[learning rate: 0.00010653]
	Learning Rate: 0.00010653
	LOSS [training: 0.04892485820371905 | validation: 0.019901495507822175]
	TIME [epoch: 8.28 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03408550382437339		[learning rate: 0.00010627]
		[batch 20/20] avg loss: 0.05843380035198061		[learning rate: 0.00010602]
	Learning Rate: 0.000106015
	LOSS [training: 0.046259652088177 | validation: 0.020603654246962883]
	TIME [epoch: 8.27 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04571148050764585		[learning rate: 0.00010576]
		[batch 20/20] avg loss: 0.0444756484161173		[learning rate: 0.0001055]
	Learning Rate: 0.000105503
	LOSS [training: 0.04509356446188158 | validation: 0.026835865350541645]
	TIME [epoch: 8.27 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.053047631792849395		[learning rate: 0.00010525]
		[batch 20/20] avg loss: 0.05105488036703567		[learning rate: 0.00010499]
	Learning Rate: 0.000104992
	LOSS [training: 0.05205125607994253 | validation: 0.02365661776050877]
	TIME [epoch: 8.27 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05366506406299276		[learning rate: 0.00010474]
		[batch 20/20] avg loss: 0.0403250626765921		[learning rate: 0.00010448]
	Learning Rate: 0.000104485
	LOSS [training: 0.04699506336979242 | validation: 0.024087393341146155]
	TIME [epoch: 8.29 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.050033393157773956		[learning rate: 0.00010423]
		[batch 20/20] avg loss: 0.04475334948750691		[learning rate: 0.00010398]
	Learning Rate: 0.000103979
	LOSS [training: 0.04739337132264044 | validation: 0.04536445262604042]
	TIME [epoch: 8.27 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05891626109571648		[learning rate: 0.00010373]
		[batch 20/20] avg loss: 0.03978568022106864		[learning rate: 0.00010348]
	Learning Rate: 0.000103477
	LOSS [training: 0.04935097065839257 | validation: 0.02675220056332936]
	TIME [epoch: 8.27 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04875852941563054		[learning rate: 0.00010323]
		[batch 20/20] avg loss: 0.05343939309141708		[learning rate: 0.00010298]
	Learning Rate: 0.000102976
	LOSS [training: 0.0510989612535238 | validation: 0.030371608156018682]
	TIME [epoch: 8.27 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0460010804736214		[learning rate: 0.00010273]
		[batch 20/20] avg loss: 0.04899471479788311		[learning rate: 0.00010248]
	Learning Rate: 0.000102478
	LOSS [training: 0.047497897635752254 | validation: 0.023316121214604614]
	TIME [epoch: 8.29 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05121331957444749		[learning rate: 0.00010223]
		[batch 20/20] avg loss: 0.053622306341344225		[learning rate: 0.00010198]
	Learning Rate: 0.000101983
	LOSS [training: 0.05241781295789587 | validation: 0.023965040528729078]
	TIME [epoch: 8.27 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.042097432041857855		[learning rate: 0.00010174]
		[batch 20/20] avg loss: 0.04182905960810361		[learning rate: 0.00010149]
	Learning Rate: 0.000101489
	LOSS [training: 0.04196324582498074 | validation: 0.028308249509978477]
	TIME [epoch: 8.27 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03982833583081053		[learning rate: 0.00010124]
		[batch 20/20] avg loss: 0.0521240593974456		[learning rate: 0.000101]
	Learning Rate: 0.000100999
	LOSS [training: 0.045976197614128064 | validation: 0.025223835868258684]
	TIME [epoch: 8.27 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04123459736066058		[learning rate: 0.00010075]
		[batch 20/20] avg loss: 0.04835755712266067		[learning rate: 0.00010051]
	Learning Rate: 0.00010051
	LOSS [training: 0.04479607724166061 | validation: 0.028947641487132917]
	TIME [epoch: 8.29 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04976132050334814		[learning rate: 0.00010027]
		[batch 20/20] avg loss: 0.05363635617533098		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.05169883833933957 | validation: 0.025814068707978213]
	TIME [epoch: 8.28 sec]
Finished training in 8396.676 seconds.
