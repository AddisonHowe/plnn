Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r5', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1200377566

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/20] avg loss: 7.9250184556840795		[learning rate: 0.01]
		[batch 20/20] avg loss: 7.132575373891314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.528796914787695 | validation: 6.195964758895359]
	TIME [epoch: 78.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/20] avg loss: 6.212167633841778		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.582857934903968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.397512784372873 | validation: 3.7840405263077863]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.354650597807087		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.566041327216091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9603459625115893 | validation: 2.790565554990767]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.381896159772522		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.3766839038954286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.379290031833975 | validation: 2.4014060678070743]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.865535120442378		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.7244919812991746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7950135508707763 | validation: 1.239417348073845]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.8420053278312387		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.8547974835533036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8484014056922713 | validation: 1.371351903907735]
	TIME [epoch: 8.32 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5078068268662155		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4460171316682744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4769119792672447 | validation: 1.0574259957552525]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4355639748287656		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2947548719285327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.365159423378649 | validation: 0.9443150370650679]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1387702062312928		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.130945890310284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1348580482707884 | validation: 1.9486016462709657]
	TIME [epoch: 8.35 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.026329866098667		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.0612809143080093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0438053902033384 | validation: 0.8604309953866742]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.6648762914453843		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8757782425264292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2703272669859067 | validation: 1.3008888099459675]
	TIME [epoch: 8.31 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9335483454400741		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9899073295093379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9617278374747057 | validation: 0.8635249104537853]
	TIME [epoch: 8.32 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8858745055355026		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7855141463342987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8356943259349009 | validation: 0.9149452591516656]
	TIME [epoch: 8.31 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.84648299938401		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7825948981941646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8145389487890873 | validation: 0.7812140701687053]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7572382981767418		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7029589064759858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7300986023263637 | validation: 0.4219873191079468]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7586760827280694		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8806016684956358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8196388756118527 | validation: 0.5926615136412757]
	TIME [epoch: 8.33 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.652235149808991		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7556976983959002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7039664241024457 | validation: 0.7180723086723415]
	TIME [epoch: 8.31 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7715991305693		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8554993443868957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8135492374780977 | validation: 0.4151374501547987]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6958208940713873		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8604760848545654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7781484894629763 | validation: 0.7947617033347684]
	TIME [epoch: 8.31 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6444412670609112		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5976899445003252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6210656057806183 | validation: 0.5160984501136089]
	TIME [epoch: 8.34 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.678166163731169		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7934290064792713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7357975851052202 | validation: 0.7806642200616803]
	TIME [epoch: 8.31 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5569307487926837		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.629068495596443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5929996221945633 | validation: 0.8697421911814676]
	TIME [epoch: 8.31 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6568049704713042		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6565104218826006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6566576961769524 | validation: 0.5334352235762229]
	TIME [epoch: 8.3 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.614345677203171		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.786154947702778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7002503124529746 | validation: 0.5554897169816442]
	TIME [epoch: 8.32 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5800033961478935		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8086053463492563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6943043712485749 | validation: 0.46900661148666783]
	TIME [epoch: 8.3 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5755477821948956		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5996964017542831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5876220919745895 | validation: 0.49469494174461875]
	TIME [epoch: 8.31 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.521925602657996		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6729384318407359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.597432017249366 | validation: 0.5939249941956954]
	TIME [epoch: 8.3 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8132970946003111		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5702641187297314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6917806066650213 | validation: 0.443385238874686]
	TIME [epoch: 8.32 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6788621746240743		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.549730029143159		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6142961018836165 | validation: 0.641222890108729]
	TIME [epoch: 8.3 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5789349365490344		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6723359413061234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6256354389275789 | validation: 0.609172410566703]
	TIME [epoch: 8.3 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6193551828459885		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6599355278840986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6396453553650435 | validation: 0.4207958350241076]
	TIME [epoch: 8.29 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5630310994203043		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5444344591315049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5537327792759045 | validation: 0.5652914355970554]
	TIME [epoch: 8.32 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5902162351213792		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.553913936273495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5720650856974372 | validation: 0.5235321975317089]
	TIME [epoch: 8.3 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5460612065636882		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.810934809118392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6784980078410402 | validation: 0.5379623473117031]
	TIME [epoch: 8.3 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.728337932204632		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.564331848507573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6463348903561025 | validation: 0.7415952566494892]
	TIME [epoch: 8.3 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5964452627865034		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.4818856465590661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5391654546727846 | validation: 0.45966831176695105]
	TIME [epoch: 8.32 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6016319065334562		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6776155943839598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6396237504587081 | validation: 0.7454151134200923]
	TIME [epoch: 8.3 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8059860743154224		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5299828544233665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6679844643693944 | validation: 0.5286462423253986]
	TIME [epoch: 8.29 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.47269156016451674		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6645535469608055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5686225535626611 | validation: 0.9983259286683939]
	TIME [epoch: 8.29 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6096932458486268		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5453642974540047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5775287716513158 | validation: 0.8302933766442592]
	TIME [epoch: 8.32 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5347277746241093		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5534914032441807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.544109588934145 | validation: 0.5186111641755428]
	TIME [epoch: 8.29 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5314078070415004		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5997991109488059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5656034589951531 | validation: 0.602584435813705]
	TIME [epoch: 8.29 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7263585746850808		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6916568856000359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7090077301425584 | validation: 1.1044659388216174]
	TIME [epoch: 8.29 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5230916542894491		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5087903877120781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5159410210007638 | validation: 0.5534895346579584]
	TIME [epoch: 8.32 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.47279895403876615		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5701939139880035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.521496434013385 | validation: 0.615658166927262]
	TIME [epoch: 8.3 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6419363517053962		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5680917042451783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6050140279752874 | validation: 1.0848925763106]
	TIME [epoch: 8.29 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.48710398098783864		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5099161270973792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49851005404260906 | validation: 1.1996996692012993]
	TIME [epoch: 8.31 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6085136514657219		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.41740268111224665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5129581662889844 | validation: 0.7352427723569837]
	TIME [epoch: 8.33 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5495907020194264		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.4241452633216712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48686798267054865 | validation: 0.8088853184694113]
	TIME [epoch: 8.3 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.562634108047072		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.4909390527881777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5267865804176249 | validation: 0.3360236107103508]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_50.pth
	Model improved!!!
EPOCH 51/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4760143943915483		[learning rate: 0.0099782]
		[batch 20/20] avg loss: 0.5426323229364368		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 0.5093233586639925 | validation: 0.6767437053602219]
	TIME [epoch: 8.3 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5712381077949902		[learning rate: 0.00993]
		[batch 20/20] avg loss: 0.4620444006719612		[learning rate: 0.0099059]
	Learning Rate: 0.00990592
	LOSS [training: 0.5166412542334757 | validation: 0.9414489348222583]
	TIME [epoch: 8.34 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5195596731196404		[learning rate: 0.0098819]
		[batch 20/20] avg loss: 0.5171765914803721		[learning rate: 0.009858]
	Learning Rate: 0.00985801
	LOSS [training: 0.5183681323000062 | validation: 0.3934840039019861]
	TIME [epoch: 8.31 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5237205951363001		[learning rate: 0.0098341]
		[batch 20/20] avg loss: 0.538868107994355		[learning rate: 0.0098103]
	Learning Rate: 0.00981034
	LOSS [training: 0.5312943515653276 | validation: 0.6844164696379007]
	TIME [epoch: 8.31 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5868735794520683		[learning rate: 0.0097866]
		[batch 20/20] avg loss: 0.468707994629078		[learning rate: 0.0097629]
	Learning Rate: 0.0097629
	LOSS [training: 0.5277907870405733 | validation: 0.6392766714459364]
	TIME [epoch: 8.32 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.42512965285540216		[learning rate: 0.0097393]
		[batch 20/20] avg loss: 0.4800089823622473		[learning rate: 0.0097157]
	Learning Rate: 0.00971569
	LOSS [training: 0.45256931760882474 | validation: 0.46503951055819787]
	TIME [epoch: 8.34 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4874625602047401		[learning rate: 0.0096922]
		[batch 20/20] avg loss: 0.44992809081702845		[learning rate: 0.0096687]
	Learning Rate: 0.00966871
	LOSS [training: 0.46869532551088433 | validation: 0.47785026559763777]
	TIME [epoch: 8.31 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5208820689731846		[learning rate: 0.0096453]
		[batch 20/20] avg loss: 0.4019698555556218		[learning rate: 0.009622]
	Learning Rate: 0.00962195
	LOSS [training: 0.46142596226440313 | validation: 0.5116618342901973]
	TIME [epoch: 8.32 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5216817954928485		[learning rate: 0.0095987]
		[batch 20/20] avg loss: 0.4121977763608977		[learning rate: 0.0095754]
	Learning Rate: 0.00957542
	LOSS [training: 0.46693978592687324 | validation: 0.8193197931972241]
	TIME [epoch: 8.32 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.45714644188463927		[learning rate: 0.0095522]
		[batch 20/20] avg loss: 0.574300439637018		[learning rate: 0.0095291]
	Learning Rate: 0.00952912
	LOSS [training: 0.5157234407608287 | validation: 0.3610629408666016]
	TIME [epoch: 8.35 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5241030566730333		[learning rate: 0.009506]
		[batch 20/20] avg loss: 0.5510378132060051		[learning rate: 0.009483]
	Learning Rate: 0.00948303
	LOSS [training: 0.5375704349395192 | validation: 0.34478488587902856]
	TIME [epoch: 8.32 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.48568645165335705		[learning rate: 0.0094601]
		[batch 20/20] avg loss: 0.43181058893899377		[learning rate: 0.0094372]
	Learning Rate: 0.00943718
	LOSS [training: 0.4587485202961755 | validation: 0.5327614765174368]
	TIME [epoch: 8.3 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4274867394312148		[learning rate: 0.0094143]
		[batch 20/20] avg loss: 0.47482510059501915		[learning rate: 0.0093915]
	Learning Rate: 0.00939154
	LOSS [training: 0.45115592001311694 | validation: 0.5219825456029967]
	TIME [epoch: 8.31 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.562744405543337		[learning rate: 0.0093688]
		[batch 20/20] avg loss: 0.44699336617896124		[learning rate: 0.0093461]
	Learning Rate: 0.00934612
	LOSS [training: 0.5048688858611491 | validation: 0.646788558326265]
	TIME [epoch: 8.34 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4915947477627305		[learning rate: 0.0093235]
		[batch 20/20] avg loss: 0.4187891527363325		[learning rate: 0.0093009]
	Learning Rate: 0.00930093
	LOSS [training: 0.4551919502495315 | validation: 0.45644608914076495]
	TIME [epoch: 8.3 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.47924995507441925		[learning rate: 0.0092784]
		[batch 20/20] avg loss: 0.4414939283998738		[learning rate: 0.009256]
	Learning Rate: 0.00925595
	LOSS [training: 0.46037194173714646 | validation: 0.5306454830257202]
	TIME [epoch: 8.31 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5066985457997524		[learning rate: 0.0092335]
		[batch 20/20] avg loss: 0.4832445042289426		[learning rate: 0.0092112]
	Learning Rate: 0.00921119
	LOSS [training: 0.4949715250143475 | validation: 0.6676359447350451]
	TIME [epoch: 8.31 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4181062573692123		[learning rate: 0.0091889]
		[batch 20/20] avg loss: 0.45946737787483494		[learning rate: 0.0091666]
	Learning Rate: 0.00916665
	LOSS [training: 0.43878681762202365 | validation: 0.3393489526328317]
	TIME [epoch: 8.34 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.38722019187919593		[learning rate: 0.0091445]
		[batch 20/20] avg loss: 0.5264914903804326		[learning rate: 0.0091223]
	Learning Rate: 0.00912232
	LOSS [training: 0.45685584112981437 | validation: 0.35806120948968523]
	TIME [epoch: 8.33 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4623934079075392		[learning rate: 0.0091002]
		[batch 20/20] avg loss: 0.5215331600006526		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 0.49196328395409594 | validation: 0.7098546028623877]
	TIME [epoch: 8.31 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4887591437073723		[learning rate: 0.0090562]
		[batch 20/20] avg loss: 0.48326418201421306		[learning rate: 0.0090343]
	Learning Rate: 0.0090343
	LOSS [training: 0.4860116628607927 | validation: 0.41270702631298517]
	TIME [epoch: 8.31 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6686385926076922		[learning rate: 0.0090124]
		[batch 20/20] avg loss: 0.43482516133752175		[learning rate: 0.0089906]
	Learning Rate: 0.00899062
	LOSS [training: 0.5517318769726071 | validation: 0.3965789119442804]
	TIME [epoch: 8.34 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3918651017269398		[learning rate: 0.0089689]
		[batch 20/20] avg loss: 0.38726766890446257		[learning rate: 0.0089471]
	Learning Rate: 0.00894714
	LOSS [training: 0.3895663853157011 | validation: 0.31844059631871074]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_73.pth
	Model improved!!!
EPOCH 74/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.39904829122072244		[learning rate: 0.0089255]
		[batch 20/20] avg loss: 0.42841835141717716		[learning rate: 0.0089039]
	Learning Rate: 0.00890387
	LOSS [training: 0.4137333213189498 | validation: 0.44882304935553813]
	TIME [epoch: 8.32 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3762074656255116		[learning rate: 0.0088823]
		[batch 20/20] avg loss: 0.36392989204813025		[learning rate: 0.0088608]
	Learning Rate: 0.00886082
	LOSS [training: 0.370068678836821 | validation: 0.3384027696067148]
	TIME [epoch: 8.32 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36813459848754626		[learning rate: 0.0088394]
		[batch 20/20] avg loss: 0.40932112226155215		[learning rate: 0.008818]
	Learning Rate: 0.00881797
	LOSS [training: 0.38872786037454926 | validation: 0.5636371883066013]
	TIME [epoch: 8.34 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5356537351845783		[learning rate: 0.0087966]
		[batch 20/20] avg loss: 0.3742985294519694		[learning rate: 0.0087753]
	Learning Rate: 0.00877532
	LOSS [training: 0.45497613231827383 | validation: 0.4314820323391061]
	TIME [epoch: 8.61 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.44362820006769227		[learning rate: 0.0087541]
		[batch 20/20] avg loss: 0.3847038230131038		[learning rate: 0.0087329]
	Learning Rate: 0.00873289
	LOSS [training: 0.41416601154039806 | validation: 0.4095164181007316]
	TIME [epoch: 8.31 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4654294587115887		[learning rate: 0.0087117]
		[batch 20/20] avg loss: 0.4142519145918782		[learning rate: 0.0086907]
	Learning Rate: 0.00869066
	LOSS [training: 0.43984068665173337 | validation: 0.30436691688682804]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_79.pth
	Model improved!!!
EPOCH 80/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3341083298130622		[learning rate: 0.0086696]
		[batch 20/20] avg loss: 0.44035694831659933		[learning rate: 0.0086486]
	Learning Rate: 0.00864863
	LOSS [training: 0.38723263906483074 | validation: 0.27856241908711593]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_80.pth
	Model improved!!!
EPOCH 81/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.40572981468218583		[learning rate: 0.0086277]
		[batch 20/20] avg loss: 0.346010177771515		[learning rate: 0.0086068]
	Learning Rate: 0.00860681
	LOSS [training: 0.3758699962268504 | validation: 0.5420521844575935]
	TIME [epoch: 8.32 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4350761509263498		[learning rate: 0.008586]
		[batch 20/20] avg loss: 0.4078635197826694		[learning rate: 0.0085652]
	Learning Rate: 0.00856519
	LOSS [training: 0.42146983535450966 | validation: 0.3500695505964342]
	TIME [epoch: 8.31 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3235650941613281		[learning rate: 0.0085445]
		[batch 20/20] avg loss: 0.46846567719035903		[learning rate: 0.0085238]
	Learning Rate: 0.00852377
	LOSS [training: 0.3960153856758436 | validation: 0.33842679987601765]
	TIME [epoch: 8.31 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.40361619846479496		[learning rate: 0.0085031]
		[batch 20/20] avg loss: 0.4777584986935099		[learning rate: 0.0084825]
	Learning Rate: 0.00848255
	LOSS [training: 0.44068734857915237 | validation: 0.49136906771292577]
	TIME [epoch: 8.33 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4538060261169787		[learning rate: 0.008462]
		[batch 20/20] avg loss: 0.3593214704959567		[learning rate: 0.0084415]
	Learning Rate: 0.00844153
	LOSS [training: 0.4065637483064676 | validation: 0.6058727619438973]
	TIME [epoch: 8.31 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4052338031774327		[learning rate: 0.0084211]
		[batch 20/20] avg loss: 0.37393360351557997		[learning rate: 0.0084007]
	Learning Rate: 0.00840071
	LOSS [training: 0.3895837033465064 | validation: 0.5466532688572079]
	TIME [epoch: 8.31 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5053856977186029		[learning rate: 0.0083804]
		[batch 20/20] avg loss: 0.34625101505262135		[learning rate: 0.0083601]
	Learning Rate: 0.00836008
	LOSS [training: 0.42581835638561205 | validation: 0.3838585549834647]
	TIME [epoch: 8.31 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4733104149821977		[learning rate: 0.0083398]
		[batch 20/20] avg loss: 0.32363588425740053		[learning rate: 0.0083197]
	Learning Rate: 0.00831965
	LOSS [training: 0.3984731496197991 | validation: 0.7911985184633347]
	TIME [epoch: 8.33 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3723233265458934		[learning rate: 0.0082995]
		[batch 20/20] avg loss: 0.4010152348849102		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 0.3866692807154018 | validation: 0.32472494503007665]
	TIME [epoch: 8.31 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.35943359054142554		[learning rate: 0.0082594]
		[batch 20/20] avg loss: 0.5228791163156996		[learning rate: 0.0082394]
	Learning Rate: 0.00823938
	LOSS [training: 0.4411563534285626 | validation: 0.8929126335316873]
	TIME [epoch: 8.31 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4231335045955292		[learning rate: 0.0082194]
		[batch 20/20] avg loss: 0.3434305947177314		[learning rate: 0.0081995]
	Learning Rate: 0.00819954
	LOSS [training: 0.38328204965663026 | validation: 0.2662217267110132]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_91.pth
	Model improved!!!
EPOCH 92/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3926011054871177		[learning rate: 0.0081797]
		[batch 20/20] avg loss: 0.3849229843303654		[learning rate: 0.0081599]
	Learning Rate: 0.00815989
	LOSS [training: 0.3887620449087415 | validation: 0.30225835682313773]
	TIME [epoch: 8.34 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.37864756795573146		[learning rate: 0.0081401]
		[batch 20/20] avg loss: 0.36732581518033774		[learning rate: 0.0081204]
	Learning Rate: 0.00812043
	LOSS [training: 0.3729866915680346 | validation: 0.3548626205041837]
	TIME [epoch: 8.32 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3393062016778603		[learning rate: 0.0081008]
		[batch 20/20] avg loss: 0.347533352739544		[learning rate: 0.0080812]
	Learning Rate: 0.00808116
	LOSS [training: 0.34341977720870215 | validation: 0.6461147200991628]
	TIME [epoch: 8.32 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.39905225167493075		[learning rate: 0.0080616]
		[batch 20/20] avg loss: 0.34757576054868095		[learning rate: 0.0080421]
	Learning Rate: 0.00804208
	LOSS [training: 0.3733140061118059 | validation: 0.7353145553052091]
	TIME [epoch: 8.33 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4806846575627288		[learning rate: 0.0080226]
		[batch 20/20] avg loss: 0.40079124524076004		[learning rate: 0.0080032]
	Learning Rate: 0.00800319
	LOSS [training: 0.44073795140174454 | validation: 0.35446306104678843]
	TIME [epoch: 8.34 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.35723394249265		[learning rate: 0.0079838]
		[batch 20/20] avg loss: 0.35804646059880263		[learning rate: 0.0079645]
	Learning Rate: 0.00796449
	LOSS [training: 0.35764020154572634 | validation: 0.5514031633063985]
	TIME [epoch: 8.32 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3386725038130844		[learning rate: 0.0079452]
		[batch 20/20] avg loss: 0.3206851261568399		[learning rate: 0.007926]
	Learning Rate: 0.00792597
	LOSS [training: 0.32967881498496215 | validation: 0.2929642569269886]
	TIME [epoch: 8.31 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29100011750619215		[learning rate: 0.0079068]
		[batch 20/20] avg loss: 0.34733260334524213		[learning rate: 0.0078876]
	Learning Rate: 0.00788765
	LOSS [training: 0.31916636042571717 | validation: 0.31516940152125433]
	TIME [epoch: 8.31 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3503952002194143		[learning rate: 0.0078685]
		[batch 20/20] avg loss: 0.3353995394748052		[learning rate: 0.0078495]
	Learning Rate: 0.0078495
	LOSS [training: 0.3428973698471098 | validation: 0.2973088525748931]
	TIME [epoch: 8.34 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2986432715537206		[learning rate: 0.0078305]
		[batch 20/20] avg loss: 0.2870425852889643		[learning rate: 0.0078115]
	Learning Rate: 0.00781154
	LOSS [training: 0.2928429284213424 | validation: 0.3977586545685641]
	TIME [epoch: 8.31 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3896630823067776		[learning rate: 0.0077926]
		[batch 20/20] avg loss: 0.40484181383393797		[learning rate: 0.0077738]
	Learning Rate: 0.00777377
	LOSS [training: 0.3972524480703578 | validation: 0.465465717612376]
	TIME [epoch: 8.31 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2905393958280318		[learning rate: 0.0077549]
		[batch 20/20] avg loss: 0.5588603975588652		[learning rate: 0.0077362]
	Learning Rate: 0.00773618
	LOSS [training: 0.4246998966934485 | validation: 0.3113929636929147]
	TIME [epoch: 8.31 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.33284350807037116		[learning rate: 0.0077174]
		[batch 20/20] avg loss: 0.31992305698472767		[learning rate: 0.0076988]
	Learning Rate: 0.00769876
	LOSS [training: 0.3263832825275494 | validation: 0.38036195230923575]
	TIME [epoch: 8.33 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.42726594803812834		[learning rate: 0.0076801]
		[batch 20/20] avg loss: 0.2876404699780122		[learning rate: 0.0076615]
	Learning Rate: 0.00766153
	LOSS [training: 0.35745320900807026 | validation: 0.3947558204736975]
	TIME [epoch: 8.31 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3302242681711284		[learning rate: 0.007643]
		[batch 20/20] avg loss: 0.3754545191839508		[learning rate: 0.0076245]
	Learning Rate: 0.00762449
	LOSS [training: 0.3528393936775395 | validation: 0.2815010400139785]
	TIME [epoch: 8.31 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2884119368755304		[learning rate: 0.007606]
		[batch 20/20] avg loss: 0.3284699161614529		[learning rate: 0.0075876]
	Learning Rate: 0.00758761
	LOSS [training: 0.3084409265184916 | validation: 0.3989332369630718]
	TIME [epoch: 8.3 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.32214177310843584		[learning rate: 0.0075692]
		[batch 20/20] avg loss: 0.409065595435601		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 0.36560368427201845 | validation: 0.29689616650573686]
	TIME [epoch: 8.33 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.32739656468924877		[learning rate: 0.0075326]
		[batch 20/20] avg loss: 0.3353108664778516		[learning rate: 0.0075144]
	Learning Rate: 0.00751441
	LOSS [training: 0.3313537155835502 | validation: 0.417083186623363]
	TIME [epoch: 8.3 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.33399968045670003		[learning rate: 0.0074962]
		[batch 20/20] avg loss: 0.374200928725147		[learning rate: 0.0074781]
	Learning Rate: 0.00747807
	LOSS [training: 0.35410030459092356 | validation: 0.34148797686083876]
	TIME [epoch: 8.3 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36071843423472416		[learning rate: 0.00746]
		[batch 20/20] avg loss: 0.35654882889210704		[learning rate: 0.0074419]
	Learning Rate: 0.00744191
	LOSS [training: 0.35863363156341554 | validation: 0.4343905983954829]
	TIME [epoch: 8.3 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.32404566488195463		[learning rate: 0.0074239]
		[batch 20/20] avg loss: 0.30237019102147616		[learning rate: 0.0074059]
	Learning Rate: 0.00740592
	LOSS [training: 0.31320792795171537 | validation: 0.19182615317334933]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_112.pth
	Model improved!!!
EPOCH 113/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2642152572840421		[learning rate: 0.007388]
		[batch 20/20] avg loss: 0.3654545294610571		[learning rate: 0.0073701]
	Learning Rate: 0.00737011
	LOSS [training: 0.3148348933725496 | validation: 0.2609748908492526]
	TIME [epoch: 8.3 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3731321393314272		[learning rate: 0.0073523]
		[batch 20/20] avg loss: 0.3205418101000312		[learning rate: 0.0073345]
	Learning Rate: 0.00733446
	LOSS [training: 0.3468369747157292 | validation: 0.2682468531137032]
	TIME [epoch: 8.3 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.31235447896326485		[learning rate: 0.0073167]
		[batch 20/20] avg loss: 0.32678754672737254		[learning rate: 0.007299]
	Learning Rate: 0.007299
	LOSS [training: 0.31957101284531875 | validation: 0.35648153681343353]
	TIME [epoch: 8.31 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27290298597231055		[learning rate: 0.0072813]
		[batch 20/20] avg loss: 0.32417274167708243		[learning rate: 0.0072637]
	Learning Rate: 0.0072637
	LOSS [training: 0.2985378638246964 | validation: 0.23739793223277714]
	TIME [epoch: 8.33 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24292635419945485		[learning rate: 0.0072461]
		[batch 20/20] avg loss: 0.3126162964469438		[learning rate: 0.0072286]
	Learning Rate: 0.00722857
	LOSS [training: 0.27777132532319937 | validation: 0.29776329159235737]
	TIME [epoch: 8.31 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3169298517583672		[learning rate: 0.0072111]
		[batch 20/20] avg loss: 0.35339785249258904		[learning rate: 0.0071936]
	Learning Rate: 0.00719362
	LOSS [training: 0.33516385212547817 | validation: 0.3947065541497746]
	TIME [epoch: 8.3 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21961965278957335		[learning rate: 0.0071762]
		[batch 20/20] avg loss: 0.36598074651170986		[learning rate: 0.0071588]
	Learning Rate: 0.00715883
	LOSS [training: 0.29280019965064163 | validation: 0.2441962878400143]
	TIME [epoch: 8.3 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.33265248728165664		[learning rate: 0.0071415]
		[batch 20/20] avg loss: 0.35209524443643236		[learning rate: 0.0071242]
	Learning Rate: 0.00712421
	LOSS [training: 0.3423738658590445 | validation: 0.2867277119244977]
	TIME [epoch: 8.33 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25434310402273036		[learning rate: 0.007107]
		[batch 20/20] avg loss: 0.2868476500647099		[learning rate: 0.0070898]
	Learning Rate: 0.00708976
	LOSS [training: 0.2705953770437202 | validation: 0.39077780048190447]
	TIME [epoch: 8.3 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2721198322963641		[learning rate: 0.0070726]
		[batch 20/20] avg loss: 0.278069070938459		[learning rate: 0.0070555]
	Learning Rate: 0.00705548
	LOSS [training: 0.2750944516174116 | validation: 0.19082795757561818]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_122.pth
	Model improved!!!
EPOCH 123/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29136381206202777		[learning rate: 0.0070384]
		[batch 20/20] avg loss: 0.3535012380763335		[learning rate: 0.0070214]
	Learning Rate: 0.00702136
	LOSS [training: 0.3224325250691807 | validation: 0.19968193044503169]
	TIME [epoch: 8.31 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27906488479914093		[learning rate: 0.0070044]
		[batch 20/20] avg loss: 0.23356387947235477		[learning rate: 0.0069874]
	Learning Rate: 0.0069874
	LOSS [training: 0.25631438213574786 | validation: 0.3178622222852291]
	TIME [epoch: 8.33 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26980485407400195		[learning rate: 0.0069705]
		[batch 20/20] avg loss: 0.29082362725679123		[learning rate: 0.0069536]
	Learning Rate: 0.00695361
	LOSS [training: 0.28031424066539656 | validation: 0.23061222645289475]
	TIME [epoch: 8.31 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23064589384298756		[learning rate: 0.0069368]
		[batch 20/20] avg loss: 0.27518635106977557		[learning rate: 0.00692]
	Learning Rate: 0.00691999
	LOSS [training: 0.2529161224563815 | validation: 0.23572682646064763]
	TIME [epoch: 8.3 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3070339655073159		[learning rate: 0.0069032]
		[batch 20/20] avg loss: 0.32438382672350663		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 0.31570889611541125 | validation: 0.19154608355551567]
	TIME [epoch: 8.3 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2917429510913706		[learning rate: 0.0068699]
		[batch 20/20] avg loss: 0.2813857220553201		[learning rate: 0.0068532]
	Learning Rate: 0.00685322
	LOSS [training: 0.28656433657334535 | validation: 0.21575140917888846]
	TIME [epoch: 8.33 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28755914737408905		[learning rate: 0.0068366]
		[batch 20/20] avg loss: 0.25086474212931076		[learning rate: 0.0068201]
	Learning Rate: 0.00682008
	LOSS [training: 0.26921194475169996 | validation: 0.23421401741481307]
	TIME [epoch: 8.31 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27877065912121685		[learning rate: 0.0068036]
		[batch 20/20] avg loss: 0.28383166935373844		[learning rate: 0.0067871]
	Learning Rate: 0.0067871
	LOSS [training: 0.28130116423747764 | validation: 0.29943994682944464]
	TIME [epoch: 8.3 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30212789603160695		[learning rate: 0.0067707]
		[batch 20/20] avg loss: 0.33768764327199097		[learning rate: 0.0067543]
	Learning Rate: 0.00675428
	LOSS [training: 0.319907769651799 | validation: 0.2632545587922328]
	TIME [epoch: 8.31 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22275528957684793		[learning rate: 0.0067379]
		[batch 20/20] avg loss: 0.24625501299889066		[learning rate: 0.0067216]
	Learning Rate: 0.00672162
	LOSS [training: 0.23450515128786922 | validation: 0.523528188226581]
	TIME [epoch: 8.33 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5992905865497995		[learning rate: 0.0067053]
		[batch 20/20] avg loss: 0.2876833700138091		[learning rate: 0.0066891]
	Learning Rate: 0.00668911
	LOSS [training: 0.4434869782818044 | validation: 0.612573339516777]
	TIME [epoch: 8.31 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2968589268343079		[learning rate: 0.0066729]
		[batch 20/20] avg loss: 0.28533674859932984		[learning rate: 0.0066568]
	Learning Rate: 0.00665676
	LOSS [training: 0.291097837716819 | validation: 0.22159624438802586]
	TIME [epoch: 8.31 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29936692815728777		[learning rate: 0.0066406]
		[batch 20/20] avg loss: 0.34117789499670875		[learning rate: 0.0066246]
	Learning Rate: 0.00662457
	LOSS [training: 0.32027241157699826 | validation: 0.21207205957519878]
	TIME [epoch: 8.3 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25717495129654705		[learning rate: 0.0066085]
		[batch 20/20] avg loss: 0.23528492499723894		[learning rate: 0.0065925]
	Learning Rate: 0.00659254
	LOSS [training: 0.24622993814689295 | validation: 0.3708519142759037]
	TIME [epoch: 8.33 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.34283214601082407		[learning rate: 0.0065766]
		[batch 20/20] avg loss: 0.27134649392094634		[learning rate: 0.0065607]
	Learning Rate: 0.00656066
	LOSS [training: 0.30708931996588523 | validation: 0.1832613433724683]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_137.pth
	Model improved!!!
EPOCH 138/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22064091971384733		[learning rate: 0.0065448]
		[batch 20/20] avg loss: 0.3255291543666235		[learning rate: 0.0065289]
	Learning Rate: 0.00652893
	LOSS [training: 0.2730850370402354 | validation: 0.2707304924814295]
	TIME [epoch: 8.31 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29326093626600397		[learning rate: 0.0065131]
		[batch 20/20] avg loss: 0.2311491348646511		[learning rate: 0.0064974]
	Learning Rate: 0.00649736
	LOSS [training: 0.2622050355653275 | validation: 0.22204797539460408]
	TIME [epoch: 8.31 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29029564387651113		[learning rate: 0.0064816]
		[batch 20/20] avg loss: 0.2598057552060565		[learning rate: 0.0064659]
	Learning Rate: 0.00646594
	LOSS [training: 0.2750506995412838 | validation: 0.21842580384874047]
	TIME [epoch: 8.33 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2813030146715225		[learning rate: 0.0064503]
		[batch 20/20] avg loss: 0.27983444716685135		[learning rate: 0.0064347]
	Learning Rate: 0.00643467
	LOSS [training: 0.2805687309191869 | validation: 1.173009423969071]
	TIME [epoch: 8.31 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.342278505441482		[learning rate: 0.0064191]
		[batch 20/20] avg loss: 0.254086777509796		[learning rate: 0.0064036]
	Learning Rate: 0.00640355
	LOSS [training: 0.29818264147563905 | validation: 0.29729686271283007]
	TIME [epoch: 8.3 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26909695554356794		[learning rate: 0.0063881]
		[batch 20/20] avg loss: 0.28835652195939476		[learning rate: 0.0063726]
	Learning Rate: 0.00637259
	LOSS [training: 0.27872673875148135 | validation: 0.2615082011200795]
	TIME [epoch: 8.3 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23008280064571043		[learning rate: 0.0063572]
		[batch 20/20] avg loss: 0.28384464687261446		[learning rate: 0.0063418]
	Learning Rate: 0.00634177
	LOSS [training: 0.2569637237591625 | validation: 0.22391981469539368]
	TIME [epoch: 8.34 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23501218246829061		[learning rate: 0.0063264]
		[batch 20/20] avg loss: 0.34317616008943086		[learning rate: 0.0063111]
	Learning Rate: 0.0063111
	LOSS [training: 0.2890941712788607 | validation: 0.19186223953640447]
	TIME [epoch: 8.3 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.31936931272751234		[learning rate: 0.0062958]
		[batch 20/20] avg loss: 0.29133229581728715		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 0.3053508042723997 | validation: 0.27724164497358084]
	TIME [epoch: 8.3 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2532013655185643		[learning rate: 0.0062654]
		[batch 20/20] avg loss: 0.2656417000238509		[learning rate: 0.0062502]
	Learning Rate: 0.00625021
	LOSS [training: 0.2594215327712076 | validation: 0.15808454623074245]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_147.pth
	Model improved!!!
EPOCH 148/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18483933369333294		[learning rate: 0.0062351]
		[batch 20/20] avg loss: 0.21476235981901132		[learning rate: 0.00622]
	Learning Rate: 0.00621999
	LOSS [training: 0.19980084675617213 | validation: 0.30102998933390546]
	TIME [epoch: 8.33 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.320423744132874		[learning rate: 0.0062049]
		[batch 20/20] avg loss: 0.2943076234102492		[learning rate: 0.0061899]
	Learning Rate: 0.00618991
	LOSS [training: 0.3073656837715616 | validation: 0.19587376276707308]
	TIME [epoch: 8.31 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2597111748888246		[learning rate: 0.0061749]
		[batch 20/20] avg loss: 0.2935979021569614		[learning rate: 0.00616]
	Learning Rate: 0.00615997
	LOSS [training: 0.27665453852289296 | validation: 0.2752897071113506]
	TIME [epoch: 8.3 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22134177182384568		[learning rate: 0.0061451]
		[batch 20/20] avg loss: 0.25467927526256223		[learning rate: 0.0061302]
	Learning Rate: 0.00613019
	LOSS [training: 0.238010523543204 | validation: 0.4624711849485072]
	TIME [epoch: 8.31 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.34686098387716274		[learning rate: 0.0061153]
		[batch 20/20] avg loss: 0.26167975776738384		[learning rate: 0.0061005]
	Learning Rate: 0.00610054
	LOSS [training: 0.3042703708222733 | validation: 0.358639545281785]
	TIME [epoch: 8.34 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23895207168712784		[learning rate: 0.0060858]
		[batch 20/20] avg loss: 0.21568500200112184		[learning rate: 0.006071]
	Learning Rate: 0.00607104
	LOSS [training: 0.22731853684412484 | validation: 0.24531941069519358]
	TIME [epoch: 8.3 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2971349397218359		[learning rate: 0.0060563]
		[batch 20/20] avg loss: 0.2513926115633313		[learning rate: 0.0060417]
	Learning Rate: 0.00604168
	LOSS [training: 0.2742637756425836 | validation: 0.26327986936337067]
	TIME [epoch: 8.3 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19517666217882174		[learning rate: 0.0060271]
		[batch 20/20] avg loss: 0.2434817198463549		[learning rate: 0.0060125]
	Learning Rate: 0.00601247
	LOSS [training: 0.21932919101258838 | validation: 0.23850383944680778]
	TIME [epoch: 8.31 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1926211658459141		[learning rate: 0.0059979]
		[batch 20/20] avg loss: 0.277369963685464		[learning rate: 0.0059834]
	Learning Rate: 0.00598339
	LOSS [training: 0.23499556476568909 | validation: 0.3071835163457715]
	TIME [epoch: 8.33 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2291503479768983		[learning rate: 0.0059689]
		[batch 20/20] avg loss: 0.281829728433545		[learning rate: 0.0059545]
	Learning Rate: 0.00595446
	LOSS [training: 0.25549003820522165 | validation: 0.20696800005932842]
	TIME [epoch: 8.3 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2301405037751984		[learning rate: 0.00594]
		[batch 20/20] avg loss: 0.3361497240203712		[learning rate: 0.0059257]
	Learning Rate: 0.00592566
	LOSS [training: 0.28314511389778485 | validation: 0.337849625631893]
	TIME [epoch: 8.3 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2008253033120484		[learning rate: 0.0059113]
		[batch 20/20] avg loss: 0.2130018871183371		[learning rate: 0.005897]
	Learning Rate: 0.00589701
	LOSS [training: 0.20691359521519273 | validation: 0.24867390920045743]
	TIME [epoch: 8.3 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.300131461536399		[learning rate: 0.0058827]
		[batch 20/20] avg loss: 0.22510082933092876		[learning rate: 0.0058685]
	Learning Rate: 0.00586849
	LOSS [training: 0.26261614543366396 | validation: 0.29275205948813443]
	TIME [epoch: 8.33 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1997040399288571		[learning rate: 0.0058543]
		[batch 20/20] avg loss: 0.29528069835072057		[learning rate: 0.0058401]
	Learning Rate: 0.00584011
	LOSS [training: 0.24749236913978878 | validation: 0.15507392194091896]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_161.pth
	Model improved!!!
EPOCH 162/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23362581136842656		[learning rate: 0.005826]
		[batch 20/20] avg loss: 0.22531414053931456		[learning rate: 0.0058119]
	Learning Rate: 0.00581187
	LOSS [training: 0.22946997595387053 | validation: 0.18394640830092535]
	TIME [epoch: 8.31 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24209962063599438		[learning rate: 0.0057978]
		[batch 20/20] avg loss: 0.21368014849994665		[learning rate: 0.0057838]
	Learning Rate: 0.00578376
	LOSS [training: 0.22788988456797052 | validation: 0.17227723395967878]
	TIME [epoch: 8.32 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2312304807015182		[learning rate: 0.0057698]
		[batch 20/20] avg loss: 0.2745936221166549		[learning rate: 0.0057558]
	Learning Rate: 0.00575579
	LOSS [training: 0.2529120514090865 | validation: 0.2925058817571582]
	TIME [epoch: 8.34 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1855557500808537		[learning rate: 0.0057419]
		[batch 20/20] avg loss: 0.19359001161849404		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 0.18957288084967389 | validation: 0.3057928850811107]
	TIME [epoch: 8.32 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3851739885754137		[learning rate: 0.0057141]
		[batch 20/20] avg loss: 0.277525317501872		[learning rate: 0.0057003]
	Learning Rate: 0.00570026
	LOSS [training: 0.33134965303864294 | validation: 0.15379231380038683]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_166.pth
	Model improved!!!
EPOCH 167/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21935223875007276		[learning rate: 0.0056865]
		[batch 20/20] avg loss: 0.2967849751090016		[learning rate: 0.0056727]
	Learning Rate: 0.0056727
	LOSS [training: 0.25806860692953715 | validation: 0.1602122961960766]
	TIME [epoch: 8.32 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2057324878677837		[learning rate: 0.005659]
		[batch 20/20] avg loss: 0.2300219730816611		[learning rate: 0.0056453]
	Learning Rate: 0.00564526
	LOSS [training: 0.21787723047472238 | validation: 0.1950920186755848]
	TIME [epoch: 8.31 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.32114168944352933		[learning rate: 0.0056316]
		[batch 20/20] avg loss: 0.2501277799448132		[learning rate: 0.005618]
	Learning Rate: 0.00561796
	LOSS [training: 0.28563473469417133 | validation: 0.16126383813059675]
	TIME [epoch: 8.31 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18816412462489113		[learning rate: 0.0056044]
		[batch 20/20] avg loss: 0.21372285522704573		[learning rate: 0.0055908]
	Learning Rate: 0.0055908
	LOSS [training: 0.20094348992596842 | validation: 0.19940701373562905]
	TIME [epoch: 8.31 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16925853447150965		[learning rate: 0.0055773]
		[batch 20/20] avg loss: 0.20098026491247784		[learning rate: 0.0055638]
	Learning Rate: 0.00556376
	LOSS [training: 0.18511939969199373 | validation: 0.31812818150798283]
	TIME [epoch: 8.32 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23600243862320847		[learning rate: 0.0055503]
		[batch 20/20] avg loss: 0.22047402941293756		[learning rate: 0.0055369]
	Learning Rate: 0.00553685
	LOSS [training: 0.22823823401807303 | validation: 0.24206312570352778]
	TIME [epoch: 8.32 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20268106664666888		[learning rate: 0.0055235]
		[batch 20/20] avg loss: 0.2094771516744824		[learning rate: 0.0055101]
	Learning Rate: 0.00551008
	LOSS [training: 0.20607910916057567 | validation: 0.20805539725574987]
	TIME [epoch: 8.31 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24034139084675		[learning rate: 0.0054967]
		[batch 20/20] avg loss: 0.23624104264720253		[learning rate: 0.0054834]
	Learning Rate: 0.00548343
	LOSS [training: 0.23829121674697631 | validation: 0.23944266385080712]
	TIME [epoch: 8.3 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2039420371443131		[learning rate: 0.0054702]
		[batch 20/20] avg loss: 0.332429394149394		[learning rate: 0.0054569]
	Learning Rate: 0.00545692
	LOSS [training: 0.2681857156468535 | validation: 0.3264571196622173]
	TIME [epoch: 8.31 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23756852731254036		[learning rate: 0.0054437]
		[batch 20/20] avg loss: 0.201103343046963		[learning rate: 0.0054305]
	Learning Rate: 0.00543053
	LOSS [training: 0.21933593517975164 | validation: 0.6373557536469204]
	TIME [epoch: 8.33 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2349011098634426		[learning rate: 0.0054174]
		[batch 20/20] avg loss: 0.2215901018498067		[learning rate: 0.0054043]
	Learning Rate: 0.00540427
	LOSS [training: 0.22824560585662468 | validation: 0.39376000547682355]
	TIME [epoch: 8.31 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21308818682164218		[learning rate: 0.0053912]
		[batch 20/20] avg loss: 0.23091704072787858		[learning rate: 0.0053781]
	Learning Rate: 0.00537813
	LOSS [training: 0.22200261377476038 | validation: 0.1957225774624788]
	TIME [epoch: 8.29 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24215771262559463		[learning rate: 0.0053651]
		[batch 20/20] avg loss: 0.1531069171694974		[learning rate: 0.0053521]
	Learning Rate: 0.00535213
	LOSS [training: 0.197632314897546 | validation: 0.41191795815408305]
	TIME [epoch: 8.3 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2633508634550973		[learning rate: 0.0053392]
		[batch 20/20] avg loss: 0.23284570632883672		[learning rate: 0.0053262]
	Learning Rate: 0.00532624
	LOSS [training: 0.24809828489196706 | validation: 0.43643295413439637]
	TIME [epoch: 8.31 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2599227377112991		[learning rate: 0.0053133]
		[batch 20/20] avg loss: 0.29185776163650334		[learning rate: 0.0053005]
	Learning Rate: 0.00530049
	LOSS [training: 0.2758902496739012 | validation: 0.1490444195155648]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_181.pth
	Model improved!!!
EPOCH 182/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15117747040296656		[learning rate: 0.0052877]
		[batch 20/20] avg loss: 0.24918111851454428		[learning rate: 0.0052749]
	Learning Rate: 0.00527485
	LOSS [training: 0.2001792944587554 | validation: 0.2623613853521818]
	TIME [epoch: 8.31 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26407213976167954		[learning rate: 0.0052621]
		[batch 20/20] avg loss: 0.22315582944460322		[learning rate: 0.0052493]
	Learning Rate: 0.00524935
	LOSS [training: 0.24361398460314138 | validation: 0.23448962370274926]
	TIME [epoch: 8.34 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19709757219672053		[learning rate: 0.0052366]
		[batch 20/20] avg loss: 0.2971044564135033		[learning rate: 0.005224]
	Learning Rate: 0.00522396
	LOSS [training: 0.24710101430511192 | validation: 0.1838829872206843]
	TIME [epoch: 8.33 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23599730273330852		[learning rate: 0.0052113]
		[batch 20/20] avg loss: 0.22607954364711244		[learning rate: 0.0051987]
	Learning Rate: 0.0051987
	LOSS [training: 0.23103842319021045 | validation: 0.23549407997255525]
	TIME [epoch: 8.32 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24822614462619744		[learning rate: 0.0051861]
		[batch 20/20] avg loss: 0.1937409264032694		[learning rate: 0.0051736]
	Learning Rate: 0.00517356
	LOSS [training: 0.22098353551473343 | validation: 0.35278584412475056]
	TIME [epoch: 8.32 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.207348729352726		[learning rate: 0.005161]
		[batch 20/20] avg loss: 0.31699335750849955		[learning rate: 0.0051485]
	Learning Rate: 0.00514854
	LOSS [training: 0.26217104343061276 | validation: 0.19125246121687345]
	TIME [epoch: 8.34 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2909688705389607		[learning rate: 0.0051361]
		[batch 20/20] avg loss: 0.2217672454860813		[learning rate: 0.0051236]
	Learning Rate: 0.00512364
	LOSS [training: 0.25636805801252105 | validation: 0.1702573395057283]
	TIME [epoch: 8.33 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1785861263995836		[learning rate: 0.0051112]
		[batch 20/20] avg loss: 0.2357231526477464		[learning rate: 0.0050989]
	Learning Rate: 0.00509887
	LOSS [training: 0.20715463952366497 | validation: 0.3647665172180381]
	TIME [epoch: 8.3 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2863890904950725		[learning rate: 0.0050865]
		[batch 20/20] avg loss: 0.22808583214341768		[learning rate: 0.0050742]
	Learning Rate: 0.00507421
	LOSS [training: 0.2572374613192451 | validation: 0.19911333998275996]
	TIME [epoch: 8.3 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18227273889147602		[learning rate: 0.0050619]
		[batch 20/20] avg loss: 0.17654400957597555		[learning rate: 0.0050497]
	Learning Rate: 0.00504967
	LOSS [training: 0.17940837423372583 | validation: 0.14891909966792546]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_191.pth
	Model improved!!!
EPOCH 192/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25459474554576145		[learning rate: 0.0050374]
		[batch 20/20] avg loss: 0.1595114708468877		[learning rate: 0.0050253]
	Learning Rate: 0.00502525
	LOSS [training: 0.20705310819632455 | validation: 0.1405266732992029]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_192.pth
	Model improved!!!
EPOCH 193/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2750305625762398		[learning rate: 0.0050131]
		[batch 20/20] avg loss: 0.2748635772787785		[learning rate: 0.005001]
	Learning Rate: 0.00500095
	LOSS [training: 0.2749470699275092 | validation: 0.18181056361036851]
	TIME [epoch: 8.31 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14422328643239557		[learning rate: 0.0049888]
		[batch 20/20] avg loss: 0.19459646835322642		[learning rate: 0.0049768]
	Learning Rate: 0.00497677
	LOSS [training: 0.169409877392811 | validation: 1.1201390161984297]
	TIME [epoch: 8.31 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2415364247133794		[learning rate: 0.0049647]
		[batch 20/20] avg loss: 0.1664686156339387		[learning rate: 0.0049527]
	Learning Rate: 0.0049527
	LOSS [training: 0.204002520173659 | validation: 0.25609517749582067]
	TIME [epoch: 8.33 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23531004999934516		[learning rate: 0.0049407]
		[batch 20/20] avg loss: 0.285622467307621		[learning rate: 0.0049288]
	Learning Rate: 0.00492875
	LOSS [training: 0.2604662586534831 | validation: 0.33730630229710534]
	TIME [epoch: 8.32 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20911825497124478		[learning rate: 0.0049168]
		[batch 20/20] avg loss: 0.204829621563334		[learning rate: 0.0049049]
	Learning Rate: 0.00490492
	LOSS [training: 0.2069739382672894 | validation: 0.13284801885755226]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_197.pth
	Model improved!!!
EPOCH 198/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22881779381453998		[learning rate: 0.004893]
		[batch 20/20] avg loss: 0.21579630191961835		[learning rate: 0.0048812]
	Learning Rate: 0.0048812
	LOSS [training: 0.22230704786707914 | validation: 0.14666531814512765]
	TIME [epoch: 8.32 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.32141200200315867		[learning rate: 0.0048694]
		[batch 20/20] avg loss: 0.22159307227401603		[learning rate: 0.0048576]
	Learning Rate: 0.00485759
	LOSS [training: 0.2715025371385873 | validation: 0.3128632008488848]
	TIME [epoch: 8.33 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18038063992479536		[learning rate: 0.0048458]
		[batch 20/20] avg loss: 0.23788857027641028		[learning rate: 0.0048341]
	Learning Rate: 0.0048341
	LOSS [training: 0.20913460510060283 | validation: 0.3130695933834524]
	TIME [epoch: 8.33 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28926776727581793		[learning rate: 0.0048224]
		[batch 20/20] avg loss: 0.2106588738359927		[learning rate: 0.0048107]
	Learning Rate: 0.00481072
	LOSS [training: 0.24996332055590537 | validation: 0.12000690826500077]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r5_20240217_161409/states/model_tr_study2_201.pth
	Model improved!!!
EPOCH 202/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21015053215493856		[learning rate: 0.0047991]
		[batch 20/20] avg loss: 0.2756767571077897		[learning rate: 0.0047875]
	Learning Rate: 0.00478746
	LOSS [training: 0.24291364463136417 | validation: 0.30827526077674866]
	TIME [epoch: 8.31 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2484046700893865		[learning rate: 0.0047759]
		[batch 20/20] avg loss: 0.3182272929664368		[learning rate: 0.0047643]
	Learning Rate: 0.00476431
	LOSS [training: 0.28331598152791165 | validation: 0.3495261417137439]
	TIME [epoch: 8.32 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3520148561132519		[learning rate: 0.0047528]
		[batch 20/20] avg loss: 0.34478399037453933		[learning rate: 0.0047413]
	Learning Rate: 0.00474127
	LOSS [training: 0.34839942324389567 | validation: 0.1422467735425751]
	TIME [epoch: 8.32 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2942125862570301		[learning rate: 0.0047298]
		[batch 20/20] avg loss: 0.22703334377464396		[learning rate: 0.0047183]
	Learning Rate: 0.00471834
	LOSS [training: 0.26062296501583704 | validation: 0.40845995307245303]
	TIME [epoch: 8.31 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4528327378924559		[learning rate: 0.0047069]
		[batch 20/20] avg loss: 0.1934920090226198		[learning rate: 0.0046955]
	Learning Rate: 0.00469553
	LOSS [training: 0.32316237345753784 | validation: 0.33366729170769116]
	TIME [epoch: 8.32 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2129897453587911		[learning rate: 0.0046842]
		[batch 20/20] avg loss: 0.20967075527106793		[learning rate: 0.0046728]
	Learning Rate: 0.00467282
	LOSS [training: 0.21133025031492955 | validation: 0.21492801155280122]
	TIME [epoch: 8.33 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.48685698273782485		[learning rate: 0.0046615]
		[batch 20/20] avg loss: 0.25266958754240315		[learning rate: 0.0046502]
	Learning Rate: 0.00465022
	LOSS [training: 0.369763285140114 | validation: 0.14810363672672525]
	TIME [epoch: 8.33 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17225250058736147		[learning rate: 0.004639]
		[batch 20/20] avg loss: 0.20739260769816448		[learning rate: 0.0046277]
	Learning Rate: 0.00462773
	LOSS [training: 0.18982255414276294 | validation: 0.1373772016475755]
	TIME [epoch: 8.32 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.31568915783603646		[learning rate: 0.0046165]
		[batch 20/20] avg loss: 0.6783620310222522		[learning rate: 0.0046054]
	Learning Rate: 0.00460536
	LOSS [training: 0.4970255944291444 | validation: 0.7749684157622707]
	TIME [epoch: 8.32 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.38690539234597926		[learning rate: 0.0045942]
		[batch 20/20] avg loss: 0.6489498898632495		[learning rate: 0.0045831]
	Learning Rate: 0.00458308
	LOSS [training: 0.5179276411046143 | validation: 0.34978720301089083]
	TIME [epoch: 8.34 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5937766778540844		[learning rate: 0.004572]
		[batch 20/20] avg loss: 0.3784172376120504		[learning rate: 0.0045609]
	Learning Rate: 0.00456092
	LOSS [training: 0.4860969577330674 | validation: 0.2712982727886315]
	TIME [epoch: 8.33 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.46738403941875006		[learning rate: 0.0045499]
		[batch 20/20] avg loss: 0.3409338178263247		[learning rate: 0.0045389]
	Learning Rate: 0.00453887
	LOSS [training: 0.40415892862253733 | validation: 0.3542492965562818]
	TIME [epoch: 8.33 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3259033158439088		[learning rate: 0.0045279]
		[batch 20/20] avg loss: 0.3353002310796945		[learning rate: 0.0045169]
	Learning Rate: 0.00451692
	LOSS [training: 0.33060177346180175 | validation: 0.385382948784657]
	TIME [epoch: 8.32 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7875027183327682		[learning rate: 0.004506]
		[batch 20/20] avg loss: 1.3100032847596768		[learning rate: 0.0044951]
	Learning Rate: 0.00449507
	LOSS [training: 1.048753001546222 | validation: 0.27382516748514246]
	TIME [epoch: 8.33 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3056924793994481		[learning rate: 0.0044842]
		[batch 20/20] avg loss: 0.5611858079834777		[learning rate: 0.0044733]
	Learning Rate: 0.00447334
	LOSS [training: 0.4334391436914629 | validation: 0.20360070599141944]
	TIME [epoch: 8.34 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4056068461093233		[learning rate: 0.0044625]
		[batch 20/20] avg loss: 0.47370289842804575		[learning rate: 0.0044517]
	Learning Rate: 0.0044517
	LOSS [training: 0.4396548722686845 | validation: 0.23425071249053608]
	TIME [epoch: 8.33 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3838982390276951		[learning rate: 0.0044409]
		[batch 20/20] avg loss: 0.26797515107952635		[learning rate: 0.0044302]
	Learning Rate: 0.00443018
	LOSS [training: 0.3259366950536106 | validation: 0.19460598749582753]
	TIME [epoch: 8.32 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2956151373599783		[learning rate: 0.0044195]
		[batch 20/20] avg loss: 0.391715550160034		[learning rate: 0.0044088]
	Learning Rate: 0.00440875
	LOSS [training: 0.34366534376000607 | validation: 0.2489827808711219]
	TIME [epoch: 8.34 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.840846601928446		[learning rate: 0.0043981]
		[batch 20/20] avg loss: 3.5960067697222384		[learning rate: 0.0043874]
	Learning Rate: 0.00438743
	LOSS [training: 3.218426685825343 | validation: 0.9481827341531714]
	TIME [epoch: 8.33 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9764140054489209		[learning rate: 0.0043768]
		[batch 20/20] avg loss: 0.3501263930506266		[learning rate: 0.0043662]
	Learning Rate: 0.00436622
	LOSS [training: 0.6632701992497737 | validation: 0.14569332834781829]
	TIME [epoch: 8.32 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.48124666921013864		[learning rate: 0.0043556]
		[batch 20/20] avg loss: 0.4155561870691531		[learning rate: 0.0043451]
	Learning Rate: 0.0043451
	LOSS [training: 0.44840142813964584 | validation: 0.2702115341707814]
	TIME [epoch: 8.32 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2206427879455511		[learning rate: 0.0043346]
		[batch 20/20] avg loss: 0.36698282609189503		[learning rate: 0.0043241]
	Learning Rate: 0.00432409
	LOSS [training: 0.2938128070187231 | validation: 0.2228361826550213]
	TIME [epoch: 8.34 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2666707849248904		[learning rate: 0.0043136]
		[batch 20/20] avg loss: 3.803254259296331		[learning rate: 0.0043032]
	Learning Rate: 0.00430318
	LOSS [training: 2.534962522110611 | validation: 1.9120938846683726]
	TIME [epoch: 8.33 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.8681579410479117		[learning rate: 0.0042928]
		[batch 20/20] avg loss: 4.366279165902322		[learning rate: 0.0042824]
	Learning Rate: 0.00428237
	LOSS [training: 4.117218553475118 | validation: 4.098954217096738]
	TIME [epoch: 8.32 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/20] avg loss: 5.186772529757077		[learning rate: 0.004272]
		[batch 20/20] avg loss: 3.9311534566299073		[learning rate: 0.0042617]
	Learning Rate: 0.00426166
	LOSS [training: 4.558962993193493 | validation: 1.6085865686326462]
	TIME [epoch: 8.32 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/20] avg loss: 4.125257808113998		[learning rate: 0.0042513]
		[batch 20/20] avg loss: 3.7998053122206388		[learning rate: 0.0042411]
	Learning Rate: 0.00424105
	LOSS [training: 3.9625315601673194 | validation: 1.4564615115328565]
	TIME [epoch: 8.35 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.493308015711251		[learning rate: 0.0042308]
		[batch 20/20] avg loss: 1.212554238118552		[learning rate: 0.0042205]
	Learning Rate: 0.00422054
	LOSS [training: 1.852931126914901 | validation: 0.7009015107124982]
	TIME [epoch: 8.32 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1871470099011476		[learning rate: 0.0042103]
		[batch 20/20] avg loss: 1.0040230800199101		[learning rate: 0.0042001]
	Learning Rate: 0.00420013
	LOSS [training: 1.0955850449605289 | validation: 0.5316113990657185]
	TIME [epoch: 8.32 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.891730944568667		[learning rate: 0.00419]
		[batch 20/20] avg loss: 0.7312918691341117		[learning rate: 0.0041798]
	Learning Rate: 0.00417982
	LOSS [training: 0.8115114068513893 | validation: 0.3379247613739059]
	TIME [epoch: 8.32 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8758966359916972		[learning rate: 0.0041697]
		[batch 20/20] avg loss: 0.6740889036643243		[learning rate: 0.0041596]
	Learning Rate: 0.00415961
	LOSS [training: 0.7749927698280107 | validation: 0.2836420978383989]
	TIME [epoch: 8.35 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7526903759733627		[learning rate: 0.0041495]
		[batch 20/20] avg loss: 0.6109899626441222		[learning rate: 0.0041395]
	Learning Rate: 0.0041395
	LOSS [training: 0.6818401693087425 | validation: 0.4355322854018664]
	TIME [epoch: 8.33 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5418989155969859		[learning rate: 0.0041295]
		[batch 20/20] avg loss: 0.42831779467235187		[learning rate: 0.0041195]
	Learning Rate: 0.00411948
	LOSS [training: 0.4851083551346688 | validation: 0.38053752201622787]
	TIME [epoch: 8.32 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5931189524509245		[learning rate: 0.0041095]
		[batch 20/20] avg loss: 0.5469525719203254		[learning rate: 0.0040996]
	Learning Rate: 0.00409956
	LOSS [training: 0.570035762185625 | validation: 0.2775901312652277]
	TIME [epoch: 8.33 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.48481479090264246		[learning rate: 0.0040896]
		[batch 20/20] avg loss: 0.4070640046944106		[learning rate: 0.0040797]
	Learning Rate: 0.00407973
	LOSS [training: 0.44593939779852654 | validation: 0.18658789605773826]
	TIME [epoch: 8.35 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.42095364285468345		[learning rate: 0.0040699]
		[batch 20/20] avg loss: 0.44821074988278975		[learning rate: 0.00406]
	Learning Rate: 0.00406
	LOSS [training: 0.4345821963687365 | validation: 0.44307232232874316]
	TIME [epoch: 8.33 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.790044914763102		[learning rate: 0.0040502]
		[batch 20/20] avg loss: 2.8918196579977624		[learning rate: 0.0040404]
	Learning Rate: 0.00404037
	LOSS [training: 2.3409322863804327 | validation: 1.2127363798721646]
	TIME [epoch: 8.32 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.2057842503855176		[learning rate: 0.0040306]
		[batch 20/20] avg loss: 3.969128451833325		[learning rate: 0.0040208]
	Learning Rate: 0.00402083
	LOSS [training: 3.587456351109421 | validation: 2.877935716756847]
	TIME [epoch: 8.32 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/20] avg loss: 5.304811795697871		[learning rate: 0.0040111]
		[batch 20/20] avg loss: 5.215698220247446		[learning rate: 0.0040014]
	Learning Rate: 0.00400139
	LOSS [training: 5.260255007972658 | validation: 4.881509858028212]
	TIME [epoch: 8.34 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/20] avg loss: 5.827157655274808		[learning rate: 0.0039917]
		[batch 20/20] avg loss: nan		[learning rate: 0.003982]
ERROR:
nan encountered in epoch 239 (training loss).
