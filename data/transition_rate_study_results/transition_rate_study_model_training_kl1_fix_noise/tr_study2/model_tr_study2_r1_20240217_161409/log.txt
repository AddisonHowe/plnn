Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r1', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 709225016

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/20] avg loss: 8.42843859254467		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.980755745576327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.704597169060499 | validation: 6.146139116089435]
	TIME [epoch: 76.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/20] avg loss: 5.895743539185371		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.42117314615585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6584583426706105 | validation: 5.191707453939199]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/20] avg loss: 5.203597662151741		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.318729708135839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.761163685143791 | validation: 3.996172647442124]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.8479752944984353		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.4288031112856117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.638389202892024 | validation: 3.9006963268543107]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.926023371808357		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.769764173079353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8478937724438547 | validation: 2.4583949654986457]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.3115885671213228		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.020629317512559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.166108942316941 | validation: 1.65627395511292]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.161508872539321		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6926930398511302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9271009561952255 | validation: 2.612062704571234]
	TIME [epoch: 8.3 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.7375337554753352		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5756854191916885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6566095873335116 | validation: 1.4114725923756262]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5699278978291846		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.9413944167990447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7556611573141148 | validation: 2.9930772822157046]
	TIME [epoch: 8.32 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4238706275555777		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.329756567821552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.376813597688565 | validation: 2.3431592165698216]
	TIME [epoch: 8.28 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4810724853872475		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.586558041597509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5338152634923783 | validation: 2.2996958360274826]
	TIME [epoch: 8.29 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3177867357024005		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.070002026796621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1938943812495109 | validation: 1.6635714143040157]
	TIME [epoch: 8.28 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.221061639482017		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9270566651743645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0740591523281908 | validation: 0.6333202326935626]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8041030111742277		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7278644829334616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7659837470538446 | validation: 0.780261839736253]
	TIME [epoch: 8.3 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7690554497645288		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7249806771318991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7470180634482139 | validation: 0.919605431805582]
	TIME [epoch: 8.29 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1439585256023037		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8024626132867935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9732105694445486 | validation: 0.5888669117791134]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1921451599620425		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.1471894269589258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.169667293460484 | validation: 0.37290085173955556]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6452430754678663		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7460610701362945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6956520728020802 | validation: 0.44358483340919846]
	TIME [epoch: 8.3 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6285635302579344		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7107891322860032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6696763312719687 | validation: 0.3867957374328454]
	TIME [epoch: 8.28 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7007203996709974		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6192689552706396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6599946774708186 | validation: 0.27608845736495224]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6511116662059105		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6176404420164315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.634376054111171 | validation: 0.7693207719566408]
	TIME [epoch: 8.32 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7732719292106651		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6669471848711415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7201095570409033 | validation: 0.9567777525116554]
	TIME [epoch: 8.27 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7548036055491396		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.652219758790071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7035116821696052 | validation: 0.5647658325179021]
	TIME [epoch: 8.28 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5959328781991406		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5670657736017968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5814993259004687 | validation: 1.0924052710937258]
	TIME [epoch: 8.28 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7631410577880434		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8545767597554221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8088589087717327 | validation: 0.3807034029280114]
	TIME [epoch: 8.31 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6698254901351409		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7231518803778322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6964886852564864 | validation: 0.46265844845711956]
	TIME [epoch: 8.29 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5944996042762476		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6160572753749987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6052784398256231 | validation: 0.8607699303276425]
	TIME [epoch: 8.29 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6105673053696218		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5954776629749958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6030224841723089 | validation: 0.4500966891475954]
	TIME [epoch: 8.28 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5074763435671605		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5896243600226928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5485503517949266 | validation: 1.1919449611912984]
	TIME [epoch: 8.32 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6263458233337948		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5254885004468568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5759171618903258 | validation: 0.6312349376135301]
	TIME [epoch: 8.28 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5281994094732125		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6702874069110553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5992434081921341 | validation: 0.5284602544190713]
	TIME [epoch: 8.28 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8502398734481785		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.500659114879179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6754494941636787 | validation: 0.7782038225361299]
	TIME [epoch: 8.29 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.566239064106622		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6287744530614955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5975067585840587 | validation: 0.8282229230405231]
	TIME [epoch: 8.31 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.593741842452234		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7062956326153251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6500187375337796 | validation: 0.5768628636841971]
	TIME [epoch: 8.28 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.513341149865728		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.614418910553058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5638800302093929 | validation: 0.40072179636068567]
	TIME [epoch: 8.27 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5409399833728479		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5679813937956134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5544606885842306 | validation: 0.708247346981872]
	TIME [epoch: 8.32 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6974501958403271		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6741891119955945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.685819653917961 | validation: 0.47105150909956084]
	TIME [epoch: 8.3 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5264550123260539		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5128143008120502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5196346565690521 | validation: 0.37395806137545]
	TIME [epoch: 8.28 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5832482278917459		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5795579025037999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.581403065197773 | validation: 0.4527034061280317]
	TIME [epoch: 8.28 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5911868721379439		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5494295928700268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5703082325039854 | validation: 0.5149092974110313]
	TIME [epoch: 8.28 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5176760172181657		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5566364551786271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5371562361983965 | validation: 0.7442780380365426]
	TIME [epoch: 8.31 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.48469300431840434		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5649154214946147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5248042129065096 | validation: 0.3209838516481758]
	TIME [epoch: 8.27 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.508065414334983		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.4937354735464585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5009004439407208 | validation: 1.1802362049246147]
	TIME [epoch: 8.27 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5643520905016134		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5618861176559306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.563119104078772 | validation: 0.5816983160117294]
	TIME [epoch: 8.27 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.49870185523166344		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.629802125798941		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5642519905153021 | validation: 0.32759805300585926]
	TIME [epoch: 8.31 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.46610097373247916		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.4697580067604695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46792949024647446 | validation: 0.46120933905633194]
	TIME [epoch: 8.28 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4490882934825654		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5867755074402466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.517931900461406 | validation: 1.0380361615854699]
	TIME [epoch: 8.28 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5267201490166996		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8218384917119647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.674279320364332 | validation: 0.5913233596912705]
	TIME [epoch: 8.29 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4367131326946649		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5342682471832969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48549068993898076 | validation: 0.6128351074285316]
	TIME [epoch: 8.31 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.48563652672147306		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5123223201086615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4989794234150673 | validation: 0.37833795730345177]
	TIME [epoch: 8.27 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5109575933435087		[learning rate: 0.0099782]
		[batch 20/20] avg loss: 0.7272441484368137		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 0.6191008708901611 | validation: 0.7703363964576058]
	TIME [epoch: 8.28 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.49642819956676787		[learning rate: 0.00993]
		[batch 20/20] avg loss: 0.5594211914811376		[learning rate: 0.0099059]
	Learning Rate: 0.00990592
	LOSS [training: 0.5279246955239526 | validation: 0.5584624064797287]
	TIME [epoch: 8.28 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4994479402365032		[learning rate: 0.0098819]
		[batch 20/20] avg loss: 0.5076524933602109		[learning rate: 0.009858]
	Learning Rate: 0.00985801
	LOSS [training: 0.503550216798357 | validation: 0.8314437539717985]
	TIME [epoch: 8.3 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6518090136752611		[learning rate: 0.0098341]
		[batch 20/20] avg loss: 0.4923784940185608		[learning rate: 0.0098103]
	Learning Rate: 0.00981034
	LOSS [training: 0.572093753846911 | validation: 0.44776404532938474]
	TIME [epoch: 8.28 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.45355702712722773		[learning rate: 0.0097866]
		[batch 20/20] avg loss: 0.5829847332151322		[learning rate: 0.0097629]
	Learning Rate: 0.0097629
	LOSS [training: 0.5182708801711801 | validation: 0.6819696783386316]
	TIME [epoch: 8.28 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5022597936948636		[learning rate: 0.0097393]
		[batch 20/20] avg loss: 0.5251569096543708		[learning rate: 0.0097157]
	Learning Rate: 0.00971569
	LOSS [training: 0.513708351674617 | validation: 0.4175221878173895]
	TIME [epoch: 8.28 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.45688119094308377		[learning rate: 0.0096922]
		[batch 20/20] avg loss: 0.7486580574073886		[learning rate: 0.0096687]
	Learning Rate: 0.00966871
	LOSS [training: 0.602769624175236 | validation: 0.3027043108590052]
	TIME [epoch: 8.31 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.49073087822848177		[learning rate: 0.0096453]
		[batch 20/20] avg loss: 0.5192416656915146		[learning rate: 0.009622]
	Learning Rate: 0.00962195
	LOSS [training: 0.5049862719599982 | validation: 0.3932630985551984]
	TIME [epoch: 8.28 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.46337327864102723		[learning rate: 0.0095987]
		[batch 20/20] avg loss: 0.6688232918716104		[learning rate: 0.0095754]
	Learning Rate: 0.00957542
	LOSS [training: 0.5660982852563188 | validation: 0.3955018372246484]
	TIME [epoch: 8.28 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6032159490944039		[learning rate: 0.0095522]
		[batch 20/20] avg loss: 0.4546820885038471		[learning rate: 0.0095291]
	Learning Rate: 0.00952912
	LOSS [training: 0.5289490187991256 | validation: 0.5034700133879539]
	TIME [epoch: 8.28 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.46666695312336587		[learning rate: 0.009506]
		[batch 20/20] avg loss: 0.4531627037209119		[learning rate: 0.009483]
	Learning Rate: 0.00948303
	LOSS [training: 0.4599148284221388 | validation: 0.33482135240330535]
	TIME [epoch: 8.3 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5063195999571949		[learning rate: 0.0094601]
		[batch 20/20] avg loss: 0.5256518881168031		[learning rate: 0.0094372]
	Learning Rate: 0.00943718
	LOSS [training: 0.515985744036999 | validation: 0.440914968316218]
	TIME [epoch: 8.28 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.567232446611942		[learning rate: 0.0094143]
		[batch 20/20] avg loss: 0.6222555034121687		[learning rate: 0.0093915]
	Learning Rate: 0.00939154
	LOSS [training: 0.5947439750120554 | validation: 0.6607609477211046]
	TIME [epoch: 8.27 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.43006828028924626		[learning rate: 0.0093688]
		[batch 20/20] avg loss: 0.49700684962844816		[learning rate: 0.0093461]
	Learning Rate: 0.00934612
	LOSS [training: 0.4635375649588472 | validation: 0.6534746464405682]
	TIME [epoch: 8.27 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4693359597890422		[learning rate: 0.0093235]
		[batch 20/20] avg loss: 0.5075232339940025		[learning rate: 0.0093009]
	Learning Rate: 0.00930093
	LOSS [training: 0.4884295968915223 | validation: 0.32626142477393205]
	TIME [epoch: 8.32 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.47086493693064135		[learning rate: 0.0092784]
		[batch 20/20] avg loss: 0.47319908548412987		[learning rate: 0.009256]
	Learning Rate: 0.00925595
	LOSS [training: 0.4720320112073856 | validation: 0.26713954417161434]
	TIME [epoch: 8.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_66.pth
	Model improved!!!
EPOCH 67/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6609180495686001		[learning rate: 0.0092335]
		[batch 20/20] avg loss: 0.5529761473712319		[learning rate: 0.0092112]
	Learning Rate: 0.00921119
	LOSS [training: 0.606947098469916 | validation: 0.2636079350669349]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_67.pth
	Model improved!!!
EPOCH 68/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7859454404204657		[learning rate: 0.0091889]
		[batch 20/20] avg loss: 0.6285633889767499		[learning rate: 0.0091666]
	Learning Rate: 0.00916665
	LOSS [training: 0.7072544146986078 | validation: 0.4771105419376246]
	TIME [epoch: 8.28 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4881691238231978		[learning rate: 0.0091445]
		[batch 20/20] avg loss: 0.4274889138802983		[learning rate: 0.0091223]
	Learning Rate: 0.00912232
	LOSS [training: 0.457829018851748 | validation: 0.3123895417432893]
	TIME [epoch: 8.31 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5698541565759613		[learning rate: 0.0091002]
		[batch 20/20] avg loss: 0.48984659137415953		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 0.5298503739750603 | validation: 0.2972918267110455]
	TIME [epoch: 8.3 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5034210115730617		[learning rate: 0.0090562]
		[batch 20/20] avg loss: 0.5418654228246824		[learning rate: 0.0090343]
	Learning Rate: 0.0090343
	LOSS [training: 0.522643217198872 | validation: 0.5584406889132267]
	TIME [epoch: 8.29 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.54976777037426		[learning rate: 0.0090124]
		[batch 20/20] avg loss: 0.4278553924408575		[learning rate: 0.0089906]
	Learning Rate: 0.00899062
	LOSS [training: 0.48881158140755865 | validation: 0.291643799777754]
	TIME [epoch: 8.3 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.566546560996245		[learning rate: 0.0089689]
		[batch 20/20] avg loss: 0.38213428613788986		[learning rate: 0.0089471]
	Learning Rate: 0.00894714
	LOSS [training: 0.4743404235670675 | validation: 0.45366254724459554]
	TIME [epoch: 8.31 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.40485136895139107		[learning rate: 0.0089255]
		[batch 20/20] avg loss: 0.6200536468760178		[learning rate: 0.0089039]
	Learning Rate: 0.00890387
	LOSS [training: 0.5124525079137046 | validation: 0.2778617021616234]
	TIME [epoch: 8.29 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4007688084179056		[learning rate: 0.0088823]
		[batch 20/20] avg loss: 0.44828154738336956		[learning rate: 0.0088608]
	Learning Rate: 0.00886082
	LOSS [training: 0.42452517790063754 | validation: 0.3292317557940417]
	TIME [epoch: 8.29 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.47402090595961344		[learning rate: 0.0088394]
		[batch 20/20] avg loss: 0.6384514968717566		[learning rate: 0.008818]
	Learning Rate: 0.00881797
	LOSS [training: 0.556236201415685 | validation: 0.3424607792860179]
	TIME [epoch: 8.3 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4192456121196185		[learning rate: 0.0087966]
		[batch 20/20] avg loss: 0.4149034603464564		[learning rate: 0.0087753]
	Learning Rate: 0.00877532
	LOSS [training: 0.4170745362330375 | validation: 0.6743571754178503]
	TIME [epoch: 8.32 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.41524696907109887		[learning rate: 0.0087541]
		[batch 20/20] avg loss: 0.4097589408907619		[learning rate: 0.0087329]
	Learning Rate: 0.00873289
	LOSS [training: 0.4125029549809304 | validation: 0.5419740453251054]
	TIME [epoch: 8.28 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.427359092368341		[learning rate: 0.0087117]
		[batch 20/20] avg loss: 0.917611384776037		[learning rate: 0.0086907]
	Learning Rate: 0.00869066
	LOSS [training: 0.6724852385721889 | validation: 0.4670100278415823]
	TIME [epoch: 8.3 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36482846343582154		[learning rate: 0.0086696]
		[batch 20/20] avg loss: 0.5065050907355715		[learning rate: 0.0086486]
	Learning Rate: 0.00864863
	LOSS [training: 0.43566677708569657 | validation: 0.278554069085145]
	TIME [epoch: 8.28 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.41880684379196065		[learning rate: 0.0086277]
		[batch 20/20] avg loss: 0.5475296225224089		[learning rate: 0.0086068]
	Learning Rate: 0.00860681
	LOSS [training: 0.4831682331571847 | validation: 0.4909999046482339]
	TIME [epoch: 8.31 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.43320726106954976		[learning rate: 0.008586]
		[batch 20/20] avg loss: 0.4545452377791802		[learning rate: 0.0085652]
	Learning Rate: 0.00856519
	LOSS [training: 0.4438762494243651 | validation: 0.3568048682576397]
	TIME [epoch: 8.29 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.47278327627742484		[learning rate: 0.0085445]
		[batch 20/20] avg loss: 0.473168515418139		[learning rate: 0.0085238]
	Learning Rate: 0.00852377
	LOSS [training: 0.4729758958477818 | validation: 0.28677551946621094]
	TIME [epoch: 8.28 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.41195875533669446		[learning rate: 0.0085031]
		[batch 20/20] avg loss: 0.44591138715662326		[learning rate: 0.0084825]
	Learning Rate: 0.00848255
	LOSS [training: 0.42893507124665886 | validation: 0.27317556589776315]
	TIME [epoch: 8.57 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3504810079571451		[learning rate: 0.008462]
		[batch 20/20] avg loss: 0.4376681212094593		[learning rate: 0.0084415]
	Learning Rate: 0.00844153
	LOSS [training: 0.3940745645833022 | validation: 0.2582992595633045]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_85.pth
	Model improved!!!
EPOCH 86/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4569140172718672		[learning rate: 0.0084211]
		[batch 20/20] avg loss: 0.43132255534646113		[learning rate: 0.0084007]
	Learning Rate: 0.00840071
	LOSS [training: 0.4441182863091642 | validation: 0.3103862819747207]
	TIME [epoch: 8.3 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3252585382105272		[learning rate: 0.0083804]
		[batch 20/20] avg loss: 0.3965730086867385		[learning rate: 0.0083601]
	Learning Rate: 0.00836008
	LOSS [training: 0.36091577344863274 | validation: 0.2660894444767278]
	TIME [epoch: 8.29 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3720128250185335		[learning rate: 0.0083398]
		[batch 20/20] avg loss: 0.3618437945839933		[learning rate: 0.0083197]
	Learning Rate: 0.00831965
	LOSS [training: 0.36692830980126334 | validation: 0.19596618101948454]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_88.pth
	Model improved!!!
EPOCH 89/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.38834670839318847		[learning rate: 0.0082995]
		[batch 20/20] avg loss: 0.4624718290873946		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 0.4254092687402916 | validation: 0.1938144708364435]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_89.pth
	Model improved!!!
EPOCH 90/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3832431464948502		[learning rate: 0.0082594]
		[batch 20/20] avg loss: 0.5832780214120243		[learning rate: 0.0082394]
	Learning Rate: 0.00823938
	LOSS [training: 0.4832605839534373 | validation: 0.3285944449283141]
	TIME [epoch: 8.31 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.38769733108744536		[learning rate: 0.0082194]
		[batch 20/20] avg loss: 0.3829944207358943		[learning rate: 0.0081995]
	Learning Rate: 0.00819954
	LOSS [training: 0.38534587591166974 | validation: 0.5793231900355786]
	TIME [epoch: 8.29 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.41443054893165454		[learning rate: 0.0081797]
		[batch 20/20] avg loss: 0.33366156060881175		[learning rate: 0.0081599]
	Learning Rate: 0.00815989
	LOSS [training: 0.3740460547702331 | validation: 0.37507395046452197]
	TIME [epoch: 8.3 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.48136911515124564		[learning rate: 0.0081401]
		[batch 20/20] avg loss: 0.35048559848204897		[learning rate: 0.0081204]
	Learning Rate: 0.00812043
	LOSS [training: 0.4159273568166473 | validation: 0.32207534489151507]
	TIME [epoch: 8.32 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3216954572549463		[learning rate: 0.0081008]
		[batch 20/20] avg loss: 0.471166255731711		[learning rate: 0.0080812]
	Learning Rate: 0.00808116
	LOSS [training: 0.39643085649332865 | validation: 1.058236823509939]
	TIME [epoch: 8.29 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4403660059197597		[learning rate: 0.0080616]
		[batch 20/20] avg loss: 0.354962638860601		[learning rate: 0.0080421]
	Learning Rate: 0.00804208
	LOSS [training: 0.3976643223901803 | validation: 0.6196961825993312]
	TIME [epoch: 8.3 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3693142830021651		[learning rate: 0.0080226]
		[batch 20/20] avg loss: 0.3092138347894428		[learning rate: 0.0080032]
	Learning Rate: 0.00800319
	LOSS [training: 0.33926405889580397 | validation: 0.5029526709679429]
	TIME [epoch: 8.29 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5554570334705755		[learning rate: 0.0079838]
		[batch 20/20] avg loss: 0.45542778243576015		[learning rate: 0.0079645]
	Learning Rate: 0.00796449
	LOSS [training: 0.5054424079531679 | validation: 0.25126270299381626]
	TIME [epoch: 8.32 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.294801302470039		[learning rate: 0.0079452]
		[batch 20/20] avg loss: 0.40775804286282824		[learning rate: 0.007926]
	Learning Rate: 0.00792597
	LOSS [training: 0.3512796726664337 | validation: 0.35155618516717724]
	TIME [epoch: 8.3 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.33365339357611623		[learning rate: 0.0079068]
		[batch 20/20] avg loss: 0.5132256574620334		[learning rate: 0.0078876]
	Learning Rate: 0.00788765
	LOSS [training: 0.4234395255190749 | validation: 0.4890984767215429]
	TIME [epoch: 8.3 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4591855430821873		[learning rate: 0.0078685]
		[batch 20/20] avg loss: 0.32831008430949626		[learning rate: 0.0078495]
	Learning Rate: 0.0078495
	LOSS [training: 0.39374781369584183 | validation: 0.6959127632553833]
	TIME [epoch: 8.29 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4149201589468546		[learning rate: 0.0078305]
		[batch 20/20] avg loss: 0.3552497557430251		[learning rate: 0.0078115]
	Learning Rate: 0.00781154
	LOSS [training: 0.38508495734493986 | validation: 0.6613026132754658]
	TIME [epoch: 8.32 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3285082184207616		[learning rate: 0.0077926]
		[batch 20/20] avg loss: 0.3846468884326196		[learning rate: 0.0077738]
	Learning Rate: 0.00777377
	LOSS [training: 0.3565775534266906 | validation: 0.2340157639752138]
	TIME [epoch: 8.29 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28835686756460616		[learning rate: 0.0077549]
		[batch 20/20] avg loss: 0.3600559556310501		[learning rate: 0.0077362]
	Learning Rate: 0.00773618
	LOSS [training: 0.32420641159782815 | validation: 0.2693681406944924]
	TIME [epoch: 8.29 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3372527744105064		[learning rate: 0.0077174]
		[batch 20/20] avg loss: 0.37769996580369886		[learning rate: 0.0076988]
	Learning Rate: 0.00769876
	LOSS [training: 0.3574763701071027 | validation: 0.2988016597141161]
	TIME [epoch: 8.29 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3009696252982056		[learning rate: 0.0076801]
		[batch 20/20] avg loss: 0.3503289235201571		[learning rate: 0.0076615]
	Learning Rate: 0.00766153
	LOSS [training: 0.3256492744091813 | validation: 0.28690439409959545]
	TIME [epoch: 8.31 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4842823530446962		[learning rate: 0.007643]
		[batch 20/20] avg loss: 0.32148537797585314		[learning rate: 0.0076245]
	Learning Rate: 0.00762449
	LOSS [training: 0.40288386551027455 | validation: 0.24875571369626862]
	TIME [epoch: 8.29 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.34163318692697586		[learning rate: 0.007606]
		[batch 20/20] avg loss: 0.2894276564954315		[learning rate: 0.0075876]
	Learning Rate: 0.00758761
	LOSS [training: 0.3155304217112037 | validation: 0.3029465487651831]
	TIME [epoch: 8.29 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.43894391761584367		[learning rate: 0.0075692]
		[batch 20/20] avg loss: 0.29822185108104127		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 0.36858288434844255 | validation: 0.3738712241220743]
	TIME [epoch: 8.3 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3258051467776381		[learning rate: 0.0075326]
		[batch 20/20] avg loss: 0.3195284629760819		[learning rate: 0.0075144]
	Learning Rate: 0.00751441
	LOSS [training: 0.32266680487686 | validation: 0.2243151098127224]
	TIME [epoch: 8.32 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2832656521276727		[learning rate: 0.0074962]
		[batch 20/20] avg loss: 0.35608158153291125		[learning rate: 0.0074781]
	Learning Rate: 0.00747807
	LOSS [training: 0.31967361683029194 | validation: 0.6434427156678394]
	TIME [epoch: 8.3 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2785368810075407		[learning rate: 0.00746]
		[batch 20/20] avg loss: 0.24655787264532153		[learning rate: 0.0074419]
	Learning Rate: 0.00744191
	LOSS [training: 0.26254737682643114 | validation: 0.18042531341441062]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_111.pth
	Model improved!!!
EPOCH 112/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2783387457997419		[learning rate: 0.0074239]
		[batch 20/20] avg loss: 0.28828602376289697		[learning rate: 0.0074059]
	Learning Rate: 0.00740592
	LOSS [training: 0.2833123847813194 | validation: 0.20305495022580133]
	TIME [epoch: 8.29 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.32106249675853743		[learning rate: 0.007388]
		[batch 20/20] avg loss: 0.22512452234048314		[learning rate: 0.0073701]
	Learning Rate: 0.00737011
	LOSS [training: 0.27309350954951017 | validation: 0.2435893416820456]
	TIME [epoch: 8.31 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27808486794143245		[learning rate: 0.0073523]
		[batch 20/20] avg loss: 0.2976269962170984		[learning rate: 0.0073345]
	Learning Rate: 0.00733446
	LOSS [training: 0.28785593207926546 | validation: 0.12098695362591008]
	TIME [epoch: 8.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_114.pth
	Model improved!!!
EPOCH 115/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2530991551161005		[learning rate: 0.0073167]
		[batch 20/20] avg loss: 0.30090761111194936		[learning rate: 0.007299]
	Learning Rate: 0.007299
	LOSS [training: 0.27700338311402495 | validation: 0.14759317421255025]
	TIME [epoch: 8.29 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3671139322647983		[learning rate: 0.0072813]
		[batch 20/20] avg loss: 0.2949518021914575		[learning rate: 0.0072637]
	Learning Rate: 0.0072637
	LOSS [training: 0.33103286722812786 | validation: 0.32672302129921427]
	TIME [epoch: 8.28 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24275159366688276		[learning rate: 0.0072461]
		[batch 20/20] avg loss: 0.31681512214094504		[learning rate: 0.0072286]
	Learning Rate: 0.00722857
	LOSS [training: 0.2797833579039139 | validation: 0.1845483882305776]
	TIME [epoch: 8.31 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2902998135285023		[learning rate: 0.0072111]
		[batch 20/20] avg loss: 0.19520411623121398		[learning rate: 0.0071936]
	Learning Rate: 0.00719362
	LOSS [training: 0.24275196487985812 | validation: 0.20068907150411874]
	TIME [epoch: 8.29 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27739614313352584		[learning rate: 0.0071762]
		[batch 20/20] avg loss: 0.23484635466652143		[learning rate: 0.0071588]
	Learning Rate: 0.00715883
	LOSS [training: 0.25612124890002363 | validation: 0.45191535037812997]
	TIME [epoch: 8.28 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2599000260453833		[learning rate: 0.0071415]
		[batch 20/20] avg loss: 0.277264565997155		[learning rate: 0.0071242]
	Learning Rate: 0.00712421
	LOSS [training: 0.2685822960212692 | validation: 0.17823256537946364]
	TIME [epoch: 8.28 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23199625059137544		[learning rate: 0.007107]
		[batch 20/20] avg loss: 0.31478709685675127		[learning rate: 0.0070898]
	Learning Rate: 0.00708976
	LOSS [training: 0.27339167372406337 | validation: 0.21790208697111907]
	TIME [epoch: 8.31 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.305939151175715		[learning rate: 0.0070726]
		[batch 20/20] avg loss: 0.2928008717446023		[learning rate: 0.0070555]
	Learning Rate: 0.00705548
	LOSS [training: 0.2993700114601586 | validation: 0.24540533566233344]
	TIME [epoch: 8.29 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2354473980437215		[learning rate: 0.0070384]
		[batch 20/20] avg loss: 0.3154457244680874		[learning rate: 0.0070214]
	Learning Rate: 0.00702136
	LOSS [training: 0.2754465612559044 | validation: 0.2873358112326121]
	TIME [epoch: 8.29 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2373375625292677		[learning rate: 0.0070044]
		[batch 20/20] avg loss: 0.26094184271472254		[learning rate: 0.0069874]
	Learning Rate: 0.0069874
	LOSS [training: 0.2491397026219951 | validation: 0.203255832980197]
	TIME [epoch: 8.29 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26303136723992704		[learning rate: 0.0069705]
		[batch 20/20] avg loss: 0.2184552342986199		[learning rate: 0.0069536]
	Learning Rate: 0.00695361
	LOSS [training: 0.24074330076927347 | validation: 0.6799421025271002]
	TIME [epoch: 8.31 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3277641284951557		[learning rate: 0.0069368]
		[batch 20/20] avg loss: 0.19650944533961606		[learning rate: 0.00692]
	Learning Rate: 0.00691999
	LOSS [training: 0.2621367869173859 | validation: 0.33153934617910324]
	TIME [epoch: 8.29 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29330559452638627		[learning rate: 0.0069032]
		[batch 20/20] avg loss: 0.4262750694960106		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 0.3597903320111985 | validation: 0.9198101343759972]
	TIME [epoch: 8.28 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3225143976353977		[learning rate: 0.0068699]
		[batch 20/20] avg loss: 0.29463389878602053		[learning rate: 0.0068532]
	Learning Rate: 0.00685322
	LOSS [training: 0.30857414821070905 | validation: 0.12276122596952302]
	TIME [epoch: 8.28 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23571421313016364		[learning rate: 0.0068366]
		[batch 20/20] avg loss: 0.21860261236719808		[learning rate: 0.0068201]
	Learning Rate: 0.00682008
	LOSS [training: 0.22715841274868084 | validation: 0.09722391192767521]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_129.pth
	Model improved!!!
EPOCH 130/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36183339897964295		[learning rate: 0.0068036]
		[batch 20/20] avg loss: 0.2867092971394193		[learning rate: 0.0067871]
	Learning Rate: 0.0067871
	LOSS [training: 0.32427134805953106 | validation: 0.2208529675996998]
	TIME [epoch: 8.29 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2721462259424885		[learning rate: 0.0067707]
		[batch 20/20] avg loss: 0.17370843823626433		[learning rate: 0.0067543]
	Learning Rate: 0.00675428
	LOSS [training: 0.2229273320893764 | validation: 0.4972783359745019]
	TIME [epoch: 8.29 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.272125764357955		[learning rate: 0.0067379]
		[batch 20/20] avg loss: 0.2578882227799942		[learning rate: 0.0067216]
	Learning Rate: 0.00672162
	LOSS [training: 0.2650069935689746 | validation: 0.6010682352550003]
	TIME [epoch: 8.29 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25419303413949146		[learning rate: 0.0067053]
		[batch 20/20] avg loss: 0.23218300272288284		[learning rate: 0.0066891]
	Learning Rate: 0.00668911
	LOSS [training: 0.24318801843118712 | validation: 0.17816186139891468]
	TIME [epoch: 8.31 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2623904669342081		[learning rate: 0.0066729]
		[batch 20/20] avg loss: 0.22686056360896956		[learning rate: 0.0066568]
	Learning Rate: 0.00665676
	LOSS [training: 0.24462551527158874 | validation: 0.1256685598934664]
	TIME [epoch: 8.29 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36267882914082505		[learning rate: 0.0066406]
		[batch 20/20] avg loss: 0.26051205848799963		[learning rate: 0.0066246]
	Learning Rate: 0.00662457
	LOSS [training: 0.31159544381441245 | validation: 0.2563720882698]
	TIME [epoch: 8.29 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22426692007949595		[learning rate: 0.0066085]
		[batch 20/20] avg loss: 0.21700598590595893		[learning rate: 0.0065925]
	Learning Rate: 0.00659254
	LOSS [training: 0.22063645299272747 | validation: 0.22753842242760475]
	TIME [epoch: 8.29 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2912614707959661		[learning rate: 0.0065766]
		[batch 20/20] avg loss: 0.28417853794815795		[learning rate: 0.0065607]
	Learning Rate: 0.00656066
	LOSS [training: 0.28772000437206197 | validation: 0.25400212547320766]
	TIME [epoch: 8.31 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18229537630565915		[learning rate: 0.0065448]
		[batch 20/20] avg loss: 0.3253422676910637		[learning rate: 0.0065289]
	Learning Rate: 0.00652893
	LOSS [training: 0.2538188219983614 | validation: 0.43894199818083285]
	TIME [epoch: 8.29 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36877777891973657		[learning rate: 0.0065131]
		[batch 20/20] avg loss: 0.2742721272121448		[learning rate: 0.0064974]
	Learning Rate: 0.00649736
	LOSS [training: 0.32152495306594064 | validation: 0.4133294927067196]
	TIME [epoch: 8.28 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28495153054608946		[learning rate: 0.0064816]
		[batch 20/20] avg loss: 0.18544044625333272		[learning rate: 0.0064659]
	Learning Rate: 0.00646594
	LOSS [training: 0.23519598839971115 | validation: 0.2480932157991828]
	TIME [epoch: 8.28 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2527774892650948		[learning rate: 0.0064503]
		[batch 20/20] avg loss: 0.28897214216009554		[learning rate: 0.0064347]
	Learning Rate: 0.00643467
	LOSS [training: 0.2708748157125952 | validation: 0.3227229819399306]
	TIME [epoch: 8.31 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27068421089142913		[learning rate: 0.0064191]
		[batch 20/20] avg loss: 0.21634404771586815		[learning rate: 0.0064036]
	Learning Rate: 0.00640355
	LOSS [training: 0.2435141293036486 | validation: 0.19930199852814143]
	TIME [epoch: 8.29 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17739962795659125		[learning rate: 0.0063881]
		[batch 20/20] avg loss: 0.23471939553734017		[learning rate: 0.0063726]
	Learning Rate: 0.00637259
	LOSS [training: 0.20605951174696568 | validation: 0.3656327581317458]
	TIME [epoch: 8.28 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25572380965492203		[learning rate: 0.0063572]
		[batch 20/20] avg loss: 0.27061403871019607		[learning rate: 0.0063418]
	Learning Rate: 0.00634177
	LOSS [training: 0.2631689241825591 | validation: 0.11986587211327321]
	TIME [epoch: 8.28 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22215562560217092		[learning rate: 0.0063264]
		[batch 20/20] avg loss: 0.24330256463188915		[learning rate: 0.0063111]
	Learning Rate: 0.0063111
	LOSS [training: 0.23272909511703005 | validation: 0.18703637824292374]
	TIME [epoch: 8.31 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4191623577365765		[learning rate: 0.0062958]
		[batch 20/20] avg loss: 0.22537910286713028		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 0.3222707303018534 | validation: 0.15249775497071066]
	TIME [epoch: 8.28 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18948527141906982		[learning rate: 0.0062654]
		[batch 20/20] avg loss: 0.3059388021803095		[learning rate: 0.0062502]
	Learning Rate: 0.00625021
	LOSS [training: 0.24771203679968973 | validation: 0.9025650120843633]
	TIME [epoch: 8.28 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3007515418137766		[learning rate: 0.0062351]
		[batch 20/20] avg loss: 0.329018582729928		[learning rate: 0.00622]
	Learning Rate: 0.00621999
	LOSS [training: 0.31488506227185226 | validation: 0.35214682659189617]
	TIME [epoch: 8.28 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28820758963048376		[learning rate: 0.0062049]
		[batch 20/20] avg loss: 0.29123737582990483		[learning rate: 0.0061899]
	Learning Rate: 0.00618991
	LOSS [training: 0.2897224827301943 | validation: 0.15800809306330552]
	TIME [epoch: 8.31 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.44402909021217274		[learning rate: 0.0061749]
		[batch 20/20] avg loss: 0.2153481272021108		[learning rate: 0.00616]
	Learning Rate: 0.00615997
	LOSS [training: 0.3296886087071419 | validation: 0.09437172345850622]
	TIME [epoch: 8.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_150.pth
	Model improved!!!
EPOCH 151/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22363653510143272		[learning rate: 0.0061451]
		[batch 20/20] avg loss: 0.33907127561004957		[learning rate: 0.0061302]
	Learning Rate: 0.00613019
	LOSS [training: 0.2813539053557411 | validation: 0.1472912864465098]
	TIME [epoch: 8.28 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2904331258517131		[learning rate: 0.0061153]
		[batch 20/20] avg loss: 0.3027034235254494		[learning rate: 0.0061005]
	Learning Rate: 0.00610054
	LOSS [training: 0.29656827468858127 | validation: 0.45406066982973586]
	TIME [epoch: 8.27 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3498228692274835		[learning rate: 0.0060858]
		[batch 20/20] avg loss: 0.21946687092575434		[learning rate: 0.006071]
	Learning Rate: 0.00607104
	LOSS [training: 0.2846448700766189 | validation: 0.14777417356835848]
	TIME [epoch: 8.31 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20896512790845004		[learning rate: 0.0060563]
		[batch 20/20] avg loss: 0.2503294919097175		[learning rate: 0.0060417]
	Learning Rate: 0.00604168
	LOSS [training: 0.22964730990908372 | validation: 0.21172329139284404]
	TIME [epoch: 8.27 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29977857184389245		[learning rate: 0.0060271]
		[batch 20/20] avg loss: 0.2506300101481655		[learning rate: 0.0060125]
	Learning Rate: 0.00601247
	LOSS [training: 0.27520429099602906 | validation: 0.1566387025675834]
	TIME [epoch: 8.27 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.37816161429680845		[learning rate: 0.0059979]
		[batch 20/20] avg loss: 0.25242183613341423		[learning rate: 0.0059834]
	Learning Rate: 0.00598339
	LOSS [training: 0.3152917252151113 | validation: 0.10880716569890153]
	TIME [epoch: 8.29 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2213897302425417		[learning rate: 0.0059689]
		[batch 20/20] avg loss: 0.30474970896232784		[learning rate: 0.0059545]
	Learning Rate: 0.00595446
	LOSS [training: 0.26306971960243475 | validation: 0.09266498998832082]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_157.pth
	Model improved!!!
EPOCH 158/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20633446647569179		[learning rate: 0.00594]
		[batch 20/20] avg loss: 0.23908906977421066		[learning rate: 0.0059257]
	Learning Rate: 0.00592566
	LOSS [training: 0.22271176812495122 | validation: 0.9324852915553674]
	TIME [epoch: 8.3 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3385561277977872		[learning rate: 0.0059113]
		[batch 20/20] avg loss: 0.21579956070007372		[learning rate: 0.005897]
	Learning Rate: 0.00589701
	LOSS [training: 0.2771778442489305 | validation: 0.09098532466754988]
	TIME [epoch: 8.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_159.pth
	Model improved!!!
EPOCH 160/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.33989294560209415		[learning rate: 0.0058827]
		[batch 20/20] avg loss: 0.16035530674936288		[learning rate: 0.0058685]
	Learning Rate: 0.00586849
	LOSS [training: 0.25012412617572843 | validation: 0.1577079645645493]
	TIME [epoch: 8.28 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21697667204817267		[learning rate: 0.0058543]
		[batch 20/20] avg loss: 0.277986501646686		[learning rate: 0.0058401]
	Learning Rate: 0.00584011
	LOSS [training: 0.24748158684742932 | validation: 0.1804664298759243]
	TIME [epoch: 8.31 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27707324004073397		[learning rate: 0.005826]
		[batch 20/20] avg loss: 0.28281480377794266		[learning rate: 0.0058119]
	Learning Rate: 0.00581187
	LOSS [training: 0.27994402190933826 | validation: 0.24777138205298205]
	TIME [epoch: 8.29 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2497380921126838		[learning rate: 0.0057978]
		[batch 20/20] avg loss: 0.24415720840951435		[learning rate: 0.0057838]
	Learning Rate: 0.00578376
	LOSS [training: 0.24694765026109908 | validation: 0.08922557264335378]
	TIME [epoch: 8.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_163.pth
	Model improved!!!
EPOCH 164/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18213230128039667		[learning rate: 0.0057698]
		[batch 20/20] avg loss: 0.2376059994364667		[learning rate: 0.0057558]
	Learning Rate: 0.00575579
	LOSS [training: 0.2098691503584317 | validation: 0.07920819368824503]
	TIME [epoch: 8.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study2/model_tr_study2_r1_20240217_161409/states/model_tr_study2_164.pth
	Model improved!!!
EPOCH 165/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.31853712822553204		[learning rate: 0.0057419]
		[batch 20/20] avg loss: 0.2513169989828329		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 0.2849270636041825 | validation: 0.13609227310785602]
	TIME [epoch: 8.32 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3001004783252121		[learning rate: 0.0057141]
		[batch 20/20] avg loss: 0.37998624802909486		[learning rate: 0.0057003]
	Learning Rate: 0.00570026
	LOSS [training: 0.34004336317715345 | validation: 1.954487123153575]
	TIME [epoch: 8.28 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4604711797323423		[learning rate: 0.0056865]
		[batch 20/20] avg loss: 0.4628175268902952		[learning rate: 0.0056727]
	Learning Rate: 0.0056727
	LOSS [training: 0.4616443533113187 | validation: 0.25417650648820583]
	TIME [epoch: 8.28 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25643068392086305		[learning rate: 0.005659]
		[batch 20/20] avg loss: 0.24274619509019998		[learning rate: 0.0056453]
	Learning Rate: 0.00564526
	LOSS [training: 0.2495884395055315 | validation: 0.24940996523150996]
	TIME [epoch: 8.28 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28659141648309505		[learning rate: 0.0056316]
		[batch 20/20] avg loss: 0.5077096208821402		[learning rate: 0.005618]
	Learning Rate: 0.00561796
	LOSS [training: 0.3971505186826175 | validation: 0.129662084692561]
	TIME [epoch: 8.3 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4389036598269471		[learning rate: 0.0056044]
		[batch 20/20] avg loss: 0.5476869299020002		[learning rate: 0.0055908]
	Learning Rate: 0.0055908
	LOSS [training: 0.49329529486447365 | validation: 0.29622072626272034]
	TIME [epoch: 8.28 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3107789644537834		[learning rate: 0.0055773]
		[batch 20/20] avg loss: 0.3837088619310373		[learning rate: 0.0055638]
	Learning Rate: 0.00556376
	LOSS [training: 0.3472439131924104 | validation: 0.32492581832809553]
	TIME [epoch: 8.28 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4231688172785245		[learning rate: 0.0055503]
		[batch 20/20] avg loss: 0.6426676301514745		[learning rate: 0.0055369]
	Learning Rate: 0.00553685
	LOSS [training: 0.5329182237149995 | validation: 0.7181123916277079]
	TIME [epoch: 8.28 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5583070660362578		[learning rate: 0.0055235]
		[batch 20/20] avg loss: 0.9968007288938836		[learning rate: 0.0055101]
	Learning Rate: 0.00551008
	LOSS [training: 0.7775538974650708 | validation: 0.7330213009662149]
	TIME [epoch: 8.31 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5662758932585986		[learning rate: 0.0054967]
		[batch 20/20] avg loss: 0.43735122142005267		[learning rate: 0.0054834]
	Learning Rate: 0.00548343
	LOSS [training: 0.5018135573393256 | validation: 0.30117398778475396]
	TIME [epoch: 8.29 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.49824187276788245		[learning rate: 0.0054702]
		[batch 20/20] avg loss: 0.3060616234975978		[learning rate: 0.0054569]
	Learning Rate: 0.00545692
	LOSS [training: 0.40215174813274013 | validation: 0.5210353799943951]
	TIME [epoch: 8.29 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.41787597715206626		[learning rate: 0.0054437]
		[batch 20/20] avg loss: 0.4424168752839976		[learning rate: 0.0054305]
	Learning Rate: 0.00543053
	LOSS [training: 0.43014642621803195 | validation: 0.2210619292021358]
	TIME [epoch: 8.29 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7769955232014335		[learning rate: 0.0054174]
		[batch 20/20] avg loss: 0.3558776972104497		[learning rate: 0.0054043]
	Learning Rate: 0.00540427
	LOSS [training: 0.5664366102059416 | validation: 0.490870592279113]
	TIME [epoch: 8.32 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.45248291412437813		[learning rate: 0.0053912]
		[batch 20/20] avg loss: 2.1464406293851144		[learning rate: 0.0053781]
	Learning Rate: 0.00537813
	LOSS [training: 1.2994617717547463 | validation: 0.3565955793951677]
	TIME [epoch: 8.29 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3738926130932327		[learning rate: 0.0053651]
		[batch 20/20] avg loss: 0.3272107410030989		[learning rate: 0.0053521]
	Learning Rate: 0.00535213
	LOSS [training: 0.3505516770481658 | validation: 0.25532577247364396]
	TIME [epoch: 8.29 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3771798021526092		[learning rate: 0.0053392]
		[batch 20/20] avg loss: 0.29776214305479415		[learning rate: 0.0053262]
	Learning Rate: 0.00532624
	LOSS [training: 0.3374709726037017 | validation: 0.18381660930467844]
	TIME [epoch: 8.29 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.33511026055167104		[learning rate: 0.0053133]
		[batch 20/20] avg loss: 0.35868863283893826		[learning rate: 0.0053005]
	Learning Rate: 0.00530049
	LOSS [training: 0.34689944669530465 | validation: 0.217975443579071]
	TIME [epoch: 8.31 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3933572828402637		[learning rate: 0.0052877]
		[batch 20/20] avg loss: 0.5328014002720145		[learning rate: 0.0052749]
	Learning Rate: 0.00527485
	LOSS [training: 0.46307934155613906 | validation: 0.4969249313918793]
	TIME [epoch: 8.29 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5398101586541001		[learning rate: 0.0052621]
		[batch 20/20] avg loss: 0.3074783199317498		[learning rate: 0.0052493]
	Learning Rate: 0.00524935
	LOSS [training: 0.42364423929292505 | validation: 0.37863599242851653]
	TIME [epoch: 8.29 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3617218039886443		[learning rate: 0.0052366]
		[batch 20/20] avg loss: 0.5311037447957092		[learning rate: 0.005224]
	Learning Rate: 0.00522396
	LOSS [training: 0.44641277439217675 | validation: 1.7450580441532328]
	TIME [epoch: 8.29 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6604116628011322		[learning rate: 0.0052113]
		[batch 20/20] avg loss: 0.3868132728028527		[learning rate: 0.0051987]
	Learning Rate: 0.0051987
	LOSS [training: 0.5236124678019923 | validation: 0.18697727362211433]
	TIME [epoch: 8.32 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30957369986367966		[learning rate: 0.0051861]
		[batch 20/20] avg loss: 1.161244581235716		[learning rate: 0.0051736]
	Learning Rate: 0.00517356
	LOSS [training: 0.7354091405496976 | validation: 0.41771788563982787]
	TIME [epoch: 8.29 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3618207509574201		[learning rate: 0.005161]
		[batch 20/20] avg loss: 0.7172680131367167		[learning rate: 0.0051485]
	Learning Rate: 0.00514854
	LOSS [training: 0.5395443820470683 | validation: 3.646887785288909]
	TIME [epoch: 8.29 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.2695154618658453		[learning rate: 0.0051361]
		[batch 20/20] avg loss: 0.3585358934552263		[learning rate: 0.0051236]
	Learning Rate: 0.00512364
	LOSS [training: 1.3140256776605357 | validation: 0.27461212001722907]
	TIME [epoch: 8.29 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.48648871423085305		[learning rate: 0.0051112]
		[batch 20/20] avg loss: 0.7466806702881135		[learning rate: 0.0050989]
	Learning Rate: 0.00509887
	LOSS [training: 0.6165846922594833 | validation: 0.22253986502823764]
	TIME [epoch: 8.32 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3218785586383766		[learning rate: 0.0050865]
		[batch 20/20] avg loss: 0.30114840478513744		[learning rate: 0.0050742]
	Learning Rate: 0.00507421
	LOSS [training: 0.31151348171175697 | validation: 0.23879800428833442]
	TIME [epoch: 8.29 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9120371363059474		[learning rate: 0.0050619]
		[batch 20/20] avg loss: 0.828959550830548		[learning rate: 0.0050497]
	Learning Rate: 0.00504967
	LOSS [training: 0.8704983435682475 | validation: 0.3145823902102327]
	TIME [epoch: 8.3 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2976236233199782		[learning rate: 0.0050374]
		[batch 20/20] avg loss: 0.4011005822036512		[learning rate: 0.0050253]
	Learning Rate: 0.00502525
	LOSS [training: 0.3493621027618147 | validation: 0.2902237204028043]
	TIME [epoch: 8.29 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.33742327595191624		[learning rate: 0.0050131]
		[batch 20/20] avg loss: 0.375214452868542		[learning rate: 0.005001]
	Learning Rate: 0.00500095
	LOSS [training: 0.35631886441022914 | validation: 0.24442119536135024]
	TIME [epoch: 8.32 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2722716913032724		[learning rate: 0.0049888]
		[batch 20/20] avg loss: 0.2932194168228833		[learning rate: 0.0049768]
	Learning Rate: 0.00497677
	LOSS [training: 0.28274555406307783 | validation: 0.32280120954057245]
	TIME [epoch: 8.3 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5070837583166468		[learning rate: 0.0049647]
		[batch 20/20] avg loss: 0.40514416966148675		[learning rate: 0.0049527]
	Learning Rate: 0.0049527
	LOSS [training: 0.45611396398906673 | validation: 0.3700377508787207]
	TIME [epoch: 8.29 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.33052540364756855		[learning rate: 0.0049407]
		[batch 20/20] avg loss: 0.2717706581324909		[learning rate: 0.0049288]
	Learning Rate: 0.00492875
	LOSS [training: 0.30114803089002967 | validation: 0.42889568183539173]
	TIME [epoch: 8.3 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3462218634495468		[learning rate: 0.0049168]
		[batch 20/20] avg loss: 0.35379999543852503		[learning rate: 0.0049049]
	Learning Rate: 0.00490492
	LOSS [training: 0.35001092944403595 | validation: 0.18000549521240283]
	TIME [epoch: 8.32 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.32606171215242796		[learning rate: 0.004893]
		[batch 20/20] avg loss: 1.4301971985925828		[learning rate: 0.0048812]
	Learning Rate: 0.0048812
	LOSS [training: 0.8781294553725054 | validation: 3.5008171183655796]
	TIME [epoch: 8.3 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8126263109510768		[learning rate: 0.0048694]
		[batch 20/20] avg loss: 0.8575694281038011		[learning rate: 0.0048576]
	Learning Rate: 0.00485759
	LOSS [training: 0.835097869527439 | validation: 1.7601438301417336]
	TIME [epoch: 8.3 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.39100975661710596		[learning rate: 0.0048458]
		[batch 20/20] avg loss: 0.7146435275613616		[learning rate: 0.0048341]
	Learning Rate: 0.0048341
	LOSS [training: 0.5528266420892339 | validation: 0.19804051667740158]
	TIME [epoch: 8.3 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.38586570321719404		[learning rate: 0.0048224]
		[batch 20/20] avg loss: 0.32588465846197084		[learning rate: 0.0048107]
	Learning Rate: 0.00481072
	LOSS [training: 0.3558751808395825 | validation: 0.442008870376843]
	TIME [epoch: 8.33 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30296113369753885		[learning rate: 0.0047991]
		[batch 20/20] avg loss: 0.4727973862679823		[learning rate: 0.0047875]
	Learning Rate: 0.00478746
	LOSS [training: 0.38787925998276057 | validation: 0.21350444720677592]
	TIME [epoch: 8.31 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26538285599509703		[learning rate: 0.0047759]
		[batch 20/20] avg loss: 0.30396640709563705		[learning rate: 0.0047643]
	Learning Rate: 0.00476431
	LOSS [training: 0.2846746315453671 | validation: 0.1395914371621816]
	TIME [epoch: 8.3 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6899338052573506		[learning rate: 0.0047528]
		[batch 20/20] avg loss: 0.3981899501141575		[learning rate: 0.0047413]
	Learning Rate: 0.00474127
	LOSS [training: 0.544061877685754 | validation: 1.9449007677845715]
	TIME [epoch: 8.3 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9630880123693524		[learning rate: 0.0047298]
		[batch 20/20] avg loss: 0.3480979262575658		[learning rate: 0.0047183]
	Learning Rate: 0.00471834
	LOSS [training: 0.655592969313459 | validation: 1.0414639334084987]
	TIME [epoch: 8.33 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.6860990267260427		[learning rate: 0.0047069]
		[batch 20/20] avg loss: 0.6606423278755656		[learning rate: 0.0046955]
	Learning Rate: 0.00469553
	LOSS [training: 1.1733706773008041 | validation: 0.3035917816966913]
	TIME [epoch: 8.3 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0583654822478843		[learning rate: 0.0046842]
		[batch 20/20] avg loss: 0.7274456686783586		[learning rate: 0.0046728]
	Learning Rate: 0.00467282
	LOSS [training: 0.8929055754631212 | validation: 0.2628911431954035]
	TIME [epoch: 8.3 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4687843305692064		[learning rate: 0.0046615]
		[batch 20/20] avg loss: 0.49264210527882435		[learning rate: 0.0046502]
	Learning Rate: 0.00465022
	LOSS [training: 0.48071321792401545 | validation: 0.25713020281074583]
	TIME [epoch: 8.3 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.2499475320618156		[learning rate: 0.004639]
		[batch 20/20] avg loss: 1.7723894846857071		[learning rate: 0.0046277]
	Learning Rate: 0.00462773
	LOSS [training: 2.0111685083737614 | validation: 0.40052139362136596]
	TIME [epoch: 8.33 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.211881351813094		[learning rate: 0.0046165]
		[batch 20/20] avg loss: 2.0801275434136346		[learning rate: 0.0046054]
	Learning Rate: 0.00460536
	LOSS [training: 1.6460044476133646 | validation: 1.5550468368326542]
	TIME [epoch: 8.3 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9974263751814612		[learning rate: 0.0045942]
		[batch 20/20] avg loss: nan		[learning rate: 0.0045831]
ERROR:
nan encountered in epoch 210 (training loss).
