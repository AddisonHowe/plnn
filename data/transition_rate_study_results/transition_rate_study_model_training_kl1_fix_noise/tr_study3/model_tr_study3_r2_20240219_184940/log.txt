Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r2', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3166156337

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.70338992997788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.70338992997788 | validation: 9.417044925927275]
	TIME [epoch: 79.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.857031598589014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.857031598589014 | validation: 9.548608364045332]
	TIME [epoch: 8.39 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.193072684082454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.193072684082454 | validation: 8.214654190361774]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.61780134257957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.61780134257957 | validation: 8.44784641185819]
	TIME [epoch: 8.37 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.442301390295826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.442301390295826 | validation: 8.063249087156013]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.311593334995452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.311593334995452 | validation: 8.133595953473309]
	TIME [epoch: 8.37 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.257753037376787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.257753037376787 | validation: 7.9937023828283555]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.229921835867133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.229921835867133 | validation: 8.004904939413002]
	TIME [epoch: 8.38 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.262632574922762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.262632574922762 | validation: 8.049754322205754]
	TIME [epoch: 8.38 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.560600744273096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.560600744273096 | validation: 7.855087357979944]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.09442655947202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.09442655947202 | validation: 8.257023806719266]
	TIME [epoch: 8.36 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.139639895607093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.139639895607093 | validation: 7.803542183531256]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.023410652526152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.023410652526152 | validation: 7.737223564530253]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.8997761606865025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.8997761606865025 | validation: 7.7112205192513406]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.838441192648209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.838441192648209 | validation: 7.649852693299422]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.6007792045157245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.6007792045157245 | validation: 6.845471673667905]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.995736506633648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.995736506633648 | validation: 6.714117106429374]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.822259002905406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.822259002905406 | validation: 6.656882966720504]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.71598590633926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.71598590633926 | validation: 6.30184016479158]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.354472872216079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.354472872216079 | validation: 7.050757089858663]
	TIME [epoch: 8.36 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.951649424292301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.951649424292301 | validation: 6.6875548868766685]
	TIME [epoch: 8.38 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.684608745193211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.684608745193211 | validation: 7.181294217962794]
	TIME [epoch: 8.37 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.016682042765511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.016682042765511 | validation: 6.672783040717972]
	TIME [epoch: 8.37 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.500895416163485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.500895416163485 | validation: 4.886055741209445]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.013601147189859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.013601147189859 | validation: 5.147420396894832]
	TIME [epoch: 8.39 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.858208308191166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.858208308191166 | validation: 4.067224555455304]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.582551645261117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.582551645261117 | validation: 8.92127870765786]
	TIME [epoch: 8.36 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.199629236910572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.199629236910572 | validation: 3.971376939821715]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.318775582419234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.318775582419234 | validation: 3.865037138631746]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.392104915335292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.392104915335292 | validation: 4.661198780604497]
	TIME [epoch: 8.36 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.253226799359181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.253226799359181 | validation: 3.753677030690229]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.170114445643703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.170114445643703 | validation: 3.788045891336096]
	TIME [epoch: 8.35 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.5369179422985635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5369179422985635 | validation: 3.2510309766191794]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.084120023105788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.084120023105788 | validation: 3.7601757586252234]
	TIME [epoch: 8.35 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8999852737049947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8999852737049947 | validation: 3.176065465430571]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6667975358259484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6667975358259484 | validation: 3.1759140372599535]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5308972099195053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5308972099195053 | validation: 2.855828085763166]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7952609595343647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7952609595343647 | validation: 2.9012133043120656]
	TIME [epoch: 8.35 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8241521825488336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8241521825488336 | validation: 3.391157715390623]
	TIME [epoch: 8.36 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2527428561693044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2527428561693044 | validation: 3.0751781433909455]
	TIME [epoch: 8.34 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4996734098842763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4996734098842763 | validation: 2.199694522362048]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4891047116370624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4891047116370624 | validation: 3.1562790363125384]
	TIME [epoch: 8.34 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5415198536315575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5415198536315575 | validation: 1.9720374409657377]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.094872072371358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.094872072371358 | validation: 2.4365270636022514]
	TIME [epoch: 8.34 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.470127430216939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.470127430216939 | validation: 2.134817982780522]
	TIME [epoch: 8.37 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1957069693216056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1957069693216056 | validation: 2.665984118881064]
	TIME [epoch: 8.34 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.400159388348536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.400159388348536 | validation: 2.1539045733229703]
	TIME [epoch: 8.34 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3529352167940636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3529352167940636 | validation: 3.4183458112942167]
	TIME [epoch: 8.35 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.165634853503345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.165634853503345 | validation: 1.703439748256752]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1386682657977705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1386682657977705 | validation: 2.7057487104384847]
	TIME [epoch: 8.34 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.285960946969135		[learning rate: 0.0099788]
	Learning Rate: 0.00997877
	LOSS [training: 2.285960946969135 | validation: 2.0241053952435872]
	TIME [epoch: 8.34 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8537966181753849		[learning rate: 0.0099552]
	Learning Rate: 0.00995523
	LOSS [training: 1.8537966181753849 | validation: 1.4151888052338797]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1508228155405686		[learning rate: 0.0099317]
	Learning Rate: 0.00993175
	LOSS [training: 2.1508228155405686 | validation: 1.9605703448774472]
	TIME [epoch: 8.36 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8755607223732085		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 1.8755607223732085 | validation: 1.9913049842348423]
	TIME [epoch: 8.33 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3478606319485666		[learning rate: 0.0098849]
	Learning Rate: 0.00988495
	LOSS [training: 2.3478606319485666 | validation: 1.8280922671519004]
	TIME [epoch: 8.33 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9675872877845937		[learning rate: 0.0098616]
	Learning Rate: 0.00986163
	LOSS [training: 1.9675872877845937 | validation: 1.5070589568604245]
	TIME [epoch: 8.34 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8923344853460324		[learning rate: 0.0098384]
	Learning Rate: 0.00983837
	LOSS [training: 1.8923344853460324 | validation: 1.4453662182089402]
	TIME [epoch: 8.36 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9133581119706922		[learning rate: 0.0098152]
	Learning Rate: 0.00981516
	LOSS [training: 1.9133581119706922 | validation: 1.600259947116551]
	TIME [epoch: 8.33 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8837099501782049		[learning rate: 0.009792]
	Learning Rate: 0.00979201
	LOSS [training: 1.8837099501782049 | validation: 1.5313013421982706]
	TIME [epoch: 8.33 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7156279417355633		[learning rate: 0.0097689]
	Learning Rate: 0.00976891
	LOSS [training: 1.7156279417355633 | validation: 1.6560970757863842]
	TIME [epoch: 8.34 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9547092400772237		[learning rate: 0.0097459]
	Learning Rate: 0.00974587
	LOSS [training: 1.9547092400772237 | validation: 1.790058717818162]
	TIME [epoch: 8.36 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9644989729703224		[learning rate: 0.0097229]
	Learning Rate: 0.00972288
	LOSS [training: 1.9644989729703224 | validation: 2.2826319393239736]
	TIME [epoch: 8.33 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0989464918953553		[learning rate: 0.0096999]
	Learning Rate: 0.00969994
	LOSS [training: 2.0989464918953553 | validation: 1.7174031748143193]
	TIME [epoch: 8.33 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.996252854615015		[learning rate: 0.0096771]
	Learning Rate: 0.00967706
	LOSS [training: 1.996252854615015 | validation: 2.291283882999056]
	TIME [epoch: 8.33 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0101992622153095		[learning rate: 0.0096542]
	Learning Rate: 0.00965424
	LOSS [training: 2.0101992622153095 | validation: 2.198795805227774]
	TIME [epoch: 8.36 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4269960205541397		[learning rate: 0.0096315]
	Learning Rate: 0.00963146
	LOSS [training: 2.4269960205541397 | validation: 2.1514249304572486]
	TIME [epoch: 8.33 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.061244420597687		[learning rate: 0.0096087]
	Learning Rate: 0.00960874
	LOSS [training: 2.061244420597687 | validation: 1.957205242932125]
	TIME [epoch: 8.33 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.919177919379731		[learning rate: 0.0095861]
	Learning Rate: 0.00958608
	LOSS [training: 1.919177919379731 | validation: 1.8448660391772789]
	TIME [epoch: 8.34 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.068109443807848		[learning rate: 0.0095635]
	Learning Rate: 0.00956347
	LOSS [training: 2.068109443807848 | validation: 1.9856394765182972]
	TIME [epoch: 8.36 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9939784436514967		[learning rate: 0.0095409]
	Learning Rate: 0.00954091
	LOSS [training: 1.9939784436514967 | validation: 1.9956665300859573]
	TIME [epoch: 8.34 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9336726087424245		[learning rate: 0.0095184]
	Learning Rate: 0.0095184
	LOSS [training: 1.9336726087424245 | validation: 2.482169150497235]
	TIME [epoch: 8.33 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0089790878966065		[learning rate: 0.009496]
	Learning Rate: 0.00949595
	LOSS [training: 2.0089790878966065 | validation: 2.5304223242290513]
	TIME [epoch: 8.34 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.109869855790593		[learning rate: 0.0094736]
	Learning Rate: 0.00947355
	LOSS [training: 2.109869855790593 | validation: 1.757534618322655]
	TIME [epoch: 8.36 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8694442587479476		[learning rate: 0.0094512]
	Learning Rate: 0.0094512
	LOSS [training: 1.8694442587479476 | validation: 1.8073494010571864]
	TIME [epoch: 8.33 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8976180373051263		[learning rate: 0.0094289]
	Learning Rate: 0.00942891
	LOSS [training: 1.8976180373051263 | validation: 2.0463209794629442]
	TIME [epoch: 8.34 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8145786124543655		[learning rate: 0.0094067]
	Learning Rate: 0.00940667
	LOSS [training: 1.8145786124543655 | validation: 1.6737432144348803]
	TIME [epoch: 8.34 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8561718936905742		[learning rate: 0.0093845]
	Learning Rate: 0.00938448
	LOSS [training: 1.8561718936905742 | validation: 1.7576644786821478]
	TIME [epoch: 8.35 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.862049962594611		[learning rate: 0.0093623]
	Learning Rate: 0.00936234
	LOSS [training: 1.862049962594611 | validation: 1.3163857350826351]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5842210650494037		[learning rate: 0.0093403]
	Learning Rate: 0.00934026
	LOSS [training: 1.5842210650494037 | validation: 2.1534412678502006]
	TIME [epoch: 8.33 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6162848805118586		[learning rate: 0.0093182]
	Learning Rate: 0.00931823
	LOSS [training: 1.6162848805118586 | validation: 1.3967105842219352]
	TIME [epoch: 8.34 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7444137650168883		[learning rate: 0.0092962]
	Learning Rate: 0.00929625
	LOSS [training: 1.7444137650168883 | validation: 1.4632469984366052]
	TIME [epoch: 8.36 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5353691892448216		[learning rate: 0.0092743]
	Learning Rate: 0.00927432
	LOSS [training: 1.5353691892448216 | validation: 1.5681419820592004]
	TIME [epoch: 8.33 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7939112669402035		[learning rate: 0.0092524]
	Learning Rate: 0.00925244
	LOSS [training: 1.7939112669402035 | validation: 1.4787265382875687]
	TIME [epoch: 8.33 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5833698211503533		[learning rate: 0.0092306]
	Learning Rate: 0.00923062
	LOSS [training: 1.5833698211503533 | validation: 1.5685135603891474]
	TIME [epoch: 8.34 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0595692617773222		[learning rate: 0.0092088]
	Learning Rate: 0.00920884
	LOSS [training: 2.0595692617773222 | validation: 1.578408227685344]
	TIME [epoch: 8.35 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4969924204569145		[learning rate: 0.0091871]
	Learning Rate: 0.00918712
	LOSS [training: 1.4969924204569145 | validation: 1.433998840024453]
	TIME [epoch: 8.33 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8372591354867887		[learning rate: 0.0091655]
	Learning Rate: 0.00916545
	LOSS [training: 1.8372591354867887 | validation: 1.6570285452489424]
	TIME [epoch: 8.33 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4366038059146025		[learning rate: 0.0091438]
	Learning Rate: 0.00914383
	LOSS [training: 1.4366038059146025 | validation: 1.3089141948037042]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8057223707343837		[learning rate: 0.0091223]
	Learning Rate: 0.00912226
	LOSS [training: 1.8057223707343837 | validation: 1.6921219331789317]
	TIME [epoch: 8.34 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5299612366193127		[learning rate: 0.0091007]
	Learning Rate: 0.00910074
	LOSS [training: 1.5299612366193127 | validation: 2.2075740262578862]
	TIME [epoch: 8.33 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.680262297305416		[learning rate: 0.0090793]
	Learning Rate: 0.00907928
	LOSS [training: 1.680262297305416 | validation: 1.2765357903605836]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5077038128003482		[learning rate: 0.0090579]
	Learning Rate: 0.00905786
	LOSS [training: 1.5077038128003482 | validation: 1.353197867222872]
	TIME [epoch: 8.34 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4824244128383124		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 1.4824244128383124 | validation: 1.5376051610833734]
	TIME [epoch: 8.34 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.686889843767714		[learning rate: 0.0090152]
	Learning Rate: 0.00901518
	LOSS [training: 2.686889843767714 | validation: 3.2199562861694573]
	TIME [epoch: 8.33 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9739703564294375		[learning rate: 0.0089939]
	Learning Rate: 0.00899391
	LOSS [training: 3.9739703564294375 | validation: 3.2196654884972133]
	TIME [epoch: 8.33 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8789026059212945		[learning rate: 0.0089727]
	Learning Rate: 0.0089727
	LOSS [training: 3.8789026059212945 | validation: 3.6201094415254165]
	TIME [epoch: 8.35 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3715892090967805		[learning rate: 0.0089515]
	Learning Rate: 0.00895153
	LOSS [training: 3.3715892090967805 | validation: 1.630377900091149]
	TIME [epoch: 8.34 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3125547589475528		[learning rate: 0.0089304]
	Learning Rate: 0.00893042
	LOSS [training: 1.3125547589475528 | validation: 1.4365229687061656]
	TIME [epoch: 8.33 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.199220136153008		[learning rate: 0.0089094]
	Learning Rate: 0.00890935
	LOSS [training: 1.199220136153008 | validation: 2.537067478705194]
	TIME [epoch: 8.33 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4236428603947697		[learning rate: 0.0088883]
	Learning Rate: 0.00888834
	LOSS [training: 1.4236428603947697 | validation: 1.650001325535529]
	TIME [epoch: 8.34 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.522502356350899		[learning rate: 0.0088674]
	Learning Rate: 0.00886737
	LOSS [training: 1.522502356350899 | validation: 1.1155792953803663]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.299129163678024		[learning rate: 0.0088465]
	Learning Rate: 0.00884645
	LOSS [training: 1.299129163678024 | validation: 1.2398774686452319]
	TIME [epoch: 8.33 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2234044910049913		[learning rate: 0.0088256]
	Learning Rate: 0.00882559
	LOSS [training: 1.2234044910049913 | validation: 0.926493466820655]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2285371210021947		[learning rate: 0.0088048]
	Learning Rate: 0.00880477
	LOSS [training: 1.2285371210021947 | validation: 1.0147093252707668]
	TIME [epoch: 8.35 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3549737068256715		[learning rate: 0.008784]
	Learning Rate: 0.008784
	LOSS [training: 1.3549737068256715 | validation: 0.9313992172759642]
	TIME [epoch: 8.33 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1225725088210508		[learning rate: 0.0087633]
	Learning Rate: 0.00876328
	LOSS [training: 1.1225725088210508 | validation: 0.8344328597310309]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.100124480320988		[learning rate: 0.0087426]
	Learning Rate: 0.00874261
	LOSS [training: 1.100124480320988 | validation: 1.0986914508125174]
	TIME [epoch: 8.33 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0830248926556074		[learning rate: 0.008722]
	Learning Rate: 0.00872199
	LOSS [training: 1.0830248926556074 | validation: 0.9783576122865452]
	TIME [epoch: 8.35 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1735010033950177		[learning rate: 0.0087014]
	Learning Rate: 0.00870141
	LOSS [training: 1.1735010033950177 | validation: 2.094523479932673]
	TIME [epoch: 8.33 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2440507198091122		[learning rate: 0.0086809]
	Learning Rate: 0.00868089
	LOSS [training: 1.2440507198091122 | validation: 0.8740717408385508]
	TIME [epoch: 8.33 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1141958260823333		[learning rate: 0.0086604]
	Learning Rate: 0.00866041
	LOSS [training: 1.1141958260823333 | validation: 0.8582825558883439]
	TIME [epoch: 8.34 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1905765675868083		[learning rate: 0.00864]
	Learning Rate: 0.00863998
	LOSS [training: 1.1905765675868083 | validation: 0.8888585847455615]
	TIME [epoch: 8.36 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1987217553522747		[learning rate: 0.0086196]
	Learning Rate: 0.0086196
	LOSS [training: 1.1987217553522747 | validation: 1.2429808981902837]
	TIME [epoch: 8.34 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1388435346789183		[learning rate: 0.0085993]
	Learning Rate: 0.00859927
	LOSS [training: 1.1388435346789183 | validation: 1.0914411497703624]
	TIME [epoch: 8.33 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9743219262573376		[learning rate: 0.008579]
	Learning Rate: 0.00857898
	LOSS [training: 0.9743219262573376 | validation: 0.9928533910504926]
	TIME [epoch: 8.33 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0542853400604975		[learning rate: 0.0085587]
	Learning Rate: 0.00855875
	LOSS [training: 1.0542853400604975 | validation: 1.048249843760198]
	TIME [epoch: 8.37 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8862657723440741		[learning rate: 0.0085386]
	Learning Rate: 0.00853856
	LOSS [training: 0.8862657723440741 | validation: 0.7733517209949857]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0186118163017743		[learning rate: 0.0085184]
	Learning Rate: 0.00851842
	LOSS [training: 1.0186118163017743 | validation: 1.3297630153468656]
	TIME [epoch: 8.33 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0846423177821145		[learning rate: 0.0084983]
	Learning Rate: 0.00849833
	LOSS [training: 1.0846423177821145 | validation: 1.7542706017754095]
	TIME [epoch: 8.33 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9500574018103697		[learning rate: 0.0084783]
	Learning Rate: 0.00847828
	LOSS [training: 0.9500574018103697 | validation: 0.4436630540918075]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7008642606067683		[learning rate: 0.0084583]
	Learning Rate: 0.00845828
	LOSS [training: 0.7008642606067683 | validation: 0.4427120906710063]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8597435496489865		[learning rate: 0.0084383]
	Learning Rate: 0.00843833
	LOSS [training: 0.8597435496489865 | validation: 0.5185781589907847]
	TIME [epoch: 8.37 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.013018503173656		[learning rate: 0.0084184]
	Learning Rate: 0.00841842
	LOSS [training: 1.013018503173656 | validation: 0.5821750079282111]
	TIME [epoch: 8.37 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9649039636767162		[learning rate: 0.0083986]
	Learning Rate: 0.00839857
	LOSS [training: 0.9649039636767162 | validation: 0.9961590570240791]
	TIME [epoch: 8.39 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9331293893724151		[learning rate: 0.0083788]
	Learning Rate: 0.00837875
	LOSS [training: 0.9331293893724151 | validation: 0.5022488199201767]
	TIME [epoch: 8.38 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6673773698077515		[learning rate: 0.008359]
	Learning Rate: 0.00835899
	LOSS [training: 0.6673773698077515 | validation: 0.9929022136771779]
	TIME [epoch: 8.37 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8368999449928868		[learning rate: 0.0083393]
	Learning Rate: 0.00833927
	LOSS [training: 0.8368999449928868 | validation: 1.1931521104584857]
	TIME [epoch: 8.37 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8474453730645459		[learning rate: 0.0083196]
	Learning Rate: 0.0083196
	LOSS [training: 0.8474453730645459 | validation: 0.5930151144649338]
	TIME [epoch: 8.4 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1206602895902555		[learning rate: 0.0083]
	Learning Rate: 0.00829998
	LOSS [training: 1.1206602895902555 | validation: 1.0423685048230769]
	TIME [epoch: 8.37 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9495357595109493		[learning rate: 0.0082804]
	Learning Rate: 0.0082804
	LOSS [training: 0.9495357595109493 | validation: 0.7447127162232392]
	TIME [epoch: 8.37 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9071637542206717		[learning rate: 0.0082609]
	Learning Rate: 0.00826087
	LOSS [training: 0.9071637542206717 | validation: 0.43109340644070965]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.672042677882337		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 0.672042677882337 | validation: 0.7035639101449844]
	TIME [epoch: 8.39 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6830515291964488		[learning rate: 0.0082219]
	Learning Rate: 0.00822194
	LOSS [training: 0.6830515291964488 | validation: 0.768412927335322]
	TIME [epoch: 8.36 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.778965651366636		[learning rate: 0.0082025]
	Learning Rate: 0.00820255
	LOSS [training: 0.778965651366636 | validation: 0.7553756646085668]
	TIME [epoch: 8.36 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9499166837846043		[learning rate: 0.0081832]
	Learning Rate: 0.0081832
	LOSS [training: 0.9499166837846043 | validation: 0.6660712409035308]
	TIME [epoch: 8.37 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9412125960830716		[learning rate: 0.0081639]
	Learning Rate: 0.00816389
	LOSS [training: 0.9412125960830716 | validation: 0.5295662319489929]
	TIME [epoch: 8.39 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0764454658183324		[learning rate: 0.0081446]
	Learning Rate: 0.00814464
	LOSS [training: 1.0764454658183324 | validation: 0.6439743607887554]
	TIME [epoch: 8.37 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.198401228894674		[learning rate: 0.0081254]
	Learning Rate: 0.00812543
	LOSS [training: 1.198401228894674 | validation: 0.9376756737849786]
	TIME [epoch: 8.36 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8036699455700438		[learning rate: 0.0081063]
	Learning Rate: 0.00810626
	LOSS [training: 0.8036699455700438 | validation: 0.7937930987945201]
	TIME [epoch: 8.36 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7400324182549559		[learning rate: 0.0080871]
	Learning Rate: 0.00808714
	LOSS [training: 0.7400324182549559 | validation: 0.6623847143612831]
	TIME [epoch: 8.39 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0419362459574262		[learning rate: 0.0080681]
	Learning Rate: 0.00806806
	LOSS [training: 1.0419362459574262 | validation: 1.5771043772496764]
	TIME [epoch: 8.37 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1115881754641823		[learning rate: 0.008049]
	Learning Rate: 0.00804903
	LOSS [training: 1.1115881754641823 | validation: 0.7099912486879938]
	TIME [epoch: 8.37 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7600107289794631		[learning rate: 0.00803]
	Learning Rate: 0.00803004
	LOSS [training: 0.7600107289794631 | validation: 0.47856562013577564]
	TIME [epoch: 8.37 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.835185598711577		[learning rate: 0.0080111]
	Learning Rate: 0.0080111
	LOSS [training: 0.835185598711577 | validation: 0.4756145292200671]
	TIME [epoch: 8.39 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.788820473424152		[learning rate: 0.0079922]
	Learning Rate: 0.00799221
	LOSS [training: 0.788820473424152 | validation: 0.5104817030338624]
	TIME [epoch: 8.37 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6597010603569161		[learning rate: 0.0079734]
	Learning Rate: 0.00797335
	LOSS [training: 0.6597010603569161 | validation: 0.574948893602949]
	TIME [epoch: 8.36 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7897031835298145		[learning rate: 0.0079545]
	Learning Rate: 0.00795455
	LOSS [training: 0.7897031835298145 | validation: 0.5450652572541436]
	TIME [epoch: 8.37 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.70399201111616		[learning rate: 0.0079358]
	Learning Rate: 0.00793578
	LOSS [training: 0.70399201111616 | validation: 1.2263169053010805]
	TIME [epoch: 8.4 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9932524031741512		[learning rate: 0.0079171]
	Learning Rate: 0.00791706
	LOSS [training: 0.9932524031741512 | validation: 0.5192596984422687]
	TIME [epoch: 8.37 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6829153789325378		[learning rate: 0.0078984]
	Learning Rate: 0.00789839
	LOSS [training: 0.6829153789325378 | validation: 0.42996509269378846]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7569733646521349		[learning rate: 0.0078798]
	Learning Rate: 0.00787976
	LOSS [training: 0.7569733646521349 | validation: 0.4755720207961749]
	TIME [epoch: 8.37 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.969851397317678		[learning rate: 0.0078612]
	Learning Rate: 0.00786117
	LOSS [training: 0.969851397317678 | validation: 0.7150712166289674]
	TIME [epoch: 8.39 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8771039138480121		[learning rate: 0.0078426]
	Learning Rate: 0.00784263
	LOSS [training: 0.8771039138480121 | validation: 0.557274801884551]
	TIME [epoch: 8.36 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7961555614278143		[learning rate: 0.0078241]
	Learning Rate: 0.00782413
	LOSS [training: 0.7961555614278143 | validation: 0.6149507284859387]
	TIME [epoch: 8.37 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.313439108809731		[learning rate: 0.0078057]
	Learning Rate: 0.00780567
	LOSS [training: 1.313439108809731 | validation: 0.7846737872177076]
	TIME [epoch: 8.37 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6974152667880994		[learning rate: 0.0077873]
	Learning Rate: 0.00778726
	LOSS [training: 0.6974152667880994 | validation: 0.9479464691922074]
	TIME [epoch: 8.4 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7826277146839449		[learning rate: 0.0077689]
	Learning Rate: 0.00776889
	LOSS [training: 0.7826277146839449 | validation: 0.8236837996042352]
	TIME [epoch: 8.37 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6714187178894904		[learning rate: 0.0077506]
	Learning Rate: 0.00775056
	LOSS [training: 0.6714187178894904 | validation: 0.5503056429907599]
	TIME [epoch: 8.36 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6611346729811985		[learning rate: 0.0077323]
	Learning Rate: 0.00773228
	LOSS [training: 0.6611346729811985 | validation: 1.1411821538514255]
	TIME [epoch: 8.36 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8690969820468718		[learning rate: 0.007714]
	Learning Rate: 0.00771404
	LOSS [training: 0.8690969820468718 | validation: 0.8349628347659364]
	TIME [epoch: 8.39 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6915368826291772		[learning rate: 0.0076958]
	Learning Rate: 0.00769585
	LOSS [training: 0.6915368826291772 | validation: 0.8346749072193678]
	TIME [epoch: 8.37 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7046885434472445		[learning rate: 0.0076777]
	Learning Rate: 0.00767769
	LOSS [training: 0.7046885434472445 | validation: 0.5369846195050201]
	TIME [epoch: 8.36 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6578816802465879		[learning rate: 0.0076596]
	Learning Rate: 0.00765958
	LOSS [training: 0.6578816802465879 | validation: 0.8916251002640301]
	TIME [epoch: 8.36 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5844475765225483		[learning rate: 0.0076415]
	Learning Rate: 0.00764151
	LOSS [training: 0.5844475765225483 | validation: 0.4480184002421628]
	TIME [epoch: 8.39 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8189692098279803		[learning rate: 0.0076235]
	Learning Rate: 0.00762349
	LOSS [training: 0.8189692098279803 | validation: 0.5773061635425774]
	TIME [epoch: 8.36 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7809786147466468		[learning rate: 0.0076055]
	Learning Rate: 0.00760551
	LOSS [training: 0.7809786147466468 | validation: 1.0340603262812662]
	TIME [epoch: 8.36 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7689673896495132		[learning rate: 0.0075876]
	Learning Rate: 0.00758757
	LOSS [training: 0.7689673896495132 | validation: 0.32933052860093504]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7879570889778889		[learning rate: 0.0075697]
	Learning Rate: 0.00756967
	LOSS [training: 0.7879570889778889 | validation: 0.8335592571527081]
	TIME [epoch: 8.38 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6883590181584929		[learning rate: 0.0075518]
	Learning Rate: 0.00755181
	LOSS [training: 0.6883590181584929 | validation: 0.4593892238781152]
	TIME [epoch: 8.36 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.962439885311964		[learning rate: 0.007534]
	Learning Rate: 0.007534
	LOSS [training: 0.962439885311964 | validation: 0.62642695650379]
	TIME [epoch: 8.36 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5672564107649446		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.5672564107649446 | validation: 0.5571915049711669]
	TIME [epoch: 8.37 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8792068367453523		[learning rate: 0.0074985]
	Learning Rate: 0.0074985
	LOSS [training: 0.8792068367453523 | validation: 0.9545874666173155]
	TIME [epoch: 8.37 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2128295016625306		[learning rate: 0.0074808]
	Learning Rate: 0.00748081
	LOSS [training: 1.2128295016625306 | validation: 0.39976401950431556]
	TIME [epoch: 8.37 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6493646605211509		[learning rate: 0.0074632]
	Learning Rate: 0.00746317
	LOSS [training: 0.6493646605211509 | validation: 1.014851586406877]
	TIME [epoch: 8.36 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8852323159633964		[learning rate: 0.0074456]
	Learning Rate: 0.00744556
	LOSS [training: 0.8852323159633964 | validation: 1.0210443030682395]
	TIME [epoch: 8.37 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0036774057295912		[learning rate: 0.007428]
	Learning Rate: 0.007428
	LOSS [training: 1.0036774057295912 | validation: 1.7979062028163602]
	TIME [epoch: 8.38 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1549852186402634		[learning rate: 0.0074105]
	Learning Rate: 0.00741048
	LOSS [training: 1.1549852186402634 | validation: 0.8713544078143648]
	TIME [epoch: 8.36 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.107935330122212		[learning rate: 0.007393]
	Learning Rate: 0.007393
	LOSS [training: 1.107935330122212 | validation: 1.2530371532943054]
	TIME [epoch: 8.36 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0386597222434806		[learning rate: 0.0073756]
	Learning Rate: 0.00737556
	LOSS [training: 1.0386597222434806 | validation: 0.8809634917995574]
	TIME [epoch: 8.37 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9757217447577918		[learning rate: 0.0073582]
	Learning Rate: 0.00735816
	LOSS [training: 0.9757217447577918 | validation: 0.7658768377063851]
	TIME [epoch: 8.37 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.172713495627192		[learning rate: 0.0073408]
	Learning Rate: 0.0073408
	LOSS [training: 1.172713495627192 | validation: 0.6343653273997114]
	TIME [epoch: 8.36 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5522187745012852		[learning rate: 0.0073235]
	Learning Rate: 0.00732349
	LOSS [training: 0.5522187745012852 | validation: 0.423938874630455]
	TIME [epoch: 8.36 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.526333650196899		[learning rate: 0.0073062]
	Learning Rate: 0.00730621
	LOSS [training: 0.526333650196899 | validation: 0.8647158669407786]
	TIME [epoch: 8.37 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.877307870733962		[learning rate: 0.007289]
	Learning Rate: 0.00728898
	LOSS [training: 0.877307870733962 | validation: 0.9491388885200525]
	TIME [epoch: 8.37 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.329230059400225		[learning rate: 0.0072718]
	Learning Rate: 0.00727178
	LOSS [training: 1.329230059400225 | validation: 0.8260745461396222]
	TIME [epoch: 8.36 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5934242789005422		[learning rate: 0.0072546]
	Learning Rate: 0.00725463
	LOSS [training: 0.5934242789005422 | validation: 0.3505200125250314]
	TIME [epoch: 8.36 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7215761914090991		[learning rate: 0.0072375]
	Learning Rate: 0.00723752
	LOSS [training: 0.7215761914090991 | validation: 0.43064038553965206]
	TIME [epoch: 8.37 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5840394139597131		[learning rate: 0.0072204]
	Learning Rate: 0.00722045
	LOSS [training: 0.5840394139597131 | validation: 0.7917341226011918]
	TIME [epoch: 8.37 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.838473956606634		[learning rate: 0.0072034]
	Learning Rate: 0.00720342
	LOSS [training: 0.838473956606634 | validation: 0.9046405994369604]
	TIME [epoch: 8.35 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6371427565125174		[learning rate: 0.0071864]
	Learning Rate: 0.00718642
	LOSS [training: 0.6371427565125174 | validation: 1.1630433490015042]
	TIME [epoch: 8.36 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6919858286401096		[learning rate: 0.0071695]
	Learning Rate: 0.00716947
	LOSS [training: 0.6919858286401096 | validation: 0.3290797196208796]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_191.pth
	Model improved!!!
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8444532427441619		[learning rate: 0.0071526]
	Learning Rate: 0.00715256
	LOSS [training: 0.8444532427441619 | validation: 0.675417565134537]
	TIME [epoch: 8.38 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8469757821894301		[learning rate: 0.0071357]
	Learning Rate: 0.00713569
	LOSS [training: 0.8469757821894301 | validation: 0.3306252759195269]
	TIME [epoch: 8.36 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7048749156579565		[learning rate: 0.0071189]
	Learning Rate: 0.00711886
	LOSS [training: 0.7048749156579565 | validation: 0.5660243985251017]
	TIME [epoch: 8.36 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6622965842746871		[learning rate: 0.0071021]
	Learning Rate: 0.00710206
	LOSS [training: 0.6622965842746871 | validation: 0.40032728514864535]
	TIME [epoch: 8.37 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.559197551426428		[learning rate: 0.0070853]
	Learning Rate: 0.00708531
	LOSS [training: 0.559197551426428 | validation: 0.43238265673900145]
	TIME [epoch: 8.37 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46176037562290856		[learning rate: 0.0070686]
	Learning Rate: 0.0070686
	LOSS [training: 0.46176037562290856 | validation: 0.4809659960570484]
	TIME [epoch: 8.36 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6320691513199712		[learning rate: 0.0070519]
	Learning Rate: 0.00705192
	LOSS [training: 0.6320691513199712 | validation: 0.3798286990987638]
	TIME [epoch: 8.36 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5751279088678591		[learning rate: 0.0070353]
	Learning Rate: 0.00703529
	LOSS [training: 0.5751279088678591 | validation: 0.649737237386984]
	TIME [epoch: 8.38 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9494920783601927		[learning rate: 0.0070187]
	Learning Rate: 0.0070187
	LOSS [training: 0.9494920783601927 | validation: 0.8014528077838541]
	TIME [epoch: 8.37 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6284616974138773		[learning rate: 0.0070021]
	Learning Rate: 0.00700214
	LOSS [training: 0.6284616974138773 | validation: 0.2782185672771701]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6152309402029055		[learning rate: 0.0069856]
	Learning Rate: 0.00698562
	LOSS [training: 0.6152309402029055 | validation: 0.4821998126543344]
	TIME [epoch: 8.36 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5281444246527587		[learning rate: 0.0069691]
	Learning Rate: 0.00696914
	LOSS [training: 0.5281444246527587 | validation: 0.36387231776858686]
	TIME [epoch: 8.38 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6936166812756039		[learning rate: 0.0069527]
	Learning Rate: 0.00695271
	LOSS [training: 0.6936166812756039 | validation: 0.9547479194421266]
	TIME [epoch: 8.36 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6163121237172101		[learning rate: 0.0069363]
	Learning Rate: 0.00693631
	LOSS [training: 0.6163121237172101 | validation: 0.4409441193487351]
	TIME [epoch: 8.36 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9050005895412829		[learning rate: 0.0069199]
	Learning Rate: 0.00691994
	LOSS [training: 0.9050005895412829 | validation: 0.5716043898808145]
	TIME [epoch: 8.36 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6395379456938233		[learning rate: 0.0069036]
	Learning Rate: 0.00690362
	LOSS [training: 0.6395379456938233 | validation: 0.3786754164125441]
	TIME [epoch: 8.39 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6323537019110297		[learning rate: 0.0068873]
	Learning Rate: 0.00688734
	LOSS [training: 0.6323537019110297 | validation: 0.2942081702191059]
	TIME [epoch: 8.36 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6758159964946467		[learning rate: 0.0068711]
	Learning Rate: 0.00687109
	LOSS [training: 0.6758159964946467 | validation: 0.3743227897760659]
	TIME [epoch: 8.36 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6292391961210282		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.6292391961210282 | validation: 0.6360774356415128]
	TIME [epoch: 8.36 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5999559082073704		[learning rate: 0.0068387]
	Learning Rate: 0.00683871
	LOSS [training: 0.5999559082073704 | validation: 0.38050035922872777]
	TIME [epoch: 8.39 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5779860507988441		[learning rate: 0.0068226]
	Learning Rate: 0.00682258
	LOSS [training: 0.5779860507988441 | validation: 0.36635017339050735]
	TIME [epoch: 8.36 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5980895104025931		[learning rate: 0.0068065]
	Learning Rate: 0.00680649
	LOSS [training: 0.5980895104025931 | validation: 0.48557294286874436]
	TIME [epoch: 8.36 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.559151618045493		[learning rate: 0.0067904]
	Learning Rate: 0.00679043
	LOSS [training: 0.559151618045493 | validation: 0.42196287923135734]
	TIME [epoch: 8.35 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.591884325417399		[learning rate: 0.0067744]
	Learning Rate: 0.00677441
	LOSS [training: 0.591884325417399 | validation: 0.36050997880950475]
	TIME [epoch: 8.39 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43738309429714234		[learning rate: 0.0067584]
	Learning Rate: 0.00675843
	LOSS [training: 0.43738309429714234 | validation: 0.32508537878611504]
	TIME [epoch: 8.36 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6694235886569418		[learning rate: 0.0067425]
	Learning Rate: 0.00674249
	LOSS [training: 0.6694235886569418 | validation: 0.46526729698569624]
	TIME [epoch: 8.36 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5011808182732096		[learning rate: 0.0067266]
	Learning Rate: 0.00672659
	LOSS [training: 0.5011808182732096 | validation: 0.4641132952100655]
	TIME [epoch: 8.36 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5165788445919055		[learning rate: 0.0067107]
	Learning Rate: 0.00671072
	LOSS [training: 0.5165788445919055 | validation: 0.7309434896559357]
	TIME [epoch: 8.38 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6442829065359196		[learning rate: 0.0066949]
	Learning Rate: 0.00669489
	LOSS [training: 0.6442829065359196 | validation: 0.3563114671097857]
	TIME [epoch: 8.36 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6940275426891862		[learning rate: 0.0066791]
	Learning Rate: 0.0066791
	LOSS [training: 0.6940275426891862 | validation: 0.5800669604123105]
	TIME [epoch: 8.36 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8304366372088554		[learning rate: 0.0066633]
	Learning Rate: 0.00666334
	LOSS [training: 0.8304366372088554 | validation: 0.39216247773869434]
	TIME [epoch: 8.36 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.460101518157723		[learning rate: 0.0066476]
	Learning Rate: 0.00664763
	LOSS [training: 0.460101518157723 | validation: 0.3698334638056576]
	TIME [epoch: 8.39 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.441793486264398		[learning rate: 0.0066319]
	Learning Rate: 0.00663195
	LOSS [training: 0.441793486264398 | validation: 0.4538461788919073]
	TIME [epoch: 8.37 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6645971876260538		[learning rate: 0.0066163]
	Learning Rate: 0.0066163
	LOSS [training: 0.6645971876260538 | validation: 0.36938181958196087]
	TIME [epoch: 8.36 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7205968404211722		[learning rate: 0.0066007]
	Learning Rate: 0.0066007
	LOSS [training: 0.7205968404211722 | validation: 0.33197131809607117]
	TIME [epoch: 8.36 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6069565027798494		[learning rate: 0.0065851]
	Learning Rate: 0.00658513
	LOSS [training: 0.6069565027798494 | validation: 0.7577484417184179]
	TIME [epoch: 8.38 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44396865643784017		[learning rate: 0.0065696]
	Learning Rate: 0.00656959
	LOSS [training: 0.44396865643784017 | validation: 0.6635827601595843]
	TIME [epoch: 8.36 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7304590216261396		[learning rate: 0.0065541]
	Learning Rate: 0.0065541
	LOSS [training: 0.7304590216261396 | validation: 1.6398317583752609]
	TIME [epoch: 8.36 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8849105688277588		[learning rate: 0.0065386]
	Learning Rate: 0.00653864
	LOSS [training: 0.8849105688277588 | validation: 0.7021435782734148]
	TIME [epoch: 8.36 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8898194381586142		[learning rate: 0.0065232]
	Learning Rate: 0.00652321
	LOSS [training: 0.8898194381586142 | validation: 0.8222010477969834]
	TIME [epoch: 8.38 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0453395667511327		[learning rate: 0.0065078]
	Learning Rate: 0.00650783
	LOSS [training: 1.0453395667511327 | validation: 1.3791956474498037]
	TIME [epoch: 8.36 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.923582756735615		[learning rate: 0.0064925]
	Learning Rate: 0.00649247
	LOSS [training: 0.923582756735615 | validation: 0.418229154540382]
	TIME [epoch: 8.36 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5197787838000074		[learning rate: 0.0064772]
	Learning Rate: 0.00647716
	LOSS [training: 0.5197787838000074 | validation: 0.48259918674701574]
	TIME [epoch: 8.36 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.586225977505018		[learning rate: 0.0064619]
	Learning Rate: 0.00646188
	LOSS [training: 0.586225977505018 | validation: 0.5950629985945656]
	TIME [epoch: 8.38 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5351828818257418		[learning rate: 0.0064466]
	Learning Rate: 0.00644664
	LOSS [training: 0.5351828818257418 | validation: 0.4732645006950514]
	TIME [epoch: 8.36 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43761911127090636		[learning rate: 0.0064314]
	Learning Rate: 0.00643143
	LOSS [training: 0.43761911127090636 | validation: 0.26221621260495903]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5094261224924403		[learning rate: 0.0064163]
	Learning Rate: 0.00641626
	LOSS [training: 0.5094261224924403 | validation: 0.5886025738576292]
	TIME [epoch: 8.36 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5253696077143639		[learning rate: 0.0064011]
	Learning Rate: 0.00640113
	LOSS [training: 0.5253696077143639 | validation: 0.43800457637272716]
	TIME [epoch: 8.38 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4136585721702737		[learning rate: 0.006386]
	Learning Rate: 0.00638603
	LOSS [training: 0.4136585721702737 | validation: 0.36728215066360187]
	TIME [epoch: 8.36 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8152723891656987		[learning rate: 0.006371]
	Learning Rate: 0.00637096
	LOSS [training: 0.8152723891656987 | validation: 0.4972251538877036]
	TIME [epoch: 8.35 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7080750297993935		[learning rate: 0.0063559]
	Learning Rate: 0.00635594
	LOSS [training: 0.7080750297993935 | validation: 0.3820122189637668]
	TIME [epoch: 8.36 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44120810889543105		[learning rate: 0.0063409]
	Learning Rate: 0.00634094
	LOSS [training: 0.44120810889543105 | validation: 0.6353674289645997]
	TIME [epoch: 8.38 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5393532754239002		[learning rate: 0.006326]
	Learning Rate: 0.00632599
	LOSS [training: 0.5393532754239002 | validation: 0.3554713362871328]
	TIME [epoch: 8.35 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5125824357375801		[learning rate: 0.0063111]
	Learning Rate: 0.00631106
	LOSS [training: 0.5125824357375801 | validation: 0.5266689531588356]
	TIME [epoch: 8.35 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5995692908692017		[learning rate: 0.0062962]
	Learning Rate: 0.00629618
	LOSS [training: 0.5995692908692017 | validation: 0.397742885433458]
	TIME [epoch: 8.35 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5837623475254742		[learning rate: 0.0062813]
	Learning Rate: 0.00628133
	LOSS [training: 0.5837623475254742 | validation: 0.6921401778968117]
	TIME [epoch: 8.38 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4753905290221144		[learning rate: 0.0062665]
	Learning Rate: 0.00626651
	LOSS [training: 0.4753905290221144 | validation: 0.48147213391130056]
	TIME [epoch: 8.35 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4553259066284344		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.4553259066284344 | validation: 0.30314492854284836]
	TIME [epoch: 8.36 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6264946241977517		[learning rate: 0.006237]
	Learning Rate: 0.00623698
	LOSS [training: 0.6264946241977517 | validation: 0.6310992199479266]
	TIME [epoch: 8.36 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5872482429216533		[learning rate: 0.0062223]
	Learning Rate: 0.00622227
	LOSS [training: 0.5872482429216533 | validation: 0.41542128254529864]
	TIME [epoch: 8.38 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5621547747907566		[learning rate: 0.0062076]
	Learning Rate: 0.00620759
	LOSS [training: 0.5621547747907566 | validation: 0.7275860329472]
	TIME [epoch: 8.35 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.441085037463547		[learning rate: 0.0061929]
	Learning Rate: 0.00619295
	LOSS [training: 0.441085037463547 | validation: 0.7584856734962258]
	TIME [epoch: 8.36 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7658410788681707		[learning rate: 0.0061783]
	Learning Rate: 0.00617834
	LOSS [training: 0.7658410788681707 | validation: 0.5720200182025441]
	TIME [epoch: 8.35 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6606378045073035		[learning rate: 0.0061638]
	Learning Rate: 0.00616377
	LOSS [training: 0.6606378045073035 | validation: 0.481427757934339]
	TIME [epoch: 8.39 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45680978840480063		[learning rate: 0.0061492]
	Learning Rate: 0.00614923
	LOSS [training: 0.45680978840480063 | validation: 0.43575194921574245]
	TIME [epoch: 8.36 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4927580200883842		[learning rate: 0.0061347]
	Learning Rate: 0.00613472
	LOSS [training: 0.4927580200883842 | validation: 0.7579651121290529]
	TIME [epoch: 8.36 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4975871801433097		[learning rate: 0.0061203]
	Learning Rate: 0.00612025
	LOSS [training: 0.4975871801433097 | validation: 0.6825958255202362]
	TIME [epoch: 8.36 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5971282134302572		[learning rate: 0.0061058]
	Learning Rate: 0.00610581
	LOSS [training: 0.5971282134302572 | validation: 0.7660361176855243]
	TIME [epoch: 8.38 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5697072832874961		[learning rate: 0.0060914]
	Learning Rate: 0.00609141
	LOSS [training: 0.5697072832874961 | validation: 0.34592901928689335]
	TIME [epoch: 8.36 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5824543064770665		[learning rate: 0.006077]
	Learning Rate: 0.00607704
	LOSS [training: 0.5824543064770665 | validation: 0.4569877048773848]
	TIME [epoch: 8.36 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5749854687395866		[learning rate: 0.0060627]
	Learning Rate: 0.00606271
	LOSS [training: 0.5749854687395866 | validation: 0.35209286097517145]
	TIME [epoch: 8.37 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5148342598788832		[learning rate: 0.0060484]
	Learning Rate: 0.00604841
	LOSS [training: 0.5148342598788832 | validation: 0.5645440564695852]
	TIME [epoch: 8.38 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5437379376351333		[learning rate: 0.0060341]
	Learning Rate: 0.00603414
	LOSS [training: 0.5437379376351333 | validation: 0.6129628021734818]
	TIME [epoch: 8.36 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44105869342267495		[learning rate: 0.0060199]
	Learning Rate: 0.00601991
	LOSS [training: 0.44105869342267495 | validation: 1.0745328638360419]
	TIME [epoch: 8.36 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5568322265904394		[learning rate: 0.0060057]
	Learning Rate: 0.00600571
	LOSS [training: 0.5568322265904394 | validation: 0.2913011562442561]
	TIME [epoch: 8.37 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5758483137594678		[learning rate: 0.0059915]
	Learning Rate: 0.00599154
	LOSS [training: 0.5758483137594678 | validation: 0.6323339961618546]
	TIME [epoch: 8.37 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5301480063188838		[learning rate: 0.0059774]
	Learning Rate: 0.00597741
	LOSS [training: 0.5301480063188838 | validation: 0.49090493609569413]
	TIME [epoch: 8.35 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48531213827901387		[learning rate: 0.0059633]
	Learning Rate: 0.00596331
	LOSS [training: 0.48531213827901387 | validation: 0.7125762597970126]
	TIME [epoch: 8.36 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6744838719733208		[learning rate: 0.0059492]
	Learning Rate: 0.00594924
	LOSS [training: 0.6744838719733208 | validation: 0.36022876935227427]
	TIME [epoch: 8.36 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4898337899217017		[learning rate: 0.0059352]
	Learning Rate: 0.00593521
	LOSS [training: 0.4898337899217017 | validation: 0.24753459870171463]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4873031890650349		[learning rate: 0.0059212]
	Learning Rate: 0.00592121
	LOSS [training: 0.4873031890650349 | validation: 0.5130996471485306]
	TIME [epoch: 8.35 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7801687549907991		[learning rate: 0.0059072]
	Learning Rate: 0.00590724
	LOSS [training: 0.7801687549907991 | validation: 0.8224758161492447]
	TIME [epoch: 8.36 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6554663359474135		[learning rate: 0.0058933]
	Learning Rate: 0.00589331
	LOSS [training: 0.6554663359474135 | validation: 0.45876198739016527]
	TIME [epoch: 8.37 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5189376710163064		[learning rate: 0.0058794]
	Learning Rate: 0.0058794
	LOSS [training: 0.5189376710163064 | validation: 0.5427721060723016]
	TIME [epoch: 8.37 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5241609683120141		[learning rate: 0.0058655]
	Learning Rate: 0.00586554
	LOSS [training: 0.5241609683120141 | validation: 0.3761824380661492]
	TIME [epoch: 8.36 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4567155416890163		[learning rate: 0.0058517]
	Learning Rate: 0.0058517
	LOSS [training: 0.4567155416890163 | validation: 0.40703660566614386]
	TIME [epoch: 8.36 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5353638627982171		[learning rate: 0.0058379]
	Learning Rate: 0.0058379
	LOSS [training: 0.5353638627982171 | validation: 0.34956598548791484]
	TIME [epoch: 8.38 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45276655226153634		[learning rate: 0.0058241]
	Learning Rate: 0.00582413
	LOSS [training: 0.45276655226153634 | validation: 0.2576521636476481]
	TIME [epoch: 8.37 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4517123337496119		[learning rate: 0.0058104]
	Learning Rate: 0.00581039
	LOSS [training: 0.4517123337496119 | validation: 0.5933546830293684]
	TIME [epoch: 8.36 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47661464574144574		[learning rate: 0.0057967]
	Learning Rate: 0.00579668
	LOSS [training: 0.47661464574144574 | validation: 0.47483942755519676]
	TIME [epoch: 8.36 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6050567596125447		[learning rate: 0.005783]
	Learning Rate: 0.00578301
	LOSS [training: 0.6050567596125447 | validation: 0.28182223548397445]
	TIME [epoch: 8.37 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5389258995499433		[learning rate: 0.0057694]
	Learning Rate: 0.00576937
	LOSS [training: 0.5389258995499433 | validation: 0.30623187672891555]
	TIME [epoch: 8.36 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5352385013734436		[learning rate: 0.0057558]
	Learning Rate: 0.00575576
	LOSS [training: 0.5352385013734436 | validation: 0.4856249313575355]
	TIME [epoch: 8.36 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.598672827194691		[learning rate: 0.0057422]
	Learning Rate: 0.00574218
	LOSS [training: 0.598672827194691 | validation: 0.27576284538402496]
	TIME [epoch: 8.36 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4699113268366385		[learning rate: 0.0057286]
	Learning Rate: 0.00572864
	LOSS [training: 0.4699113268366385 | validation: 0.27390887534461167]
	TIME [epoch: 8.36 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40267468039238485		[learning rate: 0.0057151]
	Learning Rate: 0.00571512
	LOSS [training: 0.40267468039238485 | validation: 0.34485752781885926]
	TIME [epoch: 8.36 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4469437795404384		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.4469437795404384 | validation: 0.2406388854483238]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_288.pth
	Model improved!!!
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.843184992535355		[learning rate: 0.0056882]
	Learning Rate: 0.00568819
	LOSS [training: 0.843184992535355 | validation: 0.3470771435124004]
	TIME [epoch: 8.35 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.541433217809438		[learning rate: 0.0056748]
	Learning Rate: 0.00567478
	LOSS [training: 0.541433217809438 | validation: 0.8632190465138472]
	TIME [epoch: 8.37 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4150120784575032		[learning rate: 0.0056614]
	Learning Rate: 0.00566139
	LOSS [training: 0.4150120784575032 | validation: 0.3239683414725958]
	TIME [epoch: 8.36 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5845379961521128		[learning rate: 0.005648]
	Learning Rate: 0.00564804
	LOSS [training: 0.5845379961521128 | validation: 0.3323513649280918]
	TIME [epoch: 8.35 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5620359978019633		[learning rate: 0.0056347]
	Learning Rate: 0.00563471
	LOSS [training: 0.5620359978019633 | validation: 0.5926286510464766]
	TIME [epoch: 8.35 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.534736936823107		[learning rate: 0.0056214]
	Learning Rate: 0.00562142
	LOSS [training: 0.534736936823107 | validation: 0.33991466794922925]
	TIME [epoch: 8.37 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4809976555774108		[learning rate: 0.0056082]
	Learning Rate: 0.00560816
	LOSS [training: 0.4809976555774108 | validation: 0.42710063982724866]
	TIME [epoch: 8.36 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.416528962188859		[learning rate: 0.0055949]
	Learning Rate: 0.00559493
	LOSS [training: 0.416528962188859 | validation: 0.4877852669139106]
	TIME [epoch: 8.35 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5447331233857546		[learning rate: 0.0055817]
	Learning Rate: 0.00558173
	LOSS [training: 0.5447331233857546 | validation: 0.4519050958949407]
	TIME [epoch: 8.35 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6125043710670152		[learning rate: 0.0055686]
	Learning Rate: 0.00556857
	LOSS [training: 0.6125043710670152 | validation: 0.26150199019665793]
	TIME [epoch: 8.37 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4644078417150609		[learning rate: 0.0055554]
	Learning Rate: 0.00555543
	LOSS [training: 0.4644078417150609 | validation: 0.48837263687047594]
	TIME [epoch: 8.35 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43986129192488105		[learning rate: 0.0055423]
	Learning Rate: 0.00554233
	LOSS [training: 0.43986129192488105 | validation: 0.5188449191208502]
	TIME [epoch: 8.35 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4530789666313944		[learning rate: 0.0055293]
	Learning Rate: 0.00552926
	LOSS [training: 0.4530789666313944 | validation: 0.6712639976403842]
	TIME [epoch: 8.35 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.63046275192621		[learning rate: 0.0055162]
	Learning Rate: 0.00551621
	LOSS [training: 0.63046275192621 | validation: 0.20600077040986212]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6322391599638364		[learning rate: 0.0055032]
	Learning Rate: 0.0055032
	LOSS [training: 0.6322391599638364 | validation: 0.4661963183118738]
	TIME [epoch: 8.35 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.601538839890794		[learning rate: 0.0054902]
	Learning Rate: 0.00549022
	LOSS [training: 0.601538839890794 | validation: 0.3341427190157672]
	TIME [epoch: 8.35 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5264324882430621		[learning rate: 0.0054773]
	Learning Rate: 0.00547727
	LOSS [training: 0.5264324882430621 | validation: 0.5833186364182616]
	TIME [epoch: 8.35 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4157960539511209		[learning rate: 0.0054643]
	Learning Rate: 0.00546435
	LOSS [training: 0.4157960539511209 | validation: 0.30709807260233446]
	TIME [epoch: 8.38 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47420973833402263		[learning rate: 0.0054515]
	Learning Rate: 0.00545146
	LOSS [training: 0.47420973833402263 | validation: 0.32326603424508604]
	TIME [epoch: 8.36 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44617748338137897		[learning rate: 0.0054386]
	Learning Rate: 0.0054386
	LOSS [training: 0.44617748338137897 | validation: 0.4578372993937533]
	TIME [epoch: 8.35 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3536949098879563		[learning rate: 0.0054258]
	Learning Rate: 0.00542577
	LOSS [training: 0.3536949098879563 | validation: 0.320844431152723]
	TIME [epoch: 8.35 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3579399849273204		[learning rate: 0.005413]
	Learning Rate: 0.00541297
	LOSS [training: 0.3579399849273204 | validation: 0.480463177504186]
	TIME [epoch: 8.37 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4076351572849658		[learning rate: 0.0054002]
	Learning Rate: 0.00540021
	LOSS [training: 0.4076351572849658 | validation: 0.3182389458003553]
	TIME [epoch: 8.36 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45915448530165176		[learning rate: 0.0053875]
	Learning Rate: 0.00538747
	LOSS [training: 0.45915448530165176 | validation: 0.43735532869162985]
	TIME [epoch: 8.36 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4548796626839528		[learning rate: 0.0053748]
	Learning Rate: 0.00537476
	LOSS [training: 0.4548796626839528 | validation: 0.3184637033980564]
	TIME [epoch: 8.36 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.532065847797163		[learning rate: 0.0053621]
	Learning Rate: 0.00536208
	LOSS [training: 0.532065847797163 | validation: 0.7793359796428054]
	TIME [epoch: 8.38 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6739459607779038		[learning rate: 0.0053494]
	Learning Rate: 0.00534943
	LOSS [training: 0.6739459607779038 | validation: 0.5629054381100617]
	TIME [epoch: 8.36 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4509966358959753		[learning rate: 0.0053368]
	Learning Rate: 0.00533681
	LOSS [training: 0.4509966358959753 | validation: 0.2699171354886115]
	TIME [epoch: 8.35 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5794239695797107		[learning rate: 0.0053242]
	Learning Rate: 0.00532423
	LOSS [training: 0.5794239695797107 | validation: 0.47463608062797497]
	TIME [epoch: 8.36 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6170804253094195		[learning rate: 0.0053117]
	Learning Rate: 0.00531167
	LOSS [training: 0.6170804253094195 | validation: 0.33534131159147285]
	TIME [epoch: 8.38 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.409450032662347		[learning rate: 0.0052991]
	Learning Rate: 0.00529914
	LOSS [training: 0.409450032662347 | validation: 0.3019454289781097]
	TIME [epoch: 8.36 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35987639218027934		[learning rate: 0.0052866]
	Learning Rate: 0.00528664
	LOSS [training: 0.35987639218027934 | validation: 0.28874497673491056]
	TIME [epoch: 8.36 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.550556536673584		[learning rate: 0.0052742]
	Learning Rate: 0.00527417
	LOSS [training: 0.550556536673584 | validation: 0.3237176249528535]
	TIME [epoch: 8.35 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49190429861150753		[learning rate: 0.0052617]
	Learning Rate: 0.00526173
	LOSS [training: 0.49190429861150753 | validation: 0.6641414909538237]
	TIME [epoch: 8.38 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3884178732362881		[learning rate: 0.0052493]
	Learning Rate: 0.00524931
	LOSS [training: 0.3884178732362881 | validation: 0.3513394153157272]
	TIME [epoch: 8.36 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.418108950307435		[learning rate: 0.0052369]
	Learning Rate: 0.00523693
	LOSS [training: 0.418108950307435 | validation: 0.2679112725924061]
	TIME [epoch: 8.36 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41189889112295097		[learning rate: 0.0052246]
	Learning Rate: 0.00522458
	LOSS [training: 0.41189889112295097 | validation: 0.22602294888899682]
	TIME [epoch: 8.36 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41037346838404803		[learning rate: 0.0052123]
	Learning Rate: 0.00521225
	LOSS [training: 0.41037346838404803 | validation: 0.3975313298245432]
	TIME [epoch: 8.38 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3650126365443214		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.3650126365443214 | validation: 0.44520953586402623]
	TIME [epoch: 8.36 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3873671724393231		[learning rate: 0.0051877]
	Learning Rate: 0.00518769
	LOSS [training: 0.3873671724393231 | validation: 0.2281530834622582]
	TIME [epoch: 8.36 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3535607064710919		[learning rate: 0.0051755]
	Learning Rate: 0.00517546
	LOSS [training: 0.3535607064710919 | validation: 0.38662216027704954]
	TIME [epoch: 8.36 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4959315102345377		[learning rate: 0.0051632]
	Learning Rate: 0.00516325
	LOSS [training: 0.4959315102345377 | validation: 0.4288347473732286]
	TIME [epoch: 8.38 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5142868548736124		[learning rate: 0.0051511]
	Learning Rate: 0.00515107
	LOSS [training: 0.5142868548736124 | validation: 0.4214525145565058]
	TIME [epoch: 8.36 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4196226363671614		[learning rate: 0.0051389]
	Learning Rate: 0.00513892
	LOSS [training: 0.4196226363671614 | validation: 0.22715798707956258]
	TIME [epoch: 8.36 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34354397589123103		[learning rate: 0.0051268]
	Learning Rate: 0.0051268
	LOSS [training: 0.34354397589123103 | validation: 0.2047843540670639]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_333.pth
	Model improved!!!
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38748388989168564		[learning rate: 0.0051147]
	Learning Rate: 0.0051147
	LOSS [training: 0.38748388989168564 | validation: 0.25403339877278985]
	TIME [epoch: 8.38 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4044117215957387		[learning rate: 0.0051026]
	Learning Rate: 0.00510264
	LOSS [training: 0.4044117215957387 | validation: 0.3192457329982196]
	TIME [epoch: 8.36 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4328165234899659		[learning rate: 0.0050906]
	Learning Rate: 0.0050906
	LOSS [training: 0.4328165234899659 | validation: 0.34087872162265215]
	TIME [epoch: 8.36 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3033210165381188		[learning rate: 0.0050786]
	Learning Rate: 0.00507859
	LOSS [training: 0.3033210165381188 | validation: 0.36814822278336456]
	TIME [epoch: 8.35 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3651814416612825		[learning rate: 0.0050666]
	Learning Rate: 0.00506661
	LOSS [training: 0.3651814416612825 | validation: 0.3054113554072949]
	TIME [epoch: 8.38 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40755999286870015		[learning rate: 0.0050547]
	Learning Rate: 0.00505466
	LOSS [training: 0.40755999286870015 | validation: 0.3019099157174575]
	TIME [epoch: 8.35 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4238934822712898		[learning rate: 0.0050427]
	Learning Rate: 0.00504274
	LOSS [training: 0.4238934822712898 | validation: 0.2868387880353628]
	TIME [epoch: 8.35 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32049228042426403		[learning rate: 0.0050308]
	Learning Rate: 0.00503085
	LOSS [training: 0.32049228042426403 | validation: 0.18216155980259274]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_341.pth
	Model improved!!!
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35446186340742125		[learning rate: 0.005019]
	Learning Rate: 0.00501898
	LOSS [training: 0.35446186340742125 | validation: 0.4748037077583429]
	TIME [epoch: 8.38 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46718948845047487		[learning rate: 0.0050071]
	Learning Rate: 0.00500714
	LOSS [training: 0.46718948845047487 | validation: 0.2356640755236174]
	TIME [epoch: 8.35 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35483504793998094		[learning rate: 0.0049953]
	Learning Rate: 0.00499533
	LOSS [training: 0.35483504793998094 | validation: 0.2127030660467365]
	TIME [epoch: 8.35 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34491423474267946		[learning rate: 0.0049835]
	Learning Rate: 0.00498355
	LOSS [training: 0.34491423474267946 | validation: 0.26085479764655084]
	TIME [epoch: 8.35 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44086446165129267		[learning rate: 0.0049718]
	Learning Rate: 0.00497179
	LOSS [training: 0.44086446165129267 | validation: 0.40279733463393363]
	TIME [epoch: 8.37 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40689117826981985		[learning rate: 0.0049601]
	Learning Rate: 0.00496006
	LOSS [training: 0.40689117826981985 | validation: 1.0444002046297765]
	TIME [epoch: 8.36 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47986218881009685		[learning rate: 0.0049484]
	Learning Rate: 0.00494836
	LOSS [training: 0.47986218881009685 | validation: 0.22746706331920025]
	TIME [epoch: 8.35 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4519807174901689		[learning rate: 0.0049367]
	Learning Rate: 0.00493669
	LOSS [training: 0.4519807174901689 | validation: 0.1844132914599315]
	TIME [epoch: 8.35 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36764464113662876		[learning rate: 0.004925]
	Learning Rate: 0.00492505
	LOSS [training: 0.36764464113662876 | validation: 0.27182453242645377]
	TIME [epoch: 8.39 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4424565976677843		[learning rate: 0.0049134]
	Learning Rate: 0.00491343
	LOSS [training: 0.4424565976677843 | validation: 0.2654582009703925]
	TIME [epoch: 8.36 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6604627859537805		[learning rate: 0.0049018]
	Learning Rate: 0.00490184
	LOSS [training: 0.6604627859537805 | validation: 0.3707086910015438]
	TIME [epoch: 8.36 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3997380231754274		[learning rate: 0.0048903]
	Learning Rate: 0.00489028
	LOSS [training: 0.3997380231754274 | validation: 0.26989874430908267]
	TIME [epoch: 8.36 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4298401661250466		[learning rate: 0.0048787]
	Learning Rate: 0.00487874
	LOSS [training: 0.4298401661250466 | validation: 0.8775034053802094]
	TIME [epoch: 8.38 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4488468749154363		[learning rate: 0.0048672]
	Learning Rate: 0.00486723
	LOSS [training: 0.4488468749154363 | validation: 0.5313979967768623]
	TIME [epoch: 8.35 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3421045127934116		[learning rate: 0.0048558]
	Learning Rate: 0.00485575
	LOSS [training: 0.3421045127934116 | validation: 0.26209719521674474]
	TIME [epoch: 8.36 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.333922062971974		[learning rate: 0.0048443]
	Learning Rate: 0.0048443
	LOSS [training: 0.333922062971974 | validation: 0.7346119256710424]
	TIME [epoch: 8.36 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3735463938705557		[learning rate: 0.0048329]
	Learning Rate: 0.00483287
	LOSS [training: 0.3735463938705557 | validation: 0.22603235399319382]
	TIME [epoch: 8.39 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27937051843192123		[learning rate: 0.0048215]
	Learning Rate: 0.00482147
	LOSS [training: 0.27937051843192123 | validation: 0.3669406646318761]
	TIME [epoch: 8.36 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34617480834193953		[learning rate: 0.0048101]
	Learning Rate: 0.0048101
	LOSS [training: 0.34617480834193953 | validation: 0.30414456943815826]
	TIME [epoch: 8.36 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3317830143648735		[learning rate: 0.0047988]
	Learning Rate: 0.00479875
	LOSS [training: 0.3317830143648735 | validation: 0.34535848107628453]
	TIME [epoch: 8.36 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42127799399012406		[learning rate: 0.0047874]
	Learning Rate: 0.00478743
	LOSS [training: 0.42127799399012406 | validation: 0.25130499242204457]
	TIME [epoch: 8.38 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42439235564903266		[learning rate: 0.0047761]
	Learning Rate: 0.00477614
	LOSS [training: 0.42439235564903266 | validation: 0.26250270607454423]
	TIME [epoch: 8.36 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32345341298110164		[learning rate: 0.0047649]
	Learning Rate: 0.00476487
	LOSS [training: 0.32345341298110164 | validation: 0.6363765339198661]
	TIME [epoch: 8.36 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37423932152438083		[learning rate: 0.0047536]
	Learning Rate: 0.00475363
	LOSS [training: 0.37423932152438083 | validation: 0.2487527723813583]
	TIME [epoch: 8.36 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3551071128989195		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.3551071128989195 | validation: 0.27631331892931926]
	TIME [epoch: 8.38 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2913654710831381		[learning rate: 0.0047312]
	Learning Rate: 0.00473123
	LOSS [training: 0.2913654710831381 | validation: 0.23110490403104855]
	TIME [epoch: 8.36 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3674960650518027		[learning rate: 0.0047201]
	Learning Rate: 0.00472007
	LOSS [training: 0.3674960650518027 | validation: 0.39540476957088866]
	TIME [epoch: 8.36 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3119249495761238		[learning rate: 0.0047089]
	Learning Rate: 0.00470894
	LOSS [training: 0.3119249495761238 | validation: 0.22143979561849314]
	TIME [epoch: 8.35 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.342974469808085		[learning rate: 0.0046978]
	Learning Rate: 0.00469783
	LOSS [training: 0.342974469808085 | validation: 0.40906618625616087]
	TIME [epoch: 8.38 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32182049587947903		[learning rate: 0.0046868]
	Learning Rate: 0.00468675
	LOSS [training: 0.32182049587947903 | validation: 0.2613904829045903]
	TIME [epoch: 8.35 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3605306829892151		[learning rate: 0.0046757]
	Learning Rate: 0.00467569
	LOSS [training: 0.3605306829892151 | validation: 0.33977880727894466]
	TIME [epoch: 8.35 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33798620389914047		[learning rate: 0.0046647]
	Learning Rate: 0.00466467
	LOSS [training: 0.33798620389914047 | validation: 0.3310288098271905]
	TIME [epoch: 8.36 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30454192988867795		[learning rate: 0.0046537]
	Learning Rate: 0.00465366
	LOSS [training: 0.30454192988867795 | validation: 0.18464565223317897]
	TIME [epoch: 8.38 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5259618089774806		[learning rate: 0.0046427]
	Learning Rate: 0.00464268
	LOSS [training: 0.5259618089774806 | validation: 0.22661432882912308]
	TIME [epoch: 8.35 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27732388053094736		[learning rate: 0.0046317]
	Learning Rate: 0.00463173
	LOSS [training: 0.27732388053094736 | validation: 0.303810907361575]
	TIME [epoch: 8.36 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.332241275068325		[learning rate: 0.0046208]
	Learning Rate: 0.00462081
	LOSS [training: 0.332241275068325 | validation: 0.26773176134836746]
	TIME [epoch: 8.35 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3088399603300798		[learning rate: 0.0046099]
	Learning Rate: 0.00460991
	LOSS [training: 0.3088399603300798 | validation: 0.19770221652941786]
	TIME [epoch: 8.38 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29769821168286054		[learning rate: 0.004599]
	Learning Rate: 0.00459903
	LOSS [training: 0.29769821168286054 | validation: 0.24659911373755183]
	TIME [epoch: 8.35 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27675880910793715		[learning rate: 0.0045882]
	Learning Rate: 0.00458819
	LOSS [training: 0.27675880910793715 | validation: 0.21164294969114172]
	TIME [epoch: 8.36 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3632438742490816		[learning rate: 0.0045774]
	Learning Rate: 0.00457736
	LOSS [training: 0.3632438742490816 | validation: 0.2543871918081081]
	TIME [epoch: 8.35 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2889650684194396		[learning rate: 0.0045666]
	Learning Rate: 0.00456657
	LOSS [training: 0.2889650684194396 | validation: 0.38241474359070077]
	TIME [epoch: 8.38 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2893347463615867		[learning rate: 0.0045558]
	Learning Rate: 0.00455579
	LOSS [training: 0.2893347463615867 | validation: 0.27023122310789494]
	TIME [epoch: 8.35 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.376792398145354		[learning rate: 0.004545]
	Learning Rate: 0.00454505
	LOSS [training: 0.376792398145354 | validation: 0.20860374357828326]
	TIME [epoch: 8.36 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3984805024782432		[learning rate: 0.0045343]
	Learning Rate: 0.00453433
	LOSS [training: 0.3984805024782432 | validation: 0.3220174210830996]
	TIME [epoch: 8.36 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.417653454361378		[learning rate: 0.0045236]
	Learning Rate: 0.00452363
	LOSS [training: 0.417653454361378 | validation: 0.47733883730003146]
	TIME [epoch: 8.38 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.334655233330052		[learning rate: 0.004513]
	Learning Rate: 0.00451296
	LOSS [training: 0.334655233330052 | validation: 0.2518412322220592]
	TIME [epoch: 8.36 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2938212373810488		[learning rate: 0.0045023]
	Learning Rate: 0.00450232
	LOSS [training: 0.2938212373810488 | validation: 0.1975283722793048]
	TIME [epoch: 8.35 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3423315275322718		[learning rate: 0.0044917]
	Learning Rate: 0.00449169
	LOSS [training: 0.3423315275322718 | validation: 0.30069415991529824]
	TIME [epoch: 8.36 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34319106021529744		[learning rate: 0.0044811]
	Learning Rate: 0.0044811
	LOSS [training: 0.34319106021529744 | validation: 0.29559161966790143]
	TIME [epoch: 8.37 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4161112749282778		[learning rate: 0.0044705]
	Learning Rate: 0.00447053
	LOSS [training: 0.4161112749282778 | validation: 0.21189503442301377]
	TIME [epoch: 8.35 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39982863742994346		[learning rate: 0.00446]
	Learning Rate: 0.00445998
	LOSS [training: 0.39982863742994346 | validation: 0.272747798354229]
	TIME [epoch: 8.35 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33687124114709255		[learning rate: 0.0044495]
	Learning Rate: 0.00444946
	LOSS [training: 0.33687124114709255 | validation: 0.35830864529016326]
	TIME [epoch: 8.36 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3416819706686618		[learning rate: 0.004439]
	Learning Rate: 0.00443897
	LOSS [training: 0.3416819706686618 | validation: 0.49306955540045183]
	TIME [epoch: 8.37 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40960466227408787		[learning rate: 0.0044285]
	Learning Rate: 0.0044285
	LOSS [training: 0.40960466227408787 | validation: 0.5306239873244634]
	TIME [epoch: 8.36 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38875560459177194		[learning rate: 0.0044181]
	Learning Rate: 0.00441805
	LOSS [training: 0.38875560459177194 | validation: 0.17293213852333067]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.331865126853676		[learning rate: 0.0044076]
	Learning Rate: 0.00440763
	LOSS [training: 0.331865126853676 | validation: 0.26257817465169125]
	TIME [epoch: 8.37 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40288959989464523		[learning rate: 0.0043972]
	Learning Rate: 0.00439723
	LOSS [training: 0.40288959989464523 | validation: 0.680992098594268]
	TIME [epoch: 8.37 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48522713735977396		[learning rate: 0.0043869]
	Learning Rate: 0.00438686
	LOSS [training: 0.48522713735977396 | validation: 0.42052988604419206]
	TIME [epoch: 8.35 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29950974100126804		[learning rate: 0.0043765]
	Learning Rate: 0.00437651
	LOSS [training: 0.29950974100126804 | validation: 0.24288586466378448]
	TIME [epoch: 8.35 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3550888687396116		[learning rate: 0.0043662]
	Learning Rate: 0.00436619
	LOSS [training: 0.3550888687396116 | validation: 0.38262393360942826]
	TIME [epoch: 8.37 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29897913563132555		[learning rate: 0.0043559]
	Learning Rate: 0.00435589
	LOSS [training: 0.29897913563132555 | validation: 0.1865558402657532]
	TIME [epoch: 8.37 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4128545870182908		[learning rate: 0.0043456]
	Learning Rate: 0.00434561
	LOSS [training: 0.4128545870182908 | validation: 0.25403247435043663]
	TIME [epoch: 8.35 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4338769042759044		[learning rate: 0.0043354]
	Learning Rate: 0.00433536
	LOSS [training: 0.4338769042759044 | validation: 0.28300532074325635]
	TIME [epoch: 8.35 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3544628344897317		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.3544628344897317 | validation: 0.2721469692942183]
	TIME [epoch: 8.37 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3135872070227711		[learning rate: 0.0043149]
	Learning Rate: 0.00431494
	LOSS [training: 0.3135872070227711 | validation: 0.3674134521076181]
	TIME [epoch: 8.37 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38457752843365917		[learning rate: 0.0043048]
	Learning Rate: 0.00430476
	LOSS [training: 0.38457752843365917 | validation: 0.3159257458758437]
	TIME [epoch: 8.35 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3450389516713087		[learning rate: 0.0042946]
	Learning Rate: 0.0042946
	LOSS [training: 0.3450389516713087 | validation: 0.322709810660213]
	TIME [epoch: 8.35 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43816027881003256		[learning rate: 0.0042845]
	Learning Rate: 0.00428447
	LOSS [training: 0.43816027881003256 | validation: 0.28803380435842907]
	TIME [epoch: 8.37 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2749135360589401		[learning rate: 0.0042744]
	Learning Rate: 0.00427437
	LOSS [training: 0.2749135360589401 | validation: 0.4323109494032368]
	TIME [epoch: 8.36 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34248462101228994		[learning rate: 0.0042643]
	Learning Rate: 0.00426428
	LOSS [training: 0.34248462101228994 | validation: 0.2020697823052515]
	TIME [epoch: 8.35 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36852021382106775		[learning rate: 0.0042542]
	Learning Rate: 0.00425423
	LOSS [training: 0.36852021382106775 | validation: 0.25564345001921324]
	TIME [epoch: 8.35 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31644526979270066		[learning rate: 0.0042442]
	Learning Rate: 0.00424419
	LOSS [training: 0.31644526979270066 | validation: 0.30953684021460515]
	TIME [epoch: 8.36 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3200369686637398		[learning rate: 0.0042342]
	Learning Rate: 0.00423418
	LOSS [training: 0.3200369686637398 | validation: 0.3028243793432978]
	TIME [epoch: 8.36 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3767911290870395		[learning rate: 0.0042242]
	Learning Rate: 0.00422419
	LOSS [training: 0.3767911290870395 | validation: 0.2601534423005625]
	TIME [epoch: 8.35 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28038057621207824		[learning rate: 0.0042142]
	Learning Rate: 0.00421423
	LOSS [training: 0.28038057621207824 | validation: 0.32677628348946003]
	TIME [epoch: 8.35 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30388343862648226		[learning rate: 0.0042043]
	Learning Rate: 0.00420429
	LOSS [training: 0.30388343862648226 | validation: 0.2072761631866078]
	TIME [epoch: 8.37 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4100824368418946		[learning rate: 0.0041944]
	Learning Rate: 0.00419437
	LOSS [training: 0.4100824368418946 | validation: 0.3524207034471466]
	TIME [epoch: 8.37 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3697733152423638		[learning rate: 0.0041845]
	Learning Rate: 0.00418448
	LOSS [training: 0.3697733152423638 | validation: 0.37788525494228514]
	TIME [epoch: 8.35 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2730148593905678		[learning rate: 0.0041746]
	Learning Rate: 0.0041746
	LOSS [training: 0.2730148593905678 | validation: 0.2739284903634731]
	TIME [epoch: 8.35 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37041945434392554		[learning rate: 0.0041648]
	Learning Rate: 0.00416476
	LOSS [training: 0.37041945434392554 | validation: 0.3894073289566273]
	TIME [epoch: 8.37 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3132870909241885		[learning rate: 0.0041549]
	Learning Rate: 0.00415493
	LOSS [training: 0.3132870909241885 | validation: 0.2486536601970459]
	TIME [epoch: 8.35 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4232477312247778		[learning rate: 0.0041451]
	Learning Rate: 0.00414513
	LOSS [training: 0.4232477312247778 | validation: 0.39117350133925255]
	TIME [epoch: 8.35 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34728405481905644		[learning rate: 0.0041354]
	Learning Rate: 0.00413535
	LOSS [training: 0.34728405481905644 | validation: 0.2695342841494963]
	TIME [epoch: 8.35 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31581623188244057		[learning rate: 0.0041256]
	Learning Rate: 0.0041256
	LOSS [training: 0.31581623188244057 | validation: 0.2885113053920051]
	TIME [epoch: 8.37 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41459892135031007		[learning rate: 0.0041159]
	Learning Rate: 0.00411587
	LOSS [training: 0.41459892135031007 | validation: 0.21496074243671054]
	TIME [epoch: 8.35 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.506767784584236		[learning rate: 0.0041062]
	Learning Rate: 0.00410616
	LOSS [training: 0.506767784584236 | validation: 0.3284133375385203]
	TIME [epoch: 8.35 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3427310523838372		[learning rate: 0.0040965]
	Learning Rate: 0.00409647
	LOSS [training: 0.3427310523838372 | validation: 0.22605809757647052]
	TIME [epoch: 8.34 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3785007793253457		[learning rate: 0.0040868]
	Learning Rate: 0.00408681
	LOSS [training: 0.3785007793253457 | validation: 0.33929966518923776]
	TIME [epoch: 8.37 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34735606519341744		[learning rate: 0.0040772]
	Learning Rate: 0.00407717
	LOSS [training: 0.34735606519341744 | validation: 0.26241406405451806]
	TIME [epoch: 8.35 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41025353487664695		[learning rate: 0.0040676]
	Learning Rate: 0.00406755
	LOSS [training: 0.41025353487664695 | validation: 0.23252117725580654]
	TIME [epoch: 8.35 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27702385524415407		[learning rate: 0.004058]
	Learning Rate: 0.00405796
	LOSS [training: 0.27702385524415407 | validation: 0.2437080960791187]
	TIME [epoch: 8.35 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33132375329675356		[learning rate: 0.0040484]
	Learning Rate: 0.00404839
	LOSS [training: 0.33132375329675356 | validation: 0.5549911626748744]
	TIME [epoch: 8.37 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30929286629935226		[learning rate: 0.0040388]
	Learning Rate: 0.00403884
	LOSS [training: 0.30929286629935226 | validation: 0.41600117441052387]
	TIME [epoch: 8.35 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43513653217536097		[learning rate: 0.0040293]
	Learning Rate: 0.00402931
	LOSS [training: 0.43513653217536097 | validation: 0.21004252850194607]
	TIME [epoch: 8.35 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3712424972441998		[learning rate: 0.0040198]
	Learning Rate: 0.00401981
	LOSS [training: 0.3712424972441998 | validation: 0.3005021551588023]
	TIME [epoch: 8.35 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5463502146300641		[learning rate: 0.0040103]
	Learning Rate: 0.00401032
	LOSS [training: 0.5463502146300641 | validation: 0.25900067785543696]
	TIME [epoch: 8.38 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29556139755117866		[learning rate: 0.0040009]
	Learning Rate: 0.00400086
	LOSS [training: 0.29556139755117866 | validation: 0.440818817114963]
	TIME [epoch: 8.35 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35320927041117106		[learning rate: 0.0039914]
	Learning Rate: 0.00399143
	LOSS [training: 0.35320927041117106 | validation: 0.3317739167993784]
	TIME [epoch: 8.35 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32190402146534514		[learning rate: 0.003982]
	Learning Rate: 0.00398201
	LOSS [training: 0.32190402146534514 | validation: 0.3170782403309499]
	TIME [epoch: 8.35 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2932097830119716		[learning rate: 0.0039726]
	Learning Rate: 0.00397262
	LOSS [training: 0.2932097830119716 | validation: 0.3561469993320622]
	TIME [epoch: 8.37 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3064851428967047		[learning rate: 0.0039632]
	Learning Rate: 0.00396325
	LOSS [training: 0.3064851428967047 | validation: 0.3109841285271764]
	TIME [epoch: 8.35 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3067106117258521		[learning rate: 0.0039539]
	Learning Rate: 0.0039539
	LOSS [training: 0.3067106117258521 | validation: 0.21040565571152467]
	TIME [epoch: 8.35 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24622503779009336		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.24622503779009336 | validation: 0.3868166486166192]
	TIME [epoch: 8.34 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29841410474842583		[learning rate: 0.0039353]
	Learning Rate: 0.00393527
	LOSS [training: 0.29841410474842583 | validation: 0.22630704572141785]
	TIME [epoch: 8.38 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33311712265318366		[learning rate: 0.003926]
	Learning Rate: 0.00392599
	LOSS [training: 0.33311712265318366 | validation: 0.2863441679021568]
	TIME [epoch: 8.35 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27086041593936266		[learning rate: 0.0039167]
	Learning Rate: 0.00391672
	LOSS [training: 0.27086041593936266 | validation: 0.4599045699407279]
	TIME [epoch: 8.35 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36034476848853014		[learning rate: 0.0039075]
	Learning Rate: 0.00390749
	LOSS [training: 0.36034476848853014 | validation: 0.394277674666471]
	TIME [epoch: 8.35 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2752788946182871		[learning rate: 0.0038983]
	Learning Rate: 0.00389827
	LOSS [training: 0.2752788946182871 | validation: 0.28773345193196187]
	TIME [epoch: 8.37 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2571122331692727		[learning rate: 0.0038891]
	Learning Rate: 0.00388907
	LOSS [training: 0.2571122331692727 | validation: 0.20264387711226223]
	TIME [epoch: 8.36 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39449641217971354		[learning rate: 0.0038799]
	Learning Rate: 0.0038799
	LOSS [training: 0.39449641217971354 | validation: 0.41745754156467646]
	TIME [epoch: 8.35 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2973038330896694		[learning rate: 0.0038707]
	Learning Rate: 0.00387075
	LOSS [training: 0.2973038330896694 | validation: 0.17722051447435727]
	TIME [epoch: 8.36 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3144079135053811		[learning rate: 0.0038616]
	Learning Rate: 0.00386162
	LOSS [training: 0.3144079135053811 | validation: 0.39755987539140347]
	TIME [epoch: 8.37 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3201345210955309		[learning rate: 0.0038525]
	Learning Rate: 0.00385251
	LOSS [training: 0.3201345210955309 | validation: 0.15912861894125624]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_454.pth
	Model improved!!!
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30937574263810147		[learning rate: 0.0038434]
	Learning Rate: 0.00384342
	LOSS [training: 0.30937574263810147 | validation: 0.5824008980124327]
	TIME [epoch: 8.35 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3423009621947942		[learning rate: 0.0038344]
	Learning Rate: 0.00383435
	LOSS [training: 0.3423009621947942 | validation: 0.3200809798637617]
	TIME [epoch: 8.35 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3766750780847882		[learning rate: 0.0038253]
	Learning Rate: 0.00382531
	LOSS [training: 0.3766750780847882 | validation: 0.3097254495643134]
	TIME [epoch: 8.38 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36750791083488316		[learning rate: 0.0038163]
	Learning Rate: 0.00381629
	LOSS [training: 0.36750791083488316 | validation: 0.34446317960924244]
	TIME [epoch: 8.35 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27178080680445543		[learning rate: 0.0038073]
	Learning Rate: 0.00380728
	LOSS [training: 0.27178080680445543 | validation: 0.21694790628042226]
	TIME [epoch: 8.35 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33361158079678077		[learning rate: 0.0037983]
	Learning Rate: 0.0037983
	LOSS [training: 0.33361158079678077 | validation: 0.3471481331835047]
	TIME [epoch: 8.36 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3053872948477353		[learning rate: 0.0037893]
	Learning Rate: 0.00378934
	LOSS [training: 0.3053872948477353 | validation: 0.2950052837888616]
	TIME [epoch: 8.38 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2663069420229579		[learning rate: 0.0037804]
	Learning Rate: 0.00378041
	LOSS [training: 0.2663069420229579 | validation: 0.16090710863565455]
	TIME [epoch: 8.35 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42148482781941315		[learning rate: 0.0037715]
	Learning Rate: 0.00377149
	LOSS [training: 0.42148482781941315 | validation: 0.20245803315032526]
	TIME [epoch: 8.36 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3374026912656287		[learning rate: 0.0037626]
	Learning Rate: 0.00376259
	LOSS [training: 0.3374026912656287 | validation: 0.32676501714446327]
	TIME [epoch: 8.35 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3886938831597951		[learning rate: 0.0037537]
	Learning Rate: 0.00375372
	LOSS [training: 0.3886938831597951 | validation: 0.22831282595748192]
	TIME [epoch: 8.38 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31582908603132615		[learning rate: 0.0037449]
	Learning Rate: 0.00374486
	LOSS [training: 0.31582908603132615 | validation: 0.3819122007363489]
	TIME [epoch: 8.35 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26380305014082917		[learning rate: 0.003736]
	Learning Rate: 0.00373603
	LOSS [training: 0.26380305014082917 | validation: 0.18534147223143804]
	TIME [epoch: 8.35 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3319215800997255		[learning rate: 0.0037272]
	Learning Rate: 0.00372722
	LOSS [training: 0.3319215800997255 | validation: 0.24064518203865065]
	TIME [epoch: 8.35 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2940277105399886		[learning rate: 0.0037184]
	Learning Rate: 0.00371842
	LOSS [training: 0.2940277105399886 | validation: 0.31493233388732145]
	TIME [epoch: 8.38 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.277661625538968		[learning rate: 0.0037097]
	Learning Rate: 0.00370965
	LOSS [training: 0.277661625538968 | validation: 0.3437202496651178]
	TIME [epoch: 8.35 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2706723043478135		[learning rate: 0.0037009]
	Learning Rate: 0.0037009
	LOSS [training: 0.2706723043478135 | validation: 0.3248867289974491]
	TIME [epoch: 8.35 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31448060900853825		[learning rate: 0.0036922]
	Learning Rate: 0.00369217
	LOSS [training: 0.31448060900853825 | validation: 0.1829963309618386]
	TIME [epoch: 8.35 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27981944780152557		[learning rate: 0.0036835]
	Learning Rate: 0.00368346
	LOSS [training: 0.27981944780152557 | validation: 0.17251022334091742]
	TIME [epoch: 8.38 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.353961783067544		[learning rate: 0.0036748]
	Learning Rate: 0.00367478
	LOSS [training: 0.353961783067544 | validation: 0.3066616856477114]
	TIME [epoch: 8.35 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.361596219139865		[learning rate: 0.0036661]
	Learning Rate: 0.00366611
	LOSS [training: 0.361596219139865 | validation: 0.3167516528958929]
	TIME [epoch: 8.35 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32987121902927774		[learning rate: 0.0036575]
	Learning Rate: 0.00365746
	LOSS [training: 0.32987121902927774 | validation: 0.20388428001174383]
	TIME [epoch: 8.35 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25363255901283277		[learning rate: 0.0036488]
	Learning Rate: 0.00364883
	LOSS [training: 0.25363255901283277 | validation: 0.29633426697512066]
	TIME [epoch: 8.38 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2973268878447755		[learning rate: 0.0036402]
	Learning Rate: 0.00364022
	LOSS [training: 0.2973268878447755 | validation: 0.2011623219956781]
	TIME [epoch: 8.36 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3528476118301411		[learning rate: 0.0036316]
	Learning Rate: 0.00363164
	LOSS [training: 0.3528476118301411 | validation: 0.23477337841030732]
	TIME [epoch: 8.35 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3200239085291465		[learning rate: 0.0036231]
	Learning Rate: 0.00362307
	LOSS [training: 0.3200239085291465 | validation: 0.2624264580892294]
	TIME [epoch: 8.36 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28337951914202786		[learning rate: 0.0036145]
	Learning Rate: 0.00361453
	LOSS [training: 0.28337951914202786 | validation: 0.33018217100807395]
	TIME [epoch: 8.37 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26281392963029476		[learning rate: 0.003606]
	Learning Rate: 0.003606
	LOSS [training: 0.26281392963029476 | validation: 0.3634633990793178]
	TIME [epoch: 8.35 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24437728118102195		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.24437728118102195 | validation: 0.20098742422917854]
	TIME [epoch: 8.35 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2994291114630386		[learning rate: 0.003589]
	Learning Rate: 0.00358901
	LOSS [training: 0.2994291114630386 | validation: 0.21392547056275063]
	TIME [epoch: 8.35 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2389927299083995		[learning rate: 0.0035805]
	Learning Rate: 0.00358054
	LOSS [training: 0.2389927299083995 | validation: 0.24937508187378915]
	TIME [epoch: 8.37 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2745372615277794		[learning rate: 0.0035721]
	Learning Rate: 0.0035721
	LOSS [training: 0.2745372615277794 | validation: 0.22774167726688366]
	TIME [epoch: 8.36 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27312325355254846		[learning rate: 0.0035637]
	Learning Rate: 0.00356367
	LOSS [training: 0.27312325355254846 | validation: 0.22281354119529587]
	TIME [epoch: 8.35 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25862101570161194		[learning rate: 0.0035553]
	Learning Rate: 0.00355526
	LOSS [training: 0.25862101570161194 | validation: 0.2775450087859536]
	TIME [epoch: 8.36 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24194396798859122		[learning rate: 0.0035469]
	Learning Rate: 0.00354688
	LOSS [training: 0.24194396798859122 | validation: 0.16553617185261782]
	TIME [epoch: 8.38 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24585517792185185		[learning rate: 0.0035385]
	Learning Rate: 0.00353851
	LOSS [training: 0.24585517792185185 | validation: 0.19051801028874238]
	TIME [epoch: 8.35 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23954850879378387		[learning rate: 0.0035302]
	Learning Rate: 0.00353016
	LOSS [training: 0.23954850879378387 | validation: 0.379567881390164]
	TIME [epoch: 8.35 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29074656400629595		[learning rate: 0.0035218]
	Learning Rate: 0.00352184
	LOSS [training: 0.29074656400629595 | validation: 0.36289113280211327]
	TIME [epoch: 8.36 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2719231626081008		[learning rate: 0.0035135]
	Learning Rate: 0.00351353
	LOSS [training: 0.2719231626081008 | validation: 0.21143965230854714]
	TIME [epoch: 8.37 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3055857268723553		[learning rate: 0.0035052]
	Learning Rate: 0.00350524
	LOSS [training: 0.3055857268723553 | validation: 0.22174151747686585]
	TIME [epoch: 8.35 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2733387518953036		[learning rate: 0.003497]
	Learning Rate: 0.00349697
	LOSS [training: 0.2733387518953036 | validation: 0.3833542037639831]
	TIME [epoch: 8.36 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30678850459170137		[learning rate: 0.0034887]
	Learning Rate: 0.00348872
	LOSS [training: 0.30678850459170137 | validation: 0.20866324466898167]
	TIME [epoch: 8.36 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30692178620401067		[learning rate: 0.0034805]
	Learning Rate: 0.00348049
	LOSS [training: 0.30692178620401067 | validation: 0.1607910998388987]
	TIME [epoch: 8.37 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34324214478569515		[learning rate: 0.0034723]
	Learning Rate: 0.00347228
	LOSS [training: 0.34324214478569515 | validation: 0.2117582800753502]
	TIME [epoch: 8.35 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28229871143595053		[learning rate: 0.0034641]
	Learning Rate: 0.00346409
	LOSS [training: 0.28229871143595053 | validation: 0.40342073463541084]
	TIME [epoch: 8.35 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.368509149419631		[learning rate: 0.0034559]
	Learning Rate: 0.00345592
	LOSS [training: 0.368509149419631 | validation: 0.37535827190974375]
	TIME [epoch: 8.36 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3659218191598503		[learning rate: 0.0034478]
	Learning Rate: 0.00344777
	LOSS [training: 0.3659218191598503 | validation: 0.3399779667052394]
	TIME [epoch: 8.37 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3136249626375293		[learning rate: 0.0034396]
	Learning Rate: 0.00343964
	LOSS [training: 0.3136249626375293 | validation: 0.8279649744600067]
	TIME [epoch: 8.36 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43219708740816537		[learning rate: 0.0034315]
	Learning Rate: 0.00343152
	LOSS [training: 0.43219708740816537 | validation: 0.21141197248226187]
	TIME [epoch: 8.35 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2980322421122874		[learning rate: 0.0034234]
	Learning Rate: 0.00342343
	LOSS [training: 0.2980322421122874 | validation: 0.3454451292137347]
	TIME [epoch: 8.36 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2989497003063147		[learning rate: 0.0034154]
	Learning Rate: 0.00341535
	LOSS [training: 0.2989497003063147 | validation: 0.2582633657818724]
	TIME [epoch: 8.37 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21623619499812405		[learning rate: 0.0034073]
	Learning Rate: 0.0034073
	LOSS [training: 0.21623619499812405 | validation: 0.2603207441353222]
	TIME [epoch: 8.35 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29313838368930045		[learning rate: 0.0033993]
	Learning Rate: 0.00339926
	LOSS [training: 0.29313838368930045 | validation: 0.22521615257031521]
	TIME [epoch: 8.35 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.261534642649216		[learning rate: 0.0033912]
	Learning Rate: 0.00339124
	LOSS [training: 0.261534642649216 | validation: 0.19891634393519328]
	TIME [epoch: 8.36 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31936226242118904		[learning rate: 0.0033832]
	Learning Rate: 0.00338324
	LOSS [training: 0.31936226242118904 | validation: 0.19705129995183487]
	TIME [epoch: 8.36 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2917089903750854		[learning rate: 0.0033753]
	Learning Rate: 0.00337526
	LOSS [training: 0.2917089903750854 | validation: 0.3855389593735489]
	TIME [epoch: 8.35 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4140714349054078		[learning rate: 0.0033673]
	Learning Rate: 0.0033673
	LOSS [training: 0.4140714349054078 | validation: 0.22478652634335639]
	TIME [epoch: 8.35 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2649996633818684		[learning rate: 0.0033594]
	Learning Rate: 0.00335936
	LOSS [training: 0.2649996633818684 | validation: 0.34509301740074894]
	TIME [epoch: 8.36 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25822527470695217		[learning rate: 0.0033514]
	Learning Rate: 0.00335143
	LOSS [training: 0.25822527470695217 | validation: 0.18895183882035216]
	TIME [epoch: 8.36 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.215512103391201		[learning rate: 0.0033435]
	Learning Rate: 0.00334353
	LOSS [training: 0.215512103391201 | validation: 0.3140275333765696]
	TIME [epoch: 8.36 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2822944446477118		[learning rate: 0.0033356]
	Learning Rate: 0.00333564
	LOSS [training: 0.2822944446477118 | validation: 0.3126865977299397]
	TIME [epoch: 8.35 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2277919503743581		[learning rate: 0.0033278]
	Learning Rate: 0.00332777
	LOSS [training: 0.2277919503743581 | validation: 0.17719887096450598]
	TIME [epoch: 8.36 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.221810945608471		[learning rate: 0.0033199]
	Learning Rate: 0.00331992
	LOSS [training: 0.221810945608471 | validation: 0.23243035334902867]
	TIME [epoch: 8.36 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2295434095113044		[learning rate: 0.0033121]
	Learning Rate: 0.00331209
	LOSS [training: 0.2295434095113044 | validation: 0.28846379934186595]
	TIME [epoch: 8.35 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29953001377108956		[learning rate: 0.0033043]
	Learning Rate: 0.00330428
	LOSS [training: 0.29953001377108956 | validation: 0.19986396115701532]
	TIME [epoch: 8.35 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28001911259879975		[learning rate: 0.0032965]
	Learning Rate: 0.00329649
	LOSS [training: 0.28001911259879975 | validation: 0.23074017344075026]
	TIME [epoch: 8.36 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2655647653266922		[learning rate: 0.0032887]
	Learning Rate: 0.00328871
	LOSS [training: 0.2655647653266922 | validation: 0.40888297986020594]
	TIME [epoch: 8.36 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28760489455013133		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.28760489455013133 | validation: 0.2337449859881484]
	TIME [epoch: 8.35 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2777824604436225		[learning rate: 0.0032732]
	Learning Rate: 0.00327321
	LOSS [training: 0.2777824604436225 | validation: 0.15347293196447437]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_523.pth
	Model improved!!!
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2202216128891879		[learning rate: 0.0032655]
	Learning Rate: 0.00326549
	LOSS [training: 0.2202216128891879 | validation: 0.14465692911611316]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_524.pth
	Model improved!!!
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2597751614522788		[learning rate: 0.0032578]
	Learning Rate: 0.00325779
	LOSS [training: 0.2597751614522788 | validation: 0.24298055073670816]
	TIME [epoch: 8.36 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2682925070387757		[learning rate: 0.0032501]
	Learning Rate: 0.00325011
	LOSS [training: 0.2682925070387757 | validation: 0.17651892269242114]
	TIME [epoch: 8.35 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2426604660868848		[learning rate: 0.0032424]
	Learning Rate: 0.00324244
	LOSS [training: 0.2426604660868848 | validation: 0.1552953981293307]
	TIME [epoch: 8.35 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24091511339138486		[learning rate: 0.0032348]
	Learning Rate: 0.00323479
	LOSS [training: 0.24091511339138486 | validation: 0.3239455473780842]
	TIME [epoch: 8.37 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42557026508535784		[learning rate: 0.0032272]
	Learning Rate: 0.00322716
	LOSS [training: 0.42557026508535784 | validation: 0.18631259602681977]
	TIME [epoch: 8.36 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2630766369582276		[learning rate: 0.0032195]
	Learning Rate: 0.00321955
	LOSS [training: 0.2630766369582276 | validation: 0.28467592889363436]
	TIME [epoch: 8.36 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22307805952726115		[learning rate: 0.003212]
	Learning Rate: 0.00321195
	LOSS [training: 0.22307805952726115 | validation: 0.1835948653475476]
	TIME [epoch: 8.35 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2428877825882867		[learning rate: 0.0032044]
	Learning Rate: 0.00320438
	LOSS [training: 0.2428877825882867 | validation: 0.32394673388433526]
	TIME [epoch: 8.37 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2685415165137315		[learning rate: 0.0031968]
	Learning Rate: 0.00319682
	LOSS [training: 0.2685415165137315 | validation: 0.21711275886075448]
	TIME [epoch: 8.35 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3245154268031584		[learning rate: 0.0031893]
	Learning Rate: 0.00318928
	LOSS [training: 0.3245154268031584 | validation: 0.2972072699423804]
	TIME [epoch: 8.34 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24710812794121564		[learning rate: 0.0031818]
	Learning Rate: 0.00318175
	LOSS [training: 0.24710812794121564 | validation: 0.16548698131532358]
	TIME [epoch: 8.35 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2537195981469372		[learning rate: 0.0031742]
	Learning Rate: 0.00317425
	LOSS [training: 0.2537195981469372 | validation: 0.23734939942117883]
	TIME [epoch: 8.37 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33090696081044324		[learning rate: 0.0031668]
	Learning Rate: 0.00316676
	LOSS [training: 0.33090696081044324 | validation: 0.36881121440169884]
	TIME [epoch: 8.35 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.326752191242598		[learning rate: 0.0031593]
	Learning Rate: 0.00315929
	LOSS [training: 0.326752191242598 | validation: 0.23567892415270847]
	TIME [epoch: 8.35 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29533578745993044		[learning rate: 0.0031518]
	Learning Rate: 0.00315184
	LOSS [training: 0.29533578745993044 | validation: 0.17898824711749545]
	TIME [epoch: 8.34 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3007570517547273		[learning rate: 0.0031444]
	Learning Rate: 0.0031444
	LOSS [training: 0.3007570517547273 | validation: 0.2714848970378477]
	TIME [epoch: 8.37 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21919120502511316		[learning rate: 0.003137]
	Learning Rate: 0.00313699
	LOSS [training: 0.21919120502511316 | validation: 0.18597761228605242]
	TIME [epoch: 8.35 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2559088109686375		[learning rate: 0.0031296]
	Learning Rate: 0.00312959
	LOSS [training: 0.2559088109686375 | validation: 0.18886966564545155]
	TIME [epoch: 8.35 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2834428137118873		[learning rate: 0.0031222]
	Learning Rate: 0.00312221
	LOSS [training: 0.2834428137118873 | validation: 0.17956105819432144]
	TIME [epoch: 8.35 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2748253349981026		[learning rate: 0.0031148]
	Learning Rate: 0.00311484
	LOSS [training: 0.2748253349981026 | validation: 0.2758065330560063]
	TIME [epoch: 8.37 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2859813542058199		[learning rate: 0.0031075]
	Learning Rate: 0.00310749
	LOSS [training: 0.2859813542058199 | validation: 0.3280328915250294]
	TIME [epoch: 8.35 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27986963900554584		[learning rate: 0.0031002]
	Learning Rate: 0.00310016
	LOSS [training: 0.27986963900554584 | validation: 0.5427678606533939]
	TIME [epoch: 8.34 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29868385420387644		[learning rate: 0.0030929]
	Learning Rate: 0.00309285
	LOSS [training: 0.29868385420387644 | validation: 0.20260763967624035]
	TIME [epoch: 8.35 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2283296180581813		[learning rate: 0.0030856]
	Learning Rate: 0.00308556
	LOSS [training: 0.2283296180581813 | validation: 0.1779730623677383]
	TIME [epoch: 8.37 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21314264130175445		[learning rate: 0.0030783]
	Learning Rate: 0.00307828
	LOSS [training: 0.21314264130175445 | validation: 0.166885615478925]
	TIME [epoch: 8.35 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20432824065109148		[learning rate: 0.003071]
	Learning Rate: 0.00307102
	LOSS [training: 0.20432824065109148 | validation: 0.2600685692549523]
	TIME [epoch: 8.35 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22980181831808935		[learning rate: 0.0030638]
	Learning Rate: 0.00306377
	LOSS [training: 0.22980181831808935 | validation: 0.20091177385903625]
	TIME [epoch: 8.35 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24285295250059166		[learning rate: 0.0030565]
	Learning Rate: 0.00305654
	LOSS [training: 0.24285295250059166 | validation: 0.12975378128346648]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_552.pth
	Model improved!!!
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22209078554016384		[learning rate: 0.0030493]
	Learning Rate: 0.00304933
	LOSS [training: 0.22209078554016384 | validation: 0.16186585037472773]
	TIME [epoch: 8.35 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2342269387487134		[learning rate: 0.0030421]
	Learning Rate: 0.00304214
	LOSS [training: 0.2342269387487134 | validation: 0.17323861958316467]
	TIME [epoch: 8.35 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23997123641070733		[learning rate: 0.003035]
	Learning Rate: 0.00303497
	LOSS [training: 0.23997123641070733 | validation: 0.24791092738332587]
	TIME [epoch: 8.35 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2542197645923686		[learning rate: 0.0030278]
	Learning Rate: 0.00302781
	LOSS [training: 0.2542197645923686 | validation: 0.18117031634103767]
	TIME [epoch: 8.37 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2968103426047797		[learning rate: 0.0030207]
	Learning Rate: 0.00302066
	LOSS [training: 0.2968103426047797 | validation: 0.21697805273134896]
	TIME [epoch: 8.36 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22768169987399323		[learning rate: 0.0030135]
	Learning Rate: 0.00301354
	LOSS [training: 0.22768169987399323 | validation: 0.1988036832924164]
	TIME [epoch: 8.35 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2518677263505992		[learning rate: 0.0030064]
	Learning Rate: 0.00300643
	LOSS [training: 0.2518677263505992 | validation: 0.2809379336616541]
	TIME [epoch: 8.35 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23046129864490497		[learning rate: 0.0029993]
	Learning Rate: 0.00299934
	LOSS [training: 0.23046129864490497 | validation: 0.18628625407339194]
	TIME [epoch: 8.37 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22996456176914065		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.22996456176914065 | validation: 0.1547066869315518]
	TIME [epoch: 8.36 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2340135894793974		[learning rate: 0.0029852]
	Learning Rate: 0.00298521
	LOSS [training: 0.2340135894793974 | validation: 0.18211809642864024]
	TIME [epoch: 8.35 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22847358305498172		[learning rate: 0.0029782]
	Learning Rate: 0.00297816
	LOSS [training: 0.22847358305498172 | validation: 0.16896936005953256]
	TIME [epoch: 8.34 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2260197970528063		[learning rate: 0.0029711]
	Learning Rate: 0.00297114
	LOSS [training: 0.2260197970528063 | validation: 0.21338721543500244]
	TIME [epoch: 8.38 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2844288335877767		[learning rate: 0.0029641]
	Learning Rate: 0.00296413
	LOSS [training: 0.2844288335877767 | validation: 0.18213477125095182]
	TIME [epoch: 8.35 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23971057749680397		[learning rate: 0.0029571]
	Learning Rate: 0.00295714
	LOSS [training: 0.23971057749680397 | validation: 0.22537929531280232]
	TIME [epoch: 8.35 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2220320614486831		[learning rate: 0.0029502]
	Learning Rate: 0.00295016
	LOSS [training: 0.2220320614486831 | validation: 0.2346639194832203]
	TIME [epoch: 8.35 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23119224543343858		[learning rate: 0.0029432]
	Learning Rate: 0.0029432
	LOSS [training: 0.23119224543343858 | validation: 0.26676699526011693]
	TIME [epoch: 8.37 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24097044109745744		[learning rate: 0.0029363]
	Learning Rate: 0.00293626
	LOSS [training: 0.24097044109745744 | validation: 0.13176962291471772]
	TIME [epoch: 8.35 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2544543761072232		[learning rate: 0.0029293]
	Learning Rate: 0.00292934
	LOSS [training: 0.2544543761072232 | validation: 0.3968923877948658]
	TIME [epoch: 8.35 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3238113406039595		[learning rate: 0.0029224]
	Learning Rate: 0.00292243
	LOSS [training: 0.3238113406039595 | validation: 0.24054364716188578]
	TIME [epoch: 8.35 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23737260078312464		[learning rate: 0.0029155]
	Learning Rate: 0.00291553
	LOSS [training: 0.23737260078312464 | validation: 0.21249954106241215]
	TIME [epoch: 8.38 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.229343567938428		[learning rate: 0.0029087]
	Learning Rate: 0.00290866
	LOSS [training: 0.229343567938428 | validation: 0.18813932785988963]
	TIME [epoch: 8.35 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2175257714604036		[learning rate: 0.0029018]
	Learning Rate: 0.00290179
	LOSS [training: 0.2175257714604036 | validation: 0.1863134935125214]
	TIME [epoch: 8.35 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2748267668054152		[learning rate: 0.0028949]
	Learning Rate: 0.00289495
	LOSS [training: 0.2748267668054152 | validation: 0.16941559071951698]
	TIME [epoch: 8.35 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23740059244729342		[learning rate: 0.0028881]
	Learning Rate: 0.00288812
	LOSS [training: 0.23740059244729342 | validation: 0.25296904990269525]
	TIME [epoch: 8.38 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2150962847594758		[learning rate: 0.0028813]
	Learning Rate: 0.00288131
	LOSS [training: 0.2150962847594758 | validation: 0.1367724370041179]
	TIME [epoch: 8.35 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20826436237373797		[learning rate: 0.0028745]
	Learning Rate: 0.00287451
	LOSS [training: 0.20826436237373797 | validation: 0.175373197489356]
	TIME [epoch: 8.34 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23632459405060963		[learning rate: 0.0028677]
	Learning Rate: 0.00286773
	LOSS [training: 0.23632459405060963 | validation: 0.2839807539539528]
	TIME [epoch: 8.35 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28654759717854816		[learning rate: 0.002861]
	Learning Rate: 0.00286097
	LOSS [training: 0.28654759717854816 | validation: 0.24657112386298857]
	TIME [epoch: 8.37 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20978927909821438		[learning rate: 0.0028542]
	Learning Rate: 0.00285422
	LOSS [training: 0.20978927909821438 | validation: 0.162905782645788]
	TIME [epoch: 8.35 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1914373100800916		[learning rate: 0.0028475]
	Learning Rate: 0.00284749
	LOSS [training: 0.1914373100800916 | validation: 0.1925066821210391]
	TIME [epoch: 8.34 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24995312026859637		[learning rate: 0.0028408]
	Learning Rate: 0.00284077
	LOSS [training: 0.24995312026859637 | validation: 0.1500046613843407]
	TIME [epoch: 8.35 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23810265122245636		[learning rate: 0.0028341]
	Learning Rate: 0.00283407
	LOSS [training: 0.23810265122245636 | validation: 0.13377751968727042]
	TIME [epoch: 8.37 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21693686069340162		[learning rate: 0.0028274]
	Learning Rate: 0.00282738
	LOSS [training: 0.21693686069340162 | validation: 0.1641899131888806]
	TIME [epoch: 8.34 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22916020910264692		[learning rate: 0.0028207]
	Learning Rate: 0.00282071
	LOSS [training: 0.22916020910264692 | validation: 0.15855884783682833]
	TIME [epoch: 8.34 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20969013959596933		[learning rate: 0.0028141]
	Learning Rate: 0.00281406
	LOSS [training: 0.20969013959596933 | validation: 0.4488781539177308]
	TIME [epoch: 8.35 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33888355293993594		[learning rate: 0.0028074]
	Learning Rate: 0.00280742
	LOSS [training: 0.33888355293993594 | validation: 0.16573528757027206]
	TIME [epoch: 8.36 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24359498440455057		[learning rate: 0.0028008]
	Learning Rate: 0.0028008
	LOSS [training: 0.24359498440455057 | validation: 0.17587767071383056]
	TIME [epoch: 8.34 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2278600822118278		[learning rate: 0.0027942]
	Learning Rate: 0.00279419
	LOSS [training: 0.2278600822118278 | validation: 0.20462621991775654]
	TIME [epoch: 8.35 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2713626730117437		[learning rate: 0.0027876]
	Learning Rate: 0.0027876
	LOSS [training: 0.2713626730117437 | validation: 0.2450299949606668]
	TIME [epoch: 8.36 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2177259664013746		[learning rate: 0.002781]
	Learning Rate: 0.00278103
	LOSS [training: 0.2177259664013746 | validation: 0.23410376065760602]
	TIME [epoch: 8.37 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2622762873131549		[learning rate: 0.0027745]
	Learning Rate: 0.00277447
	LOSS [training: 0.2622762873131549 | validation: 0.16346599630139624]
	TIME [epoch: 8.35 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1948292421557388		[learning rate: 0.0027679]
	Learning Rate: 0.00276792
	LOSS [training: 0.1948292421557388 | validation: 0.13362689141589817]
	TIME [epoch: 8.35 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23870782201225532		[learning rate: 0.0027614]
	Learning Rate: 0.00276139
	LOSS [training: 0.23870782201225532 | validation: 0.126661243900002]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_595.pth
	Model improved!!!
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25053533541789863		[learning rate: 0.0027549]
	Learning Rate: 0.00275488
	LOSS [training: 0.25053533541789863 | validation: 0.21117164337728245]
	TIME [epoch: 8.36 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22308481141733413		[learning rate: 0.0027484]
	Learning Rate: 0.00274838
	LOSS [training: 0.22308481141733413 | validation: 0.19432041542101297]
	TIME [epoch: 8.35 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25345694548096864		[learning rate: 0.0027419]
	Learning Rate: 0.0027419
	LOSS [training: 0.25345694548096864 | validation: 0.14157282967267285]
	TIME [epoch: 8.34 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2126593335035647		[learning rate: 0.0027354]
	Learning Rate: 0.00273543
	LOSS [training: 0.2126593335035647 | validation: 0.12387028324805796]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_599.pth
	Model improved!!!
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20060914671327393		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.20060914671327393 | validation: 0.37386189608516285]
	TIME [epoch: 8.37 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23412807459413482		[learning rate: 0.0027225]
	Learning Rate: 0.00272254
	LOSS [training: 0.23412807459413482 | validation: 0.2950888339836738]
	TIME [epoch: 8.35 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2650499760009214		[learning rate: 0.0027161]
	Learning Rate: 0.00271612
	LOSS [training: 0.2650499760009214 | validation: 0.15277984745090384]
	TIME [epoch: 8.35 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20065094832591818		[learning rate: 0.0027097]
	Learning Rate: 0.00270971
	LOSS [training: 0.20065094832591818 | validation: 0.13690297100243368]
	TIME [epoch: 8.36 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18829797641325025		[learning rate: 0.0027033]
	Learning Rate: 0.00270332
	LOSS [training: 0.18829797641325025 | validation: 0.19064295321171393]
	TIME [epoch: 8.36 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18965223280846452		[learning rate: 0.0026969]
	Learning Rate: 0.00269694
	LOSS [training: 0.18965223280846452 | validation: 0.17493500617664232]
	TIME [epoch: 8.35 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2146118145044978		[learning rate: 0.0026906]
	Learning Rate: 0.00269058
	LOSS [training: 0.2146118145044978 | validation: 0.17951853549897326]
	TIME [epoch: 8.34 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22706779335648802		[learning rate: 0.0026842]
	Learning Rate: 0.00268423
	LOSS [training: 0.22706779335648802 | validation: 0.27652232619175576]
	TIME [epoch: 8.36 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27296639952734275		[learning rate: 0.0026779]
	Learning Rate: 0.0026779
	LOSS [training: 0.27296639952734275 | validation: 0.23913088215733533]
	TIME [epoch: 8.36 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24390471429668303		[learning rate: 0.0026716]
	Learning Rate: 0.00267159
	LOSS [training: 0.24390471429668303 | validation: 0.3506069148962393]
	TIME [epoch: 8.34 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28854523570016827		[learning rate: 0.0026653]
	Learning Rate: 0.00266528
	LOSS [training: 0.28854523570016827 | validation: 0.35648911942819317]
	TIME [epoch: 8.34 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24767243959804625		[learning rate: 0.002659]
	Learning Rate: 0.002659
	LOSS [training: 0.24767243959804625 | validation: 0.22556152839049814]
	TIME [epoch: 8.36 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2157083301730401		[learning rate: 0.0026527]
	Learning Rate: 0.00265273
	LOSS [training: 0.2157083301730401 | validation: 0.1452796512467221]
	TIME [epoch: 8.36 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17864029279735294		[learning rate: 0.0026465]
	Learning Rate: 0.00264647
	LOSS [training: 0.17864029279735294 | validation: 0.1672287609045638]
	TIME [epoch: 8.35 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18399903230715725		[learning rate: 0.0026402]
	Learning Rate: 0.00264023
	LOSS [training: 0.18399903230715725 | validation: 0.13917619788408359]
	TIME [epoch: 8.34 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2289080167714474		[learning rate: 0.002634]
	Learning Rate: 0.002634
	LOSS [training: 0.2289080167714474 | validation: 0.22361969792425374]
	TIME [epoch: 8.35 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23410468176067542		[learning rate: 0.0026278]
	Learning Rate: 0.00262778
	LOSS [training: 0.23410468176067542 | validation: 0.19196031049235251]
	TIME [epoch: 8.36 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19565335742282355		[learning rate: 0.0026216]
	Learning Rate: 0.00262159
	LOSS [training: 0.19565335742282355 | validation: 0.3344323535681925]
	TIME [epoch: 8.35 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26903956044901767		[learning rate: 0.0026154]
	Learning Rate: 0.0026154
	LOSS [training: 0.26903956044901767 | validation: 0.15193770644677618]
	TIME [epoch: 8.35 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22555524549602235		[learning rate: 0.0026092]
	Learning Rate: 0.00260923
	LOSS [training: 0.22555524549602235 | validation: 0.30155297159840144]
	TIME [epoch: 8.36 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23276318250189448		[learning rate: 0.0026031]
	Learning Rate: 0.00260308
	LOSS [training: 0.23276318250189448 | validation: 0.2081965342003748]
	TIME [epoch: 8.35 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21074993446031484		[learning rate: 0.0025969]
	Learning Rate: 0.00259694
	LOSS [training: 0.21074993446031484 | validation: 0.1466408912229758]
	TIME [epoch: 8.34 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1948151825326892		[learning rate: 0.0025908]
	Learning Rate: 0.00259081
	LOSS [training: 0.1948151825326892 | validation: 0.3639389694943985]
	TIME [epoch: 8.34 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20011426231101934		[learning rate: 0.0025847]
	Learning Rate: 0.0025847
	LOSS [training: 0.20011426231101934 | validation: 0.20582175322014412]
	TIME [epoch: 8.37 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22004464523255168		[learning rate: 0.0025786]
	Learning Rate: 0.0025786
	LOSS [training: 0.22004464523255168 | validation: 0.33440128179452044]
	TIME [epoch: 8.35 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28246380582515723		[learning rate: 0.0025725]
	Learning Rate: 0.00257252
	LOSS [training: 0.28246380582515723 | validation: 0.2607688571344118]
	TIME [epoch: 8.35 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24359786767947728		[learning rate: 0.0025665]
	Learning Rate: 0.00256645
	LOSS [training: 0.24359786767947728 | validation: 0.15190421333599458]
	TIME [epoch: 8.35 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29553316407820945		[learning rate: 0.0025604]
	Learning Rate: 0.0025604
	LOSS [training: 0.29553316407820945 | validation: 0.19950478544579914]
	TIME [epoch: 8.37 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2926090804205298		[learning rate: 0.0025544]
	Learning Rate: 0.00255436
	LOSS [training: 0.2926090804205298 | validation: 0.3205070922436216]
	TIME [epoch: 8.35 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2645376579185389		[learning rate: 0.0025483]
	Learning Rate: 0.00254833
	LOSS [training: 0.2645376579185389 | validation: 0.19917020173358835]
	TIME [epoch: 8.34 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24730360600052054		[learning rate: 0.0025423]
	Learning Rate: 0.00254232
	LOSS [training: 0.24730360600052054 | validation: 0.1611634627607629]
	TIME [epoch: 8.35 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2015681080217208		[learning rate: 0.0025363]
	Learning Rate: 0.00253633
	LOSS [training: 0.2015681080217208 | validation: 0.1369473089472919]
	TIME [epoch: 8.37 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20701336971948767		[learning rate: 0.0025303]
	Learning Rate: 0.00253034
	LOSS [training: 0.20701336971948767 | validation: 0.2183132431838587]
	TIME [epoch: 8.35 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2412733555360304		[learning rate: 0.0025244]
	Learning Rate: 0.00252437
	LOSS [training: 0.2412733555360304 | validation: 0.3286229994643995]
	TIME [epoch: 8.34 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23092998429318076		[learning rate: 0.0025184]
	Learning Rate: 0.00251842
	LOSS [training: 0.23092998429318076 | validation: 0.1657250422758177]
	TIME [epoch: 8.34 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20049988104716004		[learning rate: 0.0025125]
	Learning Rate: 0.00251248
	LOSS [training: 0.20049988104716004 | validation: 0.17781939703959693]
	TIME [epoch: 8.36 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33036669683731634		[learning rate: 0.0025066]
	Learning Rate: 0.00250655
	LOSS [training: 0.33036669683731634 | validation: 0.2279948627374791]
	TIME [epoch: 8.35 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3358225869451462		[learning rate: 0.0025006]
	Learning Rate: 0.00250064
	LOSS [training: 0.3358225869451462 | validation: 0.2009305863680126]
	TIME [epoch: 8.34 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26217407711090057		[learning rate: 0.0024947]
	Learning Rate: 0.00249474
	LOSS [training: 0.26217407711090057 | validation: 0.2968227267066391]
	TIME [epoch: 8.34 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21832476980614754		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.21832476980614754 | validation: 0.17956078258322994]
	TIME [epoch: 8.36 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1836131980571622		[learning rate: 0.002483]
	Learning Rate: 0.00248299
	LOSS [training: 0.1836131980571622 | validation: 0.18357258796749848]
	TIME [epoch: 8.35 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25754024867474246		[learning rate: 0.0024771]
	Learning Rate: 0.00247713
	LOSS [training: 0.25754024867474246 | validation: 0.301775239275097]
	TIME [epoch: 8.34 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1855713876521336		[learning rate: 0.0024713]
	Learning Rate: 0.00247129
	LOSS [training: 0.1855713876521336 | validation: 0.16643882484280065]
	TIME [epoch: 8.34 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20968161677625918		[learning rate: 0.0024655]
	Learning Rate: 0.00246546
	LOSS [training: 0.20968161677625918 | validation: 0.1572381186664954]
	TIME [epoch: 8.37 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2134792566548113		[learning rate: 0.0024596]
	Learning Rate: 0.00245964
	LOSS [training: 0.2134792566548113 | validation: 0.32968887668223384]
	TIME [epoch: 8.35 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19004772179153925		[learning rate: 0.0024538]
	Learning Rate: 0.00245384
	LOSS [training: 0.19004772179153925 | validation: 0.14562479635104764]
	TIME [epoch: 8.34 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1845321055781026		[learning rate: 0.0024481]
	Learning Rate: 0.00244805
	LOSS [training: 0.1845321055781026 | validation: 0.18289934133574332]
	TIME [epoch: 8.35 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19569389535646778		[learning rate: 0.0024423]
	Learning Rate: 0.00244228
	LOSS [training: 0.19569389535646778 | validation: 0.17161264384533187]
	TIME [epoch: 8.37 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.207932438868096		[learning rate: 0.0024365]
	Learning Rate: 0.00243652
	LOSS [training: 0.207932438868096 | validation: 0.19838706435332418]
	TIME [epoch: 8.35 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2484469504197441		[learning rate: 0.0024308]
	Learning Rate: 0.00243077
	LOSS [training: 0.2484469504197441 | validation: 0.1771872896927526]
	TIME [epoch: 8.34 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18374548886001252		[learning rate: 0.002425]
	Learning Rate: 0.00242503
	LOSS [training: 0.18374548886001252 | validation: 0.3015036696045387]
	TIME [epoch: 8.34 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25422213248247905		[learning rate: 0.0024193]
	Learning Rate: 0.00241931
	LOSS [training: 0.25422213248247905 | validation: 0.20145538596611404]
	TIME [epoch: 8.36 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20034550036814838		[learning rate: 0.0024136]
	Learning Rate: 0.00241361
	LOSS [training: 0.20034550036814838 | validation: 0.329813985315805]
	TIME [epoch: 8.35 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28566419552957456		[learning rate: 0.0024079]
	Learning Rate: 0.00240791
	LOSS [training: 0.28566419552957456 | validation: 0.12221648502079366]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_653.pth
	Model improved!!!
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1950305516147907		[learning rate: 0.0024022]
	Learning Rate: 0.00240223
	LOSS [training: 0.1950305516147907 | validation: 0.17490192835413332]
	TIME [epoch: 8.34 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15624737206678302		[learning rate: 0.0023966]
	Learning Rate: 0.00239657
	LOSS [training: 0.15624737206678302 | validation: 0.13670565041889587]
	TIME [epoch: 8.36 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19487525938278466		[learning rate: 0.0023909]
	Learning Rate: 0.00239092
	LOSS [training: 0.19487525938278466 | validation: 0.1964709813804367]
	TIME [epoch: 8.36 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23191798881984504		[learning rate: 0.0023853]
	Learning Rate: 0.00238527
	LOSS [training: 0.23191798881984504 | validation: 0.2683170156854626]
	TIME [epoch: 8.34 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1840914978759082		[learning rate: 0.0023796]
	Learning Rate: 0.00237965
	LOSS [training: 0.1840914978759082 | validation: 0.11575084367856221]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_658.pth
	Model improved!!!
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16270066937140676		[learning rate: 0.002374]
	Learning Rate: 0.00237404
	LOSS [training: 0.16270066937140676 | validation: 0.24506636069722237]
	TIME [epoch: 8.37 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2413478969176419		[learning rate: 0.0023684]
	Learning Rate: 0.00236844
	LOSS [training: 0.2413478969176419 | validation: 0.13596482336918153]
	TIME [epoch: 8.35 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18236502560521858		[learning rate: 0.0023628]
	Learning Rate: 0.00236285
	LOSS [training: 0.18236502560521858 | validation: 0.16379944693757598]
	TIME [epoch: 8.34 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2029232265870212		[learning rate: 0.0023573]
	Learning Rate: 0.00235727
	LOSS [training: 0.2029232265870212 | validation: 0.1803513416902331]
	TIME [epoch: 8.35 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2358900797639129		[learning rate: 0.0023517]
	Learning Rate: 0.00235171
	LOSS [training: 0.2358900797639129 | validation: 0.16770206687955783]
	TIME [epoch: 8.37 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2400645807275076		[learning rate: 0.0023462]
	Learning Rate: 0.00234617
	LOSS [training: 0.2400645807275076 | validation: 0.19776395868857505]
	TIME [epoch: 8.34 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20785435677047653		[learning rate: 0.0023406]
	Learning Rate: 0.00234063
	LOSS [training: 0.20785435677047653 | validation: 0.16394800977432497]
	TIME [epoch: 8.34 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1968963381941869		[learning rate: 0.0023351]
	Learning Rate: 0.00233511
	LOSS [training: 0.1968963381941869 | validation: 0.1529898392210948]
	TIME [epoch: 8.34 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1851920644687647		[learning rate: 0.0023296]
	Learning Rate: 0.0023296
	LOSS [training: 0.1851920644687647 | validation: 0.1481525376379902]
	TIME [epoch: 8.37 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21957405915252082		[learning rate: 0.0023241]
	Learning Rate: 0.00232411
	LOSS [training: 0.21957405915252082 | validation: 0.18411122035033117]
	TIME [epoch: 8.34 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2334069273060268		[learning rate: 0.0023186]
	Learning Rate: 0.00231863
	LOSS [training: 0.2334069273060268 | validation: 0.16556535874840972]
	TIME [epoch: 8.34 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3256071521797159		[learning rate: 0.0023132]
	Learning Rate: 0.00231316
	LOSS [training: 0.3256071521797159 | validation: 0.3249686827898337]
	TIME [epoch: 8.33 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21128082910032808		[learning rate: 0.0023077]
	Learning Rate: 0.0023077
	LOSS [training: 0.21128082910032808 | validation: 0.22472965762569463]
	TIME [epoch: 8.36 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22823503493365602		[learning rate: 0.0023023]
	Learning Rate: 0.00230226
	LOSS [training: 0.22823503493365602 | validation: 0.14889979835412392]
	TIME [epoch: 8.34 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19857208927894623		[learning rate: 0.0022968]
	Learning Rate: 0.00229683
	LOSS [training: 0.19857208927894623 | validation: 0.18821775763896864]
	TIME [epoch: 8.34 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1922113036214049		[learning rate: 0.0022914]
	Learning Rate: 0.00229141
	LOSS [training: 0.1922113036214049 | validation: 0.2827238210924081]
	TIME [epoch: 8.34 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22923473687838541		[learning rate: 0.002286]
	Learning Rate: 0.002286
	LOSS [training: 0.22923473687838541 | validation: 0.13882089752548787]
	TIME [epoch: 8.37 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21663630700223888		[learning rate: 0.0022806]
	Learning Rate: 0.00228061
	LOSS [training: 0.21663630700223888 | validation: 0.17671007630357727]
	TIME [epoch: 8.33 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3059769914199304		[learning rate: 0.0022752]
	Learning Rate: 0.00227523
	LOSS [training: 0.3059769914199304 | validation: 0.24923820656671067]
	TIME [epoch: 8.33 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2208092906252921		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.2208092906252921 | validation: 0.2131917455471726]
	TIME [epoch: 8.34 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2234274852472701		[learning rate: 0.0022645]
	Learning Rate: 0.00226451
	LOSS [training: 0.2234274852472701 | validation: 0.15243252311814126]
	TIME [epoch: 8.37 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22097725423029022		[learning rate: 0.0022592]
	Learning Rate: 0.00225917
	LOSS [training: 0.22097725423029022 | validation: 0.1690106877807906]
	TIME [epoch: 8.34 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17458226453837625		[learning rate: 0.0022538]
	Learning Rate: 0.00225384
	LOSS [training: 0.17458226453837625 | validation: 0.19453124735037253]
	TIME [epoch: 8.35 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2083379899592816		[learning rate: 0.0022485]
	Learning Rate: 0.00224852
	LOSS [training: 0.2083379899592816 | validation: 0.16620031360057108]
	TIME [epoch: 8.35 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22028851465019966		[learning rate: 0.0022432]
	Learning Rate: 0.00224322
	LOSS [training: 0.22028851465019966 | validation: 0.18339097712700175]
	TIME [epoch: 8.37 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20143130570120857		[learning rate: 0.0022379]
	Learning Rate: 0.00223793
	LOSS [training: 0.20143130570120857 | validation: 0.15115919478813106]
	TIME [epoch: 8.35 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22217113568879449		[learning rate: 0.0022326]
	Learning Rate: 0.00223265
	LOSS [training: 0.22217113568879449 | validation: 0.20263345778358333]
	TIME [epoch: 8.34 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.227327476340944		[learning rate: 0.0022274]
	Learning Rate: 0.00222738
	LOSS [training: 0.227327476340944 | validation: 0.32898934448734873]
	TIME [epoch: 8.34 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20457815162557433		[learning rate: 0.0022221]
	Learning Rate: 0.00222213
	LOSS [training: 0.20457815162557433 | validation: 0.2954131484372347]
	TIME [epoch: 8.35 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21426961000790562		[learning rate: 0.0022169]
	Learning Rate: 0.00221689
	LOSS [training: 0.21426961000790562 | validation: 0.18593108444695813]
	TIME [epoch: 8.34 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.261590292899932		[learning rate: 0.0022117]
	Learning Rate: 0.00221166
	LOSS [training: 0.261590292899932 | validation: 0.24882774088438822]
	TIME [epoch: 8.35 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23044887931002397		[learning rate: 0.0022064]
	Learning Rate: 0.00220644
	LOSS [training: 0.23044887931002397 | validation: 0.21026191268625222]
	TIME [epoch: 8.35 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21164643068189753		[learning rate: 0.0022012]
	Learning Rate: 0.00220124
	LOSS [training: 0.21164643068189753 | validation: 0.24276378043866442]
	TIME [epoch: 8.37 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22113573585274807		[learning rate: 0.002196]
	Learning Rate: 0.00219604
	LOSS [training: 0.22113573585274807 | validation: 0.15953119807199753]
	TIME [epoch: 8.34 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21237438384546117		[learning rate: 0.0021909]
	Learning Rate: 0.00219086
	LOSS [training: 0.21237438384546117 | validation: 0.17697585061783824]
	TIME [epoch: 8.33 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1605985386202829		[learning rate: 0.0021857]
	Learning Rate: 0.0021857
	LOSS [training: 0.1605985386202829 | validation: 0.14336296842591903]
	TIME [epoch: 8.35 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20109451148503338		[learning rate: 0.0021805]
	Learning Rate: 0.00218054
	LOSS [training: 0.20109451148503338 | validation: 0.13565775967549107]
	TIME [epoch: 8.37 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1791588145063682		[learning rate: 0.0021754]
	Learning Rate: 0.0021754
	LOSS [training: 0.1791588145063682 | validation: 0.10300270604683825]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_696.pth
	Model improved!!!
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1748931992246961		[learning rate: 0.0021703]
	Learning Rate: 0.00217027
	LOSS [training: 0.1748931992246961 | validation: 0.1656769748147781]
	TIME [epoch: 8.35 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20363538936256997		[learning rate: 0.0021651]
	Learning Rate: 0.00216515
	LOSS [training: 0.20363538936256997 | validation: 0.2516434651413083]
	TIME [epoch: 8.36 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23423873628017247		[learning rate: 0.00216]
	Learning Rate: 0.00216004
	LOSS [training: 0.23423873628017247 | validation: 0.15779667734819863]
	TIME [epoch: 8.36 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16988719448732933		[learning rate: 0.0021549]
	Learning Rate: 0.00215494
	LOSS [training: 0.16988719448732933 | validation: 0.13462278549862872]
	TIME [epoch: 8.34 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1804598381676733		[learning rate: 0.0021499]
	Learning Rate: 0.00214986
	LOSS [training: 0.1804598381676733 | validation: 0.14052782317098614]
	TIME [epoch: 8.34 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1803370028575814		[learning rate: 0.0021448]
	Learning Rate: 0.00214479
	LOSS [training: 0.1803370028575814 | validation: 0.11260966174704354]
	TIME [epoch: 8.36 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1643087561968564		[learning rate: 0.0021397]
	Learning Rate: 0.00213973
	LOSS [training: 0.1643087561968564 | validation: 0.16607528217534218]
	TIME [epoch: 8.35 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17145471451731234		[learning rate: 0.0021347]
	Learning Rate: 0.00213468
	LOSS [training: 0.17145471451731234 | validation: 0.20100528555354924]
	TIME [epoch: 8.34 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19268760697236517		[learning rate: 0.0021296]
	Learning Rate: 0.00212965
	LOSS [training: 0.19268760697236517 | validation: 0.15968769647034498]
	TIME [epoch: 8.34 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2082795478467217		[learning rate: 0.0021246]
	Learning Rate: 0.00212462
	LOSS [training: 0.2082795478467217 | validation: 0.1533645317415116]
	TIME [epoch: 8.35 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.221998720618258		[learning rate: 0.0021196]
	Learning Rate: 0.00211961
	LOSS [training: 0.221998720618258 | validation: 0.22921860082783924]
	TIME [epoch: 8.36 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17842998569591195		[learning rate: 0.0021146]
	Learning Rate: 0.00211461
	LOSS [training: 0.17842998569591195 | validation: 0.1253478380828324]
	TIME [epoch: 8.34 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19786562582991807		[learning rate: 0.0021096]
	Learning Rate: 0.00210962
	LOSS [training: 0.19786562582991807 | validation: 0.31444106629808777]
	TIME [epoch: 8.34 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2307080977430375		[learning rate: 0.0021046]
	Learning Rate: 0.00210465
	LOSS [training: 0.2307080977430375 | validation: 0.20344597173004472]
	TIME [epoch: 8.34 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17979865545286555		[learning rate: 0.0020997]
	Learning Rate: 0.00209968
	LOSS [training: 0.17979865545286555 | validation: 0.30953766458030774]
	TIME [epoch: 8.35 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2056159055318357		[learning rate: 0.0020947]
	Learning Rate: 0.00209473
	LOSS [training: 0.2056159055318357 | validation: 0.15445456554403253]
	TIME [epoch: 8.34 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20404926246707283		[learning rate: 0.0020898]
	Learning Rate: 0.00208979
	LOSS [training: 0.20404926246707283 | validation: 0.13121929951627553]
	TIME [epoch: 8.34 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19063081581683133		[learning rate: 0.0020849]
	Learning Rate: 0.00208486
	LOSS [training: 0.19063081581683133 | validation: 0.16394405027524114]
	TIME [epoch: 8.35 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18776893785838542		[learning rate: 0.0020799]
	Learning Rate: 0.00207994
	LOSS [training: 0.18776893785838542 | validation: 0.1599139633263486]
	TIME [epoch: 8.35 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18854843880315889		[learning rate: 0.002075]
	Learning Rate: 0.00207504
	LOSS [training: 0.18854843880315889 | validation: 0.12528952331417356]
	TIME [epoch: 8.35 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14966561686242433		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.14966561686242433 | validation: 0.13091756736945606]
	TIME [epoch: 8.34 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16474264298228322		[learning rate: 0.0020653]
	Learning Rate: 0.00206526
	LOSS [training: 0.16474264298228322 | validation: 0.14450384449970854]
	TIME [epoch: 8.36 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18263543823780998		[learning rate: 0.0020604]
	Learning Rate: 0.00206039
	LOSS [training: 0.18263543823780998 | validation: 0.15780107208932198]
	TIME [epoch: 8.35 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2064287073178012		[learning rate: 0.0020555]
	Learning Rate: 0.00205553
	LOSS [training: 0.2064287073178012 | validation: 0.167293917795926]
	TIME [epoch: 8.34 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2214031266732393		[learning rate: 0.0020507]
	Learning Rate: 0.00205068
	LOSS [training: 0.2214031266732393 | validation: 0.18260579925167947]
	TIME [epoch: 8.34 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19798278126543675		[learning rate: 0.0020458]
	Learning Rate: 0.00204584
	LOSS [training: 0.19798278126543675 | validation: 0.1787609593951582]
	TIME [epoch: 8.35 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1924455833348877		[learning rate: 0.002041]
	Learning Rate: 0.00204101
	LOSS [training: 0.1924455833348877 | validation: 0.14714694453403682]
	TIME [epoch: 8.35 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20123689226234526		[learning rate: 0.0020362]
	Learning Rate: 0.0020362
	LOSS [training: 0.20123689226234526 | validation: 0.21868372895832733]
	TIME [epoch: 8.34 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18818167821225554		[learning rate: 0.0020314]
	Learning Rate: 0.0020314
	LOSS [training: 0.18818167821225554 | validation: 0.15433004296765288]
	TIME [epoch: 8.35 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20940691022628122		[learning rate: 0.0020266]
	Learning Rate: 0.00202661
	LOSS [training: 0.20940691022628122 | validation: 0.14793565151614693]
	TIME [epoch: 8.35 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1947079857275456		[learning rate: 0.0020218]
	Learning Rate: 0.00202182
	LOSS [training: 0.1947079857275456 | validation: 0.17154187559803802]
	TIME [epoch: 8.35 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16963870922084023		[learning rate: 0.0020171]
	Learning Rate: 0.00201706
	LOSS [training: 0.16963870922084023 | validation: 0.13071639101354615]
	TIME [epoch: 8.33 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21235928804517584		[learning rate: 0.0020123]
	Learning Rate: 0.0020123
	LOSS [training: 0.21235928804517584 | validation: 0.20203242709100178]
	TIME [epoch: 8.34 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26013251278357263		[learning rate: 0.0020076]
	Learning Rate: 0.00200755
	LOSS [training: 0.26013251278357263 | validation: 0.33714909719163944]
	TIME [epoch: 8.36 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2597765251013441		[learning rate: 0.0020028]
	Learning Rate: 0.00200282
	LOSS [training: 0.2597765251013441 | validation: 0.1355260473645299]
	TIME [epoch: 8.34 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18257416454260217		[learning rate: 0.0019981]
	Learning Rate: 0.00199809
	LOSS [training: 0.18257416454260217 | validation: 0.2498632004550183]
	TIME [epoch: 8.34 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22610871381431602		[learning rate: 0.0019934]
	Learning Rate: 0.00199338
	LOSS [training: 0.22610871381431602 | validation: 0.1545287541984224]
	TIME [epoch: 8.34 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1431655028308521		[learning rate: 0.0019887]
	Learning Rate: 0.00198868
	LOSS [training: 0.1431655028308521 | validation: 0.14700837800185956]
	TIME [epoch: 8.37 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15177385259217388		[learning rate: 0.001984]
	Learning Rate: 0.00198399
	LOSS [training: 0.15177385259217388 | validation: 0.17010446639717877]
	TIME [epoch: 8.35 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17423960358787688		[learning rate: 0.0019793]
	Learning Rate: 0.00197931
	LOSS [training: 0.17423960358787688 | validation: 0.15219298874859138]
	TIME [epoch: 8.34 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2064963330816027		[learning rate: 0.0019746]
	Learning Rate: 0.00197464
	LOSS [training: 0.2064963330816027 | validation: 0.34778127083083205]
	TIME [epoch: 8.34 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1615842576617811		[learning rate: 0.00197]
	Learning Rate: 0.00196998
	LOSS [training: 0.1615842576617811 | validation: 0.11667028211122459]
	TIME [epoch: 8.37 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15595467707507263		[learning rate: 0.0019653]
	Learning Rate: 0.00196533
	LOSS [training: 0.15595467707507263 | validation: 0.13984479565427055]
	TIME [epoch: 8.35 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18769645484849345		[learning rate: 0.0019607]
	Learning Rate: 0.0019607
	LOSS [training: 0.18769645484849345 | validation: 0.16117905370802382]
	TIME [epoch: 8.34 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17603831296022748		[learning rate: 0.0019561]
	Learning Rate: 0.00195607
	LOSS [training: 0.17603831296022748 | validation: 0.10616722999254423]
	TIME [epoch: 8.34 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16101271899540567		[learning rate: 0.0019515]
	Learning Rate: 0.00195146
	LOSS [training: 0.16101271899540567 | validation: 0.2507654370535324]
	TIME [epoch: 8.37 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19428693140886216		[learning rate: 0.0019469]
	Learning Rate: 0.00194685
	LOSS [training: 0.19428693140886216 | validation: 0.34670107393216654]
	TIME [epoch: 8.35 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.198981287171095		[learning rate: 0.0019423]
	Learning Rate: 0.00194226
	LOSS [training: 0.198981287171095 | validation: 0.1401050679307052]
	TIME [epoch: 8.35 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2049294440454835		[learning rate: 0.0019377]
	Learning Rate: 0.00193768
	LOSS [training: 0.2049294440454835 | validation: 0.17039373138777025]
	TIME [epoch: 8.35 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21795482676582645		[learning rate: 0.0019331]
	Learning Rate: 0.00193311
	LOSS [training: 0.21795482676582645 | validation: 0.1881218574210915]
	TIME [epoch: 8.37 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.191150166824259		[learning rate: 0.0019285]
	Learning Rate: 0.00192855
	LOSS [training: 0.191150166824259 | validation: 0.13530631887930966]
	TIME [epoch: 8.35 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2437877451458322		[learning rate: 0.001924]
	Learning Rate: 0.001924
	LOSS [training: 0.2437877451458322 | validation: 0.11405276539047651]
	TIME [epoch: 8.34 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23334980054312368		[learning rate: 0.0019195]
	Learning Rate: 0.00191946
	LOSS [training: 0.23334980054312368 | validation: 0.10638943425672655]
	TIME [epoch: 8.34 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15614484267315268		[learning rate: 0.0019149]
	Learning Rate: 0.00191493
	LOSS [training: 0.15614484267315268 | validation: 0.14508412461326675]
	TIME [epoch: 8.37 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1715036775567071		[learning rate: 0.0019104]
	Learning Rate: 0.00191042
	LOSS [training: 0.1715036775567071 | validation: 0.12949344227745424]
	TIME [epoch: 8.35 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17910498927508395		[learning rate: 0.0019059]
	Learning Rate: 0.00190591
	LOSS [training: 0.17910498927508395 | validation: 0.11313525042809525]
	TIME [epoch: 8.35 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21254440273845096		[learning rate: 0.0019014]
	Learning Rate: 0.00190141
	LOSS [training: 0.21254440273845096 | validation: 0.32755185150765903]
	TIME [epoch: 8.34 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22031401799980938		[learning rate: 0.0018969]
	Learning Rate: 0.00189693
	LOSS [training: 0.22031401799980938 | validation: 0.18841485949610548]
	TIME [epoch: 8.37 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20431633969227483		[learning rate: 0.0018925]
	Learning Rate: 0.00189246
	LOSS [training: 0.20431633969227483 | validation: 0.25439344155668603]
	TIME [epoch: 8.33 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22505661954259093		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.22505661954259093 | validation: 0.2553806422163369]
	TIME [epoch: 8.34 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21163838255394007		[learning rate: 0.0018835]
	Learning Rate: 0.00188354
	LOSS [training: 0.21163838255394007 | validation: 0.25079364134859194]
	TIME [epoch: 8.34 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1859383131658612		[learning rate: 0.0018791]
	Learning Rate: 0.00187909
	LOSS [training: 0.1859383131658612 | validation: 0.14281843167950922]
	TIME [epoch: 8.37 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1720484866234102		[learning rate: 0.0018747]
	Learning Rate: 0.00187466
	LOSS [training: 0.1720484866234102 | validation: 0.17309686818788178]
	TIME [epoch: 8.35 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19719997921631474		[learning rate: 0.0018702]
	Learning Rate: 0.00187024
	LOSS [training: 0.19719997921631474 | validation: 0.1439040736704878]
	TIME [epoch: 8.34 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1836041113096175		[learning rate: 0.0018658]
	Learning Rate: 0.00186583
	LOSS [training: 0.1836041113096175 | validation: 0.1355859441180915]
	TIME [epoch: 8.34 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16897192577441095		[learning rate: 0.0018614]
	Learning Rate: 0.00186143
	LOSS [training: 0.16897192577441095 | validation: 0.09570719384814286]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_762.pth
	Model improved!!!
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16472420974357863		[learning rate: 0.001857]
	Learning Rate: 0.00185704
	LOSS [training: 0.16472420974357863 | validation: 0.18267949712388884]
	TIME [epoch: 8.36 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21233946465115858		[learning rate: 0.0018527]
	Learning Rate: 0.00185266
	LOSS [training: 0.21233946465115858 | validation: 0.16816833094314224]
	TIME [epoch: 8.34 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1822459605591035		[learning rate: 0.0018483]
	Learning Rate: 0.00184829
	LOSS [training: 0.1822459605591035 | validation: 0.14877064266737816]
	TIME [epoch: 8.34 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1839007908280945		[learning rate: 0.0018439]
	Learning Rate: 0.00184393
	LOSS [training: 0.1839007908280945 | validation: 0.16618883939973372]
	TIME [epoch: 8.37 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19212567055502633		[learning rate: 0.0018396]
	Learning Rate: 0.00183958
	LOSS [training: 0.19212567055502633 | validation: 0.12879534325874092]
	TIME [epoch: 8.35 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19490385481881084		[learning rate: 0.0018352]
	Learning Rate: 0.00183524
	LOSS [training: 0.19490385481881084 | validation: 0.1493453517833569]
	TIME [epoch: 8.34 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16128496015605737		[learning rate: 0.0018309]
	Learning Rate: 0.00183091
	LOSS [training: 0.16128496015605737 | validation: 0.14953167410862658]
	TIME [epoch: 8.34 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1933516282911116		[learning rate: 0.0018266]
	Learning Rate: 0.00182659
	LOSS [training: 0.1933516282911116 | validation: 0.2758696794194789]
	TIME [epoch: 8.36 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19901714789953479		[learning rate: 0.0018223]
	Learning Rate: 0.00182228
	LOSS [training: 0.19901714789953479 | validation: 0.1266473703058315]
	TIME [epoch: 8.34 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16410628886521642		[learning rate: 0.001818]
	Learning Rate: 0.00181798
	LOSS [training: 0.16410628886521642 | validation: 0.1546052526126851]
	TIME [epoch: 8.34 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15267499340493715		[learning rate: 0.0018137]
	Learning Rate: 0.00181369
	LOSS [training: 0.15267499340493715 | validation: 0.28301239032017816]
	TIME [epoch: 8.35 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18444300937138908		[learning rate: 0.0018094]
	Learning Rate: 0.00180942
	LOSS [training: 0.18444300937138908 | validation: 0.11211097322984731]
	TIME [epoch: 8.36 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14515768175264324		[learning rate: 0.0018051]
	Learning Rate: 0.00180515
	LOSS [training: 0.14515768175264324 | validation: 0.11593952193338536]
	TIME [epoch: 8.34 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15586578232569967		[learning rate: 0.0018009]
	Learning Rate: 0.00180089
	LOSS [training: 0.15586578232569967 | validation: 0.14638943731696974]
	TIME [epoch: 8.34 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15331940764617916		[learning rate: 0.0017966]
	Learning Rate: 0.00179664
	LOSS [training: 0.15331940764617916 | validation: 0.1618693629991827]
	TIME [epoch: 8.34 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14165111385568113		[learning rate: 0.0017924]
	Learning Rate: 0.0017924
	LOSS [training: 0.14165111385568113 | validation: 0.1287570086967406]
	TIME [epoch: 8.36 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16841575193741223		[learning rate: 0.0017882]
	Learning Rate: 0.00178818
	LOSS [training: 0.16841575193741223 | validation: 0.13249336866807662]
	TIME [epoch: 8.34 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17721199311705096		[learning rate: 0.001784]
	Learning Rate: 0.00178396
	LOSS [training: 0.17721199311705096 | validation: 0.13985054428871882]
	TIME [epoch: 8.33 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22432732359970706		[learning rate: 0.0017797]
	Learning Rate: 0.00177975
	LOSS [training: 0.22432732359970706 | validation: 0.19503848710857224]
	TIME [epoch: 8.34 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17794994414526985		[learning rate: 0.0017756]
	Learning Rate: 0.00177555
	LOSS [training: 0.17794994414526985 | validation: 0.11974502196597578]
	TIME [epoch: 8.37 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13191516004237935		[learning rate: 0.0017714]
	Learning Rate: 0.00177136
	LOSS [training: 0.13191516004237935 | validation: 0.17612937109029086]
	TIME [epoch: 8.33 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19555928159333008		[learning rate: 0.0017672]
	Learning Rate: 0.00176719
	LOSS [training: 0.19555928159333008 | validation: 0.20874160574843215]
	TIME [epoch: 8.34 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19918490945800876		[learning rate: 0.001763]
	Learning Rate: 0.00176302
	LOSS [training: 0.19918490945800876 | validation: 0.10562011649299816]
	TIME [epoch: 8.34 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1570969660287851		[learning rate: 0.0017589]
	Learning Rate: 0.00175886
	LOSS [training: 0.1570969660287851 | validation: 0.20356183835451006]
	TIME [epoch: 8.36 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17609089715638135		[learning rate: 0.0017547]
	Learning Rate: 0.00175471
	LOSS [training: 0.17609089715638135 | validation: 0.12179398334807656]
	TIME [epoch: 8.34 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18485080443950302		[learning rate: 0.0017506]
	Learning Rate: 0.00175057
	LOSS [training: 0.18485080443950302 | validation: 0.19590380462715923]
	TIME [epoch: 8.34 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17080161140866823		[learning rate: 0.0017464]
	Learning Rate: 0.00174644
	LOSS [training: 0.17080161140866823 | validation: 0.12132631873941377]
	TIME [epoch: 8.33 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1757428876544951		[learning rate: 0.0017423]
	Learning Rate: 0.00174232
	LOSS [training: 0.1757428876544951 | validation: 0.13986282370519715]
	TIME [epoch: 8.36 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17423727495023172		[learning rate: 0.0017382]
	Learning Rate: 0.00173821
	LOSS [training: 0.17423727495023172 | validation: 0.1266859239695621]
	TIME [epoch: 8.32 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14046819165262106		[learning rate: 0.0017341]
	Learning Rate: 0.00173411
	LOSS [training: 0.14046819165262106 | validation: 0.20013030414016852]
	TIME [epoch: 8.34 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1623338738321879		[learning rate: 0.00173]
	Learning Rate: 0.00173002
	LOSS [training: 0.1623338738321879 | validation: 0.18605326340885653]
	TIME [epoch: 8.34 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17632906156962255		[learning rate: 0.0017259]
	Learning Rate: 0.00172594
	LOSS [training: 0.17632906156962255 | validation: 0.1239389648763394]
	TIME [epoch: 8.36 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15708612528720464		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.15708612528720464 | validation: 0.12944103601787943]
	TIME [epoch: 8.33 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18679294774930452		[learning rate: 0.0017178]
	Learning Rate: 0.00171781
	LOSS [training: 0.18679294774930452 | validation: 0.09242865399864049]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_796.pth
	Model improved!!!
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1498942689882205		[learning rate: 0.0017138]
	Learning Rate: 0.00171375
	LOSS [training: 0.1498942689882205 | validation: 0.11964087343547586]
	TIME [epoch: 8.37 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16305861142927433		[learning rate: 0.0017097]
	Learning Rate: 0.00170971
	LOSS [training: 0.16305861142927433 | validation: 0.17483263051386758]
	TIME [epoch: 8.37 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17915960461757505		[learning rate: 0.0017057]
	Learning Rate: 0.00170568
	LOSS [training: 0.17915960461757505 | validation: 0.19550635509520892]
	TIME [epoch: 8.36 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23289439340432933		[learning rate: 0.0017017]
	Learning Rate: 0.00170166
	LOSS [training: 0.23289439340432933 | validation: 0.27663910866258606]
	TIME [epoch: 8.35 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22989909691564409		[learning rate: 0.0016976]
	Learning Rate: 0.00169764
	LOSS [training: 0.22989909691564409 | validation: 0.1526101457862753]
	TIME [epoch: 8.36 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16164106241193985		[learning rate: 0.0016936]
	Learning Rate: 0.00169364
	LOSS [training: 0.16164106241193985 | validation: 0.15972204188724387]
	TIME [epoch: 8.38 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19519165830026686		[learning rate: 0.0016896]
	Learning Rate: 0.00168964
	LOSS [training: 0.19519165830026686 | validation: 0.12936700888823544]
	TIME [epoch: 8.35 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14149699611213723		[learning rate: 0.0016857]
	Learning Rate: 0.00168566
	LOSS [training: 0.14149699611213723 | validation: 0.1954422001245943]
	TIME [epoch: 8.36 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1730853201277021		[learning rate: 0.0016817]
	Learning Rate: 0.00168168
	LOSS [training: 0.1730853201277021 | validation: 0.1699262487822248]
	TIME [epoch: 8.35 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17764947701649397		[learning rate: 0.0016777]
	Learning Rate: 0.00167771
	LOSS [training: 0.17764947701649397 | validation: 0.20129156679318988]
	TIME [epoch: 8.39 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2251723173329696		[learning rate: 0.0016738]
	Learning Rate: 0.00167376
	LOSS [training: 0.2251723173329696 | validation: 0.14432165213778875]
	TIME [epoch: 8.35 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17414235169027478		[learning rate: 0.0016698]
	Learning Rate: 0.00166981
	LOSS [training: 0.17414235169027478 | validation: 0.1616227802993594]
	TIME [epoch: 8.36 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20787846912496044		[learning rate: 0.0016659]
	Learning Rate: 0.00166587
	LOSS [training: 0.20787846912496044 | validation: 0.2240486734450139]
	TIME [epoch: 8.36 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17639729580710065		[learning rate: 0.0016619]
	Learning Rate: 0.00166194
	LOSS [training: 0.17639729580710065 | validation: 0.12812150673267875]
	TIME [epoch: 8.38 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17352356427596155		[learning rate: 0.001658]
	Learning Rate: 0.00165802
	LOSS [training: 0.17352356427596155 | validation: 0.13303486905755613]
	TIME [epoch: 8.35 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18426680457472838		[learning rate: 0.0016541]
	Learning Rate: 0.00165411
	LOSS [training: 0.18426680457472838 | validation: 0.19629022120058615]
	TIME [epoch: 8.35 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17127033012067786		[learning rate: 0.0016502]
	Learning Rate: 0.00165021
	LOSS [training: 0.17127033012067786 | validation: 0.17950070439070392]
	TIME [epoch: 8.36 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19192975719032543		[learning rate: 0.0016463]
	Learning Rate: 0.00164631
	LOSS [training: 0.19192975719032543 | validation: 0.12088512146573185]
	TIME [epoch: 8.39 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1241796685198275		[learning rate: 0.0016424]
	Learning Rate: 0.00164243
	LOSS [training: 0.1241796685198275 | validation: 0.13365983535830867]
	TIME [epoch: 8.36 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14195501168170582		[learning rate: 0.0016386]
	Learning Rate: 0.00163856
	LOSS [training: 0.14195501168170582 | validation: 0.16402538995891994]
	TIME [epoch: 8.36 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1792550485711934		[learning rate: 0.0016347]
	Learning Rate: 0.00163469
	LOSS [training: 0.1792550485711934 | validation: 0.183283848128111]
	TIME [epoch: 8.36 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2077256766258182		[learning rate: 0.0016308]
	Learning Rate: 0.00163084
	LOSS [training: 0.2077256766258182 | validation: 0.1879355344544175]
	TIME [epoch: 8.38 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15323565148445423		[learning rate: 0.001627]
	Learning Rate: 0.00162699
	LOSS [training: 0.15323565148445423 | validation: 0.13813591983100215]
	TIME [epoch: 8.35 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1680744873212396		[learning rate: 0.0016232]
	Learning Rate: 0.00162315
	LOSS [training: 0.1680744873212396 | validation: 0.12981459832137796]
	TIME [epoch: 8.35 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13924466166169952		[learning rate: 0.0016193]
	Learning Rate: 0.00161932
	LOSS [training: 0.13924466166169952 | validation: 0.12561668307480794]
	TIME [epoch: 8.36 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15973809372235603		[learning rate: 0.0016155]
	Learning Rate: 0.0016155
	LOSS [training: 0.15973809372235603 | validation: 0.20209221650653914]
	TIME [epoch: 8.39 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17827813166553302		[learning rate: 0.0016117]
	Learning Rate: 0.00161169
	LOSS [training: 0.17827813166553302 | validation: 0.22421457697280606]
	TIME [epoch: 8.35 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1926222678797374		[learning rate: 0.0016079]
	Learning Rate: 0.00160789
	LOSS [training: 0.1926222678797374 | validation: 0.1288000701094815]
	TIME [epoch: 8.36 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14607484956698835		[learning rate: 0.0016041]
	Learning Rate: 0.0016041
	LOSS [training: 0.14607484956698835 | validation: 0.12907774622308604]
	TIME [epoch: 8.36 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13683665084014648		[learning rate: 0.0016003]
	Learning Rate: 0.00160031
	LOSS [training: 0.13683665084014648 | validation: 0.09475630119814082]
	TIME [epoch: 8.39 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1696826308623704		[learning rate: 0.0015965]
	Learning Rate: 0.00159654
	LOSS [training: 0.1696826308623704 | validation: 0.121417338690192]
	TIME [epoch: 8.36 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1749055290704031		[learning rate: 0.0015928]
	Learning Rate: 0.00159277
	LOSS [training: 0.1749055290704031 | validation: 0.10694875129183412]
	TIME [epoch: 8.36 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17785816110451597		[learning rate: 0.001589]
	Learning Rate: 0.00158902
	LOSS [training: 0.17785816110451597 | validation: 0.24325585787023568]
	TIME [epoch: 8.36 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20103966485903446		[learning rate: 0.0015853]
	Learning Rate: 0.00158527
	LOSS [training: 0.20103966485903446 | validation: 0.1250907739912319]
	TIME [epoch: 8.38 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17330206260604383		[learning rate: 0.0015815]
	Learning Rate: 0.00158153
	LOSS [training: 0.17330206260604383 | validation: 0.13269534715583875]
	TIME [epoch: 8.35 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15530096363792373		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.15530096363792373 | validation: 0.12223682772632868]
	TIME [epoch: 8.35 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15939617729284858		[learning rate: 0.0015741]
	Learning Rate: 0.00157408
	LOSS [training: 0.15939617729284858 | validation: 0.22310034289804853]
	TIME [epoch: 8.37 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1921309586848752		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.1921309586848752 | validation: 0.19356826779500713]
	TIME [epoch: 8.38 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16447254714095286		[learning rate: 0.0015667]
	Learning Rate: 0.00156666
	LOSS [training: 0.16447254714095286 | validation: 0.10975060168411746]
	TIME [epoch: 8.35 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17224680213506482		[learning rate: 0.001563]
	Learning Rate: 0.00156296
	LOSS [training: 0.17224680213506482 | validation: 0.16723196907810403]
	TIME [epoch: 8.36 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22380100606907755		[learning rate: 0.0015593]
	Learning Rate: 0.00155928
	LOSS [training: 0.22380100606907755 | validation: 0.20137573897953892]
	TIME [epoch: 8.36 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1922132830144293		[learning rate: 0.0015556]
	Learning Rate: 0.0015556
	LOSS [training: 0.1922132830144293 | validation: 0.14440955739252445]
	TIME [epoch: 8.38 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17359047631832242		[learning rate: 0.0015519]
	Learning Rate: 0.00155193
	LOSS [training: 0.17359047631832242 | validation: 0.11412695232787062]
	TIME [epoch: 8.35 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17847203707031764		[learning rate: 0.0015483]
	Learning Rate: 0.00154827
	LOSS [training: 0.17847203707031764 | validation: 0.1430519090227271]
	TIME [epoch: 8.36 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14730086549538518		[learning rate: 0.0015446]
	Learning Rate: 0.00154462
	LOSS [training: 0.14730086549538518 | validation: 0.16830478063589746]
	TIME [epoch: 8.36 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14896647895931767		[learning rate: 0.001541]
	Learning Rate: 0.00154097
	LOSS [training: 0.14896647895931767 | validation: 0.14234092026346948]
	TIME [epoch: 8.38 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14939542376523046		[learning rate: 0.0015373]
	Learning Rate: 0.00153734
	LOSS [training: 0.14939542376523046 | validation: 0.11205170340087403]
	TIME [epoch: 8.35 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15447948580841472		[learning rate: 0.0015337]
	Learning Rate: 0.00153371
	LOSS [training: 0.15447948580841472 | validation: 0.22251036495861362]
	TIME [epoch: 8.36 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21429717696423606		[learning rate: 0.0015301]
	Learning Rate: 0.00153009
	LOSS [training: 0.21429717696423606 | validation: 0.1631774412471506]
	TIME [epoch: 8.38 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17286040001735287		[learning rate: 0.0015265]
	Learning Rate: 0.00152648
	LOSS [training: 0.17286040001735287 | validation: 0.14742656444059654]
	TIME [epoch: 8.37 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18878052434954273		[learning rate: 0.0015229]
	Learning Rate: 0.00152288
	LOSS [training: 0.18878052434954273 | validation: 0.1349986234478907]
	TIME [epoch: 8.36 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.158997001881037		[learning rate: 0.0015193]
	Learning Rate: 0.00151929
	LOSS [training: 0.158997001881037 | validation: 0.21556924994584412]
	TIME [epoch: 8.35 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15599367100331712		[learning rate: 0.0015157]
	Learning Rate: 0.00151571
	LOSS [training: 0.15599367100331712 | validation: 0.1297087366852557]
	TIME [epoch: 8.37 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15851313204900713		[learning rate: 0.0015121]
	Learning Rate: 0.00151213
	LOSS [training: 0.15851313204900713 | validation: 0.2712557587154468]
	TIME [epoch: 8.37 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17818977406762243		[learning rate: 0.0015086]
	Learning Rate: 0.00150857
	LOSS [training: 0.17818977406762243 | validation: 0.1231915148558655]
	TIME [epoch: 8.36 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1861116230451851		[learning rate: 0.001505]
	Learning Rate: 0.00150501
	LOSS [training: 0.1861116230451851 | validation: 0.1427135935274968]
	TIME [epoch: 8.36 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14419626302753624		[learning rate: 0.0015015]
	Learning Rate: 0.00150146
	LOSS [training: 0.14419626302753624 | validation: 0.15662464173662724]
	TIME [epoch: 8.37 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16803984869441843		[learning rate: 0.0014979]
	Learning Rate: 0.00149791
	LOSS [training: 0.16803984869441843 | validation: 0.18304783302672112]
	TIME [epoch: 8.37 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16527926498808004		[learning rate: 0.0014944]
	Learning Rate: 0.00149438
	LOSS [training: 0.16527926498808004 | validation: 0.09227990280966063]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_855.pth
	Model improved!!!
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14577324531163924		[learning rate: 0.0014909]
	Learning Rate: 0.00149086
	LOSS [training: 0.14577324531163924 | validation: 0.13536616672975907]
	TIME [epoch: 8.36 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1508087726543605		[learning rate: 0.0014873]
	Learning Rate: 0.00148734
	LOSS [training: 0.1508087726543605 | validation: 0.14462309839801557]
	TIME [epoch: 8.37 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13799427443294193		[learning rate: 0.0014838]
	Learning Rate: 0.00148383
	LOSS [training: 0.13799427443294193 | validation: 0.10539874006052452]
	TIME [epoch: 8.36 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1656282506883548		[learning rate: 0.0014803]
	Learning Rate: 0.00148033
	LOSS [training: 0.1656282506883548 | validation: 0.12208265052435352]
	TIME [epoch: 8.35 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18828663803321868		[learning rate: 0.0014768]
	Learning Rate: 0.00147684
	LOSS [training: 0.18828663803321868 | validation: 0.13215435195058728]
	TIME [epoch: 8.35 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19714384631594853		[learning rate: 0.0014734]
	Learning Rate: 0.00147336
	LOSS [training: 0.19714384631594853 | validation: 0.15682452892960408]
	TIME [epoch: 8.37 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1607106508504646		[learning rate: 0.0014699]
	Learning Rate: 0.00146988
	LOSS [training: 0.1607106508504646 | validation: 0.1363864777654423]
	TIME [epoch: 8.36 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14863423959354166		[learning rate: 0.0014664]
	Learning Rate: 0.00146641
	LOSS [training: 0.14863423959354166 | validation: 0.09665976670790813]
	TIME [epoch: 8.36 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15122035376432302		[learning rate: 0.001463]
	Learning Rate: 0.00146295
	LOSS [training: 0.15122035376432302 | validation: 0.09290845668047139]
	TIME [epoch: 8.36 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.150870466468164		[learning rate: 0.0014595]
	Learning Rate: 0.0014595
	LOSS [training: 0.150870466468164 | validation: 0.1595895054899216]
	TIME [epoch: 8.38 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16063644523091375		[learning rate: 0.0014561]
	Learning Rate: 0.00145606
	LOSS [training: 0.16063644523091375 | validation: 0.20467726427154942]
	TIME [epoch: 8.36 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16105454822122564		[learning rate: 0.0014526]
	Learning Rate: 0.00145263
	LOSS [training: 0.16105454822122564 | validation: 0.15899492910834345]
	TIME [epoch: 8.35 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1835005278145217		[learning rate: 0.0014492]
	Learning Rate: 0.0014492
	LOSS [training: 0.1835005278145217 | validation: 0.16373021463848264]
	TIME [epoch: 8.35 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15605204445311327		[learning rate: 0.0014458]
	Learning Rate: 0.00144578
	LOSS [training: 0.15605204445311327 | validation: 0.13046531401976352]
	TIME [epoch: 8.38 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14457731633515128		[learning rate: 0.0014424]
	Learning Rate: 0.00144237
	LOSS [training: 0.14457731633515128 | validation: 0.10359568524675533]
	TIME [epoch: 8.36 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15621133809300575		[learning rate: 0.001439]
	Learning Rate: 0.00143897
	LOSS [training: 0.15621133809300575 | validation: 0.1984080867311897]
	TIME [epoch: 8.35 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17081702003359023		[learning rate: 0.0014356]
	Learning Rate: 0.00143557
	LOSS [training: 0.17081702003359023 | validation: 0.19998830857119426]
	TIME [epoch: 8.35 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19682243681961903		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.19682243681961903 | validation: 0.17359369705463057]
	TIME [epoch: 8.37 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19069674959519053		[learning rate: 0.0014288]
	Learning Rate: 0.00142881
	LOSS [training: 0.19069674959519053 | validation: 0.14840461503841507]
	TIME [epoch: 8.35 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14549655813862364		[learning rate: 0.0014254]
	Learning Rate: 0.00142544
	LOSS [training: 0.14549655813862364 | validation: 0.1453366686903993]
	TIME [epoch: 8.35 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18103742320732236		[learning rate: 0.0014221]
	Learning Rate: 0.00142208
	LOSS [training: 0.18103742320732236 | validation: 0.204730357757867]
	TIME [epoch: 8.35 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18350832033964573		[learning rate: 0.0014187]
	Learning Rate: 0.00141872
	LOSS [training: 0.18350832033964573 | validation: 0.11220573164041547]
	TIME [epoch: 8.37 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20608084546065167		[learning rate: 0.0014154]
	Learning Rate: 0.00141538
	LOSS [training: 0.20608084546065167 | validation: 0.1257495999584647]
	TIME [epoch: 8.36 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15175485520649348		[learning rate: 0.001412]
	Learning Rate: 0.00141204
	LOSS [training: 0.15175485520649348 | validation: 0.1442213637346243]
	TIME [epoch: 8.35 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.197175318635188		[learning rate: 0.0014087]
	Learning Rate: 0.00140871
	LOSS [training: 0.197175318635188 | validation: 0.13897776578105892]
	TIME [epoch: 8.35 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17978053641688022		[learning rate: 0.0014054]
	Learning Rate: 0.00140538
	LOSS [training: 0.17978053641688022 | validation: 0.2148081783200488]
	TIME [epoch: 8.38 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25782825681355426		[learning rate: 0.0014021]
	Learning Rate: 0.00140207
	LOSS [training: 0.25782825681355426 | validation: 0.13340683922033184]
	TIME [epoch: 8.35 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17654154519094195		[learning rate: 0.0013988]
	Learning Rate: 0.00139876
	LOSS [training: 0.17654154519094195 | validation: 0.10559271501235329]
	TIME [epoch: 8.35 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14273485697076022		[learning rate: 0.0013955]
	Learning Rate: 0.00139546
	LOSS [training: 0.14273485697076022 | validation: 0.09454446197997654]
	TIME [epoch: 8.35 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18131630474746901		[learning rate: 0.0013922]
	Learning Rate: 0.00139217
	LOSS [training: 0.18131630474746901 | validation: 0.20459036772358713]
	TIME [epoch: 8.38 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18619521745126003		[learning rate: 0.0013889]
	Learning Rate: 0.00138889
	LOSS [training: 0.18619521745126003 | validation: 0.14338021113904365]
	TIME [epoch: 8.35 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15360771838775378		[learning rate: 0.0013856]
	Learning Rate: 0.00138561
	LOSS [training: 0.15360771838775378 | validation: 0.16245750269539388]
	TIME [epoch: 8.36 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16710036961954333		[learning rate: 0.0013823]
	Learning Rate: 0.00138234
	LOSS [training: 0.16710036961954333 | validation: 0.1302736215790104]
	TIME [epoch: 8.35 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17981816192144187		[learning rate: 0.0013791]
	Learning Rate: 0.00137908
	LOSS [training: 0.17981816192144187 | validation: 0.31038986114833117]
	TIME [epoch: 8.38 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2270723426311767		[learning rate: 0.0013758]
	Learning Rate: 0.00137583
	LOSS [training: 0.2270723426311767 | validation: 0.19567131005801502]
	TIME [epoch: 8.36 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16329765455512724		[learning rate: 0.0013726]
	Learning Rate: 0.00137258
	LOSS [training: 0.16329765455512724 | validation: 0.16733488436828625]
	TIME [epoch: 8.35 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15859973269049593		[learning rate: 0.0013693]
	Learning Rate: 0.00136934
	LOSS [training: 0.15859973269049593 | validation: 0.19473860909255322]
	TIME [epoch: 8.35 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16580452296439163		[learning rate: 0.0013661]
	Learning Rate: 0.00136611
	LOSS [training: 0.16580452296439163 | validation: 0.10499286840081823]
	TIME [epoch: 8.37 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15889310937660028		[learning rate: 0.0013629]
	Learning Rate: 0.00136289
	LOSS [training: 0.15889310937660028 | validation: 0.12994099855156294]
	TIME [epoch: 8.35 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14867352020524213		[learning rate: 0.0013597]
	Learning Rate: 0.00135968
	LOSS [training: 0.14867352020524213 | validation: 0.11461706083607595]
	TIME [epoch: 8.35 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14974276592265667		[learning rate: 0.0013565]
	Learning Rate: 0.00135647
	LOSS [training: 0.14974276592265667 | validation: 0.12449618110565853]
	TIME [epoch: 8.36 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1644205004330802		[learning rate: 0.0013533]
	Learning Rate: 0.00135327
	LOSS [training: 0.1644205004330802 | validation: 0.13388676894267063]
	TIME [epoch: 8.38 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1620578474633497		[learning rate: 0.0013501]
	Learning Rate: 0.00135008
	LOSS [training: 0.1620578474633497 | validation: 0.10922021009514264]
	TIME [epoch: 8.35 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18510947883997536		[learning rate: 0.0013469]
	Learning Rate: 0.00134689
	LOSS [training: 0.18510947883997536 | validation: 0.11842690128433202]
	TIME [epoch: 8.35 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15271870105112445		[learning rate: 0.0013437]
	Learning Rate: 0.00134372
	LOSS [training: 0.15271870105112445 | validation: 0.13070702379676155]
	TIME [epoch: 8.35 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15204294238575938		[learning rate: 0.0013405]
	Learning Rate: 0.00134055
	LOSS [training: 0.15204294238575938 | validation: 0.11000426515262174]
	TIME [epoch: 8.37 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14669540302547243		[learning rate: 0.0013374]
	Learning Rate: 0.00133738
	LOSS [training: 0.14669540302547243 | validation: 0.14723096360833807]
	TIME [epoch: 8.36 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1595874908639421		[learning rate: 0.0013342]
	Learning Rate: 0.00133423
	LOSS [training: 0.1595874908639421 | validation: 0.1295345084071122]
	TIME [epoch: 8.35 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13411448413776114		[learning rate: 0.0013311]
	Learning Rate: 0.00133108
	LOSS [training: 0.13411448413776114 | validation: 0.1628072854330222]
	TIME [epoch: 8.35 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15132015995350848		[learning rate: 0.0013279]
	Learning Rate: 0.00132794
	LOSS [training: 0.15132015995350848 | validation: 0.13905899851152687]
	TIME [epoch: 8.38 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1394086575989171		[learning rate: 0.0013248]
	Learning Rate: 0.00132481
	LOSS [training: 0.1394086575989171 | validation: 0.09828919548250994]
	TIME [epoch: 8.34 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16348103147448617		[learning rate: 0.0013217]
	Learning Rate: 0.00132169
	LOSS [training: 0.16348103147448617 | validation: 0.11719685371690097]
	TIME [epoch: 8.36 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1355695893654047		[learning rate: 0.0013186]
	Learning Rate: 0.00131857
	LOSS [training: 0.1355695893654047 | validation: 0.1530563826051992]
	TIME [epoch: 8.35 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14614818153175874		[learning rate: 0.0013155]
	Learning Rate: 0.00131546
	LOSS [training: 0.14614818153175874 | validation: 0.18215275598252223]
	TIME [epoch: 8.37 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13982218747279576		[learning rate: 0.0013124]
	Learning Rate: 0.00131235
	LOSS [training: 0.13982218747279576 | validation: 0.12237147510993834]
	TIME [epoch: 8.35 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15374373015393486		[learning rate: 0.0013093]
	Learning Rate: 0.00130926
	LOSS [training: 0.15374373015393486 | validation: 0.14151588708095342]
	TIME [epoch: 8.35 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15265156111528147		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.15265156111528147 | validation: 0.12265574754427344]
	TIME [epoch: 8.35 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13650001844618231		[learning rate: 0.0013031]
	Learning Rate: 0.00130309
	LOSS [training: 0.13650001844618231 | validation: 0.10051169757509423]
	TIME [epoch: 8.37 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14077247262759296		[learning rate: 0.0013]
	Learning Rate: 0.00130002
	LOSS [training: 0.14077247262759296 | validation: 0.15232896388637757]
	TIME [epoch: 8.35 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17650790747658246		[learning rate: 0.0012969]
	Learning Rate: 0.00129695
	LOSS [training: 0.17650790747658246 | validation: 0.17991414934897326]
	TIME [epoch: 8.34 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17581978606644286		[learning rate: 0.0012939]
	Learning Rate: 0.00129389
	LOSS [training: 0.17581978606644286 | validation: 0.22151903954091506]
	TIME [epoch: 8.35 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17001995874170295		[learning rate: 0.0012908]
	Learning Rate: 0.00129084
	LOSS [training: 0.17001995874170295 | validation: 0.11856095215981682]
	TIME [epoch: 8.37 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14579859033819034		[learning rate: 0.0012878]
	Learning Rate: 0.00128779
	LOSS [training: 0.14579859033819034 | validation: 0.11564331706801607]
	TIME [epoch: 8.35 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14742897972450683		[learning rate: 0.0012848]
	Learning Rate: 0.00128476
	LOSS [training: 0.14742897972450683 | validation: 0.10821145584368871]
	TIME [epoch: 8.34 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15090700807206994		[learning rate: 0.0012817]
	Learning Rate: 0.00128173
	LOSS [training: 0.15090700807206994 | validation: 0.09872413348909548]
	TIME [epoch: 8.35 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11778183046660487		[learning rate: 0.0012787]
	Learning Rate: 0.0012787
	LOSS [training: 0.11778183046660487 | validation: 0.10566603569609213]
	TIME [epoch: 8.37 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18088753693934495		[learning rate: 0.0012757]
	Learning Rate: 0.00127569
	LOSS [training: 0.18088753693934495 | validation: 0.10151605335958105]
	TIME [epoch: 8.35 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1667923094217506		[learning rate: 0.0012727]
	Learning Rate: 0.00127268
	LOSS [training: 0.1667923094217506 | validation: 0.1048023774774079]
	TIME [epoch: 8.34 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13896699526510772		[learning rate: 0.0012697]
	Learning Rate: 0.00126967
	LOSS [training: 0.13896699526510772 | validation: 0.11128232367523544]
	TIME [epoch: 8.35 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15612643100448698		[learning rate: 0.0012667]
	Learning Rate: 0.00126668
	LOSS [training: 0.15612643100448698 | validation: 0.17037012912798238]
	TIME [epoch: 8.36 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30097136927103624		[learning rate: 0.0012637]
	Learning Rate: 0.00126369
	LOSS [training: 0.30097136927103624 | validation: 0.16173755837436282]
	TIME [epoch: 8.35 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17032658939428375		[learning rate: 0.0012607]
	Learning Rate: 0.00126071
	LOSS [training: 0.17032658939428375 | validation: 0.24527948693988916]
	TIME [epoch: 8.34 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17965358893186778		[learning rate: 0.0012577]
	Learning Rate: 0.00125774
	LOSS [training: 0.17965358893186778 | validation: 0.1085733163094397]
	TIME [epoch: 8.34 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14892023052768805		[learning rate: 0.0012548]
	Learning Rate: 0.00125477
	LOSS [training: 0.14892023052768805 | validation: 0.23951701079193788]
	TIME [epoch: 8.37 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14972842739253828		[learning rate: 0.0012518]
	Learning Rate: 0.00125181
	LOSS [training: 0.14972842739253828 | validation: 0.11511131426325161]
	TIME [epoch: 8.34 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1353293839091769		[learning rate: 0.0012489]
	Learning Rate: 0.00124886
	LOSS [training: 0.1353293839091769 | validation: 0.12762030607775507]
	TIME [epoch: 8.35 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14290523606357314		[learning rate: 0.0012459]
	Learning Rate: 0.00124591
	LOSS [training: 0.14290523606357314 | validation: 0.10452074730431761]
	TIME [epoch: 8.34 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12245388767999113		[learning rate: 0.001243]
	Learning Rate: 0.00124297
	LOSS [training: 0.12245388767999113 | validation: 0.13058355638452013]
	TIME [epoch: 8.37 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12960110752556978		[learning rate: 0.00124]
	Learning Rate: 0.00124004
	LOSS [training: 0.12960110752556978 | validation: 0.10957712597153887]
	TIME [epoch: 8.34 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13607748211592954		[learning rate: 0.0012371]
	Learning Rate: 0.00123712
	LOSS [training: 0.13607748211592954 | validation: 0.12180897436574113]
	TIME [epoch: 8.35 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19908686133645628		[learning rate: 0.0012342]
	Learning Rate: 0.0012342
	LOSS [training: 0.19908686133645628 | validation: 0.1635832862193074]
	TIME [epoch: 8.35 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14385895944183308		[learning rate: 0.0012313]
	Learning Rate: 0.00123129
	LOSS [training: 0.14385895944183308 | validation: 0.12009809577649891]
	TIME [epoch: 8.37 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17632870312322077		[learning rate: 0.0012284]
	Learning Rate: 0.00122838
	LOSS [training: 0.17632870312322077 | validation: 0.12563635728612813]
	TIME [epoch: 8.34 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16053527748770793		[learning rate: 0.0012255]
	Learning Rate: 0.00122548
	LOSS [training: 0.16053527748770793 | validation: 0.13144229448540035]
	TIME [epoch: 8.34 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1537799608032409		[learning rate: 0.0012226]
	Learning Rate: 0.00122259
	LOSS [training: 0.1537799608032409 | validation: 0.17280434064256667]
	TIME [epoch: 8.34 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17146550016624407		[learning rate: 0.0012197]
	Learning Rate: 0.00121971
	LOSS [training: 0.17146550016624407 | validation: 0.10765225854057336]
	TIME [epoch: 8.36 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1446590917129941		[learning rate: 0.0012168]
	Learning Rate: 0.00121683
	LOSS [training: 0.1446590917129941 | validation: 0.09796538563834636]
	TIME [epoch: 8.35 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13074805756713254		[learning rate: 0.001214]
	Learning Rate: 0.00121396
	LOSS [training: 0.13074805756713254 | validation: 0.1290144362005274]
	TIME [epoch: 8.34 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1482779643928392		[learning rate: 0.0012111]
	Learning Rate: 0.0012111
	LOSS [training: 0.1482779643928392 | validation: 0.13415457848998166]
	TIME [epoch: 8.35 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15905183968916717		[learning rate: 0.0012082]
	Learning Rate: 0.00120824
	LOSS [training: 0.15905183968916717 | validation: 0.2434402316482334]
	TIME [epoch: 8.37 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16311517378531676		[learning rate: 0.0012054]
	Learning Rate: 0.00120539
	LOSS [training: 0.16311517378531676 | validation: 0.1018312334638315]
	TIME [epoch: 8.34 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13145629089321856		[learning rate: 0.0012025]
	Learning Rate: 0.00120255
	LOSS [training: 0.13145629089321856 | validation: 0.10941973241301298]
	TIME [epoch: 8.34 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14162954035890665		[learning rate: 0.0011997]
	Learning Rate: 0.00119971
	LOSS [training: 0.14162954035890665 | validation: 0.13151758484184584]
	TIME [epoch: 8.36 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12659456601119362		[learning rate: 0.0011969]
	Learning Rate: 0.00119688
	LOSS [training: 0.12659456601119362 | validation: 0.09231550051981954]
	TIME [epoch: 8.35 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14055263703813892		[learning rate: 0.0011941]
	Learning Rate: 0.00119406
	LOSS [training: 0.14055263703813892 | validation: 0.13482404821208788]
	TIME [epoch: 8.35 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13988494708374916		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.13988494708374916 | validation: 0.1300901873040507]
	TIME [epoch: 8.35 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13263526610535809		[learning rate: 0.0011884]
	Learning Rate: 0.00118843
	LOSS [training: 0.13263526610535809 | validation: 0.15924222200181604]
	TIME [epoch: 8.36 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1562764599009085		[learning rate: 0.0011856]
	Learning Rate: 0.00118563
	LOSS [training: 0.1562764599009085 | validation: 0.19304964434652777]
	TIME [epoch: 8.35 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13592288169597924		[learning rate: 0.0011828]
	Learning Rate: 0.00118283
	LOSS [training: 0.13592288169597924 | validation: 0.12260020420214507]
	TIME [epoch: 8.34 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16306584861053303		[learning rate: 0.00118]
	Learning Rate: 0.00118004
	LOSS [training: 0.16306584861053303 | validation: 0.14013424236141558]
	TIME [epoch: 8.34 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1351839275981813		[learning rate: 0.0011773]
	Learning Rate: 0.00117726
	LOSS [training: 0.1351839275981813 | validation: 0.12326391020003974]
	TIME [epoch: 8.36 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15992426100510773		[learning rate: 0.0011745]
	Learning Rate: 0.00117448
	LOSS [training: 0.15992426100510773 | validation: 0.11085192350774425]
	TIME [epoch: 8.35 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13310533046584147		[learning rate: 0.0011717]
	Learning Rate: 0.00117171
	LOSS [training: 0.13310533046584147 | validation: 0.10919923102468936]
	TIME [epoch: 8.34 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15697701308054787		[learning rate: 0.0011689]
	Learning Rate: 0.00116895
	LOSS [training: 0.15697701308054787 | validation: 0.08740434392671095]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_959.pth
	Model improved!!!
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13422258953323832		[learning rate: 0.0011662]
	Learning Rate: 0.00116619
	LOSS [training: 0.13422258953323832 | validation: 0.12357706947756637]
	TIME [epoch: 8.37 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13070983615672133		[learning rate: 0.0011634]
	Learning Rate: 0.00116344
	LOSS [training: 0.13070983615672133 | validation: 0.15580482861462297]
	TIME [epoch: 8.35 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1375188182330523		[learning rate: 0.0011607]
	Learning Rate: 0.00116069
	LOSS [training: 0.1375188182330523 | validation: 0.10717823095098036]
	TIME [epoch: 8.34 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14844128610437446		[learning rate: 0.001158]
	Learning Rate: 0.00115796
	LOSS [training: 0.14844128610437446 | validation: 0.09982773154125824]
	TIME [epoch: 8.34 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11816135150381837		[learning rate: 0.0011552]
	Learning Rate: 0.00115523
	LOSS [training: 0.11816135150381837 | validation: 0.11613661611439122]
	TIME [epoch: 8.36 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13523443867748577		[learning rate: 0.0011525]
	Learning Rate: 0.0011525
	LOSS [training: 0.13523443867748577 | validation: 0.09162981850655261]
	TIME [epoch: 8.35 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1253213254446146		[learning rate: 0.0011498]
	Learning Rate: 0.00114978
	LOSS [training: 0.1253213254446146 | validation: 0.10399648752423299]
	TIME [epoch: 8.33 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14036113925279237		[learning rate: 0.0011471]
	Learning Rate: 0.00114707
	LOSS [training: 0.14036113925279237 | validation: 0.10462024487846211]
	TIME [epoch: 8.34 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12656305723485764		[learning rate: 0.0011444]
	Learning Rate: 0.00114436
	LOSS [training: 0.12656305723485764 | validation: 0.1162248564730054]
	TIME [epoch: 8.36 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12345272511074665		[learning rate: 0.0011417]
	Learning Rate: 0.00114166
	LOSS [training: 0.12345272511074665 | validation: 0.14698683362166703]
	TIME [epoch: 8.35 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15098365915314116		[learning rate: 0.001139]
	Learning Rate: 0.00113897
	LOSS [training: 0.15098365915314116 | validation: 0.11658383240065279]
	TIME [epoch: 8.33 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11370026738128955		[learning rate: 0.0011363]
	Learning Rate: 0.00113628
	LOSS [training: 0.11370026738128955 | validation: 0.15986214275384233]
	TIME [epoch: 8.35 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13853236910639616		[learning rate: 0.0011336]
	Learning Rate: 0.0011336
	LOSS [training: 0.13853236910639616 | validation: 0.11280582680301877]
	TIME [epoch: 8.37 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1325320757256659		[learning rate: 0.0011309]
	Learning Rate: 0.00113093
	LOSS [training: 0.1325320757256659 | validation: 0.09413481822761073]
	TIME [epoch: 8.35 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15731486160315425		[learning rate: 0.0011283]
	Learning Rate: 0.00112826
	LOSS [training: 0.15731486160315425 | validation: 0.1025098527103607]
	TIME [epoch: 8.33 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13629667039265836		[learning rate: 0.0011256]
	Learning Rate: 0.0011256
	LOSS [training: 0.13629667039265836 | validation: 0.11492779450591706]
	TIME [epoch: 8.34 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12960434421106343		[learning rate: 0.0011229]
	Learning Rate: 0.00112295
	LOSS [training: 0.12960434421106343 | validation: 0.12204021718669002]
	TIME [epoch: 8.36 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1388524352566831		[learning rate: 0.0011203]
	Learning Rate: 0.0011203
	LOSS [training: 0.1388524352566831 | validation: 0.09550497348581698]
	TIME [epoch: 8.34 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13508416110235344		[learning rate: 0.0011177]
	Learning Rate: 0.00111765
	LOSS [training: 0.13508416110235344 | validation: 0.09170477262607729]
	TIME [epoch: 8.34 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1498088840645293		[learning rate: 0.001115]
	Learning Rate: 0.00111502
	LOSS [training: 0.1498088840645293 | validation: 0.11858417383207542]
	TIME [epoch: 8.33 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14142449521382175		[learning rate: 0.0011124]
	Learning Rate: 0.00111239
	LOSS [training: 0.14142449521382175 | validation: 0.12550387897098214]
	TIME [epoch: 8.37 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13887212341737454		[learning rate: 0.0011098]
	Learning Rate: 0.00110976
	LOSS [training: 0.13887212341737454 | validation: 0.11850669387053146]
	TIME [epoch: 8.35 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12251077495844132		[learning rate: 0.0011071]
	Learning Rate: 0.00110715
	LOSS [training: 0.12251077495844132 | validation: 0.07936855510375074]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_982.pth
	Model improved!!!
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1335237211558366		[learning rate: 0.0011045]
	Learning Rate: 0.00110453
	LOSS [training: 0.1335237211558366 | validation: 0.12446219509114581]
	TIME [epoch: 8.34 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14456199174709466		[learning rate: 0.0011019]
	Learning Rate: 0.00110193
	LOSS [training: 0.14456199174709466 | validation: 0.10043568125927338]
	TIME [epoch: 8.35 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13079333525839637		[learning rate: 0.0010993]
	Learning Rate: 0.00109933
	LOSS [training: 0.13079333525839637 | validation: 0.1292426725179189]
	TIME [epoch: 8.33 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16643221225466584		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.16643221225466584 | validation: 0.09585887224917888]
	TIME [epoch: 8.33 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13991544463296882		[learning rate: 0.0010942]
	Learning Rate: 0.00109415
	LOSS [training: 0.13991544463296882 | validation: 0.08186964540251018]
	TIME [epoch: 8.33 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14282654096833752		[learning rate: 0.0010916]
	Learning Rate: 0.00109157
	LOSS [training: 0.14282654096833752 | validation: 0.0872462935560104]
	TIME [epoch: 8.36 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12611021844833037		[learning rate: 0.001089]
	Learning Rate: 0.00108899
	LOSS [training: 0.12611021844833037 | validation: 0.21038876935703552]
	TIME [epoch: 8.34 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13155378970778783		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.13155378970778783 | validation: 0.16748456386115124]
	TIME [epoch: 8.33 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14850197661297262		[learning rate: 0.0010839]
	Learning Rate: 0.00108386
	LOSS [training: 0.14850197661297262 | validation: 0.14741645852868432]
	TIME [epoch: 8.34 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14769986947074493		[learning rate: 0.0010813]
	Learning Rate: 0.00108131
	LOSS [training: 0.14769986947074493 | validation: 0.14778989085131933]
	TIME [epoch: 8.36 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14723212584549128		[learning rate: 0.0010788]
	Learning Rate: 0.00107876
	LOSS [training: 0.14723212584549128 | validation: 0.09562841863874702]
	TIME [epoch: 8.33 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12419762022499699		[learning rate: 0.0010762]
	Learning Rate: 0.00107621
	LOSS [training: 0.12419762022499699 | validation: 0.1321475063916696]
	TIME [epoch: 8.33 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15760774527599355		[learning rate: 0.0010737]
	Learning Rate: 0.00107367
	LOSS [training: 0.15760774527599355 | validation: 0.106683615290427]
	TIME [epoch: 8.33 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11425174868941419		[learning rate: 0.0010711]
	Learning Rate: 0.00107114
	LOSS [training: 0.11425174868941419 | validation: 0.1403568047653209]
	TIME [epoch: 8.35 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13469167797689935		[learning rate: 0.0010686]
	Learning Rate: 0.00106861
	LOSS [training: 0.13469167797689935 | validation: 0.1289275031832411]
	TIME [epoch: 8.33 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12051122236923609		[learning rate: 0.0010661]
	Learning Rate: 0.00106609
	LOSS [training: 0.12051122236923609 | validation: 0.09311125419770364]
	TIME [epoch: 8.33 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12802779122859248		[learning rate: 0.0010636]
	Learning Rate: 0.00106358
	LOSS [training: 0.12802779122859248 | validation: 0.10525987225096091]
	TIME [epoch: 8.33 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15279542920331413		[learning rate: 0.0010611]
	Learning Rate: 0.00106107
	LOSS [training: 0.15279542920331413 | validation: 0.09939037216415783]
	TIME [epoch: 8.35 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11796259288630502		[learning rate: 0.0010586]
	Learning Rate: 0.00105857
	LOSS [training: 0.11796259288630502 | validation: 0.10528821207008948]
	TIME [epoch: 8.34 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1354383513077601		[learning rate: 0.0010561]
	Learning Rate: 0.00105607
	LOSS [training: 0.1354383513077601 | validation: 0.1232404859791525]
	TIME [epoch: 8.33 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1815803000491518		[learning rate: 0.0010536]
	Learning Rate: 0.00105358
	LOSS [training: 0.1815803000491518 | validation: 0.12313018339227966]
	TIME [epoch: 8.32 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14455870996448852		[learning rate: 0.0010511]
	Learning Rate: 0.00105109
	LOSS [training: 0.14455870996448852 | validation: 0.10353949240198826]
	TIME [epoch: 8.35 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1257118182651326		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.1257118182651326 | validation: 0.07564180155914761]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_1005.pth
	Model improved!!!
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12968576262601314		[learning rate: 0.0010461]
	Learning Rate: 0.00104614
	LOSS [training: 0.12968576262601314 | validation: 0.08128948991759254]
	TIME [epoch: 8.34 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11189763039667244		[learning rate: 0.0010437]
	Learning Rate: 0.00104367
	LOSS [training: 0.11189763039667244 | validation: 0.10480212389876822]
	TIME [epoch: 8.33 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1159029064565305		[learning rate: 0.0010412]
	Learning Rate: 0.00104121
	LOSS [training: 0.1159029064565305 | validation: 0.11117616982450945]
	TIME [epoch: 8.36 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13127550037656038		[learning rate: 0.0010388]
	Learning Rate: 0.00103875
	LOSS [training: 0.13127550037656038 | validation: 0.1481505654048702]
	TIME [epoch: 8.32 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16378965892324		[learning rate: 0.0010363]
	Learning Rate: 0.0010363
	LOSS [training: 0.16378965892324 | validation: 0.11330003865220269]
	TIME [epoch: 8.34 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1733686550812227		[learning rate: 0.0010339]
	Learning Rate: 0.00103386
	LOSS [training: 0.1733686550812227 | validation: 0.10716367562003787]
	TIME [epoch: 8.33 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12387937627995779		[learning rate: 0.0010314]
	Learning Rate: 0.00103142
	LOSS [training: 0.12387937627995779 | validation: 0.12964382756145726]
	TIME [epoch: 8.36 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14168233195591443		[learning rate: 0.001029]
	Learning Rate: 0.00102899
	LOSS [training: 0.14168233195591443 | validation: 0.0995077417863177]
	TIME [epoch: 8.33 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1297549308094564		[learning rate: 0.0010266]
	Learning Rate: 0.00102656
	LOSS [training: 0.1297549308094564 | validation: 0.14216391222011776]
	TIME [epoch: 8.33 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17188141836419712		[learning rate: 0.0010241]
	Learning Rate: 0.00102414
	LOSS [training: 0.17188141836419712 | validation: 0.09346866968658597]
	TIME [epoch: 8.33 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13192099005708396		[learning rate: 0.0010217]
	Learning Rate: 0.00102172
	LOSS [training: 0.13192099005708396 | validation: 0.13236025692461872]
	TIME [epoch: 8.35 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13974063963475847		[learning rate: 0.0010193]
	Learning Rate: 0.00101931
	LOSS [training: 0.13974063963475847 | validation: 0.11281143079196485]
	TIME [epoch: 8.33 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1272446338764923		[learning rate: 0.0010169]
	Learning Rate: 0.00101691
	LOSS [training: 0.1272446338764923 | validation: 0.08957302921142271]
	TIME [epoch: 8.32 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1404399689154775		[learning rate: 0.0010145]
	Learning Rate: 0.00101451
	LOSS [training: 0.1404399689154775 | validation: 0.10494010125022729]
	TIME [epoch: 8.33 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11716398510219825		[learning rate: 0.0010121]
	Learning Rate: 0.00101212
	LOSS [training: 0.11716398510219825 | validation: 0.098199448715832]
	TIME [epoch: 8.35 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13877843563449804		[learning rate: 0.0010097]
	Learning Rate: 0.00100973
	LOSS [training: 0.13877843563449804 | validation: 0.11458350213229362]
	TIME [epoch: 8.33 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13355802296625643		[learning rate: 0.0010073]
	Learning Rate: 0.00100735
	LOSS [training: 0.13355802296625643 | validation: 0.08281054217345522]
	TIME [epoch: 8.33 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11531218502361133		[learning rate: 0.001005]
	Learning Rate: 0.00100497
	LOSS [training: 0.11531218502361133 | validation: 0.10751412937288507]
	TIME [epoch: 8.33 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14153129189341776		[learning rate: 0.0010026]
	Learning Rate: 0.0010026
	LOSS [training: 0.14153129189341776 | validation: 0.11800411236333197]
	TIME [epoch: 8.35 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11174811520989034		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.11174811520989034 | validation: 0.14411013940157646]
	TIME [epoch: 8.33 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1440474086478456		[learning rate: 0.00099788]
	Learning Rate: 0.000997877
	LOSS [training: 0.1440474086478456 | validation: 0.09080648719854616]
	TIME [epoch: 8.33 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13961851609435222		[learning rate: 0.00099552]
	Learning Rate: 0.000995523
	LOSS [training: 0.13961851609435222 | validation: 0.11206925654116945]
	TIME [epoch: 8.34 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11989127228760872		[learning rate: 0.00099317]
	Learning Rate: 0.000993175
	LOSS [training: 0.11989127228760872 | validation: 0.14245772184706934]
	TIME [epoch: 8.35 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1341505922369692		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.1341505922369692 | validation: 0.12369546049031122]
	TIME [epoch: 8.33 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1173485474038219		[learning rate: 0.00098849]
	Learning Rate: 0.000988495
	LOSS [training: 0.1173485474038219 | validation: 0.08883777882991403]
	TIME [epoch: 8.33 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10769542947794268		[learning rate: 0.00098616]
	Learning Rate: 0.000986163
	LOSS [training: 0.10769542947794268 | validation: 0.09053106173729811]
	TIME [epoch: 8.33 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13806981855657957		[learning rate: 0.00098384]
	Learning Rate: 0.000983837
	LOSS [training: 0.13806981855657957 | validation: 0.12919681149179463]
	TIME [epoch: 8.36 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1277612580254251		[learning rate: 0.00098152]
	Learning Rate: 0.000981516
	LOSS [training: 0.1277612580254251 | validation: 0.11214897820368591]
	TIME [epoch: 8.33 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12272168602398074		[learning rate: 0.0009792]
	Learning Rate: 0.000979201
	LOSS [training: 0.12272168602398074 | validation: 0.09106418364363421]
	TIME [epoch: 8.33 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12777961741426694		[learning rate: 0.00097689]
	Learning Rate: 0.000976891
	LOSS [training: 0.12777961741426694 | validation: 0.1306140873122076]
	TIME [epoch: 8.33 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17753095447690462		[learning rate: 0.00097459]
	Learning Rate: 0.000974587
	LOSS [training: 0.17753095447690462 | validation: 0.13787254885879405]
	TIME [epoch: 8.36 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1424268476541966		[learning rate: 0.00097229]
	Learning Rate: 0.000972288
	LOSS [training: 0.1424268476541966 | validation: 0.13405563993325906]
	TIME [epoch: 8.33 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12721162869807423		[learning rate: 0.00096999]
	Learning Rate: 0.000969994
	LOSS [training: 0.12721162869807423 | validation: 0.10818544041531847]
	TIME [epoch: 8.33 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14440488779315616		[learning rate: 0.00096771]
	Learning Rate: 0.000967706
	LOSS [training: 0.14440488779315616 | validation: 0.13326814112344532]
	TIME [epoch: 8.33 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13796350865508258		[learning rate: 0.00096542]
	Learning Rate: 0.000965424
	LOSS [training: 0.13796350865508258 | validation: 0.09916368310355364]
	TIME [epoch: 8.36 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13478297591970068		[learning rate: 0.00096315]
	Learning Rate: 0.000963146
	LOSS [training: 0.13478297591970068 | validation: 0.08378232147080297]
	TIME [epoch: 8.33 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13576505967536787		[learning rate: 0.00096087]
	Learning Rate: 0.000960874
	LOSS [training: 0.13576505967536787 | validation: 0.10004734561268777]
	TIME [epoch: 8.33 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1471692799187505		[learning rate: 0.00095861]
	Learning Rate: 0.000958608
	LOSS [training: 0.1471692799187505 | validation: 0.1327298082272666]
	TIME [epoch: 8.34 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13701837050318372		[learning rate: 0.00095635]
	Learning Rate: 0.000956347
	LOSS [training: 0.13701837050318372 | validation: 0.14664337843150327]
	TIME [epoch: 8.35 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15902913413021247		[learning rate: 0.00095409]
	Learning Rate: 0.000954091
	LOSS [training: 0.15902913413021247 | validation: 0.0943881644903023]
	TIME [epoch: 8.34 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13195884059258858		[learning rate: 0.00095184]
	Learning Rate: 0.00095184
	LOSS [training: 0.13195884059258858 | validation: 0.09087571666950602]
	TIME [epoch: 8.33 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11824837894314137		[learning rate: 0.0009496]
	Learning Rate: 0.000949595
	LOSS [training: 0.11824837894314137 | validation: 0.1368701182707423]
	TIME [epoch: 8.34 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12566717010995515		[learning rate: 0.00094736]
	Learning Rate: 0.000947355
	LOSS [training: 0.12566717010995515 | validation: 0.11693892602871765]
	TIME [epoch: 8.34 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14516368048216122		[learning rate: 0.00094512]
	Learning Rate: 0.000945121
	LOSS [training: 0.14516368048216122 | validation: 0.15206076321811585]
	TIME [epoch: 8.33 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14286371700726802		[learning rate: 0.00094289]
	Learning Rate: 0.000942891
	LOSS [training: 0.14286371700726802 | validation: 0.07913164741114415]
	TIME [epoch: 8.34 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12161783994312977		[learning rate: 0.00094067]
	Learning Rate: 0.000940667
	LOSS [training: 0.12161783994312977 | validation: 0.12302820849088236]
	TIME [epoch: 8.34 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12227737074150802		[learning rate: 0.00093845]
	Learning Rate: 0.000938448
	LOSS [training: 0.12227737074150802 | validation: 0.07560805806816201]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_1052.pth
	Model improved!!!
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11804188634074822		[learning rate: 0.00093623]
	Learning Rate: 0.000936234
	LOSS [training: 0.11804188634074822 | validation: 0.0939013043096012]
	TIME [epoch: 8.34 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13339626020388806		[learning rate: 0.00093403]
	Learning Rate: 0.000934026
	LOSS [training: 0.13339626020388806 | validation: 0.0930154117177347]
	TIME [epoch: 8.33 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14144764227717516		[learning rate: 0.00093182]
	Learning Rate: 0.000931823
	LOSS [training: 0.14144764227717516 | validation: 0.13903107818564375]
	TIME [epoch: 8.35 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12071733637861044		[learning rate: 0.00092962]
	Learning Rate: 0.000929625
	LOSS [training: 0.12071733637861044 | validation: 0.08536426298906208]
	TIME [epoch: 8.34 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11815915335162934		[learning rate: 0.00092743]
	Learning Rate: 0.000927432
	LOSS [training: 0.11815915335162934 | validation: 0.15046616146702527]
	TIME [epoch: 8.33 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13569526452942376		[learning rate: 0.00092524]
	Learning Rate: 0.000925244
	LOSS [training: 0.13569526452942376 | validation: 0.10155980657206742]
	TIME [epoch: 8.34 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10570579868976837		[learning rate: 0.00092306]
	Learning Rate: 0.000923062
	LOSS [training: 0.10570579868976837 | validation: 0.09503631050619127]
	TIME [epoch: 8.34 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1213136550057925		[learning rate: 0.00092088]
	Learning Rate: 0.000920884
	LOSS [training: 0.1213136550057925 | validation: 0.08333992631997261]
	TIME [epoch: 8.35 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11182985487317505		[learning rate: 0.00091871]
	Learning Rate: 0.000918712
	LOSS [training: 0.11182985487317505 | validation: 0.08538851814055179]
	TIME [epoch: 8.33 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11361516146937942		[learning rate: 0.00091654]
	Learning Rate: 0.000916545
	LOSS [training: 0.11361516146937942 | validation: 0.10853832024077249]
	TIME [epoch: 8.34 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10039188103243708		[learning rate: 0.00091438]
	Learning Rate: 0.000914383
	LOSS [training: 0.10039188103243708 | validation: 0.09277392530293427]
	TIME [epoch: 8.35 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11974299893268218		[learning rate: 0.00091223]
	Learning Rate: 0.000912226
	LOSS [training: 0.11974299893268218 | validation: 0.1162071814703587]
	TIME [epoch: 8.34 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1168910598564183		[learning rate: 0.00091007]
	Learning Rate: 0.000910074
	LOSS [training: 0.1168910598564183 | validation: 0.10027824138956376]
	TIME [epoch: 8.34 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1738483106290329		[learning rate: 0.00090793]
	Learning Rate: 0.000907928
	LOSS [training: 0.1738483106290329 | validation: 0.11478547492544716]
	TIME [epoch: 8.33 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12262642400112815		[learning rate: 0.00090579]
	Learning Rate: 0.000905786
	LOSS [training: 0.12262642400112815 | validation: 0.09860910562203512]
	TIME [epoch: 8.34 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13000767804208652		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.13000767804208652 | validation: 0.10312792074067836]
	TIME [epoch: 8.34 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12560960234899982		[learning rate: 0.00090152]
	Learning Rate: 0.000901518
	LOSS [training: 0.12560960234899982 | validation: 0.10718663578205756]
	TIME [epoch: 8.33 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12093103831407861		[learning rate: 0.00089939]
	Learning Rate: 0.000899391
	LOSS [training: 0.12093103831407861 | validation: 0.08541377519654814]
	TIME [epoch: 8.34 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15515331419363418		[learning rate: 0.00089727]
	Learning Rate: 0.00089727
	LOSS [training: 0.15515331419363418 | validation: 0.1111580355698818]
	TIME [epoch: 8.35 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11846399702597821		[learning rate: 0.00089515]
	Learning Rate: 0.000895153
	LOSS [training: 0.11846399702597821 | validation: 0.08749548297846525]
	TIME [epoch: 8.34 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10863313476051846		[learning rate: 0.00089304]
	Learning Rate: 0.000893042
	LOSS [training: 0.10863313476051846 | validation: 0.10355837808087225]
	TIME [epoch: 8.33 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1449765228896748		[learning rate: 0.00089094]
	Learning Rate: 0.000890935
	LOSS [training: 0.1449765228896748 | validation: 0.08236627774477956]
	TIME [epoch: 8.33 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15183589087397426		[learning rate: 0.00088883]
	Learning Rate: 0.000888834
	LOSS [training: 0.15183589087397426 | validation: 0.15235157865216123]
	TIME [epoch: 8.35 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1263486215200941		[learning rate: 0.00088674]
	Learning Rate: 0.000886737
	LOSS [training: 0.1263486215200941 | validation: 0.10905461825168619]
	TIME [epoch: 8.34 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14003021696055482		[learning rate: 0.00088465]
	Learning Rate: 0.000884645
	LOSS [training: 0.14003021696055482 | validation: 0.19943018241707203]
	TIME [epoch: 8.33 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1576750659974964		[learning rate: 0.00088256]
	Learning Rate: 0.000882559
	LOSS [training: 0.1576750659974964 | validation: 0.09131467572208105]
	TIME [epoch: 8.34 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11292758814065429		[learning rate: 0.00088048]
	Learning Rate: 0.000880477
	LOSS [training: 0.11292758814065429 | validation: 0.09001196057245839]
	TIME [epoch: 8.35 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1309856020705305		[learning rate: 0.0008784]
	Learning Rate: 0.0008784
	LOSS [training: 0.1309856020705305 | validation: 0.12767276276477862]
	TIME [epoch: 8.34 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1161211917166172		[learning rate: 0.00087633]
	Learning Rate: 0.000876328
	LOSS [training: 0.1161211917166172 | validation: 0.12896375641796748]
	TIME [epoch: 8.34 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11869691602988441		[learning rate: 0.00087426]
	Learning Rate: 0.000874261
	LOSS [training: 0.11869691602988441 | validation: 0.11173880747502006]
	TIME [epoch: 8.34 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1278589847121329		[learning rate: 0.0008722]
	Learning Rate: 0.000872199
	LOSS [training: 0.1278589847121329 | validation: 0.12497608702789109]
	TIME [epoch: 8.35 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10845257428688415		[learning rate: 0.00087014]
	Learning Rate: 0.000870141
	LOSS [training: 0.10845257428688415 | validation: 0.09662565868774528]
	TIME [epoch: 8.34 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11917799624433034		[learning rate: 0.00086809]
	Learning Rate: 0.000868089
	LOSS [training: 0.11917799624433034 | validation: 0.10922305781731745]
	TIME [epoch: 8.34 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11659079124116851		[learning rate: 0.00086604]
	Learning Rate: 0.000866041
	LOSS [training: 0.11659079124116851 | validation: 0.09106945160862275]
	TIME [epoch: 8.33 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11391330365159862		[learning rate: 0.000864]
	Learning Rate: 0.000863998
	LOSS [training: 0.11391330365159862 | validation: 0.10130334191966925]
	TIME [epoch: 8.36 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11027670123404339		[learning rate: 0.00086196]
	Learning Rate: 0.00086196
	LOSS [training: 0.11027670123404339 | validation: 0.0898661494220438]
	TIME [epoch: 8.33 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11776566357332105		[learning rate: 0.00085993]
	Learning Rate: 0.000859927
	LOSS [training: 0.11776566357332105 | validation: 0.1192998666741865]
	TIME [epoch: 8.34 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12219586691232094		[learning rate: 0.0008579]
	Learning Rate: 0.000857898
	LOSS [training: 0.12219586691232094 | validation: 0.11044332864065304]
	TIME [epoch: 8.33 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11445006241141724		[learning rate: 0.00085587]
	Learning Rate: 0.000855875
	LOSS [training: 0.11445006241141724 | validation: 0.08190391632863439]
	TIME [epoch: 8.35 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10739318951609948		[learning rate: 0.00085386]
	Learning Rate: 0.000853856
	LOSS [training: 0.10739318951609948 | validation: 0.07423928452505657]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_1092.pth
	Model improved!!!
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10649740932171223		[learning rate: 0.00085184]
	Learning Rate: 0.000851842
	LOSS [training: 0.10649740932171223 | validation: 0.10861286782050866]
	TIME [epoch: 8.34 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12457855660823798		[learning rate: 0.00084983]
	Learning Rate: 0.000849832
	LOSS [training: 0.12457855660823798 | validation: 0.11114230463447927]
	TIME [epoch: 8.33 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1266369314329659		[learning rate: 0.00084783]
	Learning Rate: 0.000847828
	LOSS [training: 0.1266369314329659 | validation: 0.08325776741618479]
	TIME [epoch: 8.36 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10932451294838685		[learning rate: 0.00084583]
	Learning Rate: 0.000845828
	LOSS [training: 0.10932451294838685 | validation: 0.11770242445975727]
	TIME [epoch: 8.34 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12561310599275788		[learning rate: 0.00084383]
	Learning Rate: 0.000843833
	LOSS [training: 0.12561310599275788 | validation: 0.08370898300781304]
	TIME [epoch: 8.33 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1151103776701762		[learning rate: 0.00084184]
	Learning Rate: 0.000841842
	LOSS [training: 0.1151103776701762 | validation: 0.0846603650162221]
	TIME [epoch: 8.33 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.121966820128582		[learning rate: 0.00083986]
	Learning Rate: 0.000839856
	LOSS [training: 0.121966820128582 | validation: 0.09863587726838673]
	TIME [epoch: 8.35 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1289328184837208		[learning rate: 0.00083788]
	Learning Rate: 0.000837876
	LOSS [training: 0.1289328184837208 | validation: 0.08995013995597347]
	TIME [epoch: 8.34 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1263685103629179		[learning rate: 0.0008359]
	Learning Rate: 0.000835899
	LOSS [training: 0.1263685103629179 | validation: 0.12017297022979187]
	TIME [epoch: 8.32 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1262562745977554		[learning rate: 0.00083393]
	Learning Rate: 0.000833927
	LOSS [training: 0.1262562745977554 | validation: 0.18852043313369446]
	TIME [epoch: 8.33 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16549127606968092		[learning rate: 0.00083196]
	Learning Rate: 0.00083196
	LOSS [training: 0.16549127606968092 | validation: 0.12377522126785874]
	TIME [epoch: 8.35 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12849564323071228		[learning rate: 0.00083]
	Learning Rate: 0.000829998
	LOSS [training: 0.12849564323071228 | validation: 0.10732499703601148]
	TIME [epoch: 8.33 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13000592555522		[learning rate: 0.00082804]
	Learning Rate: 0.00082804
	LOSS [training: 0.13000592555522 | validation: 0.10767988039029036]
	TIME [epoch: 8.34 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10129557139665904		[learning rate: 0.00082609]
	Learning Rate: 0.000826087
	LOSS [training: 0.10129557139665904 | validation: 0.09514704618149493]
	TIME [epoch: 8.32 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11771914210447612		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.11771914210447612 | validation: 0.13879725113123]
	TIME [epoch: 8.36 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11909635588199594		[learning rate: 0.00082219]
	Learning Rate: 0.000822194
	LOSS [training: 0.11909635588199594 | validation: 0.10182902620179958]
	TIME [epoch: 8.34 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11105809668473081		[learning rate: 0.00082025]
	Learning Rate: 0.000820254
	LOSS [training: 0.11105809668473081 | validation: 0.10863380140664874]
	TIME [epoch: 8.33 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13168917012307269		[learning rate: 0.00081832]
	Learning Rate: 0.00081832
	LOSS [training: 0.13168917012307269 | validation: 0.102310983192208]
	TIME [epoch: 8.33 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11226839423358068		[learning rate: 0.00081639]
	Learning Rate: 0.000816389
	LOSS [training: 0.11226839423358068 | validation: 0.07742185362143489]
	TIME [epoch: 8.35 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12419151919151805		[learning rate: 0.00081446]
	Learning Rate: 0.000814464
	LOSS [training: 0.12419151919151805 | validation: 0.09040208890659614]
	TIME [epoch: 8.34 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1286214496621131		[learning rate: 0.00081254]
	Learning Rate: 0.000812543
	LOSS [training: 0.1286214496621131 | validation: 0.1120646051917436]
	TIME [epoch: 8.33 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11775416078505996		[learning rate: 0.00081063]
	Learning Rate: 0.000810626
	LOSS [training: 0.11775416078505996 | validation: 0.14926603489424994]
	TIME [epoch: 8.33 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15881163042226637		[learning rate: 0.00080871]
	Learning Rate: 0.000808714
	LOSS [training: 0.15881163042226637 | validation: 0.09032640308198786]
	TIME [epoch: 8.35 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12476481028108877		[learning rate: 0.00080681]
	Learning Rate: 0.000806806
	LOSS [training: 0.12476481028108877 | validation: 0.10627591042725883]
	TIME [epoch: 8.33 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12683493367467208		[learning rate: 0.0008049]
	Learning Rate: 0.000804903
	LOSS [training: 0.12683493367467208 | validation: 0.10017075551639991]
	TIME [epoch: 8.32 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10718418885850474		[learning rate: 0.000803]
	Learning Rate: 0.000803004
	LOSS [training: 0.10718418885850474 | validation: 0.0768125026542668]
	TIME [epoch: 8.34 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11801624524020146		[learning rate: 0.00080111]
	Learning Rate: 0.00080111
	LOSS [training: 0.11801624524020146 | validation: 0.1044383338605159]
	TIME [epoch: 8.35 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11484800123480494		[learning rate: 0.00079922]
	Learning Rate: 0.000799221
	LOSS [training: 0.11484800123480494 | validation: 0.09880526887279886]
	TIME [epoch: 8.34 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11733227746211183		[learning rate: 0.00079734]
	Learning Rate: 0.000797335
	LOSS [training: 0.11733227746211183 | validation: 0.12198187507963686]
	TIME [epoch: 8.33 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10779624438293392		[learning rate: 0.00079545]
	Learning Rate: 0.000795454
	LOSS [training: 0.10779624438293392 | validation: 0.10185357163409012]
	TIME [epoch: 8.34 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11463496405288935		[learning rate: 0.00079358]
	Learning Rate: 0.000793578
	LOSS [training: 0.11463496405288935 | validation: 0.08812615272341415]
	TIME [epoch: 8.36 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10751729833801331		[learning rate: 0.00079171]
	Learning Rate: 0.000791706
	LOSS [training: 0.10751729833801331 | validation: 0.10983039157176006]
	TIME [epoch: 8.34 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12003108699855554		[learning rate: 0.00078984]
	Learning Rate: 0.000789839
	LOSS [training: 0.12003108699855554 | validation: 0.10659445510721971]
	TIME [epoch: 8.33 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10487918619292638		[learning rate: 0.00078798]
	Learning Rate: 0.000787976
	LOSS [training: 0.10487918619292638 | validation: 0.12123787989659598]
	TIME [epoch: 8.33 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11741352510037391		[learning rate: 0.00078612]
	Learning Rate: 0.000786117
	LOSS [training: 0.11741352510037391 | validation: 0.09251316323554584]
	TIME [epoch: 8.36 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13243206010395636		[learning rate: 0.00078426]
	Learning Rate: 0.000784263
	LOSS [training: 0.13243206010395636 | validation: 0.10259657826186207]
	TIME [epoch: 8.34 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1421153970286726		[learning rate: 0.00078241]
	Learning Rate: 0.000782413
	LOSS [training: 0.1421153970286726 | validation: 0.08282625458771439]
	TIME [epoch: 8.34 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11096833002601122		[learning rate: 0.00078057]
	Learning Rate: 0.000780567
	LOSS [training: 0.11096833002601122 | validation: 0.11697991450754867]
	TIME [epoch: 8.34 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.121391723314073		[learning rate: 0.00077873]
	Learning Rate: 0.000778726
	LOSS [training: 0.121391723314073 | validation: 0.10459648591373727]
	TIME [epoch: 8.36 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12332995426406476		[learning rate: 0.00077689]
	Learning Rate: 0.000776889
	LOSS [training: 0.12332995426406476 | validation: 0.10671366473084988]
	TIME [epoch: 8.35 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11840062600997929		[learning rate: 0.00077506]
	Learning Rate: 0.000775056
	LOSS [training: 0.11840062600997929 | validation: 0.09867112573061429]
	TIME [epoch: 8.33 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10866749507016493		[learning rate: 0.00077323]
	Learning Rate: 0.000773228
	LOSS [training: 0.10866749507016493 | validation: 0.10717666226032055]
	TIME [epoch: 8.34 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1278062984309352		[learning rate: 0.0007714]
	Learning Rate: 0.000771404
	LOSS [training: 0.1278062984309352 | validation: 0.12768401240013133]
	TIME [epoch: 8.36 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10665225413003679		[learning rate: 0.00076958]
	Learning Rate: 0.000769585
	LOSS [training: 0.10665225413003679 | validation: 0.11348067077331236]
	TIME [epoch: 8.33 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12934250507384357		[learning rate: 0.00076777]
	Learning Rate: 0.000767769
	LOSS [training: 0.12934250507384357 | validation: 0.1101487209187407]
	TIME [epoch: 8.34 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10342091893875065		[learning rate: 0.00076596]
	Learning Rate: 0.000765958
	LOSS [training: 0.10342091893875065 | validation: 0.08091102062542432]
	TIME [epoch: 8.34 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10665033161447215		[learning rate: 0.00076415]
	Learning Rate: 0.000764151
	LOSS [training: 0.10665033161447215 | validation: 0.09175190140891999]
	TIME [epoch: 8.37 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10039622538070132		[learning rate: 0.00076235]
	Learning Rate: 0.000762349
	LOSS [training: 0.10039622538070132 | validation: 0.08539930565135326]
	TIME [epoch: 8.34 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09838874444032468		[learning rate: 0.00076055]
	Learning Rate: 0.000760551
	LOSS [training: 0.09838874444032468 | validation: 0.10705392984346432]
	TIME [epoch: 8.34 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10773405326376595		[learning rate: 0.00075876]
	Learning Rate: 0.000758757
	LOSS [training: 0.10773405326376595 | validation: 0.09190703623403287]
	TIME [epoch: 8.35 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11225838441127751		[learning rate: 0.00075697]
	Learning Rate: 0.000756967
	LOSS [training: 0.11225838441127751 | validation: 0.11607144784059673]
	TIME [epoch: 8.36 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12296455034127245		[learning rate: 0.00075518]
	Learning Rate: 0.000755181
	LOSS [training: 0.12296455034127245 | validation: 0.09682996611987571]
	TIME [epoch: 8.34 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10960414839824029		[learning rate: 0.0007534]
	Learning Rate: 0.0007534
	LOSS [training: 0.10960414839824029 | validation: 0.10559298247213972]
	TIME [epoch: 8.34 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10744910738162423		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.10744910738162423 | validation: 0.09603484276896412]
	TIME [epoch: 8.35 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1051957266672737		[learning rate: 0.00074985]
	Learning Rate: 0.00074985
	LOSS [training: 0.1051957266672737 | validation: 0.0998038686636428]
	TIME [epoch: 8.36 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11216257229021878		[learning rate: 0.00074808]
	Learning Rate: 0.000748081
	LOSS [training: 0.11216257229021878 | validation: 0.08616214890652865]
	TIME [epoch: 8.33 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1153404722741203		[learning rate: 0.00074632]
	Learning Rate: 0.000746316
	LOSS [training: 0.1153404722741203 | validation: 0.1231800872938675]
	TIME [epoch: 8.34 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14019319124276716		[learning rate: 0.00074456]
	Learning Rate: 0.000744556
	LOSS [training: 0.14019319124276716 | validation: 0.07338862151624263]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_1150.pth
	Model improved!!!
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10261342048034386		[learning rate: 0.0007428]
	Learning Rate: 0.0007428
	LOSS [training: 0.10261342048034386 | validation: 0.08282890277552599]
	TIME [epoch: 8.37 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10245656463549724		[learning rate: 0.00074105]
	Learning Rate: 0.000741048
	LOSS [training: 0.10245656463549724 | validation: 0.0882297407147111]
	TIME [epoch: 8.33 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10333578612931427		[learning rate: 0.0007393]
	Learning Rate: 0.0007393
	LOSS [training: 0.10333578612931427 | validation: 0.10760888377741995]
	TIME [epoch: 8.34 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1238043874869655		[learning rate: 0.00073756]
	Learning Rate: 0.000737556
	LOSS [training: 0.1238043874869655 | validation: 0.12599946154031677]
	TIME [epoch: 8.34 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13494041472423304		[learning rate: 0.00073582]
	Learning Rate: 0.000735816
	LOSS [training: 0.13494041472423304 | validation: 0.12448519670533197]
	TIME [epoch: 8.36 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12896649772405866		[learning rate: 0.00073408]
	Learning Rate: 0.00073408
	LOSS [training: 0.12896649772405866 | validation: 0.10928712247657069]
	TIME [epoch: 8.34 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12818059360126638		[learning rate: 0.00073235]
	Learning Rate: 0.000732349
	LOSS [training: 0.12818059360126638 | validation: 0.16376866814388225]
	TIME [epoch: 8.35 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15510715579890508		[learning rate: 0.00073062]
	Learning Rate: 0.000730621
	LOSS [training: 0.15510715579890508 | validation: 0.11442138242710878]
	TIME [epoch: 8.34 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1168916928959359		[learning rate: 0.0007289]
	Learning Rate: 0.000728898
	LOSS [training: 0.1168916928959359 | validation: 0.09534080099071496]
	TIME [epoch: 8.36 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11828345731363796		[learning rate: 0.00072718]
	Learning Rate: 0.000727178
	LOSS [training: 0.11828345731363796 | validation: 0.09232422479222668]
	TIME [epoch: 8.34 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10844340868402184		[learning rate: 0.00072546]
	Learning Rate: 0.000725463
	LOSS [training: 0.10844340868402184 | validation: 0.09009364345153839]
	TIME [epoch: 8.34 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1131575541508872		[learning rate: 0.00072375]
	Learning Rate: 0.000723752
	LOSS [training: 0.1131575541508872 | validation: 0.09274247714209646]
	TIME [epoch: 8.35 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10879165518657555		[learning rate: 0.00072204]
	Learning Rate: 0.000722045
	LOSS [training: 0.10879165518657555 | validation: 0.08409973828332994]
	TIME [epoch: 8.35 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10407306594676671		[learning rate: 0.00072034]
	Learning Rate: 0.000720342
	LOSS [training: 0.10407306594676671 | validation: 0.08540508130798685]
	TIME [epoch: 8.35 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09846085556922417		[learning rate: 0.00071864]
	Learning Rate: 0.000718642
	LOSS [training: 0.09846085556922417 | validation: 0.07619476147426248]
	TIME [epoch: 8.34 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09983789839628834		[learning rate: 0.00071695]
	Learning Rate: 0.000716947
	LOSS [training: 0.09983789839628834 | validation: 0.09350909220052409]
	TIME [epoch: 8.34 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10898132303507035		[learning rate: 0.00071526]
	Learning Rate: 0.000715256
	LOSS [training: 0.10898132303507035 | validation: 0.09801895483507456]
	TIME [epoch: 8.37 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10976158716578724		[learning rate: 0.00071357]
	Learning Rate: 0.000713569
	LOSS [training: 0.10976158716578724 | validation: 0.0902105414285693]
	TIME [epoch: 8.34 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12392296364615234		[learning rate: 0.00071189]
	Learning Rate: 0.000711886
	LOSS [training: 0.12392296364615234 | validation: 0.11359984081760544]
	TIME [epoch: 8.34 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10565336365826913		[learning rate: 0.00071021]
	Learning Rate: 0.000710206
	LOSS [training: 0.10565336365826913 | validation: 0.06547859942594568]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_1170.pth
	Model improved!!!
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10973788465199788		[learning rate: 0.00070853]
	Learning Rate: 0.000708531
	LOSS [training: 0.10973788465199788 | validation: 0.08076346076418572]
	TIME [epoch: 8.34 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11037598981199026		[learning rate: 0.00070686]
	Learning Rate: 0.00070686
	LOSS [training: 0.11037598981199026 | validation: 0.1042835244501244]
	TIME [epoch: 8.34 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10526591787934195		[learning rate: 0.00070519]
	Learning Rate: 0.000705193
	LOSS [training: 0.10526591787934195 | validation: 0.10138415494653456]
	TIME [epoch: 8.34 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12563533855564424		[learning rate: 0.00070353]
	Learning Rate: 0.000703529
	LOSS [training: 0.12563533855564424 | validation: 0.11668966278554095]
	TIME [epoch: 8.35 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11445888618197646		[learning rate: 0.00070187]
	Learning Rate: 0.000701869
	LOSS [training: 0.11445888618197646 | validation: 0.11381465058190038]
	TIME [epoch: 8.35 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15148731682495598		[learning rate: 0.00070021]
	Learning Rate: 0.000700214
	LOSS [training: 0.15148731682495598 | validation: 0.10696242334854425]
	TIME [epoch: 8.34 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12051735532228813		[learning rate: 0.00069856]
	Learning Rate: 0.000698562
	LOSS [training: 0.12051735532228813 | validation: 0.0796266376698973]
	TIME [epoch: 8.34 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10207733602835045		[learning rate: 0.00069691]
	Learning Rate: 0.000696914
	LOSS [training: 0.10207733602835045 | validation: 0.10541015799974829]
	TIME [epoch: 8.35 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10465659005684322		[learning rate: 0.00069527]
	Learning Rate: 0.00069527
	LOSS [training: 0.10465659005684322 | validation: 0.08842264034440625]
	TIME [epoch: 8.35 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08861789995152525		[learning rate: 0.00069363]
	Learning Rate: 0.000693631
	LOSS [training: 0.08861789995152525 | validation: 0.08493584390706065]
	TIME [epoch: 8.34 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.103089717105639		[learning rate: 0.00069199]
	Learning Rate: 0.000691994
	LOSS [training: 0.103089717105639 | validation: 0.09921251186884292]
	TIME [epoch: 8.34 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11701869851564786		[learning rate: 0.00069036]
	Learning Rate: 0.000690362
	LOSS [training: 0.11701869851564786 | validation: 0.09635119456931128]
	TIME [epoch: 8.35 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1298122440662384		[learning rate: 0.00068873]
	Learning Rate: 0.000688734
	LOSS [training: 0.1298122440662384 | validation: 0.11012763339454784]
	TIME [epoch: 8.34 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12032447015500285		[learning rate: 0.00068711]
	Learning Rate: 0.000687109
	LOSS [training: 0.12032447015500285 | validation: 0.09766523849758402]
	TIME [epoch: 8.34 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10893704566387455		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.10893704566387455 | validation: 0.1288505194203095]
	TIME [epoch: 8.33 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11545202198212545		[learning rate: 0.00068387]
	Learning Rate: 0.000683871
	LOSS [training: 0.11545202198212545 | validation: 0.0863048084655822]
	TIME [epoch: 8.35 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12289000454255165		[learning rate: 0.00068226]
	Learning Rate: 0.000682258
	LOSS [training: 0.12289000454255165 | validation: 0.1157931391320326]
	TIME [epoch: 8.35 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11783680026252814		[learning rate: 0.00068065]
	Learning Rate: 0.000680649
	LOSS [training: 0.11783680026252814 | validation: 0.11132057931274092]
	TIME [epoch: 8.34 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12547826614398566		[learning rate: 0.00067904]
	Learning Rate: 0.000679043
	LOSS [training: 0.12547826614398566 | validation: 0.10050555406834175]
	TIME [epoch: 8.34 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12227147249249722		[learning rate: 0.00067744]
	Learning Rate: 0.000677442
	LOSS [training: 0.12227147249249722 | validation: 0.09051618271497189]
	TIME [epoch: 8.36 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11387585790503163		[learning rate: 0.00067584]
	Learning Rate: 0.000675844
	LOSS [training: 0.11387585790503163 | validation: 0.1158740246699087]
	TIME [epoch: 8.34 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1252661113065348		[learning rate: 0.00067425]
	Learning Rate: 0.000674249
	LOSS [training: 0.1252661113065348 | validation: 0.0875478897341852]
	TIME [epoch: 8.34 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10182886134853852		[learning rate: 0.00067266]
	Learning Rate: 0.000672659
	LOSS [training: 0.10182886134853852 | validation: 0.09868775886356779]
	TIME [epoch: 8.34 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1008689030547478		[learning rate: 0.00067107]
	Learning Rate: 0.000671072
	LOSS [training: 0.1008689030547478 | validation: 0.07580167702477214]
	TIME [epoch: 8.36 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10515976270531693		[learning rate: 0.00066949]
	Learning Rate: 0.000669489
	LOSS [training: 0.10515976270531693 | validation: 0.13178647142999128]
	TIME [epoch: 8.33 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10611805809511568		[learning rate: 0.00066791]
	Learning Rate: 0.00066791
	LOSS [training: 0.10611805809511568 | validation: 0.09320986990711069]
	TIME [epoch: 8.33 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1122461392159538		[learning rate: 0.00066633]
	Learning Rate: 0.000666335
	LOSS [training: 0.1122461392159538 | validation: 0.09437814924311497]
	TIME [epoch: 8.34 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11302754470132863		[learning rate: 0.00066476]
	Learning Rate: 0.000664763
	LOSS [training: 0.11302754470132863 | validation: 0.08122481007540869]
	TIME [epoch: 8.36 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1079647146993686		[learning rate: 0.00066319]
	Learning Rate: 0.000663195
	LOSS [training: 0.1079647146993686 | validation: 0.07421153031990421]
	TIME [epoch: 8.34 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09751740403612325		[learning rate: 0.00066163]
	Learning Rate: 0.00066163
	LOSS [training: 0.09751740403612325 | validation: 0.09633580264664776]
	TIME [epoch: 8.34 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11124143179511463		[learning rate: 0.00066007]
	Learning Rate: 0.00066007
	LOSS [training: 0.11124143179511463 | validation: 0.08650718008258174]
	TIME [epoch: 8.32 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10528410553639582		[learning rate: 0.00065851]
	Learning Rate: 0.000658513
	LOSS [training: 0.10528410553639582 | validation: 0.08673613806022056]
	TIME [epoch: 8.36 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09884859864344858		[learning rate: 0.00065696]
	Learning Rate: 0.000656959
	LOSS [training: 0.09884859864344858 | validation: 0.07639026067299973]
	TIME [epoch: 8.33 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1065397694757004		[learning rate: 0.00065541]
	Learning Rate: 0.00065541
	LOSS [training: 0.1065397694757004 | validation: 0.09635488390140587]
	TIME [epoch: 8.34 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11604949254492056		[learning rate: 0.00065386]
	Learning Rate: 0.000653864
	LOSS [training: 0.11604949254492056 | validation: 0.08763798272207154]
	TIME [epoch: 8.33 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10824631685015942		[learning rate: 0.00065232]
	Learning Rate: 0.000652321
	LOSS [training: 0.10824631685015942 | validation: 0.11171056307054657]
	TIME [epoch: 8.35 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1124069962462925		[learning rate: 0.00065078]
	Learning Rate: 0.000650783
	LOSS [training: 0.1124069962462925 | validation: 0.08042288624431296]
	TIME [epoch: 8.34 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10729670180189836		[learning rate: 0.00064925]
	Learning Rate: 0.000649247
	LOSS [training: 0.10729670180189836 | validation: 0.11078547758911989]
	TIME [epoch: 8.33 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11641529455675315		[learning rate: 0.00064772]
	Learning Rate: 0.000647716
	LOSS [training: 0.11641529455675315 | validation: 0.11550658160001492]
	TIME [epoch: 8.33 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13374772491026757		[learning rate: 0.00064619]
	Learning Rate: 0.000646188
	LOSS [training: 0.13374772491026757 | validation: 0.09114167218823369]
	TIME [epoch: 8.36 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10476064699530947		[learning rate: 0.00064466]
	Learning Rate: 0.000644664
	LOSS [training: 0.10476064699530947 | validation: 0.1083174449210807]
	TIME [epoch: 8.34 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11243069833673931		[learning rate: 0.00064314]
	Learning Rate: 0.000643143
	LOSS [training: 0.11243069833673931 | validation: 0.09489208352653539]
	TIME [epoch: 8.34 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10607670946352002		[learning rate: 0.00064163]
	Learning Rate: 0.000641626
	LOSS [training: 0.10607670946352002 | validation: 0.08361998421695291]
	TIME [epoch: 8.33 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1010092410111761		[learning rate: 0.00064011]
	Learning Rate: 0.000640113
	LOSS [training: 0.1010092410111761 | validation: 0.11608931369449894]
	TIME [epoch: 8.35 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10697532786052422		[learning rate: 0.0006386]
	Learning Rate: 0.000638603
	LOSS [training: 0.10697532786052422 | validation: 0.13787539645993507]
	TIME [epoch: 8.33 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12298254257128402		[learning rate: 0.0006371]
	Learning Rate: 0.000637096
	LOSS [training: 0.12298254257128402 | validation: 0.10360906285426788]
	TIME [epoch: 8.33 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09880910427805638		[learning rate: 0.00063559]
	Learning Rate: 0.000635594
	LOSS [training: 0.09880910427805638 | validation: 0.09169448776923966]
	TIME [epoch: 8.34 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09315534121117379		[learning rate: 0.00063409]
	Learning Rate: 0.000634094
	LOSS [training: 0.09315534121117379 | validation: 0.07464207338176174]
	TIME [epoch: 8.36 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09888855905050067		[learning rate: 0.0006326]
	Learning Rate: 0.000632598
	LOSS [training: 0.09888855905050067 | validation: 0.09133794529860567]
	TIME [epoch: 8.34 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0961732170019753		[learning rate: 0.00063111]
	Learning Rate: 0.000631106
	LOSS [training: 0.0961732170019753 | validation: 0.09414031468901532]
	TIME [epoch: 8.33 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10019211658568514		[learning rate: 0.00062962]
	Learning Rate: 0.000629618
	LOSS [training: 0.10019211658568514 | validation: 0.0782282960557315]
	TIME [epoch: 8.33 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09809233154131276		[learning rate: 0.00062813]
	Learning Rate: 0.000628132
	LOSS [training: 0.09809233154131276 | validation: 0.08388777134265801]
	TIME [epoch: 8.35 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10134980520577264		[learning rate: 0.00062665]
	Learning Rate: 0.000626651
	LOSS [training: 0.10134980520577264 | validation: 0.0787685937467161]
	TIME [epoch: 8.35 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10167085875838164		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.10167085875838164 | validation: 0.08660565671059407]
	TIME [epoch: 8.33 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10346716722588511		[learning rate: 0.0006237]
	Learning Rate: 0.000623698
	LOSS [training: 0.10346716722588511 | validation: 0.09320327830502306]
	TIME [epoch: 8.34 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10704784698184325		[learning rate: 0.00062223]
	Learning Rate: 0.000622227
	LOSS [training: 0.10704784698184325 | validation: 0.07323235513895221]
	TIME [epoch: 8.36 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1013676791516033		[learning rate: 0.00062076]
	Learning Rate: 0.000620759
	LOSS [training: 0.1013676791516033 | validation: 0.0834616173130846]
	TIME [epoch: 8.34 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10507475913444927		[learning rate: 0.00061929]
	Learning Rate: 0.000619295
	LOSS [training: 0.10507475913444927 | validation: 0.08285496632409511]
	TIME [epoch: 8.33 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10658665656546011		[learning rate: 0.00061783]
	Learning Rate: 0.000617834
	LOSS [training: 0.10658665656546011 | validation: 0.11540628671326078]
	TIME [epoch: 8.34 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10804066134428174		[learning rate: 0.00061638]
	Learning Rate: 0.000616377
	LOSS [training: 0.10804066134428174 | validation: 0.09471677459108674]
	TIME [epoch: 8.36 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10434131812229056		[learning rate: 0.00061492]
	Learning Rate: 0.000614923
	LOSS [training: 0.10434131812229056 | validation: 0.07921370276269805]
	TIME [epoch: 8.34 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11727245015520056		[learning rate: 0.00061347]
	Learning Rate: 0.000613472
	LOSS [training: 0.11727245015520056 | validation: 0.09727821227071368]
	TIME [epoch: 8.33 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10935004232599999		[learning rate: 0.00061203]
	Learning Rate: 0.000612025
	LOSS [training: 0.10935004232599999 | validation: 0.07615915053529454]
	TIME [epoch: 8.33 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10193460475466791		[learning rate: 0.00061058]
	Learning Rate: 0.000610581
	LOSS [training: 0.10193460475466791 | validation: 0.11703237209642173]
	TIME [epoch: 8.36 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1100306136606239		[learning rate: 0.00060914]
	Learning Rate: 0.000609141
	LOSS [training: 0.1100306136606239 | validation: 0.07787165163193133]
	TIME [epoch: 8.33 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10122145069216107		[learning rate: 0.0006077]
	Learning Rate: 0.000607704
	LOSS [training: 0.10122145069216107 | validation: 0.11410822291733504]
	TIME [epoch: 8.33 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1194781177968289		[learning rate: 0.00060627]
	Learning Rate: 0.000606271
	LOSS [training: 0.1194781177968289 | validation: 0.09717330386626413]
	TIME [epoch: 8.34 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1082733320205562		[learning rate: 0.00060484]
	Learning Rate: 0.000604841
	LOSS [training: 0.1082733320205562 | validation: 0.0916342127107806]
	TIME [epoch: 8.36 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10895641558267473		[learning rate: 0.00060341]
	Learning Rate: 0.000603414
	LOSS [training: 0.10895641558267473 | validation: 0.0972386178943537]
	TIME [epoch: 8.34 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10290661331866731		[learning rate: 0.00060199]
	Learning Rate: 0.000601991
	LOSS [training: 0.10290661331866731 | validation: 0.07453905945929651]
	TIME [epoch: 8.34 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10245266153378865		[learning rate: 0.00060057]
	Learning Rate: 0.000600571
	LOSS [training: 0.10245266153378865 | validation: 0.11320788560635539]
	TIME [epoch: 8.33 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11742391917859636		[learning rate: 0.00059915]
	Learning Rate: 0.000599154
	LOSS [training: 0.11742391917859636 | validation: 0.07949117219502683]
	TIME [epoch: 8.35 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09425450069695257		[learning rate: 0.00059774]
	Learning Rate: 0.000597741
	LOSS [training: 0.09425450069695257 | validation: 0.06766809214050842]
	TIME [epoch: 8.34 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11060738075388506		[learning rate: 0.00059633]
	Learning Rate: 0.000596331
	LOSS [training: 0.11060738075388506 | validation: 0.08989205818078262]
	TIME [epoch: 8.33 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11020937734402833		[learning rate: 0.00059492]
	Learning Rate: 0.000594924
	LOSS [training: 0.11020937734402833 | validation: 0.0811324425915545]
	TIME [epoch: 8.34 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09137462601101438		[learning rate: 0.00059352]
	Learning Rate: 0.000593521
	LOSS [training: 0.09137462601101438 | validation: 0.07859580969943075]
	TIME [epoch: 8.35 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09705787164151944		[learning rate: 0.00059212]
	Learning Rate: 0.000592121
	LOSS [training: 0.09705787164151944 | validation: 0.07815808812000882]
	TIME [epoch: 8.34 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14665151444306057		[learning rate: 0.00059072]
	Learning Rate: 0.000590724
	LOSS [training: 0.14665151444306057 | validation: 0.1473404140625989]
	TIME [epoch: 8.33 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12037801988785632		[learning rate: 0.00058933]
	Learning Rate: 0.000589331
	LOSS [training: 0.12037801988785632 | validation: 0.07163385250025854]
	TIME [epoch: 8.33 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10160666578541935		[learning rate: 0.00058794]
	Learning Rate: 0.00058794
	LOSS [training: 0.10160666578541935 | validation: 0.0915032005441576]
	TIME [epoch: 8.36 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.093138582709115		[learning rate: 0.00058655]
	Learning Rate: 0.000586554
	LOSS [training: 0.093138582709115 | validation: 0.07430954327013353]
	TIME [epoch: 8.33 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11427915516283897		[learning rate: 0.00058517]
	Learning Rate: 0.00058517
	LOSS [training: 0.11427915516283897 | validation: 0.11035263617803634]
	TIME [epoch: 8.33 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11981708997006743		[learning rate: 0.00058379]
	Learning Rate: 0.00058379
	LOSS [training: 0.11981708997006743 | validation: 0.09732182672607294]
	TIME [epoch: 8.33 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10669619663585898		[learning rate: 0.00058241]
	Learning Rate: 0.000582413
	LOSS [training: 0.10669619663585898 | validation: 0.08268510855372097]
	TIME [epoch: 8.35 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12222238043282636		[learning rate: 0.00058104]
	Learning Rate: 0.000581039
	LOSS [training: 0.12222238043282636 | validation: 0.08920239260304688]
	TIME [epoch: 8.33 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12271464851016974		[learning rate: 0.00057967]
	Learning Rate: 0.000579668
	LOSS [training: 0.12271464851016974 | validation: 0.09595929801265429]
	TIME [epoch: 8.33 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11725040909120657		[learning rate: 0.0005783]
	Learning Rate: 0.000578301
	LOSS [training: 0.11725040909120657 | validation: 0.07928103747804703]
	TIME [epoch: 8.33 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09126748801353946		[learning rate: 0.00057694]
	Learning Rate: 0.000576937
	LOSS [training: 0.09126748801353946 | validation: 0.0724892285590869]
	TIME [epoch: 8.36 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10647979215574846		[learning rate: 0.00057558]
	Learning Rate: 0.000575576
	LOSS [training: 0.10647979215574846 | validation: 0.0775553280117304]
	TIME [epoch: 8.34 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1149398269409673		[learning rate: 0.00057422]
	Learning Rate: 0.000574218
	LOSS [training: 0.1149398269409673 | validation: 0.1060897329591208]
	TIME [epoch: 8.33 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09963887666244198		[learning rate: 0.00057286]
	Learning Rate: 0.000572864
	LOSS [training: 0.09963887666244198 | validation: 0.08325715852522352]
	TIME [epoch: 8.34 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0952711235612815		[learning rate: 0.00057151]
	Learning Rate: 0.000571512
	LOSS [training: 0.0952711235612815 | validation: 0.11537835371875872]
	TIME [epoch: 8.35 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11912254409525025		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.11912254409525025 | validation: 0.08752931864716343]
	TIME [epoch: 8.34 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11731170125893813		[learning rate: 0.00056882]
	Learning Rate: 0.000568819
	LOSS [training: 0.11731170125893813 | validation: 0.071314549826191]
	TIME [epoch: 8.33 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10397518032660791		[learning rate: 0.00056748]
	Learning Rate: 0.000567478
	LOSS [training: 0.10397518032660791 | validation: 0.09527120046173564]
	TIME [epoch: 8.33 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09248727240445521		[learning rate: 0.00056614]
	Learning Rate: 0.000566139
	LOSS [training: 0.09248727240445521 | validation: 0.09853572055311]
	TIME [epoch: 8.36 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09454204477199916		[learning rate: 0.0005648]
	Learning Rate: 0.000564804
	LOSS [training: 0.09454204477199916 | validation: 0.08716317654274232]
	TIME [epoch: 8.33 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11280203090080307		[learning rate: 0.00056347]
	Learning Rate: 0.000563471
	LOSS [training: 0.11280203090080307 | validation: 0.09545124130388558]
	TIME [epoch: 8.33 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10149339550930588		[learning rate: 0.00056214]
	Learning Rate: 0.000562142
	LOSS [training: 0.10149339550930588 | validation: 0.09675724121982363]
	TIME [epoch: 8.34 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08347779731722138		[learning rate: 0.00056082]
	Learning Rate: 0.000560816
	LOSS [training: 0.08347779731722138 | validation: 0.0916381979772052]
	TIME [epoch: 8.35 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11874100247493172		[learning rate: 0.00055949]
	Learning Rate: 0.000559493
	LOSS [training: 0.11874100247493172 | validation: 0.09012781217162003]
	TIME [epoch: 8.34 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0955641957292403		[learning rate: 0.00055817]
	Learning Rate: 0.000558173
	LOSS [training: 0.0955641957292403 | validation: 0.09021851766829563]
	TIME [epoch: 8.33 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10228542962653733		[learning rate: 0.00055686]
	Learning Rate: 0.000556857
	LOSS [training: 0.10228542962653733 | validation: 0.09294295051394413]
	TIME [epoch: 8.34 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08847275082784292		[learning rate: 0.00055554]
	Learning Rate: 0.000555543
	LOSS [training: 0.08847275082784292 | validation: 0.09920553917330571]
	TIME [epoch: 8.35 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09094169674644828		[learning rate: 0.00055423]
	Learning Rate: 0.000554233
	LOSS [training: 0.09094169674644828 | validation: 0.07700531796066437]
	TIME [epoch: 8.34 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08490650582952457		[learning rate: 0.00055293]
	Learning Rate: 0.000552925
	LOSS [training: 0.08490650582952457 | validation: 0.11177508103920791]
	TIME [epoch: 8.33 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10624621504926837		[learning rate: 0.00055162]
	Learning Rate: 0.000551621
	LOSS [training: 0.10624621504926837 | validation: 0.07553306095070095]
	TIME [epoch: 8.34 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10597917355777889		[learning rate: 0.00055032]
	Learning Rate: 0.00055032
	LOSS [training: 0.10597917355777889 | validation: 0.13062876253966235]
	TIME [epoch: 8.35 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09478916712923739		[learning rate: 0.00054902]
	Learning Rate: 0.000549022
	LOSS [training: 0.09478916712923739 | validation: 0.09739540986231045]
	TIME [epoch: 8.33 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10249284840201296		[learning rate: 0.00054773]
	Learning Rate: 0.000547727
	LOSS [training: 0.10249284840201296 | validation: 0.08530380349865643]
	TIME [epoch: 8.34 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10467931227069707		[learning rate: 0.00054643]
	Learning Rate: 0.000546435
	LOSS [training: 0.10467931227069707 | validation: 0.09020969082828464]
	TIME [epoch: 8.34 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10481413640233321		[learning rate: 0.00054515]
	Learning Rate: 0.000545146
	LOSS [training: 0.10481413640233321 | validation: 0.0985443559721526]
	TIME [epoch: 8.35 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10361667211000307		[learning rate: 0.00054386]
	Learning Rate: 0.00054386
	LOSS [training: 0.10361667211000307 | validation: 0.1160233923539677]
	TIME [epoch: 8.33 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10261697323622551		[learning rate: 0.00054258]
	Learning Rate: 0.000542577
	LOSS [training: 0.10261697323622551 | validation: 0.09320764910000122]
	TIME [epoch: 8.33 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1114269118448944		[learning rate: 0.0005413]
	Learning Rate: 0.000541297
	LOSS [training: 0.1114269118448944 | validation: 0.0823107644347423]
	TIME [epoch: 8.33 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09871222554937609		[learning rate: 0.00054002]
	Learning Rate: 0.00054002
	LOSS [training: 0.09871222554937609 | validation: 0.08361625732158956]
	TIME [epoch: 8.35 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11831333619346873		[learning rate: 0.00053875]
	Learning Rate: 0.000538747
	LOSS [training: 0.11831333619346873 | validation: 0.08020676444922979]
	TIME [epoch: 8.34 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09627091732147484		[learning rate: 0.00053748]
	Learning Rate: 0.000537476
	LOSS [training: 0.09627091732147484 | validation: 0.07550905951136677]
	TIME [epoch: 8.33 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09702550245448101		[learning rate: 0.00053621]
	Learning Rate: 0.000536208
	LOSS [training: 0.09702550245448101 | validation: 0.07956216567105684]
	TIME [epoch: 8.35 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09340127523089164		[learning rate: 0.00053494]
	Learning Rate: 0.000534943
	LOSS [training: 0.09340127523089164 | validation: 0.09806597815322209]
	TIME [epoch: 8.34 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10112670939944719		[learning rate: 0.00053368]
	Learning Rate: 0.000533681
	LOSS [training: 0.10112670939944719 | validation: 0.09290351111966744]
	TIME [epoch: 8.34 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09580512560539642		[learning rate: 0.00053242]
	Learning Rate: 0.000532422
	LOSS [training: 0.09580512560539642 | validation: 0.08975246122683936]
	TIME [epoch: 8.33 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09727095587328624		[learning rate: 0.00053117]
	Learning Rate: 0.000531167
	LOSS [training: 0.09727095587328624 | validation: 0.11551076286621806]
	TIME [epoch: 8.34 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09722295078468648		[learning rate: 0.00052991]
	Learning Rate: 0.000529914
	LOSS [training: 0.09722295078468648 | validation: 0.07382251059242939]
	TIME [epoch: 8.35 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09827211961249527		[learning rate: 0.00052866]
	Learning Rate: 0.000528664
	LOSS [training: 0.09827211961249527 | validation: 0.08714453050191903]
	TIME [epoch: 8.33 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09442460358427454		[learning rate: 0.00052742]
	Learning Rate: 0.000527417
	LOSS [training: 0.09442460358427454 | validation: 0.08447817413295965]
	TIME [epoch: 8.33 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09986649374130101		[learning rate: 0.00052617]
	Learning Rate: 0.000526173
	LOSS [training: 0.09986649374130101 | validation: 0.09478506660798697]
	TIME [epoch: 8.35 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10114651028204344		[learning rate: 0.00052493]
	Learning Rate: 0.000524931
	LOSS [training: 0.10114651028204344 | validation: 0.11943836135903745]
	TIME [epoch: 8.35 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1106103650178372		[learning rate: 0.00052369]
	Learning Rate: 0.000523693
	LOSS [training: 0.1106103650178372 | validation: 0.08218115589961333]
	TIME [epoch: 8.34 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09283365432122061		[learning rate: 0.00052246]
	Learning Rate: 0.000522458
	LOSS [training: 0.09283365432122061 | validation: 0.06333389020279706]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_1300.pth
	Model improved!!!
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09087560563464245		[learning rate: 0.00052123]
	Learning Rate: 0.000521225
	LOSS [training: 0.09087560563464245 | validation: 0.09430468120885865]
	TIME [epoch: 8.35 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1101708445138309		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.1101708445138309 | validation: 0.07508657909627331]
	TIME [epoch: 8.34 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09494365842748678		[learning rate: 0.00051877]
	Learning Rate: 0.000518769
	LOSS [training: 0.09494365842748678 | validation: 0.08766153400173174]
	TIME [epoch: 8.33 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0936326085425379		[learning rate: 0.00051755]
	Learning Rate: 0.000517546
	LOSS [training: 0.0936326085425379 | validation: 0.06856087111648662]
	TIME [epoch: 8.32 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09595203185607616		[learning rate: 0.00051632]
	Learning Rate: 0.000516325
	LOSS [training: 0.09595203185607616 | validation: 0.07739466492832062]
	TIME [epoch: 8.34 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09581920949674452		[learning rate: 0.00051511]
	Learning Rate: 0.000515107
	LOSS [training: 0.09581920949674452 | validation: 0.0997870217285253]
	TIME [epoch: 8.33 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09538303534585614		[learning rate: 0.00051389]
	Learning Rate: 0.000513892
	LOSS [training: 0.09538303534585614 | validation: 0.07765639336011801]
	TIME [epoch: 8.33 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09272610994049028		[learning rate: 0.00051268]
	Learning Rate: 0.00051268
	LOSS [training: 0.09272610994049028 | validation: 0.07942978156370677]
	TIME [epoch: 8.33 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09382742181407701		[learning rate: 0.00051147]
	Learning Rate: 0.00051147
	LOSS [training: 0.09382742181407701 | validation: 0.07904534857718219]
	TIME [epoch: 8.35 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09509377464873382		[learning rate: 0.00051026]
	Learning Rate: 0.000510264
	LOSS [training: 0.09509377464873382 | validation: 0.09138712998310178]
	TIME [epoch: 8.33 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09338983310380215		[learning rate: 0.00050906]
	Learning Rate: 0.00050906
	LOSS [training: 0.09338983310380215 | validation: 0.07610148010279247]
	TIME [epoch: 8.33 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0993636431718433		[learning rate: 0.00050786]
	Learning Rate: 0.000507859
	LOSS [training: 0.0993636431718433 | validation: 0.0771765346016159]
	TIME [epoch: 8.32 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10361739943014292		[learning rate: 0.00050666]
	Learning Rate: 0.000506662
	LOSS [training: 0.10361739943014292 | validation: 0.076428405461542]
	TIME [epoch: 8.35 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09316903177245342		[learning rate: 0.00050547]
	Learning Rate: 0.000505466
	LOSS [training: 0.09316903177245342 | validation: 0.08450874514480108]
	TIME [epoch: 8.33 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09323974444285729		[learning rate: 0.00050427]
	Learning Rate: 0.000504274
	LOSS [training: 0.09323974444285729 | validation: 0.07075539213147619]
	TIME [epoch: 8.34 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09707558908433397		[learning rate: 0.00050308]
	Learning Rate: 0.000503085
	LOSS [training: 0.09707558908433397 | validation: 0.09522014042084379]
	TIME [epoch: 8.33 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10278090758195695		[learning rate: 0.0005019]
	Learning Rate: 0.000501898
	LOSS [training: 0.10278090758195695 | validation: 0.09684990373656532]
	TIME [epoch: 8.36 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11707693361500357		[learning rate: 0.00050071]
	Learning Rate: 0.000500714
	LOSS [training: 0.11707693361500357 | validation: 0.09161313956471509]
	TIME [epoch: 8.34 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11868251903052474		[learning rate: 0.00049953]
	Learning Rate: 0.000499533
	LOSS [training: 0.11868251903052474 | validation: 0.10231833595414805]
	TIME [epoch: 8.33 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10078091572977328		[learning rate: 0.00049835]
	Learning Rate: 0.000498355
	LOSS [training: 0.10078091572977328 | validation: 0.0884979518745333]
	TIME [epoch: 8.33 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11453311576887464		[learning rate: 0.00049718]
	Learning Rate: 0.000497179
	LOSS [training: 0.11453311576887464 | validation: 0.06900995797145562]
	TIME [epoch: 8.35 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09996519656855561		[learning rate: 0.00049601]
	Learning Rate: 0.000496006
	LOSS [training: 0.09996519656855561 | validation: 0.0847665194368846]
	TIME [epoch: 8.34 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10394550361794512		[learning rate: 0.00049484]
	Learning Rate: 0.000494836
	LOSS [training: 0.10394550361794512 | validation: 0.07221029811591632]
	TIME [epoch: 8.33 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10701887886679104		[learning rate: 0.00049367]
	Learning Rate: 0.000493669
	LOSS [training: 0.10701887886679104 | validation: 0.08869545641097995]
	TIME [epoch: 8.33 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09943834433783161		[learning rate: 0.0004925]
	Learning Rate: 0.000492505
	LOSS [training: 0.09943834433783161 | validation: 0.08865979209835648]
	TIME [epoch: 8.36 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10301148083224387		[learning rate: 0.00049134]
	Learning Rate: 0.000491343
	LOSS [training: 0.10301148083224387 | validation: 0.09217047538829301]
	TIME [epoch: 8.34 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09870950567638702		[learning rate: 0.00049018]
	Learning Rate: 0.000490184
	LOSS [training: 0.09870950567638702 | validation: 0.08407705110318384]
	TIME [epoch: 8.33 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1095622670154951		[learning rate: 0.00048903]
	Learning Rate: 0.000489027
	LOSS [training: 0.1095622670154951 | validation: 0.10001880257247137]
	TIME [epoch: 8.33 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09758771741218328		[learning rate: 0.00048787]
	Learning Rate: 0.000487874
	LOSS [training: 0.09758771741218328 | validation: 0.07831813671810192]
	TIME [epoch: 8.35 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10262720598795419		[learning rate: 0.00048672]
	Learning Rate: 0.000486723
	LOSS [training: 0.10262720598795419 | validation: 0.10973581452600115]
	TIME [epoch: 8.33 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0999626169320434		[learning rate: 0.00048558]
	Learning Rate: 0.000485575
	LOSS [training: 0.0999626169320434 | validation: 0.08383132354206438]
	TIME [epoch: 8.33 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09890497971557217		[learning rate: 0.00048443]
	Learning Rate: 0.00048443
	LOSS [training: 0.09890497971557217 | validation: 0.08095598834260323]
	TIME [epoch: 8.32 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11497672087813608		[learning rate: 0.00048329]
	Learning Rate: 0.000483287
	LOSS [training: 0.11497672087813608 | validation: 0.09294659639509431]
	TIME [epoch: 8.35 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09764379937949143		[learning rate: 0.00048215]
	Learning Rate: 0.000482147
	LOSS [training: 0.09764379937949143 | validation: 0.09384753780956456]
	TIME [epoch: 8.33 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09577503429448195		[learning rate: 0.00048101]
	Learning Rate: 0.00048101
	LOSS [training: 0.09577503429448195 | validation: 0.0938390910474754]
	TIME [epoch: 8.33 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09448263257975135		[learning rate: 0.00047988]
	Learning Rate: 0.000479875
	LOSS [training: 0.09448263257975135 | validation: 0.07621312343406357]
	TIME [epoch: 8.33 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08843846125568722		[learning rate: 0.00047874]
	Learning Rate: 0.000478743
	LOSS [training: 0.08843846125568722 | validation: 0.11672591914010401]
	TIME [epoch: 8.35 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10354048011057493		[learning rate: 0.00047761]
	Learning Rate: 0.000477614
	LOSS [training: 0.10354048011057493 | validation: 0.06708799071877042]
	TIME [epoch: 8.34 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09253764792590435		[learning rate: 0.00047649]
	Learning Rate: 0.000476487
	LOSS [training: 0.09253764792590435 | validation: 0.06803786799439764]
	TIME [epoch: 8.32 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08435134262171752		[learning rate: 0.00047536]
	Learning Rate: 0.000475363
	LOSS [training: 0.08435134262171752 | validation: 0.06971637874740065]
	TIME [epoch: 8.33 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09486923129311936		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.09486923129311936 | validation: 0.07562106710816338]
	TIME [epoch: 8.35 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09289987845085161		[learning rate: 0.00047312]
	Learning Rate: 0.000473123
	LOSS [training: 0.09289987845085161 | validation: 0.09490760660538283]
	TIME [epoch: 8.33 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10608341391850604		[learning rate: 0.00047201]
	Learning Rate: 0.000472007
	LOSS [training: 0.10608341391850604 | validation: 0.08856556086154921]
	TIME [epoch: 8.32 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09488133101642332		[learning rate: 0.00047089]
	Learning Rate: 0.000470894
	LOSS [training: 0.09488133101642332 | validation: 0.08104223571607826]
	TIME [epoch: 8.34 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1003524568460985		[learning rate: 0.00046978]
	Learning Rate: 0.000469783
	LOSS [training: 0.1003524568460985 | validation: 0.10830461268610203]
	TIME [epoch: 8.35 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10773031047901187		[learning rate: 0.00046867]
	Learning Rate: 0.000468675
	LOSS [training: 0.10773031047901187 | validation: 0.07655204062654886]
	TIME [epoch: 8.33 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1152904074928897		[learning rate: 0.00046757]
	Learning Rate: 0.000467569
	LOSS [training: 0.1152904074928897 | validation: 0.09671955328691866]
	TIME [epoch: 8.34 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09814642159370815		[learning rate: 0.00046647]
	Learning Rate: 0.000466467
	LOSS [training: 0.09814642159370815 | validation: 0.07488952704112226]
	TIME [epoch: 8.34 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11078513190556045		[learning rate: 0.00046537]
	Learning Rate: 0.000465366
	LOSS [training: 0.11078513190556045 | validation: 0.07391644049485113]
	TIME [epoch: 8.35 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08938263815715666		[learning rate: 0.00046427]
	Learning Rate: 0.000464269
	LOSS [training: 0.08938263815715666 | validation: 0.06701753259135551]
	TIME [epoch: 8.33 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10826012370037112		[learning rate: 0.00046317]
	Learning Rate: 0.000463173
	LOSS [training: 0.10826012370037112 | validation: 0.09176711143712381]
	TIME [epoch: 8.33 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09293293700031395		[learning rate: 0.00046208]
	Learning Rate: 0.000462081
	LOSS [training: 0.09293293700031395 | validation: 0.093540249175627]
	TIME [epoch: 8.33 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09766119193029525		[learning rate: 0.00046099]
	Learning Rate: 0.000460991
	LOSS [training: 0.09766119193029525 | validation: 0.07840652243211038]
	TIME [epoch: 8.35 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09105287006854279		[learning rate: 0.0004599]
	Learning Rate: 0.000459903
	LOSS [training: 0.09105287006854279 | validation: 0.09511653439438737]
	TIME [epoch: 8.34 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09384686208498348		[learning rate: 0.00045882]
	Learning Rate: 0.000458819
	LOSS [training: 0.09384686208498348 | validation: 0.07262561551786284]
	TIME [epoch: 8.33 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09794884920196698		[learning rate: 0.00045774]
	Learning Rate: 0.000457736
	LOSS [training: 0.09794884920196698 | validation: 0.08799609135053216]
	TIME [epoch: 8.33 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09275038066632979		[learning rate: 0.00045666]
	Learning Rate: 0.000456657
	LOSS [training: 0.09275038066632979 | validation: 0.06506327190314096]
	TIME [epoch: 8.36 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09879235593802285		[learning rate: 0.00045558]
	Learning Rate: 0.000455579
	LOSS [training: 0.09879235593802285 | validation: 0.08601515947601343]
	TIME [epoch: 8.33 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09670266458385948		[learning rate: 0.0004545]
	Learning Rate: 0.000454505
	LOSS [training: 0.09670266458385948 | validation: 0.08114661038934246]
	TIME [epoch: 8.33 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09192551014918869		[learning rate: 0.00045343]
	Learning Rate: 0.000453433
	LOSS [training: 0.09192551014918869 | validation: 0.102599773255621]
	TIME [epoch: 8.33 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0927783605481036		[learning rate: 0.00045236]
	Learning Rate: 0.000452363
	LOSS [training: 0.0927783605481036 | validation: 0.08252790065157833]
	TIME [epoch: 8.35 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10000913935664642		[learning rate: 0.0004513]
	Learning Rate: 0.000451296
	LOSS [training: 0.10000913935664642 | validation: 0.08088380114664118]
	TIME [epoch: 8.33 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09327702171860605		[learning rate: 0.00045023]
	Learning Rate: 0.000450232
	LOSS [training: 0.09327702171860605 | validation: 0.07239077800697238]
	TIME [epoch: 8.33 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10622349699655356		[learning rate: 0.00044917]
	Learning Rate: 0.000449169
	LOSS [training: 0.10622349699655356 | validation: 0.08553699856970301]
	TIME [epoch: 8.33 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09574403026331395		[learning rate: 0.00044811]
	Learning Rate: 0.00044811
	LOSS [training: 0.09574403026331395 | validation: 0.07757333010573654]
	TIME [epoch: 8.35 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09619831707252108		[learning rate: 0.00044705]
	Learning Rate: 0.000447053
	LOSS [training: 0.09619831707252108 | validation: 0.0702384470905312]
	TIME [epoch: 8.32 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09445157303908237		[learning rate: 0.000446]
	Learning Rate: 0.000445998
	LOSS [training: 0.09445157303908237 | validation: 0.08111942094336867]
	TIME [epoch: 8.33 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09656516549145823		[learning rate: 0.00044495]
	Learning Rate: 0.000444946
	LOSS [training: 0.09656516549145823 | validation: 0.07892866210667776]
	TIME [epoch: 8.34 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0912115157691699		[learning rate: 0.0004439]
	Learning Rate: 0.000443897
	LOSS [training: 0.0912115157691699 | validation: 0.08729417708778237]
	TIME [epoch: 8.35 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08774542111106318		[learning rate: 0.00044285]
	Learning Rate: 0.00044285
	LOSS [training: 0.08774542111106318 | validation: 0.09690139353394235]
	TIME [epoch: 8.33 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10426255532855158		[learning rate: 0.00044181]
	Learning Rate: 0.000441805
	LOSS [training: 0.10426255532855158 | validation: 0.09386554460760649]
	TIME [epoch: 8.33 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09387667796875018		[learning rate: 0.00044076]
	Learning Rate: 0.000440763
	LOSS [training: 0.09387667796875018 | validation: 0.08616677795685512]
	TIME [epoch: 8.33 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08903593570840639		[learning rate: 0.00043972]
	Learning Rate: 0.000439723
	LOSS [training: 0.08903593570840639 | validation: 0.07399671561878722]
	TIME [epoch: 8.36 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08868676145507433		[learning rate: 0.00043869]
	Learning Rate: 0.000438686
	LOSS [training: 0.08868676145507433 | validation: 0.06292193835027238]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_1374.pth
	Model improved!!!
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09649844651972692		[learning rate: 0.00043765]
	Learning Rate: 0.000437651
	LOSS [training: 0.09649844651972692 | validation: 0.0974254859844414]
	TIME [epoch: 8.34 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10052949507595157		[learning rate: 0.00043662]
	Learning Rate: 0.000436619
	LOSS [training: 0.10052949507595157 | validation: 0.07750583335732517]
	TIME [epoch: 8.33 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09133350088264458		[learning rate: 0.00043559]
	Learning Rate: 0.000435589
	LOSS [training: 0.09133350088264458 | validation: 0.06172376108498716]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_1377.pth
	Model improved!!!
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09685654425784251		[learning rate: 0.00043456]
	Learning Rate: 0.000434562
	LOSS [training: 0.09685654425784251 | validation: 0.06314781565664498]
	TIME [epoch: 8.34 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08563696589394512		[learning rate: 0.00043354]
	Learning Rate: 0.000433536
	LOSS [training: 0.08563696589394512 | validation: 0.07574792393546813]
	TIME [epoch: 8.33 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1017734935230377		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.1017734935230377 | validation: 0.08789498725975022]
	TIME [epoch: 8.34 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0993362739987326		[learning rate: 0.00043149]
	Learning Rate: 0.000431494
	LOSS [training: 0.0993362739987326 | validation: 0.09779975989669008]
	TIME [epoch: 8.35 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09585154975051148		[learning rate: 0.00043048]
	Learning Rate: 0.000430476
	LOSS [training: 0.09585154975051148 | validation: 0.07754244613823688]
	TIME [epoch: 8.33 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08813714041377921		[learning rate: 0.00042946]
	Learning Rate: 0.00042946
	LOSS [training: 0.08813714041377921 | validation: 0.07916066457275306]
	TIME [epoch: 8.33 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09915674968556602		[learning rate: 0.00042845]
	Learning Rate: 0.000428447
	LOSS [training: 0.09915674968556602 | validation: 0.07856444954324582]
	TIME [epoch: 8.33 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08233582930929417		[learning rate: 0.00042744]
	Learning Rate: 0.000427437
	LOSS [training: 0.08233582930929417 | validation: 0.05379327021334811]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_1385.pth
	Model improved!!!
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08265667243820132		[learning rate: 0.00042643]
	Learning Rate: 0.000426428
	LOSS [training: 0.08265667243820132 | validation: 0.08370714924753445]
	TIME [epoch: 8.33 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0901613833628935		[learning rate: 0.00042542]
	Learning Rate: 0.000425423
	LOSS [training: 0.0901613833628935 | validation: 0.07028117459307148]
	TIME [epoch: 8.34 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08295972893848082		[learning rate: 0.00042442]
	Learning Rate: 0.000424419
	LOSS [training: 0.08295972893848082 | validation: 0.08241920614675124]
	TIME [epoch: 8.34 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12102791083588235		[learning rate: 0.00042342]
	Learning Rate: 0.000423418
	LOSS [training: 0.12102791083588235 | validation: 0.08544508596939832]
	TIME [epoch: 8.36 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09986021538353314		[learning rate: 0.00042242]
	Learning Rate: 0.000422419
	LOSS [training: 0.09986021538353314 | validation: 0.08498390175318063]
	TIME [epoch: 8.34 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0936848171726513		[learning rate: 0.00042142]
	Learning Rate: 0.000421423
	LOSS [training: 0.0936848171726513 | validation: 0.06596570189116129]
	TIME [epoch: 8.35 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08255162529509136		[learning rate: 0.00042043]
	Learning Rate: 0.000420429
	LOSS [training: 0.08255162529509136 | validation: 0.06968688120383858]
	TIME [epoch: 8.34 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09618272868048805		[learning rate: 0.00041944]
	Learning Rate: 0.000419437
	LOSS [training: 0.09618272868048805 | validation: 0.0912861641508555]
	TIME [epoch: 8.37 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09752194211727425		[learning rate: 0.00041845]
	Learning Rate: 0.000418448
	LOSS [training: 0.09752194211727425 | validation: 0.10665433983575828]
	TIME [epoch: 8.34 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10884408526608542		[learning rate: 0.00041746]
	Learning Rate: 0.00041746
	LOSS [training: 0.10884408526608542 | validation: 0.07332416971167235]
	TIME [epoch: 8.34 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09455037170228867		[learning rate: 0.00041648]
	Learning Rate: 0.000416476
	LOSS [training: 0.09455037170228867 | validation: 0.0977008894250958]
	TIME [epoch: 8.34 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0962841461479468		[learning rate: 0.00041549]
	Learning Rate: 0.000415493
	LOSS [training: 0.0962841461479468 | validation: 0.0780477769065682]
	TIME [epoch: 8.38 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09343098667868674		[learning rate: 0.00041451]
	Learning Rate: 0.000414513
	LOSS [training: 0.09343098667868674 | validation: 0.07601904755341193]
	TIME [epoch: 8.34 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09732884015191813		[learning rate: 0.00041354]
	Learning Rate: 0.000413535
	LOSS [training: 0.09732884015191813 | validation: 0.08217353416119488]
	TIME [epoch: 8.35 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09170830862593392		[learning rate: 0.00041256]
	Learning Rate: 0.00041256
	LOSS [training: 0.09170830862593392 | validation: 0.07696121897613117]
	TIME [epoch: 8.34 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09510660052145782		[learning rate: 0.00041159]
	Learning Rate: 0.000411587
	LOSS [training: 0.09510660052145782 | validation: 0.09185250966685692]
	TIME [epoch: 8.37 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0843829118317399		[learning rate: 0.00041062]
	Learning Rate: 0.000410616
	LOSS [training: 0.0843829118317399 | validation: 0.0814321516861252]
	TIME [epoch: 8.34 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09126362621374674		[learning rate: 0.00040965]
	Learning Rate: 0.000409647
	LOSS [training: 0.09126362621374674 | validation: 0.09522828380060513]
	TIME [epoch: 8.35 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0932539008827745		[learning rate: 0.00040868]
	Learning Rate: 0.000408681
	LOSS [training: 0.0932539008827745 | validation: 0.07914645369268582]
	TIME [epoch: 8.34 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09605176082529382		[learning rate: 0.00040772]
	Learning Rate: 0.000407717
	LOSS [training: 0.09605176082529382 | validation: 0.07382763348597406]
	TIME [epoch: 8.37 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09225319726426738		[learning rate: 0.00040676]
	Learning Rate: 0.000406755
	LOSS [training: 0.09225319726426738 | validation: 0.07964929573468074]
	TIME [epoch: 8.34 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09851321433652768		[learning rate: 0.0004058]
	Learning Rate: 0.000405796
	LOSS [training: 0.09851321433652768 | validation: 0.0660686647539673]
	TIME [epoch: 8.35 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09263981360700883		[learning rate: 0.00040484]
	Learning Rate: 0.000404839
	LOSS [training: 0.09263981360700883 | validation: 0.08878469341305907]
	TIME [epoch: 8.34 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08913338103833675		[learning rate: 0.00040388]
	Learning Rate: 0.000403884
	LOSS [training: 0.08913338103833675 | validation: 0.07031364708253987]
	TIME [epoch: 8.36 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09237246903500652		[learning rate: 0.00040293]
	Learning Rate: 0.000402931
	LOSS [training: 0.09237246903500652 | validation: 0.1147457606558773]
	TIME [epoch: 8.34 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11313265347590817		[learning rate: 0.00040198]
	Learning Rate: 0.000401981
	LOSS [training: 0.11313265347590817 | validation: 0.07710568884759139]
	TIME [epoch: 8.35 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10708173333521753		[learning rate: 0.00040103]
	Learning Rate: 0.000401032
	LOSS [training: 0.10708173333521753 | validation: 0.10896861816295761]
	TIME [epoch: 8.35 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11816874743199435		[learning rate: 0.00040009]
	Learning Rate: 0.000400086
	LOSS [training: 0.11816874743199435 | validation: 0.09681486017923854]
	TIME [epoch: 8.37 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10143962804159139		[learning rate: 0.00039914]
	Learning Rate: 0.000399143
	LOSS [training: 0.10143962804159139 | validation: 0.07343870299611734]
	TIME [epoch: 8.34 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09501839644040151		[learning rate: 0.0003982]
	Learning Rate: 0.000398201
	LOSS [training: 0.09501839644040151 | validation: 0.08393561223932677]
	TIME [epoch: 8.35 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09542065350435973		[learning rate: 0.00039726]
	Learning Rate: 0.000397262
	LOSS [training: 0.09542065350435973 | validation: 0.0888493496279848]
	TIME [epoch: 8.35 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09366095046519904		[learning rate: 0.00039632]
	Learning Rate: 0.000396325
	LOSS [training: 0.09366095046519904 | validation: 0.06714420813847827]
	TIME [epoch: 8.37 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08367570979577113		[learning rate: 0.00039539]
	Learning Rate: 0.00039539
	LOSS [training: 0.08367570979577113 | validation: 0.09233558604521976]
	TIME [epoch: 8.34 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08853943300438578		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.08853943300438578 | validation: 0.07747520456240675]
	TIME [epoch: 8.34 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08396341472580401		[learning rate: 0.00039353]
	Learning Rate: 0.000393527
	LOSS [training: 0.08396341472580401 | validation: 0.07290542144860229]
	TIME [epoch: 8.35 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08803479894304947		[learning rate: 0.0003926]
	Learning Rate: 0.000392599
	LOSS [training: 0.08803479894304947 | validation: 0.07708630651629636]
	TIME [epoch: 8.36 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09255753730106456		[learning rate: 0.00039167]
	Learning Rate: 0.000391672
	LOSS [training: 0.09255753730106456 | validation: 0.09715007377395943]
	TIME [epoch: 8.34 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09779883591813958		[learning rate: 0.00039075]
	Learning Rate: 0.000390748
	LOSS [training: 0.09779883591813958 | validation: 0.07733676098029822]
	TIME [epoch: 8.34 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08803706049672905		[learning rate: 0.00038983]
	Learning Rate: 0.000389827
	LOSS [training: 0.08803706049672905 | validation: 0.08625791792464818]
	TIME [epoch: 8.36 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10187081065992036		[learning rate: 0.00038891]
	Learning Rate: 0.000388907
	LOSS [training: 0.10187081065992036 | validation: 0.10826961437838453]
	TIME [epoch: 8.35 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10268920024026273		[learning rate: 0.00038799]
	Learning Rate: 0.00038799
	LOSS [training: 0.10268920024026273 | validation: 0.07773639331366354]
	TIME [epoch: 8.33 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09452148067028779		[learning rate: 0.00038707]
	Learning Rate: 0.000387075
	LOSS [training: 0.09452148067028779 | validation: 0.07441134616264058]
	TIME [epoch: 8.34 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08765246374208846		[learning rate: 0.00038616]
	Learning Rate: 0.000386162
	LOSS [training: 0.08765246374208846 | validation: 0.09523480052018268]
	TIME [epoch: 8.35 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09690157750873403		[learning rate: 0.00038525]
	Learning Rate: 0.000385251
	LOSS [training: 0.09690157750873403 | validation: 0.09244542428582539]
	TIME [epoch: 8.34 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09069273458382451		[learning rate: 0.00038434]
	Learning Rate: 0.000384342
	LOSS [training: 0.09069273458382451 | validation: 0.06160883295846799]
	TIME [epoch: 8.34 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0914514287664758		[learning rate: 0.00038344]
	Learning Rate: 0.000383435
	LOSS [training: 0.0914514287664758 | validation: 0.09510883557166097]
	TIME [epoch: 8.33 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09224195193386828		[learning rate: 0.00038253]
	Learning Rate: 0.000382531
	LOSS [training: 0.09224195193386828 | validation: 0.09248260380453131]
	TIME [epoch: 8.35 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08533170479024851		[learning rate: 0.00038163]
	Learning Rate: 0.000381629
	LOSS [training: 0.08533170479024851 | validation: 0.07309575430779233]
	TIME [epoch: 8.34 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0777397450617051		[learning rate: 0.00038073]
	Learning Rate: 0.000380729
	LOSS [training: 0.0777397450617051 | validation: 0.06914156352552181]
	TIME [epoch: 8.34 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08683918123390626		[learning rate: 0.00037983]
	Learning Rate: 0.00037983
	LOSS [training: 0.08683918123390626 | validation: 0.08794218730829481]
	TIME [epoch: 8.33 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08979755066347248		[learning rate: 0.00037893]
	Learning Rate: 0.000378934
	LOSS [training: 0.08979755066347248 | validation: 0.07581057730260457]
	TIME [epoch: 8.35 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09107679462254029		[learning rate: 0.00037804]
	Learning Rate: 0.000378041
	LOSS [training: 0.09107679462254029 | validation: 0.061445606309835615]
	TIME [epoch: 8.34 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08916492538320292		[learning rate: 0.00037715]
	Learning Rate: 0.000377149
	LOSS [training: 0.08916492538320292 | validation: 0.0870098867604222]
	TIME [epoch: 8.34 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0923143032956215		[learning rate: 0.00037626]
	Learning Rate: 0.000376259
	LOSS [training: 0.0923143032956215 | validation: 0.06934543745882213]
	TIME [epoch: 8.34 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08697472642491172		[learning rate: 0.00037537]
	Learning Rate: 0.000375372
	LOSS [training: 0.08697472642491172 | validation: 0.09147186476462729]
	TIME [epoch: 8.34 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09410740808654083		[learning rate: 0.00037449]
	Learning Rate: 0.000374486
	LOSS [training: 0.09410740808654083 | validation: 0.07986616557919063]
	TIME [epoch: 8.34 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09272642375633658		[learning rate: 0.0003736]
	Learning Rate: 0.000373603
	LOSS [training: 0.09272642375633658 | validation: 0.07725391077118626]
	TIME [epoch: 8.33 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09485387335880818		[learning rate: 0.00037272]
	Learning Rate: 0.000372722
	LOSS [training: 0.09485387335880818 | validation: 0.08125021180679255]
	TIME [epoch: 8.33 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08815178123820792		[learning rate: 0.00037184]
	Learning Rate: 0.000371842
	LOSS [training: 0.08815178123820792 | validation: 0.08577466920717647]
	TIME [epoch: 8.35 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09287382668495209		[learning rate: 0.00037097]
	Learning Rate: 0.000370965
	LOSS [training: 0.09287382668495209 | validation: 0.08857378252020098]
	TIME [epoch: 8.34 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10217787659169493		[learning rate: 0.00037009]
	Learning Rate: 0.00037009
	LOSS [training: 0.10217787659169493 | validation: 0.08419383799040644]
	TIME [epoch: 8.33 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08096889107930874		[learning rate: 0.00036922]
	Learning Rate: 0.000369217
	LOSS [training: 0.08096889107930874 | validation: 0.0894686074476444]
	TIME [epoch: 8.33 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08545289741176074		[learning rate: 0.00036835]
	Learning Rate: 0.000368346
	LOSS [training: 0.08545289741176074 | validation: 0.07485435954903141]
	TIME [epoch: 8.34 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08537050868444243		[learning rate: 0.00036748]
	Learning Rate: 0.000367477
	LOSS [training: 0.08537050868444243 | validation: 0.07468917117028284]
	TIME [epoch: 8.34 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09160790933962432		[learning rate: 0.00036661]
	Learning Rate: 0.000366611
	LOSS [training: 0.09160790933962432 | validation: 0.0733779524184221]
	TIME [epoch: 8.33 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09928965767411643		[learning rate: 0.00036575]
	Learning Rate: 0.000365746
	LOSS [training: 0.09928965767411643 | validation: 0.0908433987161337]
	TIME [epoch: 8.33 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10451496757635484		[learning rate: 0.00036488]
	Learning Rate: 0.000364883
	LOSS [training: 0.10451496757635484 | validation: 0.13566157688265087]
	TIME [epoch: 8.36 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12018986091315187		[learning rate: 0.00036402]
	Learning Rate: 0.000364022
	LOSS [training: 0.12018986091315187 | validation: 0.09347596775698669]
	TIME [epoch: 8.34 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0969405221198853		[learning rate: 0.00036316]
	Learning Rate: 0.000363164
	LOSS [training: 0.0969405221198853 | validation: 0.06688564439596938]
	TIME [epoch: 8.33 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07891007135889148		[learning rate: 0.00036231]
	Learning Rate: 0.000362307
	LOSS [training: 0.07891007135889148 | validation: 0.0699310484008703]
	TIME [epoch: 8.33 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08944864654848361		[learning rate: 0.00036145]
	Learning Rate: 0.000361452
	LOSS [training: 0.08944864654848361 | validation: 0.06689828392799972]
	TIME [epoch: 8.35 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10451251994432018		[learning rate: 0.0003606]
	Learning Rate: 0.0003606
	LOSS [training: 0.10451251994432018 | validation: 0.09208931224815986]
	TIME [epoch: 8.33 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11728607698313351		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.11728607698313351 | validation: 0.10254790718990571]
	TIME [epoch: 8.33 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09303399474570487		[learning rate: 0.0003589]
	Learning Rate: 0.000358901
	LOSS [training: 0.09303399474570487 | validation: 0.07119687553888346]
	TIME [epoch: 8.33 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08845538719007075		[learning rate: 0.00035805]
	Learning Rate: 0.000358054
	LOSS [training: 0.08845538719007075 | validation: 0.0866677913685136]
	TIME [epoch: 8.35 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08720206169567266		[learning rate: 0.00035721]
	Learning Rate: 0.00035721
	LOSS [training: 0.08720206169567266 | validation: 0.06764577611334671]
	TIME [epoch: 8.34 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08081883598843348		[learning rate: 0.00035637]
	Learning Rate: 0.000356367
	LOSS [training: 0.08081883598843348 | validation: 0.07439219691523549]
	TIME [epoch: 8.33 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09090944473212342		[learning rate: 0.00035553]
	Learning Rate: 0.000355526
	LOSS [training: 0.09090944473212342 | validation: 0.07339391855069945]
	TIME [epoch: 8.33 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10707805765022538		[learning rate: 0.00035469]
	Learning Rate: 0.000354688
	LOSS [training: 0.10707805765022538 | validation: 0.07910275276529605]
	TIME [epoch: 8.35 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08971806653336349		[learning rate: 0.00035385]
	Learning Rate: 0.000353851
	LOSS [training: 0.08971806653336349 | validation: 0.0841061843498492]
	TIME [epoch: 8.33 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08937861008079902		[learning rate: 0.00035302]
	Learning Rate: 0.000353016
	LOSS [training: 0.08937861008079902 | validation: 0.08512406486634959]
	TIME [epoch: 8.33 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08435874726960493		[learning rate: 0.00035218]
	Learning Rate: 0.000352184
	LOSS [training: 0.08435874726960493 | validation: 0.0877885934144959]
	TIME [epoch: 8.33 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09127050496124706		[learning rate: 0.00035135]
	Learning Rate: 0.000351353
	LOSS [training: 0.09127050496124706 | validation: 0.08938429653793797]
	TIME [epoch: 8.36 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0905085849522283		[learning rate: 0.00035052]
	Learning Rate: 0.000350524
	LOSS [training: 0.0905085849522283 | validation: 0.0688995605060504]
	TIME [epoch: 8.33 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09141046876871346		[learning rate: 0.0003497]
	Learning Rate: 0.000349697
	LOSS [training: 0.09141046876871346 | validation: 0.0745289670004135]
	TIME [epoch: 8.32 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08348655347850224		[learning rate: 0.00034887]
	Learning Rate: 0.000348872
	LOSS [training: 0.08348655347850224 | validation: 0.06292968591145161]
	TIME [epoch: 8.33 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08709618677028862		[learning rate: 0.00034805]
	Learning Rate: 0.000348049
	LOSS [training: 0.08709618677028862 | validation: 0.07490561892322005]
	TIME [epoch: 8.35 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07855244199934693		[learning rate: 0.00034723]
	Learning Rate: 0.000347228
	LOSS [training: 0.07855244199934693 | validation: 0.07410924777899491]
	TIME [epoch: 8.33 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08153982791604404		[learning rate: 0.00034641]
	Learning Rate: 0.000346409
	LOSS [training: 0.08153982791604404 | validation: 0.08144354642982081]
	TIME [epoch: 8.32 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08968287689058907		[learning rate: 0.00034559]
	Learning Rate: 0.000345592
	LOSS [training: 0.08968287689058907 | validation: 0.07697275579761419]
	TIME [epoch: 8.33 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09943848112174324		[learning rate: 0.00034478]
	Learning Rate: 0.000344777
	LOSS [training: 0.09943848112174324 | validation: 0.09030299276505793]
	TIME [epoch: 8.36 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1018116359905153		[learning rate: 0.00034396]
	Learning Rate: 0.000343964
	LOSS [training: 0.1018116359905153 | validation: 0.08005800315126155]
	TIME [epoch: 8.33 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09860899200814892		[learning rate: 0.00034315]
	Learning Rate: 0.000343152
	LOSS [training: 0.09860899200814892 | validation: 0.08261652208204961]
	TIME [epoch: 8.33 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10284921996681437		[learning rate: 0.00034234]
	Learning Rate: 0.000342343
	LOSS [training: 0.10284921996681437 | validation: 0.06860438313454222]
	TIME [epoch: 8.34 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09835658702176894		[learning rate: 0.00034154]
	Learning Rate: 0.000341536
	LOSS [training: 0.09835658702176894 | validation: 0.10769311935302346]
	TIME [epoch: 8.35 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10077791090595892		[learning rate: 0.00034073]
	Learning Rate: 0.00034073
	LOSS [training: 0.10077791090595892 | validation: 0.07158545781343698]
	TIME [epoch: 8.33 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10185613764220705		[learning rate: 0.00033993]
	Learning Rate: 0.000339926
	LOSS [training: 0.10185613764220705 | validation: 0.08103710103944377]
	TIME [epoch: 8.33 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09909328837976214		[learning rate: 0.00033912]
	Learning Rate: 0.000339124
	LOSS [training: 0.09909328837976214 | validation: 0.08964690518427523]
	TIME [epoch: 8.33 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1015656882624227		[learning rate: 0.00033832]
	Learning Rate: 0.000338324
	LOSS [training: 0.1015656882624227 | validation: 0.0840512648039939]
	TIME [epoch: 8.35 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09682022870693047		[learning rate: 0.00033753]
	Learning Rate: 0.000337526
	LOSS [training: 0.09682022870693047 | validation: 0.0789412344009881]
	TIME [epoch: 8.33 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10333801863621128		[learning rate: 0.00033673]
	Learning Rate: 0.00033673
	LOSS [training: 0.10333801863621128 | validation: 0.08287903858635282]
	TIME [epoch: 8.33 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09027246204359277		[learning rate: 0.00033594]
	Learning Rate: 0.000335936
	LOSS [training: 0.09027246204359277 | validation: 0.08962687576349315]
	TIME [epoch: 8.34 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10095199222296129		[learning rate: 0.00033514]
	Learning Rate: 0.000335143
	LOSS [training: 0.10095199222296129 | validation: 0.06996659926490861]
	TIME [epoch: 8.35 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1023026589611595		[learning rate: 0.00033435]
	Learning Rate: 0.000334353
	LOSS [training: 0.1023026589611595 | validation: 0.0844799807697349]
	TIME [epoch: 8.34 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09851606285054058		[learning rate: 0.00033356]
	Learning Rate: 0.000333564
	LOSS [training: 0.09851606285054058 | validation: 0.08629879681619071]
	TIME [epoch: 8.32 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09384898798517219		[learning rate: 0.00033278]
	Learning Rate: 0.000332777
	LOSS [training: 0.09384898798517219 | validation: 0.10053814644178692]
	TIME [epoch: 8.34 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1009659318099817		[learning rate: 0.00033199]
	Learning Rate: 0.000331992
	LOSS [training: 0.1009659318099817 | validation: 0.08344859479173988]
	TIME [epoch: 8.35 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10213211746920174		[learning rate: 0.00033121]
	Learning Rate: 0.000331209
	LOSS [training: 0.10213211746920174 | validation: 0.08303585138253805]
	TIME [epoch: 8.33 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09268397826386339		[learning rate: 0.00033043]
	Learning Rate: 0.000330428
	LOSS [training: 0.09268397826386339 | validation: 0.09491212720732833]
	TIME [epoch: 8.33 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09078356488583421		[learning rate: 0.00032965]
	Learning Rate: 0.000329649
	LOSS [training: 0.09078356488583421 | validation: 0.07677955430511008]
	TIME [epoch: 8.33 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08781452325288733		[learning rate: 0.00032887]
	Learning Rate: 0.000328871
	LOSS [training: 0.08781452325288733 | validation: 0.0846795026245072]
	TIME [epoch: 8.35 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08721070813218962		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.08721070813218962 | validation: 0.08015616315255492]
	TIME [epoch: 8.33 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08908739196252115		[learning rate: 0.00032732]
	Learning Rate: 0.000327321
	LOSS [training: 0.08908739196252115 | validation: 0.08972325151787125]
	TIME [epoch: 8.33 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09597330451918668		[learning rate: 0.00032655]
	Learning Rate: 0.000326549
	LOSS [training: 0.09597330451918668 | validation: 0.09055622418944465]
	TIME [epoch: 8.33 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09422343718204797		[learning rate: 0.00032578]
	Learning Rate: 0.000325779
	LOSS [training: 0.09422343718204797 | validation: 0.08863037041412002]
	TIME [epoch: 8.35 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10150429487143345		[learning rate: 0.00032501]
	Learning Rate: 0.000325011
	LOSS [training: 0.10150429487143345 | validation: 0.09817641547288922]
	TIME [epoch: 8.33 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0988510307905054		[learning rate: 0.00032424]
	Learning Rate: 0.000324244
	LOSS [training: 0.0988510307905054 | validation: 0.09804682216758166]
	TIME [epoch: 8.32 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09240077463592346		[learning rate: 0.00032348]
	Learning Rate: 0.000323479
	LOSS [training: 0.09240077463592346 | validation: 0.08384766950795866]
	TIME [epoch: 8.33 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0921756015750702		[learning rate: 0.00032272]
	Learning Rate: 0.000322716
	LOSS [training: 0.0921756015750702 | validation: 0.07964420193902458]
	TIME [epoch: 8.35 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09001017827541265		[learning rate: 0.00032195]
	Learning Rate: 0.000321955
	LOSS [training: 0.09001017827541265 | validation: 0.07477173044810692]
	TIME [epoch: 8.33 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09378143629563036		[learning rate: 0.0003212]
	Learning Rate: 0.000321195
	LOSS [training: 0.09378143629563036 | validation: 0.0962901949271334]
	TIME [epoch: 8.33 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09868450346387984		[learning rate: 0.00032044]
	Learning Rate: 0.000320438
	LOSS [training: 0.09868450346387984 | validation: 0.08994052552083906]
	TIME [epoch: 8.33 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10024520058621889		[learning rate: 0.00031968]
	Learning Rate: 0.000319682
	LOSS [training: 0.10024520058621889 | validation: 0.08238006471900668]
	TIME [epoch: 8.35 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08107753650302482		[learning rate: 0.00031893]
	Learning Rate: 0.000318928
	LOSS [training: 0.08107753650302482 | validation: 0.061413334762537214]
	TIME [epoch: 8.33 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08055058986223977		[learning rate: 0.00031818]
	Learning Rate: 0.000318175
	LOSS [training: 0.08055058986223977 | validation: 0.07261355209501569]
	TIME [epoch: 8.33 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08215090357431219		[learning rate: 0.00031742]
	Learning Rate: 0.000317425
	LOSS [training: 0.08215090357431219 | validation: 0.08342982080489944]
	TIME [epoch: 8.34 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08207320126396384		[learning rate: 0.00031668]
	Learning Rate: 0.000316676
	LOSS [training: 0.08207320126396384 | validation: 0.06434397265737338]
	TIME [epoch: 8.35 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08110037991471676		[learning rate: 0.00031593]
	Learning Rate: 0.000315929
	LOSS [training: 0.08110037991471676 | validation: 0.05988057333933746]
	TIME [epoch: 8.33 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08739489289650473		[learning rate: 0.00031518]
	Learning Rate: 0.000315184
	LOSS [training: 0.08739489289650473 | validation: 0.0837310800435294]
	TIME [epoch: 8.32 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0820400918089595		[learning rate: 0.00031444]
	Learning Rate: 0.00031444
	LOSS [training: 0.0820400918089595 | validation: 0.07495977403295664]
	TIME [epoch: 8.34 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07845863164017		[learning rate: 0.0003137]
	Learning Rate: 0.000313699
	LOSS [training: 0.07845863164017 | validation: 0.07339251196296911]
	TIME [epoch: 8.34 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0875916668524389		[learning rate: 0.00031296]
	Learning Rate: 0.000312959
	LOSS [training: 0.0875916668524389 | validation: 0.08216418140354717]
	TIME [epoch: 8.33 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09664029617155423		[learning rate: 0.00031222]
	Learning Rate: 0.000312221
	LOSS [training: 0.09664029617155423 | validation: 0.05317974073836415]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_1518.pth
	Model improved!!!
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08478624302794832		[learning rate: 0.00031148]
	Learning Rate: 0.000311484
	LOSS [training: 0.08478624302794832 | validation: 0.06406967306018618]
	TIME [epoch: 8.33 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08154440348791217		[learning rate: 0.00031075]
	Learning Rate: 0.000310749
	LOSS [training: 0.08154440348791217 | validation: 0.07900836721148793]
	TIME [epoch: 8.35 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07318767119841763		[learning rate: 0.00031002]
	Learning Rate: 0.000310016
	LOSS [training: 0.07318767119841763 | validation: 0.09501732403082885]
	TIME [epoch: 8.32 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10213139953556068		[learning rate: 0.00030929]
	Learning Rate: 0.000309285
	LOSS [training: 0.10213139953556068 | validation: 0.0728207738122239]
	TIME [epoch: 8.33 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07780459030678358		[learning rate: 0.00030856]
	Learning Rate: 0.000308555
	LOSS [training: 0.07780459030678358 | validation: 0.0783614210348289]
	TIME [epoch: 8.33 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08358638378658631		[learning rate: 0.00030783]
	Learning Rate: 0.000307828
	LOSS [training: 0.08358638378658631 | validation: 0.08036537040106229]
	TIME [epoch: 8.35 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08506707470252947		[learning rate: 0.0003071]
	Learning Rate: 0.000307102
	LOSS [training: 0.08506707470252947 | validation: 0.08007550350570503]
	TIME [epoch: 8.32 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08073106093488727		[learning rate: 0.00030638]
	Learning Rate: 0.000306377
	LOSS [training: 0.08073106093488727 | validation: 0.091724597371213]
	TIME [epoch: 8.32 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10596549283011307		[learning rate: 0.00030565]
	Learning Rate: 0.000305654
	LOSS [training: 0.10596549283011307 | validation: 0.09139415936806033]
	TIME [epoch: 8.33 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08602419480602519		[learning rate: 0.00030493]
	Learning Rate: 0.000304933
	LOSS [training: 0.08602419480602519 | validation: 0.0958517698762747]
	TIME [epoch: 8.34 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08535346478960448		[learning rate: 0.00030421]
	Learning Rate: 0.000304214
	LOSS [training: 0.08535346478960448 | validation: 0.06741471440203746]
	TIME [epoch: 8.32 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08488690358834583		[learning rate: 0.0003035]
	Learning Rate: 0.000303497
	LOSS [training: 0.08488690358834583 | validation: 0.07384813336817928]
	TIME [epoch: 8.33 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09024982010283872		[learning rate: 0.00030278]
	Learning Rate: 0.000302781
	LOSS [training: 0.09024982010283872 | validation: 0.08423737241661006]
	TIME [epoch: 8.34 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09893045317175887		[learning rate: 0.00030207]
	Learning Rate: 0.000302066
	LOSS [training: 0.09893045317175887 | validation: 0.09867065747861721]
	TIME [epoch: 8.35 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08886672201707857		[learning rate: 0.00030135]
	Learning Rate: 0.000301354
	LOSS [training: 0.08886672201707857 | validation: 0.0839043378897206]
	TIME [epoch: 8.33 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09547197389787931		[learning rate: 0.00030064]
	Learning Rate: 0.000300643
	LOSS [training: 0.09547197389787931 | validation: 0.08303999132263498]
	TIME [epoch: 8.33 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09714170621242992		[learning rate: 0.00029993]
	Learning Rate: 0.000299934
	LOSS [training: 0.09714170621242992 | validation: 0.07888217575326635]
	TIME [epoch: 8.32 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08999515149593931		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.08999515149593931 | validation: 0.08170677711462507]
	TIME [epoch: 8.35 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08951872102072991		[learning rate: 0.00029852]
	Learning Rate: 0.000298521
	LOSS [training: 0.08951872102072991 | validation: 0.08400329184256274]
	TIME [epoch: 8.32 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09187163121459704		[learning rate: 0.00029782]
	Learning Rate: 0.000297816
	LOSS [training: 0.09187163121459704 | validation: 0.09258281950799832]
	TIME [epoch: 8.33 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08250420871974662		[learning rate: 0.00029711]
	Learning Rate: 0.000297114
	LOSS [training: 0.08250420871974662 | validation: 0.08379337452559518]
	TIME [epoch: 8.35 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09349151459924848		[learning rate: 0.00029641]
	Learning Rate: 0.000296413
	LOSS [training: 0.09349151459924848 | validation: 0.09579594628591687]
	TIME [epoch: 8.34 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08967161713658336		[learning rate: 0.00029571]
	Learning Rate: 0.000295714
	LOSS [training: 0.08967161713658336 | validation: 0.08195561872934673]
	TIME [epoch: 8.33 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09432963709198582		[learning rate: 0.00029502]
	Learning Rate: 0.000295016
	LOSS [training: 0.09432963709198582 | validation: 0.08257338479547091]
	TIME [epoch: 8.32 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09459307601453837		[learning rate: 0.00029432]
	Learning Rate: 0.00029432
	LOSS [training: 0.09459307601453837 | validation: 0.08507487201234315]
	TIME [epoch: 8.35 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09112246549583097		[learning rate: 0.00029363]
	Learning Rate: 0.000293626
	LOSS [training: 0.09112246549583097 | validation: 0.07526751640631343]
	TIME [epoch: 8.34 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0801805117133981		[learning rate: 0.00029293]
	Learning Rate: 0.000292934
	LOSS [training: 0.0801805117133981 | validation: 0.07276546151353402]
	TIME [epoch: 8.33 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0870997957775206		[learning rate: 0.00029224]
	Learning Rate: 0.000292243
	LOSS [training: 0.0870997957775206 | validation: 0.12004721049610345]
	TIME [epoch: 8.33 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09486243922996948		[learning rate: 0.00029155]
	Learning Rate: 0.000291553
	LOSS [training: 0.09486243922996948 | validation: 0.07551877953780317]
	TIME [epoch: 8.34 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0911542886370988		[learning rate: 0.00029087]
	Learning Rate: 0.000290866
	LOSS [training: 0.0911542886370988 | validation: 0.07156803090007759]
	TIME [epoch: 8.33 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08379971468942822		[learning rate: 0.00029018]
	Learning Rate: 0.000290179
	LOSS [training: 0.08379971468942822 | validation: 0.0687169293933903]
	TIME [epoch: 8.33 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08832558571769238		[learning rate: 0.00028949]
	Learning Rate: 0.000289495
	LOSS [training: 0.08832558571769238 | validation: 0.09485103911732921]
	TIME [epoch: 8.32 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08081280534610638		[learning rate: 0.00028881]
	Learning Rate: 0.000288812
	LOSS [training: 0.08081280534610638 | validation: 0.07827035742266837]
	TIME [epoch: 8.34 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08794420340741518		[learning rate: 0.00028813]
	Learning Rate: 0.000288131
	LOSS [training: 0.08794420340741518 | validation: 0.09561928091486471]
	TIME [epoch: 8.34 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09056467793504386		[learning rate: 0.00028745]
	Learning Rate: 0.000287451
	LOSS [training: 0.09056467793504386 | validation: 0.06754820032801631]
	TIME [epoch: 8.33 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0850612669716331		[learning rate: 0.00028677]
	Learning Rate: 0.000286773
	LOSS [training: 0.0850612669716331 | validation: 0.07754625377030153]
	TIME [epoch: 8.32 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10223046007429551		[learning rate: 0.0002861]
	Learning Rate: 0.000286097
	LOSS [training: 0.10223046007429551 | validation: 0.09944897945405742]
	TIME [epoch: 8.34 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10305745151853403		[learning rate: 0.00028542]
	Learning Rate: 0.000285422
	LOSS [training: 0.10305745151853403 | validation: 0.10041549672902754]
	TIME [epoch: 8.34 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09939428866400869		[learning rate: 0.00028475]
	Learning Rate: 0.000284749
	LOSS [training: 0.09939428866400869 | validation: 0.0805476978626137]
	TIME [epoch: 8.32 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08106533174240622		[learning rate: 0.00028408]
	Learning Rate: 0.000284077
	LOSS [training: 0.08106533174240622 | validation: 0.07548524680928334]
	TIME [epoch: 8.32 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08533339758474567		[learning rate: 0.00028341]
	Learning Rate: 0.000283407
	LOSS [training: 0.08533339758474567 | validation: 0.07637946187914335]
	TIME [epoch: 8.33 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.082105477380231		[learning rate: 0.00028274]
	Learning Rate: 0.000282738
	LOSS [training: 0.082105477380231 | validation: 0.09005112213846796]
	TIME [epoch: 8.33 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08690103434078286		[learning rate: 0.00028207]
	Learning Rate: 0.000282071
	LOSS [training: 0.08690103434078286 | validation: 0.08585049000691246]
	TIME [epoch: 8.32 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08987111252141983		[learning rate: 0.00028141]
	Learning Rate: 0.000281406
	LOSS [training: 0.08987111252141983 | validation: 0.08238229278792777]
	TIME [epoch: 8.32 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08256263765047812		[learning rate: 0.00028074]
	Learning Rate: 0.000280742
	LOSS [training: 0.08256263765047812 | validation: 0.07814239441602919]
	TIME [epoch: 8.34 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07938370313871398		[learning rate: 0.00028008]
	Learning Rate: 0.00028008
	LOSS [training: 0.07938370313871398 | validation: 0.07492177140950124]
	TIME [epoch: 8.33 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08403350688031881		[learning rate: 0.00027942]
	Learning Rate: 0.000279419
	LOSS [training: 0.08403350688031881 | validation: 0.06509756774633127]
	TIME [epoch: 8.32 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08644606375213387		[learning rate: 0.00027876]
	Learning Rate: 0.00027876
	LOSS [training: 0.08644606375213387 | validation: 0.06634321529664786]
	TIME [epoch: 8.32 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08503744965252094		[learning rate: 0.0002781]
	Learning Rate: 0.000278103
	LOSS [training: 0.08503744965252094 | validation: 0.08434082139557454]
	TIME [epoch: 8.34 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08356835897403782		[learning rate: 0.00027745]
	Learning Rate: 0.000277447
	LOSS [training: 0.08356835897403782 | validation: 0.06621774743844089]
	TIME [epoch: 8.33 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08903760594457824		[learning rate: 0.00027679]
	Learning Rate: 0.000276792
	LOSS [training: 0.08903760594457824 | validation: 0.08984830059658366]
	TIME [epoch: 8.33 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09128350569438796		[learning rate: 0.00027614]
	Learning Rate: 0.000276139
	LOSS [training: 0.09128350569438796 | validation: 0.07819375958994193]
	TIME [epoch: 8.32 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08908492114470552		[learning rate: 0.00027549]
	Learning Rate: 0.000275488
	LOSS [training: 0.08908492114470552 | validation: 0.09734135486219667]
	TIME [epoch: 8.33 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09664029129167773		[learning rate: 0.00027484]
	Learning Rate: 0.000274838
	LOSS [training: 0.09664029129167773 | validation: 0.08756173979703087]
	TIME [epoch: 8.34 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09674098402466288		[learning rate: 0.00027419]
	Learning Rate: 0.00027419
	LOSS [training: 0.09674098402466288 | validation: 0.09859189771406082]
	TIME [epoch: 8.32 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08629755823720789		[learning rate: 0.00027354]
	Learning Rate: 0.000273543
	LOSS [training: 0.08629755823720789 | validation: 0.08251816395277431]
	TIME [epoch: 8.32 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09221685850920289		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.09221685850920289 | validation: 0.09050734085717407]
	TIME [epoch: 8.34 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08732553009839193		[learning rate: 0.00027225]
	Learning Rate: 0.000272254
	LOSS [training: 0.08732553009839193 | validation: 0.07190762914168664]
	TIME [epoch: 8.33 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08327226292695682		[learning rate: 0.00027161]
	Learning Rate: 0.000271612
	LOSS [training: 0.08327226292695682 | validation: 0.07455293009019151]
	TIME [epoch: 8.34 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08136959435699757		[learning rate: 0.00027097]
	Learning Rate: 0.000270971
	LOSS [training: 0.08136959435699757 | validation: 0.07319451917299097]
	TIME [epoch: 8.32 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07556126545392619		[learning rate: 0.00027033]
	Learning Rate: 0.000270332
	LOSS [training: 0.07556126545392619 | validation: 0.08455357638254256]
	TIME [epoch: 8.34 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07863526721353026		[learning rate: 0.00026969]
	Learning Rate: 0.000269694
	LOSS [training: 0.07863526721353026 | validation: 0.06671695881529455]
	TIME [epoch: 8.33 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07599960496872186		[learning rate: 0.00026906]
	Learning Rate: 0.000269058
	LOSS [training: 0.07599960496872186 | validation: 0.06719336539116375]
	TIME [epoch: 8.33 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07512216166209414		[learning rate: 0.00026842]
	Learning Rate: 0.000268423
	LOSS [training: 0.07512216166209414 | validation: 0.0719509090997826]
	TIME [epoch: 8.32 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09460058100049401		[learning rate: 0.00026779]
	Learning Rate: 0.00026779
	LOSS [training: 0.09460058100049401 | validation: 0.09023602192705002]
	TIME [epoch: 8.35 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08578358746116124		[learning rate: 0.00026716]
	Learning Rate: 0.000267159
	LOSS [training: 0.08578358746116124 | validation: 0.07415587539533018]
	TIME [epoch: 8.32 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08022283377687453		[learning rate: 0.00026653]
	Learning Rate: 0.000266528
	LOSS [training: 0.08022283377687453 | validation: 0.07333394502620369]
	TIME [epoch: 8.32 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07958162160366603		[learning rate: 0.0002659]
	Learning Rate: 0.0002659
	LOSS [training: 0.07958162160366603 | validation: 0.07969525631541001]
	TIME [epoch: 8.32 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07945088314259885		[learning rate: 0.00026527]
	Learning Rate: 0.000265273
	LOSS [training: 0.07945088314259885 | validation: 0.06235685106169929]
	TIME [epoch: 8.34 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0793395185285298		[learning rate: 0.00026465]
	Learning Rate: 0.000264647
	LOSS [training: 0.0793395185285298 | validation: 0.07607553230083612]
	TIME [epoch: 8.32 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08763730826320923		[learning rate: 0.00026402]
	Learning Rate: 0.000264022
	LOSS [training: 0.08763730826320923 | validation: 0.06897731891161585]
	TIME [epoch: 8.32 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0889511851459687		[learning rate: 0.0002634]
	Learning Rate: 0.0002634
	LOSS [training: 0.0889511851459687 | validation: 0.08642777414174313]
	TIME [epoch: 8.33 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09513062906940464		[learning rate: 0.00026278]
	Learning Rate: 0.000262778
	LOSS [training: 0.09513062906940464 | validation: 0.07775605969955438]
	TIME [epoch: 8.34 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07688434069317748		[learning rate: 0.00026216]
	Learning Rate: 0.000262159
	LOSS [training: 0.07688434069317748 | validation: 0.0740416271797595]
	TIME [epoch: 8.33 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08568759224077678		[learning rate: 0.00026154]
	Learning Rate: 0.00026154
	LOSS [training: 0.08568759224077678 | validation: 0.08996050812467968]
	TIME [epoch: 8.33 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08613966178487842		[learning rate: 0.00026092]
	Learning Rate: 0.000260923
	LOSS [training: 0.08613966178487842 | validation: 0.08175777751580901]
	TIME [epoch: 8.33 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0886058257044041		[learning rate: 0.00026031]
	Learning Rate: 0.000260308
	LOSS [training: 0.0886058257044041 | validation: 0.07230165058555925]
	TIME [epoch: 8.35 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08490102800736085		[learning rate: 0.00025969]
	Learning Rate: 0.000259694
	LOSS [training: 0.08490102800736085 | validation: 0.07524211398634152]
	TIME [epoch: 8.32 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07989887245618045		[learning rate: 0.00025908]
	Learning Rate: 0.000259081
	LOSS [training: 0.07989887245618045 | validation: 0.06996849509103328]
	TIME [epoch: 8.33 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08737373526705679		[learning rate: 0.00025847]
	Learning Rate: 0.00025847
	LOSS [training: 0.08737373526705679 | validation: 0.07188159682907036]
	TIME [epoch: 8.32 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10502876635471754		[learning rate: 0.00025786]
	Learning Rate: 0.00025786
	LOSS [training: 0.10502876635471754 | validation: 0.0827719628214944]
	TIME [epoch: 8.35 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09036161176284355		[learning rate: 0.00025725]
	Learning Rate: 0.000257252
	LOSS [training: 0.09036161176284355 | validation: 0.06334556905946684]
	TIME [epoch: 8.34 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08667822779306258		[learning rate: 0.00025665]
	Learning Rate: 0.000256645
	LOSS [training: 0.08667822779306258 | validation: 0.09354415960717491]
	TIME [epoch: 8.33 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10899785441615847		[learning rate: 0.00025604]
	Learning Rate: 0.00025604
	LOSS [training: 0.10899785441615847 | validation: 0.09847191663696524]
	TIME [epoch: 8.34 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08914517735858667		[learning rate: 0.00025544]
	Learning Rate: 0.000255436
	LOSS [training: 0.08914517735858667 | validation: 0.07243785784040258]
	TIME [epoch: 8.34 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08003006584426328		[learning rate: 0.00025483]
	Learning Rate: 0.000254833
	LOSS [training: 0.08003006584426328 | validation: 0.08286837813050091]
	TIME [epoch: 8.33 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08864667350599036		[learning rate: 0.00025423]
	Learning Rate: 0.000254232
	LOSS [training: 0.08864667350599036 | validation: 0.07466280276674153]
	TIME [epoch: 8.33 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0817739044950257		[learning rate: 0.00025363]
	Learning Rate: 0.000253633
	LOSS [training: 0.0817739044950257 | validation: 0.061694840165175985]
	TIME [epoch: 8.32 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08163521691777884		[learning rate: 0.00025303]
	Learning Rate: 0.000253034
	LOSS [training: 0.08163521691777884 | validation: 0.08039442855881189]
	TIME [epoch: 8.34 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08181376518336056		[learning rate: 0.00025244]
	Learning Rate: 0.000252437
	LOSS [training: 0.08181376518336056 | validation: 0.08322630825255027]
	TIME [epoch: 8.34 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0983557158062428		[learning rate: 0.00025184]
	Learning Rate: 0.000251842
	LOSS [training: 0.0983557158062428 | validation: 0.07760154049818646]
	TIME [epoch: 8.32 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08230571589719601		[learning rate: 0.00025125]
	Learning Rate: 0.000251248
	LOSS [training: 0.08230571589719601 | validation: 0.07058556460234944]
	TIME [epoch: 8.32 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08040380749605328		[learning rate: 0.00025066]
	Learning Rate: 0.000250655
	LOSS [training: 0.08040380749605328 | validation: 0.08574320846656855]
	TIME [epoch: 8.35 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10357671316512089		[learning rate: 0.00025006]
	Learning Rate: 0.000250064
	LOSS [training: 0.10357671316512089 | validation: 0.08949971432240264]
	TIME [epoch: 8.33 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08008076795700111		[learning rate: 0.00024947]
	Learning Rate: 0.000249474
	LOSS [training: 0.08008076795700111 | validation: 0.06554047653238243]
	TIME [epoch: 8.33 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07924413752919737		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.07924413752919737 | validation: 0.08678647587071854]
	TIME [epoch: 8.33 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.085698154579594		[learning rate: 0.0002483]
	Learning Rate: 0.000248299
	LOSS [training: 0.085698154579594 | validation: 0.0738347982030998]
	TIME [epoch: 8.34 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07326953448123262		[learning rate: 0.00024771]
	Learning Rate: 0.000247713
	LOSS [training: 0.07326953448123262 | validation: 0.07334644496804614]
	TIME [epoch: 8.33 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07956611523810056		[learning rate: 0.00024713]
	Learning Rate: 0.000247129
	LOSS [training: 0.07956611523810056 | validation: 0.08696255775402996]
	TIME [epoch: 8.34 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08304862991627449		[learning rate: 0.00024655]
	Learning Rate: 0.000246546
	LOSS [training: 0.08304862991627449 | validation: 0.06776342068526237]
	TIME [epoch: 8.33 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09671677391750869		[learning rate: 0.00024596]
	Learning Rate: 0.000245964
	LOSS [training: 0.09671677391750869 | validation: 0.09952371070586974]
	TIME [epoch: 8.35 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09570267248902802		[learning rate: 0.00024538]
	Learning Rate: 0.000245384
	LOSS [training: 0.09570267248902802 | validation: 0.0828900386127348]
	TIME [epoch: 8.33 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08473988350721272		[learning rate: 0.00024481]
	Learning Rate: 0.000244805
	LOSS [training: 0.08473988350721272 | validation: 0.07745500324255966]
	TIME [epoch: 8.33 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09151021233939138		[learning rate: 0.00024423]
	Learning Rate: 0.000244228
	LOSS [training: 0.09151021233939138 | validation: 0.09019405023585401]
	TIME [epoch: 8.32 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08834685762317132		[learning rate: 0.00024365]
	Learning Rate: 0.000243652
	LOSS [training: 0.08834685762317132 | validation: 0.0686604673158185]
	TIME [epoch: 8.35 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09982053173807588		[learning rate: 0.00024308]
	Learning Rate: 0.000243077
	LOSS [training: 0.09982053173807588 | validation: 0.07373516028969775]
	TIME [epoch: 8.34 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08734939724585093		[learning rate: 0.0002425]
	Learning Rate: 0.000242503
	LOSS [training: 0.08734939724585093 | validation: 0.0677625057367539]
	TIME [epoch: 8.32 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08802200136743692		[learning rate: 0.00024193]
	Learning Rate: 0.000241931
	LOSS [training: 0.08802200136743692 | validation: 0.09455123950373746]
	TIME [epoch: 8.33 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10099376537066382		[learning rate: 0.00024136]
	Learning Rate: 0.000241361
	LOSS [training: 0.10099376537066382 | validation: 0.09110537268580987]
	TIME [epoch: 8.35 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09894608134706773		[learning rate: 0.00024079]
	Learning Rate: 0.000240791
	LOSS [training: 0.09894608134706773 | validation: 0.07147002556732465]
	TIME [epoch: 8.32 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08469677968353417		[learning rate: 0.00024022]
	Learning Rate: 0.000240223
	LOSS [training: 0.08469677968353417 | validation: 0.07354855992004446]
	TIME [epoch: 8.32 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08003730525546371		[learning rate: 0.00023966]
	Learning Rate: 0.000239657
	LOSS [training: 0.08003730525546371 | validation: 0.07447207278920945]
	TIME [epoch: 8.32 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0916673380950985		[learning rate: 0.00023909]
	Learning Rate: 0.000239091
	LOSS [training: 0.0916673380950985 | validation: 0.07658052254699196]
	TIME [epoch: 8.35 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07876019844542655		[learning rate: 0.00023853]
	Learning Rate: 0.000238527
	LOSS [training: 0.07876019844542655 | validation: 0.07556354503065277]
	TIME [epoch: 8.33 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08323588568218054		[learning rate: 0.00023796]
	Learning Rate: 0.000237965
	LOSS [training: 0.08323588568218054 | validation: 0.06598669345102123]
	TIME [epoch: 8.32 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08000507964310662		[learning rate: 0.0002374]
	Learning Rate: 0.000237404
	LOSS [training: 0.08000507964310662 | validation: 0.07626944164800789]
	TIME [epoch: 8.33 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08297688147564503		[learning rate: 0.00023684]
	Learning Rate: 0.000236844
	LOSS [training: 0.08297688147564503 | validation: 0.08020320261059968]
	TIME [epoch: 8.36 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08149082501491058		[learning rate: 0.00023628]
	Learning Rate: 0.000236285
	LOSS [training: 0.08149082501491058 | validation: 0.08609915632495208]
	TIME [epoch: 8.32 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08304993669672736		[learning rate: 0.00023573]
	Learning Rate: 0.000235728
	LOSS [training: 0.08304993669672736 | validation: 0.06567437628991267]
	TIME [epoch: 8.32 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08035751430367025		[learning rate: 0.00023517]
	Learning Rate: 0.000235171
	LOSS [training: 0.08035751430367025 | validation: 0.10067360773197845]
	TIME [epoch: 8.32 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09267178955314256		[learning rate: 0.00023462]
	Learning Rate: 0.000234617
	LOSS [training: 0.09267178955314256 | validation: 0.0771309318489396]
	TIME [epoch: 8.34 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08530062558827001		[learning rate: 0.00023406]
	Learning Rate: 0.000234063
	LOSS [training: 0.08530062558827001 | validation: 0.07200337343686725]
	TIME [epoch: 8.33 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08913148159744055		[learning rate: 0.00023351]
	Learning Rate: 0.000233511
	LOSS [training: 0.08913148159744055 | validation: 0.0898897256449145]
	TIME [epoch: 8.32 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0858098474997747		[learning rate: 0.00023296]
	Learning Rate: 0.00023296
	LOSS [training: 0.0858098474997747 | validation: 0.08757190121391124]
	TIME [epoch: 8.32 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07727713193957172		[learning rate: 0.00023241]
	Learning Rate: 0.000232411
	LOSS [training: 0.07727713193957172 | validation: 0.0776834591533716]
	TIME [epoch: 8.34 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07897590174576476		[learning rate: 0.00023186]
	Learning Rate: 0.000231863
	LOSS [training: 0.07897590174576476 | validation: 0.07172005086191414]
	TIME [epoch: 8.32 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08672473972767217		[learning rate: 0.00023132]
	Learning Rate: 0.000231316
	LOSS [training: 0.08672473972767217 | validation: 0.08750671034767246]
	TIME [epoch: 8.32 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08058821202283925		[learning rate: 0.00023077]
	Learning Rate: 0.00023077
	LOSS [training: 0.08058821202283925 | validation: 0.07326344163051636]
	TIME [epoch: 8.32 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0787913535137583		[learning rate: 0.00023023]
	Learning Rate: 0.000230226
	LOSS [training: 0.0787913535137583 | validation: 0.0684386136750744]
	TIME [epoch: 8.35 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0756165038318077		[learning rate: 0.00022968]
	Learning Rate: 0.000229683
	LOSS [training: 0.0756165038318077 | validation: 0.06774637690795901]
	TIME [epoch: 8.31 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07815088794551184		[learning rate: 0.00022914]
	Learning Rate: 0.000229141
	LOSS [training: 0.07815088794551184 | validation: 0.07044966395136083]
	TIME [epoch: 8.32 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07461157748021274		[learning rate: 0.0002286]
	Learning Rate: 0.0002286
	LOSS [training: 0.07461157748021274 | validation: 0.05703003734068129]
	TIME [epoch: 8.32 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07432900541404504		[learning rate: 0.00022806]
	Learning Rate: 0.000228061
	LOSS [training: 0.07432900541404504 | validation: 0.07623359970242177]
	TIME [epoch: 8.35 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07526733155479423		[learning rate: 0.00022752]
	Learning Rate: 0.000227523
	LOSS [training: 0.07526733155479423 | validation: 0.07357354426274282]
	TIME [epoch: 8.32 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0790532588317354		[learning rate: 0.00022699]
	Learning Rate: 0.000226986
	LOSS [training: 0.0790532588317354 | validation: 0.06113191978554081]
	TIME [epoch: 8.32 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08325828105360866		[learning rate: 0.00022645]
	Learning Rate: 0.000226451
	LOSS [training: 0.08325828105360866 | validation: 0.08127758788134215]
	TIME [epoch: 8.33 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0794909430950174		[learning rate: 0.00022592]
	Learning Rate: 0.000225917
	LOSS [training: 0.0794909430950174 | validation: 0.08043975530312794]
	TIME [epoch: 8.34 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08564391637440197		[learning rate: 0.00022538]
	Learning Rate: 0.000225384
	LOSS [training: 0.08564391637440197 | validation: 0.06532804585505991]
	TIME [epoch: 8.32 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07650868573201507		[learning rate: 0.00022485]
	Learning Rate: 0.000224852
	LOSS [training: 0.07650868573201507 | validation: 0.06913144728409334]
	TIME [epoch: 8.33 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0793168239301302		[learning rate: 0.00022432]
	Learning Rate: 0.000224322
	LOSS [training: 0.0793168239301302 | validation: 0.06083735020986983]
	TIME [epoch: 8.33 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07804602070319736		[learning rate: 0.00022379]
	Learning Rate: 0.000223793
	LOSS [training: 0.07804602070319736 | validation: 0.06727467743937524]
	TIME [epoch: 8.34 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0820862198690258		[learning rate: 0.00022326]
	Learning Rate: 0.000223265
	LOSS [training: 0.0820862198690258 | validation: 0.057812120450814644]
	TIME [epoch: 8.32 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08461039895681641		[learning rate: 0.00022274]
	Learning Rate: 0.000222738
	LOSS [training: 0.08461039895681641 | validation: 0.08572735819041022]
	TIME [epoch: 8.32 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0932638835307853		[learning rate: 0.00022221]
	Learning Rate: 0.000222213
	LOSS [training: 0.0932638835307853 | validation: 0.0822593404473484]
	TIME [epoch: 8.33 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08659099887761953		[learning rate: 0.00022169]
	Learning Rate: 0.000221689
	LOSS [training: 0.08659099887761953 | validation: 0.08888175558585343]
	TIME [epoch: 8.34 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09973898790364623		[learning rate: 0.00022117]
	Learning Rate: 0.000221166
	LOSS [training: 0.09973898790364623 | validation: 0.08852273707291014]
	TIME [epoch: 8.32 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07762733950451996		[learning rate: 0.00022064]
	Learning Rate: 0.000220644
	LOSS [training: 0.07762733950451996 | validation: 0.06740577215421886]
	TIME [epoch: 8.31 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07745224046172591		[learning rate: 0.00022012]
	Learning Rate: 0.000220124
	LOSS [training: 0.07745224046172591 | validation: 0.06959464043486338]
	TIME [epoch: 8.32 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08640380426912483		[learning rate: 0.0002196]
	Learning Rate: 0.000219604
	LOSS [training: 0.08640380426912483 | validation: 0.09372320572151702]
	TIME [epoch: 8.34 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08057596074764466		[learning rate: 0.00021909]
	Learning Rate: 0.000219086
	LOSS [training: 0.08057596074764466 | validation: 0.06281491089180462]
	TIME [epoch: 8.33 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07300383138106167		[learning rate: 0.00021857]
	Learning Rate: 0.00021857
	LOSS [training: 0.07300383138106167 | validation: 0.059299752161433975]
	TIME [epoch: 8.32 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07944714393334391		[learning rate: 0.00021805]
	Learning Rate: 0.000218054
	LOSS [training: 0.07944714393334391 | validation: 0.06500395637883266]
	TIME [epoch: 8.33 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07747137647949479		[learning rate: 0.00021754]
	Learning Rate: 0.00021754
	LOSS [training: 0.07747137647949479 | validation: 0.07463388406379752]
	TIME [epoch: 8.34 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0903009803938417		[learning rate: 0.00021703]
	Learning Rate: 0.000217027
	LOSS [training: 0.0903009803938417 | validation: 0.07749184052049601]
	TIME [epoch: 8.32 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07620176414710259		[learning rate: 0.00021651]
	Learning Rate: 0.000216515
	LOSS [training: 0.07620176414710259 | validation: 0.07555530288986691]
	TIME [epoch: 8.32 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06932733076221022		[learning rate: 0.000216]
	Learning Rate: 0.000216004
	LOSS [training: 0.06932733076221022 | validation: 0.07638925534549695]
	TIME [epoch: 8.34 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08113287100853614		[learning rate: 0.00021549]
	Learning Rate: 0.000215494
	LOSS [training: 0.08113287100853614 | validation: 0.0803311482475657]
	TIME [epoch: 8.34 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08465843347072771		[learning rate: 0.00021499]
	Learning Rate: 0.000214986
	LOSS [training: 0.08465843347072771 | validation: 0.09939427446447183]
	TIME [epoch: 8.32 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09326826130109565		[learning rate: 0.00021448]
	Learning Rate: 0.000214479
	LOSS [training: 0.09326826130109565 | validation: 0.06435506139175882]
	TIME [epoch: 8.32 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07337256868911106		[learning rate: 0.00021397]
	Learning Rate: 0.000213973
	LOSS [training: 0.07337256868911106 | validation: 0.06687667307991825]
	TIME [epoch: 8.33 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0780628647150903		[learning rate: 0.00021347]
	Learning Rate: 0.000213468
	LOSS [training: 0.0780628647150903 | validation: 0.06549178091053424]
	TIME [epoch: 8.34 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07980505414353929		[learning rate: 0.00021296]
	Learning Rate: 0.000212965
	LOSS [training: 0.07980505414353929 | validation: 0.08107805607271062]
	TIME [epoch: 8.32 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08331101600452763		[learning rate: 0.00021246]
	Learning Rate: 0.000212462
	LOSS [training: 0.08331101600452763 | validation: 0.06267506456989057]
	TIME [epoch: 8.32 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07660012044480186		[learning rate: 0.00021196]
	Learning Rate: 0.000211961
	LOSS [training: 0.07660012044480186 | validation: 0.06658490610053262]
	TIME [epoch: 8.33 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.085221793732889		[learning rate: 0.00021146]
	Learning Rate: 0.000211461
	LOSS [training: 0.085221793732889 | validation: 0.07074573304828453]
	TIME [epoch: 8.33 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08023684552514396		[learning rate: 0.00021096]
	Learning Rate: 0.000210962
	LOSS [training: 0.08023684552514396 | validation: 0.08341212944272348]
	TIME [epoch: 8.32 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07516689095929845		[learning rate: 0.00021046]
	Learning Rate: 0.000210465
	LOSS [training: 0.07516689095929845 | validation: 0.06191594370731553]
	TIME [epoch: 8.32 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09309196326130113		[learning rate: 0.00020997]
	Learning Rate: 0.000209968
	LOSS [training: 0.09309196326130113 | validation: 0.06470187264426702]
	TIME [epoch: 8.33 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08470801623920922		[learning rate: 0.00020947]
	Learning Rate: 0.000209473
	LOSS [training: 0.08470801623920922 | validation: 0.07259773587044413]
	TIME [epoch: 8.33 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08741848981672139		[learning rate: 0.00020898]
	Learning Rate: 0.000208979
	LOSS [training: 0.08741848981672139 | validation: 0.09099914504848783]
	TIME [epoch: 8.32 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09236391974877323		[learning rate: 0.00020849]
	Learning Rate: 0.000208486
	LOSS [training: 0.09236391974877323 | validation: 0.06978003514726464]
	TIME [epoch: 8.32 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08162219581969131		[learning rate: 0.00020799]
	Learning Rate: 0.000207994
	LOSS [training: 0.08162219581969131 | validation: 0.07504650523054304]
	TIME [epoch: 8.34 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07791164315976853		[learning rate: 0.0002075]
	Learning Rate: 0.000207504
	LOSS [training: 0.07791164315976853 | validation: 0.06454435860595165]
	TIME [epoch: 8.33 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07532873961697986		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.07532873961697986 | validation: 0.07517412699232419]
	TIME [epoch: 8.32 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07629260579859795		[learning rate: 0.00020653]
	Learning Rate: 0.000206526
	LOSS [training: 0.07629260579859795 | validation: 0.06381705965539082]
	TIME [epoch: 8.32 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07456979720650668		[learning rate: 0.00020604]
	Learning Rate: 0.000206039
	LOSS [training: 0.07456979720650668 | validation: 0.0705296405525816]
	TIME [epoch: 8.34 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07261924395295116		[learning rate: 0.00020555]
	Learning Rate: 0.000205553
	LOSS [training: 0.07261924395295116 | validation: 0.06333712672770098]
	TIME [epoch: 8.33 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07947238048921271		[learning rate: 0.00020507]
	Learning Rate: 0.000205068
	LOSS [training: 0.07947238048921271 | validation: 0.08013709359990853]
	TIME [epoch: 8.32 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08239275180873099		[learning rate: 0.00020458]
	Learning Rate: 0.000204584
	LOSS [training: 0.08239275180873099 | validation: 0.07870532613430611]
	TIME [epoch: 8.32 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07394316403289088		[learning rate: 0.0002041]
	Learning Rate: 0.000204101
	LOSS [training: 0.07394316403289088 | validation: 0.07765491933554955]
	TIME [epoch: 8.33 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0769163634113432		[learning rate: 0.00020362]
	Learning Rate: 0.00020362
	LOSS [training: 0.0769163634113432 | validation: 0.07366762851215575]
	TIME [epoch: 8.33 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08709399480550664		[learning rate: 0.00020314]
	Learning Rate: 0.00020314
	LOSS [training: 0.08709399480550664 | validation: 0.07034906166211044]
	TIME [epoch: 8.32 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0835994125242089		[learning rate: 0.00020266]
	Learning Rate: 0.000202661
	LOSS [training: 0.0835994125242089 | validation: 0.09067832128919474]
	TIME [epoch: 8.33 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0764080039726208		[learning rate: 0.00020218]
	Learning Rate: 0.000202182
	LOSS [training: 0.0764080039726208 | validation: 0.062250821987166374]
	TIME [epoch: 8.33 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08480945639749782		[learning rate: 0.00020171]
	Learning Rate: 0.000201706
	LOSS [training: 0.08480945639749782 | validation: 0.06058068635584252]
	TIME [epoch: 8.33 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07150827916503535		[learning rate: 0.00020123]
	Learning Rate: 0.00020123
	LOSS [training: 0.07150827916503535 | validation: 0.06776744366728427]
	TIME [epoch: 8.32 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07032995789932607		[learning rate: 0.00020076]
	Learning Rate: 0.000200755
	LOSS [training: 0.07032995789932607 | validation: 0.06645131563588136]
	TIME [epoch: 8.33 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.076533751752653		[learning rate: 0.00020028]
	Learning Rate: 0.000200282
	LOSS [training: 0.076533751752653 | validation: 0.07038325453223315]
	TIME [epoch: 8.33 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08206542112604073		[learning rate: 0.00019981]
	Learning Rate: 0.000199809
	LOSS [training: 0.08206542112604073 | validation: 0.07731071936635778]
	TIME [epoch: 8.33 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08008994387534454		[learning rate: 0.00019934]
	Learning Rate: 0.000199338
	LOSS [training: 0.08008994387534454 | validation: 0.08719974635667195]
	TIME [epoch: 8.32 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08301173127147529		[learning rate: 0.00019887]
	Learning Rate: 0.000198868
	LOSS [training: 0.08301173127147529 | validation: 0.06993622933089567]
	TIME [epoch: 8.32 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07578320401031953		[learning rate: 0.0001984]
	Learning Rate: 0.000198398
	LOSS [training: 0.07578320401031953 | validation: 0.07202623836364773]
	TIME [epoch: 8.34 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07673328261145394		[learning rate: 0.00019793]
	Learning Rate: 0.000197931
	LOSS [training: 0.07673328261145394 | validation: 0.0674591020308037]
	TIME [epoch: 8.32 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08352946049311352		[learning rate: 0.00019746]
	Learning Rate: 0.000197464
	LOSS [training: 0.08352946049311352 | validation: 0.06433580792138369]
	TIME [epoch: 8.32 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08194962347918915		[learning rate: 0.000197]
	Learning Rate: 0.000196998
	LOSS [training: 0.08194962347918915 | validation: 0.0675038665731966]
	TIME [epoch: 8.33 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07942879560223402		[learning rate: 0.00019653]
	Learning Rate: 0.000196533
	LOSS [training: 0.07942879560223402 | validation: 0.07395154546679826]
	TIME [epoch: 8.34 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08944608366105938		[learning rate: 0.00019607]
	Learning Rate: 0.00019607
	LOSS [training: 0.08944608366105938 | validation: 0.10356115233698474]
	TIME [epoch: 8.33 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08132492326279532		[learning rate: 0.00019561]
	Learning Rate: 0.000195607
	LOSS [training: 0.08132492326279532 | validation: 0.0712858225146773]
	TIME [epoch: 8.32 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07909852646511313		[learning rate: 0.00019515]
	Learning Rate: 0.000195146
	LOSS [training: 0.07909852646511313 | validation: 0.08067046797884489]
	TIME [epoch: 8.33 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08201573171503387		[learning rate: 0.00019469]
	Learning Rate: 0.000194685
	LOSS [training: 0.08201573171503387 | validation: 0.06687861321491766]
	TIME [epoch: 8.34 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08100169469970515		[learning rate: 0.00019423]
	Learning Rate: 0.000194226
	LOSS [training: 0.08100169469970515 | validation: 0.06918839097291976]
	TIME [epoch: 8.33 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07358167185615958		[learning rate: 0.00019377]
	Learning Rate: 0.000193768
	LOSS [training: 0.07358167185615958 | validation: 0.06692340166149433]
	TIME [epoch: 8.32 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07684070909741034		[learning rate: 0.00019331]
	Learning Rate: 0.000193311
	LOSS [training: 0.07684070909741034 | validation: 0.06789471066279558]
	TIME [epoch: 8.32 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0800707525146994		[learning rate: 0.00019285]
	Learning Rate: 0.000192855
	LOSS [training: 0.0800707525146994 | validation: 0.06998370742663426]
	TIME [epoch: 8.34 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0720651096562934		[learning rate: 0.0001924]
	Learning Rate: 0.0001924
	LOSS [training: 0.0720651096562934 | validation: 0.053805926577690386]
	TIME [epoch: 8.32 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0764020913715752		[learning rate: 0.00019195]
	Learning Rate: 0.000191946
	LOSS [training: 0.0764020913715752 | validation: 0.0637754783475482]
	TIME [epoch: 8.32 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07691077548339405		[learning rate: 0.00019149]
	Learning Rate: 0.000191493
	LOSS [training: 0.07691077548339405 | validation: 0.06390753130604623]
	TIME [epoch: 8.32 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07889773292883548		[learning rate: 0.00019104]
	Learning Rate: 0.000191042
	LOSS [training: 0.07889773292883548 | validation: 0.06667215161344803]
	TIME [epoch: 8.34 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07369935139987979		[learning rate: 0.00019059]
	Learning Rate: 0.000190591
	LOSS [training: 0.07369935139987979 | validation: 0.05394053134631606]
	TIME [epoch: 8.32 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06999083240454206		[learning rate: 0.00019014]
	Learning Rate: 0.000190141
	LOSS [training: 0.06999083240454206 | validation: 0.06591690630643761]
	TIME [epoch: 8.31 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06906373575106547		[learning rate: 0.00018969]
	Learning Rate: 0.000189693
	LOSS [training: 0.06906373575106547 | validation: 0.06231739735277905]
	TIME [epoch: 8.32 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08270586188256776		[learning rate: 0.00018925]
	Learning Rate: 0.000189245
	LOSS [training: 0.08270586188256776 | validation: 0.06457210749590866]
	TIME [epoch: 8.34 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07643379828427437		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.07643379828427437 | validation: 0.0787219427369994]
	TIME [epoch: 8.32 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08035464155711415		[learning rate: 0.00018835]
	Learning Rate: 0.000188354
	LOSS [training: 0.08035464155711415 | validation: 0.06313681641418328]
	TIME [epoch: 8.32 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08024181082997675		[learning rate: 0.00018791]
	Learning Rate: 0.000187909
	LOSS [training: 0.08024181082997675 | validation: 0.07599976841466614]
	TIME [epoch: 8.32 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0770633327072086		[learning rate: 0.00018747]
	Learning Rate: 0.000187466
	LOSS [training: 0.0770633327072086 | validation: 0.05855590016124283]
	TIME [epoch: 8.34 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07755147483394645		[learning rate: 0.00018702]
	Learning Rate: 0.000187024
	LOSS [training: 0.07755147483394645 | validation: 0.05446359074495929]
	TIME [epoch: 8.33 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07539194397432103		[learning rate: 0.00018658]
	Learning Rate: 0.000186583
	LOSS [training: 0.07539194397432103 | validation: 0.06097027031064897]
	TIME [epoch: 8.32 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07563036948082574		[learning rate: 0.00018614]
	Learning Rate: 0.000186143
	LOSS [training: 0.07563036948082574 | validation: 0.07147317986788672]
	TIME [epoch: 8.32 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08324390277762127		[learning rate: 0.0001857]
	Learning Rate: 0.000185704
	LOSS [training: 0.08324390277762127 | validation: 0.061316547510752134]
	TIME [epoch: 8.34 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08182389139480457		[learning rate: 0.00018527]
	Learning Rate: 0.000185266
	LOSS [training: 0.08182389139480457 | validation: 0.06539774619145117]
	TIME [epoch: 8.32 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08085533191702918		[learning rate: 0.00018483]
	Learning Rate: 0.000184829
	LOSS [training: 0.08085533191702918 | validation: 0.08289016070244432]
	TIME [epoch: 8.32 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08247905859397361		[learning rate: 0.00018439]
	Learning Rate: 0.000184393
	LOSS [training: 0.08247905859397361 | validation: 0.07399416393534847]
	TIME [epoch: 8.32 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0800924982003132		[learning rate: 0.00018396]
	Learning Rate: 0.000183958
	LOSS [training: 0.0800924982003132 | validation: 0.0673600109181838]
	TIME [epoch: 8.34 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0813145180411021		[learning rate: 0.00018352]
	Learning Rate: 0.000183524
	LOSS [training: 0.0813145180411021 | validation: 0.07640478340423865]
	TIME [epoch: 8.32 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0798306675339868		[learning rate: 0.00018309]
	Learning Rate: 0.000183091
	LOSS [training: 0.0798306675339868 | validation: 0.06773882971422183]
	TIME [epoch: 8.32 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0850953585511717		[learning rate: 0.00018266]
	Learning Rate: 0.000182659
	LOSS [training: 0.0850953585511717 | validation: 0.09025280326080795]
	TIME [epoch: 8.32 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0919790424567003		[learning rate: 0.00018223]
	Learning Rate: 0.000182228
	LOSS [training: 0.0919790424567003 | validation: 0.07972721712214795]
	TIME [epoch: 8.35 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08427602783261624		[learning rate: 0.0001818]
	Learning Rate: 0.000181798
	LOSS [training: 0.08427602783261624 | validation: 0.07641091681048715]
	TIME [epoch: 8.32 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07352642118437852		[learning rate: 0.00018137]
	Learning Rate: 0.000181369
	LOSS [training: 0.07352642118437852 | validation: 0.0711898057988952]
	TIME [epoch: 8.33 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07532709952206075		[learning rate: 0.00018094]
	Learning Rate: 0.000180942
	LOSS [training: 0.07532709952206075 | validation: 0.07316712643854621]
	TIME [epoch: 8.32 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07515036622670067		[learning rate: 0.00018051]
	Learning Rate: 0.000180515
	LOSS [training: 0.07515036622670067 | validation: 0.059595751103953654]
	TIME [epoch: 8.34 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07298211974973713		[learning rate: 0.00018009]
	Learning Rate: 0.000180089
	LOSS [training: 0.07298211974973713 | validation: 0.06958275017740947]
	TIME [epoch: 8.32 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07800938013942547		[learning rate: 0.00017966]
	Learning Rate: 0.000179664
	LOSS [training: 0.07800938013942547 | validation: 0.06863159062061203]
	TIME [epoch: 8.32 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08001083072294882		[learning rate: 0.00017924]
	Learning Rate: 0.00017924
	LOSS [training: 0.08001083072294882 | validation: 0.06668019760637059]
	TIME [epoch: 8.32 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08473853813608687		[learning rate: 0.00017882]
	Learning Rate: 0.000178818
	LOSS [training: 0.08473853813608687 | validation: 0.06814017126832653]
	TIME [epoch: 8.34 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08011021253710403		[learning rate: 0.0001784]
	Learning Rate: 0.000178396
	LOSS [training: 0.08011021253710403 | validation: 0.07491519864990825]
	TIME [epoch: 8.32 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0739329360429174		[learning rate: 0.00017797]
	Learning Rate: 0.000177975
	LOSS [training: 0.0739329360429174 | validation: 0.06694174748551307]
	TIME [epoch: 8.32 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07984455742179566		[learning rate: 0.00017756]
	Learning Rate: 0.000177555
	LOSS [training: 0.07984455742179566 | validation: 0.07006821963776258]
	TIME [epoch: 8.32 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07558232694397368		[learning rate: 0.00017714]
	Learning Rate: 0.000177136
	LOSS [training: 0.07558232694397368 | validation: 0.07310927676522465]
	TIME [epoch: 8.34 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0831468441825771		[learning rate: 0.00017672]
	Learning Rate: 0.000176718
	LOSS [training: 0.0831468441825771 | validation: 0.05529784473518946]
	TIME [epoch: 8.32 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07162954125919244		[learning rate: 0.0001763]
	Learning Rate: 0.000176302
	LOSS [training: 0.07162954125919244 | validation: 0.06239533272368028]
	TIME [epoch: 8.32 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07510848478548912		[learning rate: 0.00017589]
	Learning Rate: 0.000175886
	LOSS [training: 0.07510848478548912 | validation: 0.0643865822391412]
	TIME [epoch: 8.32 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07831087054004618		[learning rate: 0.00017547]
	Learning Rate: 0.000175471
	LOSS [training: 0.07831087054004618 | validation: 0.06523887232184356]
	TIME [epoch: 8.34 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07503649265064834		[learning rate: 0.00017506]
	Learning Rate: 0.000175057
	LOSS [training: 0.07503649265064834 | validation: 0.07691161013350449]
	TIME [epoch: 8.31 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08064667519824775		[learning rate: 0.00017464]
	Learning Rate: 0.000174644
	LOSS [training: 0.08064667519824775 | validation: 0.07770090979587531]
	TIME [epoch: 8.32 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08312759080049884		[learning rate: 0.00017423]
	Learning Rate: 0.000174232
	LOSS [training: 0.08312759080049884 | validation: 0.07682140159923523]
	TIME [epoch: 8.32 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08089819678891402		[learning rate: 0.00017382]
	Learning Rate: 0.000173821
	LOSS [training: 0.08089819678891402 | validation: 0.0667627507257249]
	TIME [epoch: 8.34 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07357693482097392		[learning rate: 0.00017341]
	Learning Rate: 0.000173411
	LOSS [training: 0.07357693482097392 | validation: 0.0648655766614987]
	TIME [epoch: 8.32 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07376315915313122		[learning rate: 0.000173]
	Learning Rate: 0.000173002
	LOSS [training: 0.07376315915313122 | validation: 0.07320795241897331]
	TIME [epoch: 8.32 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07408840799719363		[learning rate: 0.00017259]
	Learning Rate: 0.000172594
	LOSS [training: 0.07408840799719363 | validation: 0.06786633255963892]
	TIME [epoch: 8.32 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07592681174715693		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.07592681174715693 | validation: 0.06887065611067344]
	TIME [epoch: 8.34 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07362800326922438		[learning rate: 0.00017178]
	Learning Rate: 0.000171781
	LOSS [training: 0.07362800326922438 | validation: 0.07651713673144275]
	TIME [epoch: 8.32 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07089644348966531		[learning rate: 0.00017138]
	Learning Rate: 0.000171375
	LOSS [training: 0.07089644348966531 | validation: 0.061150592429279615]
	TIME [epoch: 8.32 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07625121503396091		[learning rate: 0.00017097]
	Learning Rate: 0.000170971
	LOSS [training: 0.07625121503396091 | validation: 0.06022859513610444]
	TIME [epoch: 8.32 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0723776875327827		[learning rate: 0.00017057]
	Learning Rate: 0.000170568
	LOSS [training: 0.0723776875327827 | validation: 0.07093966226022697]
	TIME [epoch: 8.35 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07205018519043552		[learning rate: 0.00017017]
	Learning Rate: 0.000170166
	LOSS [training: 0.07205018519043552 | validation: 0.07302182500627283]
	TIME [epoch: 8.32 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07707756244975383		[learning rate: 0.00016976]
	Learning Rate: 0.000169764
	LOSS [training: 0.07707756244975383 | validation: 0.08149032200375467]
	TIME [epoch: 8.32 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07797581085419497		[learning rate: 0.00016936]
	Learning Rate: 0.000169364
	LOSS [training: 0.07797581085419497 | validation: 0.05753116371193999]
	TIME [epoch: 8.32 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0851963720727977		[learning rate: 0.00016896]
	Learning Rate: 0.000168964
	LOSS [training: 0.0851963720727977 | validation: 0.07274441959735369]
	TIME [epoch: 8.34 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10115441918646309		[learning rate: 0.00016857]
	Learning Rate: 0.000168566
	LOSS [training: 0.10115441918646309 | validation: 0.07596004373677923]
	TIME [epoch: 8.32 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08436093076985594		[learning rate: 0.00016817]
	Learning Rate: 0.000168168
	LOSS [training: 0.08436093076985594 | validation: 0.06538278405781803]
	TIME [epoch: 8.31 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07258720873050618		[learning rate: 0.00016777]
	Learning Rate: 0.000167771
	LOSS [training: 0.07258720873050618 | validation: 0.0773390038986721]
	TIME [epoch: 8.33 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07515240656575654		[learning rate: 0.00016738]
	Learning Rate: 0.000167376
	LOSS [training: 0.07515240656575654 | validation: 0.06787427815555931]
	TIME [epoch: 8.35 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07635664717441334		[learning rate: 0.00016698]
	Learning Rate: 0.000166981
	LOSS [training: 0.07635664717441334 | validation: 0.07187161002222603]
	TIME [epoch: 8.31 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07820156754641007		[learning rate: 0.00016659]
	Learning Rate: 0.000166587
	LOSS [training: 0.07820156754641007 | validation: 0.07877048718642127]
	TIME [epoch: 8.32 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07623781245941716		[learning rate: 0.00016619]
	Learning Rate: 0.000166194
	LOSS [training: 0.07623781245941716 | validation: 0.07233239834063021]
	TIME [epoch: 8.33 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07447244761168165		[learning rate: 0.0001658]
	Learning Rate: 0.000165802
	LOSS [training: 0.07447244761168165 | validation: 0.06747931076339628]
	TIME [epoch: 8.35 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07336451407156112		[learning rate: 0.00016541]
	Learning Rate: 0.000165411
	LOSS [training: 0.07336451407156112 | validation: 0.07050204419347883]
	TIME [epoch: 8.32 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0778605055138234		[learning rate: 0.00016502]
	Learning Rate: 0.000165021
	LOSS [training: 0.0778605055138234 | validation: 0.06510669389265095]
	TIME [epoch: 8.32 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07440814839245542		[learning rate: 0.00016463]
	Learning Rate: 0.000164631
	LOSS [training: 0.07440814839245542 | validation: 0.07084139047923407]
	TIME [epoch: 8.32 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08084902108936533		[learning rate: 0.00016424]
	Learning Rate: 0.000164243
	LOSS [training: 0.08084902108936533 | validation: 0.06584673046742137]
	TIME [epoch: 8.34 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0808413352667065		[learning rate: 0.00016386]
	Learning Rate: 0.000163856
	LOSS [training: 0.0808413352667065 | validation: 0.06433892947679522]
	TIME [epoch: 8.32 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07742080813965382		[learning rate: 0.00016347]
	Learning Rate: 0.000163469
	LOSS [training: 0.07742080813965382 | validation: 0.05709361002793109]
	TIME [epoch: 8.33 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0868238540277381		[learning rate: 0.00016308]
	Learning Rate: 0.000163084
	LOSS [training: 0.0868238540277381 | validation: 0.061791020090781835]
	TIME [epoch: 8.33 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07267322543840919		[learning rate: 0.0001627]
	Learning Rate: 0.000162699
	LOSS [training: 0.07267322543840919 | validation: 0.05866840831726608]
	TIME [epoch: 8.35 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07251630792406731		[learning rate: 0.00016232]
	Learning Rate: 0.000162315
	LOSS [training: 0.07251630792406731 | validation: 0.05457410314479634]
	TIME [epoch: 8.32 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07694721737724455		[learning rate: 0.00016193]
	Learning Rate: 0.000161932
	LOSS [training: 0.07694721737724455 | validation: 0.056122324225813924]
	TIME [epoch: 8.32 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07186484210684152		[learning rate: 0.00016155]
	Learning Rate: 0.00016155
	LOSS [training: 0.07186484210684152 | validation: 0.06597446872872752]
	TIME [epoch: 8.33 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06768593463357757		[learning rate: 0.00016117]
	Learning Rate: 0.000161169
	LOSS [training: 0.06768593463357757 | validation: 0.07036428899702937]
	TIME [epoch: 8.34 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07432267845933604		[learning rate: 0.00016079]
	Learning Rate: 0.000160789
	LOSS [training: 0.07432267845933604 | validation: 0.06240840469531177]
	TIME [epoch: 8.32 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07780335553571884		[learning rate: 0.00016041]
	Learning Rate: 0.00016041
	LOSS [training: 0.07780335553571884 | validation: 0.08159421510057915]
	TIME [epoch: 8.32 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.081062991936283		[learning rate: 0.00016003]
	Learning Rate: 0.000160031
	LOSS [training: 0.081062991936283 | validation: 0.06657562091784452]
	TIME [epoch: 8.33 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07283053958492167		[learning rate: 0.00015965]
	Learning Rate: 0.000159654
	LOSS [training: 0.07283053958492167 | validation: 0.06661527974661531]
	TIME [epoch: 8.34 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07180980280026755		[learning rate: 0.00015928]
	Learning Rate: 0.000159277
	LOSS [training: 0.07180980280026755 | validation: 0.06856065424101351]
	TIME [epoch: 8.32 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07677957021617929		[learning rate: 0.0001589]
	Learning Rate: 0.000158902
	LOSS [training: 0.07677957021617929 | validation: 0.07522272507266975]
	TIME [epoch: 8.32 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0716957117744915		[learning rate: 0.00015853]
	Learning Rate: 0.000158527
	LOSS [training: 0.0716957117744915 | validation: 0.06389639283685591]
	TIME [epoch: 8.34 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06819175372773775		[learning rate: 0.00015815]
	Learning Rate: 0.000158153
	LOSS [training: 0.06819175372773775 | validation: 0.0676546799260031]
	TIME [epoch: 8.34 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07431937382095873		[learning rate: 0.00015778]
	Learning Rate: 0.00015778
	LOSS [training: 0.07431937382095873 | validation: 0.08074701048118871]
	TIME [epoch: 8.32 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07704996589446314		[learning rate: 0.00015741]
	Learning Rate: 0.000157408
	LOSS [training: 0.07704996589446314 | validation: 0.05711786252499672]
	TIME [epoch: 8.31 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0729611538711195		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.0729611538711195 | validation: 0.07274224771414592]
	TIME [epoch: 8.34 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07325831319707389		[learning rate: 0.00015667]
	Learning Rate: 0.000156666
	LOSS [training: 0.07325831319707389 | validation: 0.06799271920303968]
	TIME [epoch: 8.33 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06970350979013369		[learning rate: 0.0001563]
	Learning Rate: 0.000156296
	LOSS [training: 0.06970350979013369 | validation: 0.0643342692581919]
	TIME [epoch: 8.32 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07205678574830263		[learning rate: 0.00015593]
	Learning Rate: 0.000155928
	LOSS [training: 0.07205678574830263 | validation: 0.06422595587093276]
	TIME [epoch: 8.32 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06860774888437363		[learning rate: 0.00015556]
	Learning Rate: 0.00015556
	LOSS [training: 0.06860774888437363 | validation: 0.07182214309282517]
	TIME [epoch: 8.34 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07426658796907663		[learning rate: 0.00015519]
	Learning Rate: 0.000155193
	LOSS [training: 0.07426658796907663 | validation: 0.07039604346220993]
	TIME [epoch: 8.33 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07430034706769736		[learning rate: 0.00015483]
	Learning Rate: 0.000154827
	LOSS [training: 0.07430034706769736 | validation: 0.07391002915564075]
	TIME [epoch: 8.33 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07221174953017115		[learning rate: 0.00015446]
	Learning Rate: 0.000154462
	LOSS [training: 0.07221174953017115 | validation: 0.06111777034413618]
	TIME [epoch: 8.32 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06992003705534777		[learning rate: 0.0001541]
	Learning Rate: 0.000154097
	LOSS [training: 0.06992003705534777 | validation: 0.06825119468272586]
	TIME [epoch: 8.34 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06758131705961629		[learning rate: 0.00015373]
	Learning Rate: 0.000153734
	LOSS [training: 0.06758131705961629 | validation: 0.06058214499252469]
	TIME [epoch: 8.33 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06989927838259428		[learning rate: 0.00015337]
	Learning Rate: 0.000153371
	LOSS [training: 0.06989927838259428 | validation: 0.06479576625719821]
	TIME [epoch: 8.33 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08503795956280553		[learning rate: 0.00015301]
	Learning Rate: 0.000153009
	LOSS [training: 0.08503795956280553 | validation: 0.07220943614563995]
	TIME [epoch: 8.32 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07949258591550173		[learning rate: 0.00015265]
	Learning Rate: 0.000152648
	LOSS [training: 0.07949258591550173 | validation: 0.062167268759462976]
	TIME [epoch: 8.33 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07184393537974756		[learning rate: 0.00015229]
	Learning Rate: 0.000152288
	LOSS [training: 0.07184393537974756 | validation: 0.05855927961882429]
	TIME [epoch: 8.33 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07236984500306716		[learning rate: 0.00015193]
	Learning Rate: 0.000151929
	LOSS [training: 0.07236984500306716 | validation: 0.07020451620048307]
	TIME [epoch: 8.33 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07459635930755727		[learning rate: 0.00015157]
	Learning Rate: 0.000151571
	LOSS [training: 0.07459635930755727 | validation: 0.06477254440229868]
	TIME [epoch: 8.33 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07966967258137891		[learning rate: 0.00015121]
	Learning Rate: 0.000151213
	LOSS [training: 0.07966967258137891 | validation: 0.06466505987016724]
	TIME [epoch: 8.33 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07110773810304909		[learning rate: 0.00015086]
	Learning Rate: 0.000150857
	LOSS [training: 0.07110773810304909 | validation: 0.06687210153822284]
	TIME [epoch: 8.33 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07470575036127998		[learning rate: 0.0001505]
	Learning Rate: 0.000150501
	LOSS [training: 0.07470575036127998 | validation: 0.060306953108612456]
	TIME [epoch: 8.32 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07054852779984544		[learning rate: 0.00015015]
	Learning Rate: 0.000150146
	LOSS [training: 0.07054852779984544 | validation: 0.06940724956430307]
	TIME [epoch: 8.32 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07368367347273362		[learning rate: 0.00014979]
	Learning Rate: 0.000149791
	LOSS [training: 0.07368367347273362 | validation: 0.07235810826309454]
	TIME [epoch: 8.34 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07622708732427794		[learning rate: 0.00014944]
	Learning Rate: 0.000149438
	LOSS [training: 0.07622708732427794 | validation: 0.08077350548991022]
	TIME [epoch: 8.33 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.080514266122874		[learning rate: 0.00014909]
	Learning Rate: 0.000149086
	LOSS [training: 0.080514266122874 | validation: 0.06955682928976431]
	TIME [epoch: 8.32 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07612754309595875		[learning rate: 0.00014873]
	Learning Rate: 0.000148734
	LOSS [training: 0.07612754309595875 | validation: 0.059048316484364205]
	TIME [epoch: 8.32 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07502509711990199		[learning rate: 0.00014838]
	Learning Rate: 0.000148383
	LOSS [training: 0.07502509711990199 | validation: 0.06299617521772335]
	TIME [epoch: 8.33 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06987513175182873		[learning rate: 0.00014803]
	Learning Rate: 0.000148033
	LOSS [training: 0.06987513175182873 | validation: 0.06881225728896578]
	TIME [epoch: 8.33 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07165078733828674		[learning rate: 0.00014768]
	Learning Rate: 0.000147684
	LOSS [training: 0.07165078733828674 | validation: 0.06179226682129382]
	TIME [epoch: 8.32 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07352698186217341		[learning rate: 0.00014734]
	Learning Rate: 0.000147336
	LOSS [training: 0.07352698186217341 | validation: 0.07028589768455734]
	TIME [epoch: 8.32 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07389222006306469		[learning rate: 0.00014699]
	Learning Rate: 0.000146988
	LOSS [training: 0.07389222006306469 | validation: 0.06195122694815349]
	TIME [epoch: 8.34 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06940779469338212		[learning rate: 0.00014664]
	Learning Rate: 0.000146641
	LOSS [training: 0.06940779469338212 | validation: 0.06179351581976513]
	TIME [epoch: 8.33 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07192770867961477		[learning rate: 0.0001463]
	Learning Rate: 0.000146295
	LOSS [training: 0.07192770867961477 | validation: 0.07181359311481436]
	TIME [epoch: 8.33 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07654504927342956		[learning rate: 0.00014595]
	Learning Rate: 0.00014595
	LOSS [training: 0.07654504927342956 | validation: 0.06170983013514329]
	TIME [epoch: 8.32 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07285462699601372		[learning rate: 0.00014561]
	Learning Rate: 0.000145606
	LOSS [training: 0.07285462699601372 | validation: 0.06119835564715538]
	TIME [epoch: 8.35 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0730253066353175		[learning rate: 0.00014526]
	Learning Rate: 0.000145263
	LOSS [training: 0.0730253066353175 | validation: 0.07091943250838507]
	TIME [epoch: 8.33 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07284589919251132		[learning rate: 0.00014492]
	Learning Rate: 0.00014492
	LOSS [training: 0.07284589919251132 | validation: 0.06462127303498807]
	TIME [epoch: 8.32 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06533642933302097		[learning rate: 0.00014458]
	Learning Rate: 0.000144578
	LOSS [training: 0.06533642933302097 | validation: 0.05387344006201859]
	TIME [epoch: 8.32 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0705411781108006		[learning rate: 0.00014424]
	Learning Rate: 0.000144237
	LOSS [training: 0.0705411781108006 | validation: 0.07845452356728558]
	TIME [epoch: 8.34 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07470655911487364		[learning rate: 0.0001439]
	Learning Rate: 0.000143897
	LOSS [training: 0.07470655911487364 | validation: 0.06579002096704245]
	TIME [epoch: 8.32 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07054277376185195		[learning rate: 0.00014356]
	Learning Rate: 0.000143557
	LOSS [training: 0.07054277376185195 | validation: 0.06481618934583402]
	TIME [epoch: 8.32 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07572581963059341		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.07572581963059341 | validation: 0.07346927637804315]
	TIME [epoch: 8.32 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07447506934426536		[learning rate: 0.00014288]
	Learning Rate: 0.000142881
	LOSS [training: 0.07447506934426536 | validation: 0.06313885391925064]
	TIME [epoch: 8.34 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07548669857071383		[learning rate: 0.00014254]
	Learning Rate: 0.000142544
	LOSS [training: 0.07548669857071383 | validation: 0.07928762176000959]
	TIME [epoch: 8.32 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07128008375869958		[learning rate: 0.00014221]
	Learning Rate: 0.000142208
	LOSS [training: 0.07128008375869958 | validation: 0.07064021283898533]
	TIME [epoch: 8.32 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08348288668511877		[learning rate: 0.00014187]
	Learning Rate: 0.000141872
	LOSS [training: 0.08348288668511877 | validation: 0.06609055593678365]
	TIME [epoch: 8.32 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07369911145076014		[learning rate: 0.00014154]
	Learning Rate: 0.000141538
	LOSS [training: 0.07369911145076014 | validation: 0.061687870604055006]
	TIME [epoch: 8.34 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0712224661193119		[learning rate: 0.0001412]
	Learning Rate: 0.000141204
	LOSS [training: 0.0712224661193119 | validation: 0.06868319810578005]
	TIME [epoch: 8.32 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0736566683745249		[learning rate: 0.00014087]
	Learning Rate: 0.000140871
	LOSS [training: 0.0736566683745249 | validation: 0.06153475129672817]
	TIME [epoch: 8.32 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07371645618150141		[learning rate: 0.00014054]
	Learning Rate: 0.000140538
	LOSS [training: 0.07371645618150141 | validation: 0.06884327789347142]
	TIME [epoch: 8.32 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0686901927544806		[learning rate: 0.00014021]
	Learning Rate: 0.000140207
	LOSS [training: 0.0686901927544806 | validation: 0.062039873453194394]
	TIME [epoch: 8.35 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07752043339361071		[learning rate: 0.00013988]
	Learning Rate: 0.000139876
	LOSS [training: 0.07752043339361071 | validation: 0.07779509237558128]
	TIME [epoch: 8.32 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07196821108560955		[learning rate: 0.00013955]
	Learning Rate: 0.000139546
	LOSS [training: 0.07196821108560955 | validation: 0.07280297576182412]
	TIME [epoch: 8.32 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07476088680291229		[learning rate: 0.00013922]
	Learning Rate: 0.000139217
	LOSS [training: 0.07476088680291229 | validation: 0.059757813785165065]
	TIME [epoch: 8.32 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06717722295178064		[learning rate: 0.00013889]
	Learning Rate: 0.000138889
	LOSS [training: 0.06717722295178064 | validation: 0.06685277862528916]
	TIME [epoch: 8.35 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07203693353555331		[learning rate: 0.00013856]
	Learning Rate: 0.000138561
	LOSS [training: 0.07203693353555331 | validation: 0.06514250131406957]
	TIME [epoch: 8.32 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07404627875595607		[learning rate: 0.00013823]
	Learning Rate: 0.000138234
	LOSS [training: 0.07404627875595607 | validation: 0.07134618860428109]
	TIME [epoch: 8.33 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07123779740912907		[learning rate: 0.00013791]
	Learning Rate: 0.000137908
	LOSS [training: 0.07123779740912907 | validation: 0.07652121754846604]
	TIME [epoch: 8.32 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07495426872517816		[learning rate: 0.00013758]
	Learning Rate: 0.000137583
	LOSS [training: 0.07495426872517816 | validation: 0.061434055574633016]
	TIME [epoch: 8.35 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06897265617726654		[learning rate: 0.00013726]
	Learning Rate: 0.000137258
	LOSS [training: 0.06897265617726654 | validation: 0.07506900795294769]
	TIME [epoch: 8.32 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07684798855658238		[learning rate: 0.00013693]
	Learning Rate: 0.000136934
	LOSS [training: 0.07684798855658238 | validation: 0.06685051304280294]
	TIME [epoch: 8.32 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07780364880808179		[learning rate: 0.00013661]
	Learning Rate: 0.000136611
	LOSS [training: 0.07780364880808179 | validation: 0.07561817350357927]
	TIME [epoch: 8.33 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07209784087176332		[learning rate: 0.00013629]
	Learning Rate: 0.000136289
	LOSS [training: 0.07209784087176332 | validation: 0.07139357170965333]
	TIME [epoch: 8.34 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07891031413929586		[learning rate: 0.00013597]
	Learning Rate: 0.000135968
	LOSS [training: 0.07891031413929586 | validation: 0.06863249259068639]
	TIME [epoch: 8.33 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06830854220042852		[learning rate: 0.00013565]
	Learning Rate: 0.000135647
	LOSS [training: 0.06830854220042852 | validation: 0.06718535786298238]
	TIME [epoch: 8.32 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0725676883158867		[learning rate: 0.00013533]
	Learning Rate: 0.000135327
	LOSS [training: 0.0725676883158867 | validation: 0.07788223870456827]
	TIME [epoch: 8.32 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06927565819075071		[learning rate: 0.00013501]
	Learning Rate: 0.000135008
	LOSS [training: 0.06927565819075071 | validation: 0.06820135821156566]
	TIME [epoch: 8.35 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07116912831412694		[learning rate: 0.00013469]
	Learning Rate: 0.000134689
	LOSS [training: 0.07116912831412694 | validation: 0.0719843479447831]
	TIME [epoch: 8.34 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07321776785419554		[learning rate: 0.00013437]
	Learning Rate: 0.000134372
	LOSS [training: 0.07321776785419554 | validation: 0.06509140731602572]
	TIME [epoch: 8.32 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07609648951259258		[learning rate: 0.00013405]
	Learning Rate: 0.000134055
	LOSS [training: 0.07609648951259258 | validation: 0.06671039481432198]
	TIME [epoch: 8.33 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0695259947457896		[learning rate: 0.00013374]
	Learning Rate: 0.000133738
	LOSS [training: 0.0695259947457896 | validation: 0.07249743609352982]
	TIME [epoch: 8.35 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07057833736025142		[learning rate: 0.00013342]
	Learning Rate: 0.000133423
	LOSS [training: 0.07057833736025142 | validation: 0.07070432490173617]
	TIME [epoch: 8.32 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06960011461044392		[learning rate: 0.00013311]
	Learning Rate: 0.000133108
	LOSS [training: 0.06960011461044392 | validation: 0.06083381589461277]
	TIME [epoch: 8.33 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07095399965243442		[learning rate: 0.00013279]
	Learning Rate: 0.000132794
	LOSS [training: 0.07095399965243442 | validation: 0.08635996498749268]
	TIME [epoch: 8.33 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07683235419998702		[learning rate: 0.00013248]
	Learning Rate: 0.000132481
	LOSS [training: 0.07683235419998702 | validation: 0.05641249130735936]
	TIME [epoch: 8.34 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06956307046458532		[learning rate: 0.00013217]
	Learning Rate: 0.000132169
	LOSS [training: 0.06956307046458532 | validation: 0.0646805234343985]
	TIME [epoch: 8.32 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07121770101723236		[learning rate: 0.00013186]
	Learning Rate: 0.000131857
	LOSS [training: 0.07121770101723236 | validation: 0.06132884418988309]
	TIME [epoch: 8.32 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07215128406032198		[learning rate: 0.00013155]
	Learning Rate: 0.000131546
	LOSS [training: 0.07215128406032198 | validation: 0.0720972472931701]
	TIME [epoch: 8.32 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07059326670258641		[learning rate: 0.00013124]
	Learning Rate: 0.000131235
	LOSS [training: 0.07059326670258641 | validation: 0.07782363526365979]
	TIME [epoch: 8.35 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0756186025870756		[learning rate: 0.00013093]
	Learning Rate: 0.000130926
	LOSS [training: 0.0756186025870756 | validation: 0.07128080609463666]
	TIME [epoch: 8.33 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06776207848630125		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.06776207848630125 | validation: 0.07149250702520993]
	TIME [epoch: 8.33 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07009712350043872		[learning rate: 0.00013031]
	Learning Rate: 0.000130309
	LOSS [training: 0.07009712350043872 | validation: 0.06843784547341536]
	TIME [epoch: 8.33 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07301683267150265		[learning rate: 0.00013]
	Learning Rate: 0.000130002
	LOSS [training: 0.07301683267150265 | validation: 0.06208472970286516]
	TIME [epoch: 8.35 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07092931597475086		[learning rate: 0.00012969]
	Learning Rate: 0.000129695
	LOSS [training: 0.07092931597475086 | validation: 0.07389496970045706]
	TIME [epoch: 8.33 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07709112464174141		[learning rate: 0.00012939]
	Learning Rate: 0.000129389
	LOSS [training: 0.07709112464174141 | validation: 0.07222350066915484]
	TIME [epoch: 8.34 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07415638515767288		[learning rate: 0.00012908]
	Learning Rate: 0.000129084
	LOSS [training: 0.07415638515767288 | validation: 0.060367472187746685]
	TIME [epoch: 8.33 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06707430813962312		[learning rate: 0.00012878]
	Learning Rate: 0.000128779
	LOSS [training: 0.06707430813962312 | validation: 0.06846641524238221]
	TIME [epoch: 8.35 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07240599272224073		[learning rate: 0.00012848]
	Learning Rate: 0.000128476
	LOSS [training: 0.07240599272224073 | validation: 0.07101271685644706]
	TIME [epoch: 8.32 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07691243461623828		[learning rate: 0.00012817]
	Learning Rate: 0.000128172
	LOSS [training: 0.07691243461623828 | validation: 0.07538716227505624]
	TIME [epoch: 8.33 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07089066050586973		[learning rate: 0.00012787]
	Learning Rate: 0.00012787
	LOSS [training: 0.07089066050586973 | validation: 0.07490685871497228]
	TIME [epoch: 8.33 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07284934044174131		[learning rate: 0.00012757]
	Learning Rate: 0.000127569
	LOSS [training: 0.07284934044174131 | validation: 0.06640305409834461]
	TIME [epoch: 8.35 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07472939846878643		[learning rate: 0.00012727]
	Learning Rate: 0.000127268
	LOSS [training: 0.07472939846878643 | validation: 0.06722560522853369]
	TIME [epoch: 8.33 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06715922228144958		[learning rate: 0.00012697]
	Learning Rate: 0.000126967
	LOSS [training: 0.06715922228144958 | validation: 0.06769060888964136]
	TIME [epoch: 8.32 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06679936951963801		[learning rate: 0.00012667]
	Learning Rate: 0.000126668
	LOSS [training: 0.06679936951963801 | validation: 0.04796199173726785]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240219_184940/states/model_tr_study3_1900.pth
	Model improved!!!
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0684523503257033		[learning rate: 0.00012637]
	Learning Rate: 0.000126369
	LOSS [training: 0.0684523503257033 | validation: 0.06322137451437276]
	TIME [epoch: 8.35 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07328397690720348		[learning rate: 0.00012607]
	Learning Rate: 0.000126071
	LOSS [training: 0.07328397690720348 | validation: 0.0750031109531236]
	TIME [epoch: 8.33 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07501111321895404		[learning rate: 0.00012577]
	Learning Rate: 0.000125774
	LOSS [training: 0.07501111321895404 | validation: 0.06367098679788047]
	TIME [epoch: 8.33 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07388128593410655		[learning rate: 0.00012548]
	Learning Rate: 0.000125477
	LOSS [training: 0.07388128593410655 | validation: 0.0788618543191379]
	TIME [epoch: 8.33 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07705948709119134		[learning rate: 0.00012518]
	Learning Rate: 0.000125181
	LOSS [training: 0.07705948709119134 | validation: 0.08297671514135269]
	TIME [epoch: 8.35 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07445123660953798		[learning rate: 0.00012489]
	Learning Rate: 0.000124886
	LOSS [training: 0.07445123660953798 | validation: 0.06616499477948831]
	TIME [epoch: 8.33 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07463033761752194		[learning rate: 0.00012459]
	Learning Rate: 0.000124591
	LOSS [training: 0.07463033761752194 | validation: 0.05924974127377021]
	TIME [epoch: 8.33 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07078629915617088		[learning rate: 0.0001243]
	Learning Rate: 0.000124297
	LOSS [training: 0.07078629915617088 | validation: 0.07086739349657446]
	TIME [epoch: 8.34 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07586312116445418		[learning rate: 0.000124]
	Learning Rate: 0.000124004
	LOSS [training: 0.07586312116445418 | validation: 0.08075349663895248]
	TIME [epoch: 8.34 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07466035198217436		[learning rate: 0.00012371]
	Learning Rate: 0.000123712
	LOSS [training: 0.07466035198217436 | validation: 0.07067744659931745]
	TIME [epoch: 8.33 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0795377122262503		[learning rate: 0.00012342]
	Learning Rate: 0.00012342
	LOSS [training: 0.0795377122262503 | validation: 0.06893586012591697]
	TIME [epoch: 8.33 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0780648299133867		[learning rate: 0.00012313]
	Learning Rate: 0.000123129
	LOSS [training: 0.0780648299133867 | validation: 0.06185668836870121]
	TIME [epoch: 8.33 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07456889769701096		[learning rate: 0.00012284]
	Learning Rate: 0.000122838
	LOSS [training: 0.07456889769701096 | validation: 0.06679937209496659]
	TIME [epoch: 8.35 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07869608642250195		[learning rate: 0.00012255]
	Learning Rate: 0.000122548
	LOSS [training: 0.07869608642250195 | validation: 0.05915289210374695]
	TIME [epoch: 8.33 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07857664203749065		[learning rate: 0.00012226]
	Learning Rate: 0.000122259
	LOSS [training: 0.07857664203749065 | validation: 0.06860722810770536]
	TIME [epoch: 8.33 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07483256041968692		[learning rate: 0.00012197]
	Learning Rate: 0.000121971
	LOSS [training: 0.07483256041968692 | validation: 0.060018146573986866]
	TIME [epoch: 8.34 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07983685011357625		[learning rate: 0.00012168]
	Learning Rate: 0.000121683
	LOSS [training: 0.07983685011357625 | validation: 0.06690967769858047]
	TIME [epoch: 8.35 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07312155919597255		[learning rate: 0.0001214]
	Learning Rate: 0.000121396
	LOSS [training: 0.07312155919597255 | validation: 0.07178100677777746]
	TIME [epoch: 8.33 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07361305977206575		[learning rate: 0.00012111]
	Learning Rate: 0.00012111
	LOSS [training: 0.07361305977206575 | validation: 0.06312939766544265]
	TIME [epoch: 8.33 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07188061468945137		[learning rate: 0.00012082]
	Learning Rate: 0.000120824
	LOSS [training: 0.07188061468945137 | validation: 0.051986786653227715]
	TIME [epoch: 8.33 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0743677897108089		[learning rate: 0.00012054]
	Learning Rate: 0.000120539
	LOSS [training: 0.0743677897108089 | validation: 0.07130422316207274]
	TIME [epoch: 8.34 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07344957328340043		[learning rate: 0.00012025]
	Learning Rate: 0.000120255
	LOSS [training: 0.07344957328340043 | validation: 0.06744950540322067]
	TIME [epoch: 8.32 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07506732138449786		[learning rate: 0.00011997]
	Learning Rate: 0.000119971
	LOSS [training: 0.07506732138449786 | validation: 0.06046617129632255]
	TIME [epoch: 8.33 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07199872946703278		[learning rate: 0.00011969]
	Learning Rate: 0.000119688
	LOSS [training: 0.07199872946703278 | validation: 0.06400837583682945]
	TIME [epoch: 8.35 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06938218416492457		[learning rate: 0.00011941]
	Learning Rate: 0.000119406
	LOSS [training: 0.06938218416492457 | validation: 0.06524606938365646]
	TIME [epoch: 8.33 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06722074346330911		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.06722074346330911 | validation: 0.0621410844567426]
	TIME [epoch: 8.33 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07126146893612953		[learning rate: 0.00011884]
	Learning Rate: 0.000118843
	LOSS [training: 0.07126146893612953 | validation: 0.06700131039937099]
	TIME [epoch: 8.33 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07651256905412178		[learning rate: 0.00011856]
	Learning Rate: 0.000118563
	LOSS [training: 0.07651256905412178 | validation: 0.0679072129006973]
	TIME [epoch: 8.34 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07902096533150346		[learning rate: 0.00011828]
	Learning Rate: 0.000118283
	LOSS [training: 0.07902096533150346 | validation: 0.06079489144602139]
	TIME [epoch: 8.34 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07260033204019763		[learning rate: 0.000118]
	Learning Rate: 0.000118004
	LOSS [training: 0.07260033204019763 | validation: 0.059062276785299184]
	TIME [epoch: 8.32 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07857209912261005		[learning rate: 0.00011773]
	Learning Rate: 0.000117726
	LOSS [training: 0.07857209912261005 | validation: 0.06376044457730404]
	TIME [epoch: 8.32 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07596562281625607		[learning rate: 0.00011745]
	Learning Rate: 0.000117448
	LOSS [training: 0.07596562281625607 | validation: 0.06513780748639655]
	TIME [epoch: 8.35 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08453071228443125		[learning rate: 0.00011717]
	Learning Rate: 0.000117171
	LOSS [training: 0.08453071228443125 | validation: 0.06870677911063541]
	TIME [epoch: 8.34 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07250915524037424		[learning rate: 0.00011689]
	Learning Rate: 0.000116895
	LOSS [training: 0.07250915524037424 | validation: 0.06331345334784372]
	TIME [epoch: 8.33 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07978913712255069		[learning rate: 0.00011662]
	Learning Rate: 0.000116619
	LOSS [training: 0.07978913712255069 | validation: 0.07715466725157283]
	TIME [epoch: 8.33 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08164481985495017		[learning rate: 0.00011634]
	Learning Rate: 0.000116344
	LOSS [training: 0.08164481985495017 | validation: 0.08462430344595323]
	TIME [epoch: 8.34 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07535210832499184		[learning rate: 0.00011607]
	Learning Rate: 0.000116069
	LOSS [training: 0.07535210832499184 | validation: 0.062473350151700566]
	TIME [epoch: 8.35 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06951534976471849		[learning rate: 0.0001158]
	Learning Rate: 0.000115796
	LOSS [training: 0.06951534976471849 | validation: 0.06421253933904866]
	TIME [epoch: 8.33 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07454820638463017		[learning rate: 0.00011552]
	Learning Rate: 0.000115523
	LOSS [training: 0.07454820638463017 | validation: 0.06255331309154144]
	TIME [epoch: 8.33 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06924657995010626		[learning rate: 0.00011525]
	Learning Rate: 0.00011525
	LOSS [training: 0.06924657995010626 | validation: 0.0650762484546512]
	TIME [epoch: 8.34 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07054924225031164		[learning rate: 0.00011498]
	Learning Rate: 0.000114978
	LOSS [training: 0.07054924225031164 | validation: 0.06129172543645604]
	TIME [epoch: 8.34 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06847881606034131		[learning rate: 0.00011471]
	Learning Rate: 0.000114707
	LOSS [training: 0.06847881606034131 | validation: 0.0604970114256137]
	TIME [epoch: 8.32 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06881154423638404		[learning rate: 0.00011444]
	Learning Rate: 0.000114436
	LOSS [training: 0.06881154423638404 | validation: 0.06749959147042534]
	TIME [epoch: 8.33 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07016765062405042		[learning rate: 0.00011417]
	Learning Rate: 0.000114166
	LOSS [training: 0.07016765062405042 | validation: 0.06340197653125365]
	TIME [epoch: 8.34 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0678243338305726		[learning rate: 0.0001139]
	Learning Rate: 0.000113897
	LOSS [training: 0.0678243338305726 | validation: 0.06374423140410944]
	TIME [epoch: 8.33 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07314206234999736		[learning rate: 0.00011363]
	Learning Rate: 0.000113628
	LOSS [training: 0.07314206234999736 | validation: 0.05869776818273305]
	TIME [epoch: 8.34 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0725950664227008		[learning rate: 0.00011336]
	Learning Rate: 0.00011336
	LOSS [training: 0.0725950664227008 | validation: 0.07396741249019889]
	TIME [epoch: 8.33 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07144554899584957		[learning rate: 0.00011309]
	Learning Rate: 0.000113093
	LOSS [training: 0.07144554899584957 | validation: 0.05984162787196824]
	TIME [epoch: 8.34 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07405941008378819		[learning rate: 0.00011283]
	Learning Rate: 0.000112826
	LOSS [training: 0.07405941008378819 | validation: 0.0713890281631929]
	TIME [epoch: 8.33 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07249590972470103		[learning rate: 0.00011256]
	Learning Rate: 0.00011256
	LOSS [training: 0.07249590972470103 | validation: 0.07544128400148661]
	TIME [epoch: 8.33 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0682323923397823		[learning rate: 0.00011229]
	Learning Rate: 0.000112295
	LOSS [training: 0.0682323923397823 | validation: 0.07139272557887882]
	TIME [epoch: 8.32 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06832480682556673		[learning rate: 0.00011203]
	Learning Rate: 0.00011203
	LOSS [training: 0.06832480682556673 | validation: 0.07226148238644746]
	TIME [epoch: 8.35 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07349553671463717		[learning rate: 0.00011177]
	Learning Rate: 0.000111765
	LOSS [training: 0.07349553671463717 | validation: 0.06979962518988254]
	TIME [epoch: 8.33 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07146655258457592		[learning rate: 0.0001115]
	Learning Rate: 0.000111502
	LOSS [training: 0.07146655258457592 | validation: 0.07590414628737388]
	TIME [epoch: 8.34 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07520197679608208		[learning rate: 0.00011124]
	Learning Rate: 0.000111239
	LOSS [training: 0.07520197679608208 | validation: 0.06738228516346981]
	TIME [epoch: 8.33 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07194676473847332		[learning rate: 0.00011098]
	Learning Rate: 0.000110976
	LOSS [training: 0.07194676473847332 | validation: 0.07094753050105615]
	TIME [epoch: 8.35 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06978845312413479		[learning rate: 0.00011071]
	Learning Rate: 0.000110715
	LOSS [training: 0.06978845312413479 | validation: 0.07243690128202122]
	TIME [epoch: 8.33 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0721057064666393		[learning rate: 0.00011045]
	Learning Rate: 0.000110453
	LOSS [training: 0.0721057064666393 | validation: 0.07288962204041058]
	TIME [epoch: 8.33 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0777337022995396		[learning rate: 0.00011019]
	Learning Rate: 0.000110193
	LOSS [training: 0.0777337022995396 | validation: 0.05579119604222442]
	TIME [epoch: 8.33 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07575798472006327		[learning rate: 0.00010993]
	Learning Rate: 0.000109933
	LOSS [training: 0.07575798472006327 | validation: 0.07262415777819772]
	TIME [epoch: 8.35 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07351568540002233		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.07351568540002233 | validation: 0.06337473907417196]
	TIME [epoch: 8.34 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07441698728691169		[learning rate: 0.00010942]
	Learning Rate: 0.000109415
	LOSS [training: 0.07441698728691169 | validation: 0.07716637854360717]
	TIME [epoch: 8.33 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06927174651724018		[learning rate: 0.00010916]
	Learning Rate: 0.000109157
	LOSS [training: 0.06927174651724018 | validation: 0.06980531554249546]
	TIME [epoch: 8.33 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0716549715319646		[learning rate: 0.0001089]
	Learning Rate: 0.000108899
	LOSS [training: 0.0716549715319646 | validation: 0.07528199158352351]
	TIME [epoch: 8.35 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07105285221623465		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.07105285221623465 | validation: 0.07616428339317433]
	TIME [epoch: 8.33 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06980221500421899		[learning rate: 0.00010839]
	Learning Rate: 0.000108386
	LOSS [training: 0.06980221500421899 | validation: 0.05694299629421437]
	TIME [epoch: 8.33 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07060736730424842		[learning rate: 0.00010813]
	Learning Rate: 0.000108131
	LOSS [training: 0.07060736730424842 | validation: 0.07562222175835734]
	TIME [epoch: 8.33 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07217913030182083		[learning rate: 0.00010788]
	Learning Rate: 0.000107876
	LOSS [training: 0.07217913030182083 | validation: 0.07474029317108255]
	TIME [epoch: 8.35 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07218200048659913		[learning rate: 0.00010762]
	Learning Rate: 0.000107621
	LOSS [training: 0.07218200048659913 | validation: 0.06993453978457556]
	TIME [epoch: 8.34 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07650452656867643		[learning rate: 0.00010737]
	Learning Rate: 0.000107367
	LOSS [training: 0.07650452656867643 | validation: 0.0793562926300853]
	TIME [epoch: 8.33 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07662347174183377		[learning rate: 0.00010711]
	Learning Rate: 0.000107114
	LOSS [training: 0.07662347174183377 | validation: 0.06804454848531666]
	TIME [epoch: 8.33 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07221779286364029		[learning rate: 0.00010686]
	Learning Rate: 0.000106861
	LOSS [training: 0.07221779286364029 | validation: 0.0602877469271704]
	TIME [epoch: 8.35 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07561807141057578		[learning rate: 0.00010661]
	Learning Rate: 0.000106609
	LOSS [training: 0.07561807141057578 | validation: 0.07070840284961458]
	TIME [epoch: 8.34 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07217926988742258		[learning rate: 0.00010636]
	Learning Rate: 0.000106358
	LOSS [training: 0.07217926988742258 | validation: 0.059911017825197616]
	TIME [epoch: 8.32 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06749021846460215		[learning rate: 0.00010611]
	Learning Rate: 0.000106107
	LOSS [training: 0.06749021846460215 | validation: 0.07524966302282315]
	TIME [epoch: 8.34 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07383419769798136		[learning rate: 0.00010586]
	Learning Rate: 0.000105857
	LOSS [training: 0.07383419769798136 | validation: 0.0782454428110595]
	TIME [epoch: 8.36 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06709874971932717		[learning rate: 0.00010561]
	Learning Rate: 0.000105607
	LOSS [training: 0.06709874971932717 | validation: 0.07074048124073096]
	TIME [epoch: 8.34 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06841617582293155		[learning rate: 0.00010536]
	Learning Rate: 0.000105358
	LOSS [training: 0.06841617582293155 | validation: 0.06484758350106182]
	TIME [epoch: 8.33 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07136521957891666		[learning rate: 0.00010511]
	Learning Rate: 0.000105109
	LOSS [training: 0.07136521957891666 | validation: 0.06571431667603742]
	TIME [epoch: 8.33 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07461628026137804		[learning rate: 0.00010486]
	Learning Rate: 0.000104861
	LOSS [training: 0.07461628026137804 | validation: 0.06488103400077563]
	TIME [epoch: 8.35 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07138261776839291		[learning rate: 0.00010461]
	Learning Rate: 0.000104614
	LOSS [training: 0.07138261776839291 | validation: 0.07751315712806033]
	TIME [epoch: 8.34 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07529246921610583		[learning rate: 0.00010437]
	Learning Rate: 0.000104367
	LOSS [training: 0.07529246921610583 | validation: 0.06458970763857765]
	TIME [epoch: 8.33 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07915134951164565		[learning rate: 0.00010412]
	Learning Rate: 0.000104121
	LOSS [training: 0.07915134951164565 | validation: 0.059443663151104394]
	TIME [epoch: 8.33 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07175131866117723		[learning rate: 0.00010388]
	Learning Rate: 0.000103875
	LOSS [training: 0.07175131866117723 | validation: 0.06264520748990264]
	TIME [epoch: 8.35 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06997159782643943		[learning rate: 0.00010363]
	Learning Rate: 0.00010363
	LOSS [training: 0.06997159782643943 | validation: 0.05665687496363584]
	TIME [epoch: 8.33 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06961597176891805		[learning rate: 0.00010339]
	Learning Rate: 0.000103386
	LOSS [training: 0.06961597176891805 | validation: 0.06300292595632126]
	TIME [epoch: 8.34 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07094216286057356		[learning rate: 0.00010314]
	Learning Rate: 0.000103142
	LOSS [training: 0.07094216286057356 | validation: 0.06540488311488508]
	TIME [epoch: 8.34 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07309738858559774		[learning rate: 0.0001029]
	Learning Rate: 0.000102899
	LOSS [training: 0.07309738858559774 | validation: 0.0666275321141466]
	TIME [epoch: 8.35 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0704873739225738		[learning rate: 0.00010266]
	Learning Rate: 0.000102656
	LOSS [training: 0.0704873739225738 | validation: 0.06252600558249335]
	TIME [epoch: 8.33 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07407393463506712		[learning rate: 0.00010241]
	Learning Rate: 0.000102414
	LOSS [training: 0.07407393463506712 | validation: 0.07057635568903026]
	TIME [epoch: 8.33 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07085196426476623		[learning rate: 0.00010217]
	Learning Rate: 0.000102172
	LOSS [training: 0.07085196426476623 | validation: 0.07106109195358773]
	TIME [epoch: 8.33 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07183124049168899		[learning rate: 0.00010193]
	Learning Rate: 0.000101931
	LOSS [training: 0.07183124049168899 | validation: 0.06349873122896608]
	TIME [epoch: 8.36 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08038864699546744		[learning rate: 0.00010169]
	Learning Rate: 0.000101691
	LOSS [training: 0.08038864699546744 | validation: 0.06555631479902851]
	TIME [epoch: 8.32 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07466101735693395		[learning rate: 0.00010145]
	Learning Rate: 0.000101451
	LOSS [training: 0.07466101735693395 | validation: 0.066986604416986]
	TIME [epoch: 8.33 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07317657900605354		[learning rate: 0.00010121]
	Learning Rate: 0.000101212
	LOSS [training: 0.07317657900605354 | validation: 0.07061975066693987]
	TIME [epoch: 8.33 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0731818206301869		[learning rate: 0.00010097]
	Learning Rate: 0.000100973
	LOSS [training: 0.0731818206301869 | validation: 0.06156910205197289]
	TIME [epoch: 8.36 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0708347320101089		[learning rate: 0.00010073]
	Learning Rate: 0.000100735
	LOSS [training: 0.0708347320101089 | validation: 0.06336282380359344]
	TIME [epoch: 8.33 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07421208293504747		[learning rate: 0.0001005]
	Learning Rate: 0.000100497
	LOSS [training: 0.07421208293504747 | validation: 0.06170622893494549]
	TIME [epoch: 8.34 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07823019965400566		[learning rate: 0.00010026]
	Learning Rate: 0.00010026
	LOSS [training: 0.07823019965400566 | validation: 0.06803464762842962]
	TIME [epoch: 8.32 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07469599567297767		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.07469599567297767 | validation: 0.07243623375408861]
	TIME [epoch: 8.36 sec]
Finished training in 16854.038 seconds.
