Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r5', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3402281132

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/10] avg loss: 11.123463796460362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.123463796460362 | validation: 9.269316394693135]
	TIME [epoch: 79.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/10] avg loss: 10.394948076278048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.394948076278048 | validation: 8.841992296099134]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/10] avg loss: 9.441493064816731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.441493064816731 | validation: 10.621783812426742]
	TIME [epoch: 8.54 sec]
EPOCH 4/1000:
	Training over batches...
		[batch 10/10] avg loss: 10.17191385799619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.17191385799619 | validation: 9.773053596171152]
	TIME [epoch: 8.54 sec]
EPOCH 5/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.434483288429893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.434483288429893 | validation: 7.67345124200555]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.49669664489372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.49669664489372 | validation: 8.472739435884348]
	TIME [epoch: 8.53 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.859189579132577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.859189579132577 | validation: 7.099480300682275]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.980984600945857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.980984600945857 | validation: 8.500943961463127]
	TIME [epoch: 8.53 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.771040428404379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.771040428404379 | validation: 6.880202047065542]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.845803728019081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.845803728019081 | validation: 6.185553459253173]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.82553886418868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.82553886418868 | validation: 6.372899363917496]
	TIME [epoch: 8.52 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.836717804170384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.836717804170384 | validation: 5.5897697842787775]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.079844350653671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.079844350653671 | validation: 5.814121150922838]
	TIME [epoch: 8.57 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.416719637187553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.416719637187553 | validation: 5.819229612844423]
	TIME [epoch: 8.53 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.120422716169413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.120422716169413 | validation: 6.263844598112474]
	TIME [epoch: 8.53 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.004511757639305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.004511757639305 | validation: 6.5853388869122575]
	TIME [epoch: 8.54 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.858317323485939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.858317323485939 | validation: 6.443499355213511]
	TIME [epoch: 8.54 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.594223434295874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.594223434295874 | validation: 6.488953087016142]
	TIME [epoch: 8.52 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.645798313745123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.645798313745123 | validation: 5.630787703203477]
	TIME [epoch: 8.53 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.471997599318866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.471997599318866 | validation: 5.5193589501600595]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.897406509147965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.897406509147965 | validation: 5.896931680674504]
	TIME [epoch: 8.54 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.548916724006544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.548916724006544 | validation: 5.501304389013811]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.427402349115129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.427402349115129 | validation: 6.496741608482965]
	TIME [epoch: 8.53 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.548704034161285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.548704034161285 | validation: 5.979885758723241]
	TIME [epoch: 8.54 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.333460534307764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.333460534307764 | validation: 5.675801369049985]
	TIME [epoch: 8.53 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.209597857935689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.209597857935689 | validation: 5.734625659142752]
	TIME [epoch: 8.53 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.347122033740634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.347122033740634 | validation: 5.740838194547912]
	TIME [epoch: 8.53 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.240199916852324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.240199916852324 | validation: 5.303485676456477]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_28.pth
	Model improved!!!
EPOCH 29/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.1683514930605625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1683514930605625 | validation: 5.497156459432041]
	TIME [epoch: 8.54 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.193622094992944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.193622094992944 | validation: 5.6016173697179195]
	TIME [epoch: 8.53 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.0684367661610725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0684367661610725 | validation: 5.152246589350342]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_31.pth
	Model improved!!!
EPOCH 32/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.580775290100776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.580775290100776 | validation: 5.121864403046892]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.067686708047697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.067686708047697 | validation: 5.039362801925156]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_33.pth
	Model improved!!!
EPOCH 34/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.930848344846505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.930848344846505 | validation: 5.216103987474193]
	TIME [epoch: 8.53 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.953566240076432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.953566240076432 | validation: 5.6780335346621005]
	TIME [epoch: 8.52 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.9460645793002795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9460645793002795 | validation: 5.2276153467304525]
	TIME [epoch: 8.56 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.4068505788919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4068505788919 | validation: 6.0274045559630665]
	TIME [epoch: 8.53 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.925877338012638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.925877338012638 | validation: 5.317219619099124]
	TIME [epoch: 8.53 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.868640044448455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.868640044448455 | validation: 5.331597862827852]
	TIME [epoch: 8.53 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.747715799561919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.747715799561919 | validation: 4.727244187631892]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_40.pth
	Model improved!!!
EPOCH 41/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.807147737792927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.807147737792927 | validation: 5.253058774553762]
	TIME [epoch: 8.53 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.5698331621507435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5698331621507435 | validation: 4.540517000803768]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.842823806667165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.842823806667165 | validation: 5.324652824761598]
	TIME [epoch: 8.56 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.928193776368256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.928193776368256 | validation: 5.216528124508024]
	TIME [epoch: 8.54 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.86970088005352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.86970088005352 | validation: 4.737984315079026]
	TIME [epoch: 8.53 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.430550985668108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.430550985668108 | validation: 4.48950050983003]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_46.pth
	Model improved!!!
EPOCH 47/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.386285278941923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.386285278941923 | validation: 4.473146581970481]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_47.pth
	Model improved!!!
EPOCH 48/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.291239896299778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.291239896299778 | validation: 4.409644622052897]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.202559461213495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.202559461213495 | validation: 4.719390951613896]
	TIME [epoch: 8.51 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.205985850944684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.205985850944684 | validation: 4.287033559964288]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_50.pth
	Model improved!!!
EPOCH 51/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.914362117843978		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 4.914362117843978 | validation: 4.094506423235215]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_51.pth
	Model improved!!!
EPOCH 52/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.966506129738962		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 4.966506129738962 | validation: 3.964188553473065]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_52.pth
	Model improved!!!
EPOCH 53/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.831585393569625		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 4.831585393569625 | validation: 4.1621913007524425]
	TIME [epoch: 8.51 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.784183500785408		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 4.784183500785408 | validation: 3.84902942553814]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_54.pth
	Model improved!!!
EPOCH 55/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.694607214658186		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 4.694607214658186 | validation: 3.834336408080498]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_55.pth
	Model improved!!!
EPOCH 56/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.863028607203127		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 4.863028607203127 | validation: 3.7115454995843074]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_56.pth
	Model improved!!!
EPOCH 57/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.713994909320403		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 4.713994909320403 | validation: 4.453717580210394]
	TIME [epoch: 8.51 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.726087769759134		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 4.726087769759134 | validation: 3.9910374658735135]
	TIME [epoch: 8.52 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.55149273252072		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 4.55149273252072 | validation: 3.90008702939652]
	TIME [epoch: 8.52 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.565937483463935		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 4.565937483463935 | validation: 3.515824218183114]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_60.pth
	Model improved!!!
EPOCH 61/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.4542187223925165		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 4.4542187223925165 | validation: 3.7609642177955225]
	TIME [epoch: 8.51 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.4472360394998836		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 4.4472360394998836 | validation: 3.5837735153501855]
	TIME [epoch: 8.53 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.730083353761154		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 4.730083353761154 | validation: 3.8658592616984917]
	TIME [epoch: 8.51 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.5391534741767305		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 4.5391534741767305 | validation: 3.940747207399282]
	TIME [epoch: 8.51 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.5492646073794765		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 4.5492646073794765 | validation: 3.573812515013408]
	TIME [epoch: 8.5 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.383019714551925		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 4.383019714551925 | validation: 3.3249016953819033]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_66.pth
	Model improved!!!
EPOCH 67/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.5549578250400815		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 4.5549578250400815 | validation: 3.5798049830326395]
	TIME [epoch: 8.52 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.707522862896897		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 4.707522862896897 | validation: 4.197285186533972]
	TIME [epoch: 8.5 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.4661936101218895		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 4.4661936101218895 | validation: 3.9864813137480666]
	TIME [epoch: 8.52 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.425905863480401		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 4.425905863480401 | validation: 3.361321264754858]
	TIME [epoch: 8.54 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.452129765832427		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 4.452129765832427 | validation: 3.540085183610878]
	TIME [epoch: 8.52 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.327073481784754		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 4.327073481784754 | validation: 3.6291799798930597]
	TIME [epoch: 8.51 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.272650550040445		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 4.272650550040445 | validation: 3.312791631488133]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_73.pth
	Model improved!!!
EPOCH 74/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.244013027704918		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 4.244013027704918 | validation: 3.55511700694029]
	TIME [epoch: 8.54 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.332199889638795		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 4.332199889638795 | validation: 3.638883912583446]
	TIME [epoch: 8.51 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.624934884755447		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 4.624934884755447 | validation: 3.4174989621874463]
	TIME [epoch: 8.52 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.13082376776212		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 4.13082376776212 | validation: 3.3966169577112826]
	TIME [epoch: 8.52 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.2277067016006855		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 4.2277067016006855 | validation: 3.7175782448686494]
	TIME [epoch: 8.54 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.490929823973647		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 4.490929823973647 | validation: 3.4274531374200135]
	TIME [epoch: 8.5 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.166870513114539		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 4.166870513114539 | validation: 3.5910449822101382]
	TIME [epoch: 8.51 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.192783263540799		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 4.192783263540799 | validation: 4.78939678660517]
	TIME [epoch: 8.51 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.603015388013955		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 4.603015388013955 | validation: 3.5488027060811844]
	TIME [epoch: 8.53 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.277402538267587		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 4.277402538267587 | validation: 3.388145692986559]
	TIME [epoch: 8.51 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.107943052490893		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 4.107943052490893 | validation: 3.1048614490909374]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_84.pth
	Model improved!!!
EPOCH 85/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.9108095537633716		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 3.9108095537633716 | validation: 3.000037267258713]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_85.pth
	Model improved!!!
EPOCH 86/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.6859667162195833		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 3.6859667162195833 | validation: 2.740284597774569]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_86.pth
	Model improved!!!
EPOCH 87/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.531760607499426		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 3.531760607499426 | validation: 2.9726804231092063]
	TIME [epoch: 8.53 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.3948959909421665		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 3.3948959909421665 | validation: 2.6787379290072284]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_88.pth
	Model improved!!!
EPOCH 89/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.067727839445088		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 3.067727839445088 | validation: 2.4325677715423755]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_89.pth
	Model improved!!!
EPOCH 90/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9472314506036041		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 1.9472314506036041 | validation: 2.3049634485106405]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_90.pth
	Model improved!!!
EPOCH 91/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9501570488107056		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 1.9501570488107056 | validation: 1.0091319338031055]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_91.pth
	Model improved!!!
EPOCH 92/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4583970776377422		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 1.4583970776377422 | validation: 1.3826856108857728]
	TIME [epoch: 8.52 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.5893112334972592		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 2.5893112334972592 | validation: 1.8019751557117951]
	TIME [epoch: 8.55 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3089909273601983		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 1.3089909273601983 | validation: 1.3197541741742074]
	TIME [epoch: 8.52 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4838104482055825		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 1.4838104482055825 | validation: 1.169167987350351]
	TIME [epoch: 8.51 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3044299846124237		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 1.3044299846124237 | validation: 1.2106855292904901]
	TIME [epoch: 8.53 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5146042221790892		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 1.5146042221790892 | validation: 2.2197756247643925]
	TIME [epoch: 8.53 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4998396836870171		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 1.4998396836870171 | validation: 1.2525899718367348]
	TIME [epoch: 8.52 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1791014228184307		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 1.1791014228184307 | validation: 1.2871155185505407]
	TIME [epoch: 8.52 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0838325181528419		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 1.0838325181528419 | validation: 2.058285204931848]
	TIME [epoch: 8.54 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7855382631917398		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 1.7855382631917398 | validation: 1.4222288178625693]
	TIME [epoch: 8.52 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3034235389325786		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 1.3034235389325786 | validation: 1.5860196186599882]
	TIME [epoch: 8.52 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2076291849537706		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 1.2076291849537706 | validation: 0.6457862860706607]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_103.pth
	Model improved!!!
EPOCH 104/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2719892515446247		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 1.2719892515446247 | validation: 2.076250397244853]
	TIME [epoch: 8.54 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4893291284218635		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 1.4893291284218635 | validation: 0.6389806463996516]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_105.pth
	Model improved!!!
EPOCH 106/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9999582780834997		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 0.9999582780834997 | validation: 0.878172883431122]
	TIME [epoch: 8.5 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1961586084482274		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 1.1961586084482274 | validation: 0.9191335172918433]
	TIME [epoch: 8.52 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1795771846498444		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 1.1795771846498444 | validation: 1.524187863261308]
	TIME [epoch: 8.54 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.410767228453607		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 1.410767228453607 | validation: 1.202377578299695]
	TIME [epoch: 8.52 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3880527339141167		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 1.3880527339141167 | validation: 0.5783523445618493]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_110.pth
	Model improved!!!
EPOCH 111/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0972246541387727		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 1.0972246541387727 | validation: 0.7739315490492702]
	TIME [epoch: 8.53 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.150623478853009		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 1.150623478853009 | validation: 0.9384335768065428]
	TIME [epoch: 8.53 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9566104094569472		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 0.9566104094569472 | validation: 0.8570412342604733]
	TIME [epoch: 8.52 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0070152330872595		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 1.0070152330872595 | validation: 0.5272659612905364]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_114.pth
	Model improved!!!
EPOCH 115/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2939090017332777		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 1.2939090017332777 | validation: 0.6601725865745682]
	TIME [epoch: 8.54 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0761582680499364		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 1.0761582680499364 | validation: 0.8268283309228683]
	TIME [epoch: 8.52 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8940305162950108		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 0.8940305162950108 | validation: 0.8405786530700419]
	TIME [epoch: 8.52 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9246559737410458		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 0.9246559737410458 | validation: 1.6294803347006934]
	TIME [epoch: 8.52 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5464410090748117		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 1.5464410090748117 | validation: 0.9391522346358501]
	TIME [epoch: 8.53 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7778648913071142		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 0.7778648913071142 | validation: 1.4330010811480618]
	TIME [epoch: 8.52 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0236149145099904		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 1.0236149145099904 | validation: 0.7557762011656122]
	TIME [epoch: 8.51 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0246940178726822		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 1.0246940178726822 | validation: 0.8654776340626009]
	TIME [epoch: 8.51 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9437986349905776		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 0.9437986349905776 | validation: 0.8598869925319188]
	TIME [epoch: 8.54 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8851453146820148		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 0.8851453146820148 | validation: 1.337389837434299]
	TIME [epoch: 8.52 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1522013512835643		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 1.1522013512835643 | validation: 1.932842457697868]
	TIME [epoch: 8.52 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9634268237848023		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 0.9634268237848023 | validation: 1.6741185534825869]
	TIME [epoch: 8.54 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4405661885419754		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 1.4405661885419754 | validation: 1.382487090309013]
	TIME [epoch: 8.53 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.268110539232269		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 1.268110539232269 | validation: 1.3949207003062407]
	TIME [epoch: 8.52 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2804462881067358		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 1.2804462881067358 | validation: 0.9185638930508216]
	TIME [epoch: 8.51 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8539185750515956		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 0.8539185750515956 | validation: 0.8205788750513073]
	TIME [epoch: 8.55 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9978388651391071		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 0.9978388651391071 | validation: 0.7569392739348629]
	TIME [epoch: 8.51 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7688225970168587		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 0.7688225970168587 | validation: 0.6417048714949758]
	TIME [epoch: 8.52 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9520578286221136		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 0.9520578286221136 | validation: 1.05369083422918]
	TIME [epoch: 8.53 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9556246854021879		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 0.9556246854021879 | validation: 0.7425743072270306]
	TIME [epoch: 8.53 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9701871240730918		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 0.9701871240730918 | validation: 1.0695398047533193]
	TIME [epoch: 8.52 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1240121562870313		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 1.1240121562870313 | validation: 0.7923030015034429]
	TIME [epoch: 8.51 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8920698306485869		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 0.8920698306485869 | validation: 0.9523633370249314]
	TIME [epoch: 8.54 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8611990835197464		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 0.8611990835197464 | validation: 0.9632051946572546]
	TIME [epoch: 8.52 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9221367544491749		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 0.9221367544491749 | validation: 0.5978898095205067]
	TIME [epoch: 8.51 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6938011699683674		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 0.6938011699683674 | validation: 0.9757483196574956]
	TIME [epoch: 8.54 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.903914220828851		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 0.903914220828851 | validation: 0.38247588702370583]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_141.pth
	Model improved!!!
EPOCH 142/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8043595987075391		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 0.8043595987075391 | validation: 0.5377339082839064]
	TIME [epoch: 8.51 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.651993956539709		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 0.651993956539709 | validation: 0.7998933492815019]
	TIME [epoch: 8.51 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0657751578743564		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 1.0657751578743564 | validation: 1.690866983578326]
	TIME [epoch: 8.55 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8669829419207208		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 0.8669829419207208 | validation: 0.47822945757458857]
	TIME [epoch: 8.52 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9917940909754128		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 0.9917940909754128 | validation: 0.5350722011750602]
	TIME [epoch: 8.52 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8868915002817841		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.8868915002817841 | validation: 0.7832566481243017]
	TIME [epoch: 8.52 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7749670051998125		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 0.7749670051998125 | validation: 1.4883805258169889]
	TIME [epoch: 8.55 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7638443851869681		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 0.7638443851869681 | validation: 0.4901144164199227]
	TIME [epoch: 8.52 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1067204045368317		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 1.1067204045368317 | validation: 0.9839565932560648]
	TIME [epoch: 8.52 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9407751256086165		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 0.9407751256086165 | validation: 0.6496370505318549]
	TIME [epoch: 8.53 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9814714045462785		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 0.9814714045462785 | validation: 1.6170375757522262]
	TIME [epoch: 8.53 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9818434263840448		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 0.9818434263840448 | validation: 0.6595298191099703]
	TIME [epoch: 8.52 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8346576248122682		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 0.8346576248122682 | validation: 0.39654976516865376]
	TIME [epoch: 8.52 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7797893400438094		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 0.7797893400438094 | validation: 0.8584002933706454]
	TIME [epoch: 8.53 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.787848952695124		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 0.787848952695124 | validation: 0.9368253327663689]
	TIME [epoch: 8.52 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8909229242575138		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 0.8909229242575138 | validation: 0.6575959421735629]
	TIME [epoch: 8.52 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7043461212746993		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 0.7043461212746993 | validation: 0.48745866499360846]
	TIME [epoch: 8.52 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8753690631172537		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 0.8753690631172537 | validation: 0.7131725939178641]
	TIME [epoch: 8.54 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6117010631100434		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 0.6117010631100434 | validation: 0.5760765165815491]
	TIME [epoch: 8.52 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6613743294549221		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 0.6613743294549221 | validation: 1.583096544417402]
	TIME [epoch: 8.52 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9231246171393952		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 0.9231246171393952 | validation: 0.6615309041775597]
	TIME [epoch: 8.54 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5996340229088071		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 0.5996340229088071 | validation: 0.6903428321641831]
	TIME [epoch: 8.53 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6537325882179386		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 0.6537325882179386 | validation: 0.5185325524218372]
	TIME [epoch: 8.52 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8292180632027609		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 0.8292180632027609 | validation: 0.4087489904268974]
	TIME [epoch: 8.52 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5375726599266253		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.5375726599266253 | validation: 0.9209963301563425]
	TIME [epoch: 8.53 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8268370305444345		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 0.8268370305444345 | validation: 0.43935966822168526]
	TIME [epoch: 8.51 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6997409782103933		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 0.6997409782103933 | validation: 0.666471707324883]
	TIME [epoch: 8.51 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8765987633640796		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 0.8765987633640796 | validation: 0.6309031851209826]
	TIME [epoch: 8.53 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6457933697668218		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 0.6457933697668218 | validation: 0.3540876605928476]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_170.pth
	Model improved!!!
EPOCH 171/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5917654778391281		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 0.5917654778391281 | validation: 0.4316903794537599]
	TIME [epoch: 8.51 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7768208339192224		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 0.7768208339192224 | validation: 1.3329350949800085]
	TIME [epoch: 8.51 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7555644328379788		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 0.7555644328379788 | validation: 1.247744039936609]
	TIME [epoch: 8.53 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7306511123433952		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 0.7306511123433952 | validation: 0.31132851797675176]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_174.pth
	Model improved!!!
EPOCH 175/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6412402015859391		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 0.6412402015859391 | validation: 0.4345419151036556]
	TIME [epoch: 8.51 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6806931771652907		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.6806931771652907 | validation: 0.47385143541635855]
	TIME [epoch: 8.52 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6580203377802152		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 0.6580203377802152 | validation: 1.4892832504979978]
	TIME [epoch: 8.54 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7114654999455109		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 0.7114654999455109 | validation: 0.4759045864063206]
	TIME [epoch: 8.51 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6483500839389764		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.6483500839389764 | validation: 0.6679239455821757]
	TIME [epoch: 8.51 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.708496462953919		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 0.708496462953919 | validation: 0.6092094679504004]
	TIME [epoch: 8.51 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6561806062784934		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 0.6561806062784934 | validation: 0.6193499596439493]
	TIME [epoch: 8.54 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7011029411522929		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.7011029411522929 | validation: 0.9043948968115195]
	TIME [epoch: 8.51 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5882096891898815		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 0.5882096891898815 | validation: 0.4716368650982411]
	TIME [epoch: 8.52 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.685004177983466		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 0.685004177983466 | validation: 0.9599653391653965]
	TIME [epoch: 8.54 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7830681934267201		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.7830681934267201 | validation: 0.5171929169702882]
	TIME [epoch: 8.52 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7407229539626038		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.7407229539626038 | validation: 0.5040117551529678]
	TIME [epoch: 8.51 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6489513474525495		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 0.6489513474525495 | validation: 0.43961631436680715]
	TIME [epoch: 8.51 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5585337999059878		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 0.5585337999059878 | validation: 0.4510793955879451]
	TIME [epoch: 8.54 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.607186900074203		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 0.607186900074203 | validation: 0.6468416534855139]
	TIME [epoch: 8.51 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.696773769936387		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.696773769936387 | validation: 0.40201712404638557]
	TIME [epoch: 8.51 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.600833429567892		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 0.600833429567892 | validation: 0.5497585255815117]
	TIME [epoch: 8.51 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48203001184136357		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 0.48203001184136357 | validation: 0.422427167961725]
	TIME [epoch: 8.54 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.682003427034271		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 0.682003427034271 | validation: 0.6095173173641865]
	TIME [epoch: 8.51 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8201626483268273		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.8201626483268273 | validation: 0.4659355988245869]
	TIME [epoch: 8.51 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4825969110727778		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.4825969110727778 | validation: 0.5430503206600817]
	TIME [epoch: 8.54 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5137749689993305		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.5137749689993305 | validation: 0.601438417260306]
	TIME [epoch: 8.52 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6017245728342588		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.6017245728342588 | validation: 0.40484745763553154]
	TIME [epoch: 8.51 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7237459142654428		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 0.7237459142654428 | validation: 1.7534841740482736]
	TIME [epoch: 8.52 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5884578015128769		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.5884578015128769 | validation: 0.42570220597041303]
	TIME [epoch: 8.54 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8294378471897241		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.8294378471897241 | validation: 0.7202688316096124]
	TIME [epoch: 8.51 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6552886697056591		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.6552886697056591 | validation: 0.2935685383146709]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_201.pth
	Model improved!!!
EPOCH 202/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6172747776686635		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.6172747776686635 | validation: 0.675429251185369]
	TIME [epoch: 8.53 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.530516604688404		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 0.530516604688404 | validation: 0.3411849676384886]
	TIME [epoch: 8.51 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6070867293165653		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.6070867293165653 | validation: 0.34501874771669183]
	TIME [epoch: 8.51 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5741025042387551		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.5741025042387551 | validation: 0.5331206978875505]
	TIME [epoch: 8.51 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5406457059420756		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 0.5406457059420756 | validation: 0.6549655260869981]
	TIME [epoch: 8.55 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6007409528694286		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.6007409528694286 | validation: 0.8270650380867237]
	TIME [epoch: 8.52 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6389645723269083		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.6389645723269083 | validation: 0.8886950178365072]
	TIME [epoch: 8.51 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5750436672529134		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.5750436672529134 | validation: 0.43182193806346253]
	TIME [epoch: 8.51 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49748765336887235		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.49748765336887235 | validation: 0.4749774818966117]
	TIME [epoch: 8.54 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5062395546765595		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.5062395546765595 | validation: 0.925492267491252]
	TIME [epoch: 8.51 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6345776482214689		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.6345776482214689 | validation: 0.3260379308874022]
	TIME [epoch: 8.51 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8170540733071554		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.8170540733071554 | validation: 0.3784478747416802]
	TIME [epoch: 8.54 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6059221740554434		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.6059221740554434 | validation: 0.9408268358947074]
	TIME [epoch: 8.52 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7893808637638476		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.7893808637638476 | validation: 0.9143092398988238]
	TIME [epoch: 8.51 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6750885282856597		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.6750885282856597 | validation: 0.5189799367276627]
	TIME [epoch: 8.51 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5692322210101282		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.5692322210101282 | validation: 0.46193384914482405]
	TIME [epoch: 8.54 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8368026752730222		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.8368026752730222 | validation: 0.5992231497138925]
	TIME [epoch: 8.52 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6640337115274864		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.6640337115274864 | validation: 0.995465000298597]
	TIME [epoch: 8.51 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8499402561925254		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.8499402561925254 | validation: 0.39312176826515666]
	TIME [epoch: 8.53 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.472886835653327		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.472886835653327 | validation: 0.3760886615587261]
	TIME [epoch: 8.52 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.609555132362788		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.609555132362788 | validation: 0.443168981824147]
	TIME [epoch: 8.51 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6465715923041099		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.6465715923041099 | validation: 0.547188327737351]
	TIME [epoch: 8.51 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5535142634501355		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.5535142634501355 | validation: 0.3639777422633996]
	TIME [epoch: 8.54 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5270111000851461		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.5270111000851461 | validation: 0.5393552014951328]
	TIME [epoch: 8.51 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6634684788447426		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.6634684788447426 | validation: 0.504013716266064]
	TIME [epoch: 8.51 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5655881185862652		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.5655881185862652 | validation: 0.3218886887057145]
	TIME [epoch: 8.53 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3465927581985512		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.3465927581985512 | validation: 0.5629298780813223]
	TIME [epoch: 8.52 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5498102816253796		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.5498102816253796 | validation: 0.4765563781691636]
	TIME [epoch: 8.5 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5219443544143859		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.5219443544143859 | validation: 0.3084639241947328]
	TIME [epoch: 8.51 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5411952907873283		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.5411952907873283 | validation: 0.6593856133106419]
	TIME [epoch: 8.53 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4429611017497191		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.4429611017497191 | validation: 0.3260985516372098]
	TIME [epoch: 8.52 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5098532991750098		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.5098532991750098 | validation: 0.4675481736286008]
	TIME [epoch: 8.5 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7673646396515075		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.7673646396515075 | validation: 0.34236032129809013]
	TIME [epoch: 8.52 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5423666461414767		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.5423666461414767 | validation: 0.2856059077107198]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_235.pth
	Model improved!!!
EPOCH 236/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4040384657171658		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.4040384657171658 | validation: 0.2363795325261342]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_236.pth
	Model improved!!!
EPOCH 237/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4620360033638537		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.4620360033638537 | validation: 0.3796845329960399]
	TIME [epoch: 8.51 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4503012689034659		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.4503012689034659 | validation: 0.25628892661186853]
	TIME [epoch: 8.53 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5237693240248239		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.5237693240248239 | validation: 0.48680916838916355]
	TIME [epoch: 8.51 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9332121538324831		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.9332121538324831 | validation: 0.4814393849921845]
	TIME [epoch: 8.5 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4434930189950827		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.4434930189950827 | validation: 0.5386446253566731]
	TIME [epoch: 8.51 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47165239641721846		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.47165239641721846 | validation: 0.3984672475361594]
	TIME [epoch: 8.53 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4914365879960846		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.4914365879960846 | validation: 0.32209661759191427]
	TIME [epoch: 8.51 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5546308097185733		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.5546308097185733 | validation: 0.34020352824220845]
	TIME [epoch: 8.5 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5763968091726404		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.5763968091726404 | validation: 0.3325039713207708]
	TIME [epoch: 8.5 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3493493147616463		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.3493493147616463 | validation: 0.4027047283502584]
	TIME [epoch: 8.53 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6036894157776652		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.6036894157776652 | validation: 1.2101120377019583]
	TIME [epoch: 8.5 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7490746699341209		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.7490746699341209 | validation: 0.3621203380812589]
	TIME [epoch: 8.5 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4890628859519535		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.4890628859519535 | validation: 0.654745673386806]
	TIME [epoch: 8.52 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3837974628131371		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.3837974628131371 | validation: 0.5850784470934489]
	TIME [epoch: 8.52 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4739188934004478		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.4739188934004478 | validation: 0.2742215820333997]
	TIME [epoch: 8.5 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3866093983637696		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.3866093983637696 | validation: 0.351047345267943]
	TIME [epoch: 8.51 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46064436411883375		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.46064436411883375 | validation: 0.4437876392433459]
	TIME [epoch: 8.53 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5905941515533566		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.5905941515533566 | validation: 0.6313427419612926]
	TIME [epoch: 8.5 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4922166680114991		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.4922166680114991 | validation: 0.43924373512356124]
	TIME [epoch: 8.5 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44459875833861257		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.44459875833861257 | validation: 0.4788554763304874]
	TIME [epoch: 8.52 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5057784021803775		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.5057784021803775 | validation: 0.3387820830187945]
	TIME [epoch: 8.51 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4901458822744552		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.4901458822744552 | validation: 0.40034258220482216]
	TIME [epoch: 8.5 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5287714194627334		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.5287714194627334 | validation: 0.8228568377277106]
	TIME [epoch: 8.5 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5949140044175831		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.5949140044175831 | validation: 0.5279147768131656]
	TIME [epoch: 8.53 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6015312317470033		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.6015312317470033 | validation: 0.3657229986426135]
	TIME [epoch: 8.51 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9510322123395227		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.9510322123395227 | validation: 0.276360263780001]
	TIME [epoch: 8.5 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5337453855673622		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.5337453855673622 | validation: 0.4235339980326146]
	TIME [epoch: 8.51 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6088913119112649		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.6088913119112649 | validation: 0.2917743947950089]
	TIME [epoch: 8.53 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9186122117858566		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.9186122117858566 | validation: 0.7709913965671202]
	TIME [epoch: 8.5 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.686286816005792		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.686286816005792 | validation: 0.6619272848844889]
	TIME [epoch: 8.5 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6238562141954557		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.6238562141954557 | validation: 0.675386273499738]
	TIME [epoch: 8.53 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6162264053818802		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.6162264053818802 | validation: 0.3355938946449536]
	TIME [epoch: 8.51 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5057658890417605		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.5057658890417605 | validation: 0.4681051852766823]
	TIME [epoch: 8.5 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6276811671534068		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.6276811671534068 | validation: 0.28841428215517917]
	TIME [epoch: 8.5 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4159869647118648		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.4159869647118648 | validation: 0.748207429709485]
	TIME [epoch: 8.52 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6580264460994942		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.6580264460994942 | validation: 0.5629135887048002]
	TIME [epoch: 8.5 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5349804989388475		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.5349804989388475 | validation: 0.4121899567457278]
	TIME [epoch: 8.5 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5271595447012739		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.5271595447012739 | validation: 0.5452991952049427]
	TIME [epoch: 8.52 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.505281878427509		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.505281878427509 | validation: 0.43010179449624797]
	TIME [epoch: 8.5 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5563994476785461		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.5563994476785461 | validation: 0.41413620359103775]
	TIME [epoch: 8.5 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5670194822725052		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.5670194822725052 | validation: 0.33122988786084884]
	TIME [epoch: 8.49 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4476550855371383		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.4476550855371383 | validation: 0.3370696413596054]
	TIME [epoch: 8.53 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4737688071639295		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.4737688071639295 | validation: 0.359765813279371]
	TIME [epoch: 8.5 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38868824553761433		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.38868824553761433 | validation: 0.4916708469948875]
	TIME [epoch: 8.5 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.432513277558164		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.432513277558164 | validation: 0.2796172678426909]
	TIME [epoch: 8.52 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37455727989902965		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.37455727989902965 | validation: 0.5770555040007935]
	TIME [epoch: 8.5 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7899022494410168		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.7899022494410168 | validation: 0.6674641905152411]
	TIME [epoch: 8.5 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6207271909541066		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.6207271909541066 | validation: 0.416071648813384]
	TIME [epoch: 8.5 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5661948299645333		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.5661948299645333 | validation: 0.5732722216805511]
	TIME [epoch: 8.52 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4513839013666187		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.4513839013666187 | validation: 0.32408999708383573]
	TIME [epoch: 8.5 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4370795473961354		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.4370795473961354 | validation: 0.41497396445447654]
	TIME [epoch: 8.5 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41930249957462234		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.41930249957462234 | validation: 0.6576384168096566]
	TIME [epoch: 8.51 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4508323681919738		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.4508323681919738 | validation: 0.36292867740793044]
	TIME [epoch: 8.51 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3971945200897723		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.3971945200897723 | validation: 0.33566185725219577]
	TIME [epoch: 8.5 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4505835630736671		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.4505835630736671 | validation: 0.4457731762814695]
	TIME [epoch: 8.5 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4349185773027383		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.4349185773027383 | validation: 0.7795840162974047]
	TIME [epoch: 8.52 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4168080713879732		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.4168080713879732 | validation: 0.2598293154826416]
	TIME [epoch: 8.5 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5653074634432147		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.5653074634432147 | validation: 0.33665414014729084]
	TIME [epoch: 8.5 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.661199853640176		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.661199853640176 | validation: 0.35803171884677704]
	TIME [epoch: 8.51 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4438825681822639		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.4438825681822639 | validation: 0.4370413282239852]
	TIME [epoch: 8.51 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4007451882912047		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.4007451882912047 | validation: 0.3441378642403729]
	TIME [epoch: 8.5 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38176800979607994		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.38176800979607994 | validation: 0.21901668436649385]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_298.pth
	Model improved!!!
EPOCH 299/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31894964230594147		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.31894964230594147 | validation: 0.3534447136711654]
	TIME [epoch: 8.53 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38623929023783793		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.38623929023783793 | validation: 0.4421497644158409]
	TIME [epoch: 8.51 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4004635923616509		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.4004635923616509 | validation: 0.8983572857478662]
	TIME [epoch: 8.5 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49711876891706963		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.49711876891706963 | validation: 0.25883305151389885]
	TIME [epoch: 8.5 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6974012690343687		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.6974012690343687 | validation: 0.5388228051651784]
	TIME [epoch: 8.53 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4310009873153926		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.4310009873153926 | validation: 0.3946057236492411]
	TIME [epoch: 8.51 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8379748125090577		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.8379748125090577 | validation: 0.7456487669839023]
	TIME [epoch: 8.5 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45404856651213593		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.45404856651213593 | validation: 0.5364375280472602]
	TIME [epoch: 8.52 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3864227906598801		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.3864227906598801 | validation: 0.3846876811109271]
	TIME [epoch: 8.52 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3990727793024237		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.3990727793024237 | validation: 0.8190338718375679]
	TIME [epoch: 8.5 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5676859952221595		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.5676859952221595 | validation: 0.47467268494509945]
	TIME [epoch: 8.51 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4997362594030326		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.4997362594030326 | validation: 0.2626841835186739]
	TIME [epoch: 8.52 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44276626703984656		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.44276626703984656 | validation: 0.1899004627735889]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_311.pth
	Model improved!!!
EPOCH 312/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4262125562600471		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.4262125562600471 | validation: 0.25334386642469153]
	TIME [epoch: 8.5 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3860524971537059		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.3860524971537059 | validation: 0.3236837835985875]
	TIME [epoch: 8.51 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33701607863650884		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.33701607863650884 | validation: 0.22162712656132758]
	TIME [epoch: 8.54 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7146712148426848		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.7146712148426848 | validation: 0.29460430107592794]
	TIME [epoch: 8.5 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4320446022034397		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.4320446022034397 | validation: 0.42114578937444413]
	TIME [epoch: 8.5 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3184584024293732		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.3184584024293732 | validation: 0.46945427979563814]
	TIME [epoch: 8.5 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5118308296528629		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.5118308296528629 | validation: 0.5243125621680169]
	TIME [epoch: 8.54 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3455811457669503		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.3455811457669503 | validation: 0.22539606162095513]
	TIME [epoch: 8.51 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3400571520764814		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.3400571520764814 | validation: 0.2943192408394243]
	TIME [epoch: 8.5 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41055014600117545		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.41055014600117545 | validation: 0.6828717378430142]
	TIME [epoch: 8.53 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4844090618487458		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.4844090618487458 | validation: 0.29625618002283055]
	TIME [epoch: 8.51 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4544111805443789		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.4544111805443789 | validation: 0.24244758230030797]
	TIME [epoch: 8.49 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33422884881628656		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.33422884881628656 | validation: 0.8978908166497004]
	TIME [epoch: 8.5 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5620905145494135		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.5620905145494135 | validation: 0.713873198764098]
	TIME [epoch: 8.52 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47581780020735265		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.47581780020735265 | validation: 0.663935443431116]
	TIME [epoch: 8.5 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4272637010365963		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.4272637010365963 | validation: 0.3679266395416647]
	TIME [epoch: 8.5 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3662130254138956		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.3662130254138956 | validation: 0.282181650535288]
	TIME [epoch: 8.5 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3842803377683014		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.3842803377683014 | validation: 0.3329877360216026]
	TIME [epoch: 8.53 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3568878476228201		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.3568878476228201 | validation: 0.33455044135131307]
	TIME [epoch: 8.5 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5020845235362917		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.5020845235362917 | validation: 0.41980585336771953]
	TIME [epoch: 8.5 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4400626509416886		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.4400626509416886 | validation: 0.5614976932349292]
	TIME [epoch: 8.52 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3275390884086331		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.3275390884086331 | validation: 0.3918427975661967]
	TIME [epoch: 8.5 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3751080061313148		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.3751080061313148 | validation: 0.2872255331362538]
	TIME [epoch: 8.5 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37257970427576126		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.37257970427576126 | validation: 0.33592352237457357]
	TIME [epoch: 8.5 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43476454507567014		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.43476454507567014 | validation: 0.22922795986585465]
	TIME [epoch: 8.52 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36758983134391016		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.36758983134391016 | validation: 0.21729445532485853]
	TIME [epoch: 8.5 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2949716719104391		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.2949716719104391 | validation: 0.6194480498331316]
	TIME [epoch: 8.5 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3938074376308216		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.3938074376308216 | validation: 0.4615822198786211]
	TIME [epoch: 8.51 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6410149278272004		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.6410149278272004 | validation: 1.7609241896951513]
	TIME [epoch: 8.51 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.602882888224079		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.602882888224079 | validation: 0.30688941274483994]
	TIME [epoch: 8.5 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33758707714658576		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.33758707714658576 | validation: 0.198902698676936]
	TIME [epoch: 8.5 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3375801641444887		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.3375801641444887 | validation: 0.2913196568775509]
	TIME [epoch: 8.52 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3941868894481226		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.3941868894481226 | validation: 0.3221176916643055]
	TIME [epoch: 8.5 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4230935189674911		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.4230935189674911 | validation: 0.3528913121811442]
	TIME [epoch: 8.52 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3917623375523477		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.3917623375523477 | validation: 0.4299220609725891]
	TIME [epoch: 8.51 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4187357713008427		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.4187357713008427 | validation: 0.7957746115498974]
	TIME [epoch: 8.51 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40452571895673917		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.40452571895673917 | validation: 0.1969150807074927]
	TIME [epoch: 8.5 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2745493408969823		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.2745493408969823 | validation: 0.3610904750498478]
	TIME [epoch: 8.5 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42145737778445336		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.42145737778445336 | validation: 0.27705889034531395]
	TIME [epoch: 8.52 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4307057773366723		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.4307057773366723 | validation: 0.7185596195926518]
	TIME [epoch: 8.5 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8120621939806449		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.8120621939806449 | validation: 0.31009471866058336]
	TIME [epoch: 8.5 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3216265839885261		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.3216265839885261 | validation: 0.23192292711875373]
	TIME [epoch: 8.5 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37476285234893103		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.37476285234893103 | validation: 0.4247295238002386]
	TIME [epoch: 8.52 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32473599952706034		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.32473599952706034 | validation: 0.20740872243385877]
	TIME [epoch: 8.5 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3451996112442187		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.3451996112442187 | validation: 0.21168563566440773]
	TIME [epoch: 8.49 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2931612358753966		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.2931612358753966 | validation: 0.3479566309161517]
	TIME [epoch: 8.52 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46850074442611567		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.46850074442611567 | validation: 0.37282697230521655]
	TIME [epoch: 8.5 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4047959082968354		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.4047959082968354 | validation: 0.7366525975623226]
	TIME [epoch: 8.5 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45639079868171956		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.45639079868171956 | validation: 0.18253023743815136]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_360.pth
	Model improved!!!
EPOCH 361/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3458093080237446		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.3458093080237446 | validation: 0.2177720572441993]
	TIME [epoch: 8.53 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29979659316646123		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.29979659316646123 | validation: 0.15994899531754705]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_362.pth
	Model improved!!!
EPOCH 363/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35827892219966817		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.35827892219966817 | validation: 0.24746059081855376]
	TIME [epoch: 8.5 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3458111003125555		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.3458111003125555 | validation: 0.208437319750638]
	TIME [epoch: 8.51 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3070086513538214		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.3070086513538214 | validation: 0.5867870043218244]
	TIME [epoch: 8.52 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4147230108496546		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.4147230108496546 | validation: 0.27106428347432276]
	TIME [epoch: 8.5 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3061990782491469		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.3061990782491469 | validation: 0.24708387260693165]
	TIME [epoch: 8.51 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36980304679407366		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.36980304679407366 | validation: 0.3255438519349757]
	TIME [epoch: 8.52 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2980341966283623		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.2980341966283623 | validation: 0.28337330898001223]
	TIME [epoch: 8.53 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27080713333717144		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.27080713333717144 | validation: 0.15011146590838728]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_370.pth
	Model improved!!!
EPOCH 371/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2764996003424864		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.2764996003424864 | validation: 0.22555541868742995]
	TIME [epoch: 8.5 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3568503232579197		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.3568503232579197 | validation: 0.35201720729755026]
	TIME [epoch: 8.52 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27654659523243613		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.27654659523243613 | validation: 0.26994255654639887]
	TIME [epoch: 8.51 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36557068765805123		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.36557068765805123 | validation: 0.45300030705147176]
	TIME [epoch: 8.5 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30573646792759457		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.30573646792759457 | validation: 0.2909463257577442]
	TIME [epoch: 8.5 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3048567294187263		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.3048567294187263 | validation: 0.35734400783068476]
	TIME [epoch: 8.52 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4679362304782383		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.4679362304782383 | validation: 0.3297133169177813]
	TIME [epoch: 8.52 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39451990804833		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.39451990804833 | validation: 0.36290035904212736]
	TIME [epoch: 8.5 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31655250598872653		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.31655250598872653 | validation: 0.3002924233096399]
	TIME [epoch: 8.5 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2639229152449559		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.2639229152449559 | validation: 0.15921456311881393]
	TIME [epoch: 8.53 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2866411465293769		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.2866411465293769 | validation: 0.2474005762403269]
	TIME [epoch: 8.5 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3348573068293071		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.3348573068293071 | validation: 0.1735954223604072]
	TIME [epoch: 8.51 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.295381216802678		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.295381216802678 | validation: 0.26561473022622123]
	TIME [epoch: 8.52 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23347797757659267		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.23347797757659267 | validation: 0.1431481373940351]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_384.pth
	Model improved!!!
EPOCH 385/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27293802474963424		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.27293802474963424 | validation: 0.3135157406031226]
	TIME [epoch: 8.5 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39240346015210886		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.39240346015210886 | validation: 0.2549041330707873]
	TIME [epoch: 8.5 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3212785709792524		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.3212785709792524 | validation: 0.319646836110156]
	TIME [epoch: 8.52 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41840534849951166		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.41840534849951166 | validation: 0.46557943948035607]
	TIME [epoch: 8.51 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31106483464913337		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.31106483464913337 | validation: 0.3220505716244344]
	TIME [epoch: 8.5 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25657478165751896		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.25657478165751896 | validation: 0.31639706412082896]
	TIME [epoch: 8.5 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3356336253849671		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.3356336253849671 | validation: 0.23575980042493677]
	TIME [epoch: 8.53 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.416114102622205		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.416114102622205 | validation: 0.18721331732619872]
	TIME [epoch: 8.49 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.321446038395251		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.321446038395251 | validation: 0.16775198470187241]
	TIME [epoch: 8.49 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4447893966822492		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.4447893966822492 | validation: 0.33641080961046854]
	TIME [epoch: 8.52 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.359374270058575		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.359374270058575 | validation: 0.326665254055734]
	TIME [epoch: 8.51 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3053229027210683		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.3053229027210683 | validation: 0.32715147600331995]
	TIME [epoch: 8.5 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3020399011061715		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.3020399011061715 | validation: 0.2647728887755506]
	TIME [epoch: 8.5 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3064539950581068		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.3064539950581068 | validation: 0.2288378816365293]
	TIME [epoch: 8.52 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.278217222070859		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.278217222070859 | validation: 0.4169964729713914]
	TIME [epoch: 8.5 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3083700598731882		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.3083700598731882 | validation: 0.22305204608852158]
	TIME [epoch: 8.51 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37041661468304865		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.37041661468304865 | validation: 0.2586708803507481]
	TIME [epoch: 8.53 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3278593419757785		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.3278593419757785 | validation: 0.27665098804036536]
	TIME [epoch: 8.5 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3453534447515204		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.3453534447515204 | validation: 0.2536266343813835]
	TIME [epoch: 8.49 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2904649940364523		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.2904649940364523 | validation: 0.2519620486741744]
	TIME [epoch: 8.51 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3228897374711119		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.3228897374711119 | validation: 0.5195471290925652]
	TIME [epoch: 8.52 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33138614759129925		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.33138614759129925 | validation: 0.48359768577436646]
	TIME [epoch: 8.49 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3923682693852881		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.3923682693852881 | validation: 0.17880057495516335]
	TIME [epoch: 8.5 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35366400878379567		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.35366400878379567 | validation: 0.14017947347868157]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_408.pth
	Model improved!!!
EPOCH 409/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24108138584106847		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.24108138584106847 | validation: 0.19128042589668373]
	TIME [epoch: 8.51 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25950368776238236		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.25950368776238236 | validation: 0.15821397843089585]
	TIME [epoch: 8.49 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2634915083340118		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.2634915083340118 | validation: 0.2285558236058684]
	TIME [epoch: 8.51 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2251924909037059		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.2251924909037059 | validation: 0.24117641683074822]
	TIME [epoch: 8.52 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2873069896488223		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.2873069896488223 | validation: 0.3570196083068782]
	TIME [epoch: 8.52 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3369919246205067		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.3369919246205067 | validation: 0.21998393025483404]
	TIME [epoch: 8.49 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2648843123807484		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.2648843123807484 | validation: 0.1632788243873428]
	TIME [epoch: 8.49 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2793657805626073		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.2793657805626073 | validation: 0.18885618688566674]
	TIME [epoch: 8.52 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22984913911049532		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.22984913911049532 | validation: 0.21562752708935803]
	TIME [epoch: 8.51 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32693143312312023		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.32693143312312023 | validation: 0.196737209923922]
	TIME [epoch: 8.49 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24665694309581165		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.24665694309581165 | validation: 0.3736229567386883]
	TIME [epoch: 8.5 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32586864119148623		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.32586864119148623 | validation: 0.43151928721074156]
	TIME [epoch: 8.52 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4340571247546441		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.4340571247546441 | validation: 0.2203293977437557]
	TIME [epoch: 8.5 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26983082822737353		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.26983082822737353 | validation: 0.25711162824106576]
	TIME [epoch: 8.5 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26825913706555116		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.26825913706555116 | validation: 0.18136821008812054]
	TIME [epoch: 8.52 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24973824897947533		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.24973824897947533 | validation: 0.2871413485121855]
	TIME [epoch: 8.5 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35909192966083847		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.35909192966083847 | validation: 0.2124690626229495]
	TIME [epoch: 8.5 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2751755721915105		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.2751755721915105 | validation: 0.5132030814115801]
	TIME [epoch: 8.5 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3695265107563097		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.3695265107563097 | validation: 0.25461228023030336]
	TIME [epoch: 8.54 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3148708731692406		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.3148708731692406 | validation: 0.4106831744558481]
	TIME [epoch: 8.51 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28771308734195533		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.28771308734195533 | validation: 0.30271916788768227]
	TIME [epoch: 8.5 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26093266476373833		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.26093266476373833 | validation: 0.16060580725864065]
	TIME [epoch: 8.51 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2563286844575122		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.2563286844575122 | validation: 0.25594251593260964]
	TIME [epoch: 8.51 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2535811904709727		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.2535811904709727 | validation: 0.27830191184838887]
	TIME [epoch: 8.5 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42039717863972054		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.42039717863972054 | validation: 0.19877139966799112]
	TIME [epoch: 8.49 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2390572491955716		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.2390572491955716 | validation: 0.3120704469496791]
	TIME [epoch: 8.52 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22928202485684346		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.22928202485684346 | validation: 0.2665547956502742]
	TIME [epoch: 8.5 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3500864684979288		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.3500864684979288 | validation: 0.36008289835590024]
	TIME [epoch: 8.49 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33678060147740513		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.33678060147740513 | validation: 0.2919693707504524]
	TIME [epoch: 8.51 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2710934701114117		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.2710934701114117 | validation: 0.257548189060391]
	TIME [epoch: 8.52 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29717501118794276		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.29717501118794276 | validation: 0.19659566339295317]
	TIME [epoch: 8.49 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24315314266167945		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.24315314266167945 | validation: 0.345598629922382]
	TIME [epoch: 8.5 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24340304980656632		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.24340304980656632 | validation: 0.20092157152225226]
	TIME [epoch: 8.52 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24074959206893226		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.24074959206893226 | validation: 0.2549650988834795]
	TIME [epoch: 8.49 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.323303773862893		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.323303773862893 | validation: 0.35631019863338453]
	TIME [epoch: 8.5 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.302308999459055		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.302308999459055 | validation: 0.16734091225000172]
	TIME [epoch: 8.5 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26160462244667065		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.26160462244667065 | validation: 0.30322572060113434]
	TIME [epoch: 8.51 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22795318062608963		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.22795318062608963 | validation: 0.1893134594747224]
	TIME [epoch: 8.49 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2665942075674673		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.2665942075674673 | validation: 0.39747666084233346]
	TIME [epoch: 8.49 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3059974247431966		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.3059974247431966 | validation: 0.29657122528373847]
	TIME [epoch: 8.51 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2226786289545238		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.2226786289545238 | validation: 0.21367327980467163]
	TIME [epoch: 8.5 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25344232289011476		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.25344232289011476 | validation: 0.26127429635250876]
	TIME [epoch: 8.5 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3493761854889674		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.3493761854889674 | validation: 0.45370527609540723]
	TIME [epoch: 8.49 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2936915455359497		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.2936915455359497 | validation: 0.3295093144056214]
	TIME [epoch: 8.53 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25547426778226423		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.25547426778226423 | validation: 0.1571811426590427]
	TIME [epoch: 8.49 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22901730872040216		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.22901730872040216 | validation: 0.18154342182146363]
	TIME [epoch: 8.49 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23835236666532983		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.23835236666532983 | validation: 0.2394860015076855]
	TIME [epoch: 8.5 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26782549843152964		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.26782549843152964 | validation: 0.42199247276138485]
	TIME [epoch: 8.51 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2680344320514206		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.2680344320514206 | validation: 0.4023990340846143]
	TIME [epoch: 8.49 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22204628291680956		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.22204628291680956 | validation: 0.1484682911284162]
	TIME [epoch: 8.49 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2163253087656937		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.2163253087656937 | validation: 0.336051658041489]
	TIME [epoch: 8.52 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31534899742273537		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.31534899742273537 | validation: 0.3037721055585821]
	TIME [epoch: 8.5 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24586252087969718		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.24586252087969718 | validation: 0.2904031382565796]
	TIME [epoch: 8.49 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26367924611001836		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.26367924611001836 | validation: 0.18009926793705944]
	TIME [epoch: 8.49 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2115369509806843		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.2115369509806843 | validation: 0.2548017949349082]
	TIME [epoch: 8.52 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24998978863541138		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.24998978863541138 | validation: 0.5580089172990179]
	TIME [epoch: 8.5 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2803436287043478		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.2803436287043478 | validation: 0.222454345935578]
	TIME [epoch: 8.49 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21215217337456793		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.21215217337456793 | validation: 0.37059653509666646]
	TIME [epoch: 8.53 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24143487515745427		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.24143487515745427 | validation: 0.17364303081161683]
	TIME [epoch: 8.51 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24646865169484028		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.24646865169484028 | validation: 0.259443640078327]
	TIME [epoch: 8.5 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2623605159172335		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.2623605159172335 | validation: 0.34631596383945445]
	TIME [epoch: 8.5 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2535713854499446		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.2535713854499446 | validation: 0.19166073607814138]
	TIME [epoch: 8.53 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2430829537642114		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.2430829537642114 | validation: 0.2170554859899274]
	TIME [epoch: 8.49 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19498783730696218		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.19498783730696218 | validation: 0.18310904003578077]
	TIME [epoch: 8.49 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2513455271113606		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.2513455271113606 | validation: 0.6175341995815941]
	TIME [epoch: 8.52 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3126384687959077		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.3126384687959077 | validation: 0.19822880602447526]
	TIME [epoch: 8.51 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2854094930276266		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.2854094930276266 | validation: 0.14180992548565546]
	TIME [epoch: 8.5 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2382869546696766		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.2382869546696766 | validation: 0.23635114485302877]
	TIME [epoch: 8.5 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2712545921688658		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.2712545921688658 | validation: 0.2574886005687996]
	TIME [epoch: 8.52 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29511464159432765		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.29511464159432765 | validation: 0.25046103588431023]
	TIME [epoch: 8.51 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23400215286961495		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.23400215286961495 | validation: 0.20148451134720752]
	TIME [epoch: 8.51 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21111540271680213		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.21111540271680213 | validation: 0.20466381891137142]
	TIME [epoch: 8.53 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21011299140227918		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.21011299140227918 | validation: 0.20758377083090096]
	TIME [epoch: 8.53 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23630304620046907		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.23630304620046907 | validation: 0.29506617663951784]
	TIME [epoch: 8.51 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2426955108299691		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.2426955108299691 | validation: 0.22033784508368248]
	TIME [epoch: 8.5 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2620746530917438		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.2620746530917438 | validation: 0.2307596070473662]
	TIME [epoch: 8.52 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.258183812136306		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.258183812136306 | validation: 0.21277864774305869]
	TIME [epoch: 8.5 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26204520240432566		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.26204520240432566 | validation: 0.2544219064260124]
	TIME [epoch: 8.5 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28899296673623		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.28899296673623 | validation: 0.1862894492818387]
	TIME [epoch: 8.51 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2513905744617075		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.2513905744617075 | validation: 0.20216619516103457]
	TIME [epoch: 8.52 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3064383159409678		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.3064383159409678 | validation: 0.2205934809975935]
	TIME [epoch: 8.51 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19859407379530059		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.19859407379530059 | validation: 0.29360613680949843]
	TIME [epoch: 8.5 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21460347783652342		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.21460347783652342 | validation: 0.13454986636821337]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_491.pth
	Model improved!!!
EPOCH 492/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2829625953073927		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.2829625953073927 | validation: 0.14697802529772042]
	TIME [epoch: 8.52 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21275596514180473		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.21275596514180473 | validation: 0.18855590676705752]
	TIME [epoch: 8.51 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22039366848306643		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.22039366848306643 | validation: 0.19855384697461553]
	TIME [epoch: 8.51 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24125132080446368		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.24125132080446368 | validation: 0.20370055864298325]
	TIME [epoch: 8.51 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23899738373780632		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.23899738373780632 | validation: 0.19726653268452887]
	TIME [epoch: 8.49 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2618046900867195		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.2618046900867195 | validation: 0.14151016953716142]
	TIME [epoch: 8.5 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26721242692926234		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.26721242692926234 | validation: 0.17676910638882004]
	TIME [epoch: 8.51 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23223499270425788		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.23223499270425788 | validation: 0.19384765500783757]
	TIME [epoch: 8.52 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1185699371720168		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 1.1185699371720168 | validation: 0.798333637194963]
	TIME [epoch: 8.5 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3746980483040053		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.3746980483040053 | validation: 0.17918066735493937]
	TIME [epoch: 8.5 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3133349133094593		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.3133349133094593 | validation: 0.3496623587581956]
	TIME [epoch: 8.5 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2901516241724439		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.2901516241724439 | validation: 0.19578781284066088]
	TIME [epoch: 8.51 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2355788142022861		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.2355788142022861 | validation: 0.19221793448703692]
	TIME [epoch: 8.49 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19274552371814285		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.19274552371814285 | validation: 0.12681651539400177]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_505.pth
	Model improved!!!
EPOCH 506/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2218806069078408		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.2218806069078408 | validation: 0.15375431613354024]
	TIME [epoch: 8.53 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2119004906499291		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.2119004906499291 | validation: 0.1321059405263198]
	TIME [epoch: 8.5 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21149591079623078		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.21149591079623078 | validation: 0.2707793874678499]
	TIME [epoch: 8.5 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24851164083143878		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.24851164083143878 | validation: 0.21257069881305762]
	TIME [epoch: 8.5 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23366962439445232		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.23366962439445232 | validation: 0.6051083132684785]
	TIME [epoch: 8.53 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3658627456944505		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.3658627456944505 | validation: 0.24797526985511403]
	TIME [epoch: 8.5 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22070669745140875		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.22070669745140875 | validation: 0.21075073608040035]
	TIME [epoch: 8.5 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2901201042824596		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.2901201042824596 | validation: 0.21039585048500176]
	TIME [epoch: 8.51 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2905145149414931		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.2905145149414931 | validation: 0.1715617343420633]
	TIME [epoch: 8.63 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20462960089777313		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.20462960089777313 | validation: 0.2649939837437129]
	TIME [epoch: 8.51 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2121170658361872		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.2121170658361872 | validation: 0.17229875728325617]
	TIME [epoch: 8.51 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18392543013147752		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.18392543013147752 | validation: 0.14089454988663783]
	TIME [epoch: 8.54 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17614162187181026		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.17614162187181026 | validation: 0.21253065749259897]
	TIME [epoch: 8.52 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21687884095159626		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.21687884095159626 | validation: 0.15893073082667494]
	TIME [epoch: 8.51 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1973775458797441		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.1973775458797441 | validation: 0.12774852945131113]
	TIME [epoch: 8.51 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2335278098214814		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.2335278098214814 | validation: 0.16144283049642372]
	TIME [epoch: 8.54 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20584362465602846		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.20584362465602846 | validation: 0.2158255312455711]
	TIME [epoch: 8.51 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24894574877097497		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.24894574877097497 | validation: 0.19217049971259714]
	TIME [epoch: 8.52 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2812155380013007		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.2812155380013007 | validation: 0.1318491846155234]
	TIME [epoch: 8.53 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20672468123213078		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.20672468123213078 | validation: 0.18673605206870378]
	TIME [epoch: 8.53 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2614474767838427		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.2614474767838427 | validation: 0.15004226453926783]
	TIME [epoch: 8.52 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29005798431288266		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.29005798431288266 | validation: 0.22637675352359904]
	TIME [epoch: 8.51 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19649782197660207		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.19649782197660207 | validation: 0.24926570582786256]
	TIME [epoch: 8.54 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.216421716199465		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.216421716199465 | validation: 0.27695724091309515]
	TIME [epoch: 8.52 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19307830158489392		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.19307830158489392 | validation: 0.1269016824813624]
	TIME [epoch: 8.55 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18896060802879475		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.18896060802879475 | validation: 0.17667387593295253]
	TIME [epoch: 8.53 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18839502633094285		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.18839502633094285 | validation: 0.15332703176312373]
	TIME [epoch: 8.53 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17586410527565607		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.17586410527565607 | validation: 0.12529264764155928]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_533.pth
	Model improved!!!
EPOCH 534/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.203883421798913		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.203883421798913 | validation: 0.12532671192734024]
	TIME [epoch: 8.52 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2005867256125588		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.2005867256125588 | validation: 0.1661302064523919]
	TIME [epoch: 8.54 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22011964395645958		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.22011964395645958 | validation: 0.21724791619272288]
	TIME [epoch: 8.51 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2676923726848274		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.2676923726848274 | validation: 0.2328137029906121]
	TIME [epoch: 8.51 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2054563068600927		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.2054563068600927 | validation: 0.15098068812641086]
	TIME [epoch: 8.52 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17054438923943682		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.17054438923943682 | validation: 0.168242180111909]
	TIME [epoch: 8.53 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2274139201608909		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.2274139201608909 | validation: 0.19258852806385357]
	TIME [epoch: 8.52 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17160355440227568		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.17160355440227568 | validation: 0.12972677201870675]
	TIME [epoch: 8.51 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18441841389672237		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.18441841389672237 | validation: 0.28930076395599813]
	TIME [epoch: 8.52 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25271677921164104		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.25271677921164104 | validation: 0.24066937130668647]
	TIME [epoch: 8.53 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.183319991956633		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.183319991956633 | validation: 0.1535170194647898]
	TIME [epoch: 8.51 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.231339490408129		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.231339490408129 | validation: 0.19768426879550705]
	TIME [epoch: 8.52 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2506442686411224		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.2506442686411224 | validation: 0.24435377614095705]
	TIME [epoch: 8.54 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22341785391673805		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.22341785391673805 | validation: 0.1384042088734434]
	TIME [epoch: 8.52 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19543760127877702		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.19543760127877702 | validation: 0.19980002584561954]
	TIME [epoch: 8.52 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17608623150746233		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.17608623150746233 | validation: 0.22451527307064]
	TIME [epoch: 8.52 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22661953998593193		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.22661953998593193 | validation: 0.14494061050477275]
	TIME [epoch: 8.55 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19769311437951603		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.19769311437951603 | validation: 0.22150529105977257]
	TIME [epoch: 8.51 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20877225061701857		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.20877225061701857 | validation: 0.2638461052342409]
	TIME [epoch: 8.52 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26642566062467865		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.26642566062467865 | validation: 0.16732647740923937]
	TIME [epoch: 8.53 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19646364494164642		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.19646364494164642 | validation: 0.17433741435431965]
	TIME [epoch: 8.52 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19950900545530942		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.19950900545530942 | validation: 0.4606261539957268]
	TIME [epoch: 8.51 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25333366498928955		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.25333366498928955 | validation: 0.11074998487021201]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_556.pth
	Model improved!!!
EPOCH 557/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19018179960773565		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.19018179960773565 | validation: 0.1352968247365585]
	TIME [epoch: 8.53 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2091652045373432		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.2091652045373432 | validation: 0.14305371809468503]
	TIME [epoch: 8.51 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20403104798967261		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.20403104798967261 | validation: 0.17741742455108733]
	TIME [epoch: 8.51 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1756385476146713		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.1756385476146713 | validation: 0.15483437540614264]
	TIME [epoch: 8.52 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21279061749907946		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.21279061749907946 | validation: 0.1929638444637388]
	TIME [epoch: 8.53 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.271039694928652		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.271039694928652 | validation: 0.21819522351200027]
	TIME [epoch: 8.51 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18811746178804295		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.18811746178804295 | validation: 0.14000182001081213]
	TIME [epoch: 8.51 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19470715341927775		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.19470715341927775 | validation: 0.2501355701209232]
	TIME [epoch: 8.53 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1655341681521907		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.1655341681521907 | validation: 0.21176513965394694]
	TIME [epoch: 8.53 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19551342794649412		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.19551342794649412 | validation: 0.1867883059248257]
	TIME [epoch: 8.52 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1944405183090833		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.1944405183090833 | validation: 0.4955084007971923]
	TIME [epoch: 8.52 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29911106514706765		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.29911106514706765 | validation: 0.1490361500227516]
	TIME [epoch: 8.54 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16413530359133371		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.16413530359133371 | validation: 0.14319235647078118]
	TIME [epoch: 8.52 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1615285681741627		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.1615285681741627 | validation: 0.2506449002639563]
	TIME [epoch: 8.51 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19793925791153374		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.19793925791153374 | validation: 0.19285280418432804]
	TIME [epoch: 8.51 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19960720269688803		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.19960720269688803 | validation: 0.14499396383461421]
	TIME [epoch: 8.54 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17899664099600546		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.17899664099600546 | validation: 0.22513683318092276]
	TIME [epoch: 8.51 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18059072170941076		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.18059072170941076 | validation: 0.138430077595523]
	TIME [epoch: 8.51 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14305994572722805		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.14305994572722805 | validation: 0.14933284490754098]
	TIME [epoch: 8.54 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15989515288492362		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.15989515288492362 | validation: 0.1503688640274629]
	TIME [epoch: 8.5 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1511718374248449		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.1511718374248449 | validation: 0.14317552061726369]
	TIME [epoch: 8.5 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1851789345566319		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.1851789345566319 | validation: 0.17933229111847104]
	TIME [epoch: 8.52 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16886653000904356		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.16886653000904356 | validation: 0.1512808287349758]
	TIME [epoch: 8.55 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17541458923697165		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.17541458923697165 | validation: 0.2514650913336804]
	TIME [epoch: 8.52 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19724297191389886		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.19724297191389886 | validation: 0.15823829213371648]
	TIME [epoch: 8.52 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1880850362180705		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.1880850362180705 | validation: 0.13942685322565396]
	TIME [epoch: 8.54 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29928015305354727		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.29928015305354727 | validation: 0.21654287790672036]
	TIME [epoch: 8.53 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2555661793766388		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.2555661793766388 | validation: 0.1871746382580576]
	TIME [epoch: 8.51 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21508979752106763		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.21508979752106763 | validation: 0.2690731816255683]
	TIME [epoch: 8.51 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17932606329935025		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.17932606329935025 | validation: 0.20496278564914916]
	TIME [epoch: 8.53 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.210642275251158		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.210642275251158 | validation: 0.19231014515330802]
	TIME [epoch: 8.52 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20398665280882916		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.20398665280882916 | validation: 0.2049829553673579]
	TIME [epoch: 8.52 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16002734794917303		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.16002734794917303 | validation: 0.14204067357716177]
	TIME [epoch: 8.53 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17359223909318727		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.17359223909318727 | validation: 0.15670254840152376]
	TIME [epoch: 8.53 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2265080032077343		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.2265080032077343 | validation: 0.11710062870700859]
	TIME [epoch: 8.51 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16583268841063678		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.16583268841063678 | validation: 0.13055036691467023]
	TIME [epoch: 8.52 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20129861306204155		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.20129861306204155 | validation: 0.20931003556019695]
	TIME [epoch: 8.55 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1970824321578683		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.1970824321578683 | validation: 0.16726198249940788]
	TIME [epoch: 8.52 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18428449186198528		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.18428449186198528 | validation: 0.1677420972893518]
	TIME [epoch: 8.52 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16224565271907482		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.16224565271907482 | validation: 0.2062826920322144]
	TIME [epoch: 8.53 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19761193910505614		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.19761193910505614 | validation: 0.18867094989556382]
	TIME [epoch: 8.53 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19524452792880503		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.19524452792880503 | validation: 0.19172525765042997]
	TIME [epoch: 8.52 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21085429291920182		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.21085429291920182 | validation: 0.21145152737586015]
	TIME [epoch: 8.52 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2057988502451895		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.2057988502451895 | validation: 0.1295209065593166]
	TIME [epoch: 8.54 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2143400460796959		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.2143400460796959 | validation: 0.13092354776565654]
	TIME [epoch: 8.52 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13916320002549726		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.13916320002549726 | validation: 0.1177419855821133]
	TIME [epoch: 8.52 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1483393299263302		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.1483393299263302 | validation: 0.19214212708555128]
	TIME [epoch: 8.53 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17859789961364164		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.17859789961364164 | validation: 0.35527721949025926]
	TIME [epoch: 8.54 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19992702973225757		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.19992702973225757 | validation: 0.18765570097750123]
	TIME [epoch: 8.52 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23321264819488072		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.23321264819488072 | validation: 0.20314806133857777]
	TIME [epoch: 8.52 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18747084419203658		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.18747084419203658 | validation: 0.18834998316682033]
	TIME [epoch: 8.54 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2287547969576011		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.2287547969576011 | validation: 0.2916761244124857]
	TIME [epoch: 8.52 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20873850873938954		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.20873850873938954 | validation: 0.13542047938915494]
	TIME [epoch: 8.51 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1610706437033363		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.1610706437033363 | validation: 0.17865244440639094]
	TIME [epoch: 8.52 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17754220867165638		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.17754220867165638 | validation: 0.12940418673658727]
	TIME [epoch: 8.53 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15519560203278088		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.15519560203278088 | validation: 0.29634102248287275]
	TIME [epoch: 8.51 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21843432284259684		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.21843432284259684 | validation: 0.1381887728401236]
	TIME [epoch: 8.51 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16350057405294166		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.16350057405294166 | validation: 0.17247980505366395]
	TIME [epoch: 8.53 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15908885758254904		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.15908885758254904 | validation: 0.17047323587290628]
	TIME [epoch: 8.52 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19538650873064134		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.19538650873064134 | validation: 0.15575705281682728]
	TIME [epoch: 8.52 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20599627511185728		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.20599627511185728 | validation: 0.18208413443697755]
	TIME [epoch: 8.51 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1646151839272856		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.1646151839272856 | validation: 0.15347789070076362]
	TIME [epoch: 8.54 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16957364582308804		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.16957364582308804 | validation: 0.18729266526609228]
	TIME [epoch: 8.52 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21485778430558283		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.21485778430558283 | validation: 0.15918454076565808]
	TIME [epoch: 8.52 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19765725883385485		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.19765725883385485 | validation: 0.2711419349219527]
	TIME [epoch: 8.52 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20185622074770243		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.20185622074770243 | validation: 0.19730297964284665]
	TIME [epoch: 8.54 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16825452257946985		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.16825452257946985 | validation: 0.14611482190401726]
	TIME [epoch: 8.52 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1536447799652763		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.1536447799652763 | validation: 0.13772510784755468]
	TIME [epoch: 8.52 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14134383946524756		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.14134383946524756 | validation: 0.18232569253965025]
	TIME [epoch: 8.54 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2165064737671547		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.2165064737671547 | validation: 0.15972182804822338]
	TIME [epoch: 8.52 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15030023684544785		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.15030023684544785 | validation: 0.122806840447792]
	TIME [epoch: 8.53 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17573429212469294		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.17573429212469294 | validation: 0.12994697676977912]
	TIME [epoch: 8.52 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17498901555037233		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.17498901555037233 | validation: 0.15687520362208443]
	TIME [epoch: 8.55 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19366183581799987		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.19366183581799987 | validation: 0.23421600860270259]
	TIME [epoch: 8.52 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17718939413026652		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.17718939413026652 | validation: 0.11937801561554447]
	TIME [epoch: 8.52 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1661444593203404		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.1661444593203404 | validation: 0.1202252042437844]
	TIME [epoch: 8.54 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14153021273066663		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.14153021273066663 | validation: 0.1348118772708729]
	TIME [epoch: 8.52 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15158324072039703		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.15158324072039703 | validation: 0.09815769137921626]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_634.pth
	Model improved!!!
EPOCH 635/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16576808570155271		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.16576808570155271 | validation: 0.2620536352538219]
	TIME [epoch: 8.52 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16774009149394936		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.16774009149394936 | validation: 0.1274938652603776]
	TIME [epoch: 8.55 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15212509247443112		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.15212509247443112 | validation: 0.13250120625422063]
	TIME [epoch: 8.51 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1643302568839054		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.1643302568839054 | validation: 0.1631823439100728]
	TIME [epoch: 8.51 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20319888028891175		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.20319888028891175 | validation: 0.1727018489504541]
	TIME [epoch: 8.52 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19019257267915127		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.19019257267915127 | validation: 0.1642889179554905]
	TIME [epoch: 8.53 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22422013207512217		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.22422013207512217 | validation: 0.1491079114640535]
	TIME [epoch: 8.52 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19332983976039772		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.19332983976039772 | validation: 0.1562196943073303]
	TIME [epoch: 8.52 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2033970571569038		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.2033970571569038 | validation: 0.1473056966738361]
	TIME [epoch: 8.54 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15216581826974923		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.15216581826974923 | validation: 0.14853930489255174]
	TIME [epoch: 8.52 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15739286832864266		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.15739286832864266 | validation: 0.14014999287939078]
	TIME [epoch: 8.52 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15577229359457986		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.15577229359457986 | validation: 0.13849553862021438]
	TIME [epoch: 8.52 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1660973427360775		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.1660973427360775 | validation: 0.26669190908771023]
	TIME [epoch: 8.54 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15896702906174134		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.15896702906174134 | validation: 0.13996339949733122]
	TIME [epoch: 8.52 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15173576343024658		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.15173576343024658 | validation: 0.12739489463883288]
	TIME [epoch: 8.52 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21531811530192874		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.21531811530192874 | validation: 0.17077445772112493]
	TIME [epoch: 8.54 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16320396419744737		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.16320396419744737 | validation: 0.1896905708320092]
	TIME [epoch: 8.52 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1544276101663987		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.1544276101663987 | validation: 0.14644394535806182]
	TIME [epoch: 8.51 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15036393633748596		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.15036393633748596 | validation: 0.11858106275155228]
	TIME [epoch: 8.52 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1572902751382162		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.1572902751382162 | validation: 0.1447658884264666]
	TIME [epoch: 8.54 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1559555721254234		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.1559555721254234 | validation: 0.12776697690785183]
	TIME [epoch: 8.51 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18370216876291692		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.18370216876291692 | validation: 0.13165618191383638]
	TIME [epoch: 8.51 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15872078660880895		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.15872078660880895 | validation: 0.18560038753378122]
	TIME [epoch: 8.52 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17900918453886377		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.17900918453886377 | validation: 0.16348322960912948]
	TIME [epoch: 8.54 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15824210999621585		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.15824210999621585 | validation: 0.14479322545810708]
	TIME [epoch: 8.51 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14656186541148283		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.14656186541148283 | validation: 0.17576139429746962]
	TIME [epoch: 8.52 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17164195664495158		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.17164195664495158 | validation: 0.17096400937288403]
	TIME [epoch: 8.53 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16042599130513233		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.16042599130513233 | validation: 0.14186766959883684]
	TIME [epoch: 8.52 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14599990663590273		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.14599990663590273 | validation: 0.11198294682729466]
	TIME [epoch: 8.51 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.185340543415145		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.185340543415145 | validation: 0.22770654173160587]
	TIME [epoch: 8.51 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19158814520717915		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.19158814520717915 | validation: 0.13901405579105292]
	TIME [epoch: 8.54 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17617554610729086		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.17617554610729086 | validation: 0.11583949376596411]
	TIME [epoch: 8.52 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1624025959468869		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.1624025959468869 | validation: 0.24736120894457903]
	TIME [epoch: 8.51 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17914774736983058		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.17914774736983058 | validation: 0.15799054879255536]
	TIME [epoch: 8.54 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16508625632224033		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.16508625632224033 | validation: 0.12340172365524399]
	TIME [epoch: 8.52 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15852566475887575		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.15852566475887575 | validation: 0.15510420163175442]
	TIME [epoch: 8.52 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18680994514092608		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.18680994514092608 | validation: 0.18777193072831905]
	TIME [epoch: 8.52 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16909749656170203		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.16909749656170203 | validation: 0.11982464976785208]
	TIME [epoch: 8.54 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1416853561125228		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.1416853561125228 | validation: 0.1739512218757523]
	TIME [epoch: 8.51 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16346365154333675		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.16346365154333675 | validation: 0.17156959965758037]
	TIME [epoch: 8.52 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17199437233707382		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.17199437233707382 | validation: 0.1577374007982713]
	TIME [epoch: 8.53 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17697140766713243		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.17697140766713243 | validation: 0.2228774449650352]
	TIME [epoch: 8.53 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2141039435053525		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.2141039435053525 | validation: 0.16417702369537962]
	TIME [epoch: 8.51 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18225709633169068		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.18225709633169068 | validation: 0.14381681666697416]
	TIME [epoch: 8.52 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19900581778114973		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.19900581778114973 | validation: 0.16507139298825468]
	TIME [epoch: 8.54 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1681080208708398		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.1681080208708398 | validation: 0.14188776408240888]
	TIME [epoch: 8.52 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1459478071588547		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.1459478071588547 | validation: 0.11877388124270707]
	TIME [epoch: 8.52 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16914746389885715		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.16914746389885715 | validation: 0.12463038903253204]
	TIME [epoch: 8.53 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14472001498056983		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.14472001498056983 | validation: 0.1556923723200713]
	TIME [epoch: 8.53 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16024511876382225		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.16024511876382225 | validation: 0.1351326765969573]
	TIME [epoch: 8.51 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14464222218336664		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.14464222218336664 | validation: 0.1329556866235195]
	TIME [epoch: 8.52 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1394814819437006		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.1394814819437006 | validation: 0.14056590451383982]
	TIME [epoch: 8.53 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1774254337042854		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.1774254337042854 | validation: 0.12715282566706254]
	TIME [epoch: 8.52 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15568709194430946		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.15568709194430946 | validation: 0.13479898661513745]
	TIME [epoch: 8.51 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14618461518918266		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.14618461518918266 | validation: 0.13405029938282723]
	TIME [epoch: 8.53 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1563669622670253		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.1563669622670253 | validation: 0.1273383953792929]
	TIME [epoch: 8.52 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1380651975143108		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.1380651975143108 | validation: 0.13039451930098345]
	TIME [epoch: 8.51 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1374375170882252		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.1374375170882252 | validation: 0.26735661520979787]
	TIME [epoch: 8.51 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20440764889908172		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.20440764889908172 | validation: 0.12235928592476504]
	TIME [epoch: 8.54 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15249137699763263		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.15249137699763263 | validation: 0.1294393352304068]
	TIME [epoch: 8.52 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13532671785509132		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.13532671785509132 | validation: 0.13207163278027823]
	TIME [epoch: 8.51 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1436575619153638		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.1436575619153638 | validation: 0.1613039731254451]
	TIME [epoch: 8.52 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1437414745930814		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.1437414745930814 | validation: 0.1358570656192689]
	TIME [epoch: 8.54 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.144363086567929		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.144363086567929 | validation: 0.12187213856319012]
	TIME [epoch: 8.52 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17066787448127366		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.17066787448127366 | validation: 0.12340517512427121]
	TIME [epoch: 8.52 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12390803404203588		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.12390803404203588 | validation: 0.11204436440940416]
	TIME [epoch: 8.54 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13575591885769983		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.13575591885769983 | validation: 0.17327902078150295]
	TIME [epoch: 8.52 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15053836734680712		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.15053836734680712 | validation: 0.12831521766529008]
	TIME [epoch: 8.52 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13517566680780457		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.13517566680780457 | validation: 0.1383352046115434]
	TIME [epoch: 8.52 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14019581214053062		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.14019581214053062 | validation: 0.11483779766575]
	TIME [epoch: 8.54 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14287309591494107		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.14287309591494107 | validation: 0.12229375196592343]
	TIME [epoch: 8.52 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1404248507742934		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.1404248507742934 | validation: 0.2070625443522111]
	TIME [epoch: 8.52 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15409957699640098		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.15409957699640098 | validation: 0.12221917327729778]
	TIME [epoch: 8.54 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13794627342176402		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.13794627342176402 | validation: 0.11747493945653631]
	TIME [epoch: 8.53 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15323193982963032		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.15323193982963032 | validation: 0.14741341514280376]
	TIME [epoch: 8.52 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1717174700717709		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.1717174700717709 | validation: 0.12224204361266632]
	TIME [epoch: 8.52 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13827599394117313		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.13827599394117313 | validation: 0.10557431865251934]
	TIME [epoch: 8.55 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13653280196764217		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.13653280196764217 | validation: 0.15453713657355428]
	TIME [epoch: 8.52 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13153755001657091		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.13153755001657091 | validation: 0.14600159730568268]
	TIME [epoch: 8.52 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13261918052361818		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.13261918052361818 | validation: 0.11605824048491509]
	TIME [epoch: 8.54 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1379721226519089		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.1379721226519089 | validation: 0.11105828943440975]
	TIME [epoch: 8.52 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13575158417645908		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.13575158417645908 | validation: 0.12125884711003047]
	TIME [epoch: 8.52 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14928294618742508		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.14928294618742508 | validation: 0.17197718140542717]
	TIME [epoch: 8.53 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1622054103101402		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.1622054103101402 | validation: 0.11766194244149092]
	TIME [epoch: 8.55 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14142921551927445		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.14142921551927445 | validation: 0.15784047161077644]
	TIME [epoch: 8.52 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16369593787980855		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.16369593787980855 | validation: 0.12575276958530104]
	TIME [epoch: 8.53 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14958082333873787		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.14958082333873787 | validation: 0.14509200954392074]
	TIME [epoch: 8.54 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16305728466569508		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.16305728466569508 | validation: 0.13217949302794452]
	TIME [epoch: 8.54 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17085090453473994		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.17085090453473994 | validation: 0.14852038436452758]
	TIME [epoch: 8.52 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14858959528950014		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.14858959528950014 | validation: 0.09145116949179485]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_724.pth
	Model improved!!!
EPOCH 725/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.135095658163044		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.135095658163044 | validation: 0.14385483194426973]
	TIME [epoch: 8.55 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16679371461574904		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.16679371461574904 | validation: 0.1405696950548783]
	TIME [epoch: 8.51 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1434806460381343		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.1434806460381343 | validation: 0.11087653369220855]
	TIME [epoch: 8.52 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15535449703938867		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.15535449703938867 | validation: 0.12285506615978709]
	TIME [epoch: 8.52 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13720644745385024		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.13720644745385024 | validation: 0.11350342618970298]
	TIME [epoch: 8.54 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12985783111199906		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.12985783111199906 | validation: 0.11359381262373217]
	TIME [epoch: 8.51 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12845636109488512		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.12845636109488512 | validation: 0.11645838305792616]
	TIME [epoch: 8.52 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14497056232990674		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.14497056232990674 | validation: 0.12502377606398007]
	TIME [epoch: 8.52 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1390315955267894		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.1390315955267894 | validation: 0.119388223287441]
	TIME [epoch: 8.54 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14347052300623783		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.14347052300623783 | validation: 0.14161233870357975]
	TIME [epoch: 8.52 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13313343670964772		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.13313343670964772 | validation: 0.11916375299010028]
	TIME [epoch: 8.52 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18680455784726932		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.18680455784726932 | validation: 0.1428597438171776]
	TIME [epoch: 8.54 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14946842943706323		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.14946842943706323 | validation: 0.1461347088311904]
	TIME [epoch: 8.52 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16352415802932224		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.16352415802932224 | validation: 0.13444559544456533]
	TIME [epoch: 8.52 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.183142963045352		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.183142963045352 | validation: 0.21003453410418935]
	TIME [epoch: 8.52 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16397868410931146		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.16397868410931146 | validation: 0.1663392315935626]
	TIME [epoch: 8.54 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17795343373052122		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.17795343373052122 | validation: 0.11045085893183862]
	TIME [epoch: 8.52 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15979600312511177		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.15979600312511177 | validation: 0.12819085612601186]
	TIME [epoch: 8.52 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15183401672605837		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.15183401672605837 | validation: 0.12877616457230626]
	TIME [epoch: 8.54 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1571226511265369		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.1571226511265369 | validation: 0.15814520046202873]
	TIME [epoch: 8.52 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15145024319895453		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.15145024319895453 | validation: 0.14486588374874648]
	TIME [epoch: 8.51 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16809029923828483		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.16809029923828483 | validation: 0.1421975780302454]
	TIME [epoch: 8.52 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15144284100275407		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.15144284100275407 | validation: 0.23895878301565215]
	TIME [epoch: 8.54 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1670454282087738		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.1670454282087738 | validation: 0.11842505052683003]
	TIME [epoch: 8.52 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13999787498136582		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.13999787498136582 | validation: 0.11826793589262426]
	TIME [epoch: 8.51 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13762332413510675		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.13762332413510675 | validation: 0.25274475286257725]
	TIME [epoch: 8.53 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1829126871277298		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.1829126871277298 | validation: 0.11705439601872913]
	TIME [epoch: 8.52 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16248549065836645		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.16248549065836645 | validation: 0.1277983683608144]
	TIME [epoch: 8.51 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14170860800509935		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.14170860800509935 | validation: 0.1751019457959918]
	TIME [epoch: 8.51 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1615825620051558		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.1615825620051558 | validation: 0.2051991321150213]
	TIME [epoch: 8.54 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14240738254890944		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.14240738254890944 | validation: 0.10740219162980152]
	TIME [epoch: 8.51 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11603363875018817		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.11603363875018817 | validation: 0.10551087315101793]
	TIME [epoch: 8.51 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1461951128487859		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.1461951128487859 | validation: 0.17055683206115527]
	TIME [epoch: 8.53 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20052111514919785		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.20052111514919785 | validation: 0.12943578167235956]
	TIME [epoch: 8.52 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12128517917041912		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.12128517917041912 | validation: 0.129021721386098]
	TIME [epoch: 8.51 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14558295663656712		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.14558295663656712 | validation: 0.13272548633454764]
	TIME [epoch: 8.51 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1432052472600991		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.1432052472600991 | validation: 0.11012311491037818]
	TIME [epoch: 8.53 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14178837858307974		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.14178837858307974 | validation: 0.10475697432131564]
	TIME [epoch: 8.51 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1448911542979017		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.1448911542979017 | validation: 0.10817947067053521]
	TIME [epoch: 8.51 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12870137762866035		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.12870137762866035 | validation: 0.11694069288556702]
	TIME [epoch: 8.53 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21147422033771374		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.21147422033771374 | validation: 0.1301097866790495]
	TIME [epoch: 8.52 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.363430041616292		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.363430041616292 | validation: 1.1475892256781681]
	TIME [epoch: 8.51 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9811627311719316		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.9811627311719316 | validation: 0.32134980783669664]
	TIME [epoch: 8.51 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23592266016150903		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.23592266016150903 | validation: 0.31641079407307077]
	TIME [epoch: 8.53 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1816943626030572		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.1816943626030572 | validation: 0.1251427197726772]
	TIME [epoch: 8.52 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21328364178609638		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.21328364178609638 | validation: 0.1501168175569077]
	TIME [epoch: 8.51 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15448246253079562		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.15448246253079562 | validation: 0.12025655263327928]
	TIME [epoch: 8.53 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.131143331015111		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.131143331015111 | validation: 0.1690604469966997]
	TIME [epoch: 8.53 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1302973214996837		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.1302973214996837 | validation: 0.12473054501314665]
	TIME [epoch: 8.51 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12420719421852655		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.12420719421852655 | validation: 0.121869738596256]
	TIME [epoch: 8.52 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12392192828890305		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.12392192828890305 | validation: 0.13673968822562257]
	TIME [epoch: 8.54 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1286785903397949		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.1286785903397949 | validation: 0.12004003830796925]
	TIME [epoch: 8.52 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13531960383017655		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.13531960383017655 | validation: 0.16389756923531448]
	TIME [epoch: 8.51 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1551336165609626		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.1551336165609626 | validation: 0.21049622572508486]
	TIME [epoch: 8.51 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.167594759986987		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.167594759986987 | validation: 0.12101271453398176]
	TIME [epoch: 8.54 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1694938039615706		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.1694938039615706 | validation: 0.13529493776959328]
	TIME [epoch: 8.51 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14970522431964076		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.14970522431964076 | validation: 0.1361836482509309]
	TIME [epoch: 8.51 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15627621923708723		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.15627621923708723 | validation: 0.15005791903712523]
	TIME [epoch: 8.53 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14471699266563542		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.14471699266563542 | validation: 0.14575721256295893]
	TIME [epoch: 8.52 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13601989677690465		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.13601989677690465 | validation: 0.11807282173344082]
	TIME [epoch: 8.51 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14303631873389655		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.14303631873389655 | validation: 0.12549462837954728]
	TIME [epoch: 8.51 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1412597699291475		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.1412597699291475 | validation: 0.14482314109005173]
	TIME [epoch: 8.53 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14912412722825927		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.14912412722825927 | validation: 0.12004480508361529]
	TIME [epoch: 8.51 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12536742873437243		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.12536742873437243 | validation: 0.11575636078004481]
	TIME [epoch: 8.51 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12677388857174113		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.12677388857174113 | validation: 0.10239011280772513]
	TIME [epoch: 8.53 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12980633418443852		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.12980633418443852 | validation: 0.13022242032827022]
	TIME [epoch: 8.51 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13201950070751614		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.13201950070751614 | validation: 0.12633004047419422]
	TIME [epoch: 8.51 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13428674110361055		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.13428674110361055 | validation: 0.10350555198428006]
	TIME [epoch: 8.51 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13213027498380775		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.13213027498380775 | validation: 0.11891738197211474]
	TIME [epoch: 8.53 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13321186523399448		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.13321186523399448 | validation: 0.10918666890248932]
	TIME [epoch: 8.52 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1327956994827228		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.1327956994827228 | validation: 0.1339859828655498]
	TIME [epoch: 8.51 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1515488940174545		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.1515488940174545 | validation: 0.10224264550374276]
	TIME [epoch: 8.51 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13110480024025553		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.13110480024025553 | validation: 0.12307369875426694]
	TIME [epoch: 8.53 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13448614811359116		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.13448614811359116 | validation: 0.13221330934733588]
	TIME [epoch: 8.5 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15995143942439233		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.15995143942439233 | validation: 0.10968996693617455]
	TIME [epoch: 8.51 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12796476574766896		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.12796476574766896 | validation: 0.11975974093367225]
	TIME [epoch: 8.53 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12045796923233443		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.12045796923233443 | validation: 0.10591503461820226]
	TIME [epoch: 8.51 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12575914650991887		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.12575914650991887 | validation: 0.11928289950546321]
	TIME [epoch: 8.5 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13344210243453003		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.13344210243453003 | validation: 0.1134709619261047]
	TIME [epoch: 8.51 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13201621488784404		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.13201621488784404 | validation: 0.13718851633749857]
	TIME [epoch: 8.53 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13983720479183645		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.13983720479183645 | validation: 0.15417196515221296]
	TIME [epoch: 8.51 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14032011162999056		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.14032011162999056 | validation: 0.1279831726598583]
	TIME [epoch: 8.51 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1381167423265848		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.1381167423265848 | validation: 0.1506717283827489]
	TIME [epoch: 8.52 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13694086122134638		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.13694086122134638 | validation: 0.1049434646880803]
	TIME [epoch: 8.52 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12623549527760308		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.12623549527760308 | validation: 0.10747251869403825]
	TIME [epoch: 8.51 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11691820114162803		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.11691820114162803 | validation: 0.13030257046266636]
	TIME [epoch: 8.51 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11847500934393947		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.11847500934393947 | validation: 0.10220812711684935]
	TIME [epoch: 8.54 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.126194858059328		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.126194858059328 | validation: 0.11323847944917481]
	TIME [epoch: 8.51 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14030720012551698		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.14030720012551698 | validation: 0.10071242240377454]
	TIME [epoch: 8.51 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1302596349148694		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.1302596349148694 | validation: 0.1231019741361284]
	TIME [epoch: 8.52 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1263595490959594		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.1263595490959594 | validation: 0.11304652564788631]
	TIME [epoch: 8.52 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11458431811381435		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.11458431811381435 | validation: 0.09705950522665946]
	TIME [epoch: 8.51 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12081185848233958		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.12081185848233958 | validation: 0.0959289355317372]
	TIME [epoch: 8.51 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12385909509577608		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.12385909509577608 | validation: 0.11410338419197463]
	TIME [epoch: 8.54 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12136990592886969		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.12136990592886969 | validation: 0.1292606594598254]
	TIME [epoch: 8.51 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20775348206012545		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.20775348206012545 | validation: 0.12839046586976896]
	TIME [epoch: 8.51 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12459609611431004		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.12459609611431004 | validation: 0.1714827144683723]
	TIME [epoch: 8.53 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14464042669288552		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.14464042669288552 | validation: 0.1140908337271311]
	TIME [epoch: 8.53 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11957269275176612		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.11957269275176612 | validation: 0.1206103890670003]
	TIME [epoch: 8.51 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12165607648553256		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.12165607648553256 | validation: 0.13302077833968612]
	TIME [epoch: 8.51 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13492896456951908		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.13492896456951908 | validation: 0.12624396765755233]
	TIME [epoch: 8.53 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1329885141597441		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.1329885141597441 | validation: 0.12293795986430142]
	TIME [epoch: 8.52 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12447929572617444		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.12447929572617444 | validation: 0.12787270085716795]
	TIME [epoch: 8.51 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12916373182584268		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.12916373182584268 | validation: 0.1182867814160445]
	TIME [epoch: 8.52 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14836545085145655		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.14836545085145655 | validation: 0.10443698796559325]
	TIME [epoch: 8.53 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1253587707004357		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.1253587707004357 | validation: 0.12329056193230284]
	TIME [epoch: 8.52 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13384961261561568		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.13384961261561568 | validation: 0.12897155916226213]
	TIME [epoch: 8.51 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12116414632189532		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.12116414632189532 | validation: 0.10198140436649866]
	TIME [epoch: 8.54 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15792397886404072		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.15792397886404072 | validation: 0.22646171899945478]
	TIME [epoch: 8.51 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15143474965452022		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.15143474965452022 | validation: 0.11854611872101484]
	TIME [epoch: 8.51 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21875788041824612		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.21875788041824612 | validation: 0.21292457797686254]
	TIME [epoch: 8.51 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17180359155646427		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.17180359155646427 | validation: 0.266254347455661]
	TIME [epoch: 8.54 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4920119251745598		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.4920119251745598 | validation: 0.5068904399766285]
	TIME [epoch: 8.51 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.509703191109407		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.509703191109407 | validation: 0.32621273169274323]
	TIME [epoch: 8.51 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3791598280445171		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.3791598280445171 | validation: 0.3574716454762683]
	TIME [epoch: 8.53 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32132090762389015		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.32132090762389015 | validation: 0.1813186722945975]
	TIME [epoch: 8.51 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2183881074671324		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.2183881074671324 | validation: 0.19721496511717473]
	TIME [epoch: 8.51 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28137668847093816		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.28137668847093816 | validation: 0.31257792780429944]
	TIME [epoch: 8.51 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33255402369411785		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.33255402369411785 | validation: 0.19598561188122066]
	TIME [epoch: 8.54 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1866611467176384		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.1866611467176384 | validation: 0.1476415894344199]
	TIME [epoch: 8.52 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17629807453599972		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.17629807453599972 | validation: 0.17572904371408143]
	TIME [epoch: 8.51 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3542381409149315		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.3542381409149315 | validation: 0.5199486579110657]
	TIME [epoch: 8.54 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7285079538387734		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.7285079538387734 | validation: 0.5671727318036404]
	TIME [epoch: 8.52 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7115115014352521		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.7115115014352521 | validation: 0.38183247199207004]
	TIME [epoch: 8.51 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39422684597610214		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.39422684597610214 | validation: 0.18121057381119743]
	TIME [epoch: 8.51 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23747672078842683		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.23747672078842683 | validation: 0.2117477109882413]
	TIME [epoch: 8.53 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2817314458030944		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.2817314458030944 | validation: 0.24660347623170573]
	TIME [epoch: 8.51 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22039692742714645		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.22039692742714645 | validation: 0.16356621085098344]
	TIME [epoch: 8.51 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28158091757331855		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.28158091757331855 | validation: 0.489671190528736]
	TIME [epoch: 8.53 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7337471498497894		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.7337471498497894 | validation: 0.6949536491808384]
	TIME [epoch: 8.52 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49034859930283314		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.49034859930283314 | validation: 0.23611153994809328]
	TIME [epoch: 8.51 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3990967356373343		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.3990967356373343 | validation: 0.5629173119351479]
	TIME [epoch: 8.51 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43933540615212835		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.43933540615212835 | validation: 0.2531912450247775]
	TIME [epoch: 8.53 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27938735513860063		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.27938735513860063 | validation: 0.16707700513746698]
	TIME [epoch: 8.51 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23742344772129448		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.23742344772129448 | validation: 0.18794974945759674]
	TIME [epoch: 8.51 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22619689826161243		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.22619689826161243 | validation: 0.16440132221854953]
	TIME [epoch: 8.52 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2583774943250924		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.2583774943250924 | validation: 0.3138213774455338]
	TIME [epoch: 8.52 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2990189337440303		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.2990189337440303 | validation: 0.17896566924734622]
	TIME [epoch: 8.52 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24771271502659248		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.24771271502659248 | validation: 0.1819611292889043]
	TIME [epoch: 8.51 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20627586698414274		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.20627586698414274 | validation: 0.13839817862597584]
	TIME [epoch: 8.54 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1909573983064075		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.1909573983064075 | validation: 0.2520604765311697]
	TIME [epoch: 8.51 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44876236412447135		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.44876236412447135 | validation: 0.3603852408135254]
	TIME [epoch: 8.52 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2753095086195383		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.2753095086195383 | validation: 0.16734189591264814]
	TIME [epoch: 8.53 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21429787643859538		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.21429787643859538 | validation: 0.21792273788979777]
	TIME [epoch: 8.52 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1995676162366364		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.1995676162366364 | validation: 0.11648295954806033]
	TIME [epoch: 8.51 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14899034926743696		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.14899034926743696 | validation: 0.11491497452090196]
	TIME [epoch: 8.51 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1517967789897275		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.1517967789897275 | validation: 0.1389870027509092]
	TIME [epoch: 8.53 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16515294836766178		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.16515294836766178 | validation: 0.11521109934263749]
	TIME [epoch: 8.51 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14733882351032165		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.14733882351032165 | validation: 0.1299264335445719]
	TIME [epoch: 8.52 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16917578126203706		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.16917578126203706 | validation: 0.1419459621721261]
	TIME [epoch: 8.51 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15373870175298623		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.15373870175298623 | validation: 0.12331627595843361]
	TIME [epoch: 8.53 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14312508286666753		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.14312508286666753 | validation: 0.13922159307000648]
	TIME [epoch: 8.51 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1378700315471672		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.1378700315471672 | validation: 0.11643451486272333]
	TIME [epoch: 8.51 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14946334674260692		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.14946334674260692 | validation: 0.16493093680538456]
	TIME [epoch: 8.53 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16868554628988713		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.16868554628988713 | validation: 0.11656746845512521]
	TIME [epoch: 8.51 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12827741047123442		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.12827741047123442 | validation: 0.11794225605593282]
	TIME [epoch: 8.51 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1473941989144775		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.1473941989144775 | validation: 0.114415998917983]
	TIME [epoch: 8.51 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12300865138077713		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.12300865138077713 | validation: 0.10816714326909398]
	TIME [epoch: 8.53 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13330001166360908		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.13330001166360908 | validation: 0.12026277493335108]
	TIME [epoch: 8.51 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1196501401541212		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.1196501401541212 | validation: 0.10014668150164782]
	TIME [epoch: 8.51 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11797644216906067		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.11797644216906067 | validation: 0.10403977817400122]
	TIME [epoch: 8.53 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11706386311651044		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.11706386311651044 | validation: 0.1174886729719907]
	TIME [epoch: 8.52 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12483533284856578		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.12483533284856578 | validation: 0.14259421187715227]
	TIME [epoch: 8.51 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13522976249206936		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.13522976249206936 | validation: 0.11533405528877044]
	TIME [epoch: 8.51 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1339811906893938		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.1339811906893938 | validation: 0.12045075648556901]
	TIME [epoch: 8.54 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12254932057411039		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.12254932057411039 | validation: 0.166121372652169]
	TIME [epoch: 8.51 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1626356522828549		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.1626356522828549 | validation: 0.1037797726655013]
	TIME [epoch: 8.51 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11498755474039576		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.11498755474039576 | validation: 0.10471541571716383]
	TIME [epoch: 8.52 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13060974060354827		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.13060974060354827 | validation: 0.10720020859354434]
	TIME [epoch: 8.51 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11440179403465126		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.11440179403465126 | validation: 0.10215259080604723]
	TIME [epoch: 8.51 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1185482188021326		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.1185482188021326 | validation: 0.10125114467842583]
	TIME [epoch: 8.51 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1164195526702376		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.1164195526702376 | validation: 0.09348538775189214]
	TIME [epoch: 8.54 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11701240084880409		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.11701240084880409 | validation: 0.09486925560396235]
	TIME [epoch: 8.51 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11905739297872346		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.11905739297872346 | validation: 0.11239842106753722]
	TIME [epoch: 8.51 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12476655523368245		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.12476655523368245 | validation: 0.11214625053369612]
	TIME [epoch: 8.53 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12486656132739397		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.12486656132739397 | validation: 0.10729528585789412]
	TIME [epoch: 8.52 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11883811124333203		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.11883811124333203 | validation: 0.10274287553911542]
	TIME [epoch: 8.51 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1324124767937528		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.1324124767937528 | validation: 0.11354334817468076]
	TIME [epoch: 8.51 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11912786348854942		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.11912786348854942 | validation: 0.10395921514066461]
	TIME [epoch: 8.54 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1250915078871447		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.1250915078871447 | validation: 0.10215689107266612]
	TIME [epoch: 8.51 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10973873833456782		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.10973873833456782 | validation: 0.10104619940922156]
	TIME [epoch: 8.51 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11019657534995583		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.11019657534995583 | validation: 0.103298820640361]
	TIME [epoch: 8.53 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12335409079337667		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.12335409079337667 | validation: 0.09782861278107818]
	TIME [epoch: 8.52 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11489178221373106		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.11489178221373106 | validation: 0.10312952126860783]
	TIME [epoch: 8.51 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12951188779578032		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.12951188779578032 | validation: 0.14472142600598328]
	TIME [epoch: 8.51 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15859339096221542		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.15859339096221542 | validation: 0.11370275142910566]
	TIME [epoch: 8.53 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12005645238892437		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.12005645238892437 | validation: 0.12122584100160261]
	TIME [epoch: 8.51 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1765483214508332		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.1765483214508332 | validation: 0.14140354004797906]
	TIME [epoch: 8.51 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1861114217764948		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.1861114217764948 | validation: 0.2022256526984235]
	TIME [epoch: 8.51 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17191026608307652		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.17191026608307652 | validation: 0.14224785504342402]
	TIME [epoch: 8.53 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15654833984546804		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.15654833984546804 | validation: 0.12164082171472743]
	TIME [epoch: 8.51 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1415269946029452		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.1415269946029452 | validation: 0.135740187128927]
	TIME [epoch: 8.51 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12472054068163993		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.12472054068163993 | validation: 0.12217229905793581]
	TIME [epoch: 8.53 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13246809427394018		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.13246809427394018 | validation: 0.11171218355370498]
	TIME [epoch: 8.52 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11962445000627246		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.11962445000627246 | validation: 0.09906349618110113]
	TIME [epoch: 8.51 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11656830199299291		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.11656830199299291 | validation: 0.1040904969254961]
	TIME [epoch: 8.52 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13845524826325556		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.13845524826325556 | validation: 0.12104036469877004]
	TIME [epoch: 8.54 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1324083162498316		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.1324083162498316 | validation: 0.09820367130483763]
	TIME [epoch: 8.51 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1188477843450284		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.1188477843450284 | validation: 0.1465079910453959]
	TIME [epoch: 8.52 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13337419246436016		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.13337419246436016 | validation: 0.13776110571222178]
	TIME [epoch: 8.53 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14566440624514754		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.14566440624514754 | validation: 0.10543792698792319]
	TIME [epoch: 8.51 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1120109402117357		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.1120109402117357 | validation: 0.08985988807961656]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_926.pth
	Model improved!!!
EPOCH 927/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12642825978480113		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.12642825978480113 | validation: 0.09741830768861673]
	TIME [epoch: 8.52 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11652593819809169		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.11652593819809169 | validation: 0.08568713627752499]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_928.pth
	Model improved!!!
EPOCH 929/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1131378375529573		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.1131378375529573 | validation: 0.08993742968048277]
	TIME [epoch: 8.51 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1323290986433466		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.1323290986433466 | validation: 0.11040533310315936]
	TIME [epoch: 8.52 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12516233394567725		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.12516233394567725 | validation: 0.10818246599629947]
	TIME [epoch: 8.53 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12511607364419836		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.12511607364419836 | validation: 0.10880619609274875]
	TIME [epoch: 8.52 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1276676163067281		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.1276676163067281 | validation: 0.12357669706532082]
	TIME [epoch: 8.51 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12858794479641117		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.12858794479641117 | validation: 0.12818324091070316]
	TIME [epoch: 8.51 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12277920132570581		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.12277920132570581 | validation: 0.1034772125707408]
	TIME [epoch: 8.52 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12032541693313918		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.12032541693313918 | validation: 0.09248489789657219]
	TIME [epoch: 8.52 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12365442485253086		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.12365442485253086 | validation: 0.09432540342705659]
	TIME [epoch: 8.51 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11952210059634556		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.11952210059634556 | validation: 0.13132462319552782]
	TIME [epoch: 8.52 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13469688830271603		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.13469688830271603 | validation: 0.10556417468626482]
	TIME [epoch: 8.53 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11669245277746579		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.11669245277746579 | validation: 0.11241030402707017]
	TIME [epoch: 8.51 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11416762645455258		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.11416762645455258 | validation: 0.09952490843288776]
	TIME [epoch: 8.51 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12544055838062024		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.12544055838062024 | validation: 0.09978931535559304]
	TIME [epoch: 8.53 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11535001409175498		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.11535001409175498 | validation: 0.09409555149802842]
	TIME [epoch: 8.53 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12849364640777008		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.12849364640777008 | validation: 0.09277828951957684]
	TIME [epoch: 8.51 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11890787507575389		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.11890787507575389 | validation: 0.09977978559225968]
	TIME [epoch: 8.51 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.130390075019358		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.130390075019358 | validation: 0.09714324870250297]
	TIME [epoch: 8.54 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11370828746167375		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.11370828746167375 | validation: 0.09812631258679108]
	TIME [epoch: 8.52 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11411814316990551		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.11411814316990551 | validation: 0.13186568330768156]
	TIME [epoch: 8.52 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14532539777788986		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.14532539777788986 | validation: 0.11640100621797339]
	TIME [epoch: 8.52 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11947134988697863		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.11947134988697863 | validation: 0.09716353141143452]
	TIME [epoch: 8.53 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1178256687251648		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.1178256687251648 | validation: 0.10551501965870218]
	TIME [epoch: 8.51 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1219337281715254		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.1219337281715254 | validation: 0.08632235460608523]
	TIME [epoch: 8.52 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11291568156650764		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.11291568156650764 | validation: 0.10576176567940902]
	TIME [epoch: 8.54 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11722098822391176		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.11722098822391176 | validation: 0.09441005035960061]
	TIME [epoch: 8.52 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11156037056537196		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.11156037056537196 | validation: 0.09686553183955415]
	TIME [epoch: 8.52 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12246643188868747		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.12246643188868747 | validation: 0.10289958050154611]
	TIME [epoch: 8.52 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12482271478128396		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.12482271478128396 | validation: 0.11053194497384614]
	TIME [epoch: 8.54 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11921628395239185		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.11921628395239185 | validation: 0.09554233435830284]
	TIME [epoch: 8.52 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11672712058590073		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.11672712058590073 | validation: 0.08110272158278903]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240218_115024/states/model_tr_study3_959.pth
	Model improved!!!
EPOCH 960/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11113655572480663		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.11113655572480663 | validation: 0.09321656621052828]
	TIME [epoch: 8.53 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12682633781637934		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.12682633781637934 | validation: 0.09647878575050628]
	TIME [epoch: 8.51 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10883282197668735		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.10883282197668735 | validation: 0.09014807561470853]
	TIME [epoch: 8.51 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.114944236504456		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.114944236504456 | validation: 0.09805666881065363]
	TIME [epoch: 8.51 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11306040063738387		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.11306040063738387 | validation: 0.09274554885558524]
	TIME [epoch: 8.53 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11252424654224935		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.11252424654224935 | validation: 0.097864447039212]
	TIME [epoch: 8.51 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1119852253240278		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.1119852253240278 | validation: 0.09488847900924292]
	TIME [epoch: 8.51 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11177316140266957		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.11177316140266957 | validation: 0.09445665983947088]
	TIME [epoch: 8.52 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11028397723423641		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.11028397723423641 | validation: 0.09810422948103921]
	TIME [epoch: 8.53 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11150431872697994		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.11150431872697994 | validation: 0.09152276004778115]
	TIME [epoch: 8.51 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11174314418355895		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.11174314418355895 | validation: 0.09376103745473796]
	TIME [epoch: 8.51 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11938534509337033		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.11938534509337033 | validation: 0.10162748280000916]
	TIME [epoch: 8.54 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1065585633807076		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.1065585633807076 | validation: 0.10195756493948921]
	TIME [epoch: 8.51 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11197648199222943		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.11197648199222943 | validation: 0.09869119429547844]
	TIME [epoch: 8.52 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1346331259758637		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.1346331259758637 | validation: 0.12226466317693221]
	TIME [epoch: 8.52 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12522459926637286		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.12522459926637286 | validation: 0.10566713191938343]
	TIME [epoch: 8.53 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11820690036088002		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.11820690036088002 | validation: 0.11091881375364918]
	TIME [epoch: 8.52 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12477995207538176		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.12477995207538176 | validation: 0.09389172751552616]
	TIME [epoch: 8.5 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11656350639197599		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.11656350639197599 | validation: 0.08981498286745057]
	TIME [epoch: 8.53 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1131798551644015		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.1131798551644015 | validation: 0.09177273108937034]
	TIME [epoch: 8.51 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11358765923839442		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.11358765923839442 | validation: 0.09554645622903601]
	TIME [epoch: 8.51 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1161048190533844		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.1161048190533844 | validation: 0.09509989803289493]
	TIME [epoch: 8.51 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11031664794242158		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.11031664794242158 | validation: 0.09432517492940397]
	TIME [epoch: 8.53 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12098966277401683		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.12098966277401683 | validation: 0.10301574594161593]
	TIME [epoch: 8.51 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12763714502271695		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.12763714502271695 | validation: 0.11866302093610782]
	TIME [epoch: 8.52 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.132307232762534		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.132307232762534 | validation: 0.09877647209279107]
	TIME [epoch: 8.52 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11334742125296515		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.11334742125296515 | validation: 0.10103414805319928]
	TIME [epoch: 8.5 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10847816257109791		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.10847816257109791 | validation: 0.09912761020482834]
	TIME [epoch: 8.5 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10976907086751257		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.10976907086751257 | validation: 0.11153458088392702]
	TIME [epoch: 8.49 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11899148389751397		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.11899148389751397 | validation: 0.09722750379010502]
	TIME [epoch: 8.52 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11200381192144104		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.11200381192144104 | validation: 0.09638328804729779]
	TIME [epoch: 8.49 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1353673148461032		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.1353673148461032 | validation: 0.10747854349432132]
	TIME [epoch: 8.49 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11808940750051244		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.11808940750051244 | validation: 0.10269981669346231]
	TIME [epoch: 8.51 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1179532528294531		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.1179532528294531 | validation: 0.09617650511867776]
	TIME [epoch: 8.5 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11509970608236106		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.11509970608236106 | validation: 0.10416032126226693]
	TIME [epoch: 8.49 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11896358466496523		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.11896358466496523 | validation: 0.09273412625171588]
	TIME [epoch: 8.49 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12378725669961976		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.12378725669961976 | validation: 0.08760670898101793]
	TIME [epoch: 8.52 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11760410982791551		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.11760410982791551 | validation: 0.0983606833667103]
	TIME [epoch: 8.49 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11337669175293374		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.11337669175293374 | validation: 0.09690726726647644]
	TIME [epoch: 8.49 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11544161068603102		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.11544161068603102 | validation: 0.09594426381121658]
	TIME [epoch: 8.51 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11634153751044699		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.11634153751044699 | validation: 0.09160800508584005]
	TIME [epoch: 8.5 sec]
Finished training in 8629.108 seconds.
