Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r1', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3006779291

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/10] avg loss: 11.139393412462834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.139393412462834 | validation: 10.8507555882064]
	TIME [epoch: 70.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/10] avg loss: 11.092914175865538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.092914175865538 | validation: 10.872947911329074]
	TIME [epoch: 9.09 sec]
EPOCH 3/1000:
	Training over batches...
		[batch 10/10] avg loss: 10.472674536412693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.472674536412693 | validation: 9.866470975872474]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.907831912899148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.907831912899148 | validation: 8.456550196399817]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.4028869535035735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.4028869535035735 | validation: 7.13829715369185]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.532654946013897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.532654946013897 | validation: 6.939184147536363]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.467805886828612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.467805886828612 | validation: 7.137853205502858]
	TIME [epoch: 9.05 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.365257381957998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.365257381957998 | validation: 6.965630495839957]
	TIME [epoch: 9.05 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.3655412576495465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.3655412576495465 | validation: 6.790759535912066]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.333254985166862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.333254985166862 | validation: 6.856791226898286]
	TIME [epoch: 9.05 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.354385522275132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.354385522275132 | validation: 6.888885648525171]
	TIME [epoch: 9.06 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.347594649174329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.347594649174329 | validation: 6.867460356676816]
	TIME [epoch: 9.05 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.443822971519734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.443822971519734 | validation: 6.883340945568436]
	TIME [epoch: 9.05 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.335436194715714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.335436194715714 | validation: 7.014063378083382]
	TIME [epoch: 9.06 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.344095077183276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.344095077183276 | validation: 6.798271095410703]
	TIME [epoch: 9.08 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.270329021443343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.270329021443343 | validation: 6.876902397906807]
	TIME [epoch: 9.06 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.293130401009785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.293130401009785 | validation: 6.84401402021034]
	TIME [epoch: 9.05 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.261599080723813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.261599080723813 | validation: 6.812748918160759]
	TIME [epoch: 9.07 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.30150287559221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.30150287559221 | validation: 6.833112007045644]
	TIME [epoch: 9.06 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.268628231104776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.268628231104776 | validation: 6.809784260445749]
	TIME [epoch: 9.09 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.406177490667607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.406177490667607 | validation: 6.96019478153816]
	TIME [epoch: 9.06 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.284520312267974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.284520312267974 | validation: 6.813137120979995]
	TIME [epoch: 9.04 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.228069454158898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.228069454158898 | validation: 6.809211875250204]
	TIME [epoch: 9.05 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.247667032108529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.247667032108529 | validation: 6.872296355890972]
	TIME [epoch: 9.06 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.2795665674506385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2795665674506385 | validation: 6.905275668642384]
	TIME [epoch: 9.07 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.295043689514856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.295043689514856 | validation: 6.9240620317841035]
	TIME [epoch: 9.05 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.286370601584752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.286370601584752 | validation: 6.772779044785619]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.1924654644634565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1924654644634565 | validation: 6.445738592983348]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_28.pth
	Model improved!!!
EPOCH 29/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.055489939830905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.055489939830905 | validation: 6.314845011620008]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_29.pth
	Model improved!!!
EPOCH 30/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.865729216814055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.865729216814055 | validation: 6.000340540360553]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.612007418289169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.612007418289169 | validation: 5.197863947139421]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_31.pth
	Model improved!!!
EPOCH 32/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.79821752621538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.79821752621538 | validation: 4.101254292123521]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.332718046522471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.332718046522471 | validation: 4.537950701805122]
	TIME [epoch: 9.06 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.562447850175671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.562447850175671 | validation: 3.7805147821384484]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_34.pth
	Model improved!!!
EPOCH 35/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.297898425745156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.297898425745156 | validation: 3.758632250272389]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_35.pth
	Model improved!!!
EPOCH 36/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.0975805499311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0975805499311 | validation: 5.418981501427139]
	TIME [epoch: 9.04 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.43156672239714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.43156672239714 | validation: 3.842804151146318]
	TIME [epoch: 9.05 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.114502740348398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.114502740348398 | validation: 3.863597320537933]
	TIME [epoch: 9.07 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.0432648797645525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0432648797645525 | validation: 4.343365174395818]
	TIME [epoch: 9.07 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.9302473520578642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9302473520578642 | validation: 4.292148293069829]
	TIME [epoch: 9.06 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.6916609609959203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6916609609959203 | validation: 3.098396754378644]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_41.pth
	Model improved!!!
EPOCH 42/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.0286408917201744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0286408917201744 | validation: 2.8906431973590845]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.8475615770419083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8475615770419083 | validation: 2.4584578965687216]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_43.pth
	Model improved!!!
EPOCH 44/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.2602316048580002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2602316048580002 | validation: 2.687302575536328]
	TIME [epoch: 9.06 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.512967625211942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.512967625211942 | validation: 3.3898385021805804]
	TIME [epoch: 9.06 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.0072575742822503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0072575742822503 | validation: 2.5830216844119738]
	TIME [epoch: 9.05 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.663357219847579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.663357219847579 | validation: 2.5013027026259325]
	TIME [epoch: 9.05 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3912257804592847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3912257804592847 | validation: 2.1257059392987525]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.856418267230368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.856418267230368 | validation: 2.233785190353414]
	TIME [epoch: 9.05 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.395585649084675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.395585649084675 | validation: 2.31152273945754]
	TIME [epoch: 9.06 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.165279254366255		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 2.165279254366255 | validation: 2.0647606927118405]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_51.pth
	Model improved!!!
EPOCH 52/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3453407498000365		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 2.3453407498000365 | validation: 2.285719076112783]
	TIME [epoch: 9.06 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.223495805752226		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 2.223495805752226 | validation: 2.1787995259024417]
	TIME [epoch: 9.07 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.083057141143523		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 2.083057141143523 | validation: 2.1672042410185774]
	TIME [epoch: 9.04 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.321121714134394		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 2.321121714134394 | validation: 2.3937966016807914]
	TIME [epoch: 9.04 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.2541210314065068		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 2.2541210314065068 | validation: 2.368011041920335]
	TIME [epoch: 9.05 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3558750080686526		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 2.3558750080686526 | validation: 2.0315599913441824]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_57.pth
	Model improved!!!
EPOCH 58/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9766394421486697		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 1.9766394421486697 | validation: 2.7243212693313756]
	TIME [epoch: 9.09 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9870174785218615		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 1.9870174785218615 | validation: 2.313978529194159]
	TIME [epoch: 9.06 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8945994149206165		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 1.8945994149206165 | validation: 2.0235972549585903]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_60.pth
	Model improved!!!
EPOCH 61/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.928663385219512		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 1.928663385219512 | validation: 1.797903806194269]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_61.pth
	Model improved!!!
EPOCH 62/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0217640150084653		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 2.0217640150084653 | validation: 1.9040731525934178]
	TIME [epoch: 9.05 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.827227991600958		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 1.827227991600958 | validation: 2.072829802282458]
	TIME [epoch: 9.08 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9736704053962923		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 1.9736704053962923 | validation: 2.6216192455578904]
	TIME [epoch: 9.06 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.951590629634649		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 1.951590629634649 | validation: 2.1997785840752098]
	TIME [epoch: 9.04 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.758642976611879		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 1.758642976611879 | validation: 2.058923312640472]
	TIME [epoch: 9.06 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5418210946192508		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 1.5418210946192508 | validation: 1.8217094954289417]
	TIME [epoch: 9.04 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5502236870185242		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 1.5502236870185242 | validation: 1.4052197628327554]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_68.pth
	Model improved!!!
EPOCH 69/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5639781887923307		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 1.5639781887923307 | validation: 1.8687158087554998]
	TIME [epoch: 9.05 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4854447954263628		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 1.4854447954263628 | validation: 1.8658862392239461]
	TIME [epoch: 9.06 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4461778488818815		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 1.4461778488818815 | validation: 1.5631952620385956]
	TIME [epoch: 9.05 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4997780590492		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 1.4997780590492 | validation: 1.8120443976854226]
	TIME [epoch: 9.05 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4971822903696006		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 1.4971822903696006 | validation: 1.823280747298393]
	TIME [epoch: 9.07 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3826060743659987		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 1.3826060743659987 | validation: 1.4205256535318251]
	TIME [epoch: 9.05 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3186606657712416		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 1.3186606657712416 | validation: 1.4451402276324585]
	TIME [epoch: 9.05 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2341912312334238		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 1.2341912312334238 | validation: 1.4094099917072342]
	TIME [epoch: 9.04 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3352465641898141		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 1.3352465641898141 | validation: 1.268670789521769]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_77.pth
	Model improved!!!
EPOCH 78/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2426193136344579		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 1.2426193136344579 | validation: 1.7288213806918744]
	TIME [epoch: 9.07 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.291137094716392		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 1.291137094716392 | validation: 1.3221958258598157]
	TIME [epoch: 9.04 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1213401623120336		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 1.1213401623120336 | validation: 0.9374373955957633]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_80.pth
	Model improved!!!
EPOCH 81/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.093826033216629		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 1.093826033216629 | validation: 1.0542826573443824]
	TIME [epoch: 9.04 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1090293072587731		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 1.1090293072587731 | validation: 1.0233358686088225]
	TIME [epoch: 9.06 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0494531502992972		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 1.0494531502992972 | validation: 1.2870012131735584]
	TIME [epoch: 9.07 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1899461303012455		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 1.1899461303012455 | validation: 0.7998684641021199]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_84.pth
	Model improved!!!
EPOCH 85/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9093005672835801		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 0.9093005672835801 | validation: 0.7913331998036472]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_85.pth
	Model improved!!!
EPOCH 86/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.955654767713451		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 0.955654767713451 | validation: 1.0079719117546242]
	TIME [epoch: 9.06 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.88737777036475		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 0.88737777036475 | validation: 1.5157908046515325]
	TIME [epoch: 9.06 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2027688143263564		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 1.2027688143263564 | validation: 1.0203054317958]
	TIME [epoch: 9.07 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2141086413535067		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 1.2141086413535067 | validation: 0.9892034601442179]
	TIME [epoch: 9.06 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7791807392484598		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 0.7791807392484598 | validation: 0.6816598502936322]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_90.pth
	Model improved!!!
EPOCH 91/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0336427654272913		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 1.0336427654272913 | validation: 0.7527064478434397]
	TIME [epoch: 9.05 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7460463202408711		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 0.7460463202408711 | validation: 0.6914220855162689]
	TIME [epoch: 9.06 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8921850619724419		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 0.8921850619724419 | validation: 0.5931061578969308]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_93.pth
	Model improved!!!
EPOCH 94/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9705752087918775		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 0.9705752087918775 | validation: 1.1352541276730692]
	TIME [epoch: 9.04 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8134019152888194		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 0.8134019152888194 | validation: 0.8132868412831243]
	TIME [epoch: 9.04 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8890553368463283		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 0.8890553368463283 | validation: 1.2405429740314688]
	TIME [epoch: 9.05 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8274953152298702		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 0.8274953152298702 | validation: 1.2835914051652773]
	TIME [epoch: 9.05 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0072132778263003		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 1.0072132778263003 | validation: 1.4476523013511364]
	TIME [epoch: 9.07 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0241390863719162		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 1.0241390863719162 | validation: 0.8048133201359828]
	TIME [epoch: 9.05 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1832000748648253		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 1.1832000748648253 | validation: 2.359721555960495]
	TIME [epoch: 9.06 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0350732618255474		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 1.0350732618255474 | validation: 1.313454518039737]
	TIME [epoch: 9.05 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8485432348081983		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 0.8485432348081983 | validation: 0.7494259202677336]
	TIME [epoch: 9.05 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9175647405095088		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 0.9175647405095088 | validation: 1.7772157059121751]
	TIME [epoch: 9.06 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0170200848454258		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 1.0170200848454258 | validation: 0.9688199104197133]
	TIME [epoch: 9.05 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8521014132503295		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 0.8521014132503295 | validation: 1.1953617429803371]
	TIME [epoch: 9.04 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8987635487244112		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 0.8987635487244112 | validation: 0.8140685480556442]
	TIME [epoch: 9.05 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0559474650456462		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 1.0559474650456462 | validation: 0.7434717643368709]
	TIME [epoch: 9.06 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7774554575307432		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 0.7774554575307432 | validation: 0.7480964087569071]
	TIME [epoch: 9.05 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7816548154753271		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.7816548154753271 | validation: 1.6760324611868502]
	TIME [epoch: 9.05 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9142607940909547		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 0.9142607940909547 | validation: 0.8091662203583898]
	TIME [epoch: 9.04 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9004318358344967		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 0.9004318358344967 | validation: 0.8557794087536515]
	TIME [epoch: 9.07 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7054830701384454		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 0.7054830701384454 | validation: 0.879268875029997]
	TIME [epoch: 9.04 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7786089625192978		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 0.7786089625192978 | validation: 0.6637619153731635]
	TIME [epoch: 9.06 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7962133243363845		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 0.7962133243363845 | validation: 0.7843848547060859]
	TIME [epoch: 9.05 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9792649685221957		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 0.9792649685221957 | validation: 0.8028681955135502]
	TIME [epoch: 9.08 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.914773754184856		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 0.914773754184856 | validation: 0.6745080193562125]
	TIME [epoch: 9.05 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8538064908701282		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 0.8538064908701282 | validation: 0.7056616980817891]
	TIME [epoch: 9.05 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8281556991125146		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 0.8281556991125146 | validation: 0.9254306464279489]
	TIME [epoch: 9.06 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6219853755139434		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 0.6219853755139434 | validation: 0.8119425639387354]
	TIME [epoch: 9.08 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0994051771859037		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 1.0994051771859037 | validation: 0.6580785568599778]
	TIME [epoch: 9.06 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8368382738076457		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 0.8368382738076457 | validation: 0.5520782317753073]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_121.pth
	Model improved!!!
EPOCH 122/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.709150576018901		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 0.709150576018901 | validation: 0.7172726777771194]
	TIME [epoch: 9.06 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7880041584201877		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 0.7880041584201877 | validation: 0.8986183408695005]
	TIME [epoch: 9.06 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7210510888351286		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 0.7210510888351286 | validation: 0.7859728988141418]
	TIME [epoch: 9.07 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9067072534020102		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 0.9067072534020102 | validation: 0.6785120970976952]
	TIME [epoch: 9.03 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7163218516289999		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 0.7163218516289999 | validation: 0.583497864136316]
	TIME [epoch: 9.04 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7043388864786948		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 0.7043388864786948 | validation: 0.7081837106598966]
	TIME [epoch: 9.03 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8235966228728427		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.8235966228728427 | validation: 1.2209615922956798]
	TIME [epoch: 9.05 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.759828674457108		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 0.759828674457108 | validation: 0.7923697815874936]
	TIME [epoch: 9.05 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7981140513570187		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 0.7981140513570187 | validation: 0.8062086388870614]
	TIME [epoch: 9.03 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.695552567799596		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 0.695552567799596 | validation: 0.8079241236734986]
	TIME [epoch: 9.04 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7723771955574058		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 0.7723771955574058 | validation: 0.782933008751896]
	TIME [epoch: 9.04 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.745093118571125		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 0.745093118571125 | validation: 0.6278360934747456]
	TIME [epoch: 9.06 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8751219837647705		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 0.8751219837647705 | validation: 0.8505184558273589]
	TIME [epoch: 9.05 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0388117564306194		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 1.0388117564306194 | validation: 0.6681217529643402]
	TIME [epoch: 9.05 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7028877534984729		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 0.7028877534984729 | validation: 0.9735237391408116]
	TIME [epoch: 9.05 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7648022067505167		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 0.7648022067505167 | validation: 0.609021863742204]
	TIME [epoch: 9.05 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6081627351598392		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 0.6081627351598392 | validation: 0.7226462737841324]
	TIME [epoch: 9.07 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6765480680725519		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 0.6765480680725519 | validation: 0.5926093543559405]
	TIME [epoch: 9.04 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7345842180346454		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 0.7345842180346454 | validation: 0.9329840062999908]
	TIME [epoch: 9.03 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9168778561507194		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 0.9168778561507194 | validation: 1.0269158837884083]
	TIME [epoch: 9.04 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7150194724965458		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 0.7150194724965458 | validation: 0.66270671389779]
	TIME [epoch: 9.06 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6242339314049528		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 0.6242339314049528 | validation: 0.8812671695676337]
	TIME [epoch: 9.05 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7248564960212839		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 0.7248564960212839 | validation: 0.5931612940332839]
	TIME [epoch: 9.04 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6594119051563251		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 0.6594119051563251 | validation: 0.6899395063656826]
	TIME [epoch: 9.04 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6765576187789019		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 0.6765576187789019 | validation: 0.45587765416031756]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_146.pth
	Model improved!!!
EPOCH 147/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6013748764184328		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.6013748764184328 | validation: 1.8994192847297273]
	TIME [epoch: 9.07 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7811054079499055		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 0.7811054079499055 | validation: 0.8093413382306953]
	TIME [epoch: 9.05 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9198042374141933		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 0.9198042374141933 | validation: 0.9133599775395949]
	TIME [epoch: 9.05 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6722980880650702		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 0.6722980880650702 | validation: 0.5083248342935329]
	TIME [epoch: 9.06 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5003090500520825		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 0.5003090500520825 | validation: 1.031041153309409]
	TIME [epoch: 9.05 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7696246852329821		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 0.7696246852329821 | validation: 0.7959690498098728]
	TIME [epoch: 9.09 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.714590952010383		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 0.714590952010383 | validation: 0.5706120466656095]
	TIME [epoch: 9.05 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.749312240364038		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 0.749312240364038 | validation: 0.42493992845866513]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_154.pth
	Model improved!!!
EPOCH 155/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6636858653379987		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 0.6636858653379987 | validation: 0.5831509414684727]
	TIME [epoch: 9.03 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7187505248465564		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 0.7187505248465564 | validation: 0.5721413715519135]
	TIME [epoch: 9.03 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8259757826853		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 0.8259757826853 | validation: 0.9558902289038674]
	TIME [epoch: 9.06 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6266145470950153		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 0.6266145470950153 | validation: 0.5158614720056707]
	TIME [epoch: 9.03 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6013158505845114		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 0.6013158505845114 | validation: 0.7496004055559281]
	TIME [epoch: 9.03 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6702108215288132		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 0.6702108215288132 | validation: 0.40575124243826444]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_160.pth
	Model improved!!!
EPOCH 161/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5807774789632945		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 0.5807774789632945 | validation: 0.5205505391607816]
	TIME [epoch: 9.05 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5829521138005271		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 0.5829521138005271 | validation: 1.1509076608630404]
	TIME [epoch: 9.08 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6926232314856555		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 0.6926232314856555 | validation: 0.6195893664401751]
	TIME [epoch: 9.04 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5359889918172576		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 0.5359889918172576 | validation: 0.6605303133052245]
	TIME [epoch: 9.04 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6494166892482329		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 0.6494166892482329 | validation: 1.078784944847442]
	TIME [epoch: 9.03 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7417650014106097		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.7417650014106097 | validation: 0.7121772058950757]
	TIME [epoch: 9.04 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7179731730682788		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 0.7179731730682788 | validation: 0.3907057075257404]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_167.pth
	Model improved!!!
EPOCH 168/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7700623141446459		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 0.7700623141446459 | validation: 0.5741401720880526]
	TIME [epoch: 9.04 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7631946509299226		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 0.7631946509299226 | validation: 0.8958361124451515]
	TIME [epoch: 9.05 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5833077312843256		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 0.5833077312843256 | validation: 0.423856625684214]
	TIME [epoch: 9.04 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5023530138369084		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 0.5023530138369084 | validation: 0.49821567248365917]
	TIME [epoch: 9.05 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6609315562400132		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 0.6609315562400132 | validation: 0.5525305744647548]
	TIME [epoch: 9.06 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6814972592860146		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 0.6814972592860146 | validation: 0.9769269942834358]
	TIME [epoch: 9.03 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5401838292124033		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 0.5401838292124033 | validation: 0.49900375924147344]
	TIME [epoch: 9.04 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.62532595662554		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 0.62532595662554 | validation: 0.9204400754417453]
	TIME [epoch: 9.05 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7592732606072422		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.7592732606072422 | validation: 0.5493150193765626]
	TIME [epoch: 9.06 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5472690583239216		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 0.5472690583239216 | validation: 0.5728017123953725]
	TIME [epoch: 9.06 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5640529326573573		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 0.5640529326573573 | validation: 1.618611833526595]
	TIME [epoch: 9.03 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6942743299461169		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.6942743299461169 | validation: 0.6034061554437089]
	TIME [epoch: 9.03 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5840322326477713		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 0.5840322326477713 | validation: 0.7069506686333785]
	TIME [epoch: 9.03 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7700713873992722		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 0.7700713873992722 | validation: 1.3500609910514556]
	TIME [epoch: 9.05 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6594135657729973		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.6594135657729973 | validation: 0.7117333244429572]
	TIME [epoch: 9.06 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7623154608090859		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 0.7623154608090859 | validation: 0.8702914365750525]
	TIME [epoch: 9.03 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7387165865377682		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 0.7387165865377682 | validation: 0.605590304354297]
	TIME [epoch: 9.04 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5762299959506405		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.5762299959506405 | validation: 0.3622594885859912]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_185.pth
	Model improved!!!
EPOCH 186/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5879894312175157		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.5879894312175157 | validation: 0.3521054211136372]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_186.pth
	Model improved!!!
EPOCH 187/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4615492685642405		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 0.4615492685642405 | validation: 0.9712232169017632]
	TIME [epoch: 9.05 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8133971047467154		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 0.8133971047467154 | validation: 0.3235775025714108]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_188.pth
	Model improved!!!
EPOCH 189/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5816444825382435		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 0.5816444825382435 | validation: 0.7415140854316924]
	TIME [epoch: 9.05 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5448855037386684		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.5448855037386684 | validation: 0.5653202255775662]
	TIME [epoch: 9.04 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5217537240511274		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 0.5217537240511274 | validation: 0.33898554843520246]
	TIME [epoch: 9.04 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4673566139120958		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 0.4673566139120958 | validation: 0.4964516596044666]
	TIME [epoch: 9.05 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5416252893665706		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 0.5416252893665706 | validation: 0.8342562341201614]
	TIME [epoch: 9.02 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6942460770008344		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.6942460770008344 | validation: 1.342626772077798]
	TIME [epoch: 9.04 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7470906219357494		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.7470906219357494 | validation: 0.5938169153564841]
	TIME [epoch: 9.37 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6129932572703669		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.6129932572703669 | validation: 0.5832543177285066]
	TIME [epoch: 9.05 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5186507845348329		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.5186507845348329 | validation: 0.9459250907483854]
	TIME [epoch: 9.08 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6642550308501772		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 0.6642550308501772 | validation: 0.5435743036887333]
	TIME [epoch: 9.06 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5992451567075248		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.5992451567075248 | validation: 0.7647632456831862]
	TIME [epoch: 9.06 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46119193321594754		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.46119193321594754 | validation: 0.3701287840642121]
	TIME [epoch: 9.06 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5612544364039186		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.5612544364039186 | validation: 0.5188173596413208]
	TIME [epoch: 9.05 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.603872341955286		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.603872341955286 | validation: 0.3977693023879387]
	TIME [epoch: 9.09 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48459924264962406		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 0.48459924264962406 | validation: 0.4146200259347447]
	TIME [epoch: 9.06 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5797807471293889		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.5797807471293889 | validation: 0.4706717930750727]
	TIME [epoch: 9.06 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6418145401928148		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.6418145401928148 | validation: 0.8717802378855852]
	TIME [epoch: 9.06 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5293516207394149		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 0.5293516207394149 | validation: 0.6110645077489401]
	TIME [epoch: 9.06 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5982589870122295		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.5982589870122295 | validation: 0.6484694694998803]
	TIME [epoch: 9.08 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5282602292865595		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.5282602292865595 | validation: 0.4428748450695591]
	TIME [epoch: 9.06 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4369649636609335		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.4369649636609335 | validation: 0.3125649243015056]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_209.pth
	Model improved!!!
EPOCH 210/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6239742706802894		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.6239742706802894 | validation: 0.4786991169191186]
	TIME [epoch: 9.06 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5253739400620125		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.5253739400620125 | validation: 0.679761879066545]
	TIME [epoch: 9.05 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4641007228434101		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.4641007228434101 | validation: 1.1480833361917788]
	TIME [epoch: 9.09 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6001359747900299		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.6001359747900299 | validation: 0.5623181832806197]
	TIME [epoch: 9.05 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42625849351004774		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.42625849351004774 | validation: 0.7068791932930091]
	TIME [epoch: 9.06 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5952985656199333		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.5952985656199333 | validation: 0.383871425826969]
	TIME [epoch: 9.06 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4713575475341932		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.4713575475341932 | validation: 0.7093825951223984]
	TIME [epoch: 9.06 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5058093205362046		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.5058093205362046 | validation: 0.5992884541830786]
	TIME [epoch: 9.08 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5056800870112796		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.5056800870112796 | validation: 0.9986639905070847]
	TIME [epoch: 9.06 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7039240605342578		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.7039240605342578 | validation: 0.9614486986118775]
	TIME [epoch: 9.06 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6404146690766594		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.6404146690766594 | validation: 0.7180608615689128]
	TIME [epoch: 9.06 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5438825202643901		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.5438825202643901 | validation: 0.6568315807171022]
	TIME [epoch: 9.05 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5158178920527958		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.5158178920527958 | validation: 0.5370350794848038]
	TIME [epoch: 9.08 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5114081584391605		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.5114081584391605 | validation: 0.4697370960908133]
	TIME [epoch: 9.05 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4058653011398422		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.4058653011398422 | validation: 0.45210303465702123]
	TIME [epoch: 9.05 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4632565752307368		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.4632565752307368 | validation: 0.40842509672323946]
	TIME [epoch: 9.05 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.482238302354084		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.482238302354084 | validation: 0.5035446506256422]
	TIME [epoch: 9.06 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47444575536228095		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.47444575536228095 | validation: 0.4158909871164327]
	TIME [epoch: 9.07 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6663440885905934		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.6663440885905934 | validation: 0.7731841493004883]
	TIME [epoch: 9.06 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5693547794756426		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.5693547794756426 | validation: 0.36918875299326154]
	TIME [epoch: 9.06 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4242429229713237		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.4242429229713237 | validation: 0.5552602401145348]
	TIME [epoch: 9.06 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5699599587536854		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.5699599587536854 | validation: 0.3361605883168297]
	TIME [epoch: 9.08 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4983651117778999		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.4983651117778999 | validation: 0.47124582078696414]
	TIME [epoch: 9.06 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6528795499309219		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.6528795499309219 | validation: 0.7815968764271377]
	TIME [epoch: 9.06 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5441014676783704		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.5441014676783704 | validation: 0.604448544489363]
	TIME [epoch: 9.05 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47852146452233535		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.47852146452233535 | validation: 0.5302877519868316]
	TIME [epoch: 9.07 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5279569118133643		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.5279569118133643 | validation: 0.30756282120236705]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_236.pth
	Model improved!!!
EPOCH 237/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4774047575952438		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.4774047575952438 | validation: 0.4503597338759402]
	TIME [epoch: 9.06 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5949111278567012		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.5949111278567012 | validation: 0.7617850150890633]
	TIME [epoch: 9.06 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6218224625181907		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.6218224625181907 | validation: 0.6849474598412856]
	TIME [epoch: 9.05 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6246000062343029		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.6246000062343029 | validation: 0.834429323754847]
	TIME [epoch: 9.08 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6125068882480269		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.6125068882480269 | validation: 0.623961975718691]
	TIME [epoch: 9.06 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4940614930550945		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.4940614930550945 | validation: 0.6486303728357923]
	TIME [epoch: 9.06 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5468331292059416		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.5468331292059416 | validation: 0.434590734249657]
	TIME [epoch: 9.06 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5291634541048421		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.5291634541048421 | validation: 0.4367556435177904]
	TIME [epoch: 9.04 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44547597553498813		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.44547597553498813 | validation: 0.6174736449180558]
	TIME [epoch: 9.07 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5220833379936567		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.5220833379936567 | validation: 0.45867957604186116]
	TIME [epoch: 9.06 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48453712058059395		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.48453712058059395 | validation: 0.8599190667837378]
	TIME [epoch: 9.05 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47094572693911607		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.47094572693911607 | validation: 0.37191568128910246]
	TIME [epoch: 9.06 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5303807811672109		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.5303807811672109 | validation: 0.3510701628259579]
	TIME [epoch: 9.05 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5610379855300847		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.5610379855300847 | validation: 0.6742047926469168]
	TIME [epoch: 9.08 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4728387195950032		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.4728387195950032 | validation: 0.307785607882335]
	TIME [epoch: 9.05 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5086087866967265		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.5086087866967265 | validation: 0.7527405375685221]
	TIME [epoch: 9.05 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49141834538641244		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.49141834538641244 | validation: 0.3446796837319187]
	TIME [epoch: 9.05 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43101222996224714		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.43101222996224714 | validation: 0.35540079312575323]
	TIME [epoch: 9.07 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4392209560481092		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.4392209560481092 | validation: 0.42465881162009267]
	TIME [epoch: 9.08 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4443282653452285		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.4443282653452285 | validation: 0.3427521994289544]
	TIME [epoch: 9.05 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5122826166881379		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.5122826166881379 | validation: 0.3091201897143101]
	TIME [epoch: 9.06 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45590814778434324		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.45590814778434324 | validation: 0.6112436251708587]
	TIME [epoch: 9.05 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4506528902660743		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.4506528902660743 | validation: 0.49306373116949953]
	TIME [epoch: 9.07 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4363097074212396		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.4363097074212396 | validation: 0.3495986244812739]
	TIME [epoch: 9.06 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3829673531809785		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.3829673531809785 | validation: 0.6344406728751161]
	TIME [epoch: 9.05 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41029658123447044		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.41029658123447044 | validation: 0.4287873578496796]
	TIME [epoch: 9.05 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44659731650075984		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.44659731650075984 | validation: 0.4477351380931463]
	TIME [epoch: 9.04 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.466487978275533		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.466487978275533 | validation: 0.44947305598767745]
	TIME [epoch: 9.07 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5042185769822823		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.5042185769822823 | validation: 0.5770849326079396]
	TIME [epoch: 9.04 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39885576222251407		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.39885576222251407 | validation: 0.3535525080239669]
	TIME [epoch: 9.05 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48077705756592487		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.48077705756592487 | validation: 0.3931496884891937]
	TIME [epoch: 9.05 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4579246231214958		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.4579246231214958 | validation: 0.8212777623962824]
	TIME [epoch: 9.06 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5639942149660395		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.5639942149660395 | validation: 0.5256495939451538]
	TIME [epoch: 9.08 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4485298945190984		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.4485298945190984 | validation: 0.39233610724164475]
	TIME [epoch: 9.06 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39657581645611967		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.39657581645611967 | validation: 0.3817407213155673]
	TIME [epoch: 9.05 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4020314791450746		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.4020314791450746 | validation: 0.5744568289865619]
	TIME [epoch: 9.05 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.417554041914031		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.417554041914031 | validation: 0.45643082764059417]
	TIME [epoch: 9.06 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3618224373550148		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.3618224373550148 | validation: 0.38470650693388975]
	TIME [epoch: 9.06 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6511579940658793		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.6511579940658793 | validation: 0.45466718424074287]
	TIME [epoch: 9.05 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5282754320563148		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.5282754320563148 | validation: 0.39646994848371797]
	TIME [epoch: 9.05 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5265495119623328		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.5265495119623328 | validation: 0.489832431793259]
	TIME [epoch: 9.04 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4459159095622106		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.4459159095622106 | validation: 0.2922193494567734]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_278.pth
	Model improved!!!
EPOCH 279/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4336210834074918		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.4336210834074918 | validation: 0.6115455846927238]
	TIME [epoch: 9.05 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4281721209021524		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.4281721209021524 | validation: 0.34755369468366615]
	TIME [epoch: 9.05 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40018827383843664		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.40018827383843664 | validation: 0.40867909128929947]
	TIME [epoch: 9.06 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43111447391274743		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.43111447391274743 | validation: 0.27457761267396]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_282.pth
	Model improved!!!
EPOCH 283/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3888729964540048		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.3888729964540048 | validation: 0.38878654968999404]
	TIME [epoch: 9.09 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4681053421274495		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.4681053421274495 | validation: 0.5809696218600622]
	TIME [epoch: 9.05 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37814752708004795		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.37814752708004795 | validation: 0.654922502669256]
	TIME [epoch: 9.06 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4339867059464573		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.4339867059464573 | validation: 0.45178467008213724]
	TIME [epoch: 9.05 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4516310912014291		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.4516310912014291 | validation: 0.2994529633243385]
	TIME [epoch: 9.06 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3725775359609266		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.3725775359609266 | validation: 0.40096497828211974]
	TIME [epoch: 9.05 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4568579639690326		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.4568579639690326 | validation: 0.5138061719940689]
	TIME [epoch: 9.06 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46025237808966607		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.46025237808966607 | validation: 0.3243060194284908]
	TIME [epoch: 9.05 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.457416290159588		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.457416290159588 | validation: 0.399682442697292]
	TIME [epoch: 9.05 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39225402005572574		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.39225402005572574 | validation: 0.8823851274789689]
	TIME [epoch: 9.05 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5051340963890983		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.5051340963890983 | validation: 0.5574454648097068]
	TIME [epoch: 9.06 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44883050914989137		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.44883050914989137 | validation: 0.5029307171224972]
	TIME [epoch: 9.07 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48126055277442825		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.48126055277442825 | validation: 0.761654434904567]
	TIME [epoch: 9.06 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5028216575231595		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.5028216575231595 | validation: 0.37212380542981605]
	TIME [epoch: 9.06 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36727451528065713		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.36727451528065713 | validation: 0.4492743698419853]
	TIME [epoch: 9.05 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5614086657973184		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.5614086657973184 | validation: 0.8490188679351751]
	TIME [epoch: 9.07 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5142078550950073		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.5142078550950073 | validation: 0.43539295608415846]
	TIME [epoch: 9.05 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5259002041853945		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.5259002041853945 | validation: 0.4631411821281193]
	TIME [epoch: 9.05 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44788427876714076		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.44788427876714076 | validation: 0.3989821450819815]
	TIME [epoch: 9.05 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35757126631063135		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.35757126631063135 | validation: 0.44882041496920433]
	TIME [epoch: 9.05 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4504899042011397		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.4504899042011397 | validation: 0.5529246969580448]
	TIME [epoch: 9.08 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44524627695886076		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.44524627695886076 | validation: 0.4130743929252203]
	TIME [epoch: 9.05 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38639914424085964		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.38639914424085964 | validation: 0.47087186864321307]
	TIME [epoch: 9.04 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40061473139012066		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.40061473139012066 | validation: 0.3603783327590225]
	TIME [epoch: 9.05 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36753324755881905		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.36753324755881905 | validation: 0.2923391441955214]
	TIME [epoch: 9.06 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41563559591787425		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.41563559591787425 | validation: 0.3015899035968824]
	TIME [epoch: 9.08 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32246783780156796		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.32246783780156796 | validation: 0.4063491693494278]
	TIME [epoch: 9.07 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41645668792295537		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.41645668792295537 | validation: 0.5821959158427867]
	TIME [epoch: 9.05 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40747888111847397		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.40747888111847397 | validation: 0.5919507703313993]
	TIME [epoch: 9.05 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38288805150288513		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.38288805150288513 | validation: 0.32234760106340915]
	TIME [epoch: 9.07 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34677123546054467		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.34677123546054467 | validation: 0.48427193639119265]
	TIME [epoch: 9.06 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45330844020986855		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.45330844020986855 | validation: 0.5083285638528571]
	TIME [epoch: 9.05 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37922633160485164		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.37922633160485164 | validation: 0.5007875925644671]
	TIME [epoch: 9.04 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42922094720239345		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.42922094720239345 | validation: 0.576680986961174]
	TIME [epoch: 9.04 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.411516708768798		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.411516708768798 | validation: 0.4830930568503345]
	TIME [epoch: 9.06 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3855484381121358		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.3855484381121358 | validation: 0.5681959212430675]
	TIME [epoch: 9.04 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4088989629542783		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.4088989629542783 | validation: 0.39155987500800293]
	TIME [epoch: 9.04 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4259950568312563		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.4259950568312563 | validation: 0.32435232262601166]
	TIME [epoch: 9.05 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3891398151128979		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.3891398151128979 | validation: 0.3163480556082352]
	TIME [epoch: 9.06 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37443202023911837		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.37443202023911837 | validation: 0.5757049675200614]
	TIME [epoch: 9.06 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5105023919784679		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.5105023919784679 | validation: 0.2955083071207014]
	TIME [epoch: 9.05 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36733206860986034		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.36733206860986034 | validation: 0.41159951583889376]
	TIME [epoch: 9.05 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38460934873399777		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.38460934873399777 | validation: 0.3276042577433994]
	TIME [epoch: 9.04 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44809986495340937		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.44809986495340937 | validation: 0.3853625206442457]
	TIME [epoch: 9.07 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.431999599530574		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.431999599530574 | validation: 0.3467389798951703]
	TIME [epoch: 9.04 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4365795079872786		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.4365795079872786 | validation: 0.4295117906631158]
	TIME [epoch: 9.05 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35470358879205		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.35470358879205 | validation: 0.3273920093179306]
	TIME [epoch: 9.04 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36385580759013203		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.36385580759013203 | validation: 0.45320956229715315]
	TIME [epoch: 9.05 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38645339131919143		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.38645339131919143 | validation: 0.36342217070277355]
	TIME [epoch: 9.06 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38714899414695547		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.38714899414695547 | validation: 0.5081086166014547]
	TIME [epoch: 9.04 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3610232959074514		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.3610232959074514 | validation: 0.3129515590493369]
	TIME [epoch: 9.04 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35450389736439386		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.35450389736439386 | validation: 0.3498152851282237]
	TIME [epoch: 9.05 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3740346741142412		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.3740346741142412 | validation: 0.6317328970008995]
	TIME [epoch: 9.06 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43094421072440336		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.43094421072440336 | validation: 0.3283203388385312]
	TIME [epoch: 9.05 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3721209455296073		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.3721209455296073 | validation: 0.3630739410894772]
	TIME [epoch: 9.03 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3262412122866005		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.3262412122866005 | validation: 0.30019856622622976]
	TIME [epoch: 9.04 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4690096483217815		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.4690096483217815 | validation: 0.6762551870267015]
	TIME [epoch: 9.03 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4585786263338809		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.4585786263338809 | validation: 0.27880210966099506]
	TIME [epoch: 9.06 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4164353433435216		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.4164353433435216 | validation: 0.5341135231493366]
	TIME [epoch: 9.04 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37873852920683665		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.37873852920683665 | validation: 0.7500321030031245]
	TIME [epoch: 9.03 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4482066629790384		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.4482066629790384 | validation: 0.42908105185046513]
	TIME [epoch: 9.04 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3353980172881575		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.3353980172881575 | validation: 0.2914895091870361]
	TIME [epoch: 9.05 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43459028449704185		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.43459028449704185 | validation: 0.41732024074873986]
	TIME [epoch: 9.05 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38081567948455036		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.38081567948455036 | validation: 0.4599478805890064]
	TIME [epoch: 9.04 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4998455726484451		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.4998455726484451 | validation: 0.32357153356724494]
	TIME [epoch: 9.04 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3188853594703536		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.3188853594703536 | validation: 0.3900931756615653]
	TIME [epoch: 9.04 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4582598503345219		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.4582598503345219 | validation: 0.33046973835511306]
	TIME [epoch: 9.07 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35561862803100647		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.35561862803100647 | validation: 0.45936738923991577]
	TIME [epoch: 9.03 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3712761139944496		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.3712761139944496 | validation: 0.3668502324107747]
	TIME [epoch: 9.04 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3946600382546815		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.3946600382546815 | validation: 0.4106600137350334]
	TIME [epoch: 9.04 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3872271809681044		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.3872271809681044 | validation: 0.4994231320503669]
	TIME [epoch: 9.04 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4646974773771948		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.4646974773771948 | validation: 0.5273545171815123]
	TIME [epoch: 9.06 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5234289148718427		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.5234289148718427 | validation: 0.6620149724911955]
	TIME [epoch: 9.03 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40523987632305636		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.40523987632305636 | validation: 0.35669527558885195]
	TIME [epoch: 9.03 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4740517412988817		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.4740517412988817 | validation: 0.40214647509628]
	TIME [epoch: 9.03 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5237456111406311		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.5237456111406311 | validation: 0.5678482242293414]
	TIME [epoch: 9.05 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4246008665273582		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.4246008665273582 | validation: 0.2961620969759954]
	TIME [epoch: 9.04 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3655323813854343		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.3655323813854343 | validation: 0.38772438336831233]
	TIME [epoch: 9.04 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3226429382188466		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.3226429382188466 | validation: 0.3432477689047501]
	TIME [epoch: 9.05 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3297468912628312		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.3297468912628312 | validation: 0.6003682969902642]
	TIME [epoch: 9.04 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4339221711442732		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.4339221711442732 | validation: 0.33086607643506344]
	TIME [epoch: 9.07 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5661140438520956		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.5661140438520956 | validation: 0.5429384598020653]
	TIME [epoch: 9.04 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48789338220253153		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.48789338220253153 | validation: 0.6262303922395678]
	TIME [epoch: 9.03 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4654289467438363		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.4654289467438363 | validation: 0.4022292046684468]
	TIME [epoch: 9.03 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31651435583433013		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.31651435583433013 | validation: 0.5383086207179774]
	TIME [epoch: 9.05 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3503141962771509		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.3503141962771509 | validation: 0.31723224177866693]
	TIME [epoch: 9.05 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3436108340433929		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.3436108340433929 | validation: 0.37255907301479796]
	TIME [epoch: 9.04 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35917416291433785		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.35917416291433785 | validation: 0.3574267240626383]
	TIME [epoch: 9.04 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3298872407205157		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.3298872407205157 | validation: 0.4386583637958184]
	TIME [epoch: 9.03 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3657477155143472		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.3657477155143472 | validation: 0.2981391360927903]
	TIME [epoch: 9.06 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.296820488741049		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.296820488741049 | validation: 0.30958353558096513]
	TIME [epoch: 9.03 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4069938335538474		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.4069938335538474 | validation: 0.34429321963522486]
	TIME [epoch: 9.04 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31104164716990584		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.31104164716990584 | validation: 0.324434509318568]
	TIME [epoch: 9.03 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37045276076455		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.37045276076455 | validation: 0.3740120736386372]
	TIME [epoch: 9.04 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3050811807420367		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.3050811807420367 | validation: 0.2541236723019157]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_377.pth
	Model improved!!!
EPOCH 378/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34699978358725597		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.34699978358725597 | validation: 0.29836603847533794]
	TIME [epoch: 9.03 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35301854231668844		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.35301854231668844 | validation: 0.48960525957248213]
	TIME [epoch: 9.03 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4278230203622818		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.4278230203622818 | validation: 0.3707974090874706]
	TIME [epoch: 9.03 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34310173156948626		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.34310173156948626 | validation: 0.3680794438992547]
	TIME [epoch: 9.06 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31864887997659624		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.31864887997659624 | validation: 0.3732245742926733]
	TIME [epoch: 9.03 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3974197398942664		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.3974197398942664 | validation: 0.38325340830728905]
	TIME [epoch: 9.03 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6000874709029275		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.6000874709029275 | validation: 0.6476887858105336]
	TIME [epoch: 9.03 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4395186874900247		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.4395186874900247 | validation: 0.5283492827623419]
	TIME [epoch: 9.02 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4063281401017643		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.4063281401017643 | validation: 0.5086145872571426]
	TIME [epoch: 9.05 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48589458221618065		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.48589458221618065 | validation: 0.38654039579332733]
	TIME [epoch: 9.04 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3886558419011033		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.3886558419011033 | validation: 0.3850031106805689]
	TIME [epoch: 9.03 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32868109797959516		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.32868109797959516 | validation: 0.35288093128878806]
	TIME [epoch: 9.03 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3352021945085772		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.3352021945085772 | validation: 0.3360467068312998]
	TIME [epoch: 9.03 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37751684346962994		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.37751684346962994 | validation: 0.6595133756438734]
	TIME [epoch: 9.04 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45395254929262396		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.45395254929262396 | validation: 0.3422035132918936]
	TIME [epoch: 9.03 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31457831840758865		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.31457831840758865 | validation: 0.2956494527331205]
	TIME [epoch: 9.03 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2972310650666332		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.2972310650666332 | validation: 0.2814852064451297]
	TIME [epoch: 9.03 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3511028231538055		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.3511028231538055 | validation: 0.3293410476578743]
	TIME [epoch: 9.03 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4121149377188186		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.4121149377188186 | validation: 0.40378005493148633]
	TIME [epoch: 9.05 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36056464159747464		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.36056464159747464 | validation: 0.449710996704504]
	TIME [epoch: 9.03 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31607437253135207		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.31607437253135207 | validation: 0.29963491176865653]
	TIME [epoch: 9.02 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3000185829298806		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.3000185829298806 | validation: 0.2636452955507756]
	TIME [epoch: 9.04 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29005942377925253		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.29005942377925253 | validation: 0.2895188234741628]
	TIME [epoch: 9.04 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3492205023653571		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.3492205023653571 | validation: 0.5107229920942264]
	TIME [epoch: 9.05 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34882095239758104		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.34882095239758104 | validation: 0.29274190090867824]
	TIME [epoch: 9.03 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31547633397809643		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.31547633397809643 | validation: 0.3092599887905781]
	TIME [epoch: 9.02 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29823364334523383		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.29823364334523383 | validation: 0.33750374235980646]
	TIME [epoch: 9.03 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29070864050342765		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.29070864050342765 | validation: 0.3693092853926211]
	TIME [epoch: 9.05 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2831382435157942		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.2831382435157942 | validation: 0.3413111211986619]
	TIME [epoch: 9.02 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36242388239674506		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.36242388239674506 | validation: 0.29228387629189956]
	TIME [epoch: 9.03 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3670079479670796		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.3670079479670796 | validation: 0.26803490420654497]
	TIME [epoch: 9.02 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28509452869440643		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.28509452869440643 | validation: 0.3458568753133937]
	TIME [epoch: 9.04 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27411712962115586		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.27411712962115586 | validation: 0.2707895413533789]
	TIME [epoch: 9.04 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27524329092645666		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.27524329092645666 | validation: 0.25952688617414493]
	TIME [epoch: 9.02 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30244140474495285		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.30244140474495285 | validation: 0.32634012418246505]
	TIME [epoch: 9.03 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27019833199724463		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.27019833199724463 | validation: 0.3343178131612484]
	TIME [epoch: 9.04 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34938782948326075		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.34938782948326075 | validation: 0.40188762025182173]
	TIME [epoch: 9.06 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2928287540717896		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.2928287540717896 | validation: 0.3229547635254372]
	TIME [epoch: 9.05 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2819878132244941		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.2819878132244941 | validation: 0.3277761971276614]
	TIME [epoch: 9.03 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2838411173987196		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.2838411173987196 | validation: 0.2970964128858946]
	TIME [epoch: 9.03 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28378612957243854		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.28378612957243854 | validation: 0.24893926775071445]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_418.pth
	Model improved!!!
EPOCH 419/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29554029007207744		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.29554029007207744 | validation: 0.3082168731031528]
	TIME [epoch: 9.06 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34234241504832585		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.34234241504832585 | validation: 0.24165884173201246]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_420.pth
	Model improved!!!
EPOCH 421/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3235947645394462		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.3235947645394462 | validation: 0.2502251885349638]
	TIME [epoch: 9.03 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3624712171245859		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.3624712171245859 | validation: 0.4122318265614716]
	TIME [epoch: 9.03 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3041633216954878		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.3041633216954878 | validation: 0.4730482361617585]
	TIME [epoch: 9.02 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40160350401964495		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.40160350401964495 | validation: 0.3389853324070037]
	TIME [epoch: 9.05 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35924380931485667		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.35924380931485667 | validation: 0.39916959434513044]
	TIME [epoch: 9.03 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4354269045008774		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.4354269045008774 | validation: 0.590080810574487]
	TIME [epoch: 9.03 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.458197304861645		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.458197304861645 | validation: 0.38220798329449923]
	TIME [epoch: 9.04 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3391755240722217		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.3391755240722217 | validation: 0.3589538829062475]
	TIME [epoch: 9.03 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30322140343242054		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.30322140343242054 | validation: 0.28852880717356366]
	TIME [epoch: 9.06 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29366618965864405		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.29366618965864405 | validation: 0.25009694464731086]
	TIME [epoch: 9.04 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3066546229920918		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.3066546229920918 | validation: 0.3286449147768552]
	TIME [epoch: 9.03 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2889745053167894		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.2889745053167894 | validation: 0.31882172439370277]
	TIME [epoch: 9.04 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28529249743661445		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.28529249743661445 | validation: 0.39572048457192827]
	TIME [epoch: 9.03 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29528161876411885		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.29528161876411885 | validation: 0.2633930958232945]
	TIME [epoch: 9.06 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2790653501298113		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.2790653501298113 | validation: 0.3018440541229137]
	TIME [epoch: 9.04 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29116695971703116		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.29116695971703116 | validation: 0.36710126846232827]
	TIME [epoch: 9.03 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28955506056899255		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.28955506056899255 | validation: 0.4061345810165523]
	TIME [epoch: 9.03 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30403594804001577		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.30403594804001577 | validation: 0.3236034127366453]
	TIME [epoch: 9.02 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.340302816906382		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.340302816906382 | validation: 0.2584240132499844]
	TIME [epoch: 9.06 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3178603080997835		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.3178603080997835 | validation: 0.25970907044702185]
	TIME [epoch: 9.03 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24182643099193343		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.24182643099193343 | validation: 0.25066368556451935]
	TIME [epoch: 9.03 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3148986673039449		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.3148986673039449 | validation: 0.35536580858601974]
	TIME [epoch: 9.03 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3121444318627695		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.3121444318627695 | validation: 0.28026525186768303]
	TIME [epoch: 9.03 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2834626924770166		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.2834626924770166 | validation: 0.24420111795559715]
	TIME [epoch: 9.05 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30280773051009363		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.30280773051009363 | validation: 0.2668225697986816]
	TIME [epoch: 9.03 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32458625154406273		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.32458625154406273 | validation: 0.2969735818714595]
	TIME [epoch: 9.03 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29973865711264147		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.29973865711264147 | validation: 0.25774407387915604]
	TIME [epoch: 9.03 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25467049799570207		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.25467049799570207 | validation: 0.24594230350200594]
	TIME [epoch: 9.04 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2743482510688501		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.2743482510688501 | validation: 0.2634175989970507]
	TIME [epoch: 9.03 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24589012760016274		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.24589012760016274 | validation: 0.29269322348593274]
	TIME [epoch: 9.03 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2708098005695196		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.2708098005695196 | validation: 0.36082310207593127]
	TIME [epoch: 9.03 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25498682256361305		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.25498682256361305 | validation: 0.2741873351380645]
	TIME [epoch: 9.04 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24497121900896907		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.24497121900896907 | validation: 0.2967009642690137]
	TIME [epoch: 9.04 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27330662681172646		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.27330662681172646 | validation: 0.28932992457433626]
	TIME [epoch: 9.03 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35489223829359806		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.35489223829359806 | validation: 0.4924257535678952]
	TIME [epoch: 9.03 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34288983141110335		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.34288983141110335 | validation: 0.29407734644702244]
	TIME [epoch: 9.02 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31400184272819737		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.31400184272819737 | validation: 0.244975371300719]
	TIME [epoch: 9.05 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2662930587929227		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.2662930587929227 | validation: 0.3258262948400458]
	TIME [epoch: 9.04 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2615323839433974		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.2615323839433974 | validation: 0.27742647313763535]
	TIME [epoch: 9.04 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23482068342098308		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.23482068342098308 | validation: 0.2263696551723543]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_460.pth
	Model improved!!!
EPOCH 461/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30386314007988763		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.30386314007988763 | validation: 0.2705813488690052]
	TIME [epoch: 9.03 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4783586486187323		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.4783586486187323 | validation: 0.374800192940805]
	TIME [epoch: 9.06 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3596669477163095		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.3596669477163095 | validation: 0.3141678841839971]
	TIME [epoch: 9.02 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3059401372769159		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.3059401372769159 | validation: 0.30770508797016366]
	TIME [epoch: 9.02 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.320988761154764		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.320988761154764 | validation: 0.4124005531992537]
	TIME [epoch: 9.03 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33606431391053143		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.33606431391053143 | validation: 0.39193398911186406]
	TIME [epoch: 9.03 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30766269348643965		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.30766269348643965 | validation: 0.27851812166562584]
	TIME [epoch: 9.06 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3112842123401226		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.3112842123401226 | validation: 0.29805741023497356]
	TIME [epoch: 9.03 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31534524415920606		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.31534524415920606 | validation: 0.2842451030828282]
	TIME [epoch: 9.02 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2447949136945292		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.2447949136945292 | validation: 0.32346150750750857]
	TIME [epoch: 9.03 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3029484696425628		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.3029484696425628 | validation: 0.23959892152000606]
	TIME [epoch: 9.02 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2357363213293861		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.2357363213293861 | validation: 0.2604594733562157]
	TIME [epoch: 9.05 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22350039770210595		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.22350039770210595 | validation: 0.2472768123554192]
	TIME [epoch: 9.03 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31644306032126657		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.31644306032126657 | validation: 0.29106304133503214]
	TIME [epoch: 9.03 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2782202525971803		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.2782202525971803 | validation: 0.5173884456194768]
	TIME [epoch: 9.03 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3460452470115083		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.3460452470115083 | validation: 0.293759387978059]
	TIME [epoch: 9.03 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24788155632795905		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.24788155632795905 | validation: 0.3029929441679269]
	TIME [epoch: 9.04 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2697957700227619		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.2697957700227619 | validation: 0.3212760596051488]
	TIME [epoch: 9.02 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3519505661008366		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.3519505661008366 | validation: 0.24755026880178507]
	TIME [epoch: 9.03 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23800668709062633		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.23800668709062633 | validation: 0.21061797412660305]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_480.pth
	Model improved!!!
EPOCH 481/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2613104610522342		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.2613104610522342 | validation: 0.25933905574278865]
	TIME [epoch: 9.06 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2603346041146787		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.2603346041146787 | validation: 0.3295850871880419]
	TIME [epoch: 9.04 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.242901670009494		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.242901670009494 | validation: 0.21589362097610848]
	TIME [epoch: 9.03 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24117830902086396		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.24117830902086396 | validation: 0.3033559251064515]
	TIME [epoch: 9.02 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34510508976466164		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.34510508976466164 | validation: 0.5007212682347055]
	TIME [epoch: 9.03 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.340052907614772		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.340052907614772 | validation: 0.32667405662218507]
	TIME [epoch: 9.05 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32949654423464414		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.32949654423464414 | validation: 0.3172501304756092]
	TIME [epoch: 9.03 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26040611600928865		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.26040611600928865 | validation: 0.32444354902614203]
	TIME [epoch: 9.03 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34175888931621967		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.34175888931621967 | validation: 0.2997906477215543]
	TIME [epoch: 9.03 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27743325978016464		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.27743325978016464 | validation: 0.26655455964018615]
	TIME [epoch: 9.03 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25017986746767135		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.25017986746767135 | validation: 0.2884301629734398]
	TIME [epoch: 9.05 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26606779916619533		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.26606779916619533 | validation: 0.33088863157877735]
	TIME [epoch: 9.04 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2556555837595012		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.2556555837595012 | validation: 0.2387938213871597]
	TIME [epoch: 9.04 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22481907772949156		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.22481907772949156 | validation: 0.2467118683003971]
	TIME [epoch: 9.03 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2606179013662798		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.2606179013662798 | validation: 0.30696112840952905]
	TIME [epoch: 9.04 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27256711249922827		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.27256711249922827 | validation: 0.2650223599789982]
	TIME [epoch: 9.05 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2755830094320216		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.2755830094320216 | validation: 0.3371682760789917]
	TIME [epoch: 9.04 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29358805758346274		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.29358805758346274 | validation: 0.3003776378272369]
	TIME [epoch: 9.03 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25310587202805507		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.25310587202805507 | validation: 0.23288883700885948]
	TIME [epoch: 9.03 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.276093816975593		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.276093816975593 | validation: 0.28444965875382017]
	TIME [epoch: 9.05 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28154606451823727		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.28154606451823727 | validation: 0.32862344540683297]
	TIME [epoch: 9.04 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2694528457835546		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.2694528457835546 | validation: 0.2540259404060854]
	TIME [epoch: 9.03 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2431016860993372		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.2431016860993372 | validation: 0.35076408690259986]
	TIME [epoch: 9.03 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29383600872862503		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.29383600872862503 | validation: 0.33943598284864307]
	TIME [epoch: 9.03 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27397866819186756		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.27397866819186756 | validation: 0.2624113983476657]
	TIME [epoch: 9.05 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2942837636767232		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.2942837636767232 | validation: 0.33167471694815576]
	TIME [epoch: 9.04 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26384359559180953		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.26384359559180953 | validation: 0.4094030606720738]
	TIME [epoch: 9.04 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3099395319233242		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.3099395319233242 | validation: 0.6293111437459247]
	TIME [epoch: 9.04 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39941506265938587		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.39941506265938587 | validation: 0.23510997763725847]
	TIME [epoch: 9.02 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25722102152273935		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.25722102152273935 | validation: 0.25363798288429185]
	TIME [epoch: 9.06 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2952560005594139		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.2952560005594139 | validation: 0.40918637064786023]
	TIME [epoch: 9.03 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2904463130353535		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.2904463130353535 | validation: 0.2828614419610096]
	TIME [epoch: 9.03 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22835305712619677		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.22835305712619677 | validation: 0.2229204863104877]
	TIME [epoch: 9.03 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2116436076134974		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.2116436076134974 | validation: 0.21845538648253304]
	TIME [epoch: 9.04 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24622920079074656		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.24622920079074656 | validation: 0.24813594520685844]
	TIME [epoch: 9.05 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26092495924552705		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.26092495924552705 | validation: 0.3268083823329277]
	TIME [epoch: 9.03 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28311165744625527		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.28311165744625527 | validation: 0.2473190878699386]
	TIME [epoch: 9.02 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2543670191003185		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.2543670191003185 | validation: 0.22504994572352513]
	TIME [epoch: 9.04 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22939028355286503		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.22939028355286503 | validation: 0.2684656656674849]
	TIME [epoch: 9.06 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2560595425078297		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.2560595425078297 | validation: 0.35487831157061867]
	TIME [epoch: 9.04 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2689319377526573		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.2689319377526573 | validation: 0.24030859680183841]
	TIME [epoch: 9.03 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24055637019500348		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.24055637019500348 | validation: 0.2038330529255612]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_522.pth
	Model improved!!!
EPOCH 523/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24739670768226735		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.24739670768226735 | validation: 0.29587918208646347]
	TIME [epoch: 9.04 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24054030369503604		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.24054030369503604 | validation: 0.27437980756710856]
	TIME [epoch: 9.04 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27375672390548916		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.27375672390548916 | validation: 0.310588089432605]
	TIME [epoch: 9.03 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35999092863405335		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.35999092863405335 | validation: 0.28441635477905985]
	TIME [epoch: 9.03 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26576953345856585		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.26576953345856585 | validation: 0.29699497630487093]
	TIME [epoch: 9.03 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24841343673159014		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.24841343673159014 | validation: 0.25295036085959566]
	TIME [epoch: 9.04 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30797637682672807		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.30797637682672807 | validation: 0.2075417176488395]
	TIME [epoch: 9.04 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23438091211405596		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.23438091211405596 | validation: 0.2136034450181212]
	TIME [epoch: 9.04 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2681538250568004		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.2681538250568004 | validation: 0.3302222802891588]
	TIME [epoch: 9.03 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26144499330540655		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.26144499330540655 | validation: 0.22178653460042547]
	TIME [epoch: 9.03 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21722012259699844		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.21722012259699844 | validation: 0.2479626645453108]
	TIME [epoch: 9.04 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2754100947793626		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.2754100947793626 | validation: 0.24319621569559574]
	TIME [epoch: 9.05 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2793540985418664		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.2793540985418664 | validation: 0.24463320244663966]
	TIME [epoch: 9.03 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2351530045556826		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.2351530045556826 | validation: 0.24542265055001666]
	TIME [epoch: 9.03 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2765382239398586		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.2765382239398586 | validation: 0.34708212790740967]
	TIME [epoch: 9.03 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2548755224289895		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.2548755224289895 | validation: 0.3173620896161153]
	TIME [epoch: 9.06 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2783711241515189		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.2783711241515189 | validation: 0.280557415371931]
	TIME [epoch: 9.03 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2575161626658596		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.2575161626658596 | validation: 0.26524834775924505]
	TIME [epoch: 9.03 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2530267564761567		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.2530267564761567 | validation: 0.27041539976854456]
	TIME [epoch: 9.03 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2303241139025805		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.2303241139025805 | validation: 0.24736110493710212]
	TIME [epoch: 9.02 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24147861692223263		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.24147861692223263 | validation: 0.19785505276521675]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_543.pth
	Model improved!!!
EPOCH 544/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2642025198048512		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.2642025198048512 | validation: 0.40613526345446793]
	TIME [epoch: 9.03 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2729677770421463		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.2729677770421463 | validation: 0.20470799669545642]
	TIME [epoch: 9.03 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22276944734967863		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.22276944734967863 | validation: 0.1960812944127263]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_546.pth
	Model improved!!!
EPOCH 547/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.212615867953176		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.212615867953176 | validation: 0.22279506615239758]
	TIME [epoch: 9.05 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28303620102028193		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.28303620102028193 | validation: 0.2551376155767034]
	TIME [epoch: 9.05 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2323774085198996		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.2323774085198996 | validation: 0.28316439936423127]
	TIME [epoch: 9.03 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2613202331886236		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.2613202331886236 | validation: 0.27273237094251324]
	TIME [epoch: 9.03 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27619700229527566		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.27619700229527566 | validation: 0.2719104168190213]
	TIME [epoch: 9.03 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24725329449497227		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.24725329449497227 | validation: 0.29578607484330577]
	TIME [epoch: 9.05 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23038103050003095		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.23038103050003095 | validation: 0.21028552978979875]
	TIME [epoch: 9.05 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21208883271397916		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.21208883271397916 | validation: 0.24387462319425923]
	TIME [epoch: 9.03 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.255316140024023		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.255316140024023 | validation: 0.2247330072938356]
	TIME [epoch: 9.03 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.225677401698214		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.225677401698214 | validation: 0.23645933170840683]
	TIME [epoch: 9.03 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21362997432725733		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.21362997432725733 | validation: 0.3405973621690515]
	TIME [epoch: 9.04 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27484771127819835		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.27484771127819835 | validation: 0.2236540869836551]
	TIME [epoch: 9.05 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2150624707560072		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.2150624707560072 | validation: 0.2772125758265904]
	TIME [epoch: 9.04 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25346180866948187		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.25346180866948187 | validation: 0.430457457380249]
	TIME [epoch: 9.04 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2419963646962003		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.2419963646962003 | validation: 0.2108048817244274]
	TIME [epoch: 9.03 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2411266652795015		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.2411266652795015 | validation: 0.29232891539832045]
	TIME [epoch: 9.06 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21582977544256052		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.21582977544256052 | validation: 0.22443122825985545]
	TIME [epoch: 9.05 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21539931078488223		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.21539931078488223 | validation: 0.2360432594985553]
	TIME [epoch: 9.03 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21911071572314883		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.21911071572314883 | validation: 0.20538431342446678]
	TIME [epoch: 9.04 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23844921167194238		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.23844921167194238 | validation: 0.2113839918643699]
	TIME [epoch: 9.04 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24241480775745		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.24241480775745 | validation: 0.2539822866017236]
	TIME [epoch: 9.05 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24111242379682585		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.24111242379682585 | validation: 0.22127494085439453]
	TIME [epoch: 9.04 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2785553204586129		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.2785553204586129 | validation: 0.2527141068829849]
	TIME [epoch: 9.04 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23414214177780926		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.23414214177780926 | validation: 0.2510498007700652]
	TIME [epoch: 9.04 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22919525084772227		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.22919525084772227 | validation: 0.20540453993252022]
	TIME [epoch: 9.06 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.213874964882383		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.213874964882383 | validation: 0.22067538880589294]
	TIME [epoch: 9.04 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21863117786841646		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.21863117786841646 | validation: 0.2590925236722551]
	TIME [epoch: 9.04 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2707334144216267		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.2707334144216267 | validation: 0.28503348301676723]
	TIME [epoch: 9.04 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2447843240803215		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.2447843240803215 | validation: 0.2132238441552557]
	TIME [epoch: 9.03 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2612617831655947		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.2612617831655947 | validation: 0.19316197019913628]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_576.pth
	Model improved!!!
EPOCH 577/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22256262188978998		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.22256262188978998 | validation: 0.23390577929449144]
	TIME [epoch: 9.02 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2529818600218186		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.2529818600218186 | validation: 0.29072854899098827]
	TIME [epoch: 9.03 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2547746175002577		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.2547746175002577 | validation: 0.22991882310575867]
	TIME [epoch: 9.03 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21321283364782442		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.21321283364782442 | validation: 0.1852028257645964]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_580.pth
	Model improved!!!
EPOCH 581/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23535260044085443		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.23535260044085443 | validation: 0.22010286997297623]
	TIME [epoch: 9.04 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2598011441909252		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.2598011441909252 | validation: 0.31066538366333984]
	TIME [epoch: 9.02 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2399097933504164		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.2399097933504164 | validation: 0.23471430306872326]
	TIME [epoch: 9.02 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2288165501598904		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.2288165501598904 | validation: 0.2134687299755451]
	TIME [epoch: 9.02 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.218565904000212		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.218565904000212 | validation: 0.2358389622543409]
	TIME [epoch: 9.04 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21043461663012292		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.21043461663012292 | validation: 0.21783174704898522]
	TIME [epoch: 9.03 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19332543888873474		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.19332543888873474 | validation: 0.2674358543774844]
	TIME [epoch: 9.02 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21257620874308247		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.21257620874308247 | validation: 0.2685765303971698]
	TIME [epoch: 9.02 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21630953336424802		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.21630953336424802 | validation: 0.22021619866612996]
	TIME [epoch: 9.01 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21860075779032048		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.21860075779032048 | validation: 0.22577381654592998]
	TIME [epoch: 9.02 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24159544961412233		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.24159544961412233 | validation: 0.1907496959263101]
	TIME [epoch: 9.04 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21996052271694558		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.21996052271694558 | validation: 0.2178065766563482]
	TIME [epoch: 9.02 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2162100361025235		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.2162100361025235 | validation: 0.22783589993801825]
	TIME [epoch: 9.02 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24311209184456278		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.24311209184456278 | validation: 0.2743594857602881]
	TIME [epoch: 9.02 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22903249303559964		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.22903249303559964 | validation: 0.20267718843660198]
	TIME [epoch: 9.02 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22417638542870638		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.22417638542870638 | validation: 0.19504877856672478]
	TIME [epoch: 9.03 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19717674614609623		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.19717674614609623 | validation: 0.1841281340503625]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_597.pth
	Model improved!!!
EPOCH 598/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18730581562615084		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.18730581562615084 | validation: 0.18288211232644644]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_598.pth
	Model improved!!!
EPOCH 599/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20293049284264186		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.20293049284264186 | validation: 0.2467204793452774]
	TIME [epoch: 9.02 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19508961477569953		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.19508961477569953 | validation: 0.19375367278864852]
	TIME [epoch: 9.04 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19526673122375157		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.19526673122375157 | validation: 0.19346035023577834]
	TIME [epoch: 9.01 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18781439684571008		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.18781439684571008 | validation: 0.21025047206549763]
	TIME [epoch: 9.02 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2051270570442476		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.2051270570442476 | validation: 0.28499537559163357]
	TIME [epoch: 9.02 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22266180557506016		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.22266180557506016 | validation: 0.32234091125580944]
	TIME [epoch: 9.03 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21471999332312483		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.21471999332312483 | validation: 0.2050268874919875]
	TIME [epoch: 9.04 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20623291758071752		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.20623291758071752 | validation: 0.2246484256408101]
	TIME [epoch: 9.03 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2229452174529943		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.2229452174529943 | validation: 0.23741226412478478]
	TIME [epoch: 9.03 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2055557581246786		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.2055557581246786 | validation: 0.29094282349484557]
	TIME [epoch: 9.02 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20823107113174202		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.20823107113174202 | validation: 0.20499476235306097]
	TIME [epoch: 9.03 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20615142301617118		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.20615142301617118 | validation: 0.23691748669587032]
	TIME [epoch: 9.04 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2621837739077356		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.2621837739077356 | validation: 0.2808856624882081]
	TIME [epoch: 9.03 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2636522700595167		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.2636522700595167 | validation: 0.25550172954284844]
	TIME [epoch: 9.04 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24558977887045003		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.24558977887045003 | validation: 0.29610109588840494]
	TIME [epoch: 9.03 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2633710967298382		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.2633710967298382 | validation: 0.2217796358610341]
	TIME [epoch: 9.04 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21800535655259537		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.21800535655259537 | validation: 0.2441400507020472]
	TIME [epoch: 9.03 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21407422444679097		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.21407422444679097 | validation: 0.21115018947074]
	TIME [epoch: 9.03 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24072886400502727		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.24072886400502727 | validation: 0.27811211300229954]
	TIME [epoch: 9.02 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2063133411509197		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.2063133411509197 | validation: 0.2789986612884101]
	TIME [epoch: 9.03 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23826323351231976		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.23826323351231976 | validation: 0.2315818855439313]
	TIME [epoch: 9.05 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20886170167875492		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.20886170167875492 | validation: 0.2820931602330409]
	TIME [epoch: 9.03 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20459154427360207		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.20459154427360207 | validation: 0.2193844969865351]
	TIME [epoch: 9.03 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20442658977033693		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.20442658977033693 | validation: 0.25799164073137115]
	TIME [epoch: 9.03 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21450413827182396		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.21450413827182396 | validation: 0.18090770405662893]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_623.pth
	Model improved!!!
EPOCH 624/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20864924139830937		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.20864924139830937 | validation: 0.19108359357778626]
	TIME [epoch: 9.04 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19431766292553732		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.19431766292553732 | validation: 0.20399058112314702]
	TIME [epoch: 9.02 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19468338036536875		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.19468338036536875 | validation: 0.1728228960490733]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_626.pth
	Model improved!!!
EPOCH 627/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17448939520549017		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.17448939520549017 | validation: 0.17704878276179792]
	TIME [epoch: 9.04 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2210622965162398		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.2210622965162398 | validation: 0.2062118925590647]
	TIME [epoch: 9.03 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19587389194835303		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.19587389194835303 | validation: 0.2397636180014025]
	TIME [epoch: 9.06 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19277163516719742		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.19277163516719742 | validation: 0.17555224073509199]
	TIME [epoch: 9.03 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19854033025162998		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.19854033025162998 | validation: 0.23821120537111867]
	TIME [epoch: 9.03 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1975409936309513		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.1975409936309513 | validation: 0.20552369521390634]
	TIME [epoch: 9.03 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18653007642675798		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.18653007642675798 | validation: 0.21352073296762683]
	TIME [epoch: 9.03 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2162026485563183		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.2162026485563183 | validation: 0.19176299687994108]
	TIME [epoch: 9.05 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17148047201878427		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.17148047201878427 | validation: 0.17759103663118064]
	TIME [epoch: 9.03 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1736190880733353		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.1736190880733353 | validation: 0.20337907033962183]
	TIME [epoch: 9.03 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21083052752719342		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.21083052752719342 | validation: 0.262205386126916]
	TIME [epoch: 9.03 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19908539603157893		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.19908539603157893 | validation: 0.16334232725079606]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_638.pth
	Model improved!!!
EPOCH 639/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18359349338846517		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.18359349338846517 | validation: 0.20427069724147534]
	TIME [epoch: 9.06 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17047481604519168		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.17047481604519168 | validation: 0.1689586136295521]
	TIME [epoch: 9.03 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17491619336798472		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.17491619336798472 | validation: 0.21552608935016654]
	TIME [epoch: 9.01 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19215468572202746		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.19215468572202746 | validation: 0.1889687298989607]
	TIME [epoch: 9.02 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1751299829556276		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.1751299829556276 | validation: 0.1590888996623394]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_643.pth
	Model improved!!!
EPOCH 644/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17900978346326138		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.17900978346326138 | validation: 0.1857237181809872]
	TIME [epoch: 9.04 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19937572952653376		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.19937572952653376 | validation: 0.18708533511369757]
	TIME [epoch: 9.02 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20303901236437788		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.20303901236437788 | validation: 0.20622322562470424]
	TIME [epoch: 9.01 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2033141173856019		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.2033141173856019 | validation: 0.18465352563747633]
	TIME [epoch: 9.03 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18949678588697333		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.18949678588697333 | validation: 0.284648286601195]
	TIME [epoch: 9.01 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22321804248941673		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.22321804248941673 | validation: 0.1932774962599717]
	TIME [epoch: 9.06 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1801486570886038		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.1801486570886038 | validation: 0.209961372987579]
	TIME [epoch: 9.03 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1881933181168054		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.1881933181168054 | validation: 0.19217113137987563]
	TIME [epoch: 9.02 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1901365167085139		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.1901365167085139 | validation: 0.16909716532139848]
	TIME [epoch: 9.02 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19057492999788297		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.19057492999788297 | validation: 0.19692058882527824]
	TIME [epoch: 9.03 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17623545954189865		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.17623545954189865 | validation: 0.1804186177966876]
	TIME [epoch: 9.03 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1703175271053923		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.1703175271053923 | validation: 0.17177061844332742]
	TIME [epoch: 9.04 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18548003654460485		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.18548003654460485 | validation: 0.2128138111979795]
	TIME [epoch: 9.03 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18668061151255816		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.18668061151255816 | validation: 0.16838586775526182]
	TIME [epoch: 9.02 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22799839010698264		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.22799839010698264 | validation: 0.22345306926347147]
	TIME [epoch: 9.02 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18716443378971062		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.18716443378971062 | validation: 0.18571194282952352]
	TIME [epoch: 9.04 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1671006613797413		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.1671006613797413 | validation: 0.1756922776554335]
	TIME [epoch: 9.02 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.186035252584892		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.186035252584892 | validation: 0.2072173651963959]
	TIME [epoch: 9.02 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2147406575028187		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.2147406575028187 | validation: 0.17654213481916992]
	TIME [epoch: 9.03 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18402004059076882		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.18402004059076882 | validation: 0.1695511255566643]
	TIME [epoch: 9.02 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1739662025249269		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.1739662025249269 | validation: 0.19564511038685373]
	TIME [epoch: 9.05 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1942500827989609		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.1942500827989609 | validation: 0.1803481948200805]
	TIME [epoch: 9.03 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19185110130505972		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.19185110130505972 | validation: 0.18262075070389588]
	TIME [epoch: 9.02 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19470142881084188		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.19470142881084188 | validation: 0.18043219213959966]
	TIME [epoch: 9.02 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17185011046604762		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.17185011046604762 | validation: 0.1615530190007991]
	TIME [epoch: 9.03 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19167501326257078		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.19167501326257078 | validation: 0.19078032310603749]
	TIME [epoch: 9.04 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16993885695300884		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.16993885695300884 | validation: 0.17197225997234888]
	TIME [epoch: 9.03 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16598036086031906		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.16598036086031906 | validation: 0.1858975088630679]
	TIME [epoch: 9.02 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2119258690761418		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.2119258690761418 | validation: 0.17797669083205236]
	TIME [epoch: 9.03 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19035433924667372		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.19035433924667372 | validation: 0.16922749127175357]
	TIME [epoch: 9.05 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17858754000890303		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.17858754000890303 | validation: 0.17910352269800275]
	TIME [epoch: 9.03 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16808910926760828		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.16808910926760828 | validation: 0.17562848108888154]
	TIME [epoch: 9.03 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1971823538515823		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.1971823538515823 | validation: 0.17942592405918778]
	TIME [epoch: 9.02 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17574343590479263		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.17574343590479263 | validation: 0.172598987095802]
	TIME [epoch: 9.04 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16687036203913863		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.16687036203913863 | validation: 0.16587769115427314]
	TIME [epoch: 9.05 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.174068845156973		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.174068845156973 | validation: 0.18473920198458899]
	TIME [epoch: 9.04 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19223130245158992		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.19223130245158992 | validation: 0.18104099016636668]
	TIME [epoch: 9.04 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19094143649565745		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.19094143649565745 | validation: 0.1961517574170041]
	TIME [epoch: 9.02 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1789452565637492		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.1789452565637492 | validation: 0.17328021452482884]
	TIME [epoch: 9.04 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1898808753365079		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.1898808753365079 | validation: 0.20401354211251754]
	TIME [epoch: 9.03 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.200964050889383		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.200964050889383 | validation: 0.1642279318606049]
	TIME [epoch: 9.03 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1634619305603437		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.1634619305603437 | validation: 0.15687922880963634]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_685.pth
	Model improved!!!
EPOCH 686/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17053395204248326		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.17053395204248326 | validation: 0.16813027791390983]
	TIME [epoch: 9.03 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17033214040470676		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.17033214040470676 | validation: 0.1880735410968672]
	TIME [epoch: 9.05 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1754053752198452		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.1754053752198452 | validation: 0.19913253852620383]
	TIME [epoch: 9.02 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17962606214794125		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.17962606214794125 | validation: 0.18488880297348972]
	TIME [epoch: 9.03 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20245684173188208		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.20245684173188208 | validation: 0.18914088487225833]
	TIME [epoch: 9.03 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19390872463597342		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.19390872463597342 | validation: 0.18630328116919648]
	TIME [epoch: 9.03 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17990219837161758		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.17990219837161758 | validation: 0.1882037387247948]
	TIME [epoch: 9.05 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18137441896481704		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.18137441896481704 | validation: 0.1758751299879345]
	TIME [epoch: 9.03 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1791104989099229		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.1791104989099229 | validation: 0.16936404214513678]
	TIME [epoch: 9.03 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18503853793074118		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.18503853793074118 | validation: 0.19761280362845962]
	TIME [epoch: 9.03 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17556362085137617		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.17556362085137617 | validation: 0.1544041807451445]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_696.pth
	Model improved!!!
EPOCH 697/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1759223039470043		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.1759223039470043 | validation: 0.16408004176754792]
	TIME [epoch: 9.05 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1725694772508664		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.1725694772508664 | validation: 0.17404452005625376]
	TIME [epoch: 9.03 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17642431052338473		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.17642431052338473 | validation: 0.21300491385291667]
	TIME [epoch: 9.03 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20549243579350826		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.20549243579350826 | validation: 0.24800447872945638]
	TIME [epoch: 9.02 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2136579487272848		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.2136579487272848 | validation: 0.2389834223225844]
	TIME [epoch: 9.03 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17292792863832154		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.17292792863832154 | validation: 0.1715512111467039]
	TIME [epoch: 9.05 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1753921902983865		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.1753921902983865 | validation: 0.17906298358545247]
	TIME [epoch: 9.02 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1756128397670447		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.1756128397670447 | validation: 0.17842007827432815]
	TIME [epoch: 9.02 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16994162750604083		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.16994162750604083 | validation: 0.17540781200411434]
	TIME [epoch: 9.02 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.176471755318078		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.176471755318078 | validation: 0.18157654855142513]
	TIME [epoch: 9.03 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17107948431895137		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.17107948431895137 | validation: 0.22355854304406741]
	TIME [epoch: 9.05 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19237060989632998		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.19237060989632998 | validation: 0.2109789661135505]
	TIME [epoch: 9.02 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1839782247522767		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.1839782247522767 | validation: 0.25416589135911716]
	TIME [epoch: 9.03 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2217776343624601		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.2217776343624601 | validation: 0.25502523739448135]
	TIME [epoch: 9.02 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20043010976001602		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.20043010976001602 | validation: 0.23696246655638242]
	TIME [epoch: 9.02 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20380260563194436		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.20380260563194436 | validation: 0.21486865185246987]
	TIME [epoch: 9.05 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19073761881171675		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.19073761881171675 | validation: 0.21399305766524623]
	TIME [epoch: 9.03 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18820801166231574		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.18820801166231574 | validation: 0.22493160192430306]
	TIME [epoch: 9.03 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21439216141926157		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.21439216141926157 | validation: 0.1948053381678991]
	TIME [epoch: 9.02 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17649943061416265		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.17649943061416265 | validation: 0.16491867631178359]
	TIME [epoch: 9.04 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1664152311390479		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.1664152311390479 | validation: 0.1844048713668459]
	TIME [epoch: 9.05 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20168944078845724		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.20168944078845724 | validation: 0.3001149065127029]
	TIME [epoch: 9.04 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21230972339193147		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.21230972339193147 | validation: 0.20316944548543092]
	TIME [epoch: 9.03 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19163614545650448		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.19163614545650448 | validation: 0.20724611721338954]
	TIME [epoch: 9.03 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18818399828748025		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.18818399828748025 | validation: 0.17462463114743587]
	TIME [epoch: 9.05 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17550141222389395		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.17550141222389395 | validation: 0.17935915042151404]
	TIME [epoch: 9.03 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16466085910425843		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.16466085910425843 | validation: 0.18953978478628017]
	TIME [epoch: 9.03 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17473516166958786		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.17473516166958786 | validation: 0.20168983741310148]
	TIME [epoch: 9.02 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18486188727486963		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.18486188727486963 | validation: 0.19171559009750028]
	TIME [epoch: 9.03 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18036737819192414		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.18036737819192414 | validation: 0.19684801865955537]
	TIME [epoch: 9.05 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17364216757162426		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.17364216757162426 | validation: 0.18072267591482855]
	TIME [epoch: 9.03 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17181681919951533		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.17181681919951533 | validation: 0.1632800942487438]
	TIME [epoch: 9.04 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18674313588284286		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.18674313588284286 | validation: 0.19547236010632954]
	TIME [epoch: 9.04 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18235701473647142		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.18235701473647142 | validation: 0.17153478884457748]
	TIME [epoch: 9.05 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.166180857925805		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.166180857925805 | validation: 0.20683542948368128]
	TIME [epoch: 9.05 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17358625844003245		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.17358625844003245 | validation: 0.20849926643488934]
	TIME [epoch: 9.05 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17359795449783136		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.17359795449783136 | validation: 0.21725835391500442]
	TIME [epoch: 9.05 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17541625142333414		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.17541625142333414 | validation: 0.1866534909137872]
	TIME [epoch: 9.04 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16857532906382236		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.16857532906382236 | validation: 0.18039262364820813]
	TIME [epoch: 9.07 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16339467892020226		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.16339467892020226 | validation: 0.17367299017684235]
	TIME [epoch: 9.04 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1752492387922481		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.1752492387922481 | validation: 0.2517207295092239]
	TIME [epoch: 9.04 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23083787816947368		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.23083787816947368 | validation: 0.26602210984172847]
	TIME [epoch: 9.04 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21063567297556962		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.21063567297556962 | validation: 0.20894151023024554]
	TIME [epoch: 9.03 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1906606058590668		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.1906606058590668 | validation: 0.19193761393887165]
	TIME [epoch: 9.06 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16562645132590106		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.16562645132590106 | validation: 0.1759262872049501]
	TIME [epoch: 9.03 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16992072692813112		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.16992072692813112 | validation: 0.17998322701602987]
	TIME [epoch: 9.04 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17182366539221877		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.17182366539221877 | validation: 0.18423520178118585]
	TIME [epoch: 9.04 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16914216660566395		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.16914216660566395 | validation: 0.1852817163650514]
	TIME [epoch: 9.05 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16093692360219108		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.16093692360219108 | validation: 0.17341086911940667]
	TIME [epoch: 9.07 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15608734572950328		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.15608734572950328 | validation: 0.17670426668576583]
	TIME [epoch: 9.05 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16615162871502603		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.16615162871502603 | validation: 0.17030080508007772]
	TIME [epoch: 9.05 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19295542036677482		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.19295542036677482 | validation: 0.23136094305088595]
	TIME [epoch: 9.04 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18361686947120254		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.18361686947120254 | validation: 0.222881118117557]
	TIME [epoch: 9.06 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1876837226087289		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.1876837226087289 | validation: 0.1671734008685375]
	TIME [epoch: 9.05 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17611578917612755		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.17611578917612755 | validation: 0.21683016178872627]
	TIME [epoch: 9.05 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.189888213793645		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.189888213793645 | validation: 0.19762014685588966]
	TIME [epoch: 9.03 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18907280128661802		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.18907280128661802 | validation: 0.1775927096336095]
	TIME [epoch: 9.05 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1747269401735656		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.1747269401735656 | validation: 0.1631601953718226]
	TIME [epoch: 9.05 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17419725295808072		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.17419725295808072 | validation: 0.16709636006873613]
	TIME [epoch: 9.03 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16091473694129552		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.16091473694129552 | validation: 0.1683119303556438]
	TIME [epoch: 9.02 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16501893101420254		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.16501893101420254 | validation: 0.19240439460748554]
	TIME [epoch: 9.04 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1860894146274118		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.1860894146274118 | validation: 0.1738550020273839]
	TIME [epoch: 9.05 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1717953696529261		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.1717953696529261 | validation: 0.16500760747219523]
	TIME [epoch: 9.04 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18547821284453453		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.18547821284453453 | validation: 0.1770731187878103]
	TIME [epoch: 9.03 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17527044277687312		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.17527044277687312 | validation: 0.19221707765528073]
	TIME [epoch: 9.03 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1989319578092618		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.1989319578092618 | validation: 0.16833584808690186]
	TIME [epoch: 9.03 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16930124191000392		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.16930124191000392 | validation: 0.18753963603486812]
	TIME [epoch: 9.05 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1844534238503612		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.1844534238503612 | validation: 0.18154765656546953]
	TIME [epoch: 9.03 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18484574680642657		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.18484574680642657 | validation: 0.1733596704905962]
	TIME [epoch: 9.04 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17650937707719186		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.17650937707719186 | validation: 0.1976901800293258]
	TIME [epoch: 9.03 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16984502769327958		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.16984502769327958 | validation: 0.17006312419798544]
	TIME [epoch: 9.05 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1602286754335037		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.1602286754335037 | validation: 0.1717047437422551]
	TIME [epoch: 9.04 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15795511421123218		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.15795511421123218 | validation: 0.16780846330069005]
	TIME [epoch: 9.03 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1613592408181766		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.1613592408181766 | validation: 0.166726311888435]
	TIME [epoch: 9.04 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1701747836959456		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.1701747836959456 | validation: 0.1559580751366727]
	TIME [epoch: 9.04 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17505205458462683		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.17505205458462683 | validation: 0.16941485877007822]
	TIME [epoch: 9.06 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17302178612846186		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.17302178612846186 | validation: 0.17556387937401902]
	TIME [epoch: 9.03 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15466014836033537		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.15466014836033537 | validation: 0.17349003300774654]
	TIME [epoch: 9.02 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16843803800673313		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.16843803800673313 | validation: 0.22850326210865263]
	TIME [epoch: 9.04 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18831894481868766		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.18831894481868766 | validation: 0.1878288787926347]
	TIME [epoch: 9.04 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18887067058737655		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.18887067058737655 | validation: 0.15903604526457887]
	TIME [epoch: 9.05 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15336077090971828		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.15336077090971828 | validation: 0.16387399278061415]
	TIME [epoch: 9.04 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16891398587634116		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.16891398587634116 | validation: 0.16631053616865732]
	TIME [epoch: 9.03 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.156138273619518		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.156138273619518 | validation: 0.170311776683861]
	TIME [epoch: 9.02 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1552378352668366		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.1552378352668366 | validation: 0.17949804128513064]
	TIME [epoch: 9.06 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16017718571972878		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.16017718571972878 | validation: 0.16376901872104732]
	TIME [epoch: 9.03 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1578648992588432		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.1578648992588432 | validation: 0.17123564333970884]
	TIME [epoch: 9.03 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15819463981753015		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.15819463981753015 | validation: 0.18306231787857036]
	TIME [epoch: 9.04 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16818101912730749		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.16818101912730749 | validation: 0.1812107122562302]
	TIME [epoch: 9.04 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16709558533964564		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.16709558533964564 | validation: 0.17153054391147043]
	TIME [epoch: 9.06 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15789340313185735		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.15789340313185735 | validation: 0.21744885507150233]
	TIME [epoch: 9.03 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21637933376048196		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.21637933376048196 | validation: 0.19376331183198708]
	TIME [epoch: 9.03 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17004614803830118		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.17004614803830118 | validation: 0.1891268179073037]
	TIME [epoch: 9.03 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16988052370658682		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.16988052370658682 | validation: 0.16970663305237588]
	TIME [epoch: 9.05 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16510518261356266		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.16510518261356266 | validation: 0.15118991963223774]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_791.pth
	Model improved!!!
EPOCH 792/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.165486838537835		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.165486838537835 | validation: 0.20852198749801187]
	TIME [epoch: 9.03 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1924243610193161		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.1924243610193161 | validation: 0.17477380090067474]
	TIME [epoch: 9.03 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1687833933086926		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.1687833933086926 | validation: 0.1841339059298373]
	TIME [epoch: 9.02 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16570088706566583		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.16570088706566583 | validation: 0.16516789401822818]
	TIME [epoch: 9.05 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15980749090531746		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.15980749090531746 | validation: 0.16353602476256862]
	TIME [epoch: 9.02 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14568118337220834		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.14568118337220834 | validation: 0.1452402858937872]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_797.pth
	Model improved!!!
EPOCH 798/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15822351110104543		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.15822351110104543 | validation: 0.17589954463946617]
	TIME [epoch: 9.05 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1586900376674048		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.1586900376674048 | validation: 0.16920544612723154]
	TIME [epoch: 9.06 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1651620918674394		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.1651620918674394 | validation: 0.16993814441037658]
	TIME [epoch: 9.06 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1567076970933303		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.1567076970933303 | validation: 0.1721041774449799]
	TIME [epoch: 9.05 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15661442264374725		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.15661442264374725 | validation: 0.18460897158709294]
	TIME [epoch: 9.05 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1781975966903277		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.1781975966903277 | validation: 0.1998677714559051]
	TIME [epoch: 9.05 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.161992975110176		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.161992975110176 | validation: 0.1678033649608658]
	TIME [epoch: 9.05 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1767830749997356		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.1767830749997356 | validation: 0.1949725467885084]
	TIME [epoch: 9.07 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17580701050794184		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.17580701050794184 | validation: 0.1721674298356569]
	TIME [epoch: 9.06 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15163417732130097		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.15163417732130097 | validation: 0.16924316781722065]
	TIME [epoch: 9.05 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15738381382503633		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.15738381382503633 | validation: 0.1590907222080388]
	TIME [epoch: 9.05 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.154957162235547		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.154957162235547 | validation: 0.169739934798184]
	TIME [epoch: 9.05 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15413760784741262		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.15413760784741262 | validation: 0.15207680732511425]
	TIME [epoch: 9.07 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15587171239491524		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.15587171239491524 | validation: 0.16571723783499973]
	TIME [epoch: 9.07 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16118570138060545		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.16118570138060545 | validation: 0.16006614565145516]
	TIME [epoch: 9.06 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15499970160511187		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.15499970160511187 | validation: 0.16266466328836965]
	TIME [epoch: 9.06 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15517937322340203		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.15517937322340203 | validation: 0.18555952122986846]
	TIME [epoch: 9.05 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19001256977283007		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.19001256977283007 | validation: 0.16600409094550722]
	TIME [epoch: 9.07 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16306008400341448		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.16306008400341448 | validation: 0.18537412759628197]
	TIME [epoch: 9.05 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15910897768287097		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.15910897768287097 | validation: 0.17623078795812058]
	TIME [epoch: 9.05 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15295399459026268		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.15295399459026268 | validation: 0.16444596410340764]
	TIME [epoch: 9.05 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15375083254601613		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.15375083254601613 | validation: 0.17630371210561224]
	TIME [epoch: 9.07 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15946960733546384		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.15946960733546384 | validation: 0.17168584054824776]
	TIME [epoch: 9.06 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15440402270267184		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.15440402270267184 | validation: 0.17474304972973892]
	TIME [epoch: 9.05 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15800756412296363		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.15800756412296363 | validation: 0.1663485083374437]
	TIME [epoch: 9.05 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15247232125244578		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.15247232125244578 | validation: 0.17530244304098647]
	TIME [epoch: 9.05 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16459374800704346		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.16459374800704346 | validation: 0.17030036866792564]
	TIME [epoch: 9.08 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1695329764560039		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.1695329764560039 | validation: 0.19256676147651]
	TIME [epoch: 9.06 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16038395785847456		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.16038395785847456 | validation: 0.17587911448085292]
	TIME [epoch: 9.06 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.185438405704149		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.185438405704149 | validation: 0.20357253750615778]
	TIME [epoch: 9.06 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16648952312240634		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.16648952312240634 | validation: 0.18709730170636812]
	TIME [epoch: 9.06 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1695040270070107		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.1695040270070107 | validation: 0.19790436324902727]
	TIME [epoch: 9.07 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17690918882637668		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.17690918882637668 | validation: 0.18166100981000066]
	TIME [epoch: 9.05 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18294721442282863		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.18294721442282863 | validation: 0.19619243596367503]
	TIME [epoch: 9.05 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1764491038856749		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.1764491038856749 | validation: 0.1793788063496881]
	TIME [epoch: 9.05 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17069456670965052		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.17069456670965052 | validation: 0.1956698002735281]
	TIME [epoch: 9.07 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1832941397199333		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.1832941397199333 | validation: 0.19438785637433154]
	TIME [epoch: 9.05 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1716045807183713		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.1716045807183713 | validation: 0.18901935368869482]
	TIME [epoch: 9.05 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18566615200124237		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.18566615200124237 | validation: 0.19227003370298196]
	TIME [epoch: 9.05 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17398850938049062		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.17398850938049062 | validation: 0.19325065117770474]
	TIME [epoch: 9.07 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18253102872058696		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.18253102872058696 | validation: 0.1876983390239347]
	TIME [epoch: 9.08 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1702691228730437		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.1702691228730437 | validation: 0.17699884677066602]
	TIME [epoch: 9.06 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16122452961015363		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.16122452961015363 | validation: 0.16430097588960058]
	TIME [epoch: 9.05 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15645701247075539		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.15645701247075539 | validation: 0.17699384959228304]
	TIME [epoch: 9.06 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17323720822067085		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.17323720822067085 | validation: 0.1816054123067024]
	TIME [epoch: 9.07 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16702984909769905		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.16702984909769905 | validation: 0.19122581675490585]
	TIME [epoch: 9.06 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17011066157761898		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.17011066157761898 | validation: 0.18460593220215232]
	TIME [epoch: 9.06 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16878054524001762		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.16878054524001762 | validation: 0.1918753578820222]
	TIME [epoch: 9.06 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16943010441385534		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.16943010441385534 | validation: 0.19749044328872567]
	TIME [epoch: 9.06 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16499655488404102		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.16499655488404102 | validation: 0.1770945904486107]
	TIME [epoch: 9.09 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16301950630415757		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.16301950630415757 | validation: 0.17411980854667075]
	TIME [epoch: 9.05 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15625463118408267		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.15625463118408267 | validation: 0.17672064546737368]
	TIME [epoch: 9.06 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15432415302045438		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.15432415302045438 | validation: 0.16263344334193264]
	TIME [epoch: 9.07 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1560061855883766		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.1560061855883766 | validation: 0.17733884893074375]
	TIME [epoch: 9.07 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.169843042627109		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.169843042627109 | validation: 0.18102184053111312]
	TIME [epoch: 9.08 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1569806582716744		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.1569806582716744 | validation: 0.15943359122781908]
	TIME [epoch: 9.05 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15145128410769712		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.15145128410769712 | validation: 0.18119984345224488]
	TIME [epoch: 9.05 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1548401510028768		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.1548401510028768 | validation: 0.1649552746670333]
	TIME [epoch: 9.05 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15635156158273472		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.15635156158273472 | validation: 0.15611394235278908]
	TIME [epoch: 9.08 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15934177448014658		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.15934177448014658 | validation: 0.1653933730114452]
	TIME [epoch: 9.06 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14768671290186647		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.14768671290186647 | validation: 0.1578573462628768]
	TIME [epoch: 9.04 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15423554755082078		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.15423554755082078 | validation: 0.20674616878124563]
	TIME [epoch: 9.05 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1750240968900624		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.1750240968900624 | validation: 0.16993492780075314]
	TIME [epoch: 9.05 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15940468851179873		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.15940468851179873 | validation: 0.17050143257951794]
	TIME [epoch: 9.07 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15674037875275817		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.15674037875275817 | validation: 0.16079553277086167]
	TIME [epoch: 9.05 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14520209455954314		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.14520209455954314 | validation: 0.16515861963188228]
	TIME [epoch: 9.06 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.148864992287092		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.148864992287092 | validation: 0.16876008132976056]
	TIME [epoch: 9.06 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14967763168805723		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.14967763168805723 | validation: 0.1577741313155066]
	TIME [epoch: 9.07 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1492727578685024		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.1492727578685024 | validation: 0.14704500212740715]
	TIME [epoch: 9.05 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1488134232187349		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.1488134232187349 | validation: 0.15756988985152068]
	TIME [epoch: 9.06 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14939570176983422		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.14939570176983422 | validation: 0.16352103104061294]
	TIME [epoch: 9.05 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14670772885566857		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.14670772885566857 | validation: 0.16384710931250435]
	TIME [epoch: 9.05 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15146544924015987		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.15146544924015987 | validation: 0.15747273575710435]
	TIME [epoch: 9.08 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15026062776327315		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.15026062776327315 | validation: 0.16923815488695443]
	TIME [epoch: 9.05 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15770133350072618		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.15770133350072618 | validation: 0.17292852567367792]
	TIME [epoch: 9.05 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1519913656372266		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.1519913656372266 | validation: 0.16793577092342044]
	TIME [epoch: 9.05 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15676703409828505		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.15676703409828505 | validation: 0.1608876542699492]
	TIME [epoch: 9.06 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14790912513440282		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.14790912513440282 | validation: 0.16119847833598006]
	TIME [epoch: 9.07 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15550331019045335		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.15550331019045335 | validation: 0.16519144516355272]
	TIME [epoch: 9.06 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15803098709888297		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.15803098709888297 | validation: 0.1686016552903618]
	TIME [epoch: 9.06 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16392384592346693		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.16392384592346693 | validation: 0.17381101396562756]
	TIME [epoch: 9.06 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16964872682611398		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.16964872682611398 | validation: 0.16911163233720913]
	TIME [epoch: 9.08 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17239331757620865		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.17239331757620865 | validation: 0.17059745819870625]
	TIME [epoch: 9.05 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15996160196142178		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.15996160196142178 | validation: 0.1792971150191666]
	TIME [epoch: 9.05 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1826567914162259		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.1826567914162259 | validation: 0.2216226171845045]
	TIME [epoch: 9.05 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1765357205075159		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.1765357205075159 | validation: 0.18285115440805202]
	TIME [epoch: 9.06 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1604079730419442		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.1604079730419442 | validation: 0.1611272002210408]
	TIME [epoch: 9.06 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15381272702306464		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.15381272702306464 | validation: 0.1656941027215289]
	TIME [epoch: 9.05 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1582096901209435		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.1582096901209435 | validation: 0.17428729724422937]
	TIME [epoch: 9.04 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15650649521591176		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.15650649521591176 | validation: 0.16730195140839715]
	TIME [epoch: 9.05 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15053857999382855		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.15053857999382855 | validation: 0.1665803424324318]
	TIME [epoch: 9.08 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14961133230753276		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.14961133230753276 | validation: 0.17780384272655475]
	TIME [epoch: 9.05 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16439386192986594		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.16439386192986594 | validation: 0.1658898985727052]
	TIME [epoch: 9.05 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15449946869338704		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.15449946869338704 | validation: 0.1605296438246953]
	TIME [epoch: 9.05 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.152419987012217		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.152419987012217 | validation: 0.16864785560046658]
	TIME [epoch: 9.06 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15598816177907898		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.15598816177907898 | validation: 0.1603352213695084]
	TIME [epoch: 9.06 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16294103293079085		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.16294103293079085 | validation: 0.16992268318396775]
	TIME [epoch: 9.04 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16271625795624306		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.16271625795624306 | validation: 0.19843015782624945]
	TIME [epoch: 9.05 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17601506052197027		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.17601506052197027 | validation: 0.16747647057578935]
	TIME [epoch: 9.04 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1509664733197294		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.1509664733197294 | validation: 0.15652222564082102]
	TIME [epoch: 9.07 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14770159924201282		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.14770159924201282 | validation: 0.16758092917745276]
	TIME [epoch: 9.06 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15253301985112003		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.15253301985112003 | validation: 0.1560630620384772]
	TIME [epoch: 9.05 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1628974217869474		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.1628974217869474 | validation: 0.14453452247632476]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_900.pth
	Model improved!!!
EPOCH 901/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15333562050415084		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.15333562050415084 | validation: 0.1621689551443934]
	TIME [epoch: 9.05 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15857481311433136		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.15857481311433136 | validation: 0.15460431280057874]
	TIME [epoch: 9.08 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1589045759152999		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.1589045759152999 | validation: 0.18172776185903125]
	TIME [epoch: 9.05 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1657952421431979		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.1657952421431979 | validation: 0.17249236364689002]
	TIME [epoch: 9.05 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15942268445862473		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.15942268445862473 | validation: 0.1622330135336692]
	TIME [epoch: 9.05 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15293092200137542		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.15293092200137542 | validation: 0.16150530005712785]
	TIME [epoch: 9.04 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15949869396281033		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.15949869396281033 | validation: 0.1637223811650284]
	TIME [epoch: 9.07 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15695550480128323		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.15695550480128323 | validation: 0.15660665501345117]
	TIME [epoch: 9.05 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15642745911538722		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.15642745911538722 | validation: 0.15821324932203845]
	TIME [epoch: 9.04 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1567035548739561		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.1567035548739561 | validation: 0.15539010171320156]
	TIME [epoch: 9.05 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14621780613897278		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.14621780613897278 | validation: 0.15732358099756558]
	TIME [epoch: 9.05 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15447550215947356		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.15447550215947356 | validation: 0.1657229653493748]
	TIME [epoch: 9.07 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15567365411601622		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.15567365411601622 | validation: 0.16743998020441533]
	TIME [epoch: 9.04 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15677984784626345		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.15677984784626345 | validation: 0.1711278173430289]
	TIME [epoch: 9.04 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16433693781873498		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.16433693781873498 | validation: 0.16797062665097717]
	TIME [epoch: 9.05 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16102794406241466		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.16102794406241466 | validation: 0.16589885538515686]
	TIME [epoch: 9.06 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1638097042380695		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.1638097042380695 | validation: 0.17736712187720444]
	TIME [epoch: 9.07 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16260306034922345		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.16260306034922345 | validation: 0.1607324166882755]
	TIME [epoch: 9.05 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15278333238630565		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.15278333238630565 | validation: 0.15597560093214646]
	TIME [epoch: 9.04 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1523224239546435		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.1523224239546435 | validation: 0.17003202399707307]
	TIME [epoch: 9.05 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16256471634842298		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.16256471634842298 | validation: 0.17770461696899997]
	TIME [epoch: 9.07 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15980842961188824		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.15980842961188824 | validation: 0.18458366546369182]
	TIME [epoch: 9.05 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16036153414671706		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.16036153414671706 | validation: 0.183518362364688]
	TIME [epoch: 9.04 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1540116161637249		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.1540116161637249 | validation: 0.16322037561765226]
	TIME [epoch: 9.04 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14533769137508698		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.14533769137508698 | validation: 0.1543358966367926]
	TIME [epoch: 9.05 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14712332216594612		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.14712332216594612 | validation: 0.16778711212331443]
	TIME [epoch: 9.07 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14857765214217206		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.14857765214217206 | validation: 0.15451095994568148]
	TIME [epoch: 9.05 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1481273970362329		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.1481273970362329 | validation: 0.15507531946103492]
	TIME [epoch: 9.05 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1537850135568883		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.1537850135568883 | validation: 0.15903431892436218]
	TIME [epoch: 9.05 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15243118281786733		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.15243118281786733 | validation: 0.1561879377449671]
	TIME [epoch: 9.06 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15742438409435205		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.15742438409435205 | validation: 0.18764382287761994]
	TIME [epoch: 9.08 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16937440011934787		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.16937440011934787 | validation: 0.1528365189196271]
	TIME [epoch: 9.04 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15022186304403312		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.15022186304403312 | validation: 0.16220957605984687]
	TIME [epoch: 9.04 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1473859853522942		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.1473859853522942 | validation: 0.1675228358724459]
	TIME [epoch: 9.04 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1646758398551745		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.1646758398551745 | validation: 0.18324158392964607]
	TIME [epoch: 9.07 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16202228959099613		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.16202228959099613 | validation: 0.16755209817130956]
	TIME [epoch: 9.06 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15210225908637393		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.15210225908637393 | validation: 0.16334051820816287]
	TIME [epoch: 9.05 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1486782803850771		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.1486782803850771 | validation: 0.14790437369094778]
	TIME [epoch: 9.06 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14468332601211095		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.14468332601211095 | validation: 0.15967241787594177]
	TIME [epoch: 9.05 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15754014751579806		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.15754014751579806 | validation: 0.15815808822612576]
	TIME [epoch: 9.08 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1551202172714594		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.1551202172714594 | validation: 0.1690125684707372]
	TIME [epoch: 9.05 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.152376056726312		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.152376056726312 | validation: 0.1655917809742939]
	TIME [epoch: 9.05 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15584488242801625		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.15584488242801625 | validation: 0.15550945453005627]
	TIME [epoch: 9.06 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1508308355119808		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.1508308355119808 | validation: 0.1720718273530905]
	TIME [epoch: 9.07 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15440090701875003		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.15440090701875003 | validation: 0.1452055031496448]
	TIME [epoch: 9.07 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14608681365684228		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.14608681365684228 | validation: 0.1491510119539226]
	TIME [epoch: 9.05 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15149429869225747		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.15149429869225747 | validation: 0.1685354231406322]
	TIME [epoch: 9.05 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14996325980760183		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.14996325980760183 | validation: 0.16611424767983818]
	TIME [epoch: 9.06 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15750697701331093		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.15750697701331093 | validation: 0.16280018941417962]
	TIME [epoch: 9.08 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1541854781879089		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.1541854781879089 | validation: 0.15602118104798257]
	TIME [epoch: 9.06 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15024136990136566		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.15024136990136566 | validation: 0.1678550079906816]
	TIME [epoch: 9.06 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15909056349983713		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.15909056349983713 | validation: 0.15527618773937013]
	TIME [epoch: 9.06 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15331450435432986		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.15331450435432986 | validation: 0.1667450755815213]
	TIME [epoch: 9.08 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1467717650580453		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.1467717650580453 | validation: 0.1610238911503562]
	TIME [epoch: 9.07 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14830956945771637		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.14830956945771637 | validation: 0.14976022244366916]
	TIME [epoch: 9.06 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1479178522818227		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.1479178522818227 | validation: 0.16700211518992675]
	TIME [epoch: 9.06 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14352295393654008		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.14352295393654008 | validation: 0.1443762473153623]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240218_115025/states/model_tr_study3_957.pth
	Model improved!!!
EPOCH 958/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14696216923741787		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.14696216923741787 | validation: 0.1543626603726]
	TIME [epoch: 9.08 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14761029748961466		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.14761029748961466 | validation: 0.16008489106463986]
	TIME [epoch: 9.05 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14964595427420807		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.14964595427420807 | validation: 0.1513399964736794]
	TIME [epoch: 9.04 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1645320509933668		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.1645320509933668 | validation: 0.16752835620474932]
	TIME [epoch: 9.04 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15187288800432		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.15187288800432 | validation: 0.14674132993632683]
	TIME [epoch: 9.04 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15241052587287757		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.15241052587287757 | validation: 0.1623826595331443]
	TIME [epoch: 9.06 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15442721035584211		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.15442721035584211 | validation: 0.15708003580106591]
	TIME [epoch: 9.05 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1424806542024346		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.1424806542024346 | validation: 0.1492566023115051]
	TIME [epoch: 9.04 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14097035915768122		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.14097035915768122 | validation: 0.15393530983629933]
	TIME [epoch: 9.05 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15079684917627262		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.15079684917627262 | validation: 0.1540299271056632]
	TIME [epoch: 9.05 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14681856061386678		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.14681856061386678 | validation: 0.15913078831530542]
	TIME [epoch: 9.06 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1461894520923987		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.1461894520923987 | validation: 0.16007822695720803]
	TIME [epoch: 9.05 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1529156035220633		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.1529156035220633 | validation: 0.16339651337262456]
	TIME [epoch: 9.04 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1476125245180374		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.1476125245180374 | validation: 0.15701734639931705]
	TIME [epoch: 9.05 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14465404556827502		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.14465404556827502 | validation: 0.15404684547711828]
	TIME [epoch: 9.05 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14951499487797917		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.14951499487797917 | validation: 0.15135526145969913]
	TIME [epoch: 9.08 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14490764196819275		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.14490764196819275 | validation: 0.16188709542463475]
	TIME [epoch: 9.05 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14976338094829847		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.14976338094829847 | validation: 0.1455991912376463]
	TIME [epoch: 9.05 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14309537128884203		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.14309537128884203 | validation: 0.15734453004810334]
	TIME [epoch: 9.05 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14755006704524934		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.14755006704524934 | validation: 0.15901354851790822]
	TIME [epoch: 9.07 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15261751511679364		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.15261751511679364 | validation: 0.15661542501145348]
	TIME [epoch: 9.06 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15333947173213094		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.15333947173213094 | validation: 0.1521341351382625]
	TIME [epoch: 9.05 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15303861996848941		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.15303861996848941 | validation: 0.15462788288112733]
	TIME [epoch: 9.05 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15281163195809713		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.15281163195809713 | validation: 0.14796348661090689]
	TIME [epoch: 9.05 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1495760983465265		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.1495760983465265 | validation: 0.158552182171087]
	TIME [epoch: 9.07 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1491159440829096		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.1491159440829096 | validation: 0.1514714304187308]
	TIME [epoch: 9.05 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15241059599484644		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.15241059599484644 | validation: 0.16445265350725802]
	TIME [epoch: 9.05 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1500693696225856		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.1500693696225856 | validation: 0.1605071144961942]
	TIME [epoch: 9.05 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15293959001012722		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.15293959001012722 | validation: 0.16795357877943834]
	TIME [epoch: 9.06 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1558451681498894		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.1558451681498894 | validation: 0.16585526196569744]
	TIME [epoch: 9.06 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15207212704870127		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.15207212704870127 | validation: 0.1558032856284508]
	TIME [epoch: 9.04 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15044082303741618		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.15044082303741618 | validation: 0.15727698075038105]
	TIME [epoch: 9.05 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14672516799367025		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.14672516799367025 | validation: 0.15554838966311513]
	TIME [epoch: 9.04 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1533867437699908		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.1533867437699908 | validation: 0.1760034544909181]
	TIME [epoch: 9.07 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15248291899643882		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.15248291899643882 | validation: 0.1551022800579771]
	TIME [epoch: 9.05 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14262280626379925		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.14262280626379925 | validation: 0.14792534139906532]
	TIME [epoch: 9.05 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14495861767076051		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.14495861767076051 | validation: 0.15405027731838]
	TIME [epoch: 9.05 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14624796992858874		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.14624796992858874 | validation: 0.15866592602289753]
	TIME [epoch: 9.06 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14044220414774733		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.14044220414774733 | validation: 0.14886768132447692]
	TIME [epoch: 9.07 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14176529982545222		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.14176529982545222 | validation: 0.14841349458348285]
	TIME [epoch: 9.03 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15170524678237712		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.15170524678237712 | validation: 0.16298728268222057]
	TIME [epoch: 9 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14956626270687237		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.14956626270687237 | validation: 0.16149146225350616]
	TIME [epoch: 9 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1521378260798181		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.1521378260798181 | validation: 0.14620636981576063]
	TIME [epoch: 9 sec]
Finished training in 9143.036 seconds.
