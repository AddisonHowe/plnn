Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r0', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3295468319

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/10] avg loss: 10.81939143942722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.81939143942722 | validation: 9.940381056990406]
	TIME [epoch: 71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.78187390085775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.78187390085775 | validation: 8.239363942549929]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.242285304679195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.242285304679195 | validation: 10.23728938056962]
	TIME [epoch: 9.03 sec]
EPOCH 4/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.719751960020218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.719751960020218 | validation: 7.875915953086595]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.134752472812945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.134752472812945 | validation: 8.038534584436125]
	TIME [epoch: 9.01 sec]
EPOCH 6/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.237215072810386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.237215072810386 | validation: 8.202234483542277]
	TIME [epoch: 9.04 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.952130966541053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.952130966541053 | validation: 8.280673008079145]
	TIME [epoch: 9.02 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.980636253412381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.980636253412381 | validation: 8.937295232982564]
	TIME [epoch: 9.01 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.001872661997629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.001872661997629 | validation: 8.27789927990533]
	TIME [epoch: 9 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.824979961682478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.824979961682478 | validation: 7.604044773573982]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.960414516715913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.960414516715913 | validation: 8.439698690397197]
	TIME [epoch: 9.02 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.8396918137109735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.8396918137109735 | validation: 7.812169574139431]
	TIME [epoch: 9.01 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.8572139728101815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.8572139728101815 | validation: 7.5033612623077985]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.551265749415263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.551265749415263 | validation: 7.47047031126681]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.563311533083848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.563311533083848 | validation: 7.429689520006566]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.481937215224926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.481937215224926 | validation: 7.313848797262943]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.008031332140998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.008031332140998 | validation: 8.411174751314661]
	TIME [epoch: 9.03 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.4076106044602055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.4076106044602055 | validation: 7.673305555934636]
	TIME [epoch: 9.01 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.715321064509084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.715321064509084 | validation: 8.94513802315991]
	TIME [epoch: 9.02 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.632652576707647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.632652576707647 | validation: 7.681838946920207]
	TIME [epoch: 9.03 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.230534633799689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.230534633799689 | validation: 10.11660181912534]
	TIME [epoch: 9.01 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 10/10] avg loss: 10.88340048555623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.88340048555623 | validation: 10.409189166845342]
	TIME [epoch: 9 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 10/10] avg loss: 9.606102670929952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.606102670929952 | validation: 7.717672366749437]
	TIME [epoch: 9.01 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.381716212240543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.381716212240543 | validation: 7.357824960037417]
	TIME [epoch: 9.03 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 10/10] avg loss: 9.82964307042992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.82964307042992 | validation: 8.447379260259318]
	TIME [epoch: 9.02 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.952014945122851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.952014945122851 | validation: 10.28028924163177]
	TIME [epoch: 9.01 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/10] avg loss: 9.053633073818965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.053633073818965 | validation: 8.681534263351637]
	TIME [epoch: 9.01 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.543918649751137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.543918649751137 | validation: 7.259223432661667]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_28.pth
	Model improved!!!
EPOCH 29/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.126028806832752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.126028806832752 | validation: 7.158308029718929]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_29.pth
	Model improved!!!
EPOCH 30/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.976397884374724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.976397884374724 | validation: 7.246638390480202]
	TIME [epoch: 9.01 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.0851335766363395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.0851335766363395 | validation: 7.446764138519588]
	TIME [epoch: 9.01 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 10/10] avg loss: 9.587212594629367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.587212594629367 | validation: 9.47673495908594]
	TIME [epoch: 9.01 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.926203497751428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.926203497751428 | validation: 7.451871207881596]
	TIME [epoch: 9.02 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.245367258788716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.245367258788716 | validation: 7.037274085386128]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_34.pth
	Model improved!!!
EPOCH 35/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.22016934671412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.22016934671412 | validation: 7.349959655831344]
	TIME [epoch: 9.02 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.881377537689343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.881377537689343 | validation: 10.264355654437406]
	TIME [epoch: 9 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/10] avg loss: 9.812013810306969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.812013810306969 | validation: 9.344213516613472]
	TIME [epoch: 9.01 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.822612780141084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.822612780141084 | validation: 6.895201602457684]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_38.pth
	Model improved!!!
EPOCH 39/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.929691217397606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.929691217397606 | validation: 6.732682138449822]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_39.pth
	Model improved!!!
EPOCH 40/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.07964205823635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.07964205823635 | validation: 7.203400195878555]
	TIME [epoch: 9.01 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.1666217697733074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.1666217697733074 | validation: 8.023743266086466]
	TIME [epoch: 9.01 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.946082205314082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.946082205314082 | validation: 6.3593919569524]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.0324199959982305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0324199959982305 | validation: 5.771626958997032]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_43.pth
	Model improved!!!
EPOCH 44/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.18903615673343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.18903615673343 | validation: 4.700457185195211]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_44.pth
	Model improved!!!
EPOCH 45/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.4560765049673625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4560765049673625 | validation: 3.6630169888621253]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.894710165888153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.894710165888153 | validation: 2.7572721914028224]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_46.pth
	Model improved!!!
EPOCH 47/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.611682937999033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.611682937999033 | validation: 2.0335853112395474]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_47.pth
	Model improved!!!
EPOCH 48/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.37771375473942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.37771375473942 | validation: 2.014901848967639]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.4100423733228746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4100423733228746 | validation: 4.913287682423114]
	TIME [epoch: 9.02 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.8463984107715943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8463984107715943 | validation: 2.0306699022314207]
	TIME [epoch: 9.01 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.0549519650099377		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 3.0549519650099377 | validation: 2.3858023409420026]
	TIME [epoch: 9.01 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.4007409057125253		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 3.4007409057125253 | validation: 2.022387739314989]
	TIME [epoch: 9.04 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3839160177350296		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 2.3839160177350296 | validation: 2.2421933557436082]
	TIME [epoch: 9.01 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.636761893800255		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 2.636761893800255 | validation: 1.8705013631307508]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_54.pth
	Model improved!!!
EPOCH 55/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8729737662017574		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 1.8729737662017574 | validation: 2.1600030940949777]
	TIME [epoch: 9.02 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.9466034464989836		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 2.9466034464989836 | validation: 2.8066878530222565]
	TIME [epoch: 9.03 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.1041792186002617		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 2.1041792186002617 | validation: 1.596836815918783]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_57.pth
	Model improved!!!
EPOCH 58/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.035231192233937		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 2.035231192233937 | validation: 2.5315925806698925]
	TIME [epoch: 9.02 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0105649104347307		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 2.0105649104347307 | validation: 5.03328129667093]
	TIME [epoch: 9.02 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.5052734791452482		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 2.5052734791452482 | validation: 1.647819017139093]
	TIME [epoch: 9.01 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.66891287727261		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 2.66891287727261 | validation: 4.6710489083353774]
	TIME [epoch: 9.04 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.9453018191862097		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 2.9453018191862097 | validation: 1.8759496295503606]
	TIME [epoch: 9.02 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0026380271552013		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 2.0026380271552013 | validation: 2.1091391978118836]
	TIME [epoch: 9.01 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8446191425813638		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 1.8446191425813638 | validation: 1.5779775657846042]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_64.pth
	Model improved!!!
EPOCH 65/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0973790857156347		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 2.0973790857156347 | validation: 2.002129168806265]
	TIME [epoch: 9.01 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9598158480620385		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 1.9598158480620385 | validation: 1.9278931864868332]
	TIME [epoch: 9.03 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.250833819338744		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 2.250833819338744 | validation: 1.6147373778161365]
	TIME [epoch: 9.01 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.874262233035403		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 1.874262233035403 | validation: 2.5978108475849018]
	TIME [epoch: 9 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0788105386051776		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 2.0788105386051776 | validation: 1.6842342059465882]
	TIME [epoch: 9.01 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.709848389335037		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 1.709848389335037 | validation: 1.8080449967162766]
	TIME [epoch: 9.03 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8046294436714896		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 1.8046294436714896 | validation: 2.1524268311217685]
	TIME [epoch: 9.02 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9447779976651738		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 1.9447779976651738 | validation: 2.5424014229532936]
	TIME [epoch: 9.01 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9901809269774273		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 1.9901809269774273 | validation: 2.051155982558675]
	TIME [epoch: 9 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8061603001637105		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 1.8061603001637105 | validation: 1.9532740512522584]
	TIME [epoch: 9 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0736214847049848		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 2.0736214847049848 | validation: 2.2804677952085344]
	TIME [epoch: 9.03 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8680480546022977		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 1.8680480546022977 | validation: 1.7175075641084656]
	TIME [epoch: 9 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.620974959559387		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 1.620974959559387 | validation: 2.096136433059596]
	TIME [epoch: 9.01 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.2784788831485105		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 2.2784788831485105 | validation: 5.395636549644445]
	TIME [epoch: 9.01 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3633311144930116		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 2.3633311144930116 | validation: 4.627308990539882]
	TIME [epoch: 9.01 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.2139482702045328		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 2.2139482702045328 | validation: 1.987894541261435]
	TIME [epoch: 9.03 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7897977956848254		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 1.7897977956848254 | validation: 1.5427625092388224]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_81.pth
	Model improved!!!
EPOCH 82/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.913578077499577		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 1.913578077499577 | validation: 2.2010910960559276]
	TIME [epoch: 8.99 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.6749414544143306		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 2.6749414544143306 | validation: 2.591264131947077]
	TIME [epoch: 9 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8781223354065688		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 1.8781223354065688 | validation: 1.8034883298247417]
	TIME [epoch: 9.03 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8726058936282999		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 1.8726058936282999 | validation: 1.7775606590419426]
	TIME [epoch: 9.01 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7816821346628888		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 1.7816821346628888 | validation: 2.3277389692332395]
	TIME [epoch: 9.01 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9319025910098844		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 1.9319025910098844 | validation: 1.9260171803621768]
	TIME [epoch: 9 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7407730260600935		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 1.7407730260600935 | validation: 1.5213768832147516]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_88.pth
	Model improved!!!
EPOCH 89/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8534486751147312		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 1.8534486751147312 | validation: 2.0353787107657224]
	TIME [epoch: 9.04 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9930695694164988		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 1.9930695694164988 | validation: 2.0350499830638027]
	TIME [epoch: 9.01 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.719503830513646		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 1.719503830513646 | validation: 2.363776004651765]
	TIME [epoch: 9 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0100810417003148		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 2.0100810417003148 | validation: 1.4106756608080735]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_92.pth
	Model improved!!!
EPOCH 93/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7288219041683122		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 1.7288219041683122 | validation: 1.8540128431092784]
	TIME [epoch: 9.03 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9750334562485594		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 1.9750334562485594 | validation: 1.635840386717954]
	TIME [epoch: 9.02 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6440162402116525		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 1.6440162402116525 | validation: 1.4485200847222877]
	TIME [epoch: 9.01 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7554531257057486		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 1.7554531257057486 | validation: 2.782063468313509]
	TIME [epoch: 9.01 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8676081561020266		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 1.8676081561020266 | validation: 2.070737200155718]
	TIME [epoch: 9.01 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7056348379549504		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 1.7056348379549504 | validation: 1.3341121907889013]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_98.pth
	Model improved!!!
EPOCH 99/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6600566672039854		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 1.6600566672039854 | validation: 1.4530852067985358]
	TIME [epoch: 9.01 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.494228208014579		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 1.494228208014579 | validation: 1.3935845479358107]
	TIME [epoch: 9.01 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6628378249604296		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 1.6628378249604296 | validation: 2.4713035348041164]
	TIME [epoch: 9 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9170253292888126		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 1.9170253292888126 | validation: 1.6333454070758393]
	TIME [epoch: 9.02 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7331415670245196		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 1.7331415670245196 | validation: 1.4321966212781096]
	TIME [epoch: 9.02 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9283466858524894		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 1.9283466858524894 | validation: 1.4387635444224074]
	TIME [epoch: 9 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4814844872489743		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 1.4814844872489743 | validation: 1.870667170379557]
	TIME [epoch: 9.01 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6238226809343579		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 1.6238226809343579 | validation: 1.688582256251383]
	TIME [epoch: 9.01 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5114046996474204		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 1.5114046996474204 | validation: 1.5328801842163562]
	TIME [epoch: 9.04 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.549966694137669		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 1.549966694137669 | validation: 1.335090268928176]
	TIME [epoch: 9.01 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.464223796173729		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 1.464223796173729 | validation: 1.5917190019006244]
	TIME [epoch: 9.01 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8925135358481378		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 1.8925135358481378 | validation: 1.758484970980971]
	TIME [epoch: 9.01 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.63867959884535		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 1.63867959884535 | validation: 1.6244198824160105]
	TIME [epoch: 9.01 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7015113743932535		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 1.7015113743932535 | validation: 1.6082016826846903]
	TIME [epoch: 9.04 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.565778088676919		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 1.565778088676919 | validation: 3.270025131233721]
	TIME [epoch: 9 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7270407875572764		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 1.7270407875572764 | validation: 1.341323161187082]
	TIME [epoch: 9.01 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9075719468180288		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 1.9075719468180288 | validation: 1.2873125727308898]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_115.pth
	Model improved!!!
EPOCH 116/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6006993269183116		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 1.6006993269183116 | validation: 1.3620615029252496]
	TIME [epoch: 9.02 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4485858415967003		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 1.4485858415967003 | validation: 1.5985390629181784]
	TIME [epoch: 9.01 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7903485625514821		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 1.7903485625514821 | validation: 1.9836852436979495]
	TIME [epoch: 9.01 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5305029601958489		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 1.5305029601958489 | validation: 1.3868257526711325]
	TIME [epoch: 9 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.818572460173969		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 1.818572460173969 | validation: 1.773342996854149]
	TIME [epoch: 9.01 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.458881169620991		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 1.458881169620991 | validation: 1.7417633765550717]
	TIME [epoch: 9.02 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7564467765097835		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 1.7564467765097835 | validation: 1.7357424364198755]
	TIME [epoch: 9.02 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8535385077231097		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 1.8535385077231097 | validation: 2.139281307311061]
	TIME [epoch: 9.02 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5642909694663698		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 1.5642909694663698 | validation: 1.4482562018740952]
	TIME [epoch: 9.01 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4797024212128975		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 1.4797024212128975 | validation: 1.359513169344366]
	TIME [epoch: 9.03 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4694019805217389		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 1.4694019805217389 | validation: 1.8428554700175397]
	TIME [epoch: 9.01 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5756287186245341		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 1.5756287186245341 | validation: 1.9797300352161784]
	TIME [epoch: 9.01 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5126024988225093		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 1.5126024988225093 | validation: 1.8667283787544897]
	TIME [epoch: 9.01 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5233101895919186		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 1.5233101895919186 | validation: 1.7533784246106832]
	TIME [epoch: 9 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.482466415306142		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 1.482466415306142 | validation: 2.0096406365905874]
	TIME [epoch: 9.03 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4410077140247863		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 1.4410077140247863 | validation: 1.3040016654790754]
	TIME [epoch: 9.01 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8273473431903695		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 1.8273473431903695 | validation: 1.2100451857720773]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_132.pth
	Model improved!!!
EPOCH 133/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4947166612740455		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 1.4947166612740455 | validation: 1.666629022351823]
	TIME [epoch: 9 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4521832091748013		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 1.4521832091748013 | validation: 1.6985817493444901]
	TIME [epoch: 8.99 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5511371536083034		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 1.5511371536083034 | validation: 1.8724176985501333]
	TIME [epoch: 9.03 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3885990492303275		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 1.3885990492303275 | validation: 1.7391731572117175]
	TIME [epoch: 9 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4230074250461104		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 1.4230074250461104 | validation: 1.4467718195034063]
	TIME [epoch: 9 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3614301274194411		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 1.3614301274194411 | validation: 1.5084537063747496]
	TIME [epoch: 9.01 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4698226933792182		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 1.4698226933792182 | validation: 1.5292352113545542]
	TIME [epoch: 9.01 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4552982652808677		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 1.4552982652808677 | validation: 1.4664689373843685]
	TIME [epoch: 9 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5769967779051186		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 1.5769967779051186 | validation: 1.2336421955879602]
	TIME [epoch: 8.99 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2900111846114768		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 1.2900111846114768 | validation: 1.1916046688520043]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_142.pth
	Model improved!!!
EPOCH 143/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3773215225405335		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 1.3773215225405335 | validation: 1.3268970922156555]
	TIME [epoch: 9.01 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3556789805683473		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 1.3556789805683473 | validation: 1.089566231058408]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_144.pth
	Model improved!!!
EPOCH 145/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1953334484505311		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 1.1953334484505311 | validation: 1.1910821716146995]
	TIME [epoch: 9.02 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3541408109433564		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 1.3541408109433564 | validation: 1.3332533721110953]
	TIME [epoch: 9.01 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2969082271774932		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 1.2969082271774932 | validation: 1.0726634234361123]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_147.pth
	Model improved!!!
EPOCH 148/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2976188905682478		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 1.2976188905682478 | validation: 1.6625794207049602]
	TIME [epoch: 9.01 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3185672915744844		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 1.3185672915744844 | validation: 1.642676573655657]
	TIME [epoch: 9.01 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4763532383031834		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 1.4763532383031834 | validation: 1.5063538532832923]
	TIME [epoch: 9.01 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3344074527750425		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 1.3344074527750425 | validation: 1.1334309647046978]
	TIME [epoch: 9.01 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3091812825603264		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 1.3091812825603264 | validation: 1.6273283897255815]
	TIME [epoch: 9 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.57053302098542		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 1.57053302098542 | validation: 1.4765132678722948]
	TIME [epoch: 9.02 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3947035884800147		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 1.3947035884800147 | validation: 1.2628508053343304]
	TIME [epoch: 8.99 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2311968856581228		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 1.2311968856581228 | validation: 1.319203191256701]
	TIME [epoch: 9 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2690066752361477		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 1.2690066752361477 | validation: 1.115785773075939]
	TIME [epoch: 9 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1943008258730572		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 1.1943008258730572 | validation: 1.053753679124271]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_157.pth
	Model improved!!!
EPOCH 158/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.345843022033558		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 1.345843022033558 | validation: 1.1659686051875155]
	TIME [epoch: 9.03 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2796394328369087		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 1.2796394328369087 | validation: 1.1309709362816256]
	TIME [epoch: 9 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1562678532874393		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 1.1562678532874393 | validation: 1.0875358357678135]
	TIME [epoch: 8.99 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2797386309896774		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 1.2797386309896774 | validation: 1.3276933201616268]
	TIME [epoch: 8.99 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2758095974829258		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 1.2758095974829258 | validation: 1.3341898424684588]
	TIME [epoch: 9 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3180874546834904		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 1.3180874546834904 | validation: 1.4839648969893031]
	TIME [epoch: 9.01 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.311377066049702		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 1.311377066049702 | validation: 1.1114405816548953]
	TIME [epoch: 8.99 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.170283448759088		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 1.170283448759088 | validation: 1.0568119929702844]
	TIME [epoch: 8.99 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1844458234939421		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 1.1844458234939421 | validation: 1.3593907904824998]
	TIME [epoch: 8.99 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2050445771144105		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 1.2050445771144105 | validation: 1.1389863458650427]
	TIME [epoch: 9.01 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2370709330370318		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 1.2370709330370318 | validation: 1.463631127087905]
	TIME [epoch: 9 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0965931987304383		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 1.0965931987304383 | validation: 1.3773560184734888]
	TIME [epoch: 8.99 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2196965186314401		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 1.2196965186314401 | validation: 0.9534791977101469]
	TIME [epoch: 8.99 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_170.pth
	Model improved!!!
EPOCH 171/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.193165675033962		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 1.193165675033962 | validation: 1.027366022486327]
	TIME [epoch: 9.02 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.262757013753612		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 1.262757013753612 | validation: 1.3048659566942935]
	TIME [epoch: 9.02 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1947123513707922		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 1.1947123513707922 | validation: 1.3742763907064195]
	TIME [epoch: 9.01 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1613002692438728		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 1.1613002692438728 | validation: 1.0342958098586719]
	TIME [epoch: 9 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1000002086838883		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 1.1000002086838883 | validation: 1.1432414652357181]
	TIME [epoch: 9.01 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1592747562684789		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 1.1592747562684789 | validation: 0.9217242125088891]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_176.pth
	Model improved!!!
EPOCH 177/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2445660488497008		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 1.2445660488497008 | validation: 1.3373543571587887]
	TIME [epoch: 9.02 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2713378330564056		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 1.2713378330564056 | validation: 1.1859831297649257]
	TIME [epoch: 9.01 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0933267339892612		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 1.0933267339892612 | validation: 0.9358707436566898]
	TIME [epoch: 9 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1460006134606544		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 1.1460006134606544 | validation: 0.9919920477766209]
	TIME [epoch: 9.01 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0737701600748562		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 1.0737701600748562 | validation: 1.2163771770158376]
	TIME [epoch: 9.03 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0763032552596172		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 1.0763032552596172 | validation: 0.9042468705157922]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_182.pth
	Model improved!!!
EPOCH 183/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1647106232658673		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 1.1647106232658673 | validation: 0.9178049073704362]
	TIME [epoch: 9 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1122195240340318		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 1.1122195240340318 | validation: 0.8712021368268168]
	TIME [epoch: 8.98 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_184.pth
	Model improved!!!
EPOCH 185/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9606095275920854		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.9606095275920854 | validation: 0.8323054396944485]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_185.pth
	Model improved!!!
EPOCH 186/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.05820448915424		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 1.05820448915424 | validation: 1.0903194970021974]
	TIME [epoch: 9.02 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0446902455227824		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 1.0446902455227824 | validation: 0.9451020747868568]
	TIME [epoch: 9 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.075027315125306		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 1.075027315125306 | validation: 1.0136724085581934]
	TIME [epoch: 8.99 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0366323038012584		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 1.0366323038012584 | validation: 0.8712282252426203]
	TIME [epoch: 9 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8885818916353377		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.8885818916353377 | validation: 0.9038391915687928]
	TIME [epoch: 9.02 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0212167963669505		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 1.0212167963669505 | validation: 0.9496611463879029]
	TIME [epoch: 9 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0407564997955583		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 1.0407564997955583 | validation: 1.2593060644215748]
	TIME [epoch: 8.99 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9940528195676712		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 0.9940528195676712 | validation: 0.9144953559666537]
	TIME [epoch: 8.99 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.129451769510471		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 1.129451769510471 | validation: 0.801733678047549]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_194.pth
	Model improved!!!
EPOCH 195/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.016352464012381		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 1.016352464012381 | validation: 0.9780377479970581]
	TIME [epoch: 9.04 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9821419229804282		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.9821419229804282 | validation: 1.169421460019065]
	TIME [epoch: 9.02 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9776507383186642		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.9776507383186642 | validation: 0.8126209193944987]
	TIME [epoch: 9.01 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0032094375709033		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 1.0032094375709033 | validation: 0.8444022484179046]
	TIME [epoch: 9.02 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0617126894804674		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 1.0617126894804674 | validation: 1.0856317890715796]
	TIME [epoch: 9.03 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0476098012956514		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 1.0476098012956514 | validation: 1.0862010362912997]
	TIME [epoch: 9.03 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9593667685230856		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.9593667685230856 | validation: 0.9235765680161038]
	TIME [epoch: 9.02 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.970637272400827		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.970637272400827 | validation: 0.8044854776811599]
	TIME [epoch: 9.01 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.077966316815908		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 1.077966316815908 | validation: 0.7740047310697202]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_203.pth
	Model improved!!!
EPOCH 204/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8642577333855392		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.8642577333855392 | validation: 1.290389983245468]
	TIME [epoch: 9.04 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0308303311808698		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 1.0308303311808698 | validation: 1.0452424354440168]
	TIME [epoch: 9.01 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0899523925750914		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 1.0899523925750914 | validation: 0.8387944862518943]
	TIME [epoch: 9.02 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9319646764656756		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.9319646764656756 | validation: 0.9529231533261799]
	TIME [epoch: 9.01 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0231710371231366		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 1.0231710371231366 | validation: 1.089860882070695]
	TIME [epoch: 9.02 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0264113884326143		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 1.0264113884326143 | validation: 0.811118618386605]
	TIME [epoch: 9.04 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9430265382356794		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.9430265382356794 | validation: 1.0324928173028125]
	TIME [epoch: 9.02 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8763709914440858		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.8763709914440858 | validation: 0.6783392750552473]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_211.pth
	Model improved!!!
EPOCH 212/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8855512053399719		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.8855512053399719 | validation: 0.9428143397546477]
	TIME [epoch: 9.02 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8436024796686926		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.8436024796686926 | validation: 0.7108135453324773]
	TIME [epoch: 9.04 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8312622558585556		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.8312622558585556 | validation: 0.927498815196393]
	TIME [epoch: 9.02 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8618878939122526		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.8618878939122526 | validation: 0.7174124262794437]
	TIME [epoch: 9.02 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.964760221352828		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.964760221352828 | validation: 0.9581891968967506]
	TIME [epoch: 9.03 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9100861747508141		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.9100861747508141 | validation: 0.7908252068423942]
	TIME [epoch: 9.02 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9577299139447447		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.9577299139447447 | validation: 0.7676045292179806]
	TIME [epoch: 9.04 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9831748044722761		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.9831748044722761 | validation: 0.7351782604614333]
	TIME [epoch: 9.01 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7392188816210907		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.7392188816210907 | validation: 0.5964289058526682]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_220.pth
	Model improved!!!
EPOCH 221/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7444752266736075		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.7444752266736075 | validation: 0.6308778073176069]
	TIME [epoch: 9.02 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8419144626947258		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.8419144626947258 | validation: 1.168432434209913]
	TIME [epoch: 9.03 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.045170231959497		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 1.045170231959497 | validation: 0.802759895868794]
	TIME [epoch: 9.02 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8377989700047997		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.8377989700047997 | validation: 0.9603821768358947]
	TIME [epoch: 9.02 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7976611676511608		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.7976611676511608 | validation: 0.8149962741179542]
	TIME [epoch: 9 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7697871970772022		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.7697871970772022 | validation: 0.9632648181908117]
	TIME [epoch: 9.01 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9041044480835085		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.9041044480835085 | validation: 1.1407455935546231]
	TIME [epoch: 9.04 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.789031294314039		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.789031294314039 | validation: 0.6146833473484483]
	TIME [epoch: 9.02 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8343760452703173		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.8343760452703173 | validation: 1.1104178738874237]
	TIME [epoch: 9.02 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9090192098134574		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.9090192098134574 | validation: 0.6425512708195438]
	TIME [epoch: 9.02 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.749841146734125		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.749841146734125 | validation: 0.803709085032924]
	TIME [epoch: 9.03 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9009902847876923		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.9009902847876923 | validation: 0.6683301846178875]
	TIME [epoch: 9.04 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7892330698024697		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.7892330698024697 | validation: 0.6685930012546902]
	TIME [epoch: 9.01 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7818319522766503		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.7818319522766503 | validation: 0.7709931586794068]
	TIME [epoch: 9.02 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7639344457436616		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.7639344457436616 | validation: 0.799618432371313]
	TIME [epoch: 9.01 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7961208005402014		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.7961208005402014 | validation: 0.5329166017078953]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_236.pth
	Model improved!!!
EPOCH 237/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7119887369387417		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.7119887369387417 | validation: 0.6256840607124481]
	TIME [epoch: 9.02 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7579948439743045		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.7579948439743045 | validation: 0.7688337289563691]
	TIME [epoch: 9.01 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7569444340258393		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.7569444340258393 | validation: 0.6757691715908827]
	TIME [epoch: 9.01 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8471944183223463		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.8471944183223463 | validation: 0.5236214310753691]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_240.pth
	Model improved!!!
EPOCH 241/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.833275668667708		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.833275668667708 | validation: 0.6091327732288734]
	TIME [epoch: 9.03 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6777230403404962		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.6777230403404962 | validation: 0.7576529847679101]
	TIME [epoch: 9.02 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7124469418252123		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.7124469418252123 | validation: 0.6725442988305433]
	TIME [epoch: 9.01 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7047778308442247		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.7047778308442247 | validation: 0.5128359732097296]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_244.pth
	Model improved!!!
EPOCH 245/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6719570685959868		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.6719570685959868 | validation: 0.4810479232250401]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_245.pth
	Model improved!!!
EPOCH 246/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6416336036581136		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.6416336036581136 | validation: 0.950826452498774]
	TIME [epoch: 9.01 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7699055737455149		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.7699055737455149 | validation: 0.6791470485985747]
	TIME [epoch: 9 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7146578065045804		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.7146578065045804 | validation: 0.6315647471566521]
	TIME [epoch: 9 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6463973921048506		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.6463973921048506 | validation: 0.7139245105215979]
	TIME [epoch: 9.01 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6439371010591024		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.6439371010591024 | validation: 0.6874089571585962]
	TIME [epoch: 9.01 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6253706478100248		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.6253706478100248 | validation: 0.5158805361577183]
	TIME [epoch: 9 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7756901017673481		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.7756901017673481 | validation: 0.8561638463363146]
	TIME [epoch: 9 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6578453283589878		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.6578453283589878 | validation: 0.58946410572265]
	TIME [epoch: 9 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7130417525741116		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.7130417525741116 | validation: 0.49704409089889146]
	TIME [epoch: 9.01 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6263177348940897		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.6263177348940897 | validation: 0.5288641720926059]
	TIME [epoch: 9.03 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5957814566660129		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.5957814566660129 | validation: 0.5475482811526613]
	TIME [epoch: 9.01 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6559569186395883		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.6559569186395883 | validation: 0.5888188373611039]
	TIME [epoch: 9 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6211662873777496		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.6211662873777496 | validation: 0.5396090162614151]
	TIME [epoch: 8.99 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6041203650716003		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.6041203650716003 | validation: 0.5423232902277323]
	TIME [epoch: 9.02 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5997997625914564		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.5997997625914564 | validation: 0.5649070566852182]
	TIME [epoch: 8.99 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6638073507625245		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.6638073507625245 | validation: 0.567797327412076]
	TIME [epoch: 9 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6534455622585076		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.6534455622585076 | validation: 0.5650413184018119]
	TIME [epoch: 9 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7002507796657842		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.7002507796657842 | validation: 0.6270485773670333]
	TIME [epoch: 9 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.579219173581916		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.579219173581916 | validation: 0.6145807700301587]
	TIME [epoch: 9.02 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6578329597264673		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.6578329597264673 | validation: 0.7364737552359313]
	TIME [epoch: 8.99 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6446033857718453		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.6446033857718453 | validation: 0.519072020285384]
	TIME [epoch: 9 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6549566491032076		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.6549566491032076 | validation: 0.59574088924]
	TIME [epoch: 9 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6364605121675938		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.6364605121675938 | validation: 0.5606376260299595]
	TIME [epoch: 9.01 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5834403632044405		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.5834403632044405 | validation: 0.6942522312890648]
	TIME [epoch: 9.02 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6310532188318211		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.6310532188318211 | validation: 0.5359174714087185]
	TIME [epoch: 9 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5357282848991485		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.5357282848991485 | validation: 0.49266833929655923]
	TIME [epoch: 9 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5339414431568643		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.5339414431568643 | validation: 0.37801195639152263]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_272.pth
	Model improved!!!
EPOCH 273/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.503569961710091		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.503569961710091 | validation: 0.5392843133838647]
	TIME [epoch: 9.02 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5757400949430498		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.5757400949430498 | validation: 0.5467835758414212]
	TIME [epoch: 9.01 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.517425564116447		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.517425564116447 | validation: 0.6563441507906429]
	TIME [epoch: 9 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5258977497928745		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.5258977497928745 | validation: 0.553355099084547]
	TIME [epoch: 9 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5723951616416172		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.5723951616416172 | validation: 0.46828365618637335]
	TIME [epoch: 9.01 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5600298237281147		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.5600298237281147 | validation: 0.43384615365574253]
	TIME [epoch: 9.02 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5484949081812711		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.5484949081812711 | validation: 0.5630570146131788]
	TIME [epoch: 9 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.540244270607675		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.540244270607675 | validation: 0.4907718773826854]
	TIME [epoch: 9 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5022840076077215		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.5022840076077215 | validation: 0.42181737306839734]
	TIME [epoch: 9 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5870362446341546		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.5870362446341546 | validation: 0.4874898840670788]
	TIME [epoch: 9.02 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5696441580514368		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.5696441580514368 | validation: 0.4273965698572561]
	TIME [epoch: 9.01 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4824920436812613		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.4824920436812613 | validation: 0.5828254133098996]
	TIME [epoch: 9 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5826430378529296		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.5826430378529296 | validation: 0.4546723198074562]
	TIME [epoch: 9 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5270786502210598		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.5270786502210598 | validation: 0.3877116984692599]
	TIME [epoch: 8.99 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5084062013110898		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.5084062013110898 | validation: 0.48825953685653745]
	TIME [epoch: 9.01 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5290617241660647		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.5290617241660647 | validation: 0.4612558901450986]
	TIME [epoch: 8.99 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.579679453878802		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.579679453878802 | validation: 0.6248660044612764]
	TIME [epoch: 9 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4549706461775269		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.4549706461775269 | validation: 0.3535567337942821]
	TIME [epoch: 8.99 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_290.pth
	Model improved!!!
EPOCH 291/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4552139855522251		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.4552139855522251 | validation: 0.42424459357587463]
	TIME [epoch: 9.01 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6706633522028438		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.6706633522028438 | validation: 0.4131195990864102]
	TIME [epoch: 9 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5856490182643579		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.5856490182643579 | validation: 0.7432435042106138]
	TIME [epoch: 8.99 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4902182535768187		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.4902182535768187 | validation: 0.4138990558910276]
	TIME [epoch: 8.99 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5197314421955497		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.5197314421955497 | validation: 0.6646742411572848]
	TIME [epoch: 9 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.472322325998303		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.472322325998303 | validation: 0.5395981876726105]
	TIME [epoch: 9.03 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46802282744562723		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.46802282744562723 | validation: 0.36140046384012986]
	TIME [epoch: 9.01 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4244530263585181		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.4244530263585181 | validation: 0.45782426874080767]
	TIME [epoch: 8.99 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4835669071240251		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.4835669071240251 | validation: 0.5076153326673899]
	TIME [epoch: 9 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4908414932946303		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.4908414932946303 | validation: 0.580815607273821]
	TIME [epoch: 8.99 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5186665209925263		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.5186665209925263 | validation: 0.45851839522313864]
	TIME [epoch: 9.02 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.532924346243149		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.532924346243149 | validation: 0.6762330993879239]
	TIME [epoch: 8.99 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5736245107018338		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.5736245107018338 | validation: 0.3811082326558989]
	TIME [epoch: 8.99 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5485094087263266		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.5485094087263266 | validation: 0.37762800441081495]
	TIME [epoch: 8.99 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5685083281987038		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.5685083281987038 | validation: 0.4516850924351976]
	TIME [epoch: 9.01 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5513777723713404		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.5513777723713404 | validation: 0.4477942458077893]
	TIME [epoch: 9.01 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4736216138584816		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.4736216138584816 | validation: 0.524833886267946]
	TIME [epoch: 9 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.454629752150996		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.454629752150996 | validation: 0.41109824903979775]
	TIME [epoch: 9 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42729276659436116		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.42729276659436116 | validation: 0.3396116463200278]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_309.pth
	Model improved!!!
EPOCH 310/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48708002174934284		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.48708002174934284 | validation: 0.7256551576598078]
	TIME [epoch: 9.03 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46391264894914064		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.46391264894914064 | validation: 0.45863419444197795]
	TIME [epoch: 9 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42149577743420064		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.42149577743420064 | validation: 0.35721423662099705]
	TIME [epoch: 9 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41315056668448047		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.41315056668448047 | validation: 0.44483264524172483]
	TIME [epoch: 8.99 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4411024532816693		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.4411024532816693 | validation: 0.3957821072953541]
	TIME [epoch: 9.01 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40735534711977417		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.40735534711977417 | validation: 0.5231762353209182]
	TIME [epoch: 9.01 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4661452691764138		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.4661452691764138 | validation: 0.4553162419496867]
	TIME [epoch: 9 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41046937907177916		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.41046937907177916 | validation: 0.49024777304430844]
	TIME [epoch: 8.99 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41878788159910973		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.41878788159910973 | validation: 0.3231540432408463]
	TIME [epoch: 8.99 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_318.pth
	Model improved!!!
EPOCH 319/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4764256104112003		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.4764256104112003 | validation: 0.44346379716047335]
	TIME [epoch: 9.02 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49713719931200123		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.49713719931200123 | validation: 0.45267884820399545]
	TIME [epoch: 9 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4301922751327008		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.4301922751327008 | validation: 0.3138481468992325]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_321.pth
	Model improved!!!
EPOCH 322/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.448489784657066		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.448489784657066 | validation: 0.37889202538046196]
	TIME [epoch: 9.01 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4431302707925936		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.4431302707925936 | validation: 0.4524017904786758]
	TIME [epoch: 9 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44194384356908945		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.44194384356908945 | validation: 0.3783766313662247]
	TIME [epoch: 9.03 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3671254814937622		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.3671254814937622 | validation: 0.3296464473260792]
	TIME [epoch: 9 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39176415853311075		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.39176415853311075 | validation: 0.35594990564526674]
	TIME [epoch: 9 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4164973144859145		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.4164973144859145 | validation: 0.39109252397091493]
	TIME [epoch: 9 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3923535401965044		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.3923535401965044 | validation: 0.7091210717572765]
	TIME [epoch: 9.01 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44631992783312524		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.44631992783312524 | validation: 0.3482497086757357]
	TIME [epoch: 9.02 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43908895106230367		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.43908895106230367 | validation: 0.4569630282012711]
	TIME [epoch: 9 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35752153075024573		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.35752153075024573 | validation: 0.38440462358514316]
	TIME [epoch: 9 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38589454147384944		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.38589454147384944 | validation: 0.31225938086356253]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_332.pth
	Model improved!!!
EPOCH 333/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4112906558563175		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.4112906558563175 | validation: 0.32455480992781316]
	TIME [epoch: 9.03 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3930233313483256		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.3930233313483256 | validation: 0.3132486338811995]
	TIME [epoch: 9.01 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4045392893536265		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.4045392893536265 | validation: 0.6552102352937599]
	TIME [epoch: 9 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4396132506108913		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.4396132506108913 | validation: 0.4679799905811627]
	TIME [epoch: 9 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.564995982308499		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.564995982308499 | validation: 0.47741169462242344]
	TIME [epoch: 9.02 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41855352035951715		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.41855352035951715 | validation: 0.5323049080185456]
	TIME [epoch: 9.01 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43766256519731944		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.43766256519731944 | validation: 0.43381889895942427]
	TIME [epoch: 9 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4014291385114116		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.4014291385114116 | validation: 0.4456912437484628]
	TIME [epoch: 9 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43248398748141953		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.43248398748141953 | validation: 0.3823115674638161]
	TIME [epoch: 9 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45010511676170706		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.45010511676170706 | validation: 0.5407222213534996]
	TIME [epoch: 9.03 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4361064209502947		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.4361064209502947 | validation: 0.4033260049495686]
	TIME [epoch: 9 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3895275040561035		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.3895275040561035 | validation: 0.47760236475864076]
	TIME [epoch: 9 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3920265026550765		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.3920265026550765 | validation: 0.36287367330501225]
	TIME [epoch: 9 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4248547831804285		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.4248547831804285 | validation: 0.43601281279573634]
	TIME [epoch: 8.99 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4851906840311739		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.4851906840311739 | validation: 0.31625167944499766]
	TIME [epoch: 9.03 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37807861755327027		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.37807861755327027 | validation: 0.31622979722658656]
	TIME [epoch: 9 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3327350997988755		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.3327350997988755 | validation: 0.2943579496021571]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_349.pth
	Model improved!!!
EPOCH 350/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4730955533458417		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.4730955533458417 | validation: 0.36692370034011706]
	TIME [epoch: 9.01 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44252770383638484		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.44252770383638484 | validation: 0.47483243263207564]
	TIME [epoch: 9.01 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37004921245887445		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.37004921245887445 | validation: 0.36539549028821017]
	TIME [epoch: 9.01 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39271937792018885		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.39271937792018885 | validation: 0.33471054776961306]
	TIME [epoch: 9.01 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.371982771437813		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.371982771437813 | validation: 0.3170276437954692]
	TIME [epoch: 9.01 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48404498921194516		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.48404498921194516 | validation: 0.3455392119816673]
	TIME [epoch: 9.01 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5030135165903094		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.5030135165903094 | validation: 0.32768621117708524]
	TIME [epoch: 9.02 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3287992829925971		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.3287992829925971 | validation: 0.46060320983614944]
	TIME [epoch: 9 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4340240043014124		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.4340240043014124 | validation: 0.3619572247382888]
	TIME [epoch: 8.99 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4224486980280302		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.4224486980280302 | validation: 0.3558098978563574]
	TIME [epoch: 9.01 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3761291004146122		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.3761291004146122 | validation: 0.32323011369229737]
	TIME [epoch: 9.01 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3989638770038798		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.3989638770038798 | validation: 0.41334992377859237]
	TIME [epoch: 9.02 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4709932765107795		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.4709932765107795 | validation: 0.4858282501909784]
	TIME [epoch: 9.01 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5042776307621392		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.5042776307621392 | validation: 0.30503414902723675]
	TIME [epoch: 9.01 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3899217775267879		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.3899217775267879 | validation: 0.37772461184977557]
	TIME [epoch: 9.01 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45545288178382026		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.45545288178382026 | validation: 0.3595631026206488]
	TIME [epoch: 9.03 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41119965708992295		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.41119965708992295 | validation: 0.4245621308544444]
	TIME [epoch: 9 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4137401142165881		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.4137401142165881 | validation: 0.37785761558442066]
	TIME [epoch: 9.01 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3632322514626051		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.3632322514626051 | validation: 0.4408033052086429]
	TIME [epoch: 9 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3670817381631469		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.3670817381631469 | validation: 0.3991339300776443]
	TIME [epoch: 9 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39481847955474497		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.39481847955474497 | validation: 0.41006240435681496]
	TIME [epoch: 9.04 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35997546090081267		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.35997546090081267 | validation: 0.28025015860231745]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_371.pth
	Model improved!!!
EPOCH 372/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37862228436200723		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.37862228436200723 | validation: 0.3397058261172238]
	TIME [epoch: 9 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3843282561996938		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.3843282561996938 | validation: 0.3877517629694573]
	TIME [epoch: 8.99 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33724828933349754		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.33724828933349754 | validation: 0.3777541064410793]
	TIME [epoch: 9 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3951857830340958		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.3951857830340958 | validation: 0.4389506771202515]
	TIME [epoch: 9.01 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3797645775995212		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.3797645775995212 | validation: 0.3701653568848625]
	TIME [epoch: 8.99 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44927028439158495		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.44927028439158495 | validation: 0.2824047783006729]
	TIME [epoch: 8.98 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3505526562173997		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.3505526562173997 | validation: 0.26719182832886046]
	TIME [epoch: 8.99 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_378.pth
	Model improved!!!
EPOCH 379/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.340950529494106		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.340950529494106 | validation: 0.2981132019689222]
	TIME [epoch: 9.02 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3321210876798187		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.3321210876798187 | validation: 0.3101047453357829]
	TIME [epoch: 8.99 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3078383316389993		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.3078383316389993 | validation: 0.28729348372975044]
	TIME [epoch: 8.99 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3746442558210882		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.3746442558210882 | validation: 0.31075025547531054]
	TIME [epoch: 8.99 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3887058669511937		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.3887058669511937 | validation: 0.37057666520878685]
	TIME [epoch: 8.99 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3621466021968727		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.3621466021968727 | validation: 0.41262202174145146]
	TIME [epoch: 9.01 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4004075418251644		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.4004075418251644 | validation: 0.39988461494863325]
	TIME [epoch: 9 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37534755311027207		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.37534755311027207 | validation: 0.33940459316132504]
	TIME [epoch: 8.99 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33417157353190186		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.33417157353190186 | validation: 0.30249954667381673]
	TIME [epoch: 8.99 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35293704782149593		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.35293704782149593 | validation: 0.3103726573832232]
	TIME [epoch: 9 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3305672813996785		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.3305672813996785 | validation: 0.3405951104658643]
	TIME [epoch: 9.01 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37853565556509866		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.37853565556509866 | validation: 0.43008652556764054]
	TIME [epoch: 8.99 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3442382415353047		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.3442382415353047 | validation: 0.4314972543770669]
	TIME [epoch: 8.99 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3580793712316833		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.3580793712316833 | validation: 0.5203348140953258]
	TIME [epoch: 8.99 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38924438762973573		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.38924438762973573 | validation: 0.34197998921424727]
	TIME [epoch: 9.02 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3630846252163561		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.3630846252163561 | validation: 0.272374530291808]
	TIME [epoch: 8.99 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36891855969662996		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.36891855969662996 | validation: 0.27859367670719093]
	TIME [epoch: 9 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32820509557304123		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.32820509557304123 | validation: 0.31827414440708934]
	TIME [epoch: 9 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34413751355897787		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.34413751355897787 | validation: 0.30064810547897586]
	TIME [epoch: 9.01 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3791005992372091		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.3791005992372091 | validation: 0.300984856115624]
	TIME [epoch: 9.01 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31926132539134333		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.31926132539134333 | validation: 0.32850323653616165]
	TIME [epoch: 9 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38053594355912496		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.38053594355912496 | validation: 0.2802601508241498]
	TIME [epoch: 9 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3421265203955232		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.3421265203955232 | validation: 0.39388158250713445]
	TIME [epoch: 9.01 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39722653413163156		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.39722653413163156 | validation: 0.359212920077204]
	TIME [epoch: 9.03 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35521128300184096		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.35521128300184096 | validation: 0.30497219763187267]
	TIME [epoch: 9.01 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32835335120862635		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.32835335120862635 | validation: 0.4151431332450414]
	TIME [epoch: 9.01 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38494005800755515		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.38494005800755515 | validation: 0.3005219661341032]
	TIME [epoch: 9 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33959615822341577		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.33959615822341577 | validation: 0.3433166851984979]
	TIME [epoch: 8.99 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3346056975626561		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.3346056975626561 | validation: 0.38361194931087417]
	TIME [epoch: 9.02 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3654581729886025		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.3654581729886025 | validation: 0.3539319858959642]
	TIME [epoch: 8.99 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3235634297220945		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.3235634297220945 | validation: 0.37112498913000264]
	TIME [epoch: 9 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3542777369625954		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.3542777369625954 | validation: 0.3288148235310354]
	TIME [epoch: 9 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4119606946219682		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.4119606946219682 | validation: 0.37337717369944723]
	TIME [epoch: 9.01 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39406410025556843		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.39406410025556843 | validation: 0.3198582948385097]
	TIME [epoch: 9 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36493013132316693		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.36493013132316693 | validation: 0.32660646807785704]
	TIME [epoch: 8.98 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4671274614875859		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.4671274614875859 | validation: 0.3484370332039051]
	TIME [epoch: 9 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37136737242145607		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.37136737242145607 | validation: 0.28494413578208977]
	TIME [epoch: 9 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40307534117752225		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.40307534117752225 | validation: 0.3567374176224183]
	TIME [epoch: 9.02 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3206017257779424		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.3206017257779424 | validation: 0.3359794647758548]
	TIME [epoch: 9 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3236805657854258		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.3236805657854258 | validation: 0.32534676343241364]
	TIME [epoch: 8.99 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38982177006277746		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.38982177006277746 | validation: 0.3179895440959955]
	TIME [epoch: 8.99 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3190074349071013		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.3190074349071013 | validation: 0.2675262726699634]
	TIME [epoch: 9 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4096992128441145		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.4096992128441145 | validation: 0.2995667995384039]
	TIME [epoch: 9.02 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3463215166886852		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.3463215166886852 | validation: 0.29860343403429374]
	TIME [epoch: 9.01 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.320579512976322		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.320579512976322 | validation: 0.31151366162502137]
	TIME [epoch: 8.99 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3105311696434805		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.3105311696434805 | validation: 0.28908278968704837]
	TIME [epoch: 8.99 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3104580178858818		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.3104580178858818 | validation: 0.3011382010682085]
	TIME [epoch: 9.02 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31781430589150966		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.31781430589150966 | validation: 0.30167058282674764]
	TIME [epoch: 8.99 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36213382050505344		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.36213382050505344 | validation: 0.4355610793522272]
	TIME [epoch: 8.99 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32461316892121594		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.32461316892121594 | validation: 0.3639767701866331]
	TIME [epoch: 8.99 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31808695570074386		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.31808695570074386 | validation: 0.2668217499362311]
	TIME [epoch: 8.99 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_429.pth
	Model improved!!!
EPOCH 430/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3861488380133197		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.3861488380133197 | validation: 0.2805603888068251]
	TIME [epoch: 9.02 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3821885071197394		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.3821885071197394 | validation: 0.27636955284210507]
	TIME [epoch: 8.99 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35995835140396276		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.35995835140396276 | validation: 0.37977401354450047]
	TIME [epoch: 9 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3395490168094918		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.3395490168094918 | validation: 0.4062233988730841]
	TIME [epoch: 8.99 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3694277148222309		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.3694277148222309 | validation: 0.29038108334507784]
	TIME [epoch: 9.01 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3450573050140007		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.3450573050140007 | validation: 0.3115747179295473]
	TIME [epoch: 9.01 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.336283708718484		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.336283708718484 | validation: 0.3624004259858713]
	TIME [epoch: 9 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3350572921909442		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.3350572921909442 | validation: 0.2650971885273853]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_437.pth
	Model improved!!!
EPOCH 438/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29731693586350216		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.29731693586350216 | validation: 0.30804650093547725]
	TIME [epoch: 8.99 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28455763585986527		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.28455763585986527 | validation: 0.2730661218220401]
	TIME [epoch: 9.02 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2825421939470717		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.2825421939470717 | validation: 0.2492993430094786]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_440.pth
	Model improved!!!
EPOCH 441/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3028930258648875		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.3028930258648875 | validation: 0.26106053266509177]
	TIME [epoch: 8.99 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32197701698015113		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.32197701698015113 | validation: 0.27178683281378635]
	TIME [epoch: 9 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37222525527329636		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.37222525527329636 | validation: 0.37026687951715714]
	TIME [epoch: 8.99 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3494090965561778		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.3494090965561778 | validation: 0.3928871720764776]
	TIME [epoch: 9.01 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3825639032827768		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.3825639032827768 | validation: 0.25901421949128706]
	TIME [epoch: 8.99 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31988964428285194		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.31988964428285194 | validation: 0.2576484177519157]
	TIME [epoch: 8.99 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.311440440549521		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.311440440549521 | validation: 0.325075062448656]
	TIME [epoch: 8.99 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3575159461787038		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.3575159461787038 | validation: 0.46194364632753737]
	TIME [epoch: 9.01 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3316623802687618		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.3316623802687618 | validation: 0.30840753697510415]
	TIME [epoch: 8.99 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3028852160317956		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.3028852160317956 | validation: 0.38278577064994485]
	TIME [epoch: 8.99 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3133128108185329		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.3133128108185329 | validation: 0.3133044388682601]
	TIME [epoch: 8.99 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35924203431967855		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.35924203431967855 | validation: 0.3695434140637598]
	TIME [epoch: 8.99 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34763236548628634		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.34763236548628634 | validation: 0.29148901201518773]
	TIME [epoch: 9.02 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30519269350538225		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.30519269350538225 | validation: 0.6714383213820169]
	TIME [epoch: 8.99 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3767346737721528		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.3767346737721528 | validation: 0.28517001836876665]
	TIME [epoch: 8.99 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33282343981221374		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.33282343981221374 | validation: 0.3045074878612243]
	TIME [epoch: 8.99 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30914808756914247		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.30914808756914247 | validation: 0.2716929762490433]
	TIME [epoch: 9.01 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3153800769930727		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.3153800769930727 | validation: 0.26857842645271157]
	TIME [epoch: 9.01 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2867751260543366		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.2867751260543366 | validation: 0.24283650082714403]
	TIME [epoch: 8.99 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_459.pth
	Model improved!!!
EPOCH 460/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2725204218224695		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.2725204218224695 | validation: 0.27977890025748114]
	TIME [epoch: 9.01 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3116981302936565		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.3116981302936565 | validation: 0.4284956782446463]
	TIME [epoch: 9 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3114379400038868		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.3114379400038868 | validation: 0.33080273606536803]
	TIME [epoch: 9.02 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3575437442660661		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.3575437442660661 | validation: 0.31585077663403793]
	TIME [epoch: 8.99 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31159644984263246		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.31159644984263246 | validation: 0.2826826821622482]
	TIME [epoch: 8.99 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30204914681558986		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.30204914681558986 | validation: 0.26054692792177797]
	TIME [epoch: 9 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3260279772619531		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.3260279772619531 | validation: 0.3037829407093881]
	TIME [epoch: 9 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3457386768565224		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.3457386768565224 | validation: 0.3119779763806052]
	TIME [epoch: 9.03 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32459259715015004		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.32459259715015004 | validation: 0.31881107277268]
	TIME [epoch: 9.01 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2847374006067739		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.2847374006067739 | validation: 0.28259706013793756]
	TIME [epoch: 9.01 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3405091471531244		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.3405091471531244 | validation: 0.57353996115441]
	TIME [epoch: 9 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3561403696286738		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.3561403696286738 | validation: 0.24674604075072948]
	TIME [epoch: 9.02 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30290716902442655		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.30290716902442655 | validation: 0.4126446200586429]
	TIME [epoch: 9.02 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3773287296189927		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.3773287296189927 | validation: 0.2642403962415373]
	TIME [epoch: 9 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3034254549833094		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.3034254549833094 | validation: 0.30854100151737607]
	TIME [epoch: 9 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29364472968212896		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.29364472968212896 | validation: 0.2984489207098265]
	TIME [epoch: 9.01 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30771274298410123		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.30771274298410123 | validation: 0.28712935675282913]
	TIME [epoch: 9.02 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3033057842120614		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.3033057842120614 | validation: 0.3277780148305928]
	TIME [epoch: 9.01 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3246182664913267		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.3246182664913267 | validation: 0.26203742866770097]
	TIME [epoch: 9 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3334489550037788		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.3334489550037788 | validation: 0.272595298407882]
	TIME [epoch: 9 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2810991877809931		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.2810991877809931 | validation: 0.3793974393053446]
	TIME [epoch: 9.02 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3379133943553528		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.3379133943553528 | validation: 0.29631097829356534]
	TIME [epoch: 9.01 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3143334888432457		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.3143334888432457 | validation: 0.28914771982198034]
	TIME [epoch: 9.02 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32131515477638006		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.32131515477638006 | validation: 0.3838637518457317]
	TIME [epoch: 9.01 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34117421683593563		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.34117421683593563 | validation: 0.3637665415590242]
	TIME [epoch: 9.01 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.338286130951628		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.338286130951628 | validation: 0.34904470387319]
	TIME [epoch: 9.03 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30463340649117165		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.30463340649117165 | validation: 0.27398871689453375]
	TIME [epoch: 9 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3147261315742803		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.3147261315742803 | validation: 0.32412657646970156]
	TIME [epoch: 9 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3132581739551167		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.3132581739551167 | validation: 0.3636025755695996]
	TIME [epoch: 9 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31554919697415684		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.31554919697415684 | validation: 0.2719426192093912]
	TIME [epoch: 9 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29009549882239316		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.29009549882239316 | validation: 0.3264500211803547]
	TIME [epoch: 9.02 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3275199874235853		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.3275199874235853 | validation: 0.3407378827755117]
	TIME [epoch: 8.99 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29510884957605044		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.29510884957605044 | validation: 0.35857038727488033]
	TIME [epoch: 8.99 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37718459622782186		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.37718459622782186 | validation: 0.2758616871800298]
	TIME [epoch: 9 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2861205924216225		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.2861205924216225 | validation: 0.33382154460592584]
	TIME [epoch: 9 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29726975792847143		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.29726975792847143 | validation: 0.24705541128853856]
	TIME [epoch: 9.01 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29384380298569		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.29384380298569 | validation: 0.2709441605502846]
	TIME [epoch: 8.99 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2810671826307158		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.2810671826307158 | validation: 0.2394859008176658]
	TIME [epoch: 8.99 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_497.pth
	Model improved!!!
EPOCH 498/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2897727925936765		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.2897727925936765 | validation: 0.3343941891202272]
	TIME [epoch: 9 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2759961422175419		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.2759961422175419 | validation: 0.29918458904203693]
	TIME [epoch: 9.02 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3102679055383156		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.3102679055383156 | validation: 0.3152899853790251]
	TIME [epoch: 8.99 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2946480519929668		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.2946480519929668 | validation: 0.2560348335014622]
	TIME [epoch: 8.99 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31261328397526217		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.31261328397526217 | validation: 0.27406472624520606]
	TIME [epoch: 9 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2738598840975007		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.2738598840975007 | validation: 0.24928795070685467]
	TIME [epoch: 9.01 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32406753678311606		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.32406753678311606 | validation: 0.3857057645513273]
	TIME [epoch: 9 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3053900271811799		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.3053900271811799 | validation: 0.2827216332899535]
	TIME [epoch: 8.99 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3054077425999309		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.3054077425999309 | validation: 0.4207470983399509]
	TIME [epoch: 8.99 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31532501799139		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.31532501799139 | validation: 0.24694420528598066]
	TIME [epoch: 9 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2734370700813224		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.2734370700813224 | validation: 0.24208176709820695]
	TIME [epoch: 9.03 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26481008903236375		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.26481008903236375 | validation: 0.24177650921512006]
	TIME [epoch: 9.01 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3282224956084999		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.3282224956084999 | validation: 0.28581463572920585]
	TIME [epoch: 9 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3063283280289184		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.3063283280289184 | validation: 0.2783999726746249]
	TIME [epoch: 8.98 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29090461310539617		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.29090461310539617 | validation: 0.2584404590386705]
	TIME [epoch: 8.99 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2951352633256494		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.2951352633256494 | validation: 0.27297793179396324]
	TIME [epoch: 9.01 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.310118118412192		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.310118118412192 | validation: 0.4134489332129908]
	TIME [epoch: 8.98 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2972965382096287		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.2972965382096287 | validation: 0.2714096790060896]
	TIME [epoch: 8.98 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2891328650056527		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.2891328650056527 | validation: 0.2532067240482813]
	TIME [epoch: 8.99 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2794711690280361		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.2794711690280361 | validation: 0.42816528041867297]
	TIME [epoch: 9 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33507698562463656		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.33507698562463656 | validation: 0.26116367900956705]
	TIME [epoch: 9 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2750527070814147		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.2750527070814147 | validation: 0.2961458173962296]
	TIME [epoch: 8.98 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30657767206080344		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.30657767206080344 | validation: 0.28111145714295876]
	TIME [epoch: 9 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2994248218787322		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.2994248218787322 | validation: 0.31550293806676444]
	TIME [epoch: 9 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32369048974225617		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.32369048974225617 | validation: 0.2771167621362256]
	TIME [epoch: 9.02 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30120051016480687		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.30120051016480687 | validation: 0.2392705408975149]
	TIME [epoch: 8.99 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_523.pth
	Model improved!!!
EPOCH 524/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2844811530493217		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.2844811530493217 | validation: 0.3058486148417317]
	TIME [epoch: 8.99 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26951251527168923		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.26951251527168923 | validation: 0.2665555290701114]
	TIME [epoch: 8.99 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2978239171301803		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.2978239171301803 | validation: 0.32505663784479005]
	TIME [epoch: 8.99 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2809253151464416		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.2809253151464416 | validation: 0.26448663862190575]
	TIME [epoch: 9.01 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27569579349507556		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.27569579349507556 | validation: 0.25853648408467056]
	TIME [epoch: 8.99 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2613983377459434		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.2613983377459434 | validation: 0.278116245543233]
	TIME [epoch: 8.98 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2700556014648249		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.2700556014648249 | validation: 0.24365858491097442]
	TIME [epoch: 8.99 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2671610387649731		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.2671610387649731 | validation: 0.2965064510431533]
	TIME [epoch: 9.01 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2717623147319212		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.2717623147319212 | validation: 0.2521221222241634]
	TIME [epoch: 8.99 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3025244263429412		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.3025244263429412 | validation: 0.24079313015766196]
	TIME [epoch: 8.99 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2525680594308847		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.2525680594308847 | validation: 0.24034723084404158]
	TIME [epoch: 8.98 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.258943611492355		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.258943611492355 | validation: 0.24854036425481982]
	TIME [epoch: 8.99 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2496355527417194		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.2496355527417194 | validation: 0.29817093685764584]
	TIME [epoch: 9.01 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28904642261585406		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.28904642261585406 | validation: 0.29298407659727066]
	TIME [epoch: 8.99 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28780211676973144		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.28780211676973144 | validation: 0.25671988576127874]
	TIME [epoch: 8.99 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2839470040274342		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.2839470040274342 | validation: 0.26458439850648574]
	TIME [epoch: 8.98 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26822883772497325		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.26822883772497325 | validation: 0.21984198817896583]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_540.pth
	Model improved!!!
EPOCH 541/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27600125759352906		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.27600125759352906 | validation: 0.24865436828969117]
	TIME [epoch: 9 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29046602120964027		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.29046602120964027 | validation: 0.2503318085625771]
	TIME [epoch: 9.05 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2536075689949528		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.2536075689949528 | validation: 0.24041726191612273]
	TIME [epoch: 8.99 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26908132467099866		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.26908132467099866 | validation: 0.2307690191435366]
	TIME [epoch: 8.98 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26005574387425884		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.26005574387425884 | validation: 0.25372977914926664]
	TIME [epoch: 9.01 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2561523120359857		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.2561523120359857 | validation: 0.24728554088733512]
	TIME [epoch: 9 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2564061104090985		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.2564061104090985 | validation: 0.2515581776511908]
	TIME [epoch: 8.99 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24965947175564568		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.24965947175564568 | validation: 0.2555310112628475]
	TIME [epoch: 9 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27172540857189026		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.27172540857189026 | validation: 0.26603186586821087]
	TIME [epoch: 9 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2671538170197788		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.2671538170197788 | validation: 0.24202185884980393]
	TIME [epoch: 9.01 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2737206647044521		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.2737206647044521 | validation: 0.24467116151755391]
	TIME [epoch: 8.99 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2612961131178736		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.2612961131178736 | validation: 0.2540489832960396]
	TIME [epoch: 8.99 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27152246144261655		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.27152246144261655 | validation: 0.23589028207906532]
	TIME [epoch: 8.99 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26397749145256244		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.26397749145256244 | validation: 0.2829112568868821]
	TIME [epoch: 8.99 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28683056479906505		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.28683056479906505 | validation: 0.2756401217854042]
	TIME [epoch: 9 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2676504285804759		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.2676504285804759 | validation: 0.2713897293950381]
	TIME [epoch: 8.99 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26629849299016195		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.26629849299016195 | validation: 0.23804297531821364]
	TIME [epoch: 8.99 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25317584784389296		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.25317584784389296 | validation: 0.25943964378586964]
	TIME [epoch: 8.99 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26004036989602064		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.26004036989602064 | validation: 0.2526523153312235]
	TIME [epoch: 9.01 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24028560843238472		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.24028560843238472 | validation: 0.25022810086597325]
	TIME [epoch: 8.99 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2660874985194347		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.2660874985194347 | validation: 0.3066975811865153]
	TIME [epoch: 8.99 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2819154990194369		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.2819154990194369 | validation: 0.31336881503177333]
	TIME [epoch: 8.99 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2743259588708365		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.2743259588708365 | validation: 0.26325288770523997]
	TIME [epoch: 9.01 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.265419179071224		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.265419179071224 | validation: 0.2956391434511809]
	TIME [epoch: 8.99 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2730841667006567		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.2730841667006567 | validation: 0.3794737285540293]
	TIME [epoch: 8.99 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3126878382308068		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.3126878382308068 | validation: 0.23116264665225505]
	TIME [epoch: 8.98 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26212146632004496		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.26212146632004496 | validation: 0.3035588986500707]
	TIME [epoch: 8.98 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.273019252000304		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.273019252000304 | validation: 0.24889823202101263]
	TIME [epoch: 9.01 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2565971882148554		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.2565971882148554 | validation: 0.2519373607217605]
	TIME [epoch: 8.99 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2562875525738699		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.2562875525738699 | validation: 0.23341400812698732]
	TIME [epoch: 8.99 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26338829842267636		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.26338829842267636 | validation: 0.31439119418955364]
	TIME [epoch: 8.99 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33470365513962347		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.33470365513962347 | validation: 0.24998876064639952]
	TIME [epoch: 8.98 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26807372571857213		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.26807372571857213 | validation: 0.3384695207191675]
	TIME [epoch: 9.01 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27099411759761327		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.27099411759761327 | validation: 0.23448376422731138]
	TIME [epoch: 8.99 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26480872809590505		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.26480872809590505 | validation: 0.265552290694085]
	TIME [epoch: 8.99 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.266654542131939		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.266654542131939 | validation: 0.22300784792379152]
	TIME [epoch: 8.98 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25663506538028524		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.25663506538028524 | validation: 0.2671277443706932]
	TIME [epoch: 9 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2681592188622941		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.2681592188622941 | validation: 0.253473505804632]
	TIME [epoch: 9 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2748093367182643		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.2748093367182643 | validation: 0.31290680734126586]
	TIME [epoch: 8.98 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2594549833120178		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.2594549833120178 | validation: 0.2276252016207681]
	TIME [epoch: 8.98 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.254800468698044		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.254800468698044 | validation: 0.25593714557987224]
	TIME [epoch: 8.98 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2534350449296435		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.2534350449296435 | validation: 0.27824169122551123]
	TIME [epoch: 9.01 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25657704326350794		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.25657704326350794 | validation: 0.21435781975657303]
	TIME [epoch: 8.99 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_583.pth
	Model improved!!!
EPOCH 584/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2742862000369231		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.2742862000369231 | validation: 0.24473356177504219]
	TIME [epoch: 8.99 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26447845780411094		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.26447845780411094 | validation: 0.23773258258578736]
	TIME [epoch: 8.99 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2524729766965288		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.2524729766965288 | validation: 0.2658277695033998]
	TIME [epoch: 8.99 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2731227682160994		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.2731227682160994 | validation: 0.2649615647663883]
	TIME [epoch: 9.01 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2550642532019834		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.2550642532019834 | validation: 0.27289591375937367]
	TIME [epoch: 8.99 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29231079570967466		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.29231079570967466 | validation: 0.26329802255747664]
	TIME [epoch: 8.99 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26105327729689515		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.26105327729689515 | validation: 0.24597474859488797]
	TIME [epoch: 8.99 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26501340441709254		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.26501340441709254 | validation: 0.22861396912195045]
	TIME [epoch: 9 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2486649094002161		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.2486649094002161 | validation: 0.2254116830755009]
	TIME [epoch: 9 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26268506708959116		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.26268506708959116 | validation: 0.3057732661404854]
	TIME [epoch: 8.99 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26840764762305647		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.26840764762305647 | validation: 0.2210468517891972]
	TIME [epoch: 8.99 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31631868107897343		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.31631868107897343 | validation: 0.22778847075475095]
	TIME [epoch: 8.99 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2713545590352913		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.2713545590352913 | validation: 0.23061368509351604]
	TIME [epoch: 9.01 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2463527218546063		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.2463527218546063 | validation: 0.2286830698499338]
	TIME [epoch: 8.99 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24208474283779494		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.24208474283779494 | validation: 0.2220501867177714]
	TIME [epoch: 8.98 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25068993304686243		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.25068993304686243 | validation: 0.2455557706934003]
	TIME [epoch: 8.99 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23345372828019767		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.23345372828019767 | validation: 0.23554697989177442]
	TIME [epoch: 9 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2348942424125223		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.2348942424125223 | validation: 0.222123492147452]
	TIME [epoch: 9 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2612761981692446		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.2612761981692446 | validation: 0.22652327671668926]
	TIME [epoch: 8.99 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25066269028724925		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.25066269028724925 | validation: 0.2196128431467569]
	TIME [epoch: 8.99 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2733005996028044		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.2733005996028044 | validation: 0.22399877930832285]
	TIME [epoch: 8.98 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2555986485158358		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.2555986485158358 | validation: 0.24207226638354815]
	TIME [epoch: 9.02 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24504697330177772		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.24504697330177772 | validation: 0.23565236571194975]
	TIME [epoch: 8.99 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24628455574649016		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.24628455574649016 | validation: 0.2236642877750629]
	TIME [epoch: 8.99 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2472207855840766		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.2472207855840766 | validation: 0.2247990239673081]
	TIME [epoch: 8.98 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2540779874646767		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.2540779874646767 | validation: 0.26585325817142946]
	TIME [epoch: 9 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2505277056380303		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.2505277056380303 | validation: 0.21964589013237185]
	TIME [epoch: 9.01 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2382836631919508		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.2382836631919508 | validation: 0.21826766907707568]
	TIME [epoch: 8.99 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25623293610651854		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.25623293610651854 | validation: 0.2622586342462624]
	TIME [epoch: 8.99 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2733214679598853		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.2733214679598853 | validation: 0.26960840813906944]
	TIME [epoch: 8.99 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26128580664648643		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.26128580664648643 | validation: 0.24637458429477888]
	TIME [epoch: 9.01 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24571255906882872		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.24571255906882872 | validation: 0.2241660833489788]
	TIME [epoch: 9.01 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30003914435324447		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.30003914435324447 | validation: 0.22309636276589465]
	TIME [epoch: 8.99 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2936061230225759		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.2936061230225759 | validation: 0.23403716005032782]
	TIME [epoch: 8.99 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26555767954091525		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.26555767954091525 | validation: 0.22214903243799444]
	TIME [epoch: 8.98 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2476019286104592		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.2476019286104592 | validation: 0.21583697600999285]
	TIME [epoch: 9.01 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23372306727167352		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.23372306727167352 | validation: 0.23259036624896412]
	TIME [epoch: 8.99 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2607849303864345		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.2607849303864345 | validation: 0.23902108050163623]
	TIME [epoch: 8.99 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2409312130190798		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.2409312130190798 | validation: 0.23875012325236492]
	TIME [epoch: 8.99 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2556764501337599		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.2556764501337599 | validation: 0.2333005339937801]
	TIME [epoch: 9 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2436997090189521		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.2436997090189521 | validation: 0.2428808935673608]
	TIME [epoch: 9 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2589651862933803		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.2589651862933803 | validation: 0.2357102605207107]
	TIME [epoch: 8.99 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23197758200700277		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.23197758200700277 | validation: 0.24039306391694004]
	TIME [epoch: 8.98 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23818132996268138		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.23818132996268138 | validation: 0.22366818176356612]
	TIME [epoch: 8.99 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23845080828373527		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.23845080828373527 | validation: 0.31143716780288977]
	TIME [epoch: 9.01 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24966519866238182		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.24966519866238182 | validation: 0.2232416224293403]
	TIME [epoch: 9 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23066835460467683		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.23066835460467683 | validation: 0.21577794589429644]
	TIME [epoch: 8.99 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2371341022475053		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.2371341022475053 | validation: 0.2315184589698382]
	TIME [epoch: 8.99 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22944329812925868		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.22944329812925868 | validation: 0.22974720152632216]
	TIME [epoch: 8.98 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25261226052473623		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.25261226052473623 | validation: 0.24350906736111685]
	TIME [epoch: 9.35 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23675445873013964		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.23675445873013964 | validation: 0.21441397469675627]
	TIME [epoch: 8.99 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22467983039433817		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.22467983039433817 | validation: 0.23425285560012077]
	TIME [epoch: 9 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22865420941458603		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.22865420941458603 | validation: 0.23136002096938169]
	TIME [epoch: 9 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25318030838957495		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.25318030838957495 | validation: 0.227373193646144]
	TIME [epoch: 9 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2624364443290661		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.2624364443290661 | validation: 0.24036992251165765]
	TIME [epoch: 9.03 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23801857180159733		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.23801857180159733 | validation: 0.24619386686797484]
	TIME [epoch: 9 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24421360960429758		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.24421360960429758 | validation: 0.21824058592400408]
	TIME [epoch: 9 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24292578049957342		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.24292578049957342 | validation: 0.22492742847155867]
	TIME [epoch: 9.01 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24549297192770586		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.24549297192770586 | validation: 0.23780294743562272]
	TIME [epoch: 9.02 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23957014867252427		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.23957014867252427 | validation: 0.24631690883205526]
	TIME [epoch: 9.02 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2549994718754036		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.2549994718754036 | validation: 0.23323930433247964]
	TIME [epoch: 8.99 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25297874765107586		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.25297874765107586 | validation: 0.20943064461207245]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_645.pth
	Model improved!!!
EPOCH 646/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24245036817284768		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.24245036817284768 | validation: 0.25663313333113624]
	TIME [epoch: 9 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23177865868469844		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.23177865868469844 | validation: 0.24540307864780792]
	TIME [epoch: 9.01 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2586112500456833		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.2586112500456833 | validation: 0.2161697699033167]
	TIME [epoch: 9 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23424528873842965		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.23424528873842965 | validation: 0.23872528919197072]
	TIME [epoch: 9 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22895327500231563		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.22895327500231563 | validation: 0.22382609172254597]
	TIME [epoch: 8.99 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2339910198697535		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.2339910198697535 | validation: 0.21376893746999293]
	TIME [epoch: 9 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23998574060199113		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.23998574060199113 | validation: 0.2199538137803776]
	TIME [epoch: 9.01 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2580597798905402		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.2580597798905402 | validation: 0.22573515182185483]
	TIME [epoch: 9 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24162456104352725		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.24162456104352725 | validation: 0.2176055204501362]
	TIME [epoch: 9 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2735445924710118		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.2735445924710118 | validation: 0.1930801740624699]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_655.pth
	Model improved!!!
EPOCH 656/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22901223418650626		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.22901223418650626 | validation: 0.2314006308480831]
	TIME [epoch: 9.02 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24551231335744594		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.24551231335744594 | validation: 0.2301530747288281]
	TIME [epoch: 9 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2278442652029376		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.2278442652029376 | validation: 0.2208458576049015]
	TIME [epoch: 9.01 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23048106860262702		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.23048106860262702 | validation: 0.23097388969329463]
	TIME [epoch: 9 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22876203320007224		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.22876203320007224 | validation: 0.2117762116606326]
	TIME [epoch: 9 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22859784133653158		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.22859784133653158 | validation: 0.2409604299926094]
	TIME [epoch: 9.02 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23120481071988083		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.23120481071988083 | validation: 0.21521169442799679]
	TIME [epoch: 9 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2256488633457782		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.2256488633457782 | validation: 0.2251937107206517]
	TIME [epoch: 9 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23383605619223183		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.23383605619223183 | validation: 0.24066444907212925]
	TIME [epoch: 9 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24180844351193836		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.24180844351193836 | validation: 0.20897081910607823]
	TIME [epoch: 9.01 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24738614688996177		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.24738614688996177 | validation: 0.2070992105762503]
	TIME [epoch: 9.01 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22046478094817434		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.22046478094817434 | validation: 0.21559631879810137]
	TIME [epoch: 9 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2263169159077648		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.2263169159077648 | validation: 0.20488708803541217]
	TIME [epoch: 9 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23930305108272965		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.23930305108272965 | validation: 0.25344968761288195]
	TIME [epoch: 9 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25358137375364337		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.25358137375364337 | validation: 0.2308589578366067]
	TIME [epoch: 9.02 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25454525523255433		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.25454525523255433 | validation: 0.2752912978181271]
	TIME [epoch: 9 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.270177025757316		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.270177025757316 | validation: 0.22396192665672462]
	TIME [epoch: 8.99 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22813211880289735		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.22813211880289735 | validation: 0.22492105454709885]
	TIME [epoch: 9 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22754206757125103		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.22754206757125103 | validation: 0.20823192009540556]
	TIME [epoch: 9 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23276729416606093		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.23276729416606093 | validation: 0.25290587977078643]
	TIME [epoch: 9.02 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2436615704632442		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.2436615704632442 | validation: 0.22213331337855474]
	TIME [epoch: 9 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24031566727887582		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.24031566727887582 | validation: 0.20623788282445935]
	TIME [epoch: 8.99 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2229006139193137		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.2229006139193137 | validation: 0.22018078286302945]
	TIME [epoch: 9 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24713950715705688		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.24713950715705688 | validation: 0.2563435718995931]
	TIME [epoch: 9.01 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2627043101041856		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.2627043101041856 | validation: 0.20775343690123604]
	TIME [epoch: 9.01 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22370746227615138		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.22370746227615138 | validation: 0.2186066068850952]
	TIME [epoch: 9 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22454578786854845		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.22454578786854845 | validation: 0.23178575832346227]
	TIME [epoch: 9 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23985549545284313		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.23985549545284313 | validation: 0.21832204877094596]
	TIME [epoch: 9 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22921529610496436		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.22921529610496436 | validation: 0.22133570634537944]
	TIME [epoch: 9.02 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2157133667012229		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.2157133667012229 | validation: 0.20575688694671485]
	TIME [epoch: 9 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2258661974905153		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.2258661974905153 | validation: 0.2111935871847831]
	TIME [epoch: 8.99 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23575643643375574		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.23575643643375574 | validation: 0.28121444316701105]
	TIME [epoch: 9 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2479065869144415		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.2479065869144415 | validation: 0.24275615233918207]
	TIME [epoch: 9.01 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23946689613635508		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.23946689613635508 | validation: 0.2437238231253977]
	TIME [epoch: 9.01 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23910812347815277		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.23910812347815277 | validation: 0.2256180547621771]
	TIME [epoch: 9 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2451990193000098		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.2451990193000098 | validation: 0.21240695270716153]
	TIME [epoch: 8.99 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2516559745866941		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.2516559745866941 | validation: 0.2960357343702186]
	TIME [epoch: 8.99 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25085022988558714		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.25085022988558714 | validation: 0.21320242436304548]
	TIME [epoch: 9.02 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21841387238270552		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.21841387238270552 | validation: 0.22270793750908374]
	TIME [epoch: 9 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25290186994492225		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.25290186994492225 | validation: 0.2225265087542958]
	TIME [epoch: 9 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23140863040165768		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.23140863040165768 | validation: 0.225112307698225]
	TIME [epoch: 9 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2297348245014542		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.2297348245014542 | validation: 0.24580255402642087]
	TIME [epoch: 8.99 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22589621708137483		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.22589621708137483 | validation: 0.19613700111097265]
	TIME [epoch: 9.02 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21805715653379593		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.21805715653379593 | validation: 0.21718361851090165]
	TIME [epoch: 9.08 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21306755915642156		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.21306755915642156 | validation: 0.20806607458469495]
	TIME [epoch: 8.98 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2286090356530439		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.2286090356530439 | validation: 0.2591609645445388]
	TIME [epoch: 9 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25581756957311946		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.25581756957311946 | validation: 0.2272235457700434]
	TIME [epoch: 9 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25184616421504835		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.25184616421504835 | validation: 0.21036351225641392]
	TIME [epoch: 9.01 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22888299084688074		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.22888299084688074 | validation: 0.2017818257652123]
	TIME [epoch: 9 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21081766980828903		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.21081766980828903 | validation: 0.2196530063008812]
	TIME [epoch: 9 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21939669011274518		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.21939669011274518 | validation: 0.2194548246490784]
	TIME [epoch: 9 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23738921438952967		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.23738921438952967 | validation: 0.2103488670084176]
	TIME [epoch: 9.01 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2292771190843627		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.2292771190843627 | validation: 0.23428451092604807]
	TIME [epoch: 9 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24145556985263786		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.24145556985263786 | validation: 0.22229582474915607]
	TIME [epoch: 9 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25605003512779934		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.25605003512779934 | validation: 0.23402650124875352]
	TIME [epoch: 8.99 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.230551922430152		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.230551922430152 | validation: 0.2489245050421477]
	TIME [epoch: 9 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2389392712972919		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.2389392712972919 | validation: 0.23327616236778337]
	TIME [epoch: 9.01 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2212335846461948		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.2212335846461948 | validation: 0.2042473945085609]
	TIME [epoch: 9 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2197496772994712		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.2197496772994712 | validation: 0.21907108705874057]
	TIME [epoch: 9 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24026155364757878		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.24026155364757878 | validation: 0.20535021212892793]
	TIME [epoch: 9 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22903655103690576		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.22903655103690576 | validation: 0.19223528774300075]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_716.pth
	Model improved!!!
EPOCH 717/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21835750690491787		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.21835750690491787 | validation: 0.20962134936853039]
	TIME [epoch: 9 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2241582827523115		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.2241582827523115 | validation: 0.2175619713448822]
	TIME [epoch: 9 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22221719194318754		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.22221719194318754 | validation: 0.214796403335059]
	TIME [epoch: 9 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2260217409670758		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.2260217409670758 | validation: 0.21447701107539427]
	TIME [epoch: 9 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22008811145801993		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.22008811145801993 | validation: 0.2068486083988445]
	TIME [epoch: 9.03 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2269800248884783		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.2269800248884783 | validation: 0.22223680201613133]
	TIME [epoch: 9 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23872297193179226		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.23872297193179226 | validation: 0.22745954084239373]
	TIME [epoch: 8.99 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2279157760822875		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.2279157760822875 | validation: 0.20659062559107993]
	TIME [epoch: 8.99 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22122468316536653		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.22122468316536653 | validation: 0.20543054184433426]
	TIME [epoch: 9 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23356550940323176		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.23356550940323176 | validation: 0.21618824645615992]
	TIME [epoch: 9.01 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22691426616682958		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.22691426616682958 | validation: 0.21864310510184198]
	TIME [epoch: 9 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22893602999273263		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.22893602999273263 | validation: 0.21776598878621994]
	TIME [epoch: 9 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22719433184120827		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.22719433184120827 | validation: 0.20680210235253949]
	TIME [epoch: 9 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22848429679759796		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.22848429679759796 | validation: 0.2161624079655823]
	TIME [epoch: 9.02 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23301867975780866		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.23301867975780866 | validation: 0.23434623266037458]
	TIME [epoch: 9.01 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24581809549159467		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.24581809549159467 | validation: 0.21828044465278357]
	TIME [epoch: 9 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23112509979909915		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.23112509979909915 | validation: 0.21834856248212908]
	TIME [epoch: 9 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23247751677932388		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.23247751677932388 | validation: 0.22244682776322222]
	TIME [epoch: 9.01 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21371095543028798		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.21371095543028798 | validation: 0.19480310973948423]
	TIME [epoch: 9.02 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22224509477862261		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.22224509477862261 | validation: 0.21124576119868557]
	TIME [epoch: 9.01 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2157891675817613		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.2157891675817613 | validation: 0.19938714765811677]
	TIME [epoch: 9 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22293387979833512		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.22293387979833512 | validation: 0.19726350797640674]
	TIME [epoch: 9 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21614750494756177		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.21614750494756177 | validation: 0.2146124712756955]
	TIME [epoch: 9.02 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2393600913061459		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.2393600913061459 | validation: 0.2324906220501956]
	TIME [epoch: 9.01 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2369942916996354		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.2369942916996354 | validation: 0.26253719130858455]
	TIME [epoch: 9 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2609332174246745		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.2609332174246745 | validation: 0.22112129699923153]
	TIME [epoch: 9.01 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23429113221498107		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.23429113221498107 | validation: 0.2178621962126716]
	TIME [epoch: 9 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22481599742525665		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.22481599742525665 | validation: 0.19446448834022886]
	TIME [epoch: 9.03 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22517793662128488		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.22517793662128488 | validation: 0.20743299795519382]
	TIME [epoch: 9 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23059010381606684		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.23059010381606684 | validation: 0.19509574754257675]
	TIME [epoch: 9.02 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21706100422271857		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.21706100422271857 | validation: 0.20057803414311548]
	TIME [epoch: 9.01 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22145881929566308		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.22145881929566308 | validation: 0.22055303878248173]
	TIME [epoch: 9.03 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21538289692697346		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.21538289692697346 | validation: 0.21014653748537482]
	TIME [epoch: 9.02 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24412572435494068		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.24412572435494068 | validation: 0.23560827386281358]
	TIME [epoch: 9 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2339215079492293		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.2339215079492293 | validation: 0.22817273222916112]
	TIME [epoch: 9.01 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24708197618307298		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.24708197618307298 | validation: 0.2287317662649337]
	TIME [epoch: 9 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22357532729697333		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.22357532729697333 | validation: 0.20507330883454328]
	TIME [epoch: 9.02 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21262354532132793		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.21262354532132793 | validation: 0.20537440486629013]
	TIME [epoch: 9 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2148239296485385		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.2148239296485385 | validation: 0.2001117617378503]
	TIME [epoch: 9 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21211573784142054		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.21211573784142054 | validation: 0.2084669703136907]
	TIME [epoch: 9 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23027458130677175		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.23027458130677175 | validation: 0.21801987518881438]
	TIME [epoch: 9 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2277174502743088		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.2277174502743088 | validation: 0.21829462777088643]
	TIME [epoch: 9.02 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21615556689502874		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.21615556689502874 | validation: 0.202011865876893]
	TIME [epoch: 9 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2178342704045524		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.2178342704045524 | validation: 0.20149254727048505]
	TIME [epoch: 9.01 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21916311767750782		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.21916311767750782 | validation: 0.2049269494156324]
	TIME [epoch: 9.01 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21991658950360785		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.21991658950360785 | validation: 0.2262301771894309]
	TIME [epoch: 9.02 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21955755908102614		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.21955755908102614 | validation: 0.20753764269936953]
	TIME [epoch: 9 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2282429726838541		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.2282429726838541 | validation: 0.21383282566767337]
	TIME [epoch: 9 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22334664438718538		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.22334664438718538 | validation: 0.22414691340964504]
	TIME [epoch: 8.99 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2239876827383922		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.2239876827383922 | validation: 0.21073454262211996]
	TIME [epoch: 8.99 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2219972285665297		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.2219972285665297 | validation: 0.2269241235184679]
	TIME [epoch: 9.02 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23449011216909735		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.23449011216909735 | validation: 0.21951220021379658]
	TIME [epoch: 9 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23680611641035512		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.23680611641035512 | validation: 0.21923039218284218]
	TIME [epoch: 9 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2193301697656922		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.2193301697656922 | validation: 0.2094215045608051]
	TIME [epoch: 8.99 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21322682618624098		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.21322682618624098 | validation: 0.19831192742805542]
	TIME [epoch: 9.01 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21497676400430527		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.21497676400430527 | validation: 0.2129965334931787]
	TIME [epoch: 9.01 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22517862809953199		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.22517862809953199 | validation: 0.2192287050870607]
	TIME [epoch: 9 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20985820391979249		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.20985820391979249 | validation: 0.20214607636846538]
	TIME [epoch: 9.01 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21590828276593296		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.21590828276593296 | validation: 0.2196969711288975]
	TIME [epoch: 9 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23162374564332938		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.23162374564332938 | validation: 0.20857813079699924]
	TIME [epoch: 9.03 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22779646025264205		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.22779646025264205 | validation: 0.22341613928884144]
	TIME [epoch: 9 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21697701348614357		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.21697701348614357 | validation: 0.20367154118672154]
	TIME [epoch: 9 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21598623945845694		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.21598623945845694 | validation: 0.21366032491210196]
	TIME [epoch: 9 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21272000013271658		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.21272000013271658 | validation: 0.20353970426676077]
	TIME [epoch: 9 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2080495941842322		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.2080495941842322 | validation: 0.21198152993192287]
	TIME [epoch: 9.03 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21484129847703531		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.21484129847703531 | validation: 0.20455416766557352]
	TIME [epoch: 9.01 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20759979295998807		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.20759979295998807 | validation: 0.19779791120617957]
	TIME [epoch: 9 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21598540819587178		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.21598540819587178 | validation: 0.2091114933918413]
	TIME [epoch: 9 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2101628716568813		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.2101628716568813 | validation: 0.2134778701890196]
	TIME [epoch: 9.01 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2139642329053572		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.2139642329053572 | validation: 0.22042746031702287]
	TIME [epoch: 9.02 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22206626887927147		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.22206626887927147 | validation: 0.232485866675734]
	TIME [epoch: 9.01 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22142247341785395		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.22142247341785395 | validation: 0.22583661579517889]
	TIME [epoch: 9 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2197950983543957		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.2197950983543957 | validation: 0.21994882072678518]
	TIME [epoch: 9 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2648993732111148		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.2648993732111148 | validation: 0.29227151963232734]
	TIME [epoch: 9.02 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2487461444608227		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.2487461444608227 | validation: 0.24190751813048494]
	TIME [epoch: 9.01 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2299012252437577		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.2299012252437577 | validation: 0.24679193187036308]
	TIME [epoch: 9 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23039218434266034		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.23039218434266034 | validation: 0.21745057003589055]
	TIME [epoch: 9 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22470232460783857		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.22470232460783857 | validation: 0.24342105784725798]
	TIME [epoch: 9.01 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23775796551948103		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.23775796551948103 | validation: 0.27169272033758035]
	TIME [epoch: 9.02 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24562517287645788		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.24562517287645788 | validation: 0.24516227507344374]
	TIME [epoch: 9 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.234039012691062		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.234039012691062 | validation: 0.22835808221575193]
	TIME [epoch: 9 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22637572362425198		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.22637572362425198 | validation: 0.24509490253727223]
	TIME [epoch: 9 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22405009137966597		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.22405009137966597 | validation: 0.22188855877136393]
	TIME [epoch: 9.02 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21792832504801005		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.21792832504801005 | validation: 0.22270813463877073]
	TIME [epoch: 9 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2506424064899925		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.2506424064899925 | validation: 0.2599575257165365]
	TIME [epoch: 9.01 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2309947814461663		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.2309947814461663 | validation: 0.20316395384315183]
	TIME [epoch: 9 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21455813190292491		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.21455813190292491 | validation: 0.21252895589415227]
	TIME [epoch: 9 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2127235362216902		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.2127235362216902 | validation: 0.2140023598806643]
	TIME [epoch: 9.02 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22638152219615634		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.22638152219615634 | validation: 0.22449601977965092]
	TIME [epoch: 9 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2167665736660916		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.2167665736660916 | validation: 0.2210932849465463]
	TIME [epoch: 9 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22033604711877103		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.22033604711877103 | validation: 0.20651455759501913]
	TIME [epoch: 9.01 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21281773898040507		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.21281773898040507 | validation: 0.1961526709293126]
	TIME [epoch: 9.01 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20434995464774391		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.20434995464774391 | validation: 0.20807359763872602]
	TIME [epoch: 9.01 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2011293390285041		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.2011293390285041 | validation: 0.19313031286488527]
	TIME [epoch: 9 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20683973010968154		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.20683973010968154 | validation: 0.1959933552476104]
	TIME [epoch: 9 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20135303134337987		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.20135303134337987 | validation: 0.19966222543546974]
	TIME [epoch: 9 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2211553300978148		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.2211553300978148 | validation: 0.2266980162884275]
	TIME [epoch: 9.03 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21420189195951242		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.21420189195951242 | validation: 0.21835642093139343]
	TIME [epoch: 9.01 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23151481580114747		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.23151481580114747 | validation: 0.2318990957082117]
	TIME [epoch: 9.01 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21896806109596145		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.21896806109596145 | validation: 0.20253681280362446]
	TIME [epoch: 9 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20363523141645765		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.20363523141645765 | validation: 0.20406724216878772]
	TIME [epoch: 9 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20938502342463422		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.20938502342463422 | validation: 0.21057049594160926]
	TIME [epoch: 9.01 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21065455899672786		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.21065455899672786 | validation: 0.20100851275808582]
	TIME [epoch: 8.99 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21139015818225335		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.21139015818225335 | validation: 0.20342021061307697]
	TIME [epoch: 8.99 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2139102656571422		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.2139102656571422 | validation: 0.19496325632244121]
	TIME [epoch: 8.99 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2068330638983892		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.2068330638983892 | validation: 0.19502610751301042]
	TIME [epoch: 9.02 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21275961781720282		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.21275961781720282 | validation: 0.20543153295833383]
	TIME [epoch: 8.99 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22357623860139278		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.22357623860139278 | validation: 0.2099919175143046]
	TIME [epoch: 8.99 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2025287251919774		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.2025287251919774 | validation: 0.20568287314733932]
	TIME [epoch: 8.99 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.207403855389172		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.207403855389172 | validation: 0.20104497408028868]
	TIME [epoch: 8.99 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20889604233250245		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.20889604233250245 | validation: 0.19808574793271272]
	TIME [epoch: 9.02 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20964025506750605		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.20964025506750605 | validation: 0.1939530878078825]
	TIME [epoch: 8.99 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20627407677824072		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.20627407677824072 | validation: 0.2009230824529628]
	TIME [epoch: 8.99 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20891933671786628		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.20891933671786628 | validation: 0.20845092317732006]
	TIME [epoch: 8.99 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2171974998688145		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.2171974998688145 | validation: 0.20275232537111404]
	TIME [epoch: 9 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21355574775391592		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.21355574775391592 | validation: 0.2229682827439408]
	TIME [epoch: 9.01 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21826820921289847		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.21826820921289847 | validation: 0.20787952939210452]
	TIME [epoch: 8.99 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21356634532348875		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.21356634532348875 | validation: 0.21714866584292863]
	TIME [epoch: 9 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22686593002173874		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.22686593002173874 | validation: 0.22108303046330116]
	TIME [epoch: 9 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22387223253901517		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.22387223253901517 | validation: 0.2517942160748403]
	TIME [epoch: 9.02 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22768198883103538		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.22768198883103538 | validation: 0.22838743426696856]
	TIME [epoch: 9 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2179466308833214		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.2179466308833214 | validation: 0.2162045154045079]
	TIME [epoch: 8.99 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22695059926294578		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.22695059926294578 | validation: 0.23056924141717705]
	TIME [epoch: 9 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22541952972222154		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.22541952972222154 | validation: 0.21019623339335466]
	TIME [epoch: 9 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2166603104870785		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.2166603104870785 | validation: 0.21229334378191866]
	TIME [epoch: 9.03 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21381537891965027		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.21381537891965027 | validation: 0.20677208393937085]
	TIME [epoch: 8.99 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21543961959358066		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.21543961959358066 | validation: 0.20072957571311253]
	TIME [epoch: 8.99 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20559180742407168		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.20559180742407168 | validation: 0.22307325311037357]
	TIME [epoch: 9 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21429269302805234		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.21429269302805234 | validation: 0.20964501596815466]
	TIME [epoch: 9.01 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2124862006413427		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.2124862006413427 | validation: 0.20895478324218153]
	TIME [epoch: 9.01 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21999780283229012		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.21999780283229012 | validation: 0.21661018248390174]
	TIME [epoch: 9.01 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22591622953892246		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.22591622953892246 | validation: 0.2263247241143515]
	TIME [epoch: 9 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22736241252918807		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.22736241252918807 | validation: 0.21891419594849287]
	TIME [epoch: 8.99 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21895533098160813		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.21895533098160813 | validation: 0.1889551386983065]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_850.pth
	Model improved!!!
EPOCH 851/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2052386186131117		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.2052386186131117 | validation: 0.2138523217756395]
	TIME [epoch: 8.99 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2162480141468177		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.2162480141468177 | validation: 0.22078309404604926]
	TIME [epoch: 9 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21400603462151957		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.21400603462151957 | validation: 0.20442729011193195]
	TIME [epoch: 9 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20814073576701317		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.20814073576701317 | validation: 0.19935276245345218]
	TIME [epoch: 9.01 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20164979414748457		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.20164979414748457 | validation: 0.21528229785937758]
	TIME [epoch: 9.02 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20551695353524094		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.20551695353524094 | validation: 0.2087867735489976]
	TIME [epoch: 8.99 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20747311673494345		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.20747311673494345 | validation: 0.20646422870271047]
	TIME [epoch: 8.99 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21433442573832542		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.21433442573832542 | validation: 0.21201643022981728]
	TIME [epoch: 8.99 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20702256034178834		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.20702256034178834 | validation: 0.2056791666706223]
	TIME [epoch: 9.01 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21881460769376332		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.21881460769376332 | validation: 0.20996357117243397]
	TIME [epoch: 9 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21523162751681832		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.21523162751681832 | validation: 0.20237654557042262]
	TIME [epoch: 8.99 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21017506174952091		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.21017506174952091 | validation: 0.21511798385594144]
	TIME [epoch: 8.99 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20686308100460732		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.20686308100460732 | validation: 0.19899214404817295]
	TIME [epoch: 8.98 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20464387491888975		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.20464387491888975 | validation: 0.1975553117994542]
	TIME [epoch: 9.02 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2073527581851983		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.2073527581851983 | validation: 0.1915206437506919]
	TIME [epoch: 8.99 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2029806806708862		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.2029806806708862 | validation: 0.20078737616640863]
	TIME [epoch: 9 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20743618815396606		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.20743618815396606 | validation: 0.21208882858414405]
	TIME [epoch: 8.99 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20960028801080294		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.20960028801080294 | validation: 0.18764005117211052]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_868.pth
	Model improved!!!
EPOCH 869/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2029394900418576		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.2029394900418576 | validation: 0.20411881125252962]
	TIME [epoch: 9 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19977468418079333		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.19977468418079333 | validation: 0.1993271528091533]
	TIME [epoch: 8.99 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.204596461420477		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.204596461420477 | validation: 0.19093205108516223]
	TIME [epoch: 8.98 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20811198670250491		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.20811198670250491 | validation: 0.21791782400858228]
	TIME [epoch: 8.99 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2066793734964485		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.2066793734964485 | validation: 0.1965869824903625]
	TIME [epoch: 9.01 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2004171032253526		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.2004171032253526 | validation: 0.18932468786615314]
	TIME [epoch: 9 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20691929079708057		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.20691929079708057 | validation: 0.19877268281110244]
	TIME [epoch: 8.98 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19809030984807158		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.19809030984807158 | validation: 0.2049615037895443]
	TIME [epoch: 8.99 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20783990154099974		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.20783990154099974 | validation: 0.21058638836536356]
	TIME [epoch: 9 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20776921083777253		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.20776921083777253 | validation: 0.19013013364049797]
	TIME [epoch: 9 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2023612358481615		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.2023612358481615 | validation: 0.18567053060103186]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_879.pth
	Model improved!!!
EPOCH 880/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20163469425431207		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.20163469425431207 | validation: 0.18644518005448607]
	TIME [epoch: 9 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20650003788528526		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.20650003788528526 | validation: 0.19522212470032463]
	TIME [epoch: 9 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1960761688307167		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.1960761688307167 | validation: 0.19204004203718994]
	TIME [epoch: 9.02 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19582715932450953		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.19582715932450953 | validation: 0.19638739016532758]
	TIME [epoch: 8.99 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20145380648233163		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.20145380648233163 | validation: 0.1818276693183049]
	TIME [epoch: 8.99 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_884.pth
	Model improved!!!
EPOCH 885/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19447626293202022		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.19447626293202022 | validation: 0.20041670844920956]
	TIME [epoch: 8.99 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20149618456352317		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.20149618456352317 | validation: 0.1945987469017081]
	TIME [epoch: 8.99 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2051407297593598		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.2051407297593598 | validation: 0.19130024412457075]
	TIME [epoch: 9.02 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21358043800035023		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.21358043800035023 | validation: 0.2110465986351136]
	TIME [epoch: 8.98 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20395222370808846		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.20395222370808846 | validation: 0.19960980310392812]
	TIME [epoch: 8.99 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20056636712669826		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.20056636712669826 | validation: 0.20757425281392772]
	TIME [epoch: 8.99 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2036195096155396		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.2036195096155396 | validation: 0.19484371075044785]
	TIME [epoch: 9 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.206890909749065		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.206890909749065 | validation: 0.1953598537087517]
	TIME [epoch: 9.01 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1976381219167802		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.1976381219167802 | validation: 0.19802288602687562]
	TIME [epoch: 8.99 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19926696015661854		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.19926696015661854 | validation: 0.19985208394231874]
	TIME [epoch: 9 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20425318572335086		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.20425318572335086 | validation: 0.18874793925095812]
	TIME [epoch: 9 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20397844097190468		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.20397844097190468 | validation: 0.19717208512917417]
	TIME [epoch: 9 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2025214620170693		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.2025214620170693 | validation: 0.18822094945321471]
	TIME [epoch: 8.98 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2032875974218385		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.2032875974218385 | validation: 0.1979435870925124]
	TIME [epoch: 8.98 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2148588802497855		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.2148588802497855 | validation: 0.19177763067199022]
	TIME [epoch: 8.99 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20836728065796417		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.20836728065796417 | validation: 0.19750110151864197]
	TIME [epoch: 9 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2070359061297749		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.2070359061297749 | validation: 0.18978482874789568]
	TIME [epoch: 9 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20326108181741903		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.20326108181741903 | validation: 0.18833318553087575]
	TIME [epoch: 8.99 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20746095626233757		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.20746095626233757 | validation: 0.1946411629345326]
	TIME [epoch: 8.99 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2124257157680493		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.2124257157680493 | validation: 0.20335436042288121]
	TIME [epoch: 8.99 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20127154140647224		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.20127154140647224 | validation: 0.19598505406614788]
	TIME [epoch: 9.01 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20114348150508382		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.20114348150508382 | validation: 0.20083950516542615]
	TIME [epoch: 8.99 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21920647236792137		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.21920647236792137 | validation: 0.20083004516365965]
	TIME [epoch: 9 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20165803048947248		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.20165803048947248 | validation: 0.19824888292036769]
	TIME [epoch: 8.99 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20241816828974685		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.20241816828974685 | validation: 0.19056423485576568]
	TIME [epoch: 8.99 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20424048816313825		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.20424048816313825 | validation: 0.18197561369798865]
	TIME [epoch: 9.01 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20427766426775987		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.20427766426775987 | validation: 0.19928289519034093]
	TIME [epoch: 8.98 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2061190179863383		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.2061190179863383 | validation: 0.20265812188411175]
	TIME [epoch: 8.98 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2144145836877696		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.2144145836877696 | validation: 0.20047898918537443]
	TIME [epoch: 8.98 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21418182885033654		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.21418182885033654 | validation: 0.19898833789747628]
	TIME [epoch: 9 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2161296550556822		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.2161296550556822 | validation: 0.2065625403088119]
	TIME [epoch: 9 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20695666904987248		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.20695666904987248 | validation: 0.21319100688163284]
	TIME [epoch: 8.98 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20924770636288206		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.20924770636288206 | validation: 0.1989752979536933]
	TIME [epoch: 8.99 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20780393858357354		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.20780393858357354 | validation: 0.18755461189380496]
	TIME [epoch: 8.98 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21322152507033723		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.21322152507033723 | validation: 0.18918962829309924]
	TIME [epoch: 9.01 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20616741319196463		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.20616741319196463 | validation: 0.1959281177764734]
	TIME [epoch: 8.99 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20716051559681103		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.20716051559681103 | validation: 0.18389434571690333]
	TIME [epoch: 8.99 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20690968359564338		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.20690968359564338 | validation: 0.1915874937881559]
	TIME [epoch: 8.99 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2278343241442248		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.2278343241442248 | validation: 0.2126390209311586]
	TIME [epoch: 8.99 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2186423584101643		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.2186423584101643 | validation: 0.1980333939751967]
	TIME [epoch: 9 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2078486293584132		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.2078486293584132 | validation: 0.18884976242001306]
	TIME [epoch: 8.99 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20483963978835923		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.20483963978835923 | validation: 0.20626337231208497]
	TIME [epoch: 8.98 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21687282158885757		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.21687282158885757 | validation: 0.19977517014395368]
	TIME [epoch: 8.99 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2096722038520762		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.2096722038520762 | validation: 0.19999919713060582]
	TIME [epoch: 9 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21122595566099744		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.21122595566099744 | validation: 0.19544788058261037]
	TIME [epoch: 9 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2075212180483518		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.2075212180483518 | validation: 0.19417951467769207]
	TIME [epoch: 8.99 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21315116629314845		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.21315116629314845 | validation: 0.19149669111800446]
	TIME [epoch: 8.99 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2079830359870999		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.2079830359870999 | validation: 0.18553611200709308]
	TIME [epoch: 8.98 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20722484199904284		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.20722484199904284 | validation: 0.18788650169696608]
	TIME [epoch: 9.01 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2029886812927872		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.2029886812927872 | validation: 0.2029057432521571]
	TIME [epoch: 8.99 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20245565705246218		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.20245565705246218 | validation: 0.19833912209529023]
	TIME [epoch: 8.99 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19868841951668575		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.19868841951668575 | validation: 0.19605556034141525]
	TIME [epoch: 8.98 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21402728387731923		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.21402728387731923 | validation: 0.21225005259290103]
	TIME [epoch: 9 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21341801032695504		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.21341801032695504 | validation: 0.18729460949609741]
	TIME [epoch: 8.99 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20749410449939965		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.20749410449939965 | validation: 0.20716099862580922]
	TIME [epoch: 8.98 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2037307088198006		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.2037307088198006 | validation: 0.19174004152812663]
	TIME [epoch: 8.98 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20151524122380954		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.20151524122380954 | validation: 0.19244675956006155]
	TIME [epoch: 8.98 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20411886849058583		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.20411886849058583 | validation: 0.1876486607867725]
	TIME [epoch: 9.02 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20940835850277587		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.20940835850277587 | validation: 0.19690464826680615]
	TIME [epoch: 8.99 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2125632041089614		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.2125632041089614 | validation: 0.19041068152724444]
	TIME [epoch: 8.98 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2037548012964659		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.2037548012964659 | validation: 0.179253989990897]
	TIME [epoch: 8.99 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_945.pth
	Model improved!!!
EPOCH 946/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19609420349595114		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.19609420349595114 | validation: 0.18582770089214762]
	TIME [epoch: 9.07 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19989545166759864		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.19989545166759864 | validation: 0.1975432847125161]
	TIME [epoch: 9.02 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2027672109232254		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.2027672109232254 | validation: 0.19387698728202585]
	TIME [epoch: 9 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20656508927593165		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.20656508927593165 | validation: 0.19710116022319454]
	TIME [epoch: 8.98 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20153919786196056		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.20153919786196056 | validation: 0.19388066366194145]
	TIME [epoch: 8.99 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1937301789298354		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.1937301789298354 | validation: 0.19325141573187848]
	TIME [epoch: 8.99 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20335276332686134		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.20335276332686134 | validation: 0.1935803182776749]
	TIME [epoch: 9 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2056160674005138		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.2056160674005138 | validation: 0.20287162216507]
	TIME [epoch: 8.99 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2011337142935822		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.2011337142935822 | validation: 0.18841321799475524]
	TIME [epoch: 8.99 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20577912091561634		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.20577912091561634 | validation: 0.18411757555538227]
	TIME [epoch: 8.99 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19772136478010602		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.19772136478010602 | validation: 0.19118385645353464]
	TIME [epoch: 9.01 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20231428591478728		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.20231428591478728 | validation: 0.19060622594825366]
	TIME [epoch: 9 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19571320886925886		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.19571320886925886 | validation: 0.18108806162482927]
	TIME [epoch: 8.99 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1992130758144688		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.1992130758144688 | validation: 0.1952680365012156]
	TIME [epoch: 8.98 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19524298908152626		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.19524298908152626 | validation: 0.19013459135063832]
	TIME [epoch: 9 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1949885317911463		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.1949885317911463 | validation: 0.21198142285805582]
	TIME [epoch: 9.01 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19331326001507454		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.19331326001507454 | validation: 0.20171274143078577]
	TIME [epoch: 8.99 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20260567977115923		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.20260567977115923 | validation: 0.1806050874627475]
	TIME [epoch: 8.98 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20586895750090223		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.20586895750090223 | validation: 0.19199155104895838]
	TIME [epoch: 8.98 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20687695938477235		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.20687695938477235 | validation: 0.18993778126237665]
	TIME [epoch: 9.01 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20102693543031971		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.20102693543031971 | validation: 0.2061190644106149]
	TIME [epoch: 8.99 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1997268635958791		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.1997268635958791 | validation: 0.18761835680783906]
	TIME [epoch: 8.99 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1958830640330897		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.1958830640330897 | validation: 0.18325449773233599]
	TIME [epoch: 8.98 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19651718477182217		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.19651718477182217 | validation: 0.19574597128465615]
	TIME [epoch: 8.98 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2040737580716036		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.2040737580716036 | validation: 0.2043154027554105]
	TIME [epoch: 9.01 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19829852627303043		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.19829852627303043 | validation: 0.2024557030592015]
	TIME [epoch: 8.98 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1963723820533332		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.1963723820533332 | validation: 0.2007734539420215]
	TIME [epoch: 8.98 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.202805828870658		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.202805828870658 | validation: 0.19422914510922698]
	TIME [epoch: 8.98 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19970023962654995		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.19970023962654995 | validation: 0.19220661746639367]
	TIME [epoch: 9 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20137444920974854		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.20137444920974854 | validation: 0.184527632631586]
	TIME [epoch: 8.99 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19679214942300002		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.19679214942300002 | validation: 0.1928722805178767]
	TIME [epoch: 8.99 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.200157767616241		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.200157767616241 | validation: 0.1862188389276339]
	TIME [epoch: 8.99 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20033323964244584		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.20033323964244584 | validation: 0.18142602378590753]
	TIME [epoch: 8.99 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19215534220501576		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.19215534220501576 | validation: 0.18999504120905553]
	TIME [epoch: 9 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19360142662881846		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.19360142662881846 | validation: 0.1943200674987305]
	TIME [epoch: 8.99 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19117927284502886		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.19117927284502886 | validation: 0.17748806983421622]
	TIME [epoch: 8.99 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240218_115025/states/model_tr_study3_981.pth
	Model improved!!!
EPOCH 982/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19597376876684566		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.19597376876684566 | validation: 0.18838350584894292]
	TIME [epoch: 8.98 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19735794367436993		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.19735794367436993 | validation: 0.1899254965409573]
	TIME [epoch: 9 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19753956348058424		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.19753956348058424 | validation: 0.192852712331754]
	TIME [epoch: 9 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19372492354806856		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.19372492354806856 | validation: 0.19033738128930391]
	TIME [epoch: 8.99 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19730352769012885		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.19730352769012885 | validation: 0.17964670008807002]
	TIME [epoch: 8.99 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19035971952018765		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.19035971952018765 | validation: 0.18603067803764167]
	TIME [epoch: 8.98 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19917364655043973		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.19917364655043973 | validation: 0.18498770528194436]
	TIME [epoch: 9.01 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20253743272976368		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.20253743272976368 | validation: 0.18093558530413606]
	TIME [epoch: 8.99 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19989643827595943		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.19989643827595943 | validation: 0.19462255975123144]
	TIME [epoch: 8.99 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19418828483231748		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.19418828483231748 | validation: 0.19485761237173982]
	TIME [epoch: 8.98 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1966962947067959		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.1966962947067959 | validation: 0.19260924534243012]
	TIME [epoch: 8.98 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.194037861425991		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.194037861425991 | validation: 0.18333588922040311]
	TIME [epoch: 9.01 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19941896208571444		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.19941896208571444 | validation: 0.1974641457329575]
	TIME [epoch: 8.98 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2025490068115643		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.2025490068115643 | validation: 0.20004896575183864]
	TIME [epoch: 8.99 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20131647668672734		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.20131647668672734 | validation: 0.18641240337780607]
	TIME [epoch: 8.98 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20250703988561022		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.20250703988561022 | validation: 0.18218635178995646]
	TIME [epoch: 9 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19237068442451863		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.19237068442451863 | validation: 0.19075791666475236]
	TIME [epoch: 9 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19195913235073384		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.19195913235073384 | validation: 0.18387460467785935]
	TIME [epoch: 8.98 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19254277109326925		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.19254277109326925 | validation: 0.18590149089529862]
	TIME [epoch: 8.99 sec]
Finished training in 9107.489 seconds.
