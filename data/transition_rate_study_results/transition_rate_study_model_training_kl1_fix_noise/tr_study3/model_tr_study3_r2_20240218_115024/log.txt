Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r2', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 491141211

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/10] avg loss: 9.731722908982073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.731722908982073 | validation: 9.311446612715805]
	TIME [epoch: 79.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/10] avg loss: 9.066911526406164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.066911526406164 | validation: 8.776519131123397]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/10] avg loss: 9.001196999588334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.001196999588334 | validation: 9.325089035694184]
	TIME [epoch: 8.33 sec]
EPOCH 4/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.661603385454827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.661603385454827 | validation: 7.726811380274366]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.709997964541254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.709997964541254 | validation: 7.541873072346884]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.381291296724465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.381291296724465 | validation: 7.616865176784884]
	TIME [epoch: 8.33 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.128408552305377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.128408552305377 | validation: 7.575663720361987]
	TIME [epoch: 8.32 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.934670998481859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.934670998481859 | validation: 7.837689092689438]
	TIME [epoch: 8.32 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.877197690907531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.877197690907531 | validation: 7.268365541760172]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.320389044629289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.320389044629289 | validation: 7.127425503159605]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.22416517436272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.22416517436272 | validation: 6.236276113054357]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.899093583110111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.899093583110111 | validation: 7.2409029073361015]
	TIME [epoch: 8.33 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.550941605514706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.550941605514706 | validation: 5.579479679839538]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.793747558543231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.793747558543231 | validation: 6.135962929669461]
	TIME [epoch: 8.34 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.06458853945208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.06458853945208 | validation: 4.91581876729171]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.574876621388501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.574876621388501 | validation: 4.890315999074948]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.349249222617852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.349249222617852 | validation: 4.291479044611836]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.2747484565264795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2747484565264795 | validation: 4.822272255564641]
	TIME [epoch: 8.33 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.232461619807977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.232461619807977 | validation: 4.204802195501145]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.2532053735302835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2532053735302835 | validation: 3.9239784087503984]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.038396675349957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.038396675349957 | validation: 4.678208389994529]
	TIME [epoch: 8.32 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.205290576898793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.205290576898793 | validation: 5.019639078585449]
	TIME [epoch: 8.34 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.984084365962602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.984084365962602 | validation: 3.6921806515915176]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.693572873422832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.693572873422832 | validation: 4.202684884663734]
	TIME [epoch: 8.32 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.517590154754774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.517590154754774 | validation: 3.6285380615595217]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_25.pth
	Model improved!!!
EPOCH 26/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.209253582798786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.209253582798786 | validation: 6.525853311504984]
	TIME [epoch: 8.34 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.043476146288399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.043476146288399 | validation: 4.07341338308491]
	TIME [epoch: 8.32 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.38495028720332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.38495028720332 | validation: 3.8104751345015]
	TIME [epoch: 8.31 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.2667538557527624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2667538557527624 | validation: 3.8498217016914755]
	TIME [epoch: 8.31 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.179483684015648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.179483684015648 | validation: 3.6221040007790357]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.927944292168624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.927944292168624 | validation: 3.5707387976553657]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_31.pth
	Model improved!!!
EPOCH 32/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.1099925019663575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1099925019663575 | validation: 1.6701809151682894]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.671892264465648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.671892264465648 | validation: 2.264326962468809]
	TIME [epoch: 8.32 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.600359504783168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.600359504783168 | validation: 2.2559562743493484]
	TIME [epoch: 8.31 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.533030880612487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.533030880612487 | validation: 1.5114523960009776]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_35.pth
	Model improved!!!
EPOCH 36/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.1491628993588217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1491628993588217 | validation: 3.1237244307452636]
	TIME [epoch: 8.32 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.2576884131587596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2576884131587596 | validation: 1.77480871831095]
	TIME [epoch: 8.31 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3529899179684035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3529899179684035 | validation: 2.6675337363904137]
	TIME [epoch: 8.31 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.5433180211940156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5433180211940156 | validation: 2.0817943714152682]
	TIME [epoch: 8.34 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.444032858483049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.444032858483049 | validation: 1.9108585353261964]
	TIME [epoch: 8.32 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.375568160540166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.375568160540166 | validation: 1.4329399798919467]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_41.pth
	Model improved!!!
EPOCH 42/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.329029597023515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.329029597023515 | validation: 2.4218189295749686]
	TIME [epoch: 8.31 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.190388108707024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.190388108707024 | validation: 1.3534358548475676]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_43.pth
	Model improved!!!
EPOCH 44/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.1369476648883516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1369476648883516 | validation: 1.5986413304358544]
	TIME [epoch: 8.33 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.2318459469211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2318459469211 | validation: 2.324124884224482]
	TIME [epoch: 8.31 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.061762656612887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.061762656612887 | validation: 2.7242426595183726]
	TIME [epoch: 8.31 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.449355839449366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.449355839449366 | validation: 1.5657499171702043]
	TIME [epoch: 8.31 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.97048239187107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.97048239187107 | validation: 1.7135470517644829]
	TIME [epoch: 8.34 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.000660702235698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.000660702235698 | validation: 1.7026071024765443]
	TIME [epoch: 8.32 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9018030113848479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9018030113848479 | validation: 1.5288082140234502]
	TIME [epoch: 8.31 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8339094413148715		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 1.8339094413148715 | validation: 1.388460819495314]
	TIME [epoch: 8.31 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7871009462498015		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 1.7871009462498015 | validation: 2.636409248841998]
	TIME [epoch: 8.34 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.003294012208893		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 2.003294012208893 | validation: 1.6785279044777437]
	TIME [epoch: 8.32 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.742987505490189		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 1.742987505490189 | validation: 1.9909660542727585]
	TIME [epoch: 8.31 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0241399784419034		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 2.0241399784419034 | validation: 1.4247447969732585]
	TIME [epoch: 8.32 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.064666685813429		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 2.064666685813429 | validation: 1.742548653018477]
	TIME [epoch: 8.33 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8021292297380582		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 1.8021292297380582 | validation: 1.4029436587433683]
	TIME [epoch: 8.33 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5744610251171658		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 1.5744610251171658 | validation: 1.4952217780089359]
	TIME [epoch: 8.31 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.851491245992726		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 1.851491245992726 | validation: 1.5898905660807414]
	TIME [epoch: 8.31 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5702021483622837		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 1.5702021483622837 | validation: 3.5447077033407424]
	TIME [epoch: 8.32 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.356856035902727		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 2.356856035902727 | validation: 1.6386686285035428]
	TIME [epoch: 8.33 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6532741799525064		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 1.6532741799525064 | validation: 1.6087808504572054]
	TIME [epoch: 8.32 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8230308308122118		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 1.8230308308122118 | validation: 1.4304350800909766]
	TIME [epoch: 8.31 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5963587642466275		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 1.5963587642466275 | validation: 1.3091032668623799]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_64.pth
	Model improved!!!
EPOCH 65/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.081943068563777		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 2.081943068563777 | validation: 2.5275083382632904]
	TIME [epoch: 8.33 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9212461495131805		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 1.9212461495131805 | validation: 1.7451528707824857]
	TIME [epoch: 8.31 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6825101934352689		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 1.6825101934352689 | validation: 1.8461034080768264]
	TIME [epoch: 8.31 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.953758919913453		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 1.953758919913453 | validation: 2.4154649524643785]
	TIME [epoch: 8.31 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9814558768093424		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 1.9814558768093424 | validation: 1.9428281225376105]
	TIME [epoch: 8.33 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7946717205364398		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 1.7946717205364398 | validation: 1.6237276439389317]
	TIME [epoch: 8.32 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.626710503440087		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 1.626710503440087 | validation: 1.6747327259886213]
	TIME [epoch: 8.3 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.513963957656784		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 1.513963957656784 | validation: 1.4367997293847568]
	TIME [epoch: 8.3 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6969956244789812		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 1.6969956244789812 | validation: 1.652295258381572]
	TIME [epoch: 8.31 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7593522217389346		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 1.7593522217389346 | validation: 2.2646902707504832]
	TIME [epoch: 8.32 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.959067454817093		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 1.959067454817093 | validation: 1.737557099310195]
	TIME [epoch: 8.32 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5077168676985588		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 1.5077168676985588 | validation: 1.3793316928315937]
	TIME [epoch: 8.3 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5838766315846855		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 1.5838766315846855 | validation: 1.9376401365642995]
	TIME [epoch: 8.31 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6013933635648665		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 1.6013933635648665 | validation: 1.4675310697813617]
	TIME [epoch: 8.33 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5108872725441636		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 1.5108872725441636 | validation: 1.261716009216027]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_79.pth
	Model improved!!!
EPOCH 80/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.592157497672378		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 1.592157497672378 | validation: 1.228182502301788]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_80.pth
	Model improved!!!
EPOCH 81/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5963126493721786		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 1.5963126493721786 | validation: 1.144318692165719]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_81.pth
	Model improved!!!
EPOCH 82/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3612258990464694		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 1.3612258990464694 | validation: 1.9726232777708035]
	TIME [epoch: 8.33 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4923064515130517		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 1.4923064515130517 | validation: 1.4389835606171955]
	TIME [epoch: 8.32 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4319572259287936		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 1.4319572259287936 | validation: 1.5297874694770233]
	TIME [epoch: 8.31 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3956868934468472		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 1.3956868934468472 | validation: 1.475215001546009]
	TIME [epoch: 8.31 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3779477760030745		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 1.3779477760030745 | validation: 1.19441764678478]
	TIME [epoch: 8.3 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2844822790016897		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 1.2844822790016897 | validation: 1.0116455055328148]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_87.pth
	Model improved!!!
EPOCH 88/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2790900676934212		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 1.2790900676934212 | validation: 1.3890654242601164]
	TIME [epoch: 8.31 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3779863709119584		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 1.3779863709119584 | validation: 1.2571323230862905]
	TIME [epoch: 8.31 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.204967955353714		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 1.204967955353714 | validation: 1.0715528899352016]
	TIME [epoch: 8.31 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0934364343847807		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 2.0934364343847807 | validation: 1.8614474117176967]
	TIME [epoch: 8.33 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6207620421463413		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 1.6207620421463413 | validation: 1.1952556867054778]
	TIME [epoch: 8.31 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3277909881310859		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 1.3277909881310859 | validation: 1.254004242709731]
	TIME [epoch: 8.31 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.412096483213244		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 1.412096483213244 | validation: 1.029260516867665]
	TIME [epoch: 8.31 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.430088736906194		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 1.430088736906194 | validation: 1.0702947791256583]
	TIME [epoch: 8.33 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.514659809848287		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 1.514659809848287 | validation: 0.8801054533598254]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_96.pth
	Model improved!!!
EPOCH 97/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.242567640509525		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 1.242567640509525 | validation: 0.897412473074076]
	TIME [epoch: 8.31 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3117602747666528		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 1.3117602747666528 | validation: 1.1434604093559895]
	TIME [epoch: 8.31 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2399584736008085		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 1.2399584736008085 | validation: 1.095014991669663]
	TIME [epoch: 8.3 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2597610746608368		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 1.2597610746608368 | validation: 1.3274654482785762]
	TIME [epoch: 8.34 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2744479174375276		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 1.2744479174375276 | validation: 1.8396826984411643]
	TIME [epoch: 8.31 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3229008049959163		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 1.3229008049959163 | validation: 1.0814786807761134]
	TIME [epoch: 8.31 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1131651562031644		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 1.1131651562031644 | validation: 0.9086793568613409]
	TIME [epoch: 8.31 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.077000910936354		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 1.077000910936354 | validation: 1.0656762229102026]
	TIME [epoch: 8.33 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3557303026000727		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 1.3557303026000727 | validation: 1.0186389526483663]
	TIME [epoch: 8.31 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1815386085628472		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 1.1815386085628472 | validation: 0.7978598962248503]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_106.pth
	Model improved!!!
EPOCH 107/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0306719068090193		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 1.0306719068090193 | validation: 0.9933125013118488]
	TIME [epoch: 8.31 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0280911134760302		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 1.0280911134760302 | validation: 0.7164481169315629]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_108.pth
	Model improved!!!
EPOCH 109/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2695137914289956		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 1.2695137914289956 | validation: 1.0017756858461988]
	TIME [epoch: 8.31 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0956805015599032		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 1.0956805015599032 | validation: 1.3392343753101414]
	TIME [epoch: 8.3 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.108027270548844		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 1.108027270548844 | validation: 0.9201114910435937]
	TIME [epoch: 8.3 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0995044580392128		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 1.0995044580392128 | validation: 1.2639184787937439]
	TIME [epoch: 8.3 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1609548240299772		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 1.1609548240299772 | validation: 0.8248182957466128]
	TIME [epoch: 8.32 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2584829773643023		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 1.2584829773643023 | validation: 2.0049099311283443]
	TIME [epoch: 8.31 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.29296428042371		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 1.29296428042371 | validation: 0.8457558381583512]
	TIME [epoch: 8.3 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9443636939376798		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 0.9443636939376798 | validation: 0.9583954218343325]
	TIME [epoch: 8.3 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9845119985964688		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 0.9845119985964688 | validation: 1.002319110573328]
	TIME [epoch: 8.33 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0065178318263905		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 1.0065178318263905 | validation: 1.253662327421416]
	TIME [epoch: 8.3 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.972879671778532		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 0.972879671778532 | validation: 1.0615090147398474]
	TIME [epoch: 8.3 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1713218396940703		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 1.1713218396940703 | validation: 1.76165583116788]
	TIME [epoch: 8.29 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.116105947271922		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 1.116105947271922 | validation: 0.9135608102868534]
	TIME [epoch: 8.32 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.408484122108956		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 1.408484122108956 | validation: 0.7488775024468185]
	TIME [epoch: 8.32 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8764899229463081		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 0.8764899229463081 | validation: 0.8140646227150442]
	TIME [epoch: 8.31 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0728963417523296		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 1.0728963417523296 | validation: 0.7028051806182046]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_124.pth
	Model improved!!!
EPOCH 125/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8325501492507648		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 0.8325501492507648 | validation: 1.1457412683197985]
	TIME [epoch: 8.31 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0921452313381927		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 1.0921452313381927 | validation: 0.8103092236494294]
	TIME [epoch: 8.33 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1460611110200152		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 1.1460611110200152 | validation: 0.8447205960167293]
	TIME [epoch: 8.31 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1716755423762173		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 1.1716755423762173 | validation: 0.7499900498182359]
	TIME [epoch: 8.3 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0518353448436855		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 1.0518353448436855 | validation: 1.0520742140165615]
	TIME [epoch: 8.31 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.814003102362849		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 0.814003102362849 | validation: 0.7273602433626545]
	TIME [epoch: 8.33 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7977207219906385		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 0.7977207219906385 | validation: 0.8046217643151369]
	TIME [epoch: 8.32 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0067300282296956		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 1.0067300282296956 | validation: 0.6159217005789985]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_132.pth
	Model improved!!!
EPOCH 133/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9250118963547873		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 0.9250118963547873 | validation: 0.7266978374934423]
	TIME [epoch: 8.31 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8805455664694268		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 0.8805455664694268 | validation: 0.8949254922033296]
	TIME [epoch: 8.32 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9373314892286185		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 0.9373314892286185 | validation: 0.8040417596483129]
	TIME [epoch: 8.31 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9943776052451476		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 0.9943776052451476 | validation: 0.5700112240641413]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_136.pth
	Model improved!!!
EPOCH 137/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7253661788554201		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 0.7253661788554201 | validation: 0.6998702086141129]
	TIME [epoch: 8.3 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0258581216190545		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 1.0258581216190545 | validation: 0.8393764233589349]
	TIME [epoch: 8.3 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8015902754488666		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 0.8015902754488666 | validation: 0.7756446454919517]
	TIME [epoch: 8.32 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2541335663021893		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 1.2541335663021893 | validation: 1.7895103516465805]
	TIME [epoch: 8.3 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9957526763222122		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 0.9957526763222122 | validation: 0.8205591398525978]
	TIME [epoch: 8.3 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.831758727684976		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 0.831758727684976 | validation: 0.5685891308335951]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_142.pth
	Model improved!!!
EPOCH 143/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7713397621422413		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 0.7713397621422413 | validation: 0.8181107586421015]
	TIME [epoch: 8.32 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9172293161439289		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 0.9172293161439289 | validation: 0.7242606094759709]
	TIME [epoch: 8.3 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0549442234730484		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 1.0549442234730484 | validation: 0.6624171969469642]
	TIME [epoch: 8.29 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0190109863366354		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 1.0190109863366354 | validation: 2.2436136108307148]
	TIME [epoch: 8.29 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.119085712141286		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 1.119085712141286 | validation: 0.8437722222449291]
	TIME [epoch: 8.31 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1058750843033158		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 1.1058750843033158 | validation: 0.9159395311600714]
	TIME [epoch: 8.31 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.918728956247943		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 0.918728956247943 | validation: 0.5641088223477576]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_149.pth
	Model improved!!!
EPOCH 150/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9439398935944556		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 0.9439398935944556 | validation: 0.7144124515772212]
	TIME [epoch: 8.3 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7998141222239686		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 0.7998141222239686 | validation: 0.690870436028312]
	TIME [epoch: 8.3 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7611082832053481		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 0.7611082832053481 | validation: 0.8219409943345003]
	TIME [epoch: 8.33 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8867726072973106		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 0.8867726072973106 | validation: 0.44418839946928257]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_153.pth
	Model improved!!!
EPOCH 154/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8598351068223066		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 0.8598351068223066 | validation: 0.6863638602372448]
	TIME [epoch: 8.3 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.852353242444438		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 0.852353242444438 | validation: 0.9995382569199189]
	TIME [epoch: 8.3 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4781705338253022		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 1.4781705338253022 | validation: 3.912935861636596]
	TIME [epoch: 8.34 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5080488985441485		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 1.5080488985441485 | validation: 0.6089972627422735]
	TIME [epoch: 8.31 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9238618184228967		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 0.9238618184228967 | validation: 1.067859990376153]
	TIME [epoch: 8.31 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7953909444712483		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 0.7953909444712483 | validation: 0.5631779508794944]
	TIME [epoch: 8.3 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7651410971381194		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 0.7651410971381194 | validation: 0.7982226971960449]
	TIME [epoch: 8.31 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7733078264671173		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 0.7733078264671173 | validation: 0.734066875780857]
	TIME [epoch: 8.32 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7929726830130305		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 0.7929726830130305 | validation: 0.4928591448998003]
	TIME [epoch: 8.31 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7333146842584708		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 0.7333146842584708 | validation: 0.9293080754969132]
	TIME [epoch: 8.31 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.793370429870139		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 0.793370429870139 | validation: 1.000675183291928]
	TIME [epoch: 8.3 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8345526694596337		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 0.8345526694596337 | validation: 0.8667506900380948]
	TIME [epoch: 8.33 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7841480103006464		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.7841480103006464 | validation: 0.9986809476219831]
	TIME [epoch: 8.31 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8900228871935709		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 0.8900228871935709 | validation: 0.513578301813451]
	TIME [epoch: 8.31 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7680251201140618		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 0.7680251201140618 | validation: 0.5801453574765929]
	TIME [epoch: 8.3 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0963370152080663		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 1.0963370152080663 | validation: 0.6680849940615327]
	TIME [epoch: 8.33 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7325208620183981		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 0.7325208620183981 | validation: 0.7154970833543594]
	TIME [epoch: 8.31 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7163559388485654		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 0.7163559388485654 | validation: 0.5028583499840212]
	TIME [epoch: 8.31 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8876072633909053		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 0.8876072633909053 | validation: 0.773253247555551]
	TIME [epoch: 8.31 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.675037273945812		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 0.675037273945812 | validation: 1.0182824098557846]
	TIME [epoch: 8.31 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7852534501366268		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 0.7852534501366268 | validation: 0.6051801577341588]
	TIME [epoch: 8.33 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0282434619567078		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 1.0282434619567078 | validation: 0.5188409449880969]
	TIME [epoch: 8.3 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9312996037398211		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.9312996037398211 | validation: 0.5399786824151167]
	TIME [epoch: 8.3 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7000566452470327		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 0.7000566452470327 | validation: 0.6907440825115997]
	TIME [epoch: 8.3 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6558984763177576		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 0.6558984763177576 | validation: 0.4803926527577955]
	TIME [epoch: 8.32 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7721967988237878		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.7721967988237878 | validation: 0.677156410346024]
	TIME [epoch: 8.3 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7186757070777676		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 0.7186757070777676 | validation: 0.6952113695887864]
	TIME [epoch: 8.3 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7165348716696784		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 0.7165348716696784 | validation: 0.5108172055566975]
	TIME [epoch: 8.29 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7762846003392381		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.7762846003392381 | validation: 0.5526362177632045]
	TIME [epoch: 8.32 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6026498163482673		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 0.6026498163482673 | validation: 0.42921763161032206]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_183.pth
	Model improved!!!
EPOCH 184/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5928217135110472		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 0.5928217135110472 | validation: 0.9232167386665509]
	TIME [epoch: 8.3 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6896878309885337		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.6896878309885337 | validation: 0.7024868471930619]
	TIME [epoch: 8.3 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9151544262298058		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.9151544262298058 | validation: 0.6480436913283398]
	TIME [epoch: 8.31 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.702802584263112		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 0.702802584263112 | validation: 1.0671871620954563]
	TIME [epoch: 8.33 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8714597883773842		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 0.8714597883773842 | validation: 0.7141269661671337]
	TIME [epoch: 8.31 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6673323617749003		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 0.6673323617749003 | validation: 0.7555947957031826]
	TIME [epoch: 8.3 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6714855886301765		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.6714855886301765 | validation: 0.7476467777754395]
	TIME [epoch: 8.3 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6248949799390695		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 0.6248949799390695 | validation: 0.3373237008527685]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_191.pth
	Model improved!!!
EPOCH 192/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6694400134960052		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 0.6694400134960052 | validation: 0.4758872827492229]
	TIME [epoch: 8.32 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6720657628973262		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 0.6720657628973262 | validation: 0.46417636989424677]
	TIME [epoch: 8.32 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6062487725932667		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.6062487725932667 | validation: 0.4367848433213083]
	TIME [epoch: 8.31 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6855060967550483		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.6855060967550483 | validation: 0.4290960210691671]
	TIME [epoch: 8.33 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7059763173874328		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.7059763173874328 | validation: 0.6660320985649117]
	TIME [epoch: 8.32 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6312708445225013		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.6312708445225013 | validation: 0.5394775960259678]
	TIME [epoch: 8.32 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6787469860679631		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 0.6787469860679631 | validation: 0.4978614134927858]
	TIME [epoch: 8.31 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8030945983535972		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.8030945983535972 | validation: 0.9888167344614897]
	TIME [epoch: 8.31 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9149168385316548		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.9149168385316548 | validation: 0.7742885183021169]
	TIME [epoch: 8.34 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6412974822164446		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.6412974822164446 | validation: 0.6329678129880439]
	TIME [epoch: 8.31 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5409617642903012		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.5409617642903012 | validation: 0.7524792070531847]
	TIME [epoch: 8.31 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6441804778880373		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 0.6441804778880373 | validation: 0.8069667992745322]
	TIME [epoch: 8.31 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6773088491540278		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.6773088491540278 | validation: 0.9101581910834742]
	TIME [epoch: 8.34 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0096170766611738		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 1.0096170766611738 | validation: 0.927017711699043]
	TIME [epoch: 8.32 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9345625920096063		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 0.9345625920096063 | validation: 1.0900130177535825]
	TIME [epoch: 8.31 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.99280265730604		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 1.99280265730604 | validation: 0.9979723643774652]
	TIME [epoch: 8.31 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7856053552430946		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.7856053552430946 | validation: 0.5066804706078766]
	TIME [epoch: 8.34 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7785132344662521		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.7785132344662521 | validation: 0.5731149580358941]
	TIME [epoch: 8.32 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6770936844673646		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.6770936844673646 | validation: 0.9482720612450617]
	TIME [epoch: 8.31 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.671553117068736		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.671553117068736 | validation: 0.45525162164468697]
	TIME [epoch: 8.32 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1591581025768234		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 1.1591581025768234 | validation: 1.4334045231420434]
	TIME [epoch: 8.32 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9688015775426088		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.9688015775426088 | validation: 0.5597283595581224]
	TIME [epoch: 8.34 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.812705093598969		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.812705093598969 | validation: 0.9563821133159527]
	TIME [epoch: 8.31 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6996909556997007		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.6996909556997007 | validation: 0.6066760355191728]
	TIME [epoch: 8.31 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7355859319508329		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.7355859319508329 | validation: 0.9952629109616818]
	TIME [epoch: 8.31 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.718348810653224		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.718348810653224 | validation: 0.575776928761768]
	TIME [epoch: 8.34 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7949307671367872		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.7949307671367872 | validation: 0.36454857934460916]
	TIME [epoch: 8.32 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5250181915305816		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.5250181915305816 | validation: 1.0955487808233462]
	TIME [epoch: 8.32 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7079442127033927		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.7079442127033927 | validation: 0.39628347690043647]
	TIME [epoch: 8.31 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8014887284108682		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.8014887284108682 | validation: 0.4985006857806577]
	TIME [epoch: 8.34 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6653284059393056		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.6653284059393056 | validation: 0.6427122177799554]
	TIME [epoch: 8.32 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5160806826354797		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.5160806826354797 | validation: 0.4008321846695596]
	TIME [epoch: 8.32 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.596738801418603		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.596738801418603 | validation: 0.7590984344319658]
	TIME [epoch: 8.31 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5906878536241837		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.5906878536241837 | validation: 0.5676375138069998]
	TIME [epoch: 8.32 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.673832906771431		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.673832906771431 | validation: 0.6413807390741708]
	TIME [epoch: 8.34 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6037300229000935		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.6037300229000935 | validation: 0.7041164914956639]
	TIME [epoch: 8.32 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6850348397714154		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.6850348397714154 | validation: 0.5303444266224724]
	TIME [epoch: 8.31 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48153805991718324		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.48153805991718324 | validation: 1.0578359766114396]
	TIME [epoch: 8.32 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6776314789226318		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.6776314789226318 | validation: 0.3830458961023338]
	TIME [epoch: 8.34 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5675373199291407		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.5675373199291407 | validation: 0.8233459171915521]
	TIME [epoch: 8.32 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5834984826234996		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.5834984826234996 | validation: 0.45600661316905955]
	TIME [epoch: 8.31 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.566023052662073		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.566023052662073 | validation: 0.37227713346563496]
	TIME [epoch: 8.32 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5843764053841531		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.5843764053841531 | validation: 0.5519652733512619]
	TIME [epoch: 8.34 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.75910185279633		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.75910185279633 | validation: 0.8025916955932086]
	TIME [epoch: 8.32 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6979971900100432		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.6979971900100432 | validation: 0.385073648334481]
	TIME [epoch: 8.32 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5097342341965276		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.5097342341965276 | validation: 0.3324089371016903]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_237.pth
	Model improved!!!
EPOCH 238/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6007575065874672		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.6007575065874672 | validation: 0.38010506549776946]
	TIME [epoch: 8.32 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49220331255925415		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.49220331255925415 | validation: 0.3532748843520582]
	TIME [epoch: 8.34 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7366709880226506		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.7366709880226506 | validation: 0.7139443017658478]
	TIME [epoch: 8.31 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5530170776536607		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.5530170776536607 | validation: 0.40913261076413115]
	TIME [epoch: 8.32 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5404341529999749		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.5404341529999749 | validation: 0.6580539755407531]
	TIME [epoch: 8.32 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7530542211815573		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.7530542211815573 | validation: 0.41976422250363865]
	TIME [epoch: 8.34 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6441321850063846		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.6441321850063846 | validation: 0.734099415399087]
	TIME [epoch: 8.32 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5882845460565235		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.5882845460565235 | validation: 0.5635748409673966]
	TIME [epoch: 8.32 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5325563036656396		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.5325563036656396 | validation: 0.47570166180121476]
	TIME [epoch: 8.31 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.578430883326142		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.578430883326142 | validation: 0.560078258047195]
	TIME [epoch: 8.33 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8234458059405471		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.8234458059405471 | validation: 0.4172310781676071]
	TIME [epoch: 8.32 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.579176708574751		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.579176708574751 | validation: 0.5005213198058649]
	TIME [epoch: 8.32 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5683804153169756		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.5683804153169756 | validation: 0.2962846124444637]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_250.pth
	Model improved!!!
EPOCH 251/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.634108528218285		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.634108528218285 | validation: 1.620546116257647]
	TIME [epoch: 8.32 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.865106958920491		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.865106958920491 | validation: 0.6247994594042021]
	TIME [epoch: 8.33 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6710313901876943		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.6710313901876943 | validation: 0.807924604037826]
	TIME [epoch: 8.31 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7345962898542451		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.7345962898542451 | validation: 0.5157305499844987]
	TIME [epoch: 8.31 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6714236717854171		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.6714236717854171 | validation: 0.5378208084952996]
	TIME [epoch: 8.31 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5588598885017084		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.5588598885017084 | validation: 0.6438564133470345]
	TIME [epoch: 8.34 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6086670263260293		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.6086670263260293 | validation: 0.48957796981882856]
	TIME [epoch: 8.31 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.555289212729878		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.555289212729878 | validation: 0.3896931504211634]
	TIME [epoch: 8.31 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5220807068317099		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.5220807068317099 | validation: 0.41671019156903516]
	TIME [epoch: 8.31 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5138109280879345		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.5138109280879345 | validation: 0.37509080574370207]
	TIME [epoch: 8.33 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4762108907211811		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.4762108907211811 | validation: 0.6586751418467232]
	TIME [epoch: 8.32 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.552203893528966		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.552203893528966 | validation: 0.4295250703626347]
	TIME [epoch: 8.31 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5368715779398328		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.5368715779398328 | validation: 0.43087319100717103]
	TIME [epoch: 8.31 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.567652329352953		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.567652329352953 | validation: 0.4051900490529424]
	TIME [epoch: 8.31 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4704636036393114		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.4704636036393114 | validation: 0.46241562247243995]
	TIME [epoch: 8.34 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.575773042934809		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.575773042934809 | validation: 0.4147546230363278]
	TIME [epoch: 8.31 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5306117093976159		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.5306117093976159 | validation: 0.36854467664317253]
	TIME [epoch: 8.31 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4397497377098863		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.4397497377098863 | validation: 0.32145371449211335]
	TIME [epoch: 8.31 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5260144201595021		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.5260144201595021 | validation: 0.5245072279328571]
	TIME [epoch: 8.33 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5658045858493346		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.5658045858493346 | validation: 0.35681554843849217]
	TIME [epoch: 8.31 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5989218447894974		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.5989218447894974 | validation: 0.5314716338068834]
	TIME [epoch: 8.31 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5415067961914557		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.5415067961914557 | validation: 0.583878382617304]
	TIME [epoch: 8.31 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5597243192261971		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.5597243192261971 | validation: 0.39051506140076314]
	TIME [epoch: 8.33 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4578723541388385		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.4578723541388385 | validation: 0.6427916838013206]
	TIME [epoch: 8.32 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6147943678293347		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.6147943678293347 | validation: 0.41521564270860156]
	TIME [epoch: 8.31 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5769009883044743		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.5769009883044743 | validation: 0.7376753971844132]
	TIME [epoch: 8.31 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.727168929883345		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.727168929883345 | validation: 0.717610683808716]
	TIME [epoch: 8.31 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5644836794810406		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.5644836794810406 | validation: 1.1905749461466386]
	TIME [epoch: 8.33 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7187160686714		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.7187160686714 | validation: 0.5284978613010611]
	TIME [epoch: 8.31 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5567935367520347		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.5567935367520347 | validation: 0.5606400498607759]
	TIME [epoch: 8.31 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5788389797304675		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.5788389797304675 | validation: 0.6577861331400077]
	TIME [epoch: 8.31 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.532952238003092		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.532952238003092 | validation: 0.3325826719393973]
	TIME [epoch: 8.34 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5782557330686153		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.5782557330686153 | validation: 0.5304720568216548]
	TIME [epoch: 8.32 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6001355912909417		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.6001355912909417 | validation: 0.6197921510810795]
	TIME [epoch: 8.32 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48720652878280124		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.48720652878280124 | validation: 0.4358083834783064]
	TIME [epoch: 8.32 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5699102738244008		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.5699102738244008 | validation: 0.47435669436971073]
	TIME [epoch: 8.31 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6328339810049874		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.6328339810049874 | validation: 0.5944511777358068]
	TIME [epoch: 8.33 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7621644527769107		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.7621644527769107 | validation: 0.4490642485463652]
	TIME [epoch: 8.31 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6505942111350966		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.6505942111350966 | validation: 0.4753969516485709]
	TIME [epoch: 8.32 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6334622673180965		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.6334622673180965 | validation: 0.4898325595071478]
	TIME [epoch: 8.32 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49713857503503933		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.49713857503503933 | validation: 0.3181400466145812]
	TIME [epoch: 8.34 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6268335590175217		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.6268335590175217 | validation: 0.4142561108669195]
	TIME [epoch: 8.32 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8553108658222541		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.8553108658222541 | validation: 0.5022732348851855]
	TIME [epoch: 8.31 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6062741321015807		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.6062741321015807 | validation: 0.5439744382275686]
	TIME [epoch: 8.31 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6917948384177428		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.6917948384177428 | validation: 0.4962403824106628]
	TIME [epoch: 8.34 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5230000523563667		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.5230000523563667 | validation: 0.37816477231396817]
	TIME [epoch: 8.32 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6626804982500795		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.6626804982500795 | validation: 0.40352214120961827]
	TIME [epoch: 8.31 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6057228864011306		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.6057228864011306 | validation: 0.48612389601284856]
	TIME [epoch: 8.32 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47696011529068344		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.47696011529068344 | validation: 0.5800373211885013]
	TIME [epoch: 8.32 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4797376643970309		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.4797376643970309 | validation: 0.45614755561179243]
	TIME [epoch: 8.34 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.498131832737842		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.498131832737842 | validation: 0.3122372024636393]
	TIME [epoch: 8.32 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5023759795946982		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.5023759795946982 | validation: 0.4289936346809281]
	TIME [epoch: 8.31 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5222276965450218		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.5222276965450218 | validation: 0.4526522093567393]
	TIME [epoch: 8.31 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4045450124367956		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.4045450124367956 | validation: 0.3550393136172958]
	TIME [epoch: 8.34 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5270551524972387		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.5270551524972387 | validation: 0.4536633778855125]
	TIME [epoch: 8.32 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5023489174200946		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.5023489174200946 | validation: 0.2848807217793886]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_306.pth
	Model improved!!!
EPOCH 307/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4428795074528189		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.4428795074528189 | validation: 0.40123088800473516]
	TIME [epoch: 8.31 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3898412595961204		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.3898412595961204 | validation: 0.29303909133003864]
	TIME [epoch: 8.33 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4487177150199663		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.4487177150199663 | validation: 0.39839833774994426]
	TIME [epoch: 8.31 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4481593478530851		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.4481593478530851 | validation: 0.5446362513052304]
	TIME [epoch: 8.31 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5060750216745677		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.5060750216745677 | validation: 0.5158641967811457]
	TIME [epoch: 8.31 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4625987719454505		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.4625987719454505 | validation: 0.36028005616353265]
	TIME [epoch: 8.31 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4741289542084671		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.4741289542084671 | validation: 0.551814540719211]
	TIME [epoch: 8.33 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5118265574639227		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.5118265574639227 | validation: 0.33283093881467996]
	TIME [epoch: 8.31 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4302152075752611		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.4302152075752611 | validation: 0.3533551748493896]
	TIME [epoch: 8.31 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4634903818845871		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.4634903818845871 | validation: 0.6646426284340697]
	TIME [epoch: 8.31 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5032342753919667		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.5032342753919667 | validation: 0.3373950256524004]
	TIME [epoch: 8.33 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4722880663420689		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.4722880663420689 | validation: 0.6962988932720847]
	TIME [epoch: 8.31 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6302848173517138		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.6302848173517138 | validation: 0.5070265495559934]
	TIME [epoch: 8.31 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4494110093488601		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.4494110093488601 | validation: 0.461878778000557]
	TIME [epoch: 8.3 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44968510340084766		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.44968510340084766 | validation: 0.9950278193533342]
	TIME [epoch: 8.33 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47058479314119406		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.47058479314119406 | validation: 0.44215038281447105]
	TIME [epoch: 8.31 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46423583012969816		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.46423583012969816 | validation: 0.43846403210692436]
	TIME [epoch: 8.31 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46442495948850293		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.46442495948850293 | validation: 0.42391583167182767]
	TIME [epoch: 8.31 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43757280318791086		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.43757280318791086 | validation: 0.345363968069012]
	TIME [epoch: 8.31 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42182552544064045		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.42182552544064045 | validation: 0.34442377608952834]
	TIME [epoch: 8.33 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4230064474692908		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.4230064474692908 | validation: 0.40621197190462965]
	TIME [epoch: 8.31 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47179197093351144		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.47179197093351144 | validation: 0.2836830910264926]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_328.pth
	Model improved!!!
EPOCH 329/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5297518656513025		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.5297518656513025 | validation: 0.8104442424386264]
	TIME [epoch: 8.31 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4567767654707673		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.4567767654707673 | validation: 0.4642570059239857]
	TIME [epoch: 8.33 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.391747196400834		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.391747196400834 | validation: 0.35866590825096256]
	TIME [epoch: 8.31 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4152962003585971		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.4152962003585971 | validation: 0.41618499027865424]
	TIME [epoch: 8.31 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47066284482067655		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.47066284482067655 | validation: 0.4779594983601225]
	TIME [epoch: 8.3 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5333969740896215		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.5333969740896215 | validation: 0.3641891526850288]
	TIME [epoch: 8.33 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4133998336018557		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.4133998336018557 | validation: 0.658411889383193]
	TIME [epoch: 8.31 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4950354498231282		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.4950354498231282 | validation: 0.3407238171778483]
	TIME [epoch: 8.31 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3909099911771745		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.3909099911771745 | validation: 0.3274996780106424]
	TIME [epoch: 8.31 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38152317372874045		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.38152317372874045 | validation: 0.2529844347238478]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_338.pth
	Model improved!!!
EPOCH 339/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36472809068715595		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.36472809068715595 | validation: 0.271329139894364]
	TIME [epoch: 8.34 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3830927066798696		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.3830927066798696 | validation: 0.510364515520449]
	TIME [epoch: 8.31 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4478916903195536		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.4478916903195536 | validation: 0.2888572183797994]
	TIME [epoch: 8.31 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.635682423505886		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.635682423505886 | validation: 0.4384377145310272]
	TIME [epoch: 8.31 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36177956217479973		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.36177956217479973 | validation: 0.418439654706669]
	TIME [epoch: 8.33 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43220814227775106		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.43220814227775106 | validation: 0.28005750873632496]
	TIME [epoch: 8.31 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4084383122671391		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.4084383122671391 | validation: 0.38100795417275]
	TIME [epoch: 8.31 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4296579849736677		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.4296579849736677 | validation: 0.634971712319637]
	TIME [epoch: 8.31 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47715741790679445		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.47715741790679445 | validation: 0.3794317426571857]
	TIME [epoch: 8.33 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4331242297977621		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.4331242297977621 | validation: 0.33332294201782386]
	TIME [epoch: 8.31 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4501690252869791		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.4501690252869791 | validation: 0.35161382736608515]
	TIME [epoch: 8.31 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4712982726150665		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.4712982726150665 | validation: 0.34546024347894255]
	TIME [epoch: 8.3 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44415637390781415		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.44415637390781415 | validation: 0.33365259324402907]
	TIME [epoch: 8.31 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46560377498550265		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.46560377498550265 | validation: 0.7451391234501081]
	TIME [epoch: 8.33 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5423562386909863		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.5423562386909863 | validation: 0.42708620587865925]
	TIME [epoch: 8.31 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45866193724160925		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.45866193724160925 | validation: 0.3892228811929008]
	TIME [epoch: 8.31 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37578741464110155		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.37578741464110155 | validation: 0.5759961893892958]
	TIME [epoch: 8.31 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4200053140055072		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.4200053140055072 | validation: 0.3145559770749083]
	TIME [epoch: 8.33 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.547197408326105		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.547197408326105 | validation: 0.37460411271410654]
	TIME [epoch: 8.31 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4606499558996077		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.4606499558996077 | validation: 0.3673738069148579]
	TIME [epoch: 8.31 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5038621734820905		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.5038621734820905 | validation: 0.29805806533044304]
	TIME [epoch: 8.31 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39002215857038347		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.39002215857038347 | validation: 0.3298056821326379]
	TIME [epoch: 8.32 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4655466813417828		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.4655466813417828 | validation: 0.2827281765075623]
	TIME [epoch: 8.32 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4261451971326853		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.4261451971326853 | validation: 0.28222851674243854]
	TIME [epoch: 8.31 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39784981393453805		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.39784981393453805 | validation: 0.24982720528206526]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_363.pth
	Model improved!!!
EPOCH 364/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3664833735288239		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.3664833735288239 | validation: 0.5840280838583984]
	TIME [epoch: 8.31 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38663433900268346		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.38663433900268346 | validation: 0.3003003455730397]
	TIME [epoch: 8.32 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4052148765778088		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.4052148765778088 | validation: 0.24608185469283422]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_366.pth
	Model improved!!!
EPOCH 367/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33018589577862595		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.33018589577862595 | validation: 0.27617678809488827]
	TIME [epoch: 8.3 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3785840370648685		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.3785840370648685 | validation: 0.2562495095115537]
	TIME [epoch: 8.3 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34649911743245654		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.34649911743245654 | validation: 0.3561822790602942]
	TIME [epoch: 8.33 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4646081765183361		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.4646081765183361 | validation: 0.5992577965662306]
	TIME [epoch: 8.31 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44627359451723353		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.44627359451723353 | validation: 0.445690432370537]
	TIME [epoch: 8.31 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4270059326850955		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.4270059326850955 | validation: 0.29331558824718895]
	TIME [epoch: 8.3 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35493942146005253		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.35493942146005253 | validation: 0.32409860602535656]
	TIME [epoch: 8.32 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38416800935496614		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.38416800935496614 | validation: 0.27635738724123843]
	TIME [epoch: 8.32 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3380184568264223		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.3380184568264223 | validation: 0.3635115065913245]
	TIME [epoch: 8.31 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3922356945205807		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.3922356945205807 | validation: 0.5012688157198062]
	TIME [epoch: 8.3 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3897243303677021		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.3897243303677021 | validation: 0.2409088911974357]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_377.pth
	Model improved!!!
EPOCH 378/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3504171026006937		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.3504171026006937 | validation: 0.3664458166666297]
	TIME [epoch: 8.33 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37952155627077533		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.37952155627077533 | validation: 0.32699669237645107]
	TIME [epoch: 8.3 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4093549703639036		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.4093549703639036 | validation: 0.3551786181204476]
	TIME [epoch: 8.31 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4654091279956571		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.4654091279956571 | validation: 0.3127746939124567]
	TIME [epoch: 8.3 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3943129214176543		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.3943129214176543 | validation: 0.2306675024780463]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_382.pth
	Model improved!!!
EPOCH 383/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3962166274977488		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.3962166274977488 | validation: 0.4874106356491296]
	TIME [epoch: 8.31 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40460498131319095		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.40460498131319095 | validation: 0.2498247602519225]
	TIME [epoch: 8.3 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.345603471602727		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.345603471602727 | validation: 0.29827688326179425]
	TIME [epoch: 8.3 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3994668197737121		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.3994668197737121 | validation: 0.28022466216398967]
	TIME [epoch: 8.32 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37127718449493424		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.37127718449493424 | validation: 0.3184375288711336]
	TIME [epoch: 8.3 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.459252155233752		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.459252155233752 | validation: 0.41420159610229723]
	TIME [epoch: 8.3 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4225827452762957		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.4225827452762957 | validation: 0.28926418855863306]
	TIME [epoch: 8.3 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33869615184796287		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.33869615184796287 | validation: 0.269788023845842]
	TIME [epoch: 8.3 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35622067924175405		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.35622067924175405 | validation: 0.34786059824421856]
	TIME [epoch: 8.33 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35832250367259366		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.35832250367259366 | validation: 0.2481946339543188]
	TIME [epoch: 8.3 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35898273828902116		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.35898273828902116 | validation: 0.29691719134199446]
	TIME [epoch: 8.3 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4008286293588835		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.4008286293588835 | validation: 0.3783914963513473]
	TIME [epoch: 8.3 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46839642832668077		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.46839642832668077 | validation: 0.3213549180798021]
	TIME [epoch: 8.32 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38285546529739956		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.38285546529739956 | validation: 0.4237385583756117]
	TIME [epoch: 8.3 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3955461203191039		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.3955461203191039 | validation: 0.4277836633093881]
	TIME [epoch: 8.3 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38643325541218965		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.38643325541218965 | validation: 0.4342341205158152]
	TIME [epoch: 8.3 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37613022711767174		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.37613022711767174 | validation: 0.33899679245722686]
	TIME [epoch: 8.32 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41265580512687305		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.41265580512687305 | validation: 0.24398762285135883]
	TIME [epoch: 8.32 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4021641156503546		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.4021641156503546 | validation: 0.3128460500969279]
	TIME [epoch: 8.3 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33539208038370166		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.33539208038370166 | validation: 0.40450891933508043]
	TIME [epoch: 8.3 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3714646190566797		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.3714646190566797 | validation: 0.27342186588736705]
	TIME [epoch: 8.3 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.313226479434463		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.313226479434463 | validation: 0.32135832234623185]
	TIME [epoch: 8.32 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33587603534210975		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.33587603534210975 | validation: 0.321906799851092]
	TIME [epoch: 8.3 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.320113605682753		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.320113605682753 | validation: 0.2254557056125847]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_406.pth
	Model improved!!!
EPOCH 407/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3113425703171487		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.3113425703171487 | validation: 0.29335016892022936]
	TIME [epoch: 8.3 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35087798972968287		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.35087798972968287 | validation: 0.2566893921834704]
	TIME [epoch: 8.32 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38079787792283837		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.38079787792283837 | validation: 0.24472978543780505]
	TIME [epoch: 8.3 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2879924584320035		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.2879924584320035 | validation: 0.2727415882981786]
	TIME [epoch: 8.3 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3679705414585222		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.3679705414585222 | validation: 0.3812211076226011]
	TIME [epoch: 8.3 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4096456920302912		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.4096456920302912 | validation: 0.25326659755719183]
	TIME [epoch: 8.32 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4031119221558683		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.4031119221558683 | validation: 0.34212350457066965]
	TIME [epoch: 8.31 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3184587380647582		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.3184587380647582 | validation: 0.37567278822926636]
	TIME [epoch: 8.3 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42804921002638013		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.42804921002638013 | validation: 0.32916315699369414]
	TIME [epoch: 8.3 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3805415352527857		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.3805415352527857 | validation: 0.32037382428952055]
	TIME [epoch: 8.3 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30138137977639257		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.30138137977639257 | validation: 0.3358652550721218]
	TIME [epoch: 8.32 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3316864044278883		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.3316864044278883 | validation: 0.2745370449931913]
	TIME [epoch: 8.34 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3587352704824198		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.3587352704824198 | validation: 0.28032001481068625]
	TIME [epoch: 8.3 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3140718076412503		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.3140718076412503 | validation: 0.39317355966256223]
	TIME [epoch: 8.3 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4588303266023571		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.4588303266023571 | validation: 0.4743037514002663]
	TIME [epoch: 8.32 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3461969269251413		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.3461969269251413 | validation: 0.22657423505298468]
	TIME [epoch: 8.3 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39775155450687205		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.39775155450687205 | validation: 0.28848369603343027]
	TIME [epoch: 8.3 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36488912555102343		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.36488912555102343 | validation: 0.24290621555398562]
	TIME [epoch: 8.3 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35502682476752156		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.35502682476752156 | validation: 0.4214044763649562]
	TIME [epoch: 8.3 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41248628665996023		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.41248628665996023 | validation: 0.30060079780770776]
	TIME [epoch: 8.32 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32777951174489417		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.32777951174489417 | validation: 0.2150812584982104]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_427.pth
	Model improved!!!
EPOCH 428/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29478046027218385		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.29478046027218385 | validation: 0.36248463724911517]
	TIME [epoch: 8.31 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3252136110316818		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.3252136110316818 | validation: 0.28660277683996194]
	TIME [epoch: 8.3 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31083580609738165		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.31083580609738165 | validation: 0.23540139121136613]
	TIME [epoch: 8.32 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35602091578932166		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.35602091578932166 | validation: 0.3691640716939306]
	TIME [epoch: 8.3 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3354696820970193		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.3354696820970193 | validation: 0.43031997745757977]
	TIME [epoch: 8.3 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34564890590188474		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.34564890590188474 | validation: 0.24629326635617443]
	TIME [epoch: 8.3 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28413995527605623		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.28413995527605623 | validation: 0.37763070632260554]
	TIME [epoch: 8.33 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33963615266382335		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.33963615266382335 | validation: 0.25274479493938745]
	TIME [epoch: 8.31 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3703607451658244		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.3703607451658244 | validation: 0.23742713099065874]
	TIME [epoch: 8.3 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3044940604735449		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.3044940604735449 | validation: 0.2846943544354428]
	TIME [epoch: 8.3 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4597471669533274		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.4597471669533274 | validation: 0.3222284780523197]
	TIME [epoch: 8.31 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37323925358599164		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.37323925358599164 | validation: 0.35187404600062444]
	TIME [epoch: 8.32 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4049332883810031		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.4049332883810031 | validation: 0.2411193935488844]
	TIME [epoch: 8.3 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3921617089904415		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.3921617089904415 | validation: 0.31055336200876893]
	TIME [epoch: 8.3 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3691093286830035		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.3691093286830035 | validation: 0.35374079315373896]
	TIME [epoch: 8.3 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3239360248314203		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.3239360248314203 | validation: 0.3198910217768729]
	TIME [epoch: 8.33 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33702963993065577		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.33702963993065577 | validation: 0.2118725681644503]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_444.pth
	Model improved!!!
EPOCH 445/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3568547722969262		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.3568547722969262 | validation: 0.2912529588151457]
	TIME [epoch: 8.3 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3454132632106851		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.3454132632106851 | validation: 0.29880875942644536]
	TIME [epoch: 8.3 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3879433037123878		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.3879433037123878 | validation: 0.29037179307242217]
	TIME [epoch: 8.33 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.419308329596859		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.419308329596859 | validation: 0.28411366745565947]
	TIME [epoch: 8.3 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38331852125337235		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.38331852125337235 | validation: 0.3658560624657712]
	TIME [epoch: 8.3 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3477385021213721		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.3477385021213721 | validation: 0.2977567860407463]
	TIME [epoch: 8.3 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33427519916717785		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.33427519916717785 | validation: 0.2693243114170334]
	TIME [epoch: 8.3 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39277126314323496		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.39277126314323496 | validation: 0.2955704940622089]
	TIME [epoch: 8.32 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33105892653476626		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.33105892653476626 | validation: 0.2399268469088469]
	TIME [epoch: 8.3 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3175645669435883		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.3175645669435883 | validation: 0.2701737979253268]
	TIME [epoch: 8.3 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3302757148656383		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.3302757148656383 | validation: 0.36161294866675375]
	TIME [epoch: 8.3 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4168684188343028		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.4168684188343028 | validation: 0.34120389055464945]
	TIME [epoch: 8.32 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3635706067118728		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.3635706067118728 | validation: 0.36498369312391843]
	TIME [epoch: 8.31 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37663944739348565		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.37663944739348565 | validation: 0.2708297250816383]
	TIME [epoch: 8.3 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39232981361254426		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.39232981361254426 | validation: 0.21298847726135384]
	TIME [epoch: 8.31 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29210859997633914		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.29210859997633914 | validation: 0.20749301365230244]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_460.pth
	Model improved!!!
EPOCH 461/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30746054757886826		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.30746054757886826 | validation: 0.37619969187413627]
	TIME [epoch: 8.31 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3140710816174395		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.3140710816174395 | validation: 0.3012914239272283]
	TIME [epoch: 8.31 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32456280282570504		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.32456280282570504 | validation: 0.31976357589895293]
	TIME [epoch: 8.31 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.332217844430956		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.332217844430956 | validation: 0.29436784115252945]
	TIME [epoch: 8.31 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34215232880637664		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.34215232880637664 | validation: 0.25839975324102793]
	TIME [epoch: 8.33 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27030439831418457		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.27030439831418457 | validation: 0.22473413101697315]
	TIME [epoch: 8.31 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28342691261164193		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.28342691261164193 | validation: 0.259050354912474]
	TIME [epoch: 8.3 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32227529822564555		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.32227529822564555 | validation: 0.3178377519509483]
	TIME [epoch: 8.3 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26902120317181993		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.26902120317181993 | validation: 0.21700361813133454]
	TIME [epoch: 8.33 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3118564365103963		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.3118564365103963 | validation: 0.2328281747383345]
	TIME [epoch: 8.31 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29874246339116683		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.29874246339116683 | validation: 0.2485138330319097]
	TIME [epoch: 8.3 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32427369682901414		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.32427369682901414 | validation: 0.23810468307634075]
	TIME [epoch: 8.31 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2726651509072394		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.2726651509072394 | validation: 0.21773016964922068]
	TIME [epoch: 8.33 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2932475575177157		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.2932475575177157 | validation: 0.2578466635299379]
	TIME [epoch: 8.31 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2835678539364333		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.2835678539364333 | validation: 0.24808530325187664]
	TIME [epoch: 8.31 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3079897597355732		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.3079897597355732 | validation: 0.2219330101709443]
	TIME [epoch: 8.31 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31295749908552245		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.31295749908552245 | validation: 0.21363736193909974]
	TIME [epoch: 8.31 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27312769411742505		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.27312769411742505 | validation: 0.2648320042752762]
	TIME [epoch: 8.33 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3091809669811132		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.3091809669811132 | validation: 0.27675709024360906]
	TIME [epoch: 8.31 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3243022480992171		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.3243022480992171 | validation: 0.32163642818141436]
	TIME [epoch: 8.31 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3316274064401675		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.3316274064401675 | validation: 0.2783143698164109]
	TIME [epoch: 8.31 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2859871287043233		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.2859871287043233 | validation: 0.24998216544907553]
	TIME [epoch: 8.33 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3073053961972454		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.3073053961972454 | validation: 0.21590722951217678]
	TIME [epoch: 8.31 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2905539374604815		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.2905539374604815 | validation: 0.23973152928781605]
	TIME [epoch: 8.31 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2661541682449538		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.2661541682449538 | validation: 0.25557639933085624]
	TIME [epoch: 8.31 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2684736007971572		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.2684736007971572 | validation: 0.24008423418273972]
	TIME [epoch: 8.33 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2988643609181888		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.2988643609181888 | validation: 0.33549742556097484]
	TIME [epoch: 8.31 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30590540913447384		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.30590540913447384 | validation: 0.21758227947204892]
	TIME [epoch: 8.31 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2607104635126073		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.2607104635126073 | validation: 0.2456337768714379]
	TIME [epoch: 8.31 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2842395030305968		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.2842395030305968 | validation: 0.19505563071555482]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_490.pth
	Model improved!!!
EPOCH 491/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2661708689927492		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.2661708689927492 | validation: 0.2846207114119156]
	TIME [epoch: 8.33 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2959208837145459		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.2959208837145459 | validation: 0.21210181749365803]
	TIME [epoch: 8.31 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27960058527242737		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.27960058527242737 | validation: 0.2588457231355576]
	TIME [epoch: 8.3 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33225828514691064		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.33225828514691064 | validation: 0.24680154254151415]
	TIME [epoch: 8.3 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30603500169512327		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.30603500169512327 | validation: 0.268931848748469]
	TIME [epoch: 8.33 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34672744056043886		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.34672744056043886 | validation: 0.3490310894449238]
	TIME [epoch: 8.31 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32878218755715494		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.32878218755715494 | validation: 0.2586458171762217]
	TIME [epoch: 8.3 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28678903279768836		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.28678903279768836 | validation: 0.2263795321566988]
	TIME [epoch: 8.31 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25671390932671606		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.25671390932671606 | validation: 0.23478163187447498]
	TIME [epoch: 8.32 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3012648346768298		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.3012648346768298 | validation: 0.29379298344386046]
	TIME [epoch: 8.32 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34512740492546296		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.34512740492546296 | validation: 0.3402624081556441]
	TIME [epoch: 8.3 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28482985515571535		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.28482985515571535 | validation: 0.22883628296377417]
	TIME [epoch: 8.3 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3219414022543861		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.3219414022543861 | validation: 0.34161596254209065]
	TIME [epoch: 8.3 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31973125913119343		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.31973125913119343 | validation: 0.2327322593882106]
	TIME [epoch: 8.33 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3267869168473062		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.3267869168473062 | validation: 0.22428426028223902]
	TIME [epoch: 8.3 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31614952346839137		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.31614952346839137 | validation: 0.27639053410729886]
	TIME [epoch: 8.3 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33070329000688814		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.33070329000688814 | validation: 0.209490125183652]
	TIME [epoch: 8.31 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29900845961517575		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.29900845961517575 | validation: 0.24041514016347446]
	TIME [epoch: 8.33 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3273555026651865		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.3273555026651865 | validation: 0.2189987397881853]
	TIME [epoch: 8.3 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3940723520643732		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.3940723520643732 | validation: 0.3255229728433492]
	TIME [epoch: 8.3 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4990670943035386		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.4990670943035386 | validation: 0.30989286112845127]
	TIME [epoch: 8.3 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39169759803399834		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.39169759803399834 | validation: 0.2700164855649779]
	TIME [epoch: 8.32 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32506460311032326		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.32506460311032326 | validation: 0.264541934056283]
	TIME [epoch: 8.31 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30380300062148663		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.30380300062148663 | validation: 0.23287374331605365]
	TIME [epoch: 8.3 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3139654932253444		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.3139654932253444 | validation: 0.4375850156731834]
	TIME [epoch: 8.3 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33095873301273604		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.33095873301273604 | validation: 0.25423565370876605]
	TIME [epoch: 8.3 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2848191369234043		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.2848191369234043 | validation: 0.22283151220110642]
	TIME [epoch: 8.32 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2763530656253078		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.2763530656253078 | validation: 0.2735001097044819]
	TIME [epoch: 8.31 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3486364128829905		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.3486364128829905 | validation: 0.22696417344707998]
	TIME [epoch: 8.3 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2877813739664989		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.2877813739664989 | validation: 0.41330428628501314]
	TIME [epoch: 8.3 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4229737696437894		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.4229737696437894 | validation: 0.33306708399968143]
	TIME [epoch: 8.32 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28976544925474884		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.28976544925474884 | validation: 0.21770408220030552]
	TIME [epoch: 8.31 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2984573225089		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.2984573225089 | validation: 0.21902637877116699]
	TIME [epoch: 8.3 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2666127425472352		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.2666127425472352 | validation: 0.22555723172269163]
	TIME [epoch: 8.3 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28858387485909287		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.28858387485909287 | validation: 0.2779570336705256]
	TIME [epoch: 8.31 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2563289709084279		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.2563289709084279 | validation: 0.24508713130188298]
	TIME [epoch: 8.32 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3062875962090913		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.3062875962090913 | validation: 0.22053618880457276]
	TIME [epoch: 8.3 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2970111957905324		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.2970111957905324 | validation: 0.2658815953164955]
	TIME [epoch: 8.3 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2869392082266565		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.2869392082266565 | validation: 0.28790881024078785]
	TIME [epoch: 8.31 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35056049827049696		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.35056049827049696 | validation: 0.24700680224328733]
	TIME [epoch: 8.33 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26995289212315743		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.26995289212315743 | validation: 0.22988501047086224]
	TIME [epoch: 8.31 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2758765004807871		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.2758765004807871 | validation: 0.2564208491180495]
	TIME [epoch: 8.3 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34242574799792136		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.34242574799792136 | validation: 0.2522335758832062]
	TIME [epoch: 8.3 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29597312978497414		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.29597312978497414 | validation: 0.22026298799728844]
	TIME [epoch: 8.32 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2796895529465706		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.2796895529465706 | validation: 0.23524435597496357]
	TIME [epoch: 8.31 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.313434066529963		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.313434066529963 | validation: 0.2346869595718014]
	TIME [epoch: 8.3 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26302795023292547		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.26302795023292547 | validation: 0.18422534707603344]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_537.pth
	Model improved!!!
EPOCH 538/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24707625139403025		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.24707625139403025 | validation: 0.20974755982371146]
	TIME [epoch: 8.31 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2765837676296825		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.2765837676296825 | validation: 0.29258816773851115]
	TIME [epoch: 8.32 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26136149397832165		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.26136149397832165 | validation: 0.17434066823071967]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_540.pth
	Model improved!!!
EPOCH 541/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2508804788708696		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.2508804788708696 | validation: 0.18686224272692364]
	TIME [epoch: 8.3 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23354340669182788		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.23354340669182788 | validation: 0.19611132979021328]
	TIME [epoch: 8.3 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24531233275477765		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.24531233275477765 | validation: 0.2676817049726784]
	TIME [epoch: 8.33 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3021202756719451		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.3021202756719451 | validation: 0.24427678001324044]
	TIME [epoch: 8.3 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.326050194622352		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.326050194622352 | validation: 0.27316306537819557]
	TIME [epoch: 8.3 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23951308626208495		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.23951308626208495 | validation: 0.20299799155747905]
	TIME [epoch: 8.3 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2360895944387166		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.2360895944387166 | validation: 0.20921407052292335]
	TIME [epoch: 8.32 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25270025785206585		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.25270025785206585 | validation: 0.1919592959454631]
	TIME [epoch: 8.3 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2775071139007507		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.2775071139007507 | validation: 0.21258878129918812]
	TIME [epoch: 8.3 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24974940662100947		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.24974940662100947 | validation: 0.19009211221608563]
	TIME [epoch: 8.3 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29261778616434486		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.29261778616434486 | validation: 0.2241469412364224]
	TIME [epoch: 8.31 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2843373378679348		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.2843373378679348 | validation: 0.19279272647564275]
	TIME [epoch: 8.32 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26389067746927214		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.26389067746927214 | validation: 0.22766411066255518]
	TIME [epoch: 8.3 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29647711883250133		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.29647711883250133 | validation: 0.23268865011254253]
	TIME [epoch: 8.3 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2742707926653275		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.2742707926653275 | validation: 0.20829009727050057]
	TIME [epoch: 8.3 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3231198650566721		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.3231198650566721 | validation: 0.29376058358083007]
	TIME [epoch: 8.32 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28573565233090364		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.28573565233090364 | validation: 0.19987665625827128]
	TIME [epoch: 8.3 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26506026413750966		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.26506026413750966 | validation: 0.2010135022935484]
	TIME [epoch: 8.3 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2813058609864059		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.2813058609864059 | validation: 0.2554545844041615]
	TIME [epoch: 8.3 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3395249522548372		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.3395249522548372 | validation: 0.23643405665725065]
	TIME [epoch: 8.32 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29907737776525456		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.29907737776525456 | validation: 0.27532749299276493]
	TIME [epoch: 8.3 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2583507294792834		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.2583507294792834 | validation: 0.2406074240965752]
	TIME [epoch: 8.3 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35464107768449205		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.35464107768449205 | validation: 0.22332858789765492]
	TIME [epoch: 8.3 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32172955927208186		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.32172955927208186 | validation: 0.25146137587386147]
	TIME [epoch: 8.3 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2978820505269495		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.2978820505269495 | validation: 0.22044030270012577]
	TIME [epoch: 8.32 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3346834528557801		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.3346834528557801 | validation: 0.26487185238414734]
	TIME [epoch: 8.3 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3137251141884742		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.3137251141884742 | validation: 0.2526492774057369]
	TIME [epoch: 8.31 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2831189947934346		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.2831189947934346 | validation: 0.21929659778801353]
	TIME [epoch: 8.3 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2830161281809458		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.2830161281809458 | validation: 0.23790931421461653]
	TIME [epoch: 8.33 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.283390379541366		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.283390379541366 | validation: 0.21511099876867523]
	TIME [epoch: 8.31 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30312422247998927		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.30312422247998927 | validation: 0.22423505184410344]
	TIME [epoch: 8.3 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2585713134398551		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.2585713134398551 | validation: 0.2332985864169129]
	TIME [epoch: 8.3 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28520373101337504		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.28520373101337504 | validation: 0.2037972270786027]
	TIME [epoch: 8.32 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23756786529520396		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.23756786529520396 | validation: 0.21531555976287692]
	TIME [epoch: 8.31 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26192806740369395		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.26192806740369395 | validation: 0.17496922424626132]
	TIME [epoch: 8.3 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24908742785897836		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.24908742785897836 | validation: 0.20514685124302817]
	TIME [epoch: 8.3 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2426437625667351		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.2426437625667351 | validation: 0.2513499583488539]
	TIME [epoch: 8.3 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25222745003096314		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.25222745003096314 | validation: 0.20930002519370783]
	TIME [epoch: 8.33 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2535021225603134		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.2535021225603134 | validation: 0.22172631715845093]
	TIME [epoch: 8.3 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2586780499900315		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.2586780499900315 | validation: 0.20807559111923102]
	TIME [epoch: 8.3 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2618198612120611		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.2618198612120611 | validation: 0.21047719792460037]
	TIME [epoch: 8.3 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2747266483185692		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.2747266483185692 | validation: 0.19460185623791734]
	TIME [epoch: 8.32 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22163860023676835		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.22163860023676835 | validation: 0.1874130526817522]
	TIME [epoch: 8.3 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23531339805413087		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.23531339805413087 | validation: 0.22295919885678528]
	TIME [epoch: 8.3 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23989085181771191		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.23989085181771191 | validation: 0.19484030347905895]
	TIME [epoch: 8.3 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24620273893234895		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.24620273893234895 | validation: 0.19554628498373675]
	TIME [epoch: 8.31 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2436971827947521		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.2436971827947521 | validation: 0.18050915457454897]
	TIME [epoch: 8.31 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22537300731291432		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.22537300731291432 | validation: 0.20450803459184153]
	TIME [epoch: 8.3 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2914031469191102		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.2914031469191102 | validation: 0.18643090719231648]
	TIME [epoch: 8.3 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21678377064684456		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.21678377064684456 | validation: 0.1995773770898708]
	TIME [epoch: 8.3 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2467506189958942		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.2467506189958942 | validation: 0.22821178809136194]
	TIME [epoch: 8.32 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2401434991188708		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.2401434991188708 | validation: 0.25456595774511726]
	TIME [epoch: 8.3 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2530212094540824		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.2530212094540824 | validation: 0.26775744916873434]
	TIME [epoch: 8.3 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2593643387168794		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.2593643387168794 | validation: 0.18526391403706877]
	TIME [epoch: 8.3 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24604479632604428		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.24604479632604428 | validation: 0.3479464800976193]
	TIME [epoch: 8.32 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25477960429764235		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.25477960429764235 | validation: 0.23088055238474545]
	TIME [epoch: 8.3 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24504346854186734		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.24504346854186734 | validation: 0.18382151528962493]
	TIME [epoch: 8.3 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21481190108595313		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.21481190108595313 | validation: 0.23600425519429674]
	TIME [epoch: 8.3 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23048576883372102		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.23048576883372102 | validation: 0.24052818114821894]
	TIME [epoch: 8.31 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25815844782081354		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.25815844782081354 | validation: 0.17699998050599075]
	TIME [epoch: 8.31 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22325784484249		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.22325784484249 | validation: 0.1711480551647328]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_601.pth
	Model improved!!!
EPOCH 602/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22746417248091394		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.22746417248091394 | validation: 0.1933679534245144]
	TIME [epoch: 8.31 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23479388769992618		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.23479388769992618 | validation: 0.20473942670295348]
	TIME [epoch: 8.31 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25030998502488583		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.25030998502488583 | validation: 0.1827023344713421]
	TIME [epoch: 8.33 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25640217188036685		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.25640217188036685 | validation: 0.20752110090132264]
	TIME [epoch: 8.31 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26068710813837326		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.26068710813837326 | validation: 0.2533250423687706]
	TIME [epoch: 8.31 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26046741652486827		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.26046741652486827 | validation: 0.21785270373903087]
	TIME [epoch: 8.31 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2212320192404516		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.2212320192404516 | validation: 0.1810616315447332]
	TIME [epoch: 8.32 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23837379100961273		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.23837379100961273 | validation: 0.1893173220973769]
	TIME [epoch: 8.31 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22287598084019491		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.22287598084019491 | validation: 0.19690789823715626]
	TIME [epoch: 8.3 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.224762064459788		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.224762064459788 | validation: 0.2238808243563421]
	TIME [epoch: 8.31 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2304338400132909		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.2304338400132909 | validation: 0.19067693885244297]
	TIME [epoch: 8.32 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2193343196592738		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.2193343196592738 | validation: 0.20689715417591664]
	TIME [epoch: 8.32 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2328793284682366		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.2328793284682366 | validation: 0.27876482128049807]
	TIME [epoch: 8.3 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24711074029409713		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.24711074029409713 | validation: 0.2420926161872482]
	TIME [epoch: 8.3 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2924295984066988		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.2924295984066988 | validation: 0.2912505477920271]
	TIME [epoch: 8.31 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2345444818266656		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.2345444818266656 | validation: 0.15664887386112908]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_617.pth
	Model improved!!!
EPOCH 618/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21575291318106257		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.21575291318106257 | validation: 0.176456017690227]
	TIME [epoch: 8.31 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2258376188414876		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.2258376188414876 | validation: 0.18170214251397976]
	TIME [epoch: 8.3 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21693938117679806		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.21693938117679806 | validation: 0.1808405617700397]
	TIME [epoch: 8.3 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.199739604801873		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.199739604801873 | validation: 0.22522841747050087]
	TIME [epoch: 8.32 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22099818474670402		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.22099818474670402 | validation: 0.19288251255815228]
	TIME [epoch: 8.3 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2525813697939937		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.2525813697939937 | validation: 0.19694987192293223]
	TIME [epoch: 8.3 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24725833389328405		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.24725833389328405 | validation: 0.20691756104129322]
	TIME [epoch: 8.29 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23868829662190474		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.23868829662190474 | validation: 0.20119271540696967]
	TIME [epoch: 8.3 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2245005849695394		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.2245005849695394 | validation: 0.17278258290617715]
	TIME [epoch: 8.31 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24502742622772974		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.24502742622772974 | validation: 0.23966960293327005]
	TIME [epoch: 8.3 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23584413380487126		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.23584413380487126 | validation: 0.1709070245287898]
	TIME [epoch: 8.3 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23856642675683498		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.23856642675683498 | validation: 0.17004843183933863]
	TIME [epoch: 8.3 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20282351574991625		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.20282351574991625 | validation: 0.16084418078661408]
	TIME [epoch: 8.32 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22007489352604867		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.22007489352604867 | validation: 0.19344274801772607]
	TIME [epoch: 8.3 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21678835974857416		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.21678835974857416 | validation: 0.17532151706593369]
	TIME [epoch: 8.3 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23261773050997897		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.23261773050997897 | validation: 0.24168924425538552]
	TIME [epoch: 8.29 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2670290438618327		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.2670290438618327 | validation: 0.21167601990157164]
	TIME [epoch: 8.31 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25353307973729583		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.25353307973729583 | validation: 0.22787251867024644]
	TIME [epoch: 8.3 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23982885936050624		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.23982885936050624 | validation: 0.16275366802650432]
	TIME [epoch: 8.3 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2274324225516457		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.2274324225516457 | validation: 0.19515066780378482]
	TIME [epoch: 8.3 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2367392232693069		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.2367392232693069 | validation: 0.20895873682214705]
	TIME [epoch: 8.3 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25043666901358547		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.25043666901358547 | validation: 0.23434414010089985]
	TIME [epoch: 8.32 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26698523319178097		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.26698523319178097 | validation: 0.2008707915779842]
	TIME [epoch: 8.3 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26569893916039933		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.26569893916039933 | validation: 0.19113060784312297]
	TIME [epoch: 8.31 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21433057603159616		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.21433057603159616 | validation: 0.17112571700161516]
	TIME [epoch: 8.3 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22371285716666237		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.22371285716666237 | validation: 0.20362744786866363]
	TIME [epoch: 8.33 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22251447561620807		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.22251447561620807 | validation: 0.23148603329118825]
	TIME [epoch: 8.3 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23238173713560908		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.23238173713560908 | validation: 0.21746686006269195]
	TIME [epoch: 8.3 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28325984304923824		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.28325984304923824 | validation: 0.3739185412826832]
	TIME [epoch: 8.3 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3131877076098219		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.3131877076098219 | validation: 0.23551004733372946]
	TIME [epoch: 8.32 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24212677546871836		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.24212677546871836 | validation: 0.20962233571732952]
	TIME [epoch: 8.31 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22973154123799766		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.22973154123799766 | validation: 0.19462363561529705]
	TIME [epoch: 8.3 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2176321801428746		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.2176321801428746 | validation: 0.181615413307141]
	TIME [epoch: 8.3 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2759216816643577		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.2759216816643577 | validation: 0.2957435453829605]
	TIME [epoch: 8.3 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27767728580574924		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.27767728580574924 | validation: 0.19215233628704317]
	TIME [epoch: 8.33 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2460374893465032		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.2460374893465032 | validation: 0.20443939189350263]
	TIME [epoch: 8.3 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26114923244259447		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.26114923244259447 | validation: 0.22709124786386653]
	TIME [epoch: 8.3 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23359974495342967		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.23359974495342967 | validation: 0.17323918984205192]
	TIME [epoch: 8.3 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20672650290135594		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.20672650290135594 | validation: 0.1639641884561101]
	TIME [epoch: 8.32 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21278607178655706		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.21278607178655706 | validation: 0.20419661226652974]
	TIME [epoch: 8.3 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21090130456572437		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.21090130456572437 | validation: 0.1842096990463053]
	TIME [epoch: 8.3 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21871316431737675		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.21871316431737675 | validation: 0.1695823036665261]
	TIME [epoch: 8.3 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2070245983470136		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.2070245983470136 | validation: 0.165446929259636]
	TIME [epoch: 8.32 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20619607161079037		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.20619607161079037 | validation: 0.1838606345091549]
	TIME [epoch: 8.3 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20874295551634905		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.20874295551634905 | validation: 0.20519828474609458]
	TIME [epoch: 8.3 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21308143163135043		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.21308143163135043 | validation: 0.16831250714218338]
	TIME [epoch: 8.31 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19626138179173722		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.19626138179173722 | validation: 0.1717522677693804]
	TIME [epoch: 8.31 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21840987633105216		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.21840987633105216 | validation: 0.24935026074404026]
	TIME [epoch: 8.32 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23308042565430007		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.23308042565430007 | validation: 0.16367029386375642]
	TIME [epoch: 8.31 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2176665302169459		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.2176665302169459 | validation: 0.18734095111725538]
	TIME [epoch: 8.31 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21466725567715556		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.21466725567715556 | validation: 0.22746866741177985]
	TIME [epoch: 8.3 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25238766348022257		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.25238766348022257 | validation: 0.2027951755843182]
	TIME [epoch: 8.33 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22973916688780394		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.22973916688780394 | validation: 0.16207248235173705]
	TIME [epoch: 8.31 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20689174008781594		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.20689174008781594 | validation: 0.1761370435944154]
	TIME [epoch: 8.31 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2641742948453153		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.2641742948453153 | validation: 0.18524418287057615]
	TIME [epoch: 8.31 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2033600679754155		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.2033600679754155 | validation: 0.18739857197670168]
	TIME [epoch: 8.32 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20588851626061128		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.20588851626061128 | validation: 0.19862272491043081]
	TIME [epoch: 8.32 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21493846065196026		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.21493846065196026 | validation: 0.18609755322542865]
	TIME [epoch: 8.31 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19916694412271846		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.19916694412271846 | validation: 0.16916793817035247]
	TIME [epoch: 8.3 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20181775748408554		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.20181775748408554 | validation: 0.20896047121213446]
	TIME [epoch: 8.31 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2183501768071901		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.2183501768071901 | validation: 0.17038475586392426]
	TIME [epoch: 8.33 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21413756530754938		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.21413756530754938 | validation: 0.19269142553965884]
	TIME [epoch: 8.3 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1962180655125855		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.1962180655125855 | validation: 0.1637804395719863]
	TIME [epoch: 8.3 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2190253754882964		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.2190253754882964 | validation: 0.19980783459229845]
	TIME [epoch: 8.3 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20777290076386534		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.20777290076386534 | validation: 0.15142800419827862]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_682.pth
	Model improved!!!
EPOCH 683/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21443849130583872		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.21443849130583872 | validation: 0.18447152575371756]
	TIME [epoch: 8.3 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21712947705159583		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.21712947705159583 | validation: 0.18880787888579442]
	TIME [epoch: 8.3 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19853048920188443		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.19853048920188443 | validation: 0.19445743601993298]
	TIME [epoch: 8.3 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21114883785784588		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.21114883785784588 | validation: 0.19644797908032574]
	TIME [epoch: 8.31 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2325533592492926		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.2325533592492926 | validation: 0.20231717261230325]
	TIME [epoch: 8.31 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2171762475205818		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.2171762475205818 | validation: 0.16688410182676433]
	TIME [epoch: 8.3 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20404312637728866		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.20404312637728866 | validation: 0.16841560141624362]
	TIME [epoch: 8.3 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1993218808871519		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.1993218808871519 | validation: 0.17140829957895942]
	TIME [epoch: 8.3 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2009906383697489		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.2009906383697489 | validation: 0.1830497036439211]
	TIME [epoch: 8.32 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22878410335260863		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.22878410335260863 | validation: 0.19904503509693294]
	TIME [epoch: 8.3 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1998886882186211		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.1998886882186211 | validation: 0.20644989547717002]
	TIME [epoch: 8.3 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2285763874646148		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.2285763874646148 | validation: 0.19620983147886878]
	TIME [epoch: 8.29 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2089966319624464		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.2089966319624464 | validation: 0.1719809371161768]
	TIME [epoch: 8.32 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23955966525941683		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.23955966525941683 | validation: 0.22449629507599295]
	TIME [epoch: 8.29 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20379657809524016		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.20379657809524016 | validation: 0.2225105313680521]
	TIME [epoch: 8.3 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20693307428145286		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.20693307428145286 | validation: 0.17049161905905585]
	TIME [epoch: 8.3 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20426294269051834		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.20426294269051834 | validation: 0.16424729732070065]
	TIME [epoch: 8.31 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20705223969201808		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.20705223969201808 | validation: 0.17612868720662192]
	TIME [epoch: 8.31 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20607056069896185		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.20607056069896185 | validation: 0.16878038867037154]
	TIME [epoch: 8.3 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23526697484040388		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.23526697484040388 | validation: 0.23607535614846786]
	TIME [epoch: 8.3 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21476207394497546		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.21476207394497546 | validation: 0.14385251615053424]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_703.pth
	Model improved!!!
EPOCH 704/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19537853126407023		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.19537853126407023 | validation: 0.1757116981680948]
	TIME [epoch: 8.32 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19568899567012346		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.19568899567012346 | validation: 0.1856850468603612]
	TIME [epoch: 8.3 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22991112915859818		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.22991112915859818 | validation: 0.21002247540627614]
	TIME [epoch: 8.3 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19911495021891962		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.19911495021891962 | validation: 0.16026333939649035]
	TIME [epoch: 8.3 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21956823933125064		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.21956823933125064 | validation: 0.21769766738612573]
	TIME [epoch: 8.32 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21820895712732463		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.21820895712732463 | validation: 0.15342092807616442]
	TIME [epoch: 8.31 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18909393698574942		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.18909393698574942 | validation: 0.16744177310605052]
	TIME [epoch: 8.3 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20040637353949328		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.20040637353949328 | validation: 0.14644833504691535]
	TIME [epoch: 8.31 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18736069219664692		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.18736069219664692 | validation: 0.17259542281813087]
	TIME [epoch: 8.31 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19531399282580264		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.19531399282580264 | validation: 0.1659728902873498]
	TIME [epoch: 8.32 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1930518246682567		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.1930518246682567 | validation: 0.16673796822890669]
	TIME [epoch: 8.3 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23732851560771268		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.23732851560771268 | validation: 0.1579078199887038]
	TIME [epoch: 8.3 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20037153759600906		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.20037153759600906 | validation: 0.16152110366729444]
	TIME [epoch: 8.3 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20616682827786598		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.20616682827786598 | validation: 0.1526807736691903]
	TIME [epoch: 8.32 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19693150707252988		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.19693150707252988 | validation: 0.17570488319020983]
	TIME [epoch: 8.31 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18373949043220508		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.18373949043220508 | validation: 0.1620270746894124]
	TIME [epoch: 8.3 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18438228424178355		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.18438228424178355 | validation: 0.16201883033185144]
	TIME [epoch: 8.3 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1837673626716187		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.1837673626716187 | validation: 0.160698492481125]
	TIME [epoch: 8.32 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19779871922210793		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.19779871922210793 | validation: 0.14334493319281558]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_722.pth
	Model improved!!!
EPOCH 723/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19280554547177448		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.19280554547177448 | validation: 0.18272544503888044]
	TIME [epoch: 8.3 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1961995381741046		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.1961995381741046 | validation: 0.191531681853445]
	TIME [epoch: 8.3 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2029200235146079		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.2029200235146079 | validation: 0.20777161066326694]
	TIME [epoch: 8.31 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1949757326237564		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.1949757326237564 | validation: 0.19894118636405894]
	TIME [epoch: 8.32 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19276391775373375		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.19276391775373375 | validation: 0.16261941817647146]
	TIME [epoch: 8.3 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18459479501308265		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.18459479501308265 | validation: 0.14574063095646744]
	TIME [epoch: 8.3 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18654705736613322		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.18654705736613322 | validation: 0.17386365937156167]
	TIME [epoch: 8.3 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1894175173384703		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.1894175173384703 | validation: 0.17260562923448747]
	TIME [epoch: 8.32 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18879608168751466		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.18879608168751466 | validation: 0.1882673859192911]
	TIME [epoch: 8.3 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18853070373584147		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.18853070373584147 | validation: 0.17152318704949518]
	TIME [epoch: 8.29 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21001811307921234		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.21001811307921234 | validation: 0.16364103042792819]
	TIME [epoch: 8.3 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20298179128829727		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.20298179128829727 | validation: 0.16696823178517878]
	TIME [epoch: 8.32 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2109813812908934		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.2109813812908934 | validation: 0.20186674840405341]
	TIME [epoch: 8.3 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1971737495038895		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.1971737495038895 | validation: 0.152279729631065]
	TIME [epoch: 8.31 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21346460798484257		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.21346460798484257 | validation: 0.15505455807907498]
	TIME [epoch: 8.3 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2193015411897766		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.2193015411897766 | validation: 0.15813199133090824]
	TIME [epoch: 8.3 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23141632752274838		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.23141632752274838 | validation: 0.17123592304965043]
	TIME [epoch: 8.32 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22238133033056404		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.22238133033056404 | validation: 0.19149985425271915]
	TIME [epoch: 8.3 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21304378646879335		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.21304378646879335 | validation: 0.1773163672976366]
	TIME [epoch: 8.29 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19983854568832063		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.19983854568832063 | validation: 0.16284702892014968]
	TIME [epoch: 8.3 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20337891439084874		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.20337891439084874 | validation: 0.17889985796528202]
	TIME [epoch: 8.32 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19463647428116923		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.19463647428116923 | validation: 0.1574921508430847]
	TIME [epoch: 8.3 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18181751393153367		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.18181751393153367 | validation: 0.16659853276737616]
	TIME [epoch: 8.3 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18920918566560777		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.18920918566560777 | validation: 0.1757432867115309]
	TIME [epoch: 8.29 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2024287526607546		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.2024287526607546 | validation: 0.14988019982448703]
	TIME [epoch: 8.32 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20716290334296988		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.20716290334296988 | validation: 0.1805969580799971]
	TIME [epoch: 8.3 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2122740594265755		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.2122740594265755 | validation: 0.19107778699712016]
	TIME [epoch: 8.29 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2046382534423036		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.2046382534423036 | validation: 0.1718240535606168]
	TIME [epoch: 8.3 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20263542563587972		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.20263542563587972 | validation: 0.1772481437584031]
	TIME [epoch: 8.3 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20868088882647368		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.20868088882647368 | validation: 0.16144570272117884]
	TIME [epoch: 8.32 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20340582350288144		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.20340582350288144 | validation: 0.16670901091315313]
	TIME [epoch: 8.3 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19483050441740227		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.19483050441740227 | validation: 0.21236452019565955]
	TIME [epoch: 8.29 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20490727024552888		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.20490727024552888 | validation: 0.17387081668533388]
	TIME [epoch: 8.3 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20553617630416263		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.20553617630416263 | validation: 0.16297418047902207]
	TIME [epoch: 8.32 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19615965087443593		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.19615965087443593 | validation: 0.16575161310583258]
	TIME [epoch: 8.29 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19412610275971276		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.19412610275971276 | validation: 0.18523279218763744]
	TIME [epoch: 8.29 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18781097468751734		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.18781097468751734 | validation: 0.16687010517761464]
	TIME [epoch: 8.29 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17586277634291778		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.17586277634291778 | validation: 0.15638099734635405]
	TIME [epoch: 8.32 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17825864195849236		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.17825864195849236 | validation: 0.15432506525293627]
	TIME [epoch: 8.29 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19572953740798354		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.19572953740798354 | validation: 0.1899456606401073]
	TIME [epoch: 8.29 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1910874274255617		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.1910874274255617 | validation: 0.15641424352190703]
	TIME [epoch: 8.3 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18118937988236145		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.18118937988236145 | validation: 0.17031088091772467]
	TIME [epoch: 8.3 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1851266646831414		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.1851266646831414 | validation: 0.14844097414556245]
	TIME [epoch: 8.32 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1819839975858595		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.1819839975858595 | validation: 0.14607552254689254]
	TIME [epoch: 8.29 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17771976978507306		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.17771976978507306 | validation: 0.13955236949481337]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_767.pth
	Model improved!!!
EPOCH 768/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19570032981475724		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.19570032981475724 | validation: 0.15987823134766133]
	TIME [epoch: 8.29 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18854938180857145		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.18854938180857145 | validation: 0.1729617460717863]
	TIME [epoch: 8.32 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1813831153028195		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.1813831153028195 | validation: 0.1528963938894174]
	TIME [epoch: 8.3 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17291508135674002		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.17291508135674002 | validation: 0.16070410580112032]
	TIME [epoch: 8.29 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19905019420622527		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.19905019420622527 | validation: 0.16763004715117158]
	TIME [epoch: 8.3 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1999361087278793		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.1999361087278793 | validation: 0.1836362581019943]
	TIME [epoch: 8.32 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2036803313906297		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.2036803313906297 | validation: 0.15905637805850656]
	TIME [epoch: 8.3 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19834301554886458		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.19834301554886458 | validation: 0.1596732210097534]
	TIME [epoch: 8.29 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18850281145655828		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.18850281145655828 | validation: 0.15635336881039277]
	TIME [epoch: 8.3 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19716141239815238		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.19716141239815238 | validation: 0.1531561242009486]
	TIME [epoch: 8.3 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17323347482745205		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.17323347482745205 | validation: 0.15643391012565006]
	TIME [epoch: 8.32 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.195521516739828		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.195521516739828 | validation: 0.16865070875038632]
	TIME [epoch: 8.3 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1799792536614777		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.1799792536614777 | validation: 0.16200776696275734]
	TIME [epoch: 8.3 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1768484193168638		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.1768484193168638 | validation: 0.17521384667838527]
	TIME [epoch: 8.3 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17775305671525427		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.17775305671525427 | validation: 0.16197693550006712]
	TIME [epoch: 8.32 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18891900422009128		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.18891900422009128 | validation: 0.1989102325983276]
	TIME [epoch: 8.3 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19440527369089508		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.19440527369089508 | validation: 0.1546817448625457]
	TIME [epoch: 8.3 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1827731031839999		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.1827731031839999 | validation: 0.15693312822275568]
	TIME [epoch: 8.3 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18484148612450463		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.18484148612450463 | validation: 0.14226685454146537]
	TIME [epoch: 8.31 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.171568261944799		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.171568261944799 | validation: 0.1562173212707712]
	TIME [epoch: 8.31 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1752939043996151		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.1752939043996151 | validation: 0.15095200129635394]
	TIME [epoch: 8.3 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17070515850094653		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.17070515850094653 | validation: 0.14564721045642604]
	TIME [epoch: 8.3 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1658642196021435		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.1658642196021435 | validation: 0.1719896775004991]
	TIME [epoch: 8.3 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18284475364267136		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.18284475364267136 | validation: 0.15218370558250505]
	TIME [epoch: 8.32 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17201356699706596		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.17201356699706596 | validation: 0.16680242504797985]
	TIME [epoch: 8.3 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18295045311011326		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.18295045311011326 | validation: 0.17184902147893946]
	TIME [epoch: 8.3 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1892110054230291		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.1892110054230291 | validation: 0.1960316436736922]
	TIME [epoch: 8.3 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20004803227683832		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.20004803227683832 | validation: 0.14978418228579343]
	TIME [epoch: 8.32 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1700811141748025		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.1700811141748025 | validation: 0.15852057400091724]
	TIME [epoch: 8.3 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1723788294822838		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.1723788294822838 | validation: 0.18226851195806965]
	TIME [epoch: 8.29 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17922159466743728		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.17922159466743728 | validation: 0.14812386229187252]
	TIME [epoch: 8.29 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16548622448598918		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.16548622448598918 | validation: 0.14823470132112163]
	TIME [epoch: 8.31 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17568662736711443		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.17568662736711443 | validation: 0.1433513997499375]
	TIME [epoch: 8.31 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17483449756453942		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.17483449756453942 | validation: 0.16530606520034444]
	TIME [epoch: 8.3 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18569699168103976		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.18569699168103976 | validation: 0.14990074294043226]
	TIME [epoch: 8.3 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18346028700598224		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.18346028700598224 | validation: 0.15389173179993904]
	TIME [epoch: 8.3 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18459627757830924		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.18459627757830924 | validation: 0.1527232972276268]
	TIME [epoch: 8.32 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1780010749493941		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.1780010749493941 | validation: 0.17572981553641176]
	TIME [epoch: 8.3 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17775425583302312		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.17775425583302312 | validation: 0.15051611355620248]
	TIME [epoch: 8.3 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17401024578370045		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.17401024578370045 | validation: 0.15772304279315663]
	TIME [epoch: 8.3 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17364135497221989		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.17364135497221989 | validation: 0.1590011232030264]
	TIME [epoch: 8.32 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17687118862375145		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.17687118862375145 | validation: 0.14457380694239275]
	TIME [epoch: 8.3 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17111621712501993		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.17111621712501993 | validation: 0.15814358852139815]
	TIME [epoch: 8.3 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16886669670242246		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.16886669670242246 | validation: 0.15189926037588958]
	TIME [epoch: 8.29 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18070820988736522		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.18070820988736522 | validation: 0.1595742920270922]
	TIME [epoch: 8.3 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17894462210971093		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.17894462210971093 | validation: 0.12344512493539116]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_813.pth
	Model improved!!!
EPOCH 814/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1775200762836668		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.1775200762836668 | validation: 0.15174423882287089]
	TIME [epoch: 8.29 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1885905999878758		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.1885905999878758 | validation: 0.1374619218509101]
	TIME [epoch: 8.29 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17628030960077548		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.17628030960077548 | validation: 0.15330701224278193]
	TIME [epoch: 8.3 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16916542200992882		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.16916542200992882 | validation: 0.14783825407306178]
	TIME [epoch: 8.32 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16327420087987657		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.16327420087987657 | validation: 0.16380377375426225]
	TIME [epoch: 8.29 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17256028095954107		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.17256028095954107 | validation: 0.13943609047675543]
	TIME [epoch: 8.29 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18129003913779057		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.18129003913779057 | validation: 0.1357232296525877]
	TIME [epoch: 8.29 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16672212111028034		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.16672212111028034 | validation: 0.13682374261355143]
	TIME [epoch: 8.32 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16904347694953428		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.16904347694953428 | validation: 0.1393894565495588]
	TIME [epoch: 8.3 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1640806563908363		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.1640806563908363 | validation: 0.14736697899531856]
	TIME [epoch: 8.3 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16531928162633358		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.16531928162633358 | validation: 0.13162708062658862]
	TIME [epoch: 8.3 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16765317671355703		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.16765317671355703 | validation: 0.13158900986024952]
	TIME [epoch: 8.3 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1747264064346143		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.1747264064346143 | validation: 0.157680759272622]
	TIME [epoch: 8.32 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17122698010241147		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.17122698010241147 | validation: 0.14851769180007027]
	TIME [epoch: 8.3 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18709425385434456		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.18709425385434456 | validation: 0.1398242272847121]
	TIME [epoch: 8.3 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16504296804941845		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.16504296804941845 | validation: 0.1555183526881337]
	TIME [epoch: 8.3 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16670510590815193		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.16670510590815193 | validation: 0.14084501919176629]
	TIME [epoch: 8.32 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17597323445223712		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.17597323445223712 | validation: 0.16953657908001113]
	TIME [epoch: 8.3 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1834232332022658		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.1834232332022658 | validation: 0.16668471874731633]
	TIME [epoch: 8.3 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18087754946698154		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.18087754946698154 | validation: 0.14389136264647245]
	TIME [epoch: 8.3 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17062530687865224		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.17062530687865224 | validation: 0.1461700734498369]
	TIME [epoch: 8.32 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16743968040995105		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.16743968040995105 | validation: 0.15655806618090867]
	TIME [epoch: 8.3 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17098776309115027		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.17098776309115027 | validation: 0.1477886995546201]
	TIME [epoch: 8.3 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17892912620369544		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.17892912620369544 | validation: 0.13863669609429136]
	TIME [epoch: 8.3 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1811158725770816		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.1811158725770816 | validation: 0.14702599781619388]
	TIME [epoch: 8.3 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19224430455291525		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.19224430455291525 | validation: 0.17309226148551965]
	TIME [epoch: 8.32 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18082355683298973		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.18082355683298973 | validation: 0.1437463538678121]
	TIME [epoch: 8.29 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18939930114353049		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.18939930114353049 | validation: 0.15248143968469077]
	TIME [epoch: 8.3 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1781187886294448		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.1781187886294448 | validation: 0.1514392568136659]
	TIME [epoch: 8.29 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17385995089872014		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.17385995089872014 | validation: 0.1460844582393907]
	TIME [epoch: 8.33 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18048496938849842		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.18048496938849842 | validation: 0.147024524613945]
	TIME [epoch: 8.3 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17390371637247623		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.17390371637247623 | validation: 0.14032951515761902]
	TIME [epoch: 8.29 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16526355307069468		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.16526355307069468 | validation: 0.13204668306048556]
	TIME [epoch: 8.29 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1683240058315316		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.1683240058315316 | validation: 0.1582204189085739]
	TIME [epoch: 8.31 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1776453278625358		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.1776453278625358 | validation: 0.14376348261079916]
	TIME [epoch: 8.3 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16119938468670106		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.16119938468670106 | validation: 0.13490433337403873]
	TIME [epoch: 8.3 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16593031679931192		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.16593031679931192 | validation: 0.13844037164518183]
	TIME [epoch: 8.3 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16486808575185768		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.16486808575185768 | validation: 0.14324838469303006]
	TIME [epoch: 8.31 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16574675480907503		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.16574675480907503 | validation: 0.14296021856764513]
	TIME [epoch: 8.32 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17839095910416664		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.17839095910416664 | validation: 0.13812585815846035]
	TIME [epoch: 8.3 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1655256543830121		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.1655256543830121 | validation: 0.14658144456645308]
	TIME [epoch: 8.3 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16577736022310635		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.16577736022310635 | validation: 0.14816653607136082]
	TIME [epoch: 8.3 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17394374598310264		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.17394374598310264 | validation: 0.15751338992209948]
	TIME [epoch: 8.32 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1684499881993166		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.1684499881993166 | validation: 0.13955372486880013]
	TIME [epoch: 8.3 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16792529754034255		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.16792529754034255 | validation: 0.14849319424431032]
	TIME [epoch: 8.29 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17690599213460662		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.17690599213460662 | validation: 0.14366716557324993]
	TIME [epoch: 8.3 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17563857310416592		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.17563857310416592 | validation: 0.13891538959029243]
	TIME [epoch: 8.31 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16202721390379565		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.16202721390379565 | validation: 0.15169717427213153]
	TIME [epoch: 8.31 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17791803806690604		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.17791803806690604 | validation: 0.15756100780473317]
	TIME [epoch: 8.3 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18159825569995053		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.18159825569995053 | validation: 0.15311132808948943]
	TIME [epoch: 8.3 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16995969172046094		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.16995969172046094 | validation: 0.15239419899588486]
	TIME [epoch: 8.3 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1798928678701615		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.1798928678701615 | validation: 0.18329991956045022]
	TIME [epoch: 8.32 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18308927296416638		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.18308927296416638 | validation: 0.14821749526104014]
	TIME [epoch: 8.29 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17404228146194706		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.17404228146194706 | validation: 0.1444892058404431]
	TIME [epoch: 8.29 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17171716659757527		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.17171716659757527 | validation: 0.1516950746895505]
	TIME [epoch: 8.29 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1766059273166045		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.1766059273166045 | validation: 0.14663504363985602]
	TIME [epoch: 8.32 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17529023411104966		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.17529023411104966 | validation: 0.1485110877814561]
	TIME [epoch: 8.3 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1764597799872103		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.1764597799872103 | validation: 0.15580180747063865]
	TIME [epoch: 8.3 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17122831797854146		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.17122831797854146 | validation: 0.14761820211135207]
	TIME [epoch: 8.29 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17755170891860103		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.17755170891860103 | validation: 0.15390102192989746]
	TIME [epoch: 8.31 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17693484315375824		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.17693484315375824 | validation: 0.16133737820312233]
	TIME [epoch: 8.3 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17343478176523036		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.17343478176523036 | validation: 0.15125211427500704]
	TIME [epoch: 8.3 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17633543856068895		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.17633543856068895 | validation: 0.1530498468791577]
	TIME [epoch: 8.29 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1713331671379766		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.1713331671379766 | validation: 0.14843630418067777]
	TIME [epoch: 8.29 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16263484947194884		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.16263484947194884 | validation: 0.14554855478988837]
	TIME [epoch: 8.31 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16459532564060447		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.16459532564060447 | validation: 0.15038204433133065]
	TIME [epoch: 8.3 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17161762968054245		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.17161762968054245 | validation: 0.15898480809441676]
	TIME [epoch: 8.3 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16293777990137867		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.16293777990137867 | validation: 0.139803449725929]
	TIME [epoch: 8.29 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17862359186034188		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.17862359186034188 | validation: 0.1733140694387324]
	TIME [epoch: 8.32 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19321555053692885		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.19321555053692885 | validation: 0.17241047131781553]
	TIME [epoch: 8.3 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1818807347245806		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.1818807347245806 | validation: 0.16083682439208224]
	TIME [epoch: 8.3 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16858339756376423		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.16858339756376423 | validation: 0.1431215104343862]
	TIME [epoch: 8.3 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1689896903692628		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.1689896903692628 | validation: 0.15749066760848512]
	TIME [epoch: 8.3 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16927543318068367		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.16927543318068367 | validation: 0.15554470890459804]
	TIME [epoch: 8.32 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17584503423156622		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.17584503423156622 | validation: 0.15309178947727797]
	TIME [epoch: 8.3 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1719899274937947		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.1719899274937947 | validation: 0.1471410843160248]
	TIME [epoch: 8.3 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18056657655980474		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.18056657655980474 | validation: 0.1705446667260806]
	TIME [epoch: 8.3 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.169869374890987		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.169869374890987 | validation: 0.14994620067571535]
	TIME [epoch: 8.32 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16788818520733012		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.16788818520733012 | validation: 0.14445334187875494]
	TIME [epoch: 8.3 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17106158163341456		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.17106158163341456 | validation: 0.1514803455844207]
	TIME [epoch: 8.3 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16391186801219151		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.16391186801219151 | validation: 0.13734180277082914]
	TIME [epoch: 8.29 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16948926447753312		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.16948926447753312 | validation: 0.15070241944371682]
	TIME [epoch: 8.32 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15780569213957346		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.15780569213957346 | validation: 0.14120623521732129]
	TIME [epoch: 8.3 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16800340966156163		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.16800340966156163 | validation: 0.14640053006449544]
	TIME [epoch: 8.3 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16841351837837143		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.16841351837837143 | validation: 0.13471876611711037]
	TIME [epoch: 8.3 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19154151558597146		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.19154151558597146 | validation: 0.15721047652547016]
	TIME [epoch: 8.3 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18392205429246763		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.18392205429246763 | validation: 0.13298460337300477]
	TIME [epoch: 8.32 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16901527352722104		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.16901527352722104 | validation: 0.1330577832181044]
	TIME [epoch: 8.3 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1630646478023729		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.1630646478023729 | validation: 0.1409327100269526]
	TIME [epoch: 8.3 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1591233463347677		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.1591233463347677 | validation: 0.14499821538353852]
	TIME [epoch: 8.3 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16407873575139112		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.16407873575139112 | validation: 0.13722877729546584]
	TIME [epoch: 8.32 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1629967966049845		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.1629967966049845 | validation: 0.12909966492451974]
	TIME [epoch: 8.3 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16213864805529515		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.16213864805529515 | validation: 0.14767661740661106]
	TIME [epoch: 8.3 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15948233050308128		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.15948233050308128 | validation: 0.14282735352187786]
	TIME [epoch: 8.3 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15574912820945086		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.15574912820945086 | validation: 0.14026391042140174]
	TIME [epoch: 8.32 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16592823380998298		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.16592823380998298 | validation: 0.14634953938467987]
	TIME [epoch: 8.3 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16404002727159836		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.16404002727159836 | validation: 0.14298492757702552]
	TIME [epoch: 8.3 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16042552202797514		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.16042552202797514 | validation: 0.14723012752208506]
	TIME [epoch: 8.3 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15926577924191948		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.15926577924191948 | validation: 0.13747535249004678]
	TIME [epoch: 8.3 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16267008578794995		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.16267008578794995 | validation: 0.13073176306561338]
	TIME [epoch: 8.32 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1604288221502841		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.1604288221502841 | validation: 0.1365881239092332]
	TIME [epoch: 8.3 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15892462532097795		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.15892462532097795 | validation: 0.13025095563117858]
	TIME [epoch: 8.3 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1635809896183765		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.1635809896183765 | validation: 0.12733337803397818]
	TIME [epoch: 8.3 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15656263349812558		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.15656263349812558 | validation: 0.14242581147009686]
	TIME [epoch: 8.31 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16215169934386225		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.16215169934386225 | validation: 0.1351906541127578]
	TIME [epoch: 8.31 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16127158623457036		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.16127158623457036 | validation: 0.16997201930139832]
	TIME [epoch: 8.29 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16689838276081725		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.16689838276081725 | validation: 0.1428488868203076]
	TIME [epoch: 8.3 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1572613460975069		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.1572613460975069 | validation: 0.13562480558860857]
	TIME [epoch: 8.32 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15814441647516414		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.15814441647516414 | validation: 0.15489376489419454]
	TIME [epoch: 8.3 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15547704995891432		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.15547704995891432 | validation: 0.13479288476090148]
	TIME [epoch: 8.3 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16204225758025745		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.16204225758025745 | validation: 0.14527513087860638]
	TIME [epoch: 8.3 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16674216030832403		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.16674216030832403 | validation: 0.1376771688301624]
	TIME [epoch: 8.3 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16339390683012717		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.16339390683012717 | validation: 0.1274512094018203]
	TIME [epoch: 8.31 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1581047212333627		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.1581047212333627 | validation: 0.13970180604846166]
	TIME [epoch: 8.3 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1589268165019188		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.1589268165019188 | validation: 0.14736142209624303]
	TIME [epoch: 8.3 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1629310908760327		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.1629310908760327 | validation: 0.14074246600770887]
	TIME [epoch: 8.3 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15544966941829724		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.15544966941829724 | validation: 0.13601231420654256]
	TIME [epoch: 8.32 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15460467433628022		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.15460467433628022 | validation: 0.14197819334417527]
	TIME [epoch: 8.3 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15975765323141586		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.15975765323141586 | validation: 0.1366691171409703]
	TIME [epoch: 8.3 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1582594177228119		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.1582594177228119 | validation: 0.12655681502338015]
	TIME [epoch: 8.3 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16574414594997397		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.16574414594997397 | validation: 0.14387208833040138]
	TIME [epoch: 8.32 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16341896032477873		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.16341896032477873 | validation: 0.1347640126718574]
	TIME [epoch: 8.31 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1595658184350893		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.1595658184350893 | validation: 0.14934399055647926]
	TIME [epoch: 8.29 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16984898172655444		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.16984898172655444 | validation: 0.13565369401387478]
	TIME [epoch: 8.29 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1617750476859142		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.1617750476859142 | validation: 0.14203415923534424]
	TIME [epoch: 8.28 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16814142065744514		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.16814142065744514 | validation: 0.13399848953745863]
	TIME [epoch: 8.31 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1607397402118888		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.1607397402118888 | validation: 0.1297612990137728]
	TIME [epoch: 8.3 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17047908956969632		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.17047908956969632 | validation: 0.14041809036286323]
	TIME [epoch: 8.3 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16936959378598757		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.16936959378598757 | validation: 0.13725744832874642]
	TIME [epoch: 8.3 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16373954522884976		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.16373954522884976 | validation: 0.13537782814110735]
	TIME [epoch: 8.32 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1665451722404803		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.1665451722404803 | validation: 0.1441405120024632]
	TIME [epoch: 8.29 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.166499787876821		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.166499787876821 | validation: 0.13365310923723944]
	TIME [epoch: 8.3 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18408940640468585		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.18408940640468585 | validation: 0.16640617726193047]
	TIME [epoch: 8.29 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17897019088945174		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.17897019088945174 | validation: 0.13069495310355858]
	TIME [epoch: 8.31 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17372578835726607		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.17372578835726607 | validation: 0.13331689511847977]
	TIME [epoch: 8.31 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1725885936193074		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.1725885936193074 | validation: 0.1415491999192358]
	TIME [epoch: 8.3 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1698848263411242		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.1698848263411242 | validation: 0.14577042617210473]
	TIME [epoch: 8.3 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17601449690681387		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.17601449690681387 | validation: 0.1592469884219895]
	TIME [epoch: 8.29 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1726618164811432		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.1726618164811432 | validation: 0.15242001001295236]
	TIME [epoch: 8.32 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1711036393307614		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.1711036393307614 | validation: 0.13741109956272696]
	TIME [epoch: 8.29 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16387232183825162		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.16387232183825162 | validation: 0.14997981872232258]
	TIME [epoch: 8.29 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16114000803025338		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.16114000803025338 | validation: 0.1373952454233333]
	TIME [epoch: 8.29 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16011298743249155		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.16011298743249155 | validation: 0.131437261378997]
	TIME [epoch: 8.32 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16175254967164987		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.16175254967164987 | validation: 0.1348884826026091]
	TIME [epoch: 8.29 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16020380819409258		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.16020380819409258 | validation: 0.13822761404688155]
	TIME [epoch: 8.3 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16356196617387544		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.16356196617387544 | validation: 0.12087888596393226]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r2_20240218_115024/states/model_tr_study3_959.pth
	Model improved!!!
EPOCH 960/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16007923253712888		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.16007923253712888 | validation: 0.14259060766997605]
	TIME [epoch: 8.33 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1712724674804838		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.1712724674804838 | validation: 0.13354883828755523]
	TIME [epoch: 8.32 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.166578026861709		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.166578026861709 | validation: 0.13318807846213254]
	TIME [epoch: 8.31 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1645573787474618		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.1645573787474618 | validation: 0.12798162064192709]
	TIME [epoch: 8.31 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17229786147348844		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.17229786147348844 | validation: 0.14774148965910955]
	TIME [epoch: 8.31 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1795576930200962		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.1795576930200962 | validation: 0.14643901454736488]
	TIME [epoch: 8.33 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1698379068803917		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.1698379068803917 | validation: 0.14592938968741265]
	TIME [epoch: 8.31 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1657446664384449		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.1657446664384449 | validation: 0.15322306131667368]
	TIME [epoch: 8.31 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17316038431141034		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.17316038431141034 | validation: 0.145999734991002]
	TIME [epoch: 8.3 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1801862344489261		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.1801862344489261 | validation: 0.14260033018086182]
	TIME [epoch: 8.33 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17670161671526655		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.17670161671526655 | validation: 0.15363418373125995]
	TIME [epoch: 8.31 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16909727224658824		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.16909727224658824 | validation: 0.14333026743165517]
	TIME [epoch: 8.31 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.164853588506983		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.164853588506983 | validation: 0.13956608573185447]
	TIME [epoch: 8.31 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17091015044307356		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.17091015044307356 | validation: 0.14675113954024335]
	TIME [epoch: 8.32 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16820235249457063		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.16820235249457063 | validation: 0.14243013978956107]
	TIME [epoch: 8.32 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1648622440996797		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.1648622440996797 | validation: 0.14689304903524805]
	TIME [epoch: 8.31 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16687928683897513		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.16687928683897513 | validation: 0.14390685115770047]
	TIME [epoch: 8.31 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16286917551545174		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.16286917551545174 | validation: 0.13547259079899931]
	TIME [epoch: 8.3 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16623280111142918		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.16623280111142918 | validation: 0.12922534589312443]
	TIME [epoch: 8.33 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16797064515589893		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.16797064515589893 | validation: 0.1432918478152714]
	TIME [epoch: 8.31 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1659193176580339		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.1659193176580339 | validation: 0.13526903108645677]
	TIME [epoch: 8.31 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1630361119918175		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.1630361119918175 | validation: 0.1351314938135352]
	TIME [epoch: 8.31 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17036267270116387		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.17036267270116387 | validation: 0.1371553194694463]
	TIME [epoch: 8.33 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1651954463416973		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.1651954463416973 | validation: 0.13247409593907317]
	TIME [epoch: 8.31 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1670643417511743		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.1670643417511743 | validation: 0.15339005919456225]
	TIME [epoch: 8.31 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17091389967787013		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.17091389967787013 | validation: 0.14328293600099024]
	TIME [epoch: 8.31 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1674583784975518		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.1674583784975518 | validation: 0.1318894594423871]
	TIME [epoch: 8.31 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1702898954952527		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.1702898954952527 | validation: 0.13731681719267072]
	TIME [epoch: 8.33 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16560727734577285		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.16560727734577285 | validation: 0.1311938972478337]
	TIME [epoch: 8.35 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16145500832742612		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.16145500832742612 | validation: 0.13406422050618266]
	TIME [epoch: 8.31 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16268659733093374		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.16268659733093374 | validation: 0.12692142651662913]
	TIME [epoch: 8.31 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16703504591944376		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.16703504591944376 | validation: 0.138464778438231]
	TIME [epoch: 8.33 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17059586071332708		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.17059586071332708 | validation: 0.14579177175882568]
	TIME [epoch: 8.32 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1653272096517844		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.1653272096517844 | validation: 0.13258600131482487]
	TIME [epoch: 8.31 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16134883142783124		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.16134883142783124 | validation: 0.13665315100485034]
	TIME [epoch: 8.31 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1624122244113795		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.1624122244113795 | validation: 0.13660357392082723]
	TIME [epoch: 8.34 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.164540396155005		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.164540396155005 | validation: 0.13111951896114182]
	TIME [epoch: 8.31 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15713752458248326		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.15713752458248326 | validation: 0.12369695310002904]
	TIME [epoch: 8.31 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15905576661534399		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.15905576661534399 | validation: 0.13319521829446782]
	TIME [epoch: 8.31 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15475923684650178		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.15475923684650178 | validation: 0.13857901771261288]
	TIME [epoch: 8.32 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16184212493706945		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.16184212493706945 | validation: 0.14357249234409902]
	TIME [epoch: 8.34 sec]
Finished training in 8418.979 seconds.
