Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r3', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2288742887

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 11.060614032026914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.060614032026914 | validation: 9.691678515303636]
	TIME [epoch: 78.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.506673718114943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.506673718114943 | validation: 10.014022325782335]
	TIME [epoch: 8.56 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.0879269464176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.0879269464176 | validation: 9.624062363254755]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.626677391703472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.626677391703472 | validation: 8.680461430252686]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.460466887583186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.460466887583186 | validation: 8.521254957715616]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.787701855413289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.787701855413289 | validation: 7.460153007280061]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.225533104986336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.225533104986336 | validation: 6.950338210370332]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.821420883792302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.821420883792302 | validation: 6.7917935434737435]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.745507759440419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.745507759440419 | validation: 6.946474300550653]
	TIME [epoch: 8.53 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.627809964439841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.627809964439841 | validation: 7.417575066319003]
	TIME [epoch: 8.52 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.647251756222576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.647251756222576 | validation: 6.767332066282863]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.402764901541808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.402764901541808 | validation: 6.58299819740432]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.081868213193762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.081868213193762 | validation: 6.458880784336938]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.809311561914773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.809311561914773 | validation: 6.4579693834056755]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.558011509647907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.558011509647907 | validation: 5.738274617485761]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.105264529619234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.105264529619234 | validation: 6.854827963373314]
	TIME [epoch: 8.53 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.69483091730543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.69483091730543 | validation: 3.864485534420904]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.70868715209094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.70868715209094 | validation: 4.126908798447554]
	TIME [epoch: 8.53 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.564074759175029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.564074759175029 | validation: 4.901715135652902]
	TIME [epoch: 8.55 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.894611999830083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.894611999830083 | validation: 3.594156691269129]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.356444379399646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.356444379399646 | validation: 3.668676457400652]
	TIME [epoch: 8.52 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.633829854736158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.633829854736158 | validation: 3.6275302089173116]
	TIME [epoch: 8.51 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.15902650723344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.15902650723344 | validation: 3.924193043418322]
	TIME [epoch: 8.55 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.2525801396139755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2525801396139755 | validation: 3.7046791732489694]
	TIME [epoch: 8.53 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.180440590544014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.180440590544014 | validation: 3.447368352857898]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.477191214713273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.477191214713273 | validation: 3.8852176398903593]
	TIME [epoch: 8.52 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.238958087608494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.238958087608494 | validation: 3.3865024413265603]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8765134359356304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8765134359356304 | validation: 3.4120169943599787]
	TIME [epoch: 8.52 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5687984754375095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5687984754375095 | validation: 4.317388667374587]
	TIME [epoch: 8.52 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0016222557432886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0016222557432886 | validation: 2.3820553513270326]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.671229846269581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.671229846269581 | validation: 2.2564481378149246]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.374148724073985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.374148724073985 | validation: 2.3698861767033055]
	TIME [epoch: 8.52 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.372619562653827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.372619562653827 | validation: 1.9666243833168573]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.095861200711984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.095861200711984 | validation: 2.5006124351308205]
	TIME [epoch: 8.53 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3789523666056587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3789523666056587 | validation: 2.578878369853915]
	TIME [epoch: 8.53 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4429100796248244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4429100796248244 | validation: 2.8155185372912723]
	TIME [epoch: 8.52 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2941184419342093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2941184419342093 | validation: 1.6285987037033256]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9837245847544227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9837245847544227 | validation: 1.6173483675220006]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4035509933814176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4035509933814176 | validation: 1.9452985665523779]
	TIME [epoch: 8.53 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.067995365221976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.067995365221976 | validation: 2.00549146237769]
	TIME [epoch: 8.53 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0233397915994393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0233397915994393 | validation: 1.9085695805871592]
	TIME [epoch: 8.52 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8109940464154277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8109940464154277 | validation: 1.4413231497588872]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7323816736897715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7323816736897715 | validation: 1.7878835477676975]
	TIME [epoch: 8.53 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8999266421299001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8999266421299001 | validation: 1.7327798237357994]
	TIME [epoch: 8.53 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1638930904733065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1638930904733065 | validation: 2.254947598940022]
	TIME [epoch: 8.53 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.282858400082822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.282858400082822 | validation: 1.9668618330759087]
	TIME [epoch: 8.55 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.175053190613711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.175053190613711 | validation: 3.543779537484468]
	TIME [epoch: 8.53 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.497906991140861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.497906991140861 | validation: 2.071545178559875]
	TIME [epoch: 8.53 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.068707905128553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.068707905128553 | validation: 2.4695068564450606]
	TIME [epoch: 8.53 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9534574014822013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9534574014822013 | validation: 1.6516285129560309]
	TIME [epoch: 8.56 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6683285088934725		[learning rate: 0.0099788]
	Learning Rate: 0.00997877
	LOSS [training: 1.6683285088934725 | validation: 1.760456883942103]
	TIME [epoch: 8.54 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8102574517857626		[learning rate: 0.0099552]
	Learning Rate: 0.00995523
	LOSS [training: 1.8102574517857626 | validation: 1.3972879361075465]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.556683491639732		[learning rate: 0.0099317]
	Learning Rate: 0.00993175
	LOSS [training: 1.556683491639732 | validation: 1.563259756977768]
	TIME [epoch: 8.53 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.552714048113957		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 1.552714048113957 | validation: 1.1474699947619906]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5109631168449646		[learning rate: 0.0098849]
	Learning Rate: 0.00988495
	LOSS [training: 1.5109631168449646 | validation: 1.2730909348019024]
	TIME [epoch: 8.52 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7295828560526592		[learning rate: 0.0098616]
	Learning Rate: 0.00986163
	LOSS [training: 1.7295828560526592 | validation: 1.119702352795012]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3849556007750539		[learning rate: 0.0098384]
	Learning Rate: 0.00983837
	LOSS [training: 1.3849556007750539 | validation: 1.2584775446247398]
	TIME [epoch: 8.54 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3982021468756496		[learning rate: 0.0098152]
	Learning Rate: 0.00981516
	LOSS [training: 1.3982021468756496 | validation: 2.7796364567864833]
	TIME [epoch: 8.54 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6245364562601872		[learning rate: 0.009792]
	Learning Rate: 0.00979201
	LOSS [training: 1.6245364562601872 | validation: 1.3078922563723885]
	TIME [epoch: 8.53 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4805489821605806		[learning rate: 0.0097689]
	Learning Rate: 0.00976891
	LOSS [training: 1.4805489821605806 | validation: 1.6053583315839215]
	TIME [epoch: 8.52 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.330292905867846		[learning rate: 0.0097459]
	Learning Rate: 0.00974587
	LOSS [training: 1.330292905867846 | validation: 1.175769306880083]
	TIME [epoch: 8.54 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2746576668516973		[learning rate: 0.0097229]
	Learning Rate: 0.00972288
	LOSS [training: 1.2746576668516973 | validation: 1.3785753523095976]
	TIME [epoch: 8.54 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2863655285153024		[learning rate: 0.0096999]
	Learning Rate: 0.00969994
	LOSS [training: 1.2863655285153024 | validation: 2.1860611927927276]
	TIME [epoch: 8.53 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4394960644664707		[learning rate: 0.0096771]
	Learning Rate: 0.00967706
	LOSS [training: 1.4394960644664707 | validation: 1.2747304501042733]
	TIME [epoch: 8.52 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2081703213334951		[learning rate: 0.0096542]
	Learning Rate: 0.00965424
	LOSS [training: 1.2081703213334951 | validation: 1.4172813048006332]
	TIME [epoch: 8.55 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4002631526956661		[learning rate: 0.0096315]
	Learning Rate: 0.00963146
	LOSS [training: 1.4002631526956661 | validation: 0.9548074472577]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4254870037250251		[learning rate: 0.0096087]
	Learning Rate: 0.00960874
	LOSS [training: 1.4254870037250251 | validation: 0.898597176425812]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1865717808556169		[learning rate: 0.0095861]
	Learning Rate: 0.00958608
	LOSS [training: 1.1865717808556169 | validation: 1.2249658303631414]
	TIME [epoch: 8.52 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3387283639548442		[learning rate: 0.0095635]
	Learning Rate: 0.00956347
	LOSS [training: 1.3387283639548442 | validation: 1.4630942343086972]
	TIME [epoch: 8.54 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.686264182704217		[learning rate: 0.0095409]
	Learning Rate: 0.00954091
	LOSS [training: 1.686264182704217 | validation: 1.5064842354162735]
	TIME [epoch: 8.52 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1709256773314842		[learning rate: 0.0095184]
	Learning Rate: 0.0095184
	LOSS [training: 1.1709256773314842 | validation: 1.4501567370917914]
	TIME [epoch: 8.52 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2736974093743898		[learning rate: 0.009496]
	Learning Rate: 0.00949595
	LOSS [training: 1.2736974093743898 | validation: 1.380825658135031]
	TIME [epoch: 8.52 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1601078252880839		[learning rate: 0.0094736]
	Learning Rate: 0.00947355
	LOSS [training: 1.1601078252880839 | validation: 1.070543380938589]
	TIME [epoch: 8.55 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1814064044036092		[learning rate: 0.0094512]
	Learning Rate: 0.0094512
	LOSS [training: 1.1814064044036092 | validation: 1.4063547130991676]
	TIME [epoch: 8.52 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4073773510914807		[learning rate: 0.0094289]
	Learning Rate: 0.00942891
	LOSS [training: 1.4073773510914807 | validation: 0.9620023093020372]
	TIME [epoch: 8.52 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5401091819472144		[learning rate: 0.0094067]
	Learning Rate: 0.00940667
	LOSS [training: 1.5401091819472144 | validation: 1.0287507096765558]
	TIME [epoch: 8.52 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0917435399368478		[learning rate: 0.0093845]
	Learning Rate: 0.00938448
	LOSS [training: 1.0917435399368478 | validation: 1.869756779509455]
	TIME [epoch: 8.55 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2243554276305546		[learning rate: 0.0093623]
	Learning Rate: 0.00936234
	LOSS [training: 1.2243554276305546 | validation: 0.9221282258791951]
	TIME [epoch: 8.52 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.819606329888348		[learning rate: 0.0093403]
	Learning Rate: 0.00934026
	LOSS [training: 1.819606329888348 | validation: 1.7019173175417501]
	TIME [epoch: 8.52 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4537144188897455		[learning rate: 0.0093182]
	Learning Rate: 0.00931823
	LOSS [training: 1.4537144188897455 | validation: 1.7976229879654895]
	TIME [epoch: 8.52 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1708711017353448		[learning rate: 0.0092962]
	Learning Rate: 0.00929625
	LOSS [training: 1.1708711017353448 | validation: 1.199193040676581]
	TIME [epoch: 8.54 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2852153060452502		[learning rate: 0.0092743]
	Learning Rate: 0.00927432
	LOSS [training: 1.2852153060452502 | validation: 1.1172718276214928]
	TIME [epoch: 8.52 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2257291433026716		[learning rate: 0.0092524]
	Learning Rate: 0.00925244
	LOSS [training: 1.2257291433026716 | validation: 0.9892521640223713]
	TIME [epoch: 8.51 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.183812794133095		[learning rate: 0.0092306]
	Learning Rate: 0.00923062
	LOSS [training: 1.183812794133095 | validation: 1.339048823570841]
	TIME [epoch: 8.52 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1518868924872294		[learning rate: 0.0092088]
	Learning Rate: 0.00920884
	LOSS [training: 1.1518868924872294 | validation: 1.0753219903980762]
	TIME [epoch: 8.53 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1197894579852408		[learning rate: 0.0091871]
	Learning Rate: 0.00918712
	LOSS [training: 1.1197894579852408 | validation: 1.2734695642332645]
	TIME [epoch: 8.52 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1424441897092397		[learning rate: 0.0091655]
	Learning Rate: 0.00916545
	LOSS [training: 1.1424441897092397 | validation: 1.3357510067458693]
	TIME [epoch: 8.52 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2924704751114666		[learning rate: 0.0091438]
	Learning Rate: 0.00914383
	LOSS [training: 1.2924704751114666 | validation: 0.8796447736682096]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2149050229637044		[learning rate: 0.0091223]
	Learning Rate: 0.00912226
	LOSS [training: 1.2149050229637044 | validation: 1.492133693916438]
	TIME [epoch: 8.53 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5045344839352217		[learning rate: 0.0091007]
	Learning Rate: 0.00910074
	LOSS [training: 1.5045344839352217 | validation: 1.506508360433621]
	TIME [epoch: 8.52 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7034778196925497		[learning rate: 0.0090793]
	Learning Rate: 0.00907928
	LOSS [training: 1.7034778196925497 | validation: 2.1234262449028467]
	TIME [epoch: 8.52 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5235869341347335		[learning rate: 0.0090579]
	Learning Rate: 0.00905786
	LOSS [training: 1.5235869341347335 | validation: 1.3161164106432057]
	TIME [epoch: 8.53 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4753576156469346		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 1.4753576156469346 | validation: 1.1910861344789425]
	TIME [epoch: 8.53 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.087278340435715		[learning rate: 0.0090152]
	Learning Rate: 0.00901518
	LOSS [training: 1.087278340435715 | validation: 0.8022459685842249]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.404619196382506		[learning rate: 0.0089939]
	Learning Rate: 0.00899391
	LOSS [training: 1.404619196382506 | validation: 1.1942292879676857]
	TIME [epoch: 8.52 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.29150104613075		[learning rate: 0.0089727]
	Learning Rate: 0.0089727
	LOSS [training: 1.29150104613075 | validation: 0.9166518287649057]
	TIME [epoch: 8.54 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3815073386034487		[learning rate: 0.0089515]
	Learning Rate: 0.00895153
	LOSS [training: 1.3815073386034487 | validation: 1.3247876671389753]
	TIME [epoch: 8.52 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4189796998666533		[learning rate: 0.0089304]
	Learning Rate: 0.00893042
	LOSS [training: 1.4189796998666533 | validation: 2.092323876186124]
	TIME [epoch: 8.52 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3781865880556468		[learning rate: 0.0089094]
	Learning Rate: 0.00890935
	LOSS [training: 1.3781865880556468 | validation: 1.2964779471921886]
	TIME [epoch: 8.52 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0563443476022258		[learning rate: 0.0088883]
	Learning Rate: 0.00888834
	LOSS [training: 1.0563443476022258 | validation: 1.4553411206175144]
	TIME [epoch: 8.54 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2470097804578284		[learning rate: 0.0088674]
	Learning Rate: 0.00886737
	LOSS [training: 1.2470097804578284 | validation: 0.9562981703537725]
	TIME [epoch: 8.52 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1327495585352303		[learning rate: 0.0088465]
	Learning Rate: 0.00884645
	LOSS [training: 1.1327495585352303 | validation: 1.171433258667433]
	TIME [epoch: 8.51 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4517687739899152		[learning rate: 0.0088256]
	Learning Rate: 0.00882559
	LOSS [training: 1.4517687739899152 | validation: 1.2668891030853269]
	TIME [epoch: 8.52 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.31468250251122		[learning rate: 0.0088048]
	Learning Rate: 0.00880477
	LOSS [training: 1.31468250251122 | validation: 0.945463418883517]
	TIME [epoch: 8.54 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0524718056493614		[learning rate: 0.008784]
	Learning Rate: 0.008784
	LOSS [training: 1.0524718056493614 | validation: 1.1193973592284192]
	TIME [epoch: 8.52 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0563776354307057		[learning rate: 0.0087633]
	Learning Rate: 0.00876328
	LOSS [training: 1.0563776354307057 | validation: 1.2614003955761959]
	TIME [epoch: 8.52 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5507739686939555		[learning rate: 0.0087426]
	Learning Rate: 0.00874261
	LOSS [training: 1.5507739686939555 | validation: 1.419313861614903]
	TIME [epoch: 8.52 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1172409949850162		[learning rate: 0.008722]
	Learning Rate: 0.00872199
	LOSS [training: 1.1172409949850162 | validation: 0.8221886241835719]
	TIME [epoch: 8.55 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1232398875339347		[learning rate: 0.0087014]
	Learning Rate: 0.00870141
	LOSS [training: 1.1232398875339347 | validation: 0.768387743066912]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0884506884135021		[learning rate: 0.0086809]
	Learning Rate: 0.00868089
	LOSS [training: 1.0884506884135021 | validation: 0.9607679087889451]
	TIME [epoch: 8.52 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1508995168371285		[learning rate: 0.0086604]
	Learning Rate: 0.00866041
	LOSS [training: 1.1508995168371285 | validation: 1.0318417324495988]
	TIME [epoch: 8.52 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2066530462305862		[learning rate: 0.00864]
	Learning Rate: 0.00863998
	LOSS [training: 1.2066530462305862 | validation: 0.9316060662563153]
	TIME [epoch: 8.54 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.197169551263865		[learning rate: 0.0086196]
	Learning Rate: 0.0086196
	LOSS [training: 1.197169551263865 | validation: 1.1597537155708693]
	TIME [epoch: 8.53 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1481530443832573		[learning rate: 0.0085993]
	Learning Rate: 0.00859927
	LOSS [training: 1.1481530443832573 | validation: 0.8680245120563539]
	TIME [epoch: 8.52 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.064566735276533		[learning rate: 0.008579]
	Learning Rate: 0.00857898
	LOSS [training: 1.064566735276533 | validation: 0.897830456889442]
	TIME [epoch: 8.52 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1509811486945867		[learning rate: 0.0085587]
	Learning Rate: 0.00855875
	LOSS [training: 1.1509811486945867 | validation: 0.9512028830159004]
	TIME [epoch: 8.54 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9760561572448735		[learning rate: 0.0085386]
	Learning Rate: 0.00853856
	LOSS [training: 0.9760561572448735 | validation: 0.9627163922755532]
	TIME [epoch: 8.52 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1362835682242605		[learning rate: 0.0085184]
	Learning Rate: 0.00851842
	LOSS [training: 1.1362835682242605 | validation: 1.0403768112884966]
	TIME [epoch: 8.52 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1627418324105052		[learning rate: 0.0084983]
	Learning Rate: 0.00849833
	LOSS [training: 1.1627418324105052 | validation: 0.8674244960166966]
	TIME [epoch: 8.54 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.030097846537644		[learning rate: 0.0084783]
	Learning Rate: 0.00847828
	LOSS [training: 1.030097846537644 | validation: 1.4264730308078533]
	TIME [epoch: 8.52 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0752929394651047		[learning rate: 0.0084583]
	Learning Rate: 0.00845828
	LOSS [training: 1.0752929394651047 | validation: 1.2152094809919056]
	TIME [epoch: 8.52 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.032411891345847		[learning rate: 0.0084383]
	Learning Rate: 0.00843833
	LOSS [training: 1.032411891345847 | validation: 1.7246770830318945]
	TIME [epoch: 8.52 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0879673074248075		[learning rate: 0.0084184]
	Learning Rate: 0.00841842
	LOSS [training: 1.0879673074248075 | validation: 1.8824941732389586]
	TIME [epoch: 8.54 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9335033882530936		[learning rate: 0.0083986]
	Learning Rate: 0.00839857
	LOSS [training: 0.9335033882530936 | validation: 1.1762867678364324]
	TIME [epoch: 8.53 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8558384528252256		[learning rate: 0.0083788]
	Learning Rate: 0.00837875
	LOSS [training: 0.8558384528252256 | validation: 0.8851425728501263]
	TIME [epoch: 8.51 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0650032899722808		[learning rate: 0.008359]
	Learning Rate: 0.00835899
	LOSS [training: 1.0650032899722808 | validation: 1.5259950199612726]
	TIME [epoch: 8.52 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2518766754410833		[learning rate: 0.0083393]
	Learning Rate: 0.00833927
	LOSS [training: 1.2518766754410833 | validation: 0.7855812057916053]
	TIME [epoch: 8.54 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9810263624442976		[learning rate: 0.0083196]
	Learning Rate: 0.0083196
	LOSS [training: 0.9810263624442976 | validation: 1.5755325039428483]
	TIME [epoch: 8.52 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9197295632433949		[learning rate: 0.0083]
	Learning Rate: 0.00829998
	LOSS [training: 0.9197295632433949 | validation: 0.6467908279901822]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1262110570132169		[learning rate: 0.0082804]
	Learning Rate: 0.0082804
	LOSS [training: 1.1262110570132169 | validation: 1.2843877292527588]
	TIME [epoch: 8.52 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9755883845749208		[learning rate: 0.0082609]
	Learning Rate: 0.00826087
	LOSS [training: 0.9755883845749208 | validation: 1.9073494844391536]
	TIME [epoch: 8.54 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0113577215734222		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 1.0113577215734222 | validation: 1.2251412598621774]
	TIME [epoch: 8.52 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7678442680630715		[learning rate: 0.0082219]
	Learning Rate: 0.00822194
	LOSS [training: 0.7678442680630715 | validation: 0.7369833829085212]
	TIME [epoch: 8.52 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1828206957633882		[learning rate: 0.0082025]
	Learning Rate: 0.00820255
	LOSS [training: 1.1828206957633882 | validation: 0.9975858375513613]
	TIME [epoch: 8.51 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9480956280708661		[learning rate: 0.0081832]
	Learning Rate: 0.0081832
	LOSS [training: 0.9480956280708661 | validation: 0.6435005030397873]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8683305064062754		[learning rate: 0.0081639]
	Learning Rate: 0.00816389
	LOSS [training: 0.8683305064062754 | validation: 0.7019164473467396]
	TIME [epoch: 8.52 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1368024550862166		[learning rate: 0.0081446]
	Learning Rate: 0.00814464
	LOSS [training: 1.1368024550862166 | validation: 0.8414312091882525]
	TIME [epoch: 8.51 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.005835434941403		[learning rate: 0.0081254]
	Learning Rate: 0.00812543
	LOSS [training: 1.005835434941403 | validation: 0.7122434192455667]
	TIME [epoch: 8.51 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1294204206844047		[learning rate: 0.0081063]
	Learning Rate: 0.00810626
	LOSS [training: 1.1294204206844047 | validation: 1.5679256841492213]
	TIME [epoch: 8.54 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1471408837359232		[learning rate: 0.0080871]
	Learning Rate: 0.00808714
	LOSS [training: 1.1471408837359232 | validation: 1.2651304270253239]
	TIME [epoch: 8.51 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8929809230692948		[learning rate: 0.0080681]
	Learning Rate: 0.00806806
	LOSS [training: 0.8929809230692948 | validation: 0.8235137077002355]
	TIME [epoch: 8.51 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3058525174298208		[learning rate: 0.008049]
	Learning Rate: 0.00804903
	LOSS [training: 1.3058525174298208 | validation: 0.9607037299391467]
	TIME [epoch: 8.51 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8061597894843239		[learning rate: 0.00803]
	Learning Rate: 0.00803004
	LOSS [training: 0.8061597894843239 | validation: 0.7995597883392003]
	TIME [epoch: 8.54 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9185221139252304		[learning rate: 0.0080111]
	Learning Rate: 0.0080111
	LOSS [training: 0.9185221139252304 | validation: 0.7182647248575642]
	TIME [epoch: 8.51 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.18231299274636		[learning rate: 0.0079922]
	Learning Rate: 0.00799221
	LOSS [training: 1.18231299274636 | validation: 1.4029014234184682]
	TIME [epoch: 8.52 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0739742028339814		[learning rate: 0.0079734]
	Learning Rate: 0.00797335
	LOSS [training: 1.0739742028339814 | validation: 0.7086478541457022]
	TIME [epoch: 8.53 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8075949647384612		[learning rate: 0.0079545]
	Learning Rate: 0.00795455
	LOSS [training: 0.8075949647384612 | validation: 0.8354181801122242]
	TIME [epoch: 8.54 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8979730468583493		[learning rate: 0.0079358]
	Learning Rate: 0.00793578
	LOSS [training: 0.8979730468583493 | validation: 0.7639436711262955]
	TIME [epoch: 8.52 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7567568969658283		[learning rate: 0.0079171]
	Learning Rate: 0.00791706
	LOSS [training: 0.7567568969658283 | validation: 0.6849766845095273]
	TIME [epoch: 8.52 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8499201771081342		[learning rate: 0.0078984]
	Learning Rate: 0.00789839
	LOSS [training: 0.8499201771081342 | validation: 2.0166933385365726]
	TIME [epoch: 8.53 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0493222545592549		[learning rate: 0.0078798]
	Learning Rate: 0.00787976
	LOSS [training: 1.0493222545592549 | validation: 0.882843427102423]
	TIME [epoch: 8.53 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9366521391952395		[learning rate: 0.0078612]
	Learning Rate: 0.00786117
	LOSS [training: 0.9366521391952395 | validation: 0.6959068134762643]
	TIME [epoch: 8.51 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7993751880179407		[learning rate: 0.0078426]
	Learning Rate: 0.00784263
	LOSS [training: 1.7993751880179407 | validation: 0.7263135240843547]
	TIME [epoch: 8.51 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9925552803333357		[learning rate: 0.0078241]
	Learning Rate: 0.00782413
	LOSS [training: 0.9925552803333357 | validation: 1.0503197420122254]
	TIME [epoch: 8.54 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9349142443540284		[learning rate: 0.0078057]
	Learning Rate: 0.00780567
	LOSS [training: 0.9349142443540284 | validation: 0.697821864883649]
	TIME [epoch: 8.53 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8651927723919212		[learning rate: 0.0077873]
	Learning Rate: 0.00778726
	LOSS [training: 0.8651927723919212 | validation: 1.0252727413403222]
	TIME [epoch: 8.52 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0531360201832072		[learning rate: 0.0077689]
	Learning Rate: 0.00776889
	LOSS [training: 1.0531360201832072 | validation: 1.2101040388843696]
	TIME [epoch: 8.52 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0648715473237405		[learning rate: 0.0077506]
	Learning Rate: 0.00775056
	LOSS [training: 1.0648715473237405 | validation: 0.6943695355113602]
	TIME [epoch: 8.54 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.890509250580714		[learning rate: 0.0077323]
	Learning Rate: 0.00773228
	LOSS [training: 0.890509250580714 | validation: 1.0719090254568153]
	TIME [epoch: 8.53 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8617352304338061		[learning rate: 0.007714]
	Learning Rate: 0.00771404
	LOSS [training: 0.8617352304338061 | validation: 0.5327042698477967]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9416085349214367		[learning rate: 0.0076958]
	Learning Rate: 0.00769585
	LOSS [training: 0.9416085349214367 | validation: 0.9449195575004941]
	TIME [epoch: 8.52 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8725211860127475		[learning rate: 0.0076777]
	Learning Rate: 0.00767769
	LOSS [training: 0.8725211860127475 | validation: 0.6272437525886589]
	TIME [epoch: 8.54 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7936106880544425		[learning rate: 0.0076596]
	Learning Rate: 0.00765958
	LOSS [training: 0.7936106880544425 | validation: 0.6528310760614295]
	TIME [epoch: 8.52 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6666915858738017		[learning rate: 0.0076415]
	Learning Rate: 0.00764151
	LOSS [training: 0.6666915858738017 | validation: 0.8535689118594159]
	TIME [epoch: 8.52 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.726578690028756		[learning rate: 0.0076235]
	Learning Rate: 0.00762349
	LOSS [training: 0.726578690028756 | validation: 1.148478618687713]
	TIME [epoch: 8.51 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8762630898474122		[learning rate: 0.0076055]
	Learning Rate: 0.00760551
	LOSS [training: 0.8762630898474122 | validation: 0.7918196478245512]
	TIME [epoch: 8.54 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7782893884554067		[learning rate: 0.0075876]
	Learning Rate: 0.00758757
	LOSS [training: 0.7782893884554067 | validation: 0.8118585581948896]
	TIME [epoch: 8.52 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0966500819639156		[learning rate: 0.0075697]
	Learning Rate: 0.00756967
	LOSS [training: 1.0966500819639156 | validation: 1.0483605861468333]
	TIME [epoch: 8.52 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9442489221118017		[learning rate: 0.0075518]
	Learning Rate: 0.00755181
	LOSS [training: 0.9442489221118017 | validation: 1.1930793453266983]
	TIME [epoch: 8.52 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8362593638031159		[learning rate: 0.007534]
	Learning Rate: 0.007534
	LOSS [training: 0.8362593638031159 | validation: 0.7454448471324204]
	TIME [epoch: 8.54 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7315930031906535		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.7315930031906535 | validation: 0.6114330235271912]
	TIME [epoch: 8.52 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7592793649465214		[learning rate: 0.0074985]
	Learning Rate: 0.0074985
	LOSS [training: 0.7592793649465214 | validation: 0.6652276202294736]
	TIME [epoch: 8.52 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6880807099062728		[learning rate: 0.0074808]
	Learning Rate: 0.00748081
	LOSS [training: 0.6880807099062728 | validation: 0.5398445259083657]
	TIME [epoch: 8.52 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7407856954397729		[learning rate: 0.0074632]
	Learning Rate: 0.00746317
	LOSS [training: 0.7407856954397729 | validation: 0.6184871812228552]
	TIME [epoch: 8.54 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7688764775454844		[learning rate: 0.0074456]
	Learning Rate: 0.00744556
	LOSS [training: 0.7688764775454844 | validation: 0.6323561811447209]
	TIME [epoch: 8.52 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7168098382073919		[learning rate: 0.007428]
	Learning Rate: 0.007428
	LOSS [training: 0.7168098382073919 | validation: 0.6198646081043772]
	TIME [epoch: 8.52 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7450799545339306		[learning rate: 0.0074105]
	Learning Rate: 0.00741048
	LOSS [training: 0.7450799545339306 | validation: 0.9889392694058678]
	TIME [epoch: 8.53 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.794599499329971		[learning rate: 0.007393]
	Learning Rate: 0.007393
	LOSS [training: 0.794599499329971 | validation: 0.5240213426817748]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7110883076564051		[learning rate: 0.0073756]
	Learning Rate: 0.00737556
	LOSS [training: 0.7110883076564051 | validation: 0.8131300544980486]
	TIME [epoch: 8.54 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8724435352428344		[learning rate: 0.0073582]
	Learning Rate: 0.00735816
	LOSS [training: 0.8724435352428344 | validation: 0.7715590683937588]
	TIME [epoch: 8.54 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7770922889340743		[learning rate: 0.0073408]
	Learning Rate: 0.0073408
	LOSS [training: 0.7770922889340743 | validation: 0.8941599115502209]
	TIME [epoch: 8.55 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6959257520019413		[learning rate: 0.0073235]
	Learning Rate: 0.00732349
	LOSS [training: 0.6959257520019413 | validation: 0.6183454950660261]
	TIME [epoch: 8.55 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5953857275845877		[learning rate: 0.0073062]
	Learning Rate: 0.00730621
	LOSS [training: 0.5953857275845877 | validation: 0.9087509155567652]
	TIME [epoch: 8.53 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.372248288811652		[learning rate: 0.007289]
	Learning Rate: 0.00728898
	LOSS [training: 1.372248288811652 | validation: 0.5724973018522856]
	TIME [epoch: 8.54 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6554169003926568		[learning rate: 0.0072718]
	Learning Rate: 0.00727178
	LOSS [training: 0.6554169003926568 | validation: 1.331764157402202]
	TIME [epoch: 8.56 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6870916028375087		[learning rate: 0.0072546]
	Learning Rate: 0.00725463
	LOSS [training: 0.6870916028375087 | validation: 1.0476383889583807]
	TIME [epoch: 8.54 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7792546880914863		[learning rate: 0.0072375]
	Learning Rate: 0.00723752
	LOSS [training: 0.7792546880914863 | validation: 1.135742072067201]
	TIME [epoch: 8.54 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6196691781743188		[learning rate: 0.0072204]
	Learning Rate: 0.00722045
	LOSS [training: 0.6196691781743188 | validation: 0.9620221879814178]
	TIME [epoch: 8.53 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6481497221881598		[learning rate: 0.0072034]
	Learning Rate: 0.00720342
	LOSS [training: 0.6481497221881598 | validation: 0.6686607717584101]
	TIME [epoch: 8.56 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6816106174937342		[learning rate: 0.0071864]
	Learning Rate: 0.00718642
	LOSS [training: 0.6816106174937342 | validation: 3.028233258349955]
	TIME [epoch: 8.54 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2600153830897716		[learning rate: 0.0071695]
	Learning Rate: 0.00716947
	LOSS [training: 1.2600153830897716 | validation: 0.8532867675269453]
	TIME [epoch: 8.54 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.945013644696264		[learning rate: 0.0071526]
	Learning Rate: 0.00715256
	LOSS [training: 0.945013644696264 | validation: 0.8573551204236365]
	TIME [epoch: 8.53 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8236427388627623		[learning rate: 0.0071357]
	Learning Rate: 0.00713569
	LOSS [training: 0.8236427388627623 | validation: 0.4934641402455554]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6611216009749245		[learning rate: 0.0071189]
	Learning Rate: 0.00711886
	LOSS [training: 0.6611216009749245 | validation: 0.5178290006028554]
	TIME [epoch: 8.53 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6482521366659482		[learning rate: 0.0071021]
	Learning Rate: 0.00710206
	LOSS [training: 0.6482521366659482 | validation: 0.5153925081867089]
	TIME [epoch: 8.53 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7066965150430757		[learning rate: 0.0070853]
	Learning Rate: 0.00708531
	LOSS [training: 0.7066965150430757 | validation: 0.37304290504763477]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_196.pth
	Model improved!!!
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5809184149267894		[learning rate: 0.0070686]
	Learning Rate: 0.0070686
	LOSS [training: 0.5809184149267894 | validation: 0.5791120340519987]
	TIME [epoch: 8.57 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7971670285903398		[learning rate: 0.0070519]
	Learning Rate: 0.00705192
	LOSS [training: 0.7971670285903398 | validation: 0.5738320014207522]
	TIME [epoch: 8.54 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.684911623395305		[learning rate: 0.0070353]
	Learning Rate: 0.00703529
	LOSS [training: 0.684911623395305 | validation: 0.922887348916579]
	TIME [epoch: 8.54 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7628448233578817		[learning rate: 0.0070187]
	Learning Rate: 0.0070187
	LOSS [training: 0.7628448233578817 | validation: 1.367464524199607]
	TIME [epoch: 8.53 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7030881087854874		[learning rate: 0.0070021]
	Learning Rate: 0.00700214
	LOSS [training: 0.7030881087854874 | validation: 0.48031152030800367]
	TIME [epoch: 8.56 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6444061876234849		[learning rate: 0.0069856]
	Learning Rate: 0.00698562
	LOSS [training: 0.6444061876234849 | validation: 0.8898085632549273]
	TIME [epoch: 8.54 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6410246917234762		[learning rate: 0.0069691]
	Learning Rate: 0.00696914
	LOSS [training: 0.6410246917234762 | validation: 0.8873247574228971]
	TIME [epoch: 8.54 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7205501472568135		[learning rate: 0.0069527]
	Learning Rate: 0.00695271
	LOSS [training: 0.7205501472568135 | validation: 0.554145346616336]
	TIME [epoch: 8.54 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7395505520886816		[learning rate: 0.0069363]
	Learning Rate: 0.00693631
	LOSS [training: 0.7395505520886816 | validation: 0.635891811497204]
	TIME [epoch: 8.55 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5492317344799138		[learning rate: 0.0069199]
	Learning Rate: 0.00691994
	LOSS [training: 0.5492317344799138 | validation: 0.7826239523616579]
	TIME [epoch: 8.53 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5218740432193696		[learning rate: 0.0069036]
	Learning Rate: 0.00690362
	LOSS [training: 0.5218740432193696 | validation: 0.6318105712020377]
	TIME [epoch: 8.53 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.637804955731705		[learning rate: 0.0068873]
	Learning Rate: 0.00688734
	LOSS [training: 0.637804955731705 | validation: 0.7850551708561735]
	TIME [epoch: 8.55 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6722709682731223		[learning rate: 0.0068711]
	Learning Rate: 0.00687109
	LOSS [training: 0.6722709682731223 | validation: 0.4513682277852391]
	TIME [epoch: 8.54 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5138227064073407		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.5138227064073407 | validation: 1.4982670500765842]
	TIME [epoch: 8.53 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7016129459537516		[learning rate: 0.0068387]
	Learning Rate: 0.00683871
	LOSS [training: 0.7016129459537516 | validation: 0.5534065816803322]
	TIME [epoch: 8.53 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.629728618004159		[learning rate: 0.0068226]
	Learning Rate: 0.00682258
	LOSS [training: 0.629728618004159 | validation: 0.581968670767399]
	TIME [epoch: 8.55 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6960559243028422		[learning rate: 0.0068065]
	Learning Rate: 0.00680649
	LOSS [training: 0.6960559243028422 | validation: 0.5039032211724832]
	TIME [epoch: 8.54 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5778932685394025		[learning rate: 0.0067904]
	Learning Rate: 0.00679043
	LOSS [training: 0.5778932685394025 | validation: 0.7148543773043429]
	TIME [epoch: 8.53 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7587464066930043		[learning rate: 0.0067744]
	Learning Rate: 0.00677441
	LOSS [training: 0.7587464066930043 | validation: 0.7141433916769815]
	TIME [epoch: 8.52 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8538089257046675		[learning rate: 0.0067584]
	Learning Rate: 0.00675843
	LOSS [training: 0.8538089257046675 | validation: 0.4459106993941735]
	TIME [epoch: 8.55 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.752513823697181		[learning rate: 0.0067425]
	Learning Rate: 0.00674249
	LOSS [training: 0.752513823697181 | validation: 0.5398103749287586]
	TIME [epoch: 8.53 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9595931557626575		[learning rate: 0.0067266]
	Learning Rate: 0.00672659
	LOSS [training: 0.9595931557626575 | validation: 0.36969367402449027]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_218.pth
	Model improved!!!
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5617238734657073		[learning rate: 0.0067107]
	Learning Rate: 0.00671072
	LOSS [training: 0.5617238734657073 | validation: 0.4835691837110708]
	TIME [epoch: 8.53 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6422882183269659		[learning rate: 0.0066949]
	Learning Rate: 0.00669489
	LOSS [training: 0.6422882183269659 | validation: 0.3894692933340614]
	TIME [epoch: 8.55 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.695599148090444		[learning rate: 0.0066791]
	Learning Rate: 0.0066791
	LOSS [training: 0.695599148090444 | validation: 1.1190209910886857]
	TIME [epoch: 8.53 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7650541069884157		[learning rate: 0.0066633]
	Learning Rate: 0.00666334
	LOSS [training: 0.7650541069884157 | validation: 0.5485352345851874]
	TIME [epoch: 8.53 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5787794763505216		[learning rate: 0.0066476]
	Learning Rate: 0.00664763
	LOSS [training: 0.5787794763505216 | validation: 0.4875446844521571]
	TIME [epoch: 8.52 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.532064219846857		[learning rate: 0.0066319]
	Learning Rate: 0.00663195
	LOSS [training: 0.532064219846857 | validation: 0.4454183447160399]
	TIME [epoch: 8.55 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6991838680077557		[learning rate: 0.0066163]
	Learning Rate: 0.0066163
	LOSS [training: 0.6991838680077557 | validation: 0.8616628634447198]
	TIME [epoch: 8.53 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.263732422816568		[learning rate: 0.0066007]
	Learning Rate: 0.0066007
	LOSS [training: 1.263732422816568 | validation: 0.6718807559997418]
	TIME [epoch: 8.52 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7101803909066846		[learning rate: 0.0065851]
	Learning Rate: 0.00658513
	LOSS [training: 0.7101803909066846 | validation: 0.8048080980560457]
	TIME [epoch: 8.52 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5995908031346568		[learning rate: 0.0065696]
	Learning Rate: 0.00656959
	LOSS [training: 0.5995908031346568 | validation: 0.5150534908138953]
	TIME [epoch: 8.55 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7514379706026497		[learning rate: 0.0065541]
	Learning Rate: 0.0065541
	LOSS [training: 0.7514379706026497 | validation: 0.4711748000299274]
	TIME [epoch: 8.53 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6666695529834581		[learning rate: 0.0065386]
	Learning Rate: 0.00653864
	LOSS [training: 0.6666695529834581 | validation: 0.6834398600047416]
	TIME [epoch: 8.53 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5523412910525828		[learning rate: 0.0065232]
	Learning Rate: 0.00652321
	LOSS [training: 0.5523412910525828 | validation: 0.6292135433233984]
	TIME [epoch: 8.53 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6019599184608845		[learning rate: 0.0065078]
	Learning Rate: 0.00650783
	LOSS [training: 0.6019599184608845 | validation: 0.3880528910530535]
	TIME [epoch: 8.55 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5435574274370318		[learning rate: 0.0064925]
	Learning Rate: 0.00649247
	LOSS [training: 0.5435574274370318 | validation: 0.547685217462544]
	TIME [epoch: 8.53 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6546083056672056		[learning rate: 0.0064772]
	Learning Rate: 0.00647716
	LOSS [training: 0.6546083056672056 | validation: 0.6691407977519724]
	TIME [epoch: 8.53 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6265640493677439		[learning rate: 0.0064619]
	Learning Rate: 0.00646188
	LOSS [training: 0.6265640493677439 | validation: 0.4023911223748145]
	TIME [epoch: 8.53 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5998967748937379		[learning rate: 0.0064466]
	Learning Rate: 0.00644664
	LOSS [training: 0.5998967748937379 | validation: 0.4911268611112324]
	TIME [epoch: 8.54 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5850286667302813		[learning rate: 0.0064314]
	Learning Rate: 0.00643143
	LOSS [training: 0.5850286667302813 | validation: 0.46367972907044586]
	TIME [epoch: 8.52 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6386057274836741		[learning rate: 0.0064163]
	Learning Rate: 0.00641626
	LOSS [training: 0.6386057274836741 | validation: 0.6303004768358672]
	TIME [epoch: 8.52 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5914990335185015		[learning rate: 0.0064011]
	Learning Rate: 0.00640113
	LOSS [training: 0.5914990335185015 | validation: 0.6387715339507718]
	TIME [epoch: 8.54 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7216621974370613		[learning rate: 0.006386]
	Learning Rate: 0.00638603
	LOSS [training: 0.7216621974370613 | validation: 0.3576743057368591]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_240.pth
	Model improved!!!
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5718812071386109		[learning rate: 0.006371]
	Learning Rate: 0.00637096
	LOSS [training: 0.5718812071386109 | validation: 0.9358415402459607]
	TIME [epoch: 8.53 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.66784955255469		[learning rate: 0.0063559]
	Learning Rate: 0.00635594
	LOSS [training: 0.66784955255469 | validation: 0.5942349550628427]
	TIME [epoch: 8.52 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.584281561705778		[learning rate: 0.0063409]
	Learning Rate: 0.00634094
	LOSS [training: 0.584281561705778 | validation: 0.6077010052660131]
	TIME [epoch: 8.54 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7784674558680276		[learning rate: 0.006326]
	Learning Rate: 0.00632599
	LOSS [training: 0.7784674558680276 | validation: 0.6365871489384036]
	TIME [epoch: 8.53 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6738205973077226		[learning rate: 0.0063111]
	Learning Rate: 0.00631106
	LOSS [training: 0.6738205973077226 | validation: 0.3048939530119089]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6177025739346474		[learning rate: 0.0062962]
	Learning Rate: 0.00629618
	LOSS [training: 0.6177025739346474 | validation: 0.6403300759098627]
	TIME [epoch: 8.53 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4980913308992683		[learning rate: 0.0062813]
	Learning Rate: 0.00628133
	LOSS [training: 0.4980913308992683 | validation: 0.42868974128767]
	TIME [epoch: 8.55 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6304715774726517		[learning rate: 0.0062665]
	Learning Rate: 0.00626651
	LOSS [training: 0.6304715774726517 | validation: 0.4121222900437691]
	TIME [epoch: 8.53 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5603543564804797		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.5603543564804797 | validation: 0.41317656263611724]
	TIME [epoch: 8.52 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6343908139633593		[learning rate: 0.006237]
	Learning Rate: 0.00623698
	LOSS [training: 0.6343908139633593 | validation: 0.6278416099157933]
	TIME [epoch: 8.52 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5550212172643608		[learning rate: 0.0062223]
	Learning Rate: 0.00622227
	LOSS [training: 0.5550212172643608 | validation: 0.767231499809082]
	TIME [epoch: 8.55 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5638394459324838		[learning rate: 0.0062076]
	Learning Rate: 0.00620759
	LOSS [training: 0.5638394459324838 | validation: 0.6652389726466631]
	TIME [epoch: 8.53 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48778208713537563		[learning rate: 0.0061929]
	Learning Rate: 0.00619295
	LOSS [training: 0.48778208713537563 | validation: 0.5970421528927354]
	TIME [epoch: 8.52 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4753761348761647		[learning rate: 0.0061783]
	Learning Rate: 0.00617834
	LOSS [training: 0.4753761348761647 | validation: 0.42312312132351326]
	TIME [epoch: 8.52 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6936109807841015		[learning rate: 0.0061638]
	Learning Rate: 0.00616377
	LOSS [training: 0.6936109807841015 | validation: 0.7289052960402005]
	TIME [epoch: 8.56 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44969228897083147		[learning rate: 0.0061492]
	Learning Rate: 0.00614923
	LOSS [training: 0.44969228897083147 | validation: 0.474605058568183]
	TIME [epoch: 8.52 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46651127575115964		[learning rate: 0.0061347]
	Learning Rate: 0.00613472
	LOSS [training: 0.46651127575115964 | validation: 0.5213276568261414]
	TIME [epoch: 8.52 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6156935827316062		[learning rate: 0.0061203]
	Learning Rate: 0.00612025
	LOSS [training: 0.6156935827316062 | validation: 0.36033493960870167]
	TIME [epoch: 8.52 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6903447518549172		[learning rate: 0.0061058]
	Learning Rate: 0.00610581
	LOSS [training: 0.6903447518549172 | validation: 0.8648209021880162]
	TIME [epoch: 8.55 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5451473603749645		[learning rate: 0.0060914]
	Learning Rate: 0.00609141
	LOSS [training: 0.5451473603749645 | validation: 0.5751422757376046]
	TIME [epoch: 8.52 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5376797334077741		[learning rate: 0.006077]
	Learning Rate: 0.00607704
	LOSS [training: 0.5376797334077741 | validation: 0.3828098174810547]
	TIME [epoch: 8.53 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42313606204276855		[learning rate: 0.0060627]
	Learning Rate: 0.00606271
	LOSS [training: 0.42313606204276855 | validation: 0.5598274184859915]
	TIME [epoch: 8.53 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6135860441767533		[learning rate: 0.0060484]
	Learning Rate: 0.00604841
	LOSS [training: 0.6135860441767533 | validation: 0.4624797008201458]
	TIME [epoch: 8.55 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5463166747477537		[learning rate: 0.0060341]
	Learning Rate: 0.00603414
	LOSS [training: 0.5463166747477537 | validation: 0.5883385360737666]
	TIME [epoch: 8.53 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8844308545874		[learning rate: 0.0060199]
	Learning Rate: 0.00601991
	LOSS [training: 0.8844308545874 | validation: 0.4602919943558922]
	TIME [epoch: 8.52 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6353601578139376		[learning rate: 0.0060057]
	Learning Rate: 0.00600571
	LOSS [training: 0.6353601578139376 | validation: 0.42483983377973555]
	TIME [epoch: 8.53 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5546386510652789		[learning rate: 0.0059915]
	Learning Rate: 0.00599154
	LOSS [training: 0.5546386510652789 | validation: 0.37582380893726947]
	TIME [epoch: 8.54 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5281929385752829		[learning rate: 0.0059774]
	Learning Rate: 0.00597741
	LOSS [training: 0.5281929385752829 | validation: 0.4377086286527818]
	TIME [epoch: 8.52 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5564755377488144		[learning rate: 0.0059633]
	Learning Rate: 0.00596331
	LOSS [training: 0.5564755377488144 | validation: 0.5134756849527439]
	TIME [epoch: 8.52 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5362493310077041		[learning rate: 0.0059492]
	Learning Rate: 0.00594924
	LOSS [training: 0.5362493310077041 | validation: 0.5614878656023579]
	TIME [epoch: 8.54 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5192878449048051		[learning rate: 0.0059352]
	Learning Rate: 0.00593521
	LOSS [training: 0.5192878449048051 | validation: 0.41169625484815087]
	TIME [epoch: 8.53 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5305413910763968		[learning rate: 0.0059212]
	Learning Rate: 0.00592121
	LOSS [training: 0.5305413910763968 | validation: 0.8313035548666705]
	TIME [epoch: 8.52 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5660879843142271		[learning rate: 0.0059072]
	Learning Rate: 0.00590724
	LOSS [training: 0.5660879843142271 | validation: 0.376970792643442]
	TIME [epoch: 8.52 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5759923469580481		[learning rate: 0.0058933]
	Learning Rate: 0.00589331
	LOSS [training: 0.5759923469580481 | validation: 0.46460405206579236]
	TIME [epoch: 8.54 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4794637005173602		[learning rate: 0.0058794]
	Learning Rate: 0.0058794
	LOSS [training: 0.4794637005173602 | validation: 0.3164711282510284]
	TIME [epoch: 8.53 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5596979865818819		[learning rate: 0.0058655]
	Learning Rate: 0.00586554
	LOSS [training: 0.5596979865818819 | validation: 0.4756597317177563]
	TIME [epoch: 8.52 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5859897896104874		[learning rate: 0.0058517]
	Learning Rate: 0.0058517
	LOSS [training: 0.5859897896104874 | validation: 1.2265106029672908]
	TIME [epoch: 8.52 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5699236678615247		[learning rate: 0.0058379]
	Learning Rate: 0.0058379
	LOSS [training: 0.5699236678615247 | validation: 0.3632469115484419]
	TIME [epoch: 8.54 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39885836152336546		[learning rate: 0.0058241]
	Learning Rate: 0.00582413
	LOSS [training: 0.39885836152336546 | validation: 0.3628464151927191]
	TIME [epoch: 8.52 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5157365762929567		[learning rate: 0.0058104]
	Learning Rate: 0.00581039
	LOSS [training: 0.5157365762929567 | validation: 0.5412204638643919]
	TIME [epoch: 8.52 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43122013900266687		[learning rate: 0.0057967]
	Learning Rate: 0.00579668
	LOSS [training: 0.43122013900266687 | validation: 0.3873681447176257]
	TIME [epoch: 8.51 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47999057903390574		[learning rate: 0.005783]
	Learning Rate: 0.00578301
	LOSS [training: 0.47999057903390574 | validation: 0.5964409770154908]
	TIME [epoch: 8.55 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.549594877549745		[learning rate: 0.0057694]
	Learning Rate: 0.00576937
	LOSS [training: 0.549594877549745 | validation: 0.5676274532832593]
	TIME [epoch: 8.52 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4554069048290015		[learning rate: 0.0057558]
	Learning Rate: 0.00575576
	LOSS [training: 0.4554069048290015 | validation: 0.564228292385583]
	TIME [epoch: 8.52 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4668315090435424		[learning rate: 0.0057422]
	Learning Rate: 0.00574218
	LOSS [training: 0.4668315090435424 | validation: 0.5127963528393489]
	TIME [epoch: 8.52 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5487408811642849		[learning rate: 0.0057286]
	Learning Rate: 0.00572864
	LOSS [training: 0.5487408811642849 | validation: 0.7875099600771074]
	TIME [epoch: 8.54 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5872386112094257		[learning rate: 0.0057151]
	Learning Rate: 0.00571512
	LOSS [training: 0.5872386112094257 | validation: 0.47180389274071743]
	TIME [epoch: 8.53 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5392275436552836		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.5392275436552836 | validation: 1.0224814969514928]
	TIME [epoch: 8.52 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7353502216404928		[learning rate: 0.0056882]
	Learning Rate: 0.00568819
	LOSS [training: 0.7353502216404928 | validation: 0.6800249002744438]
	TIME [epoch: 8.52 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5009229095116188		[learning rate: 0.0056748]
	Learning Rate: 0.00567478
	LOSS [training: 0.5009229095116188 | validation: 1.210285085988583]
	TIME [epoch: 8.55 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6402214358359772		[learning rate: 0.0056614]
	Learning Rate: 0.00566139
	LOSS [training: 0.6402214358359772 | validation: 0.41142176344291426]
	TIME [epoch: 8.52 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44950887358249264		[learning rate: 0.005648]
	Learning Rate: 0.00564804
	LOSS [training: 0.44950887358249264 | validation: 0.40143970075180235]
	TIME [epoch: 8.52 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5977076928246692		[learning rate: 0.0056347]
	Learning Rate: 0.00563471
	LOSS [training: 0.5977076928246692 | validation: 0.5398390613280146]
	TIME [epoch: 8.52 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5949332162187014		[learning rate: 0.0056214]
	Learning Rate: 0.00562142
	LOSS [training: 0.5949332162187014 | validation: 0.6748145617214025]
	TIME [epoch: 8.54 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6074330192123465		[learning rate: 0.0056082]
	Learning Rate: 0.00560816
	LOSS [training: 0.6074330192123465 | validation: 0.46019259179084376]
	TIME [epoch: 8.52 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6153170484603677		[learning rate: 0.0055949]
	Learning Rate: 0.00559493
	LOSS [training: 0.6153170484603677 | validation: 0.39047305389101616]
	TIME [epoch: 8.52 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4879630095644484		[learning rate: 0.0055817]
	Learning Rate: 0.00558173
	LOSS [training: 0.4879630095644484 | validation: 0.33896494699734825]
	TIME [epoch: 8.52 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4876075550636639		[learning rate: 0.0055686]
	Learning Rate: 0.00556857
	LOSS [training: 0.4876075550636639 | validation: 0.41589138637624923]
	TIME [epoch: 8.54 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6254118750864974		[learning rate: 0.0055554]
	Learning Rate: 0.00555543
	LOSS [training: 0.6254118750864974 | validation: 0.6146423635635558]
	TIME [epoch: 8.52 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5648247721245784		[learning rate: 0.0055423]
	Learning Rate: 0.00554233
	LOSS [training: 0.5648247721245784 | validation: 0.3247742233988299]
	TIME [epoch: 8.52 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5388468020557953		[learning rate: 0.0055293]
	Learning Rate: 0.00552926
	LOSS [training: 0.5388468020557953 | validation: 0.4837140862200138]
	TIME [epoch: 8.53 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5195002151564796		[learning rate: 0.0055162]
	Learning Rate: 0.00551621
	LOSS [training: 0.5195002151564796 | validation: 0.327386557989106]
	TIME [epoch: 8.54 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5524525482008186		[learning rate: 0.0055032]
	Learning Rate: 0.0055032
	LOSS [training: 0.5524525482008186 | validation: 0.33622236351065504]
	TIME [epoch: 8.53 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.436642360685886		[learning rate: 0.0054902]
	Learning Rate: 0.00549022
	LOSS [training: 0.436642360685886 | validation: 0.44120089679238156]
	TIME [epoch: 8.52 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5716916814570007		[learning rate: 0.0054773]
	Learning Rate: 0.00547727
	LOSS [training: 0.5716916814570007 | validation: 0.3960770772076477]
	TIME [epoch: 8.54 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45991240441856274		[learning rate: 0.0054643]
	Learning Rate: 0.00546435
	LOSS [training: 0.45991240441856274 | validation: 0.47349461572733254]
	TIME [epoch: 8.53 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41172273955569416		[learning rate: 0.0054515]
	Learning Rate: 0.00545146
	LOSS [training: 0.41172273955569416 | validation: 0.5098467594857625]
	TIME [epoch: 8.52 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4868275512797576		[learning rate: 0.0054386]
	Learning Rate: 0.0054386
	LOSS [training: 0.4868275512797576 | validation: 0.8304510967021193]
	TIME [epoch: 8.52 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48608848402621724		[learning rate: 0.0054258]
	Learning Rate: 0.00542577
	LOSS [training: 0.48608848402621724 | validation: 0.502662993849109]
	TIME [epoch: 8.54 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5239249577938173		[learning rate: 0.005413]
	Learning Rate: 0.00541297
	LOSS [training: 0.5239249577938173 | validation: 0.39843068156898803]
	TIME [epoch: 8.53 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5279733256676061		[learning rate: 0.0054002]
	Learning Rate: 0.00540021
	LOSS [training: 0.5279733256676061 | validation: 0.349077961661458]
	TIME [epoch: 8.52 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4377412157585934		[learning rate: 0.0053875]
	Learning Rate: 0.00538747
	LOSS [training: 0.4377412157585934 | validation: 0.5718624997982042]
	TIME [epoch: 8.52 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5320389691622082		[learning rate: 0.0053748]
	Learning Rate: 0.00537476
	LOSS [training: 0.5320389691622082 | validation: 0.6840217754833303]
	TIME [epoch: 8.54 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4445170011103864		[learning rate: 0.0053621]
	Learning Rate: 0.00536208
	LOSS [training: 0.4445170011103864 | validation: 0.3341974166398093]
	TIME [epoch: 8.52 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.404115944631153		[learning rate: 0.0053494]
	Learning Rate: 0.00534943
	LOSS [training: 0.404115944631153 | validation: 0.502257541727305]
	TIME [epoch: 8.52 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4927793287943098		[learning rate: 0.0053368]
	Learning Rate: 0.00533681
	LOSS [training: 0.4927793287943098 | validation: 0.6585998691155336]
	TIME [epoch: 8.53 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7894154332846319		[learning rate: 0.0053242]
	Learning Rate: 0.00532423
	LOSS [training: 0.7894154332846319 | validation: 0.5399513050749551]
	TIME [epoch: 8.55 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5386214692609661		[learning rate: 0.0053117]
	Learning Rate: 0.00531167
	LOSS [training: 0.5386214692609661 | validation: 0.40211571258770407]
	TIME [epoch: 8.53 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4663836660810876		[learning rate: 0.0052991]
	Learning Rate: 0.00529914
	LOSS [training: 0.4663836660810876 | validation: 0.9574432062498678]
	TIME [epoch: 8.53 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4894012436861919		[learning rate: 0.0052866]
	Learning Rate: 0.00528664
	LOSS [training: 0.4894012436861919 | validation: 0.22974561965238993]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_320.pth
	Model improved!!!
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.485147108974714		[learning rate: 0.0052742]
	Learning Rate: 0.00527417
	LOSS [training: 0.485147108974714 | validation: 0.33004530207962984]
	TIME [epoch: 8.54 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5096658502318646		[learning rate: 0.0052617]
	Learning Rate: 0.00526173
	LOSS [training: 0.5096658502318646 | validation: 0.732132142196747]
	TIME [epoch: 8.51 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5050644694696258		[learning rate: 0.0052493]
	Learning Rate: 0.00524931
	LOSS [training: 0.5050644694696258 | validation: 0.38470468258546076]
	TIME [epoch: 8.51 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4359534936096856		[learning rate: 0.0052369]
	Learning Rate: 0.00523693
	LOSS [training: 0.4359534936096856 | validation: 0.5222043434348652]
	TIME [epoch: 8.52 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4283480820989891		[learning rate: 0.0052246]
	Learning Rate: 0.00522458
	LOSS [training: 0.4283480820989891 | validation: 0.30272390290826034]
	TIME [epoch: 8.54 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4508572126385285		[learning rate: 0.0052123]
	Learning Rate: 0.00521225
	LOSS [training: 0.4508572126385285 | validation: 0.4276117908468148]
	TIME [epoch: 8.52 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46899000820727965		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.46899000820727965 | validation: 0.2767379640604174]
	TIME [epoch: 8.51 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42860441509065783		[learning rate: 0.0051877]
	Learning Rate: 0.00518769
	LOSS [training: 0.42860441509065783 | validation: 0.4391750519949592]
	TIME [epoch: 8.51 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48984453584557264		[learning rate: 0.0051755]
	Learning Rate: 0.00517546
	LOSS [training: 0.48984453584557264 | validation: 0.527928727272385]
	TIME [epoch: 8.54 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4486375373461957		[learning rate: 0.0051632]
	Learning Rate: 0.00516325
	LOSS [training: 0.4486375373461957 | validation: 0.5356766245399878]
	TIME [epoch: 8.51 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5476531204304761		[learning rate: 0.0051511]
	Learning Rate: 0.00515107
	LOSS [training: 0.5476531204304761 | validation: 0.5086951907992758]
	TIME [epoch: 8.51 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48856485878077827		[learning rate: 0.0051389]
	Learning Rate: 0.00513892
	LOSS [training: 0.48856485878077827 | validation: 0.4747638536215866]
	TIME [epoch: 8.52 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.557349318004478		[learning rate: 0.0051268]
	Learning Rate: 0.0051268
	LOSS [training: 0.557349318004478 | validation: 0.4932270493778249]
	TIME [epoch: 8.53 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4993655683831612		[learning rate: 0.0051147]
	Learning Rate: 0.0051147
	LOSS [training: 0.4993655683831612 | validation: 0.6911121121629398]
	TIME [epoch: 8.51 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5548129234175244		[learning rate: 0.0051026]
	Learning Rate: 0.00510264
	LOSS [training: 0.5548129234175244 | validation: 0.2962253357937893]
	TIME [epoch: 8.51 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44395683818068327		[learning rate: 0.0050906]
	Learning Rate: 0.0050906
	LOSS [training: 0.44395683818068327 | validation: 0.2532218906938622]
	TIME [epoch: 8.53 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43566248767197235		[learning rate: 0.0050786]
	Learning Rate: 0.00507859
	LOSS [training: 0.43566248767197235 | validation: 0.47053732990673053]
	TIME [epoch: 8.53 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5055814605097851		[learning rate: 0.0050666]
	Learning Rate: 0.00506661
	LOSS [training: 0.5055814605097851 | validation: 0.33015143424939286]
	TIME [epoch: 8.51 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5386108364610674		[learning rate: 0.0050547]
	Learning Rate: 0.00505466
	LOSS [training: 0.5386108364610674 | validation: 0.3859181541932483]
	TIME [epoch: 8.51 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4238940337724757		[learning rate: 0.0050427]
	Learning Rate: 0.00504274
	LOSS [training: 0.4238940337724757 | validation: 0.3699797387431541]
	TIME [epoch: 8.53 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5027048745489129		[learning rate: 0.0050308]
	Learning Rate: 0.00503085
	LOSS [training: 0.5027048745489129 | validation: 0.6250391020300324]
	TIME [epoch: 8.52 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36753348391445373		[learning rate: 0.005019]
	Learning Rate: 0.00501898
	LOSS [training: 0.36753348391445373 | validation: 0.7932559853208727]
	TIME [epoch: 8.52 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6101476930633047		[learning rate: 0.0050071]
	Learning Rate: 0.00500714
	LOSS [training: 0.6101476930633047 | validation: 0.3245795541777607]
	TIME [epoch: 8.51 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5747017326716104		[learning rate: 0.0049953]
	Learning Rate: 0.00499533
	LOSS [training: 0.5747017326716104 | validation: 0.4962888280598148]
	TIME [epoch: 8.54 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4307725492750579		[learning rate: 0.0049835]
	Learning Rate: 0.00498355
	LOSS [training: 0.4307725492750579 | validation: 0.39871976002258674]
	TIME [epoch: 8.52 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34008235846862633		[learning rate: 0.0049718]
	Learning Rate: 0.00497179
	LOSS [training: 0.34008235846862633 | validation: 0.304744187402196]
	TIME [epoch: 8.51 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4139489680880257		[learning rate: 0.0049601]
	Learning Rate: 0.00496006
	LOSS [training: 0.4139489680880257 | validation: 0.35358155718973006]
	TIME [epoch: 8.51 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45248349428593154		[learning rate: 0.0049484]
	Learning Rate: 0.00494836
	LOSS [training: 0.45248349428593154 | validation: 0.5087018939008581]
	TIME [epoch: 8.54 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42233232790982866		[learning rate: 0.0049367]
	Learning Rate: 0.00493669
	LOSS [training: 0.42233232790982866 | validation: 0.3128839482920438]
	TIME [epoch: 8.52 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4597768700271934		[learning rate: 0.004925]
	Learning Rate: 0.00492505
	LOSS [training: 0.4597768700271934 | validation: 0.30785863754642917]
	TIME [epoch: 8.52 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4150279067563149		[learning rate: 0.0049134]
	Learning Rate: 0.00491343
	LOSS [training: 0.4150279067563149 | validation: 0.46009360759388096]
	TIME [epoch: 8.52 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4309136370912362		[learning rate: 0.0049018]
	Learning Rate: 0.00490184
	LOSS [training: 0.4309136370912362 | validation: 0.6262457893976463]
	TIME [epoch: 8.54 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48195429194077216		[learning rate: 0.0048903]
	Learning Rate: 0.00489028
	LOSS [training: 0.48195429194077216 | validation: 0.30634050097530763]
	TIME [epoch: 8.52 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4825036443530772		[learning rate: 0.0048787]
	Learning Rate: 0.00487874
	LOSS [training: 0.4825036443530772 | validation: 0.4317991771770101]
	TIME [epoch: 8.52 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34810788685981464		[learning rate: 0.0048672]
	Learning Rate: 0.00486723
	LOSS [training: 0.34810788685981464 | validation: 0.48361639383152655]
	TIME [epoch: 8.52 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4510795673035746		[learning rate: 0.0048558]
	Learning Rate: 0.00485575
	LOSS [training: 0.4510795673035746 | validation: 0.23145947916930398]
	TIME [epoch: 8.55 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38806835178047316		[learning rate: 0.0048443]
	Learning Rate: 0.0048443
	LOSS [training: 0.38806835178047316 | validation: 0.43124577726737356]
	TIME [epoch: 8.52 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43353228648633235		[learning rate: 0.0048329]
	Learning Rate: 0.00483287
	LOSS [training: 0.43353228648633235 | validation: 0.5253980934446273]
	TIME [epoch: 8.52 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4036203631000209		[learning rate: 0.0048215]
	Learning Rate: 0.00482147
	LOSS [training: 0.4036203631000209 | validation: 0.33045531290381086]
	TIME [epoch: 8.52 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35494379756937977		[learning rate: 0.0048101]
	Learning Rate: 0.0048101
	LOSS [training: 0.35494379756937977 | validation: 0.7064847597034197]
	TIME [epoch: 8.55 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5021737365705262		[learning rate: 0.0047988]
	Learning Rate: 0.00479875
	LOSS [training: 0.5021737365705262 | validation: 0.4765268300536015]
	TIME [epoch: 8.52 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6583950228860342		[learning rate: 0.0047874]
	Learning Rate: 0.00478743
	LOSS [training: 0.6583950228860342 | validation: 0.9964736766136985]
	TIME [epoch: 8.52 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5688873999050411		[learning rate: 0.0047761]
	Learning Rate: 0.00477614
	LOSS [training: 0.5688873999050411 | validation: 1.0323466183644614]
	TIME [epoch: 8.52 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.539880733823152		[learning rate: 0.0047649]
	Learning Rate: 0.00476487
	LOSS [training: 0.539880733823152 | validation: 0.35632699890982883]
	TIME [epoch: 8.54 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45144262593212164		[learning rate: 0.0047536]
	Learning Rate: 0.00475363
	LOSS [training: 0.45144262593212164 | validation: 0.4917181576622517]
	TIME [epoch: 8.52 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39083837965443624		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.39083837965443624 | validation: 0.42424892690314253]
	TIME [epoch: 8.52 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4681210754490393		[learning rate: 0.0047312]
	Learning Rate: 0.00473123
	LOSS [training: 0.4681210754490393 | validation: 0.36648785609315093]
	TIME [epoch: 8.53 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4641578177249972		[learning rate: 0.0047201]
	Learning Rate: 0.00472007
	LOSS [training: 0.4641578177249972 | validation: 1.0263978233721354]
	TIME [epoch: 8.54 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6842373325222988		[learning rate: 0.0047089]
	Learning Rate: 0.00470894
	LOSS [training: 0.6842373325222988 | validation: 0.46061138751074915]
	TIME [epoch: 8.52 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48972228368413695		[learning rate: 0.0046978]
	Learning Rate: 0.00469783
	LOSS [training: 0.48972228368413695 | validation: 0.5356277259775183]
	TIME [epoch: 8.52 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3807908390503752		[learning rate: 0.0046868]
	Learning Rate: 0.00468675
	LOSS [training: 0.3807908390503752 | validation: 0.27945133722131593]
	TIME [epoch: 8.54 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5188080824634096		[learning rate: 0.0046757]
	Learning Rate: 0.00467569
	LOSS [training: 0.5188080824634096 | validation: 0.9311860959457644]
	TIME [epoch: 8.53 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46148593753967165		[learning rate: 0.0046647]
	Learning Rate: 0.00466467
	LOSS [training: 0.46148593753967165 | validation: 0.33064815059482233]
	TIME [epoch: 8.52 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4931997834345136		[learning rate: 0.0046537]
	Learning Rate: 0.00465366
	LOSS [training: 0.4931997834345136 | validation: 0.3824240148003526]
	TIME [epoch: 8.52 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29535478147246513		[learning rate: 0.0046427]
	Learning Rate: 0.00464268
	LOSS [training: 0.29535478147246513 | validation: 0.48069374934081155]
	TIME [epoch: 8.53 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.411639782232593		[learning rate: 0.0046317]
	Learning Rate: 0.00463173
	LOSS [training: 0.411639782232593 | validation: 0.663170587018181]
	TIME [epoch: 8.53 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36024274595617073		[learning rate: 0.0046208]
	Learning Rate: 0.00462081
	LOSS [training: 0.36024274595617073 | validation: 0.6613957483462323]
	TIME [epoch: 8.52 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4118429776289031		[learning rate: 0.0046099]
	Learning Rate: 0.00460991
	LOSS [training: 0.4118429776289031 | validation: 0.5778927834951038]
	TIME [epoch: 8.51 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5402514682235383		[learning rate: 0.004599]
	Learning Rate: 0.00459903
	LOSS [training: 0.5402514682235383 | validation: 0.24341995507987207]
	TIME [epoch: 8.54 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3963603932187195		[learning rate: 0.0045882]
	Learning Rate: 0.00458819
	LOSS [training: 0.3963603932187195 | validation: 0.5328751797542961]
	TIME [epoch: 8.52 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4269987964915313		[learning rate: 0.0045774]
	Learning Rate: 0.00457736
	LOSS [training: 0.4269987964915313 | validation: 0.38542687420893307]
	TIME [epoch: 8.52 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5519584200854558		[learning rate: 0.0045666]
	Learning Rate: 0.00456657
	LOSS [training: 0.5519584200854558 | validation: 0.6967560406284736]
	TIME [epoch: 8.52 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6350159289223339		[learning rate: 0.0045558]
	Learning Rate: 0.00455579
	LOSS [training: 0.6350159289223339 | validation: 0.5200982325201394]
	TIME [epoch: 8.55 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6033850074011695		[learning rate: 0.004545]
	Learning Rate: 0.00454505
	LOSS [training: 0.6033850074011695 | validation: 0.567523362101626]
	TIME [epoch: 8.53 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5464458990851304		[learning rate: 0.0045343]
	Learning Rate: 0.00453433
	LOSS [training: 0.5464458990851304 | validation: 0.40375785458300906]
	TIME [epoch: 8.52 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4567435914549288		[learning rate: 0.0045236]
	Learning Rate: 0.00452363
	LOSS [training: 0.4567435914549288 | validation: 0.4943893359911856]
	TIME [epoch: 8.52 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4863571828476848		[learning rate: 0.004513]
	Learning Rate: 0.00451296
	LOSS [training: 0.4863571828476848 | validation: 0.3130695102458838]
	TIME [epoch: 8.55 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5191917887724877		[learning rate: 0.0045023]
	Learning Rate: 0.00450232
	LOSS [training: 0.5191917887724877 | validation: 0.2777092981916124]
	TIME [epoch: 8.52 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36224007809690667		[learning rate: 0.0044917]
	Learning Rate: 0.00449169
	LOSS [training: 0.36224007809690667 | validation: 0.3069165858805888]
	TIME [epoch: 8.52 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35627078273047713		[learning rate: 0.0044811]
	Learning Rate: 0.0044811
	LOSS [training: 0.35627078273047713 | validation: 0.4663373101804041]
	TIME [epoch: 8.52 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44979824675677094		[learning rate: 0.0044705]
	Learning Rate: 0.00447053
	LOSS [training: 0.44979824675677094 | validation: 0.4182954717382884]
	TIME [epoch: 8.55 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4614594275956859		[learning rate: 0.00446]
	Learning Rate: 0.00445998
	LOSS [training: 0.4614594275956859 | validation: 0.2717386083326186]
	TIME [epoch: 8.52 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.349890753798359		[learning rate: 0.0044495]
	Learning Rate: 0.00444946
	LOSS [training: 0.349890753798359 | validation: 0.24356852416817693]
	TIME [epoch: 8.52 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.440945056135292		[learning rate: 0.004439]
	Learning Rate: 0.00443897
	LOSS [training: 0.440945056135292 | validation: 0.392498567749745]
	TIME [epoch: 8.52 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4242869585633821		[learning rate: 0.0044285]
	Learning Rate: 0.0044285
	LOSS [training: 0.4242869585633821 | validation: 0.47368087850164664]
	TIME [epoch: 8.55 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4520335737829647		[learning rate: 0.0044181]
	Learning Rate: 0.00441805
	LOSS [training: 0.4520335737829647 | validation: 0.3390000618585912]
	TIME [epoch: 8.52 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3442615630555169		[learning rate: 0.0044076]
	Learning Rate: 0.00440763
	LOSS [training: 0.3442615630555169 | validation: 0.2831434257427763]
	TIME [epoch: 8.53 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40486468977496315		[learning rate: 0.0043972]
	Learning Rate: 0.00439723
	LOSS [training: 0.40486468977496315 | validation: 0.2805918374934368]
	TIME [epoch: 8.53 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4676967662481797		[learning rate: 0.0043869]
	Learning Rate: 0.00438686
	LOSS [training: 0.4676967662481797 | validation: 0.5420797075384955]
	TIME [epoch: 8.54 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48894257643994665		[learning rate: 0.0043765]
	Learning Rate: 0.00437651
	LOSS [training: 0.48894257643994665 | validation: 0.4239918436577076]
	TIME [epoch: 8.53 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3672991873388199		[learning rate: 0.0043662]
	Learning Rate: 0.00436619
	LOSS [training: 0.3672991873388199 | validation: 0.2669946500419424]
	TIME [epoch: 8.52 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34358181002370614		[learning rate: 0.0043559]
	Learning Rate: 0.00435589
	LOSS [training: 0.34358181002370614 | validation: 0.23955804491779598]
	TIME [epoch: 8.53 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44884191198015866		[learning rate: 0.0043456]
	Learning Rate: 0.00434561
	LOSS [training: 0.44884191198015866 | validation: 0.298830355763032]
	TIME [epoch: 8.54 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.416297898337841		[learning rate: 0.0043354]
	Learning Rate: 0.00433536
	LOSS [training: 0.416297898337841 | validation: 0.4845118591410475]
	TIME [epoch: 8.52 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4273655765227328		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.4273655765227328 | validation: 0.2198086404655234]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3072329697160649		[learning rate: 0.0043149]
	Learning Rate: 0.00431494
	LOSS [training: 0.3072329697160649 | validation: 0.461911940448962]
	TIME [epoch: 8.54 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41333178999852505		[learning rate: 0.0043048]
	Learning Rate: 0.00430476
	LOSS [training: 0.41333178999852505 | validation: 0.43764943584511706]
	TIME [epoch: 8.53 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3496324552635355		[learning rate: 0.0042946]
	Learning Rate: 0.0042946
	LOSS [training: 0.3496324552635355 | validation: 0.3731743446122594]
	TIME [epoch: 8.51 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4490057570770304		[learning rate: 0.0042845]
	Learning Rate: 0.00428447
	LOSS [training: 0.4490057570770304 | validation: 0.40634995056154033]
	TIME [epoch: 8.52 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32101826644034315		[learning rate: 0.0042744]
	Learning Rate: 0.00427437
	LOSS [training: 0.32101826644034315 | validation: 0.34714417408022874]
	TIME [epoch: 8.54 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37226829916447385		[learning rate: 0.0042643]
	Learning Rate: 0.00426428
	LOSS [training: 0.37226829916447385 | validation: 0.3109496302391449]
	TIME [epoch: 8.52 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31151672993101476		[learning rate: 0.0042542]
	Learning Rate: 0.00425423
	LOSS [training: 0.31151672993101476 | validation: 0.520781047268899]
	TIME [epoch: 8.52 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46205290623730166		[learning rate: 0.0042442]
	Learning Rate: 0.00424419
	LOSS [training: 0.46205290623730166 | validation: 0.31312829347252513]
	TIME [epoch: 8.52 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4369423901729122		[learning rate: 0.0042342]
	Learning Rate: 0.00423418
	LOSS [training: 0.4369423901729122 | validation: 0.41113614851870195]
	TIME [epoch: 8.54 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4008757306813845		[learning rate: 0.0042242]
	Learning Rate: 0.00422419
	LOSS [training: 0.4008757306813845 | validation: 0.5720579225133486]
	TIME [epoch: 8.52 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37818113739422254		[learning rate: 0.0042142]
	Learning Rate: 0.00421423
	LOSS [training: 0.37818113739422254 | validation: 0.40466153336081967]
	TIME [epoch: 8.51 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41879075431255347		[learning rate: 0.0042043]
	Learning Rate: 0.00420429
	LOSS [training: 0.41879075431255347 | validation: 0.1921589161623274]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_417.pth
	Model improved!!!
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30837406933201056		[learning rate: 0.0041944]
	Learning Rate: 0.00419437
	LOSS [training: 0.30837406933201056 | validation: 0.20800532560440782]
	TIME [epoch: 8.55 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4317447002229396		[learning rate: 0.0041845]
	Learning Rate: 0.00418448
	LOSS [training: 0.4317447002229396 | validation: 0.2620567942982523]
	TIME [epoch: 8.52 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.337464137211551		[learning rate: 0.0041746]
	Learning Rate: 0.0041746
	LOSS [training: 0.337464137211551 | validation: 0.36217257560636473]
	TIME [epoch: 8.51 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3571185871362066		[learning rate: 0.0041648]
	Learning Rate: 0.00416476
	LOSS [training: 0.3571185871362066 | validation: 0.41126136862011936]
	TIME [epoch: 8.51 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39632683904370786		[learning rate: 0.0041549]
	Learning Rate: 0.00415493
	LOSS [training: 0.39632683904370786 | validation: 0.3944609479227256]
	TIME [epoch: 8.54 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35323834782474756		[learning rate: 0.0041451]
	Learning Rate: 0.00414513
	LOSS [training: 0.35323834782474756 | validation: 0.2300985935683431]
	TIME [epoch: 8.51 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44677198946910446		[learning rate: 0.0041354]
	Learning Rate: 0.00413535
	LOSS [training: 0.44677198946910446 | validation: 0.3119114364474097]
	TIME [epoch: 8.51 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38813857360094733		[learning rate: 0.0041256]
	Learning Rate: 0.0041256
	LOSS [training: 0.38813857360094733 | validation: 0.3462393069132978]
	TIME [epoch: 8.51 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42126217685594236		[learning rate: 0.0041159]
	Learning Rate: 0.00411587
	LOSS [training: 0.42126217685594236 | validation: 0.29614090252806596]
	TIME [epoch: 8.53 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36812716757996405		[learning rate: 0.0041062]
	Learning Rate: 0.00410616
	LOSS [training: 0.36812716757996405 | validation: 0.5257052474747785]
	TIME [epoch: 8.51 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3705653088006588		[learning rate: 0.0040965]
	Learning Rate: 0.00409647
	LOSS [training: 0.3705653088006588 | validation: 0.2622245734852114]
	TIME [epoch: 8.51 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34884849492989967		[learning rate: 0.0040868]
	Learning Rate: 0.00408681
	LOSS [training: 0.34884849492989967 | validation: 0.21573509594512857]
	TIME [epoch: 8.51 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3580597099263456		[learning rate: 0.0040772]
	Learning Rate: 0.00407717
	LOSS [training: 0.3580597099263456 | validation: 0.4468061368872677]
	TIME [epoch: 8.54 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39821159110104026		[learning rate: 0.0040676]
	Learning Rate: 0.00406755
	LOSS [training: 0.39821159110104026 | validation: 0.2430871566050553]
	TIME [epoch: 8.52 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2744849981677759		[learning rate: 0.004058]
	Learning Rate: 0.00405796
	LOSS [training: 0.2744849981677759 | validation: 0.23750866001943335]
	TIME [epoch: 8.51 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3721745160730191		[learning rate: 0.0040484]
	Learning Rate: 0.00404839
	LOSS [training: 0.3721745160730191 | validation: 0.3439949077368618]
	TIME [epoch: 8.52 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32609333229777226		[learning rate: 0.0040388]
	Learning Rate: 0.00403884
	LOSS [training: 0.32609333229777226 | validation: 0.18160300555565642]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_434.pth
	Model improved!!!
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27445479007970847		[learning rate: 0.0040293]
	Learning Rate: 0.00402931
	LOSS [training: 0.27445479007970847 | validation: 0.1558874994587532]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_435.pth
	Model improved!!!
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2851366727753664		[learning rate: 0.0040198]
	Learning Rate: 0.00401981
	LOSS [training: 0.2851366727753664 | validation: 0.2318157827138388]
	TIME [epoch: 8.52 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30528483062511363		[learning rate: 0.0040103]
	Learning Rate: 0.00401032
	LOSS [training: 0.30528483062511363 | validation: 0.24069109621780405]
	TIME [epoch: 8.54 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33951630735885135		[learning rate: 0.0040009]
	Learning Rate: 0.00400086
	LOSS [training: 0.33951630735885135 | validation: 0.5414498033581762]
	TIME [epoch: 8.53 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33786136315200105		[learning rate: 0.0039914]
	Learning Rate: 0.00399143
	LOSS [training: 0.33786136315200105 | validation: 0.27491656036948886]
	TIME [epoch: 8.52 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3586574092115395		[learning rate: 0.003982]
	Learning Rate: 0.00398201
	LOSS [training: 0.3586574092115395 | validation: 0.4278502872878418]
	TIME [epoch: 8.52 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36398986449551174		[learning rate: 0.0039726]
	Learning Rate: 0.00397262
	LOSS [training: 0.36398986449551174 | validation: 0.2270274368117651]
	TIME [epoch: 8.54 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31642483687415923		[learning rate: 0.0039632]
	Learning Rate: 0.00396325
	LOSS [training: 0.31642483687415923 | validation: 0.2898674040489732]
	TIME [epoch: 8.52 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34200149350169606		[learning rate: 0.0039539]
	Learning Rate: 0.0039539
	LOSS [training: 0.34200149350169606 | validation: 0.3965679196274056]
	TIME [epoch: 8.52 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31093881368416587		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.31093881368416587 | validation: 0.36621178477805233]
	TIME [epoch: 8.51 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3135183267697744		[learning rate: 0.0039353]
	Learning Rate: 0.00393527
	LOSS [training: 0.3135183267697744 | validation: 0.23019816493603157]
	TIME [epoch: 8.54 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38799306876330797		[learning rate: 0.003926]
	Learning Rate: 0.00392599
	LOSS [training: 0.38799306876330797 | validation: 0.35396254630513485]
	TIME [epoch: 8.52 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3718011320457094		[learning rate: 0.0039167]
	Learning Rate: 0.00391672
	LOSS [training: 0.3718011320457094 | validation: 0.38899776217643245]
	TIME [epoch: 8.52 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33946067424535614		[learning rate: 0.0039075]
	Learning Rate: 0.00390749
	LOSS [training: 0.33946067424535614 | validation: 0.41196368384593063]
	TIME [epoch: 8.52 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38667345316059104		[learning rate: 0.0038983]
	Learning Rate: 0.00389827
	LOSS [training: 0.38667345316059104 | validation: 0.2512088770473016]
	TIME [epoch: 8.54 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.319112649758819		[learning rate: 0.0038891]
	Learning Rate: 0.00388907
	LOSS [training: 0.319112649758819 | validation: 0.32442618920827976]
	TIME [epoch: 8.52 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37611018037591426		[learning rate: 0.0038799]
	Learning Rate: 0.0038799
	LOSS [training: 0.37611018037591426 | validation: 0.42348895388840424]
	TIME [epoch: 8.52 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.345354075308565		[learning rate: 0.0038707]
	Learning Rate: 0.00387075
	LOSS [training: 0.345354075308565 | validation: 0.38084403994228383]
	TIME [epoch: 8.52 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36209228725929604		[learning rate: 0.0038616]
	Learning Rate: 0.00386162
	LOSS [training: 0.36209228725929604 | validation: 0.39523902276681033]
	TIME [epoch: 8.54 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3082318187112079		[learning rate: 0.0038525]
	Learning Rate: 0.00385251
	LOSS [training: 0.3082318187112079 | validation: 0.18023376910174166]
	TIME [epoch: 8.52 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2867265575009474		[learning rate: 0.0038434]
	Learning Rate: 0.00384342
	LOSS [training: 0.2867265575009474 | validation: 0.3121306224658952]
	TIME [epoch: 8.52 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30598774024268294		[learning rate: 0.0038344]
	Learning Rate: 0.00383435
	LOSS [training: 0.30598774024268294 | validation: 0.2185142197698719]
	TIME [epoch: 8.52 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30197952267977124		[learning rate: 0.0038253]
	Learning Rate: 0.00382531
	LOSS [training: 0.30197952267977124 | validation: 0.4124956812082282]
	TIME [epoch: 8.54 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28423455635449935		[learning rate: 0.0038163]
	Learning Rate: 0.00381629
	LOSS [training: 0.28423455635449935 | validation: 0.3596052496959704]
	TIME [epoch: 8.52 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27759432712382975		[learning rate: 0.0038073]
	Learning Rate: 0.00380728
	LOSS [training: 0.27759432712382975 | validation: 0.2057849933575695]
	TIME [epoch: 8.52 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24617751694387122		[learning rate: 0.0037983]
	Learning Rate: 0.0037983
	LOSS [training: 0.24617751694387122 | validation: 0.18603504799918413]
	TIME [epoch: 8.52 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2998488625484709		[learning rate: 0.0037893]
	Learning Rate: 0.00378934
	LOSS [training: 0.2998488625484709 | validation: 0.5500470189087511]
	TIME [epoch: 8.53 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40332862179651763		[learning rate: 0.0037804]
	Learning Rate: 0.00378041
	LOSS [training: 0.40332862179651763 | validation: 0.24307052302373755]
	TIME [epoch: 8.51 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.300987469905512		[learning rate: 0.0037715]
	Learning Rate: 0.00377149
	LOSS [training: 0.300987469905512 | validation: 0.2507824002223316]
	TIME [epoch: 8.52 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31420895440437935		[learning rate: 0.0037626]
	Learning Rate: 0.00376259
	LOSS [training: 0.31420895440437935 | validation: 0.41877129938710766]
	TIME [epoch: 8.53 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33567784327670236		[learning rate: 0.0037537]
	Learning Rate: 0.00375372
	LOSS [training: 0.33567784327670236 | validation: 0.26356194315276216]
	TIME [epoch: 8.52 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31633055065063165		[learning rate: 0.0037449]
	Learning Rate: 0.00374486
	LOSS [training: 0.31633055065063165 | validation: 0.3598539633216892]
	TIME [epoch: 8.51 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4309968903561825		[learning rate: 0.003736]
	Learning Rate: 0.00373603
	LOSS [training: 0.4309968903561825 | validation: 0.26078294585215445]
	TIME [epoch: 8.51 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28555282448432573		[learning rate: 0.0037272]
	Learning Rate: 0.00372722
	LOSS [training: 0.28555282448432573 | validation: 0.26109068773017335]
	TIME [epoch: 8.54 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32963877382013573		[learning rate: 0.0037184]
	Learning Rate: 0.00371842
	LOSS [training: 0.32963877382013573 | validation: 0.5219860150471485]
	TIME [epoch: 8.52 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33406318920774913		[learning rate: 0.0037097]
	Learning Rate: 0.00370965
	LOSS [training: 0.33406318920774913 | validation: 0.17313949088123592]
	TIME [epoch: 8.51 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28784245308316314		[learning rate: 0.0037009]
	Learning Rate: 0.0037009
	LOSS [training: 0.28784245308316314 | validation: 0.526446774089706]
	TIME [epoch: 8.52 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3797904922328662		[learning rate: 0.0036922]
	Learning Rate: 0.00369217
	LOSS [training: 0.3797904922328662 | validation: 0.3362825030132939]
	TIME [epoch: 8.53 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36574657644842296		[learning rate: 0.0036835]
	Learning Rate: 0.00368346
	LOSS [training: 0.36574657644842296 | validation: 0.4489530886469806]
	TIME [epoch: 8.52 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36102554830858125		[learning rate: 0.0036748]
	Learning Rate: 0.00367478
	LOSS [training: 0.36102554830858125 | validation: 0.3353852639358004]
	TIME [epoch: 8.52 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4374220008751789		[learning rate: 0.0036661]
	Learning Rate: 0.00366611
	LOSS [training: 0.4374220008751789 | validation: 0.5502576562334196]
	TIME [epoch: 8.52 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30173528528289123		[learning rate: 0.0036575]
	Learning Rate: 0.00365746
	LOSS [training: 0.30173528528289123 | validation: 0.4907257154504361]
	TIME [epoch: 8.54 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.464716271676478		[learning rate: 0.0036488]
	Learning Rate: 0.00364883
	LOSS [training: 0.464716271676478 | validation: 0.3047962000293448]
	TIME [epoch: 8.52 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37708107964654747		[learning rate: 0.0036402]
	Learning Rate: 0.00364022
	LOSS [training: 0.37708107964654747 | validation: 0.2810056378166876]
	TIME [epoch: 8.52 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31295413065766226		[learning rate: 0.0036316]
	Learning Rate: 0.00363164
	LOSS [training: 0.31295413065766226 | validation: 0.43862919299784664]
	TIME [epoch: 8.52 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39821114210136543		[learning rate: 0.0036231]
	Learning Rate: 0.00362307
	LOSS [training: 0.39821114210136543 | validation: 0.27119392975398476]
	TIME [epoch: 8.55 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3162513774379718		[learning rate: 0.0036145]
	Learning Rate: 0.00361453
	LOSS [training: 0.3162513774379718 | validation: 0.3559051889548679]
	TIME [epoch: 8.52 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36584750253014436		[learning rate: 0.003606]
	Learning Rate: 0.003606
	LOSS [training: 0.36584750253014436 | validation: 0.5488044545430042]
	TIME [epoch: 8.52 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4104284297603398		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.4104284297603398 | validation: 0.35411087367361915]
	TIME [epoch: 8.52 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2925143939985791		[learning rate: 0.003589]
	Learning Rate: 0.00358901
	LOSS [training: 0.2925143939985791 | validation: 0.5059255198450814]
	TIME [epoch: 8.55 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31726694861609395		[learning rate: 0.0035805]
	Learning Rate: 0.00358054
	LOSS [training: 0.31726694861609395 | validation: 0.42714822109101697]
	TIME [epoch: 8.52 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33227134499476785		[learning rate: 0.0035721]
	Learning Rate: 0.0035721
	LOSS [training: 0.33227134499476785 | validation: 0.2668077907853056]
	TIME [epoch: 8.51 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2723761545537816		[learning rate: 0.0035637]
	Learning Rate: 0.00356367
	LOSS [training: 0.2723761545537816 | validation: 0.4157234535015357]
	TIME [epoch: 8.52 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35136985357435035		[learning rate: 0.0035553]
	Learning Rate: 0.00355526
	LOSS [training: 0.35136985357435035 | validation: 0.33474249084719576]
	TIME [epoch: 8.54 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2700113519169203		[learning rate: 0.0035469]
	Learning Rate: 0.00354688
	LOSS [training: 0.2700113519169203 | validation: 0.2042048668930335]
	TIME [epoch: 8.52 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2531082219766635		[learning rate: 0.0035385]
	Learning Rate: 0.00353851
	LOSS [training: 0.2531082219766635 | validation: 0.3984466325342615]
	TIME [epoch: 8.52 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3099295304165762		[learning rate: 0.0035302]
	Learning Rate: 0.00353016
	LOSS [training: 0.3099295304165762 | validation: 0.41119874549414126]
	TIME [epoch: 8.52 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3220375045108633		[learning rate: 0.0035218]
	Learning Rate: 0.00352184
	LOSS [training: 0.3220375045108633 | validation: 0.7838924244448131]
	TIME [epoch: 8.55 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4395919484658256		[learning rate: 0.0035135]
	Learning Rate: 0.00351353
	LOSS [training: 0.4395919484658256 | validation: 0.23752980697916845]
	TIME [epoch: 8.52 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32772851285937404		[learning rate: 0.0035052]
	Learning Rate: 0.00350524
	LOSS [training: 0.32772851285937404 | validation: 0.32013966951337797]
	TIME [epoch: 8.52 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31044009861193705		[learning rate: 0.003497]
	Learning Rate: 0.00349697
	LOSS [training: 0.31044009861193705 | validation: 0.42704900025057124]
	TIME [epoch: 8.53 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3192206510917317		[learning rate: 0.0034887]
	Learning Rate: 0.00348872
	LOSS [training: 0.3192206510917317 | validation: 0.3374811048943501]
	TIME [epoch: 8.54 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.283829399564076		[learning rate: 0.0034805]
	Learning Rate: 0.00348049
	LOSS [training: 0.283829399564076 | validation: 0.5544539243628979]
	TIME [epoch: 8.52 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3135408601161686		[learning rate: 0.0034723]
	Learning Rate: 0.00347228
	LOSS [training: 0.3135408601161686 | validation: 0.32283016351530636]
	TIME [epoch: 8.51 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28892794996361715		[learning rate: 0.0034641]
	Learning Rate: 0.00346409
	LOSS [training: 0.28892794996361715 | validation: 0.2414403710599577]
	TIME [epoch: 8.54 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29378200001475696		[learning rate: 0.0034559]
	Learning Rate: 0.00345592
	LOSS [training: 0.29378200001475696 | validation: 0.24897780050633023]
	TIME [epoch: 8.52 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3049727849914247		[learning rate: 0.0034478]
	Learning Rate: 0.00344777
	LOSS [training: 0.3049727849914247 | validation: 0.3684426061196791]
	TIME [epoch: 8.52 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4039557496912976		[learning rate: 0.0034396]
	Learning Rate: 0.00343964
	LOSS [training: 0.4039557496912976 | validation: 0.30678837180208957]
	TIME [epoch: 8.51 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2668050465515631		[learning rate: 0.0034315]
	Learning Rate: 0.00343152
	LOSS [training: 0.2668050465515631 | validation: 0.3285714033323152]
	TIME [epoch: 8.53 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2528345931221872		[learning rate: 0.0034234]
	Learning Rate: 0.00342343
	LOSS [training: 0.2528345931221872 | validation: 0.2805768422631134]
	TIME [epoch: 8.52 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2632872828292905		[learning rate: 0.0034154]
	Learning Rate: 0.00341535
	LOSS [training: 0.2632872828292905 | validation: 0.15640663881896655]
	TIME [epoch: 8.52 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.236878599389305		[learning rate: 0.0034073]
	Learning Rate: 0.0034073
	LOSS [training: 0.236878599389305 | validation: 0.2604396565465353]
	TIME [epoch: 8.51 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.334145033517078		[learning rate: 0.0033993]
	Learning Rate: 0.00339926
	LOSS [training: 0.334145033517078 | validation: 0.193425975289247]
	TIME [epoch: 8.54 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3076492772933045		[learning rate: 0.0033912]
	Learning Rate: 0.00339124
	LOSS [training: 0.3076492772933045 | validation: 0.3712862937279917]
	TIME [epoch: 8.52 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37231230150158956		[learning rate: 0.0033832]
	Learning Rate: 0.00338324
	LOSS [training: 0.37231230150158956 | validation: 0.29420142892301976]
	TIME [epoch: 8.52 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33701090394874217		[learning rate: 0.0033753]
	Learning Rate: 0.00337526
	LOSS [training: 0.33701090394874217 | validation: 0.43277821411977724]
	TIME [epoch: 8.52 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3827724392006096		[learning rate: 0.0033673]
	Learning Rate: 0.0033673
	LOSS [training: 0.3827724392006096 | validation: 0.4149360991457886]
	TIME [epoch: 8.54 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38149148278372		[learning rate: 0.0033594]
	Learning Rate: 0.00335936
	LOSS [training: 0.38149148278372 | validation: 0.2977602617150155]
	TIME [epoch: 8.52 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2975599592801824		[learning rate: 0.0033514]
	Learning Rate: 0.00335143
	LOSS [training: 0.2975599592801824 | validation: 0.4599390547897444]
	TIME [epoch: 8.51 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2883904140544499		[learning rate: 0.0033435]
	Learning Rate: 0.00334353
	LOSS [training: 0.2883904140544499 | validation: 0.40145973087190956]
	TIME [epoch: 8.52 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3404471322569058		[learning rate: 0.0033356]
	Learning Rate: 0.00333564
	LOSS [training: 0.3404471322569058 | validation: 0.18609640184573872]
	TIME [epoch: 8.54 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3374101274079084		[learning rate: 0.0033278]
	Learning Rate: 0.00332777
	LOSS [training: 0.3374101274079084 | validation: 0.5698560855902792]
	TIME [epoch: 8.52 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3533793831587498		[learning rate: 0.0033199]
	Learning Rate: 0.00331992
	LOSS [training: 0.3533793831587498 | validation: 0.423159352946259]
	TIME [epoch: 8.52 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3285530457997814		[learning rate: 0.0033121]
	Learning Rate: 0.00331209
	LOSS [training: 0.3285530457997814 | validation: 0.4944812893452815]
	TIME [epoch: 8.52 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3725691431139272		[learning rate: 0.0033043]
	Learning Rate: 0.00330428
	LOSS [training: 0.3725691431139272 | validation: 0.27917749597688934]
	TIME [epoch: 8.54 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33716921313083353		[learning rate: 0.0032965]
	Learning Rate: 0.00329649
	LOSS [training: 0.33716921313083353 | validation: 0.1832451222927657]
	TIME [epoch: 8.52 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3006282427470629		[learning rate: 0.0032887]
	Learning Rate: 0.00328871
	LOSS [training: 0.3006282427470629 | validation: 0.17634261073430357]
	TIME [epoch: 8.52 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23846115620482927		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.23846115620482927 | validation: 0.3288324093683146]
	TIME [epoch: 8.52 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26435534284884304		[learning rate: 0.0032732]
	Learning Rate: 0.00327321
	LOSS [training: 0.26435534284884304 | validation: 0.25282209792193083]
	TIME [epoch: 8.54 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2363525737273112		[learning rate: 0.0032655]
	Learning Rate: 0.00326549
	LOSS [training: 0.2363525737273112 | validation: 0.755732010756561]
	TIME [epoch: 8.52 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3649481401578095		[learning rate: 0.0032578]
	Learning Rate: 0.00325779
	LOSS [training: 0.3649481401578095 | validation: 0.34291905918654386]
	TIME [epoch: 8.52 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20858145347526183		[learning rate: 0.0032501]
	Learning Rate: 0.00325011
	LOSS [training: 0.20858145347526183 | validation: 0.19961717048842448]
	TIME [epoch: 8.52 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2618389382515237		[learning rate: 0.0032424]
	Learning Rate: 0.00324244
	LOSS [training: 0.2618389382515237 | validation: 0.31355310387203683]
	TIME [epoch: 8.54 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3253853977018021		[learning rate: 0.0032348]
	Learning Rate: 0.00323479
	LOSS [training: 0.3253853977018021 | validation: 0.18468364173562132]
	TIME [epoch: 8.52 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2904511988061122		[learning rate: 0.0032272]
	Learning Rate: 0.00322716
	LOSS [training: 0.2904511988061122 | validation: 0.38156530026322444]
	TIME [epoch: 8.52 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3571235435079493		[learning rate: 0.0032195]
	Learning Rate: 0.00321955
	LOSS [training: 0.3571235435079493 | validation: 0.21387267847930136]
	TIME [epoch: 8.53 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22948035743840478		[learning rate: 0.003212]
	Learning Rate: 0.00321195
	LOSS [training: 0.22948035743840478 | validation: 0.31161847211299126]
	TIME [epoch: 8.53 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30991968252967994		[learning rate: 0.0032044]
	Learning Rate: 0.00320438
	LOSS [training: 0.30991968252967994 | validation: 0.19943433567622343]
	TIME [epoch: 8.52 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2620319998078874		[learning rate: 0.0031968]
	Learning Rate: 0.00319682
	LOSS [training: 0.2620319998078874 | validation: 0.30516594989182205]
	TIME [epoch: 8.52 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.261537747511566		[learning rate: 0.0031893]
	Learning Rate: 0.00318928
	LOSS [training: 0.261537747511566 | validation: 0.3768491267342846]
	TIME [epoch: 8.54 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28462099481981806		[learning rate: 0.0031818]
	Learning Rate: 0.00318175
	LOSS [training: 0.28462099481981806 | validation: 0.3664682609824112]
	TIME [epoch: 8.52 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30950878496762524		[learning rate: 0.0031742]
	Learning Rate: 0.00317425
	LOSS [training: 0.30950878496762524 | validation: 0.8843395017463804]
	TIME [epoch: 8.52 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44992152603722574		[learning rate: 0.0031668]
	Learning Rate: 0.00316676
	LOSS [training: 0.44992152603722574 | validation: 0.6260000969985053]
	TIME [epoch: 8.52 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31381505807926346		[learning rate: 0.0031593]
	Learning Rate: 0.00315929
	LOSS [training: 0.31381505807926346 | validation: 0.5885100041803294]
	TIME [epoch: 8.54 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33937414691075346		[learning rate: 0.0031518]
	Learning Rate: 0.00315184
	LOSS [training: 0.33937414691075346 | validation: 0.20852887317374522]
	TIME [epoch: 8.52 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2649262718883726		[learning rate: 0.0031444]
	Learning Rate: 0.0031444
	LOSS [training: 0.2649262718883726 | validation: 0.2128922113983762]
	TIME [epoch: 8.52 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22383243994879218		[learning rate: 0.003137]
	Learning Rate: 0.00313699
	LOSS [training: 0.22383243994879218 | validation: 0.2659831867041988]
	TIME [epoch: 8.52 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35818882287935594		[learning rate: 0.0031296]
	Learning Rate: 0.00312959
	LOSS [training: 0.35818882287935594 | validation: 0.2552551299455053]
	TIME [epoch: 8.54 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26655647113630276		[learning rate: 0.0031222]
	Learning Rate: 0.00312221
	LOSS [training: 0.26655647113630276 | validation: 0.47285124505188925]
	TIME [epoch: 8.52 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38517259078659344		[learning rate: 0.0031148]
	Learning Rate: 0.00311484
	LOSS [training: 0.38517259078659344 | validation: 0.34133603136760926]
	TIME [epoch: 8.52 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31232736877804196		[learning rate: 0.0031075]
	Learning Rate: 0.00310749
	LOSS [training: 0.31232736877804196 | validation: 0.30750795774490153]
	TIME [epoch: 8.52 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33504191963904206		[learning rate: 0.0031002]
	Learning Rate: 0.00310016
	LOSS [training: 0.33504191963904206 | validation: 0.232070615575811]
	TIME [epoch: 8.54 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2785701172651823		[learning rate: 0.0030929]
	Learning Rate: 0.00309285
	LOSS [training: 0.2785701172651823 | validation: 0.32199060485953995]
	TIME [epoch: 8.52 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2845274936263471		[learning rate: 0.0030856]
	Learning Rate: 0.00308556
	LOSS [training: 0.2845274936263471 | validation: 0.26255535795085555]
	TIME [epoch: 8.52 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2622090691475537		[learning rate: 0.0030783]
	Learning Rate: 0.00307828
	LOSS [training: 0.2622090691475537 | validation: 0.18637686097181672]
	TIME [epoch: 8.52 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2385532665549317		[learning rate: 0.003071]
	Learning Rate: 0.00307102
	LOSS [training: 0.2385532665549317 | validation: 0.6684491059318118]
	TIME [epoch: 8.55 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3007730669038352		[learning rate: 0.0030638]
	Learning Rate: 0.00306377
	LOSS [training: 0.3007730669038352 | validation: 0.23570242117280793]
	TIME [epoch: 8.52 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2562808307762171		[learning rate: 0.0030565]
	Learning Rate: 0.00305654
	LOSS [training: 0.2562808307762171 | validation: 0.16317988508109227]
	TIME [epoch: 8.52 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35691156227335397		[learning rate: 0.0030493]
	Learning Rate: 0.00304933
	LOSS [training: 0.35691156227335397 | validation: 0.2366455558726147]
	TIME [epoch: 8.52 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34640293022298835		[learning rate: 0.0030421]
	Learning Rate: 0.00304214
	LOSS [training: 0.34640293022298835 | validation: 0.16301919353683708]
	TIME [epoch: 8.55 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3246189570889177		[learning rate: 0.003035]
	Learning Rate: 0.00303497
	LOSS [training: 0.3246189570889177 | validation: 0.1751895086753915]
	TIME [epoch: 8.52 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27346884848890624		[learning rate: 0.0030278]
	Learning Rate: 0.00302781
	LOSS [training: 0.27346884848890624 | validation: 0.2365827458040196]
	TIME [epoch: 8.52 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2176829295613829		[learning rate: 0.0030207]
	Learning Rate: 0.00302066
	LOSS [training: 0.2176829295613829 | validation: 0.5689899042687223]
	TIME [epoch: 8.52 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34189219811376426		[learning rate: 0.0030135]
	Learning Rate: 0.00301354
	LOSS [training: 0.34189219811376426 | validation: 0.36807668970633056]
	TIME [epoch: 8.54 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40693081442119317		[learning rate: 0.0030064]
	Learning Rate: 0.00300643
	LOSS [training: 0.40693081442119317 | validation: 0.378497999522333]
	TIME [epoch: 8.52 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3337421608058539		[learning rate: 0.0029993]
	Learning Rate: 0.00299934
	LOSS [training: 0.3337421608058539 | validation: 0.27489233568033167]
	TIME [epoch: 8.52 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2363927632351069		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.2363927632351069 | validation: 0.18962680178995694]
	TIME [epoch: 8.52 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24356300917654666		[learning rate: 0.0029852]
	Learning Rate: 0.00298521
	LOSS [training: 0.24356300917654666 | validation: 0.3038530987358965]
	TIME [epoch: 8.54 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26285867207432295		[learning rate: 0.0029782]
	Learning Rate: 0.00297816
	LOSS [training: 0.26285867207432295 | validation: 0.3823138949199274]
	TIME [epoch: 8.52 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24309194821039962		[learning rate: 0.0029711]
	Learning Rate: 0.00297114
	LOSS [training: 0.24309194821039962 | validation: 0.17121860178663387]
	TIME [epoch: 8.52 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28009834994415067		[learning rate: 0.0029641]
	Learning Rate: 0.00296413
	LOSS [training: 0.28009834994415067 | validation: 0.2397357531532972]
	TIME [epoch: 8.53 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31169212747705594		[learning rate: 0.0029571]
	Learning Rate: 0.00295714
	LOSS [training: 0.31169212747705594 | validation: 0.2444687713428345]
	TIME [epoch: 8.53 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2534941949032602		[learning rate: 0.0029502]
	Learning Rate: 0.00295016
	LOSS [training: 0.2534941949032602 | validation: 0.2305725132301015]
	TIME [epoch: 8.52 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24414611908390663		[learning rate: 0.0029432]
	Learning Rate: 0.0029432
	LOSS [training: 0.24414611908390663 | validation: 0.24425538719782292]
	TIME [epoch: 8.52 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2954683936422543		[learning rate: 0.0029363]
	Learning Rate: 0.00293626
	LOSS [training: 0.2954683936422543 | validation: 0.1764615007007247]
	TIME [epoch: 8.53 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24973741752541886		[learning rate: 0.0029293]
	Learning Rate: 0.00292934
	LOSS [training: 0.24973741752541886 | validation: 0.21184691532073396]
	TIME [epoch: 8.52 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27482206503117335		[learning rate: 0.0029224]
	Learning Rate: 0.00292243
	LOSS [training: 0.27482206503117335 | validation: 0.281405493339293]
	TIME [epoch: 8.52 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23043926828214573		[learning rate: 0.0029155]
	Learning Rate: 0.00291553
	LOSS [training: 0.23043926828214573 | validation: 0.21052739875772017]
	TIME [epoch: 8.52 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3155101264662382		[learning rate: 0.0029087]
	Learning Rate: 0.00290866
	LOSS [training: 0.3155101264662382 | validation: 0.43749779645081244]
	TIME [epoch: 8.54 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.327479589407085		[learning rate: 0.0029018]
	Learning Rate: 0.00290179
	LOSS [training: 0.327479589407085 | validation: 0.288130089191067]
	TIME [epoch: 8.52 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27814313159392984		[learning rate: 0.0028949]
	Learning Rate: 0.00289495
	LOSS [training: 0.27814313159392984 | validation: 0.34515252331465884]
	TIME [epoch: 8.52 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31301151832631335		[learning rate: 0.0028881]
	Learning Rate: 0.00288812
	LOSS [training: 0.31301151832631335 | validation: 0.2259097457707544]
	TIME [epoch: 8.51 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26258645915368806		[learning rate: 0.0028813]
	Learning Rate: 0.00288131
	LOSS [training: 0.26258645915368806 | validation: 0.22086614315226755]
	TIME [epoch: 8.54 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27692427427095095		[learning rate: 0.0028745]
	Learning Rate: 0.00287451
	LOSS [training: 0.27692427427095095 | validation: 0.27546063062206244]
	TIME [epoch: 8.52 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2426449988572478		[learning rate: 0.0028677]
	Learning Rate: 0.00286773
	LOSS [training: 0.2426449988572478 | validation: 0.15554317408361135]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_579.pth
	Model improved!!!
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22825462817226833		[learning rate: 0.002861]
	Learning Rate: 0.00286097
	LOSS [training: 0.22825462817226833 | validation: 0.1485169483650953]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_580.pth
	Model improved!!!
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2713582729245314		[learning rate: 0.0028542]
	Learning Rate: 0.00285422
	LOSS [training: 0.2713582729245314 | validation: 0.1882445660789125]
	TIME [epoch: 8.55 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2655324388362556		[learning rate: 0.0028475]
	Learning Rate: 0.00284749
	LOSS [training: 0.2655324388362556 | validation: 0.37763840925987385]
	TIME [epoch: 8.53 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.292814103375852		[learning rate: 0.0028408]
	Learning Rate: 0.00284077
	LOSS [training: 0.292814103375852 | validation: 0.40044345373373064]
	TIME [epoch: 8.52 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3046624948428101		[learning rate: 0.0028341]
	Learning Rate: 0.00283407
	LOSS [training: 0.3046624948428101 | validation: 0.608763164745918]
	TIME [epoch: 8.53 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28007170026679246		[learning rate: 0.0028274]
	Learning Rate: 0.00282738
	LOSS [training: 0.28007170026679246 | validation: 0.20984233593176851]
	TIME [epoch: 8.55 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27593068814098565		[learning rate: 0.0028207]
	Learning Rate: 0.00282071
	LOSS [training: 0.27593068814098565 | validation: 0.18325039249511965]
	TIME [epoch: 8.53 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27913406012941133		[learning rate: 0.0028141]
	Learning Rate: 0.00281406
	LOSS [training: 0.27913406012941133 | validation: 0.2911927396070618]
	TIME [epoch: 8.52 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36226693102074525		[learning rate: 0.0028074]
	Learning Rate: 0.00280742
	LOSS [training: 0.36226693102074525 | validation: 0.3806236122911769]
	TIME [epoch: 8.53 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23084150875499665		[learning rate: 0.0028008]
	Learning Rate: 0.0028008
	LOSS [training: 0.23084150875499665 | validation: 0.40860651189836295]
	TIME [epoch: 8.55 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2543356481730189		[learning rate: 0.0027942]
	Learning Rate: 0.00279419
	LOSS [training: 0.2543356481730189 | validation: 0.21167607298145732]
	TIME [epoch: 8.53 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25236032697700367		[learning rate: 0.0027876]
	Learning Rate: 0.0027876
	LOSS [training: 0.25236032697700367 | validation: 0.18028133842772487]
	TIME [epoch: 8.53 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22873492249517274		[learning rate: 0.002781]
	Learning Rate: 0.00278103
	LOSS [training: 0.22873492249517274 | validation: 0.2941831445917017]
	TIME [epoch: 8.54 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2237280499139378		[learning rate: 0.0027745]
	Learning Rate: 0.00277447
	LOSS [training: 0.2237280499139378 | validation: 0.14533777218310454]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_593.pth
	Model improved!!!
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2539707166231947		[learning rate: 0.0027679]
	Learning Rate: 0.00276792
	LOSS [training: 0.2539707166231947 | validation: 0.5323514508292441]
	TIME [epoch: 8.52 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2700693715125836		[learning rate: 0.0027614]
	Learning Rate: 0.00276139
	LOSS [training: 0.2700693715125836 | validation: 0.2772238504189358]
	TIME [epoch: 8.53 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2605739027797318		[learning rate: 0.0027549]
	Learning Rate: 0.00275488
	LOSS [training: 0.2605739027797318 | validation: 0.31443340131842035]
	TIME [epoch: 8.55 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25211812348799817		[learning rate: 0.0027484]
	Learning Rate: 0.00274838
	LOSS [training: 0.25211812348799817 | validation: 0.2742394665663666]
	TIME [epoch: 8.54 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3176992893114611		[learning rate: 0.0027419]
	Learning Rate: 0.0027419
	LOSS [training: 0.3176992893114611 | validation: 0.22390335511349949]
	TIME [epoch: 8.53 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2807657344145735		[learning rate: 0.0027354]
	Learning Rate: 0.00273543
	LOSS [training: 0.2807657344145735 | validation: 0.22948828229168766]
	TIME [epoch: 8.53 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30795545363181676		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.30795545363181676 | validation: 0.30971029828104557]
	TIME [epoch: 8.55 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32150270986742435		[learning rate: 0.0027225]
	Learning Rate: 0.00272254
	LOSS [training: 0.32150270986742435 | validation: 0.22849955243885273]
	TIME [epoch: 8.53 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29395306065284166		[learning rate: 0.0027161]
	Learning Rate: 0.00271612
	LOSS [training: 0.29395306065284166 | validation: 0.34956537459364107]
	TIME [epoch: 8.52 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3081373547488992		[learning rate: 0.0027097]
	Learning Rate: 0.00270971
	LOSS [training: 0.3081373547488992 | validation: 0.4245414655413754]
	TIME [epoch: 8.52 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3267216539117973		[learning rate: 0.0027033]
	Learning Rate: 0.00270332
	LOSS [training: 0.3267216539117973 | validation: 0.3306148296857977]
	TIME [epoch: 8.55 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22174548402711286		[learning rate: 0.0026969]
	Learning Rate: 0.00269694
	LOSS [training: 0.22174548402711286 | validation: 0.13725599016230716]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_605.pth
	Model improved!!!
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22200935391912346		[learning rate: 0.0026906]
	Learning Rate: 0.00269058
	LOSS [training: 0.22200935391912346 | validation: 0.19278274678251012]
	TIME [epoch: 8.53 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2699788568847469		[learning rate: 0.0026842]
	Learning Rate: 0.00268423
	LOSS [training: 0.2699788568847469 | validation: 0.5669170328565929]
	TIME [epoch: 8.52 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30408492308715485		[learning rate: 0.0026779]
	Learning Rate: 0.0026779
	LOSS [training: 0.30408492308715485 | validation: 0.21443283998515]
	TIME [epoch: 8.56 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2938717821571792		[learning rate: 0.0026716]
	Learning Rate: 0.00267159
	LOSS [training: 0.2938717821571792 | validation: 0.30051525238505694]
	TIME [epoch: 8.53 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2713185377411759		[learning rate: 0.0026653]
	Learning Rate: 0.00266528
	LOSS [training: 0.2713185377411759 | validation: 0.21119747396181004]
	TIME [epoch: 8.52 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2035704458800613		[learning rate: 0.002659]
	Learning Rate: 0.002659
	LOSS [training: 0.2035704458800613 | validation: 0.150104876886128]
	TIME [epoch: 8.52 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25308101022496077		[learning rate: 0.0026527]
	Learning Rate: 0.00265273
	LOSS [training: 0.25308101022496077 | validation: 0.15936964204370901]
	TIME [epoch: 8.55 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23964921319836546		[learning rate: 0.0026465]
	Learning Rate: 0.00264647
	LOSS [training: 0.23964921319836546 | validation: 0.25138626365151095]
	TIME [epoch: 8.52 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25287692886700486		[learning rate: 0.0026402]
	Learning Rate: 0.00264023
	LOSS [training: 0.25287692886700486 | validation: 0.2031535126654221]
	TIME [epoch: 8.53 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2815703377588032		[learning rate: 0.002634]
	Learning Rate: 0.002634
	LOSS [training: 0.2815703377588032 | validation: 0.16470081539749273]
	TIME [epoch: 8.52 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21809115261429843		[learning rate: 0.0026278]
	Learning Rate: 0.00262778
	LOSS [training: 0.21809115261429843 | validation: 0.16991021845205168]
	TIME [epoch: 8.55 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21277708214975735		[learning rate: 0.0026216]
	Learning Rate: 0.00262159
	LOSS [training: 0.21277708214975735 | validation: 0.21577144776010607]
	TIME [epoch: 8.52 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.269380151108037		[learning rate: 0.0026154]
	Learning Rate: 0.0026154
	LOSS [training: 0.269380151108037 | validation: 0.24252904402274852]
	TIME [epoch: 8.52 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21998932166688942		[learning rate: 0.0026092]
	Learning Rate: 0.00260923
	LOSS [training: 0.21998932166688942 | validation: 0.23765051192778877]
	TIME [epoch: 8.52 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2734062414658419		[learning rate: 0.0026031]
	Learning Rate: 0.00260308
	LOSS [training: 0.2734062414658419 | validation: 0.20632584368920082]
	TIME [epoch: 8.55 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21647052111280418		[learning rate: 0.0025969]
	Learning Rate: 0.00259694
	LOSS [training: 0.21647052111280418 | validation: 0.3997754011676321]
	TIME [epoch: 8.53 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21952204659111452		[learning rate: 0.0025908]
	Learning Rate: 0.00259081
	LOSS [training: 0.21952204659111452 | validation: 0.2116862834566292]
	TIME [epoch: 8.53 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20489870653460174		[learning rate: 0.0025847]
	Learning Rate: 0.0025847
	LOSS [training: 0.20489870653460174 | validation: 0.3131962041983549]
	TIME [epoch: 8.53 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27946995218946424		[learning rate: 0.0025786]
	Learning Rate: 0.0025786
	LOSS [training: 0.27946995218946424 | validation: 0.39218632221916827]
	TIME [epoch: 8.54 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3060025690523363		[learning rate: 0.0025725]
	Learning Rate: 0.00257252
	LOSS [training: 0.3060025690523363 | validation: 0.21384204893273479]
	TIME [epoch: 8.52 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24453043989585654		[learning rate: 0.0025665]
	Learning Rate: 0.00256645
	LOSS [training: 0.24453043989585654 | validation: 0.21294973433266118]
	TIME [epoch: 8.52 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20820821165070286		[learning rate: 0.0025604]
	Learning Rate: 0.0025604
	LOSS [training: 0.20820821165070286 | validation: 0.22182374342809374]
	TIME [epoch: 8.54 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20645630409384844		[learning rate: 0.0025544]
	Learning Rate: 0.00255436
	LOSS [training: 0.20645630409384844 | validation: 0.20580814433887595]
	TIME [epoch: 8.53 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.244111675803984		[learning rate: 0.0025483]
	Learning Rate: 0.00254833
	LOSS [training: 0.244111675803984 | validation: 0.465779531652582]
	TIME [epoch: 8.52 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2539915667961443		[learning rate: 0.0025423]
	Learning Rate: 0.00254232
	LOSS [training: 0.2539915667961443 | validation: 0.34861709598999047]
	TIME [epoch: 8.52 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19772899963876284		[learning rate: 0.0025363]
	Learning Rate: 0.00253633
	LOSS [training: 0.19772899963876284 | validation: 0.20318376858503]
	TIME [epoch: 8.54 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21709310523606637		[learning rate: 0.0025303]
	Learning Rate: 0.00253034
	LOSS [training: 0.21709310523606637 | validation: 0.23898724749085565]
	TIME [epoch: 8.53 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24497662768584533		[learning rate: 0.0025244]
	Learning Rate: 0.00252437
	LOSS [training: 0.24497662768584533 | validation: 0.2152179848044226]
	TIME [epoch: 8.52 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23888812252123026		[learning rate: 0.0025184]
	Learning Rate: 0.00251842
	LOSS [training: 0.23888812252123026 | validation: 0.47803637373361996]
	TIME [epoch: 8.52 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2723112816901909		[learning rate: 0.0025125]
	Learning Rate: 0.00251248
	LOSS [training: 0.2723112816901909 | validation: 0.2455444371007089]
	TIME [epoch: 8.54 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2596520903686666		[learning rate: 0.0025066]
	Learning Rate: 0.00250655
	LOSS [training: 0.2596520903686666 | validation: 0.25622972857459575]
	TIME [epoch: 8.52 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28938715664545256		[learning rate: 0.0025006]
	Learning Rate: 0.00250064
	LOSS [training: 0.28938715664545256 | validation: 0.2666954651116165]
	TIME [epoch: 8.52 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27857351464512115		[learning rate: 0.0024947]
	Learning Rate: 0.00249474
	LOSS [training: 0.27857351464512115 | validation: 0.2918914294114691]
	TIME [epoch: 8.52 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26105401011972484		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.26105401011972484 | validation: 0.36975352857038224]
	TIME [epoch: 8.54 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2785761231032311		[learning rate: 0.002483]
	Learning Rate: 0.00248299
	LOSS [training: 0.2785761231032311 | validation: 0.18619471671473822]
	TIME [epoch: 8.53 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27312730561889753		[learning rate: 0.0024771]
	Learning Rate: 0.00247713
	LOSS [training: 0.27312730561889753 | validation: 0.3930372645840272]
	TIME [epoch: 8.52 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20725554740693672		[learning rate: 0.0024713]
	Learning Rate: 0.00247129
	LOSS [training: 0.20725554740693672 | validation: 0.12778938832375566]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_642.pth
	Model improved!!!
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24487293893518464		[learning rate: 0.0024655]
	Learning Rate: 0.00246546
	LOSS [training: 0.24487293893518464 | validation: 0.39289577476683524]
	TIME [epoch: 8.55 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2429798297445042		[learning rate: 0.0024596]
	Learning Rate: 0.00245964
	LOSS [training: 0.2429798297445042 | validation: 0.16657762618058067]
	TIME [epoch: 8.52 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21637584238195987		[learning rate: 0.0024538]
	Learning Rate: 0.00245384
	LOSS [training: 0.21637584238195987 | validation: 0.2742579763169858]
	TIME [epoch: 8.51 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23122089838058693		[learning rate: 0.0024481]
	Learning Rate: 0.00244805
	LOSS [training: 0.23122089838058693 | validation: 0.3759860955720894]
	TIME [epoch: 8.52 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2240918276884924		[learning rate: 0.0024423]
	Learning Rate: 0.00244228
	LOSS [training: 0.2240918276884924 | validation: 0.2419327837554095]
	TIME [epoch: 8.54 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21005944154256082		[learning rate: 0.0024365]
	Learning Rate: 0.00243652
	LOSS [training: 0.21005944154256082 | validation: 0.4407748570235147]
	TIME [epoch: 8.52 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.303831634628538		[learning rate: 0.0024308]
	Learning Rate: 0.00243077
	LOSS [training: 0.303831634628538 | validation: 0.1742352563815855]
	TIME [epoch: 8.51 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2151887785498902		[learning rate: 0.002425]
	Learning Rate: 0.00242503
	LOSS [training: 0.2151887785498902 | validation: 0.3227799502682456]
	TIME [epoch: 8.51 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20606516936537714		[learning rate: 0.0024193]
	Learning Rate: 0.00241931
	LOSS [training: 0.20606516936537714 | validation: 0.1733974703130571]
	TIME [epoch: 8.53 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23051558332144095		[learning rate: 0.0024136]
	Learning Rate: 0.00241361
	LOSS [training: 0.23051558332144095 | validation: 0.3761587019530519]
	TIME [epoch: 8.51 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20233202442131332		[learning rate: 0.0024079]
	Learning Rate: 0.00240791
	LOSS [training: 0.20233202442131332 | validation: 0.2068136241490829]
	TIME [epoch: 8.51 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.248324946130328		[learning rate: 0.0024022]
	Learning Rate: 0.00240223
	LOSS [training: 0.248324946130328 | validation: 0.3722436970182279]
	TIME [epoch: 8.52 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19503002571987443		[learning rate: 0.0023966]
	Learning Rate: 0.00239657
	LOSS [training: 0.19503002571987443 | validation: 0.26006369778231836]
	TIME [epoch: 8.53 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19925121657032932		[learning rate: 0.0023909]
	Learning Rate: 0.00239092
	LOSS [training: 0.19925121657032932 | validation: 0.22557544950901665]
	TIME [epoch: 8.51 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21655756938439116		[learning rate: 0.0023853]
	Learning Rate: 0.00238527
	LOSS [training: 0.21655756938439116 | validation: 0.19570380308088936]
	TIME [epoch: 8.51 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2300438850707875		[learning rate: 0.0023796]
	Learning Rate: 0.00237965
	LOSS [training: 0.2300438850707875 | validation: 0.33960547046178163]
	TIME [epoch: 8.53 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21043894378969044		[learning rate: 0.002374]
	Learning Rate: 0.00237404
	LOSS [training: 0.21043894378969044 | validation: 0.22935903007273728]
	TIME [epoch: 8.52 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19163730646326646		[learning rate: 0.0023684]
	Learning Rate: 0.00236844
	LOSS [training: 0.19163730646326646 | validation: 0.27891172291828636]
	TIME [epoch: 8.51 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.272509429303493		[learning rate: 0.0023628]
	Learning Rate: 0.00236285
	LOSS [training: 0.272509429303493 | validation: 0.24288568857180326]
	TIME [epoch: 8.51 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22579047693662688		[learning rate: 0.0023573]
	Learning Rate: 0.00235727
	LOSS [training: 0.22579047693662688 | validation: 0.19669700517672895]
	TIME [epoch: 8.53 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29056614817625964		[learning rate: 0.0023517]
	Learning Rate: 0.00235171
	LOSS [training: 0.29056614817625964 | validation: 0.222347163161999]
	TIME [epoch: 8.52 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25308004491846636		[learning rate: 0.0023462]
	Learning Rate: 0.00234617
	LOSS [training: 0.25308004491846636 | validation: 0.32785106736550007]
	TIME [epoch: 8.51 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21252984380865841		[learning rate: 0.0023406]
	Learning Rate: 0.00234063
	LOSS [training: 0.21252984380865841 | validation: 0.20395566440481602]
	TIME [epoch: 8.51 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29216390545665316		[learning rate: 0.0023351]
	Learning Rate: 0.00233511
	LOSS [training: 0.29216390545665316 | validation: 0.24397966899705686]
	TIME [epoch: 8.54 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21462560266774172		[learning rate: 0.0023296]
	Learning Rate: 0.0023296
	LOSS [training: 0.21462560266774172 | validation: 0.23921968120361484]
	TIME [epoch: 8.52 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19915628483497783		[learning rate: 0.0023241]
	Learning Rate: 0.00232411
	LOSS [training: 0.19915628483497783 | validation: 0.4655043984013586]
	TIME [epoch: 8.52 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.262901861537074		[learning rate: 0.0023186]
	Learning Rate: 0.00231863
	LOSS [training: 0.262901861537074 | validation: 0.16133934423980903]
	TIME [epoch: 8.52 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16560006556053328		[learning rate: 0.0023132]
	Learning Rate: 0.00231316
	LOSS [training: 0.16560006556053328 | validation: 0.17901466187481962]
	TIME [epoch: 8.54 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23517079690748596		[learning rate: 0.0023077]
	Learning Rate: 0.0023077
	LOSS [training: 0.23517079690748596 | validation: 0.22322777507228136]
	TIME [epoch: 8.52 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20128233630284093		[learning rate: 0.0023023]
	Learning Rate: 0.00230226
	LOSS [training: 0.20128233630284093 | validation: 0.16513863183712071]
	TIME [epoch: 8.51 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21236751776918789		[learning rate: 0.0022968]
	Learning Rate: 0.00229683
	LOSS [training: 0.21236751776918789 | validation: 0.4937898746680207]
	TIME [epoch: 8.52 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2497997356740112		[learning rate: 0.0022914]
	Learning Rate: 0.00229141
	LOSS [training: 0.2497997356740112 | validation: 0.1761027122152901]
	TIME [epoch: 8.53 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26905191356806235		[learning rate: 0.002286]
	Learning Rate: 0.002286
	LOSS [training: 0.26905191356806235 | validation: 0.1910331846525607]
	TIME [epoch: 8.52 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2318678191507435		[learning rate: 0.0022806]
	Learning Rate: 0.00228061
	LOSS [training: 0.2318678191507435 | validation: 0.18667894837320453]
	TIME [epoch: 8.51 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18524360533962408		[learning rate: 0.0022752]
	Learning Rate: 0.00227523
	LOSS [training: 0.18524360533962408 | validation: 0.153332157452571]
	TIME [epoch: 8.52 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18237968818328693		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.18237968818328693 | validation: 0.2607289324713846]
	TIME [epoch: 8.54 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19227804522921516		[learning rate: 0.0022645]
	Learning Rate: 0.00226451
	LOSS [training: 0.19227804522921516 | validation: 0.16839943554452674]
	TIME [epoch: 8.51 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3100606711663314		[learning rate: 0.0022592]
	Learning Rate: 0.00225917
	LOSS [training: 0.3100606711663314 | validation: 0.28889013594582996]
	TIME [epoch: 8.51 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25025449098435804		[learning rate: 0.0022538]
	Learning Rate: 0.00225384
	LOSS [training: 0.25025449098435804 | validation: 0.16379766595035397]
	TIME [epoch: 8.52 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18435654517807115		[learning rate: 0.0022485]
	Learning Rate: 0.00224852
	LOSS [training: 0.18435654517807115 | validation: 0.1722059163463494]
	TIME [epoch: 8.53 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19257149248383904		[learning rate: 0.0022432]
	Learning Rate: 0.00224322
	LOSS [training: 0.19257149248383904 | validation: 0.1810569751167017]
	TIME [epoch: 8.51 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19940103672447287		[learning rate: 0.0022379]
	Learning Rate: 0.00223793
	LOSS [training: 0.19940103672447287 | validation: 0.1947902870554058]
	TIME [epoch: 8.51 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22132387843298768		[learning rate: 0.0022326]
	Learning Rate: 0.00223265
	LOSS [training: 0.22132387843298768 | validation: 0.3918297014293324]
	TIME [epoch: 8.52 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22987269708901578		[learning rate: 0.0022274]
	Learning Rate: 0.00222738
	LOSS [training: 0.22987269708901578 | validation: 0.21611912486899548]
	TIME [epoch: 8.53 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21946188351103285		[learning rate: 0.0022221]
	Learning Rate: 0.00222213
	LOSS [training: 0.21946188351103285 | validation: 0.18889392199138683]
	TIME [epoch: 8.52 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19339957032717242		[learning rate: 0.0022169]
	Learning Rate: 0.00221689
	LOSS [training: 0.19339957032717242 | validation: 0.13581022550418861]
	TIME [epoch: 8.51 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19652798925427462		[learning rate: 0.0022117]
	Learning Rate: 0.00221166
	LOSS [training: 0.19652798925427462 | validation: 0.1857110680409283]
	TIME [epoch: 8.52 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17626799364667836		[learning rate: 0.0022064]
	Learning Rate: 0.00220644
	LOSS [training: 0.17626799364667836 | validation: 0.1268889493628119]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_690.pth
	Model improved!!!
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2027528860177367		[learning rate: 0.0022012]
	Learning Rate: 0.00220124
	LOSS [training: 0.2027528860177367 | validation: 0.16103444149618693]
	TIME [epoch: 8.51 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18142287081373465		[learning rate: 0.002196]
	Learning Rate: 0.00219604
	LOSS [training: 0.18142287081373465 | validation: 0.15191232525347836]
	TIME [epoch: 8.51 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20544603883241952		[learning rate: 0.0021909]
	Learning Rate: 0.00219086
	LOSS [training: 0.20544603883241952 | validation: 0.15180932150016702]
	TIME [epoch: 8.53 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26752082917422915		[learning rate: 0.0021857]
	Learning Rate: 0.0021857
	LOSS [training: 0.26752082917422915 | validation: 0.3491620925877071]
	TIME [epoch: 8.52 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24925489910128507		[learning rate: 0.0021805]
	Learning Rate: 0.00218054
	LOSS [training: 0.24925489910128507 | validation: 0.141758206505724]
	TIME [epoch: 8.51 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1620158711212853		[learning rate: 0.0021754]
	Learning Rate: 0.0021754
	LOSS [training: 0.1620158711212853 | validation: 0.16897050594876295]
	TIME [epoch: 8.51 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1887251322278344		[learning rate: 0.0021703]
	Learning Rate: 0.00217027
	LOSS [training: 0.1887251322278344 | validation: 0.1652010335251017]
	TIME [epoch: 8.53 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2752168634696296		[learning rate: 0.0021651]
	Learning Rate: 0.00216515
	LOSS [training: 0.2752168634696296 | validation: 0.3035597816170019]
	TIME [epoch: 8.52 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2028943947114321		[learning rate: 0.00216]
	Learning Rate: 0.00216004
	LOSS [training: 0.2028943947114321 | validation: 0.15279952498839106]
	TIME [epoch: 8.51 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2642427234283488		[learning rate: 0.0021549]
	Learning Rate: 0.00215494
	LOSS [training: 0.2642427234283488 | validation: 0.1796456109616497]
	TIME [epoch: 8.51 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22860196031854488		[learning rate: 0.0021499]
	Learning Rate: 0.00214986
	LOSS [training: 0.22860196031854488 | validation: 0.2281800572843084]
	TIME [epoch: 8.54 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18676394688577913		[learning rate: 0.0021448]
	Learning Rate: 0.00214479
	LOSS [training: 0.18676394688577913 | validation: 0.24177426474413422]
	TIME [epoch: 8.51 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.197978959860071		[learning rate: 0.0021397]
	Learning Rate: 0.00213973
	LOSS [training: 0.197978959860071 | validation: 0.16630362740852064]
	TIME [epoch: 8.51 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16532284025141752		[learning rate: 0.0021347]
	Learning Rate: 0.00213468
	LOSS [training: 0.16532284025141752 | validation: 0.24725535322497433]
	TIME [epoch: 8.51 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2267508075551074		[learning rate: 0.0021296]
	Learning Rate: 0.00212965
	LOSS [training: 0.2267508075551074 | validation: 0.24003075095800186]
	TIME [epoch: 8.53 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1806140859653957		[learning rate: 0.0021246]
	Learning Rate: 0.00212462
	LOSS [training: 0.1806140859653957 | validation: 0.2241988906983075]
	TIME [epoch: 8.51 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18737353130226228		[learning rate: 0.0021196]
	Learning Rate: 0.00211961
	LOSS [training: 0.18737353130226228 | validation: 0.2204548541534203]
	TIME [epoch: 8.51 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33682599851898853		[learning rate: 0.0021146]
	Learning Rate: 0.00211461
	LOSS [training: 0.33682599851898853 | validation: 0.1828959171829146]
	TIME [epoch: 8.51 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2010476447562853		[learning rate: 0.0021096]
	Learning Rate: 0.00210962
	LOSS [training: 0.2010476447562853 | validation: 0.1556693039789503]
	TIME [epoch: 8.54 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21512888452106868		[learning rate: 0.0021046]
	Learning Rate: 0.00210465
	LOSS [training: 0.21512888452106868 | validation: 0.234703401625814]
	TIME [epoch: 8.51 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21116822770440416		[learning rate: 0.0020997]
	Learning Rate: 0.00209968
	LOSS [training: 0.21116822770440416 | validation: 0.14411100168662172]
	TIME [epoch: 8.51 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24899762370177236		[learning rate: 0.0020947]
	Learning Rate: 0.00209473
	LOSS [training: 0.24899762370177236 | validation: 0.3500772018175481]
	TIME [epoch: 8.51 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21987412165477743		[learning rate: 0.0020898]
	Learning Rate: 0.00208979
	LOSS [training: 0.21987412165477743 | validation: 0.18291628026785417]
	TIME [epoch: 8.53 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23776022243928896		[learning rate: 0.0020849]
	Learning Rate: 0.00208486
	LOSS [training: 0.23776022243928896 | validation: 0.2289099699035434]
	TIME [epoch: 8.51 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21674930191423508		[learning rate: 0.0020799]
	Learning Rate: 0.00207994
	LOSS [training: 0.21674930191423508 | validation: 0.24324089472250587]
	TIME [epoch: 8.51 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21961782590904075		[learning rate: 0.002075]
	Learning Rate: 0.00207504
	LOSS [training: 0.21961782590904075 | validation: 0.24356828437490374]
	TIME [epoch: 8.51 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22922784980998828		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.22922784980998828 | validation: 0.2149820294996014]
	TIME [epoch: 8.53 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2114468011138278		[learning rate: 0.0020653]
	Learning Rate: 0.00206526
	LOSS [training: 0.2114468011138278 | validation: 0.41430330861289977]
	TIME [epoch: 8.51 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2853916453672857		[learning rate: 0.0020604]
	Learning Rate: 0.00206039
	LOSS [training: 0.2853916453672857 | validation: 0.16078687164682065]
	TIME [epoch: 8.51 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2277396019691182		[learning rate: 0.0020555]
	Learning Rate: 0.00205553
	LOSS [training: 0.2277396019691182 | validation: 0.18063141857960313]
	TIME [epoch: 8.52 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1731244057221664		[learning rate: 0.0020507]
	Learning Rate: 0.00205068
	LOSS [training: 0.1731244057221664 | validation: 0.9111864833898731]
	TIME [epoch: 8.52 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34610124943416365		[learning rate: 0.0020458]
	Learning Rate: 0.00204584
	LOSS [training: 0.34610124943416365 | validation: 0.24473985580043006]
	TIME [epoch: 8.52 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19804105087485196		[learning rate: 0.002041]
	Learning Rate: 0.00204101
	LOSS [training: 0.19804105087485196 | validation: 0.21621495892991216]
	TIME [epoch: 8.51 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2933136094973317		[learning rate: 0.0020362]
	Learning Rate: 0.0020362
	LOSS [training: 0.2933136094973317 | validation: 0.20109083289365792]
	TIME [epoch: 8.53 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2603167903880884		[learning rate: 0.0020314]
	Learning Rate: 0.0020314
	LOSS [training: 0.2603167903880884 | validation: 0.22253977943878306]
	TIME [epoch: 8.52 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2852905143628259		[learning rate: 0.0020266]
	Learning Rate: 0.00202661
	LOSS [training: 0.2852905143628259 | validation: 0.2191115796834302]
	TIME [epoch: 8.51 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2586614688384635		[learning rate: 0.0020218]
	Learning Rate: 0.00202182
	LOSS [training: 0.2586614688384635 | validation: 0.7857476000388368]
	TIME [epoch: 8.51 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31123484677233676		[learning rate: 0.0020171]
	Learning Rate: 0.00201706
	LOSS [training: 0.31123484677233676 | validation: 0.1462871065863353]
	TIME [epoch: 8.53 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22919302248861975		[learning rate: 0.0020123]
	Learning Rate: 0.0020123
	LOSS [training: 0.22919302248861975 | validation: 0.3003744741778106]
	TIME [epoch: 8.52 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3447515710867253		[learning rate: 0.0020076]
	Learning Rate: 0.00200755
	LOSS [training: 0.3447515710867253 | validation: 0.23103155357904603]
	TIME [epoch: 8.51 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29826756863764203		[learning rate: 0.0020028]
	Learning Rate: 0.00200282
	LOSS [training: 0.29826756863764203 | validation: 0.2386836461590918]
	TIME [epoch: 8.51 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25939309352731		[learning rate: 0.0019981]
	Learning Rate: 0.00199809
	LOSS [training: 0.25939309352731 | validation: 0.24527752650444962]
	TIME [epoch: 8.53 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2375680199020777		[learning rate: 0.0019934]
	Learning Rate: 0.00199338
	LOSS [training: 0.2375680199020777 | validation: 0.17771469331604467]
	TIME [epoch: 8.51 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23511124597629282		[learning rate: 0.0019887]
	Learning Rate: 0.00198868
	LOSS [training: 0.23511124597629282 | validation: 0.21123431485890395]
	TIME [epoch: 8.51 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2098459361848938		[learning rate: 0.001984]
	Learning Rate: 0.00198399
	LOSS [training: 0.2098459361848938 | validation: 0.1601442675581075]
	TIME [epoch: 8.51 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24707212101805248		[learning rate: 0.0019793]
	Learning Rate: 0.00197931
	LOSS [training: 0.24707212101805248 | validation: 0.1612524840700132]
	TIME [epoch: 8.54 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24063052341197513		[learning rate: 0.0019746]
	Learning Rate: 0.00197464
	LOSS [training: 0.24063052341197513 | validation: 0.21802879509752804]
	TIME [epoch: 8.51 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19863034821406747		[learning rate: 0.00197]
	Learning Rate: 0.00196998
	LOSS [training: 0.19863034821406747 | validation: 0.16524889581725055]
	TIME [epoch: 8.51 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19539709954955867		[learning rate: 0.0019653]
	Learning Rate: 0.00196533
	LOSS [training: 0.19539709954955867 | validation: 0.17786905886123838]
	TIME [epoch: 8.52 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17890098695366563		[learning rate: 0.0019607]
	Learning Rate: 0.0019607
	LOSS [training: 0.17890098695366563 | validation: 0.12352303622269589]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_740.pth
	Model improved!!!
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1964315938380353		[learning rate: 0.0019561]
	Learning Rate: 0.00195607
	LOSS [training: 0.1964315938380353 | validation: 0.1567246426898608]
	TIME [epoch: 8.51 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18868075145681512		[learning rate: 0.0019515]
	Learning Rate: 0.00195146
	LOSS [training: 0.18868075145681512 | validation: 0.13341169027128447]
	TIME [epoch: 8.51 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16362868751025558		[learning rate: 0.0019469]
	Learning Rate: 0.00194685
	LOSS [training: 0.16362868751025558 | validation: 0.15983068522394064]
	TIME [epoch: 8.51 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2042023374120022		[learning rate: 0.0019423]
	Learning Rate: 0.00194226
	LOSS [training: 0.2042023374120022 | validation: 0.21127047536228677]
	TIME [epoch: 8.54 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17488722580185664		[learning rate: 0.0019377]
	Learning Rate: 0.00193768
	LOSS [training: 0.17488722580185664 | validation: 0.26643121530072755]
	TIME [epoch: 8.51 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1726631508341599		[learning rate: 0.0019331]
	Learning Rate: 0.00193311
	LOSS [training: 0.1726631508341599 | validation: 0.19999973275149824]
	TIME [epoch: 8.52 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17833539417139882		[learning rate: 0.0019285]
	Learning Rate: 0.00192855
	LOSS [training: 0.17833539417139882 | validation: 0.22063773586792879]
	TIME [epoch: 8.51 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24301115256509434		[learning rate: 0.001924]
	Learning Rate: 0.001924
	LOSS [training: 0.24301115256509434 | validation: 0.41624352562377215]
	TIME [epoch: 8.54 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24198217589466386		[learning rate: 0.0019195]
	Learning Rate: 0.00191946
	LOSS [training: 0.24198217589466386 | validation: 0.22988910065300805]
	TIME [epoch: 8.52 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20908780144623082		[learning rate: 0.0019149]
	Learning Rate: 0.00191493
	LOSS [training: 0.20908780144623082 | validation: 0.12922129914809757]
	TIME [epoch: 8.52 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16986149642009607		[learning rate: 0.0019104]
	Learning Rate: 0.00191042
	LOSS [training: 0.16986149642009607 | validation: 0.20257123412702394]
	TIME [epoch: 8.53 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2092714149347458		[learning rate: 0.0019059]
	Learning Rate: 0.00190591
	LOSS [training: 0.2092714149347458 | validation: 0.21611662447080815]
	TIME [epoch: 8.54 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17266882008021164		[learning rate: 0.0019014]
	Learning Rate: 0.00190141
	LOSS [training: 0.17266882008021164 | validation: 0.24833343609369485]
	TIME [epoch: 8.51 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2115399380074749		[learning rate: 0.0018969]
	Learning Rate: 0.00189693
	LOSS [training: 0.2115399380074749 | validation: 0.2418301101776545]
	TIME [epoch: 8.52 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17434014682853619		[learning rate: 0.0018925]
	Learning Rate: 0.00189246
	LOSS [training: 0.17434014682853619 | validation: 0.14498474516021131]
	TIME [epoch: 8.54 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18830265066967994		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.18830265066967994 | validation: 0.2255830355207285]
	TIME [epoch: 8.53 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1775082511488512		[learning rate: 0.0018835]
	Learning Rate: 0.00188354
	LOSS [training: 0.1775082511488512 | validation: 0.24410223351405452]
	TIME [epoch: 8.52 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23015465521069153		[learning rate: 0.0018791]
	Learning Rate: 0.00187909
	LOSS [training: 0.23015465521069153 | validation: 0.23827266084212095]
	TIME [epoch: 8.51 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2292632029698251		[learning rate: 0.0018747]
	Learning Rate: 0.00187466
	LOSS [training: 0.2292632029698251 | validation: 0.184632531867566]
	TIME [epoch: 8.53 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20403369558062803		[learning rate: 0.0018702]
	Learning Rate: 0.00187024
	LOSS [training: 0.20403369558062803 | validation: 0.19357245479920576]
	TIME [epoch: 8.52 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17635556034088837		[learning rate: 0.0018658]
	Learning Rate: 0.00186583
	LOSS [training: 0.17635556034088837 | validation: 0.15795513683395154]
	TIME [epoch: 8.51 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18718303869467456		[learning rate: 0.0018614]
	Learning Rate: 0.00186143
	LOSS [training: 0.18718303869467456 | validation: 0.15842895261920978]
	TIME [epoch: 8.51 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14102762099517152		[learning rate: 0.001857]
	Learning Rate: 0.00185704
	LOSS [training: 0.14102762099517152 | validation: 0.1630240551714236]
	TIME [epoch: 8.54 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1602017906842172		[learning rate: 0.0018527]
	Learning Rate: 0.00185266
	LOSS [training: 0.1602017906842172 | validation: 0.16732653263885328]
	TIME [epoch: 8.52 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15430347361456137		[learning rate: 0.0018483]
	Learning Rate: 0.00184829
	LOSS [training: 0.15430347361456137 | validation: 0.26544803864136485]
	TIME [epoch: 8.52 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16604069444854702		[learning rate: 0.0018439]
	Learning Rate: 0.00184393
	LOSS [training: 0.16604069444854702 | validation: 0.11466491485108468]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_766.pth
	Model improved!!!
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1611728951868776		[learning rate: 0.0018396]
	Learning Rate: 0.00183958
	LOSS [training: 0.1611728951868776 | validation: 0.1080887404593456]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_767.pth
	Model improved!!!
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1653476417686292		[learning rate: 0.0018352]
	Learning Rate: 0.00183524
	LOSS [training: 0.1653476417686292 | validation: 0.2700818141492609]
	TIME [epoch: 8.52 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2075325422899878		[learning rate: 0.0018309]
	Learning Rate: 0.00183091
	LOSS [training: 0.2075325422899878 | validation: 0.13695072161404345]
	TIME [epoch: 8.52 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17036278499592888		[learning rate: 0.0018266]
	Learning Rate: 0.00182659
	LOSS [training: 0.17036278499592888 | validation: 0.18981312110965984]
	TIME [epoch: 8.51 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17419255172356068		[learning rate: 0.0018223]
	Learning Rate: 0.00182228
	LOSS [training: 0.17419255172356068 | validation: 0.2492489086487016]
	TIME [epoch: 8.54 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1779586655381541		[learning rate: 0.001818]
	Learning Rate: 0.00181798
	LOSS [training: 0.1779586655381541 | validation: 0.1377713609228659]
	TIME [epoch: 8.52 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19970013676261517		[learning rate: 0.0018137]
	Learning Rate: 0.00181369
	LOSS [training: 0.19970013676261517 | validation: 0.1505791698096481]
	TIME [epoch: 8.52 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1771394667918167		[learning rate: 0.0018094]
	Learning Rate: 0.00180942
	LOSS [training: 0.1771394667918167 | validation: 0.29405650193868915]
	TIME [epoch: 8.52 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18204596670442041		[learning rate: 0.0018051]
	Learning Rate: 0.00180515
	LOSS [training: 0.18204596670442041 | validation: 0.16823900554695853]
	TIME [epoch: 8.54 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18261716597522087		[learning rate: 0.0018009]
	Learning Rate: 0.00180089
	LOSS [training: 0.18261716597522087 | validation: 0.12323961125048928]
	TIME [epoch: 8.52 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20026927634494335		[learning rate: 0.0017966]
	Learning Rate: 0.00179664
	LOSS [training: 0.20026927634494335 | validation: 0.24022267555832233]
	TIME [epoch: 8.52 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18500716115899737		[learning rate: 0.0017924]
	Learning Rate: 0.0017924
	LOSS [training: 0.18500716115899737 | validation: 0.14434179025970212]
	TIME [epoch: 8.52 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17866626472451874		[learning rate: 0.0017882]
	Learning Rate: 0.00178818
	LOSS [training: 0.17866626472451874 | validation: 0.2055125983282866]
	TIME [epoch: 8.54 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19261631374594665		[learning rate: 0.001784]
	Learning Rate: 0.00178396
	LOSS [training: 0.19261631374594665 | validation: 0.30553191328966445]
	TIME [epoch: 8.52 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18735083429865537		[learning rate: 0.0017797]
	Learning Rate: 0.00177975
	LOSS [training: 0.18735083429865537 | validation: 0.10334171213937543]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_781.pth
	Model improved!!!
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19149541815314003		[learning rate: 0.0017756]
	Learning Rate: 0.00177555
	LOSS [training: 0.19149541815314003 | validation: 0.16641428819210918]
	TIME [epoch: 8.54 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18858791050700216		[learning rate: 0.0017714]
	Learning Rate: 0.00177136
	LOSS [training: 0.18858791050700216 | validation: 0.16314138412136842]
	TIME [epoch: 8.52 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21630861159869466		[learning rate: 0.0017672]
	Learning Rate: 0.00176719
	LOSS [training: 0.21630861159869466 | validation: 0.18147496646098465]
	TIME [epoch: 8.51 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20745990134113254		[learning rate: 0.001763]
	Learning Rate: 0.00176302
	LOSS [training: 0.20745990134113254 | validation: 0.24185031824829317]
	TIME [epoch: 8.52 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21973253842940185		[learning rate: 0.0017589]
	Learning Rate: 0.00175886
	LOSS [training: 0.21973253842940185 | validation: 0.12107724851763962]
	TIME [epoch: 8.53 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22504645423971067		[learning rate: 0.0017547]
	Learning Rate: 0.00175471
	LOSS [training: 0.22504645423971067 | validation: 0.21904731098671348]
	TIME [epoch: 8.53 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2119977951479784		[learning rate: 0.0017506]
	Learning Rate: 0.00175057
	LOSS [training: 0.2119977951479784 | validation: 0.1974329539617808]
	TIME [epoch: 8.51 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18231972054893503		[learning rate: 0.0017464]
	Learning Rate: 0.00174644
	LOSS [training: 0.18231972054893503 | validation: 0.18091972334901663]
	TIME [epoch: 8.51 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18331041709185963		[learning rate: 0.0017423]
	Learning Rate: 0.00174232
	LOSS [training: 0.18331041709185963 | validation: 0.25297472324070236]
	TIME [epoch: 8.53 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20856274596018115		[learning rate: 0.0017382]
	Learning Rate: 0.00173821
	LOSS [training: 0.20856274596018115 | validation: 0.16191715709807541]
	TIME [epoch: 8.52 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17454459901904074		[learning rate: 0.0017341]
	Learning Rate: 0.00173411
	LOSS [training: 0.17454459901904074 | validation: 0.17650438586976386]
	TIME [epoch: 8.51 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16366304495956438		[learning rate: 0.00173]
	Learning Rate: 0.00173002
	LOSS [training: 0.16366304495956438 | validation: 0.18956236641873891]
	TIME [epoch: 8.51 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2008944575065518		[learning rate: 0.0017259]
	Learning Rate: 0.00172594
	LOSS [training: 0.2008944575065518 | validation: 0.1506916354263994]
	TIME [epoch: 8.54 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19660857315558353		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.19660857315558353 | validation: 0.19617768855225182]
	TIME [epoch: 8.51 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17877760920218802		[learning rate: 0.0017178]
	Learning Rate: 0.00171781
	LOSS [training: 0.17877760920218802 | validation: 0.20460620142310987]
	TIME [epoch: 8.51 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2240599970373393		[learning rate: 0.0017138]
	Learning Rate: 0.00171375
	LOSS [training: 0.2240599970373393 | validation: 0.16821720285351846]
	TIME [epoch: 8.52 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21975834526799728		[learning rate: 0.0017097]
	Learning Rate: 0.00170971
	LOSS [training: 0.21975834526799728 | validation: 0.17016062692384687]
	TIME [epoch: 8.53 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21381521324957148		[learning rate: 0.0017057]
	Learning Rate: 0.00170568
	LOSS [training: 0.21381521324957148 | validation: 0.20107767961947648]
	TIME [epoch: 8.52 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2195035785755778		[learning rate: 0.0017017]
	Learning Rate: 0.00170166
	LOSS [training: 0.2195035785755778 | validation: 0.2168841292381749]
	TIME [epoch: 8.52 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1737253935767221		[learning rate: 0.0016976]
	Learning Rate: 0.00169764
	LOSS [training: 0.1737253935767221 | validation: 0.24523672793239876]
	TIME [epoch: 8.52 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18613203196650172		[learning rate: 0.0016936]
	Learning Rate: 0.00169364
	LOSS [training: 0.18613203196650172 | validation: 0.1486187510815299]
	TIME [epoch: 8.54 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18659070696551877		[learning rate: 0.0016896]
	Learning Rate: 0.00168964
	LOSS [training: 0.18659070696551877 | validation: 0.16705878295365198]
	TIME [epoch: 8.52 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18830834302047963		[learning rate: 0.0016857]
	Learning Rate: 0.00168566
	LOSS [training: 0.18830834302047963 | validation: 0.1310823607977517]
	TIME [epoch: 8.52 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17405211985873423		[learning rate: 0.0016817]
	Learning Rate: 0.00168168
	LOSS [training: 0.17405211985873423 | validation: 0.2613587104536057]
	TIME [epoch: 8.51 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23877095047091218		[learning rate: 0.0016777]
	Learning Rate: 0.00167771
	LOSS [training: 0.23877095047091218 | validation: 0.24020910533786505]
	TIME [epoch: 8.54 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25684358351195063		[learning rate: 0.0016738]
	Learning Rate: 0.00167376
	LOSS [training: 0.25684358351195063 | validation: 0.1549336994549464]
	TIME [epoch: 8.51 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26398856709257335		[learning rate: 0.0016698]
	Learning Rate: 0.00166981
	LOSS [training: 0.26398856709257335 | validation: 0.25732294851121185]
	TIME [epoch: 8.52 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22908434598456298		[learning rate: 0.0016659]
	Learning Rate: 0.00166587
	LOSS [training: 0.22908434598456298 | validation: 0.2032086752736011]
	TIME [epoch: 8.52 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2278580915008385		[learning rate: 0.0016619]
	Learning Rate: 0.00166194
	LOSS [training: 0.2278580915008385 | validation: 0.1947524511129331]
	TIME [epoch: 8.53 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21928208127305684		[learning rate: 0.001658]
	Learning Rate: 0.00165802
	LOSS [training: 0.21928208127305684 | validation: 0.16809351054007032]
	TIME [epoch: 8.51 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18095338276158815		[learning rate: 0.0016541]
	Learning Rate: 0.00165411
	LOSS [training: 0.18095338276158815 | validation: 0.15753137856927502]
	TIME [epoch: 8.51 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20007696877354975		[learning rate: 0.0016502]
	Learning Rate: 0.00165021
	LOSS [training: 0.20007696877354975 | validation: 0.17469714067189313]
	TIME [epoch: 8.53 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20968539170365638		[learning rate: 0.0016463]
	Learning Rate: 0.00164631
	LOSS [training: 0.20968539170365638 | validation: 0.17304730751909153]
	TIME [epoch: 8.53 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1638184919403062		[learning rate: 0.0016424]
	Learning Rate: 0.00164243
	LOSS [training: 0.1638184919403062 | validation: 0.46387606552638083]
	TIME [epoch: 8.51 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22771565682253833		[learning rate: 0.0016386]
	Learning Rate: 0.00163856
	LOSS [training: 0.22771565682253833 | validation: 0.17649814444321127]
	TIME [epoch: 8.51 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21095338911349898		[learning rate: 0.0016347]
	Learning Rate: 0.00163469
	LOSS [training: 0.21095338911349898 | validation: 0.1595737316804965]
	TIME [epoch: 8.53 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13350964724653608		[learning rate: 0.0016308]
	Learning Rate: 0.00163084
	LOSS [training: 0.13350964724653608 | validation: 0.19453286411794102]
	TIME [epoch: 8.52 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17174190023754657		[learning rate: 0.001627]
	Learning Rate: 0.00162699
	LOSS [training: 0.17174190023754657 | validation: 0.2091943284916124]
	TIME [epoch: 8.52 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1764135393502985		[learning rate: 0.0016232]
	Learning Rate: 0.00162315
	LOSS [training: 0.1764135393502985 | validation: 0.17160629083964674]
	TIME [epoch: 8.52 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1478192031773496		[learning rate: 0.0016193]
	Learning Rate: 0.00161932
	LOSS [training: 0.1478192031773496 | validation: 0.1886344549528962]
	TIME [epoch: 8.54 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20410041047167155		[learning rate: 0.0016155]
	Learning Rate: 0.0016155
	LOSS [training: 0.20410041047167155 | validation: 0.14759967573285196]
	TIME [epoch: 8.53 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17307965427642366		[learning rate: 0.0016117]
	Learning Rate: 0.00161169
	LOSS [training: 0.17307965427642366 | validation: 0.14022320151640894]
	TIME [epoch: 8.52 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1410183447180144		[learning rate: 0.0016079]
	Learning Rate: 0.00160789
	LOSS [training: 0.1410183447180144 | validation: 0.19019046056474462]
	TIME [epoch: 8.51 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16319528720606818		[learning rate: 0.0016041]
	Learning Rate: 0.0016041
	LOSS [training: 0.16319528720606818 | validation: 0.12227782436404622]
	TIME [epoch: 8.54 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17509189093898128		[learning rate: 0.0016003]
	Learning Rate: 0.00160031
	LOSS [training: 0.17509189093898128 | validation: 0.12207895550350496]
	TIME [epoch: 8.52 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17616545957228352		[learning rate: 0.0015965]
	Learning Rate: 0.00159654
	LOSS [training: 0.17616545957228352 | validation: 0.16183268222161523]
	TIME [epoch: 8.52 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1822965495643219		[learning rate: 0.0015928]
	Learning Rate: 0.00159277
	LOSS [training: 0.1822965495643219 | validation: 0.16047721992037312]
	TIME [epoch: 8.51 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16246663325006083		[learning rate: 0.001589]
	Learning Rate: 0.00158902
	LOSS [training: 0.16246663325006083 | validation: 0.13403095751493938]
	TIME [epoch: 8.54 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.158309446483545		[learning rate: 0.0015853]
	Learning Rate: 0.00158527
	LOSS [training: 0.158309446483545 | validation: 0.20260593602383958]
	TIME [epoch: 8.52 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1808524496343486		[learning rate: 0.0015815]
	Learning Rate: 0.00158153
	LOSS [training: 0.1808524496343486 | validation: 0.18399089114765987]
	TIME [epoch: 8.52 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12692541607641974		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.12692541607641974 | validation: 0.11390414752262396]
	TIME [epoch: 8.52 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16673350236958168		[learning rate: 0.0015741]
	Learning Rate: 0.00157408
	LOSS [training: 0.16673350236958168 | validation: 0.16771824956674453]
	TIME [epoch: 8.54 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2279472041559485		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.2279472041559485 | validation: 0.2552567021022145]
	TIME [epoch: 8.52 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13383879911839203		[learning rate: 0.0015667]
	Learning Rate: 0.00156666
	LOSS [training: 0.13383879911839203 | validation: 0.12654192595703914]
	TIME [epoch: 8.51 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15176852364448212		[learning rate: 0.001563]
	Learning Rate: 0.00156296
	LOSS [training: 0.15176852364448212 | validation: 0.19051964809780308]
	TIME [epoch: 8.51 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1897230813894964		[learning rate: 0.0015593]
	Learning Rate: 0.00155928
	LOSS [training: 0.1897230813894964 | validation: 0.1577763168253191]
	TIME [epoch: 8.54 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14764427091107646		[learning rate: 0.0015556]
	Learning Rate: 0.0015556
	LOSS [training: 0.14764427091107646 | validation: 0.15167465164291283]
	TIME [epoch: 8.51 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14975086255471282		[learning rate: 0.0015519]
	Learning Rate: 0.00155193
	LOSS [training: 0.14975086255471282 | validation: 0.23496156360523018]
	TIME [epoch: 8.51 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21330011956297365		[learning rate: 0.0015483]
	Learning Rate: 0.00154827
	LOSS [training: 0.21330011956297365 | validation: 0.1633175265538791]
	TIME [epoch: 8.51 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1950230189730648		[learning rate: 0.0015446]
	Learning Rate: 0.00154462
	LOSS [training: 0.1950230189730648 | validation: 0.16090124973629466]
	TIME [epoch: 8.54 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19625437168904064		[learning rate: 0.001541]
	Learning Rate: 0.00154097
	LOSS [training: 0.19625437168904064 | validation: 0.19028393057367676]
	TIME [epoch: 8.51 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17010854376204051		[learning rate: 0.0015373]
	Learning Rate: 0.00153734
	LOSS [training: 0.17010854376204051 | validation: 0.15258350774312873]
	TIME [epoch: 8.51 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16345616292143686		[learning rate: 0.0015337]
	Learning Rate: 0.00153371
	LOSS [training: 0.16345616292143686 | validation: 0.12788784749070378]
	TIME [epoch: 8.51 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15533768157625488		[learning rate: 0.0015301]
	Learning Rate: 0.00153009
	LOSS [training: 0.15533768157625488 | validation: 0.21417455702486315]
	TIME [epoch: 8.53 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22349929662527285		[learning rate: 0.0015265]
	Learning Rate: 0.00152648
	LOSS [training: 0.22349929662527285 | validation: 0.17881154308534736]
	TIME [epoch: 8.51 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18132970096022166		[learning rate: 0.0015229]
	Learning Rate: 0.00152288
	LOSS [training: 0.18132970096022166 | validation: 0.2374515691293545]
	TIME [epoch: 8.52 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16079185325604034		[learning rate: 0.0015193]
	Learning Rate: 0.00151929
	LOSS [training: 0.16079185325604034 | validation: 0.11849966616364309]
	TIME [epoch: 8.52 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1690517677401862		[learning rate: 0.0015157]
	Learning Rate: 0.00151571
	LOSS [training: 0.1690517677401862 | validation: 0.11819477878653425]
	TIME [epoch: 8.53 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21531439705820787		[learning rate: 0.0015121]
	Learning Rate: 0.00151213
	LOSS [training: 0.21531439705820787 | validation: 0.265549669870054]
	TIME [epoch: 8.51 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17636022824032854		[learning rate: 0.0015086]
	Learning Rate: 0.00150857
	LOSS [training: 0.17636022824032854 | validation: 0.1400030890981384]
	TIME [epoch: 8.51 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18903995239709587		[learning rate: 0.001505]
	Learning Rate: 0.00150501
	LOSS [training: 0.18903995239709587 | validation: 0.1703484100995264]
	TIME [epoch: 8.53 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1860594058317649		[learning rate: 0.0015015]
	Learning Rate: 0.00150146
	LOSS [training: 0.1860594058317649 | validation: 0.1419606760200264]
	TIME [epoch: 8.52 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1709185798139913		[learning rate: 0.0014979]
	Learning Rate: 0.00149791
	LOSS [training: 0.1709185798139913 | validation: 0.15554106452936323]
	TIME [epoch: 8.51 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17549251973692176		[learning rate: 0.0014944]
	Learning Rate: 0.00149438
	LOSS [training: 0.17549251973692176 | validation: 0.20155999638435007]
	TIME [epoch: 8.51 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18781416078654		[learning rate: 0.0014909]
	Learning Rate: 0.00149086
	LOSS [training: 0.18781416078654 | validation: 0.19772219385204956]
	TIME [epoch: 8.53 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19999623091542784		[learning rate: 0.0014873]
	Learning Rate: 0.00148734
	LOSS [training: 0.19999623091542784 | validation: 0.18115875888476757]
	TIME [epoch: 8.52 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23609129512247415		[learning rate: 0.0014838]
	Learning Rate: 0.00148383
	LOSS [training: 0.23609129512247415 | validation: 0.19570849054904907]
	TIME [epoch: 8.51 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1485247269385665		[learning rate: 0.0014803]
	Learning Rate: 0.00148033
	LOSS [training: 0.1485247269385665 | validation: 0.16139965426791292]
	TIME [epoch: 8.51 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17878511723285218		[learning rate: 0.0014768]
	Learning Rate: 0.00147684
	LOSS [training: 0.17878511723285218 | validation: 0.24641789936984498]
	TIME [epoch: 8.53 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16962662968722184		[learning rate: 0.0014734]
	Learning Rate: 0.00147336
	LOSS [training: 0.16962662968722184 | validation: 0.17716350165353567]
	TIME [epoch: 8.51 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1531976583452901		[learning rate: 0.0014699]
	Learning Rate: 0.00146988
	LOSS [training: 0.1531976583452901 | validation: 0.1158607228658898]
	TIME [epoch: 8.51 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16977294766253484		[learning rate: 0.0014664]
	Learning Rate: 0.00146641
	LOSS [training: 0.16977294766253484 | validation: 0.13691473950797686]
	TIME [epoch: 8.51 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17072784048032158		[learning rate: 0.001463]
	Learning Rate: 0.00146295
	LOSS [training: 0.17072784048032158 | validation: 0.15746218564612796]
	TIME [epoch: 8.53 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14450309738131542		[learning rate: 0.0014595]
	Learning Rate: 0.0014595
	LOSS [training: 0.14450309738131542 | validation: 0.140352748521294]
	TIME [epoch: 8.51 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15966805722616767		[learning rate: 0.0014561]
	Learning Rate: 0.00145606
	LOSS [training: 0.15966805722616767 | validation: 0.19627928095286812]
	TIME [epoch: 8.51 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18041622539093077		[learning rate: 0.0014526]
	Learning Rate: 0.00145263
	LOSS [training: 0.18041622539093077 | validation: 0.32262496785268346]
	TIME [epoch: 8.51 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18077733034179552		[learning rate: 0.0014492]
	Learning Rate: 0.0014492
	LOSS [training: 0.18077733034179552 | validation: 0.10715289372950731]
	TIME [epoch: 8.54 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1484720145888942		[learning rate: 0.0014458]
	Learning Rate: 0.00144578
	LOSS [training: 0.1484720145888942 | validation: 0.13090191542306723]
	TIME [epoch: 8.52 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1289756321330723		[learning rate: 0.0014424]
	Learning Rate: 0.00144237
	LOSS [training: 0.1289756321330723 | validation: 0.25839806323939873]
	TIME [epoch: 8.51 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1651542291710002		[learning rate: 0.001439]
	Learning Rate: 0.00143897
	LOSS [training: 0.1651542291710002 | validation: 0.1389996577186008]
	TIME [epoch: 8.51 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1548297416733666		[learning rate: 0.0014356]
	Learning Rate: 0.00143557
	LOSS [training: 0.1548297416733666 | validation: 0.08623543744344844]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_872.pth
	Model improved!!!
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14112840778170374		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.14112840778170374 | validation: 0.17999148359374176]
	TIME [epoch: 8.52 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13214367524885112		[learning rate: 0.0014288]
	Learning Rate: 0.00142881
	LOSS [training: 0.13214367524885112 | validation: 0.13379937335489822]
	TIME [epoch: 8.52 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1316671208892289		[learning rate: 0.0014254]
	Learning Rate: 0.00142544
	LOSS [training: 0.1316671208892289 | validation: 0.1332697277100235]
	TIME [epoch: 8.52 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1178778170942136		[learning rate: 0.0014221]
	Learning Rate: 0.00142208
	LOSS [training: 0.1178778170942136 | validation: 0.12521203365555406]
	TIME [epoch: 8.54 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13417315043577782		[learning rate: 0.0014187]
	Learning Rate: 0.00141872
	LOSS [training: 0.13417315043577782 | validation: 0.29144790298889267]
	TIME [epoch: 8.52 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1788088762793243		[learning rate: 0.0014154]
	Learning Rate: 0.00141538
	LOSS [training: 0.1788088762793243 | validation: 0.16028289077502503]
	TIME [epoch: 8.52 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1459640033459724		[learning rate: 0.001412]
	Learning Rate: 0.00141204
	LOSS [training: 0.1459640033459724 | validation: 0.2076220005195019]
	TIME [epoch: 8.53 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15303696469673836		[learning rate: 0.0014087]
	Learning Rate: 0.00140871
	LOSS [training: 0.15303696469673836 | validation: 0.09845371513636883]
	TIME [epoch: 8.53 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.128030630437189		[learning rate: 0.0014054]
	Learning Rate: 0.00140538
	LOSS [training: 0.128030630437189 | validation: 0.20729350310915334]
	TIME [epoch: 8.52 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18314628695155172		[learning rate: 0.0014021]
	Learning Rate: 0.00140207
	LOSS [training: 0.18314628695155172 | validation: 0.12080563930020198]
	TIME [epoch: 8.52 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17188870479297105		[learning rate: 0.0013988]
	Learning Rate: 0.00139876
	LOSS [training: 0.17188870479297105 | validation: 0.11564391190539275]
	TIME [epoch: 8.54 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18292183591030703		[learning rate: 0.0013955]
	Learning Rate: 0.00139546
	LOSS [training: 0.18292183591030703 | validation: 0.24953873943874413]
	TIME [epoch: 8.52 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16640159966143375		[learning rate: 0.0013922]
	Learning Rate: 0.00139217
	LOSS [training: 0.16640159966143375 | validation: 0.12730258470492675]
	TIME [epoch: 8.52 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14681347889474036		[learning rate: 0.0013889]
	Learning Rate: 0.00138889
	LOSS [training: 0.14681347889474036 | validation: 0.15507303568842193]
	TIME [epoch: 8.52 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16260239809260374		[learning rate: 0.0013856]
	Learning Rate: 0.00138561
	LOSS [training: 0.16260239809260374 | validation: 0.1593513335807351]
	TIME [epoch: 8.54 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1592384005854716		[learning rate: 0.0013823]
	Learning Rate: 0.00138234
	LOSS [training: 0.1592384005854716 | validation: 0.1581845756327733]
	TIME [epoch: 8.52 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12912983121679897		[learning rate: 0.0013791]
	Learning Rate: 0.00137908
	LOSS [training: 0.12912983121679897 | validation: 0.15574531083173904]
	TIME [epoch: 8.52 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1356734496525766		[learning rate: 0.0013758]
	Learning Rate: 0.00137583
	LOSS [training: 0.1356734496525766 | validation: 0.16070026613499017]
	TIME [epoch: 8.52 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18882263652201609		[learning rate: 0.0013726]
	Learning Rate: 0.00137258
	LOSS [training: 0.18882263652201609 | validation: 0.13997130546984407]
	TIME [epoch: 8.54 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17853663416603757		[learning rate: 0.0013693]
	Learning Rate: 0.00136934
	LOSS [training: 0.17853663416603757 | validation: 0.16351087314764368]
	TIME [epoch: 8.52 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15274627847014874		[learning rate: 0.0013661]
	Learning Rate: 0.00136611
	LOSS [training: 0.15274627847014874 | validation: 0.1354735881856023]
	TIME [epoch: 8.52 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1399033185468913		[learning rate: 0.0013629]
	Learning Rate: 0.00136289
	LOSS [training: 0.1399033185468913 | validation: 0.18943607771590082]
	TIME [epoch: 8.52 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15920354213295518		[learning rate: 0.0013597]
	Learning Rate: 0.00135968
	LOSS [training: 0.15920354213295518 | validation: 0.10702262585122535]
	TIME [epoch: 8.54 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15005081441433304		[learning rate: 0.0013565]
	Learning Rate: 0.00135647
	LOSS [training: 0.15005081441433304 | validation: 0.09895692931368653]
	TIME [epoch: 8.52 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1338078148973696		[learning rate: 0.0013533]
	Learning Rate: 0.00135327
	LOSS [training: 0.1338078148973696 | validation: 0.19963134763520052]
	TIME [epoch: 8.52 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18491100868885899		[learning rate: 0.0013501]
	Learning Rate: 0.00135008
	LOSS [training: 0.18491100868885899 | validation: 0.20064464152477723]
	TIME [epoch: 8.52 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18922816202774834		[learning rate: 0.0013469]
	Learning Rate: 0.00134689
	LOSS [training: 0.18922816202774834 | validation: 0.21340933630687547]
	TIME [epoch: 8.54 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17712003110074542		[learning rate: 0.0013437]
	Learning Rate: 0.00134372
	LOSS [training: 0.17712003110074542 | validation: 0.35825518021729497]
	TIME [epoch: 8.52 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2493947912998013		[learning rate: 0.0013405]
	Learning Rate: 0.00134055
	LOSS [training: 0.2493947912998013 | validation: 0.24099753018556547]
	TIME [epoch: 8.52 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18056157399952152		[learning rate: 0.0013374]
	Learning Rate: 0.00133738
	LOSS [training: 0.18056157399952152 | validation: 0.25559167574194186]
	TIME [epoch: 8.52 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1757627895630866		[learning rate: 0.0013342]
	Learning Rate: 0.00133423
	LOSS [training: 0.1757627895630866 | validation: 0.21364395270864062]
	TIME [epoch: 8.54 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1841832697060176		[learning rate: 0.0013311]
	Learning Rate: 0.00133108
	LOSS [training: 0.1841832697060176 | validation: 0.1574998255290589]
	TIME [epoch: 8.51 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1700865059371776		[learning rate: 0.0013279]
	Learning Rate: 0.00132794
	LOSS [training: 0.1700865059371776 | validation: 0.27804016702643614]
	TIME [epoch: 8.52 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19557993798883472		[learning rate: 0.0013248]
	Learning Rate: 0.00132481
	LOSS [training: 0.19557993798883472 | validation: 0.15689910010129604]
	TIME [epoch: 8.51 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1599318528280877		[learning rate: 0.0013217]
	Learning Rate: 0.00132169
	LOSS [training: 0.1599318528280877 | validation: 0.1262364959003024]
	TIME [epoch: 8.54 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15314094290215324		[learning rate: 0.0013186]
	Learning Rate: 0.00131857
	LOSS [training: 0.15314094290215324 | validation: 0.19087801916349384]
	TIME [epoch: 8.52 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1784389374118054		[learning rate: 0.0013155]
	Learning Rate: 0.00131546
	LOSS [training: 0.1784389374118054 | validation: 0.14568731887941117]
	TIME [epoch: 8.52 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16355108831587567		[learning rate: 0.0013124]
	Learning Rate: 0.00131235
	LOSS [training: 0.16355108831587567 | validation: 0.15934047409445012]
	TIME [epoch: 8.52 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1622024011490239		[learning rate: 0.0013093]
	Learning Rate: 0.00130926
	LOSS [training: 0.1622024011490239 | validation: 0.16040270582104924]
	TIME [epoch: 8.54 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14875897834165325		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.14875897834165325 | validation: 0.11595103991259958]
	TIME [epoch: 8.52 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12665816113833236		[learning rate: 0.0013031]
	Learning Rate: 0.00130309
	LOSS [training: 0.12665816113833236 | validation: 0.12220418580554313]
	TIME [epoch: 8.52 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19083485627075536		[learning rate: 0.0013]
	Learning Rate: 0.00130002
	LOSS [training: 0.19083485627075536 | validation: 0.15324435385366347]
	TIME [epoch: 8.54 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1522687852993974		[learning rate: 0.0012969]
	Learning Rate: 0.00129695
	LOSS [training: 0.1522687852993974 | validation: 0.1275403704549416]
	TIME [epoch: 8.52 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15240504474074767		[learning rate: 0.0012939]
	Learning Rate: 0.00129389
	LOSS [training: 0.15240504474074767 | validation: 0.10209079630437265]
	TIME [epoch: 8.52 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18196583378528206		[learning rate: 0.0012908]
	Learning Rate: 0.00129084
	LOSS [training: 0.18196583378528206 | validation: 0.14704297028149638]
	TIME [epoch: 8.52 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13427281765698124		[learning rate: 0.0012878]
	Learning Rate: 0.00128779
	LOSS [training: 0.13427281765698124 | validation: 0.20579769910425533]
	TIME [epoch: 8.54 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13162560776981114		[learning rate: 0.0012848]
	Learning Rate: 0.00128476
	LOSS [training: 0.13162560776981114 | validation: 0.14329127853698337]
	TIME [epoch: 8.53 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15916878726629352		[learning rate: 0.0012817]
	Learning Rate: 0.00128173
	LOSS [training: 0.15916878726629352 | validation: 0.16305898471909025]
	TIME [epoch: 8.52 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1619139689329561		[learning rate: 0.0012787]
	Learning Rate: 0.0012787
	LOSS [training: 0.1619139689329561 | validation: 0.12389897350051204]
	TIME [epoch: 8.52 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.148969940085418		[learning rate: 0.0012757]
	Learning Rate: 0.00127569
	LOSS [training: 0.148969940085418 | validation: 0.1457414049147139]
	TIME [epoch: 8.54 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17294419024608276		[learning rate: 0.0012727]
	Learning Rate: 0.00127268
	LOSS [training: 0.17294419024608276 | validation: 0.25049138555452044]
	TIME [epoch: 8.52 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23819041848602973		[learning rate: 0.0012697]
	Learning Rate: 0.00126967
	LOSS [training: 0.23819041848602973 | validation: 0.17878068725507884]
	TIME [epoch: 8.51 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20018215614271712		[learning rate: 0.0012667]
	Learning Rate: 0.00126668
	LOSS [training: 0.20018215614271712 | validation: 0.1975254482835041]
	TIME [epoch: 8.52 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17927650939398504		[learning rate: 0.0012637]
	Learning Rate: 0.00126369
	LOSS [training: 0.17927650939398504 | validation: 0.12288117314364122]
	TIME [epoch: 8.54 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1445419201742617		[learning rate: 0.0012607]
	Learning Rate: 0.00126071
	LOSS [training: 0.1445419201742617 | validation: 0.1229881175687626]
	TIME [epoch: 8.52 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14694148146338157		[learning rate: 0.0012577]
	Learning Rate: 0.00125774
	LOSS [training: 0.14694148146338157 | validation: 0.1319621327279756]
	TIME [epoch: 8.51 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1483624553293899		[learning rate: 0.0012548]
	Learning Rate: 0.00125477
	LOSS [training: 0.1483624553293899 | validation: 0.12292780823294452]
	TIME [epoch: 8.51 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1469072708517479		[learning rate: 0.0012518]
	Learning Rate: 0.00125181
	LOSS [training: 0.1469072708517479 | validation: 0.11985132890022905]
	TIME [epoch: 8.53 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14129349224993862		[learning rate: 0.0012489]
	Learning Rate: 0.00124886
	LOSS [training: 0.14129349224993862 | validation: 0.13218409688273294]
	TIME [epoch: 8.52 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1224338310703125		[learning rate: 0.0012459]
	Learning Rate: 0.00124591
	LOSS [training: 0.1224338310703125 | validation: 0.09949240055344039]
	TIME [epoch: 8.51 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13123425207089714		[learning rate: 0.001243]
	Learning Rate: 0.00124297
	LOSS [training: 0.13123425207089714 | validation: 0.13837478575472004]
	TIME [epoch: 8.52 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.133453339349144		[learning rate: 0.00124]
	Learning Rate: 0.00124004
	LOSS [training: 0.133453339349144 | validation: 0.18313297943481815]
	TIME [epoch: 8.54 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19679388666448155		[learning rate: 0.0012371]
	Learning Rate: 0.00123712
	LOSS [training: 0.19679388666448155 | validation: 0.11294618431546738]
	TIME [epoch: 8.52 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12958636997078019		[learning rate: 0.0012342]
	Learning Rate: 0.0012342
	LOSS [training: 0.12958636997078019 | validation: 0.1343775944080453]
	TIME [epoch: 8.52 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12563367708803022		[learning rate: 0.0012313]
	Learning Rate: 0.00123129
	LOSS [training: 0.12563367708803022 | validation: 0.12225872355530955]
	TIME [epoch: 8.51 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12683826416410474		[learning rate: 0.0012284]
	Learning Rate: 0.00122838
	LOSS [training: 0.12683826416410474 | validation: 0.1454956213699613]
	TIME [epoch: 8.54 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13977052922861544		[learning rate: 0.0012255]
	Learning Rate: 0.00122548
	LOSS [training: 0.13977052922861544 | validation: 0.12754722395942955]
	TIME [epoch: 8.51 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13415518012095967		[learning rate: 0.0012226]
	Learning Rate: 0.00122259
	LOSS [training: 0.13415518012095967 | validation: 0.13450396731829606]
	TIME [epoch: 8.52 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15482724113196772		[learning rate: 0.0012197]
	Learning Rate: 0.00121971
	LOSS [training: 0.15482724113196772 | validation: 0.312046919996726]
	TIME [epoch: 8.51 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18750830777370672		[learning rate: 0.0012168]
	Learning Rate: 0.00121683
	LOSS [training: 0.18750830777370672 | validation: 0.22949830476306599]
	TIME [epoch: 8.54 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1552344709182198		[learning rate: 0.001214]
	Learning Rate: 0.00121396
	LOSS [training: 0.1552344709182198 | validation: 0.1302094841313208]
	TIME [epoch: 8.52 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12350122154125094		[learning rate: 0.0012111]
	Learning Rate: 0.0012111
	LOSS [training: 0.12350122154125094 | validation: 0.11824301054012162]
	TIME [epoch: 8.51 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12894005064997485		[learning rate: 0.0012082]
	Learning Rate: 0.00120824
	LOSS [training: 0.12894005064997485 | validation: 0.09279553514507954]
	TIME [epoch: 8.52 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11149639825262773		[learning rate: 0.0012054]
	Learning Rate: 0.00120539
	LOSS [training: 0.11149639825262773 | validation: 0.1608728705264872]
	TIME [epoch: 8.53 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11823925704574616		[learning rate: 0.0012025]
	Learning Rate: 0.00120255
	LOSS [training: 0.11823925704574616 | validation: 0.14977531864105376]
	TIME [epoch: 8.52 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11621277585891095		[learning rate: 0.0011997]
	Learning Rate: 0.00119971
	LOSS [training: 0.11621277585891095 | validation: 0.15511072911162688]
	TIME [epoch: 8.52 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1422507703901421		[learning rate: 0.0011969]
	Learning Rate: 0.00119688
	LOSS [training: 0.1422507703901421 | validation: 0.1296788510488776]
	TIME [epoch: 8.53 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13033314466834067		[learning rate: 0.0011941]
	Learning Rate: 0.00119406
	LOSS [training: 0.13033314466834067 | validation: 0.16789636495527543]
	TIME [epoch: 8.52 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16205375561643992		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.16205375561643992 | validation: 0.15599195349646477]
	TIME [epoch: 8.51 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15365570404857276		[learning rate: 0.0011884]
	Learning Rate: 0.00118843
	LOSS [training: 0.15365570404857276 | validation: 0.14551900199837053]
	TIME [epoch: 8.52 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15702098806029685		[learning rate: 0.0011856]
	Learning Rate: 0.00118563
	LOSS [training: 0.15702098806029685 | validation: 0.16004096216788138]
	TIME [epoch: 8.53 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15444815829861683		[learning rate: 0.0011828]
	Learning Rate: 0.00118283
	LOSS [training: 0.15444815829861683 | validation: 0.12582336897758106]
	TIME [epoch: 8.52 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13281565408196966		[learning rate: 0.00118]
	Learning Rate: 0.00118004
	LOSS [training: 0.13281565408196966 | validation: 0.1876664810036331]
	TIME [epoch: 8.51 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16318549331564403		[learning rate: 0.0011773]
	Learning Rate: 0.00117726
	LOSS [training: 0.16318549331564403 | validation: 0.12006423817680015]
	TIME [epoch: 8.51 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15939118479017136		[learning rate: 0.0011745]
	Learning Rate: 0.00117448
	LOSS [training: 0.15939118479017136 | validation: 0.16444972660352117]
	TIME [epoch: 8.53 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16827038433398206		[learning rate: 0.0011717]
	Learning Rate: 0.00117171
	LOSS [training: 0.16827038433398206 | validation: 0.152007114796599]
	TIME [epoch: 8.51 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12851077967040375		[learning rate: 0.0011689]
	Learning Rate: 0.00116895
	LOSS [training: 0.12851077967040375 | validation: 0.1526822067664914]
	TIME [epoch: 8.51 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1481541253360798		[learning rate: 0.0011662]
	Learning Rate: 0.00116619
	LOSS [training: 0.1481541253360798 | validation: 0.18453355309825736]
	TIME [epoch: 8.51 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12936641339910585		[learning rate: 0.0011634]
	Learning Rate: 0.00116344
	LOSS [training: 0.12936641339910585 | validation: 0.15552989522287458]
	TIME [epoch: 8.54 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11810670928022213		[learning rate: 0.0011607]
	Learning Rate: 0.00116069
	LOSS [training: 0.11810670928022213 | validation: 0.1488318092176006]
	TIME [epoch: 8.52 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13514468148536746		[learning rate: 0.001158]
	Learning Rate: 0.00115796
	LOSS [training: 0.13514468148536746 | validation: 0.16338061362782974]
	TIME [epoch: 8.52 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13543752196953732		[learning rate: 0.0011552]
	Learning Rate: 0.00115523
	LOSS [training: 0.13543752196953732 | validation: 0.13450663393466894]
	TIME [epoch: 8.51 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1447852995866753		[learning rate: 0.0011525]
	Learning Rate: 0.0011525
	LOSS [training: 0.1447852995866753 | validation: 0.14441259547258586]
	TIME [epoch: 8.53 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18443993723435564		[learning rate: 0.0011498]
	Learning Rate: 0.00114978
	LOSS [training: 0.18443993723435564 | validation: 0.19403899205985198]
	TIME [epoch: 8.52 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15123856154824086		[learning rate: 0.0011471]
	Learning Rate: 0.00114707
	LOSS [training: 0.15123856154824086 | validation: 0.11592422761271881]
	TIME [epoch: 8.51 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1365483776512087		[learning rate: 0.0011444]
	Learning Rate: 0.00114436
	LOSS [training: 0.1365483776512087 | validation: 0.15707172113595272]
	TIME [epoch: 8.51 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15845825518686127		[learning rate: 0.0011417]
	Learning Rate: 0.00114166
	LOSS [training: 0.15845825518686127 | validation: 0.1497624653348133]
	TIME [epoch: 8.53 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.127584099284366		[learning rate: 0.001139]
	Learning Rate: 0.00113897
	LOSS [training: 0.127584099284366 | validation: 0.11068626367418495]
	TIME [epoch: 8.51 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15841676474430585		[learning rate: 0.0011363]
	Learning Rate: 0.00113628
	LOSS [training: 0.15841676474430585 | validation: 0.1762522588604844]
	TIME [epoch: 8.52 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15490002802967012		[learning rate: 0.0011336]
	Learning Rate: 0.0011336
	LOSS [training: 0.15490002802967012 | validation: 0.17850175743040086]
	TIME [epoch: 8.51 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14653516509702524		[learning rate: 0.0011309]
	Learning Rate: 0.00113093
	LOSS [training: 0.14653516509702524 | validation: 0.13561154640329426]
	TIME [epoch: 8.54 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12412138107039358		[learning rate: 0.0011283]
	Learning Rate: 0.00112826
	LOSS [training: 0.12412138107039358 | validation: 0.1440429261516771]
	TIME [epoch: 8.52 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14979728131770464		[learning rate: 0.0011256]
	Learning Rate: 0.0011256
	LOSS [training: 0.14979728131770464 | validation: 0.10928079752460862]
	TIME [epoch: 8.51 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12447285214757871		[learning rate: 0.0011229]
	Learning Rate: 0.00112295
	LOSS [training: 0.12447285214757871 | validation: 0.14655289979019503]
	TIME [epoch: 8.51 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14278938116466147		[learning rate: 0.0011203]
	Learning Rate: 0.0011203
	LOSS [training: 0.14278938116466147 | validation: 0.1220117297827297]
	TIME [epoch: 8.53 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.146353851735414		[learning rate: 0.0011177]
	Learning Rate: 0.00111765
	LOSS [training: 0.146353851735414 | validation: 0.1469607201050309]
	TIME [epoch: 8.52 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12685521765321706		[learning rate: 0.001115]
	Learning Rate: 0.00111502
	LOSS [training: 0.12685521765321706 | validation: 0.15399624309356558]
	TIME [epoch: 8.51 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14239832459109708		[learning rate: 0.0011124]
	Learning Rate: 0.00111239
	LOSS [training: 0.14239832459109708 | validation: 0.10990719746535714]
	TIME [epoch: 8.52 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11978770157774903		[learning rate: 0.0011098]
	Learning Rate: 0.00110976
	LOSS [training: 0.11978770157774903 | validation: 0.13576875399387137]
	TIME [epoch: 8.53 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13003135509177496		[learning rate: 0.0011071]
	Learning Rate: 0.00110715
	LOSS [training: 0.13003135509177496 | validation: 0.09229174765005922]
	TIME [epoch: 8.51 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11336232210672059		[learning rate: 0.0011045]
	Learning Rate: 0.00110453
	LOSS [training: 0.11336232210672059 | validation: 0.11353491410385111]
	TIME [epoch: 8.51 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10276906533206465		[learning rate: 0.0011019]
	Learning Rate: 0.00110193
	LOSS [training: 0.10276906533206465 | validation: 0.15049249395250336]
	TIME [epoch: 8.53 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1806677116752133		[learning rate: 0.0010993]
	Learning Rate: 0.00109933
	LOSS [training: 0.1806677116752133 | validation: 0.16537174414532152]
	TIME [epoch: 8.52 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12043988659274682		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.12043988659274682 | validation: 0.11675211504995793]
	TIME [epoch: 8.52 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12621695671280123		[learning rate: 0.0010942]
	Learning Rate: 0.00109415
	LOSS [training: 0.12621695671280123 | validation: 0.10222445293521172]
	TIME [epoch: 8.52 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1118492670009672		[learning rate: 0.0010916]
	Learning Rate: 0.00109157
	LOSS [training: 0.1118492670009672 | validation: 0.13881200445123149]
	TIME [epoch: 8.53 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12623021994139044		[learning rate: 0.001089]
	Learning Rate: 0.00108899
	LOSS [training: 0.12623021994139044 | validation: 0.13817668946556544]
	TIME [epoch: 8.52 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11550229306294105		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.11550229306294105 | validation: 0.11856684190408534]
	TIME [epoch: 8.52 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11109963146508564		[learning rate: 0.0010839]
	Learning Rate: 0.00108386
	LOSS [training: 0.11109963146508564 | validation: 0.20858109455411195]
	TIME [epoch: 8.51 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.141220678286235		[learning rate: 0.0010813]
	Learning Rate: 0.00108131
	LOSS [training: 0.141220678286235 | validation: 0.11861033012320446]
	TIME [epoch: 8.53 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09524900822456875		[learning rate: 0.0010788]
	Learning Rate: 0.00107876
	LOSS [training: 0.09524900822456875 | validation: 0.08347138729210105]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_993.pth
	Model improved!!!
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11354412453143121		[learning rate: 0.0010762]
	Learning Rate: 0.00107621
	LOSS [training: 0.11354412453143121 | validation: 0.1229071308204033]
	TIME [epoch: 8.52 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13215505812171946		[learning rate: 0.0010737]
	Learning Rate: 0.00107367
	LOSS [training: 0.13215505812171946 | validation: 0.09943489104224473]
	TIME [epoch: 8.51 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13116775219590626		[learning rate: 0.0010711]
	Learning Rate: 0.00107114
	LOSS [training: 0.13116775219590626 | validation: 0.11837228961828458]
	TIME [epoch: 8.53 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15445039717428202		[learning rate: 0.0010686]
	Learning Rate: 0.00106861
	LOSS [training: 0.15445039717428202 | validation: 0.15580392015191952]
	TIME [epoch: 8.51 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12266228087049022		[learning rate: 0.0010661]
	Learning Rate: 0.00106609
	LOSS [training: 0.12266228087049022 | validation: 0.1257871745161055]
	TIME [epoch: 8.51 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12897386483552484		[learning rate: 0.0010636]
	Learning Rate: 0.00106358
	LOSS [training: 0.12897386483552484 | validation: 0.13578886948540023]
	TIME [epoch: 8.51 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1476451252433546		[learning rate: 0.0010611]
	Learning Rate: 0.00106107
	LOSS [training: 0.1476451252433546 | validation: 0.14299126663867195]
	TIME [epoch: 8.53 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16723543907817875		[learning rate: 0.0010586]
	Learning Rate: 0.00105857
	LOSS [training: 0.16723543907817875 | validation: 0.14163062026145956]
	TIME [epoch: 8.51 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11912319574445011		[learning rate: 0.0010561]
	Learning Rate: 0.00105607
	LOSS [training: 0.11912319574445011 | validation: 0.1697685757517412]
	TIME [epoch: 8.51 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15486899983074226		[learning rate: 0.0010536]
	Learning Rate: 0.00105358
	LOSS [training: 0.15486899983074226 | validation: 0.1758803371276513]
	TIME [epoch: 8.51 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12822701119802019		[learning rate: 0.0010511]
	Learning Rate: 0.00105109
	LOSS [training: 0.12822701119802019 | validation: 0.12624944755516426]
	TIME [epoch: 8.53 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11202565513661086		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.11202565513661086 | validation: 0.13888789066635052]
	TIME [epoch: 8.51 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1110541208646921		[learning rate: 0.0010461]
	Learning Rate: 0.00104614
	LOSS [training: 0.1110541208646921 | validation: 0.14598642305084014]
	TIME [epoch: 8.51 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12137690420581922		[learning rate: 0.0010437]
	Learning Rate: 0.00104367
	LOSS [training: 0.12137690420581922 | validation: 0.1414772028884813]
	TIME [epoch: 8.51 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13678791106100358		[learning rate: 0.0010412]
	Learning Rate: 0.00104121
	LOSS [training: 0.13678791106100358 | validation: 0.117820083541719]
	TIME [epoch: 8.53 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1102063157317836		[learning rate: 0.0010388]
	Learning Rate: 0.00103875
	LOSS [training: 0.1102063157317836 | validation: 0.095689690922422]
	TIME [epoch: 8.51 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1118070981436027		[learning rate: 0.0010363]
	Learning Rate: 0.0010363
	LOSS [training: 0.1118070981436027 | validation: 0.13360947591237354]
	TIME [epoch: 8.51 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11579165784308247		[learning rate: 0.0010339]
	Learning Rate: 0.00103386
	LOSS [training: 0.11579165784308247 | validation: 0.1630837824549592]
	TIME [epoch: 8.52 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1335315904150565		[learning rate: 0.0010314]
	Learning Rate: 0.00103142
	LOSS [training: 0.1335315904150565 | validation: 0.1553802347680689]
	TIME [epoch: 8.52 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12856020273240762		[learning rate: 0.001029]
	Learning Rate: 0.00102899
	LOSS [training: 0.12856020273240762 | validation: 0.1096036118114937]
	TIME [epoch: 8.51 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1356347919570121		[learning rate: 0.0010266]
	Learning Rate: 0.00102656
	LOSS [training: 0.1356347919570121 | validation: 0.0983410666270727]
	TIME [epoch: 8.51 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12997008305250418		[learning rate: 0.0010241]
	Learning Rate: 0.00102414
	LOSS [training: 0.12997008305250418 | validation: 0.15154560939972064]
	TIME [epoch: 8.52 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12614671308740125		[learning rate: 0.0010217]
	Learning Rate: 0.00102172
	LOSS [training: 0.12614671308740125 | validation: 0.10497325388890211]
	TIME [epoch: 8.52 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1083151164379585		[learning rate: 0.0010193]
	Learning Rate: 0.00101931
	LOSS [training: 0.1083151164379585 | validation: 0.15337342304093665]
	TIME [epoch: 8.51 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10921479559883165		[learning rate: 0.0010169]
	Learning Rate: 0.00101691
	LOSS [training: 0.10921479559883165 | validation: 0.1033098113018247]
	TIME [epoch: 8.51 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10367077051729505		[learning rate: 0.0010145]
	Learning Rate: 0.00101451
	LOSS [training: 0.10367077051729505 | validation: 0.15141378400933006]
	TIME [epoch: 8.53 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13719696657545555		[learning rate: 0.0010121]
	Learning Rate: 0.00101212
	LOSS [training: 0.13719696657545555 | validation: 0.09711059352506776]
	TIME [epoch: 8.52 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14078119136929707		[learning rate: 0.0010097]
	Learning Rate: 0.00100973
	LOSS [training: 0.14078119136929707 | validation: 0.1882058481686792]
	TIME [epoch: 8.51 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14840579580524077		[learning rate: 0.0010073]
	Learning Rate: 0.00100735
	LOSS [training: 0.14840579580524077 | validation: 0.11892267748230564]
	TIME [epoch: 8.51 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11148529958002536		[learning rate: 0.001005]
	Learning Rate: 0.00100497
	LOSS [training: 0.11148529958002536 | validation: 0.1051833080822572]
	TIME [epoch: 8.53 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10760540236943124		[learning rate: 0.0010026]
	Learning Rate: 0.0010026
	LOSS [training: 0.10760540236943124 | validation: 0.08924354851721394]
	TIME [epoch: 8.52 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1163030699537921		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.1163030699537921 | validation: 0.12301510394867703]
	TIME [epoch: 8.51 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10980559165267775		[learning rate: 0.00099788]
	Learning Rate: 0.000997877
	LOSS [training: 0.10980559165267775 | validation: 0.15063422165022766]
	TIME [epoch: 8.51 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15576961523247318		[learning rate: 0.00099552]
	Learning Rate: 0.000995523
	LOSS [training: 0.15576961523247318 | validation: 0.14350762120023725]
	TIME [epoch: 8.53 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11799726888572677		[learning rate: 0.00099317]
	Learning Rate: 0.000993175
	LOSS [training: 0.11799726888572677 | validation: 0.16314773608115243]
	TIME [epoch: 8.51 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11973848230924947		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.11973848230924947 | validation: 0.1518278665854455]
	TIME [epoch: 8.51 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12870954892682313		[learning rate: 0.00098849]
	Learning Rate: 0.000988495
	LOSS [training: 0.12870954892682313 | validation: 0.16195557807831595]
	TIME [epoch: 8.51 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10611477782924532		[learning rate: 0.00098616]
	Learning Rate: 0.000986163
	LOSS [training: 0.10611477782924532 | validation: 0.10773946171437027]
	TIME [epoch: 8.54 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13174224128422146		[learning rate: 0.00098384]
	Learning Rate: 0.000983837
	LOSS [training: 0.13174224128422146 | validation: 0.0984234162439959]
	TIME [epoch: 8.51 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11019876661532022		[learning rate: 0.00098152]
	Learning Rate: 0.000981516
	LOSS [training: 0.11019876661532022 | validation: 0.11105479238303745]
	TIME [epoch: 8.51 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11548964092052987		[learning rate: 0.0009792]
	Learning Rate: 0.000979201
	LOSS [training: 0.11548964092052987 | validation: 0.14234611750227177]
	TIME [epoch: 8.52 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15013790164877971		[learning rate: 0.00097689]
	Learning Rate: 0.000976891
	LOSS [training: 0.15013790164877971 | validation: 0.12289955897302532]
	TIME [epoch: 8.54 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14156814277285704		[learning rate: 0.00097459]
	Learning Rate: 0.000974587
	LOSS [training: 0.14156814277285704 | validation: 0.11173463810284864]
	TIME [epoch: 8.52 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1439366271846587		[learning rate: 0.00097229]
	Learning Rate: 0.000972288
	LOSS [training: 0.1439366271846587 | validation: 0.1333064485248155]
	TIME [epoch: 8.51 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17866123266851724		[learning rate: 0.00096999]
	Learning Rate: 0.000969994
	LOSS [training: 0.17866123266851724 | validation: 0.17129218381439149]
	TIME [epoch: 8.51 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12463717962697765		[learning rate: 0.00096771]
	Learning Rate: 0.000967706
	LOSS [training: 0.12463717962697765 | validation: 0.10027942234657927]
	TIME [epoch: 8.53 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12823065704554945		[learning rate: 0.00096542]
	Learning Rate: 0.000965424
	LOSS [training: 0.12823065704554945 | validation: 0.108116326677562]
	TIME [epoch: 8.51 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1556105230546751		[learning rate: 0.00096315]
	Learning Rate: 0.000963146
	LOSS [training: 0.1556105230546751 | validation: 0.10294386671375219]
	TIME [epoch: 8.51 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10508326497166753		[learning rate: 0.00096087]
	Learning Rate: 0.000960874
	LOSS [training: 0.10508326497166753 | validation: 0.12356472158392084]
	TIME [epoch: 8.52 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13276181525494474		[learning rate: 0.00095861]
	Learning Rate: 0.000958608
	LOSS [training: 0.13276181525494474 | validation: 0.1404956934603983]
	TIME [epoch: 8.53 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11208508188887009		[learning rate: 0.00095635]
	Learning Rate: 0.000956347
	LOSS [training: 0.11208508188887009 | validation: 0.10363722739042056]
	TIME [epoch: 8.51 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12758078212082166		[learning rate: 0.00095409]
	Learning Rate: 0.000954091
	LOSS [training: 0.12758078212082166 | validation: 0.18364197233794183]
	TIME [epoch: 8.51 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1206401361357039		[learning rate: 0.00095184]
	Learning Rate: 0.00095184
	LOSS [training: 0.1206401361357039 | validation: 0.1161462622428521]
	TIME [epoch: 8.53 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12837290794611417		[learning rate: 0.0009496]
	Learning Rate: 0.000949595
	LOSS [training: 0.12837290794611417 | validation: 0.13656684864916002]
	TIME [epoch: 8.52 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15503487359601015		[learning rate: 0.00094736]
	Learning Rate: 0.000947355
	LOSS [training: 0.15503487359601015 | validation: 0.1549690670571615]
	TIME [epoch: 8.51 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16291867791686016		[learning rate: 0.00094512]
	Learning Rate: 0.000945121
	LOSS [training: 0.16291867791686016 | validation: 0.1579832760549651]
	TIME [epoch: 8.51 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13830012704714661		[learning rate: 0.00094289]
	Learning Rate: 0.000942891
	LOSS [training: 0.13830012704714661 | validation: 0.10682697096430999]
	TIME [epoch: 8.53 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12100561742754708		[learning rate: 0.00094067]
	Learning Rate: 0.000940667
	LOSS [training: 0.12100561742754708 | validation: 0.10078952717267925]
	TIME [epoch: 8.52 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13141453967781108		[learning rate: 0.00093845]
	Learning Rate: 0.000938448
	LOSS [training: 0.13141453967781108 | validation: 0.1253325694324719]
	TIME [epoch: 8.51 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10627238966160044		[learning rate: 0.00093623]
	Learning Rate: 0.000936234
	LOSS [training: 0.10627238966160044 | validation: 0.10610454692445576]
	TIME [epoch: 8.51 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10977437589513042		[learning rate: 0.00093403]
	Learning Rate: 0.000934026
	LOSS [training: 0.10977437589513042 | validation: 0.08889202138016856]
	TIME [epoch: 8.53 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1420667407016302		[learning rate: 0.00093182]
	Learning Rate: 0.000931823
	LOSS [training: 0.1420667407016302 | validation: 0.08536191031218847]
	TIME [epoch: 8.52 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10325039726146372		[learning rate: 0.00092962]
	Learning Rate: 0.000929625
	LOSS [training: 0.10325039726146372 | validation: 0.13220704980672648]
	TIME [epoch: 8.51 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1068517994727239		[learning rate: 0.00092743]
	Learning Rate: 0.000927432
	LOSS [training: 0.1068517994727239 | validation: 0.12311329397543022]
	TIME [epoch: 8.51 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12924827150829316		[learning rate: 0.00092524]
	Learning Rate: 0.000925244
	LOSS [training: 0.12924827150829316 | validation: 0.13519062409157576]
	TIME [epoch: 8.53 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12104357740966003		[learning rate: 0.00092306]
	Learning Rate: 0.000923062
	LOSS [training: 0.12104357740966003 | validation: 0.10126368409774936]
	TIME [epoch: 8.51 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10362711751901706		[learning rate: 0.00092088]
	Learning Rate: 0.000920884
	LOSS [training: 0.10362711751901706 | validation: 0.147927881389246]
	TIME [epoch: 8.51 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12271700216944299		[learning rate: 0.00091871]
	Learning Rate: 0.000918712
	LOSS [training: 0.12271700216944299 | validation: 0.20791653896536744]
	TIME [epoch: 8.52 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12634285334454898		[learning rate: 0.00091654]
	Learning Rate: 0.000916545
	LOSS [training: 0.12634285334454898 | validation: 0.13078200633203296]
	TIME [epoch: 8.53 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11827028828112762		[learning rate: 0.00091438]
	Learning Rate: 0.000914383
	LOSS [training: 0.11827028828112762 | validation: 0.12222327317949133]
	TIME [epoch: 8.51 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15493549505058563		[learning rate: 0.00091223]
	Learning Rate: 0.000912226
	LOSS [training: 0.15493549505058563 | validation: 0.1771160350503373]
	TIME [epoch: 8.51 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10240200046536432		[learning rate: 0.00091007]
	Learning Rate: 0.000910074
	LOSS [training: 0.10240200046536432 | validation: 0.13687758643782513]
	TIME [epoch: 8.51 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09967546354617421		[learning rate: 0.00090793]
	Learning Rate: 0.000907928
	LOSS [training: 0.09967546354617421 | validation: 0.13781089101323263]
	TIME [epoch: 8.53 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13997968503726957		[learning rate: 0.00090579]
	Learning Rate: 0.000905786
	LOSS [training: 0.13997968503726957 | validation: 0.14778079822497564]
	TIME [epoch: 8.51 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15002756416360746		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.15002756416360746 | validation: 0.22640115323564516]
	TIME [epoch: 8.51 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12977672192874395		[learning rate: 0.00090152]
	Learning Rate: 0.000901518
	LOSS [training: 0.12977672192874395 | validation: 0.1234441241842199]
	TIME [epoch: 8.51 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12169224273546317		[learning rate: 0.00089939]
	Learning Rate: 0.000899391
	LOSS [training: 0.12169224273546317 | validation: 0.10288545197856673]
	TIME [epoch: 8.53 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11899351609852585		[learning rate: 0.00089727]
	Learning Rate: 0.00089727
	LOSS [training: 0.11899351609852585 | validation: 0.09918992904269835]
	TIME [epoch: 8.51 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11071330344612915		[learning rate: 0.00089515]
	Learning Rate: 0.000895153
	LOSS [training: 0.11071330344612915 | validation: 0.10450426256964537]
	TIME [epoch: 8.51 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10971888099569427		[learning rate: 0.00089304]
	Learning Rate: 0.000893042
	LOSS [training: 0.10971888099569427 | validation: 0.10283566058228615]
	TIME [epoch: 8.51 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12222631104198042		[learning rate: 0.00089094]
	Learning Rate: 0.000890935
	LOSS [training: 0.12222631104198042 | validation: 0.1408996441974459]
	TIME [epoch: 8.53 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10812324378242552		[learning rate: 0.00088883]
	Learning Rate: 0.000888834
	LOSS [training: 0.10812324378242552 | validation: 0.11292909226406476]
	TIME [epoch: 8.51 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13451644974763227		[learning rate: 0.00088674]
	Learning Rate: 0.000886737
	LOSS [training: 0.13451644974763227 | validation: 0.08822475534948578]
	TIME [epoch: 8.51 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12376994426943974		[learning rate: 0.00088465]
	Learning Rate: 0.000884645
	LOSS [training: 0.12376994426943974 | validation: 0.10278432403660714]
	TIME [epoch: 8.52 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10361521202863264		[learning rate: 0.00088256]
	Learning Rate: 0.000882559
	LOSS [training: 0.10361521202863264 | validation: 0.13269241369925472]
	TIME [epoch: 8.52 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10354923642911693		[learning rate: 0.00088048]
	Learning Rate: 0.000880477
	LOSS [training: 0.10354923642911693 | validation: 0.11465893505609051]
	TIME [epoch: 8.51 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10365242600736772		[learning rate: 0.0008784]
	Learning Rate: 0.0008784
	LOSS [training: 0.10365242600736772 | validation: 0.13819759374610313]
	TIME [epoch: 8.51 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15669538059113958		[learning rate: 0.00087633]
	Learning Rate: 0.000876328
	LOSS [training: 0.15669538059113958 | validation: 0.09109797869597877]
	TIME [epoch: 8.53 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09969548576315397		[learning rate: 0.00087426]
	Learning Rate: 0.000874261
	LOSS [training: 0.09969548576315397 | validation: 0.12405755046714771]
	TIME [epoch: 8.52 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1386469212620245		[learning rate: 0.0008722]
	Learning Rate: 0.000872199
	LOSS [training: 0.1386469212620245 | validation: 0.12035932017152406]
	TIME [epoch: 8.51 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12244843434920274		[learning rate: 0.00087014]
	Learning Rate: 0.000870141
	LOSS [training: 0.12244843434920274 | validation: 0.10145562966214666]
	TIME [epoch: 8.51 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10062405424962213		[learning rate: 0.00086809]
	Learning Rate: 0.000868089
	LOSS [training: 0.10062405424962213 | validation: 0.08383681349167002]
	TIME [epoch: 8.52 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11026683621151034		[learning rate: 0.00086604]
	Learning Rate: 0.000866041
	LOSS [training: 0.11026683621151034 | validation: 0.10607107665580563]
	TIME [epoch: 8.51 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09134996020372463		[learning rate: 0.000864]
	Learning Rate: 0.000863998
	LOSS [training: 0.09134996020372463 | validation: 0.10184089323022721]
	TIME [epoch: 8.51 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10858018725973773		[learning rate: 0.00086196]
	Learning Rate: 0.00086196
	LOSS [training: 0.10858018725973773 | validation: 0.08562937242681412]
	TIME [epoch: 8.51 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10818514363353396		[learning rate: 0.00085993]
	Learning Rate: 0.000859927
	LOSS [training: 0.10818514363353396 | validation: 0.13338333965978666]
	TIME [epoch: 8.53 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.136978765440621		[learning rate: 0.0008579]
	Learning Rate: 0.000857898
	LOSS [training: 0.136978765440621 | validation: 0.16978205963992746]
	TIME [epoch: 8.51 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1248343990704233		[learning rate: 0.00085587]
	Learning Rate: 0.000855875
	LOSS [training: 0.1248343990704233 | validation: 0.11535069137395179]
	TIME [epoch: 8.82 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11451681769823067		[learning rate: 0.00085386]
	Learning Rate: 0.000853856
	LOSS [training: 0.11451681769823067 | validation: 0.1118415466713072]
	TIME [epoch: 8.52 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16331591820396502		[learning rate: 0.00085184]
	Learning Rate: 0.000851842
	LOSS [training: 0.16331591820396502 | validation: 0.09700592632657945]
	TIME [epoch: 8.54 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1090934127646509		[learning rate: 0.00084983]
	Learning Rate: 0.000849832
	LOSS [training: 0.1090934127646509 | validation: 0.1306003031736938]
	TIME [epoch: 8.53 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15157314435318622		[learning rate: 0.00084783]
	Learning Rate: 0.000847828
	LOSS [training: 0.15157314435318622 | validation: 0.11715796531131602]
	TIME [epoch: 8.53 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12611841794984743		[learning rate: 0.00084583]
	Learning Rate: 0.000845828
	LOSS [training: 0.12611841794984743 | validation: 0.10647333098769939]
	TIME [epoch: 8.52 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10949122077117428		[learning rate: 0.00084383]
	Learning Rate: 0.000843833
	LOSS [training: 0.10949122077117428 | validation: 0.09214143958291712]
	TIME [epoch: 8.55 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12785954313310485		[learning rate: 0.00084184]
	Learning Rate: 0.000841842
	LOSS [training: 0.12785954313310485 | validation: 0.13706421133983426]
	TIME [epoch: 8.53 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11461748617594758		[learning rate: 0.00083986]
	Learning Rate: 0.000839856
	LOSS [training: 0.11461748617594758 | validation: 0.10908498782000467]
	TIME [epoch: 8.52 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11928264856802406		[learning rate: 0.00083788]
	Learning Rate: 0.000837876
	LOSS [training: 0.11928264856802406 | validation: 0.1724541446889513]
	TIME [epoch: 8.52 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12047681162038845		[learning rate: 0.0008359]
	Learning Rate: 0.000835899
	LOSS [training: 0.12047681162038845 | validation: 0.09898122088133801]
	TIME [epoch: 8.55 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10427999600921425		[learning rate: 0.00083393]
	Learning Rate: 0.000833927
	LOSS [training: 0.10427999600921425 | validation: 0.08100744893115636]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_1102.pth
	Model improved!!!
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11239885465946313		[learning rate: 0.00083196]
	Learning Rate: 0.00083196
	LOSS [training: 0.11239885465946313 | validation: 0.11970251388309698]
	TIME [epoch: 8.53 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1047149495463658		[learning rate: 0.00083]
	Learning Rate: 0.000829998
	LOSS [training: 0.1047149495463658 | validation: 0.08978905439251969]
	TIME [epoch: 8.52 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10989257898367484		[learning rate: 0.00082804]
	Learning Rate: 0.00082804
	LOSS [training: 0.10989257898367484 | validation: 0.1485706432751957]
	TIME [epoch: 8.54 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10771206726977536		[learning rate: 0.00082609]
	Learning Rate: 0.000826087
	LOSS [training: 0.10771206726977536 | validation: 0.0906630988913184]
	TIME [epoch: 8.52 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.141855972209241		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.141855972209241 | validation: 0.0880658548551255]
	TIME [epoch: 8.52 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12358555499908123		[learning rate: 0.00082219]
	Learning Rate: 0.000822194
	LOSS [training: 0.12358555499908123 | validation: 0.10053424294886995]
	TIME [epoch: 8.53 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1628927748930211		[learning rate: 0.00082025]
	Learning Rate: 0.000820254
	LOSS [training: 0.1628927748930211 | validation: 0.10305605505362513]
	TIME [epoch: 8.54 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11679133951398075		[learning rate: 0.00081832]
	Learning Rate: 0.00081832
	LOSS [training: 0.11679133951398075 | validation: 0.12774012216732294]
	TIME [epoch: 8.52 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11955892238839194		[learning rate: 0.00081639]
	Learning Rate: 0.000816389
	LOSS [training: 0.11955892238839194 | validation: 0.13248707479301647]
	TIME [epoch: 8.52 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12511401597630514		[learning rate: 0.00081446]
	Learning Rate: 0.000814464
	LOSS [training: 0.12511401597630514 | validation: 0.10700249186274359]
	TIME [epoch: 8.54 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1457551320490668		[learning rate: 0.00081254]
	Learning Rate: 0.000812543
	LOSS [training: 0.1457551320490668 | validation: 0.09894188309914728]
	TIME [epoch: 8.53 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11978583351468582		[learning rate: 0.00081063]
	Learning Rate: 0.000810626
	LOSS [training: 0.11978583351468582 | validation: 0.15075109110771795]
	TIME [epoch: 8.52 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12112495865234227		[learning rate: 0.00080871]
	Learning Rate: 0.000808714
	LOSS [training: 0.12112495865234227 | validation: 0.09861031366027073]
	TIME [epoch: 8.52 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15717252427919728		[learning rate: 0.00080681]
	Learning Rate: 0.000806806
	LOSS [training: 0.15717252427919728 | validation: 0.15165766502428285]
	TIME [epoch: 8.54 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.107935686247431		[learning rate: 0.0008049]
	Learning Rate: 0.000804903
	LOSS [training: 0.107935686247431 | validation: 0.09323922051512051]
	TIME [epoch: 8.53 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11601033594692836		[learning rate: 0.000803]
	Learning Rate: 0.000803004
	LOSS [training: 0.11601033594692836 | validation: 0.10074357648264207]
	TIME [epoch: 8.52 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12856378576126612		[learning rate: 0.00080111]
	Learning Rate: 0.00080111
	LOSS [training: 0.12856378576126612 | validation: 0.10721558656744787]
	TIME [epoch: 8.52 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14205152909298943		[learning rate: 0.00079922]
	Learning Rate: 0.000799221
	LOSS [training: 0.14205152909298943 | validation: 0.12157821262030515]
	TIME [epoch: 8.54 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14972115321792998		[learning rate: 0.00079734]
	Learning Rate: 0.000797335
	LOSS [training: 0.14972115321792998 | validation: 0.1563365791395508]
	TIME [epoch: 8.52 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1323495956934992		[learning rate: 0.00079545]
	Learning Rate: 0.000795454
	LOSS [training: 0.1323495956934992 | validation: 0.10707875187051334]
	TIME [epoch: 8.52 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12483033432169388		[learning rate: 0.00079358]
	Learning Rate: 0.000793578
	LOSS [training: 0.12483033432169388 | validation: 0.14361516531843815]
	TIME [epoch: 8.52 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1292396731511687		[learning rate: 0.00079171]
	Learning Rate: 0.000791706
	LOSS [training: 0.1292396731511687 | validation: 0.10598158851535397]
	TIME [epoch: 8.54 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1195640714018978		[learning rate: 0.00078984]
	Learning Rate: 0.000789839
	LOSS [training: 0.1195640714018978 | validation: 0.13434722050479916]
	TIME [epoch: 8.53 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1227872672749493		[learning rate: 0.00078798]
	Learning Rate: 0.000787976
	LOSS [training: 0.1227872672749493 | validation: 0.20518605120390143]
	TIME [epoch: 8.52 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1334131687583605		[learning rate: 0.00078612]
	Learning Rate: 0.000786117
	LOSS [training: 0.1334131687583605 | validation: 0.14780609543455953]
	TIME [epoch: 8.52 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14273716817319743		[learning rate: 0.00078426]
	Learning Rate: 0.000784263
	LOSS [training: 0.14273716817319743 | validation: 0.1273909583945231]
	TIME [epoch: 8.54 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12533309665912162		[learning rate: 0.00078241]
	Learning Rate: 0.000782413
	LOSS [training: 0.12533309665912162 | validation: 0.09733460774101729]
	TIME [epoch: 8.52 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1256210953254871		[learning rate: 0.00078057]
	Learning Rate: 0.000780567
	LOSS [training: 0.1256210953254871 | validation: 0.10491311792598729]
	TIME [epoch: 8.52 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10146457290083515		[learning rate: 0.00077873]
	Learning Rate: 0.000778726
	LOSS [training: 0.10146457290083515 | validation: 0.1017423809197659]
	TIME [epoch: 8.52 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12527958973670097		[learning rate: 0.00077689]
	Learning Rate: 0.000776889
	LOSS [training: 0.12527958973670097 | validation: 0.12665535233808278]
	TIME [epoch: 8.54 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12180665538823447		[learning rate: 0.00077506]
	Learning Rate: 0.000775056
	LOSS [training: 0.12180665538823447 | validation: 0.1586281663298174]
	TIME [epoch: 8.52 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1457555452428699		[learning rate: 0.00077323]
	Learning Rate: 0.000773228
	LOSS [training: 0.1457555452428699 | validation: 0.12137701830581035]
	TIME [epoch: 8.52 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13001849176229638		[learning rate: 0.0007714]
	Learning Rate: 0.000771404
	LOSS [training: 0.13001849176229638 | validation: 0.12104654146122672]
	TIME [epoch: 8.52 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11190474494995839		[learning rate: 0.00076958]
	Learning Rate: 0.000769585
	LOSS [training: 0.11190474494995839 | validation: 0.10365342025654017]
	TIME [epoch: 8.54 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10522492851034237		[learning rate: 0.00076777]
	Learning Rate: 0.000767769
	LOSS [training: 0.10522492851034237 | validation: 0.0881398613635635]
	TIME [epoch: 8.52 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10056594822373517		[learning rate: 0.00076596]
	Learning Rate: 0.000765958
	LOSS [training: 0.10056594822373517 | validation: 0.13023081808026643]
	TIME [epoch: 8.52 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1384287202128284		[learning rate: 0.00076415]
	Learning Rate: 0.000764151
	LOSS [training: 0.1384287202128284 | validation: 0.1746286638454897]
	TIME [epoch: 8.53 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1210480914061141		[learning rate: 0.00076235]
	Learning Rate: 0.000762349
	LOSS [training: 0.1210480914061141 | validation: 0.15190266041855127]
	TIME [epoch: 8.53 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12479699707793739		[learning rate: 0.00076055]
	Learning Rate: 0.000760551
	LOSS [training: 0.12479699707793739 | validation: 0.0987775232211758]
	TIME [epoch: 8.52 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11332848668466047		[learning rate: 0.00075876]
	Learning Rate: 0.000758757
	LOSS [training: 0.11332848668466047 | validation: 0.08897164967661905]
	TIME [epoch: 8.52 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1023243069294939		[learning rate: 0.00075697]
	Learning Rate: 0.000756967
	LOSS [training: 0.1023243069294939 | validation: 0.11589836217709912]
	TIME [epoch: 8.53 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11342005043116783		[learning rate: 0.00075518]
	Learning Rate: 0.000755181
	LOSS [training: 0.11342005043116783 | validation: 0.11911628677666039]
	TIME [epoch: 8.53 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13350677901590727		[learning rate: 0.0007534]
	Learning Rate: 0.0007534
	LOSS [training: 0.13350677901590727 | validation: 0.09602660605755908]
	TIME [epoch: 8.52 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10803648966822668		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.10803648966822668 | validation: 0.10467150441661247]
	TIME [epoch: 8.52 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1287206030147525		[learning rate: 0.00074985]
	Learning Rate: 0.00074985
	LOSS [training: 0.1287206030147525 | validation: 0.12375626184623137]
	TIME [epoch: 8.53 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12936506225027808		[learning rate: 0.00074808]
	Learning Rate: 0.000748081
	LOSS [training: 0.12936506225027808 | validation: 0.1425362654366476]
	TIME [epoch: 8.53 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1356361107269768		[learning rate: 0.00074632]
	Learning Rate: 0.000746316
	LOSS [training: 0.1356361107269768 | validation: 0.09839080833437416]
	TIME [epoch: 8.52 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12061445462105336		[learning rate: 0.00074456]
	Learning Rate: 0.000744556
	LOSS [training: 0.12061445462105336 | validation: 0.1511326788578325]
	TIME [epoch: 8.52 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11496244408156302		[learning rate: 0.0007428]
	Learning Rate: 0.0007428
	LOSS [training: 0.11496244408156302 | validation: 0.11708050274045795]
	TIME [epoch: 8.54 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12891310857382415		[learning rate: 0.00074105]
	Learning Rate: 0.000741048
	LOSS [training: 0.12891310857382415 | validation: 0.1252470777012862]
	TIME [epoch: 8.52 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1408964011172218		[learning rate: 0.0007393]
	Learning Rate: 0.0007393
	LOSS [training: 0.1408964011172218 | validation: 0.09808655749594808]
	TIME [epoch: 8.52 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12215219564961013		[learning rate: 0.00073756]
	Learning Rate: 0.000737556
	LOSS [training: 0.12215219564961013 | validation: 0.13458039257897778]
	TIME [epoch: 8.52 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11093286104511368		[learning rate: 0.00073582]
	Learning Rate: 0.000735816
	LOSS [training: 0.11093286104511368 | validation: 0.10908269189173918]
	TIME [epoch: 8.54 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10740521103803238		[learning rate: 0.00073408]
	Learning Rate: 0.00073408
	LOSS [training: 0.10740521103803238 | validation: 0.1075265338102043]
	TIME [epoch: 8.52 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10337967282982322		[learning rate: 0.00073235]
	Learning Rate: 0.000732349
	LOSS [training: 0.10337967282982322 | validation: 0.12459375598970032]
	TIME [epoch: 8.51 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10846266177591206		[learning rate: 0.00073062]
	Learning Rate: 0.000730621
	LOSS [training: 0.10846266177591206 | validation: 0.1001219844021079]
	TIME [epoch: 8.52 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10671933593533112		[learning rate: 0.0007289]
	Learning Rate: 0.000728898
	LOSS [training: 0.10671933593533112 | validation: 0.12942121604733353]
	TIME [epoch: 8.54 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12095115499798022		[learning rate: 0.00072718]
	Learning Rate: 0.000727178
	LOSS [training: 0.12095115499798022 | validation: 0.1668981357441095]
	TIME [epoch: 8.52 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11215069890246325		[learning rate: 0.00072546]
	Learning Rate: 0.000725463
	LOSS [training: 0.11215069890246325 | validation: 0.12196246088078808]
	TIME [epoch: 8.52 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10726165498975089		[learning rate: 0.00072375]
	Learning Rate: 0.000723752
	LOSS [training: 0.10726165498975089 | validation: 0.14495412025439683]
	TIME [epoch: 8.52 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11634460463596981		[learning rate: 0.00072204]
	Learning Rate: 0.000722045
	LOSS [training: 0.11634460463596981 | validation: 0.11567050647663604]
	TIME [epoch: 8.54 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12057158475604632		[learning rate: 0.00072034]
	Learning Rate: 0.000720342
	LOSS [training: 0.12057158475604632 | validation: 0.11068840404430208]
	TIME [epoch: 8.52 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10843521787398805		[learning rate: 0.00071864]
	Learning Rate: 0.000718642
	LOSS [training: 0.10843521787398805 | validation: 0.1311486624437147]
	TIME [epoch: 8.52 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11465861482905657		[learning rate: 0.00071695]
	Learning Rate: 0.000716947
	LOSS [training: 0.11465861482905657 | validation: 0.11427858992671805]
	TIME [epoch: 8.52 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.115292816412586		[learning rate: 0.00071526]
	Learning Rate: 0.000715256
	LOSS [training: 0.115292816412586 | validation: 0.11952966774520168]
	TIME [epoch: 8.54 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11735477329053405		[learning rate: 0.00071357]
	Learning Rate: 0.000713569
	LOSS [training: 0.11735477329053405 | validation: 0.09606940314959228]
	TIME [epoch: 8.52 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10758887352224386		[learning rate: 0.00071189]
	Learning Rate: 0.000711886
	LOSS [training: 0.10758887352224386 | validation: 0.10589981837409021]
	TIME [epoch: 8.52 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1137300778794472		[learning rate: 0.00071021]
	Learning Rate: 0.000710206
	LOSS [training: 0.1137300778794472 | validation: 0.1910921843236163]
	TIME [epoch: 8.53 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13664438665399312		[learning rate: 0.00070853]
	Learning Rate: 0.000708531
	LOSS [training: 0.13664438665399312 | validation: 0.124383343553512]
	TIME [epoch: 8.54 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10705722054344875		[learning rate: 0.00070686]
	Learning Rate: 0.00070686
	LOSS [training: 0.10705722054344875 | validation: 0.10285357627353561]
	TIME [epoch: 8.52 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11624538082572382		[learning rate: 0.00070519]
	Learning Rate: 0.000705193
	LOSS [training: 0.11624538082572382 | validation: 0.14889222515412753]
	TIME [epoch: 8.53 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1425337038759678		[learning rate: 0.00070353]
	Learning Rate: 0.000703529
	LOSS [training: 0.1425337038759678 | validation: 0.1075773787770864]
	TIME [epoch: 8.54 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13885678111880617		[learning rate: 0.00070187]
	Learning Rate: 0.000701869
	LOSS [training: 0.13885678111880617 | validation: 0.16498686510919292]
	TIME [epoch: 8.53 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11372311721181867		[learning rate: 0.00070021]
	Learning Rate: 0.000700214
	LOSS [training: 0.11372311721181867 | validation: 0.1513992346471536]
	TIME [epoch: 8.52 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13218740581598284		[learning rate: 0.00069856]
	Learning Rate: 0.000698562
	LOSS [training: 0.13218740581598284 | validation: 0.1470336904175397]
	TIME [epoch: 8.52 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13941537179432317		[learning rate: 0.00069691]
	Learning Rate: 0.000696914
	LOSS [training: 0.13941537179432317 | validation: 0.09950569368611287]
	TIME [epoch: 8.54 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11690436260872898		[learning rate: 0.00069527]
	Learning Rate: 0.00069527
	LOSS [training: 0.11690436260872898 | validation: 0.12190719183390553]
	TIME [epoch: 8.53 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13284107162879874		[learning rate: 0.00069363]
	Learning Rate: 0.000693631
	LOSS [training: 0.13284107162879874 | validation: 0.12854653800026594]
	TIME [epoch: 8.52 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12475957923518581		[learning rate: 0.00069199]
	Learning Rate: 0.000691994
	LOSS [training: 0.12475957923518581 | validation: 0.12692558768147025]
	TIME [epoch: 8.52 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13492455826063243		[learning rate: 0.00069036]
	Learning Rate: 0.000690362
	LOSS [training: 0.13492455826063243 | validation: 0.14947059464895812]
	TIME [epoch: 8.54 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1368724926259145		[learning rate: 0.00068873]
	Learning Rate: 0.000688734
	LOSS [training: 0.1368724926259145 | validation: 0.16702867798870374]
	TIME [epoch: 8.52 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15052135399457828		[learning rate: 0.00068711]
	Learning Rate: 0.000687109
	LOSS [training: 0.15052135399457828 | validation: 0.14034763203840853]
	TIME [epoch: 8.52 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1503654510040089		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.1503654510040089 | validation: 0.12090960691153887]
	TIME [epoch: 8.52 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14741760377751426		[learning rate: 0.00068387]
	Learning Rate: 0.000683871
	LOSS [training: 0.14741760377751426 | validation: 0.11417673147863984]
	TIME [epoch: 8.54 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14725334832869252		[learning rate: 0.00068226]
	Learning Rate: 0.000682258
	LOSS [training: 0.14725334832869252 | validation: 0.13248046055916124]
	TIME [epoch: 8.52 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13944755391191452		[learning rate: 0.00068065]
	Learning Rate: 0.000680649
	LOSS [training: 0.13944755391191452 | validation: 0.17270621795551988]
	TIME [epoch: 8.52 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14229758051394883		[learning rate: 0.00067904]
	Learning Rate: 0.000679043
	LOSS [training: 0.14229758051394883 | validation: 0.11497293769992561]
	TIME [epoch: 8.52 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15217892646851092		[learning rate: 0.00067744]
	Learning Rate: 0.000677442
	LOSS [training: 0.15217892646851092 | validation: 0.1034316258596499]
	TIME [epoch: 8.55 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12452225313610214		[learning rate: 0.00067584]
	Learning Rate: 0.000675844
	LOSS [training: 0.12452225313610214 | validation: 0.15118216202542634]
	TIME [epoch: 8.52 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13091561076239713		[learning rate: 0.00067425]
	Learning Rate: 0.000674249
	LOSS [training: 0.13091561076239713 | validation: 0.1381224552256314]
	TIME [epoch: 8.52 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1415184220293884		[learning rate: 0.00067266]
	Learning Rate: 0.000672659
	LOSS [training: 0.1415184220293884 | validation: 0.14873852364146234]
	TIME [epoch: 8.52 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14371335170764712		[learning rate: 0.00067107]
	Learning Rate: 0.000671072
	LOSS [training: 0.14371335170764712 | validation: 0.10767732473855829]
	TIME [epoch: 8.55 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12955410510290635		[learning rate: 0.00066949]
	Learning Rate: 0.000669489
	LOSS [training: 0.12955410510290635 | validation: 0.11390210514829391]
	TIME [epoch: 8.52 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13267159548428606		[learning rate: 0.00066791]
	Learning Rate: 0.00066791
	LOSS [training: 0.13267159548428606 | validation: 0.12584387953495532]
	TIME [epoch: 8.52 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13091869730212177		[learning rate: 0.00066633]
	Learning Rate: 0.000666335
	LOSS [training: 0.13091869730212177 | validation: 0.13245504499978483]
	TIME [epoch: 8.52 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14519292101848075		[learning rate: 0.00066476]
	Learning Rate: 0.000664763
	LOSS [training: 0.14519292101848075 | validation: 0.14325697081380703]
	TIME [epoch: 8.55 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11504054556422585		[learning rate: 0.00066319]
	Learning Rate: 0.000663195
	LOSS [training: 0.11504054556422585 | validation: 0.12543333815407876]
	TIME [epoch: 8.52 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12392816089649353		[learning rate: 0.00066163]
	Learning Rate: 0.00066163
	LOSS [training: 0.12392816089649353 | validation: 0.12215986719375388]
	TIME [epoch: 8.52 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11510857032033243		[learning rate: 0.00066007]
	Learning Rate: 0.00066007
	LOSS [training: 0.11510857032033243 | validation: 0.12453442550518708]
	TIME [epoch: 8.52 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11127575253009644		[learning rate: 0.00065851]
	Learning Rate: 0.000658513
	LOSS [training: 0.11127575253009644 | validation: 0.1298915756150387]
	TIME [epoch: 8.54 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12426246351006746		[learning rate: 0.00065696]
	Learning Rate: 0.000656959
	LOSS [training: 0.12426246351006746 | validation: 0.10868769874588474]
	TIME [epoch: 8.52 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10967384828733548		[learning rate: 0.00065541]
	Learning Rate: 0.00065541
	LOSS [training: 0.10967384828733548 | validation: 0.12417760581147588]
	TIME [epoch: 8.53 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11412167360543939		[learning rate: 0.00065386]
	Learning Rate: 0.000653864
	LOSS [training: 0.11412167360543939 | validation: 0.09749288907613612]
	TIME [epoch: 8.53 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11842093644439458		[learning rate: 0.00065232]
	Learning Rate: 0.000652321
	LOSS [training: 0.11842093644439458 | validation: 0.14606693880387478]
	TIME [epoch: 8.53 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13631136596462956		[learning rate: 0.00065078]
	Learning Rate: 0.000650783
	LOSS [training: 0.13631136596462956 | validation: 0.1163967671789927]
	TIME [epoch: 8.52 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10034392324375078		[learning rate: 0.00064925]
	Learning Rate: 0.000649247
	LOSS [training: 0.10034392324375078 | validation: 0.09722938111553073]
	TIME [epoch: 8.53 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1163178328128213		[learning rate: 0.00064772]
	Learning Rate: 0.000647716
	LOSS [training: 0.1163178328128213 | validation: 0.1338277588892935]
	TIME [epoch: 8.54 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10243171445048778		[learning rate: 0.00064619]
	Learning Rate: 0.000646188
	LOSS [training: 0.10243171445048778 | validation: 0.10878765886378552]
	TIME [epoch: 8.53 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11121234281938978		[learning rate: 0.00064466]
	Learning Rate: 0.000644664
	LOSS [training: 0.11121234281938978 | validation: 0.15954067218321452]
	TIME [epoch: 8.52 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10380606444531104		[learning rate: 0.00064314]
	Learning Rate: 0.000643143
	LOSS [training: 0.10380606444531104 | validation: 0.11638488639362363]
	TIME [epoch: 8.52 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09408604034563853		[learning rate: 0.00064163]
	Learning Rate: 0.000641626
	LOSS [training: 0.09408604034563853 | validation: 0.08852703251850205]
	TIME [epoch: 8.54 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10638619714479325		[learning rate: 0.00064011]
	Learning Rate: 0.000640113
	LOSS [training: 0.10638619714479325 | validation: 0.14003425209364198]
	TIME [epoch: 8.53 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11883350335860673		[learning rate: 0.0006386]
	Learning Rate: 0.000638603
	LOSS [training: 0.11883350335860673 | validation: 0.13723078101859543]
	TIME [epoch: 8.52 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10966034987278987		[learning rate: 0.0006371]
	Learning Rate: 0.000637096
	LOSS [training: 0.10966034987278987 | validation: 0.1031168235009601]
	TIME [epoch: 8.52 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1221288362175877		[learning rate: 0.00063559]
	Learning Rate: 0.000635594
	LOSS [training: 0.1221288362175877 | validation: 0.15537592620507293]
	TIME [epoch: 8.54 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1306794290544779		[learning rate: 0.00063409]
	Learning Rate: 0.000634094
	LOSS [training: 0.1306794290544779 | validation: 0.11000963109619122]
	TIME [epoch: 8.53 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10676647826156072		[learning rate: 0.0006326]
	Learning Rate: 0.000632598
	LOSS [training: 0.10676647826156072 | validation: 0.12422669205465356]
	TIME [epoch: 8.52 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11062163678140384		[learning rate: 0.00063111]
	Learning Rate: 0.000631106
	LOSS [training: 0.11062163678140384 | validation: 0.14530531977780992]
	TIME [epoch: 8.52 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12896627264678867		[learning rate: 0.00062962]
	Learning Rate: 0.000629618
	LOSS [training: 0.12896627264678867 | validation: 0.10990504860269487]
	TIME [epoch: 8.54 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10827290517787132		[learning rate: 0.00062813]
	Learning Rate: 0.000628132
	LOSS [training: 0.10827290517787132 | validation: 0.13229730369097786]
	TIME [epoch: 8.52 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09588156874184768		[learning rate: 0.00062665]
	Learning Rate: 0.000626651
	LOSS [training: 0.09588156874184768 | validation: 0.12179430747725008]
	TIME [epoch: 8.52 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11205783489927768		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.11205783489927768 | validation: 0.09857683914177333]
	TIME [epoch: 8.52 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09881727508427417		[learning rate: 0.0006237]
	Learning Rate: 0.000623698
	LOSS [training: 0.09881727508427417 | validation: 0.19087289853932415]
	TIME [epoch: 8.54 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11375099097488137		[learning rate: 0.00062223]
	Learning Rate: 0.000622227
	LOSS [training: 0.11375099097488137 | validation: 0.10574993218017639]
	TIME [epoch: 8.52 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10988587571364809		[learning rate: 0.00062076]
	Learning Rate: 0.000620759
	LOSS [training: 0.10988587571364809 | validation: 0.10914310988599113]
	TIME [epoch: 8.52 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1254090974448085		[learning rate: 0.00061929]
	Learning Rate: 0.000619295
	LOSS [training: 0.1254090974448085 | validation: 0.11339389781883494]
	TIME [epoch: 8.52 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09157090296460736		[learning rate: 0.00061783]
	Learning Rate: 0.000617834
	LOSS [training: 0.09157090296460736 | validation: 0.1206744191518595]
	TIME [epoch: 8.54 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12305092721773092		[learning rate: 0.00061638]
	Learning Rate: 0.000616377
	LOSS [training: 0.12305092721773092 | validation: 0.12464220554741734]
	TIME [epoch: 8.52 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12124757131788502		[learning rate: 0.00061492]
	Learning Rate: 0.000614923
	LOSS [training: 0.12124757131788502 | validation: 0.11869184281497319]
	TIME [epoch: 8.52 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09666985148453308		[learning rate: 0.00061347]
	Learning Rate: 0.000613472
	LOSS [training: 0.09666985148453308 | validation: 0.14025589209861009]
	TIME [epoch: 8.52 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11974221242428791		[learning rate: 0.00061203]
	Learning Rate: 0.000612025
	LOSS [training: 0.11974221242428791 | validation: 0.11077267854564474]
	TIME [epoch: 8.55 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10936076372353958		[learning rate: 0.00061058]
	Learning Rate: 0.000610581
	LOSS [training: 0.10936076372353958 | validation: 0.10777787848763287]
	TIME [epoch: 8.52 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09500943820366999		[learning rate: 0.00060914]
	Learning Rate: 0.000609141
	LOSS [training: 0.09500943820366999 | validation: 0.08914141164475343]
	TIME [epoch: 8.52 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10504205675037803		[learning rate: 0.0006077]
	Learning Rate: 0.000607704
	LOSS [training: 0.10504205675037803 | validation: 0.11385050256518234]
	TIME [epoch: 8.53 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10501486713325783		[learning rate: 0.00060627]
	Learning Rate: 0.000606271
	LOSS [training: 0.10501486713325783 | validation: 0.1203839035418117]
	TIME [epoch: 8.53 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10713965054681511		[learning rate: 0.00060484]
	Learning Rate: 0.000604841
	LOSS [training: 0.10713965054681511 | validation: 0.09582253992854606]
	TIME [epoch: 8.52 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10673248491048962		[learning rate: 0.00060341]
	Learning Rate: 0.000603414
	LOSS [training: 0.10673248491048962 | validation: 0.12539138639328848]
	TIME [epoch: 8.52 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11624436397482488		[learning rate: 0.00060199]
	Learning Rate: 0.000601991
	LOSS [training: 0.11624436397482488 | validation: 0.11802048739300527]
	TIME [epoch: 8.54 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09869658606262792		[learning rate: 0.00060057]
	Learning Rate: 0.000600571
	LOSS [training: 0.09869658606262792 | validation: 0.09595361486296478]
	TIME [epoch: 8.53 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08870289637199652		[learning rate: 0.00059915]
	Learning Rate: 0.000599154
	LOSS [training: 0.08870289637199652 | validation: 0.12681943908685747]
	TIME [epoch: 8.52 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10434235762607094		[learning rate: 0.00059774]
	Learning Rate: 0.000597741
	LOSS [training: 0.10434235762607094 | validation: 0.13300743879471913]
	TIME [epoch: 8.52 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10146417533421848		[learning rate: 0.00059633]
	Learning Rate: 0.000596331
	LOSS [training: 0.10146417533421848 | validation: 0.14307087095339377]
	TIME [epoch: 8.54 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11076822271020821		[learning rate: 0.00059492]
	Learning Rate: 0.000594924
	LOSS [training: 0.11076822271020821 | validation: 0.11127281247595672]
	TIME [epoch: 8.53 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09434413968020189		[learning rate: 0.00059352]
	Learning Rate: 0.000593521
	LOSS [training: 0.09434413968020189 | validation: 0.1164172661912799]
	TIME [epoch: 8.52 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12090948858029327		[learning rate: 0.00059212]
	Learning Rate: 0.000592121
	LOSS [training: 0.12090948858029327 | validation: 0.1129352648437438]
	TIME [epoch: 8.52 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10936809102181763		[learning rate: 0.00059072]
	Learning Rate: 0.000590724
	LOSS [training: 0.10936809102181763 | validation: 0.1228973871536515]
	TIME [epoch: 8.54 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13828169549124078		[learning rate: 0.00058933]
	Learning Rate: 0.000589331
	LOSS [training: 0.13828169549124078 | validation: 0.14928020970256994]
	TIME [epoch: 8.52 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10486957173081864		[learning rate: 0.00058794]
	Learning Rate: 0.00058794
	LOSS [training: 0.10486957173081864 | validation: 0.11166625211993594]
	TIME [epoch: 8.52 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11291090185855249		[learning rate: 0.00058655]
	Learning Rate: 0.000586554
	LOSS [training: 0.11291090185855249 | validation: 0.11982116653494407]
	TIME [epoch: 8.52 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1336326703972054		[learning rate: 0.00058517]
	Learning Rate: 0.00058517
	LOSS [training: 0.1336326703972054 | validation: 0.11629573119527084]
	TIME [epoch: 8.54 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10406612310402978		[learning rate: 0.00058379]
	Learning Rate: 0.00058379
	LOSS [training: 0.10406612310402978 | validation: 0.11731370042522496]
	TIME [epoch: 8.52 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1166359607445415		[learning rate: 0.00058241]
	Learning Rate: 0.000582413
	LOSS [training: 0.1166359607445415 | validation: 0.10530171979042052]
	TIME [epoch: 8.52 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08990514152526523		[learning rate: 0.00058104]
	Learning Rate: 0.000581039
	LOSS [training: 0.08990514152526523 | validation: 0.0914425677877258]
	TIME [epoch: 8.52 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10526242770047785		[learning rate: 0.00057967]
	Learning Rate: 0.000579668
	LOSS [training: 0.10526242770047785 | validation: 0.12642059625733287]
	TIME [epoch: 8.54 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10812254367975864		[learning rate: 0.0005783]
	Learning Rate: 0.000578301
	LOSS [training: 0.10812254367975864 | validation: 0.0899764264425205]
	TIME [epoch: 8.52 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10365680490684011		[learning rate: 0.00057694]
	Learning Rate: 0.000576937
	LOSS [training: 0.10365680490684011 | validation: 0.14661396511813612]
	TIME [epoch: 8.52 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10346239131693605		[learning rate: 0.00057558]
	Learning Rate: 0.000575576
	LOSS [training: 0.10346239131693605 | validation: 0.09448508058491285]
	TIME [epoch: 8.52 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1028586917681493		[learning rate: 0.00057422]
	Learning Rate: 0.000574218
	LOSS [training: 0.1028586917681493 | validation: 0.11290380800891173]
	TIME [epoch: 8.54 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11015839558595386		[learning rate: 0.00057286]
	Learning Rate: 0.000572864
	LOSS [training: 0.11015839558595386 | validation: 0.10739978235383285]
	TIME [epoch: 8.52 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08857246301360779		[learning rate: 0.00057151]
	Learning Rate: 0.000571512
	LOSS [training: 0.08857246301360779 | validation: 0.12547223812407687]
	TIME [epoch: 8.52 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11388894661983881		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.11388894661983881 | validation: 0.08978300917288137]
	TIME [epoch: 8.52 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09750908633750671		[learning rate: 0.00056882]
	Learning Rate: 0.000568819
	LOSS [training: 0.09750908633750671 | validation: 0.13234765513913765]
	TIME [epoch: 8.54 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10726143970715804		[learning rate: 0.00056748]
	Learning Rate: 0.000567478
	LOSS [training: 0.10726143970715804 | validation: 0.13091112870508617]
	TIME [epoch: 8.52 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09526060955608158		[learning rate: 0.00056614]
	Learning Rate: 0.000566139
	LOSS [training: 0.09526060955608158 | validation: 0.11384549875774294]
	TIME [epoch: 8.52 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10064515383626649		[learning rate: 0.0005648]
	Learning Rate: 0.000564804
	LOSS [training: 0.10064515383626649 | validation: 0.16375903827680488]
	TIME [epoch: 8.53 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10402914954708076		[learning rate: 0.00056347]
	Learning Rate: 0.000563471
	LOSS [training: 0.10402914954708076 | validation: 0.11573115133670724]
	TIME [epoch: 8.53 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09143641012188022		[learning rate: 0.00056214]
	Learning Rate: 0.000562142
	LOSS [training: 0.09143641012188022 | validation: 0.09529423826105676]
	TIME [epoch: 8.52 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08322226679453969		[learning rate: 0.00056082]
	Learning Rate: 0.000560816
	LOSS [training: 0.08322226679453969 | validation: 0.09322828744828664]
	TIME [epoch: 8.52 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1085723983392416		[learning rate: 0.00055949]
	Learning Rate: 0.000559493
	LOSS [training: 0.1085723983392416 | validation: 0.10250381998176927]
	TIME [epoch: 8.53 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09626995339097233		[learning rate: 0.00055817]
	Learning Rate: 0.000558173
	LOSS [training: 0.09626995339097233 | validation: 0.10583315586265285]
	TIME [epoch: 8.53 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09809201713155774		[learning rate: 0.00055686]
	Learning Rate: 0.000556857
	LOSS [training: 0.09809201713155774 | validation: 0.09121181810821202]
	TIME [epoch: 8.52 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12110090963518831		[learning rate: 0.00055554]
	Learning Rate: 0.000555543
	LOSS [training: 0.12110090963518831 | validation: 0.11147633058815812]
	TIME [epoch: 8.51 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12395451522356242		[learning rate: 0.00055423]
	Learning Rate: 0.000554233
	LOSS [training: 0.12395451522356242 | validation: 0.12620047350487876]
	TIME [epoch: 8.54 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12233384664758354		[learning rate: 0.00055293]
	Learning Rate: 0.000552925
	LOSS [training: 0.12233384664758354 | validation: 0.1458585257317554]
	TIME [epoch: 8.52 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11772837222974866		[learning rate: 0.00055162]
	Learning Rate: 0.000551621
	LOSS [training: 0.11772837222974866 | validation: 0.08535968657891735]
	TIME [epoch: 8.52 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1013434936054374		[learning rate: 0.00055032]
	Learning Rate: 0.00055032
	LOSS [training: 0.1013434936054374 | validation: 0.09611052493121836]
	TIME [epoch: 8.52 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0960058616565991		[learning rate: 0.00054902]
	Learning Rate: 0.000549022
	LOSS [training: 0.0960058616565991 | validation: 0.1224444086828409]
	TIME [epoch: 8.54 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09573682088938947		[learning rate: 0.00054773]
	Learning Rate: 0.000547727
	LOSS [training: 0.09573682088938947 | validation: 0.10026987043937578]
	TIME [epoch: 8.52 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10231993823359545		[learning rate: 0.00054643]
	Learning Rate: 0.000546435
	LOSS [training: 0.10231993823359545 | validation: 0.08767523214720802]
	TIME [epoch: 8.51 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08845285522099859		[learning rate: 0.00054515]
	Learning Rate: 0.000545146
	LOSS [training: 0.08845285522099859 | validation: 0.08254852045112775]
	TIME [epoch: 8.52 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10356613699164485		[learning rate: 0.00054386]
	Learning Rate: 0.00054386
	LOSS [training: 0.10356613699164485 | validation: 0.13289870631598794]
	TIME [epoch: 8.54 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1056656197615686		[learning rate: 0.00054258]
	Learning Rate: 0.000542577
	LOSS [training: 0.1056656197615686 | validation: 0.09661797121214108]
	TIME [epoch: 8.52 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09442133408583134		[learning rate: 0.0005413]
	Learning Rate: 0.000541297
	LOSS [training: 0.09442133408583134 | validation: 0.13000254627512703]
	TIME [epoch: 8.52 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10735388987905499		[learning rate: 0.00054002]
	Learning Rate: 0.00054002
	LOSS [training: 0.10735388987905499 | validation: 0.10472012878856277]
	TIME [epoch: 8.52 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0946299787204709		[learning rate: 0.00053875]
	Learning Rate: 0.000538747
	LOSS [training: 0.0946299787204709 | validation: 0.10109340715172058]
	TIME [epoch: 8.54 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10488695472307241		[learning rate: 0.00053748]
	Learning Rate: 0.000537476
	LOSS [training: 0.10488695472307241 | validation: 0.11984300596878937]
	TIME [epoch: 8.52 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09820793048012491		[learning rate: 0.00053621]
	Learning Rate: 0.000536208
	LOSS [training: 0.09820793048012491 | validation: 0.10606107471382098]
	TIME [epoch: 8.52 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10868314275819049		[learning rate: 0.00053494]
	Learning Rate: 0.000534943
	LOSS [training: 0.10868314275819049 | validation: 0.08116554895048127]
	TIME [epoch: 8.52 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11234223063733868		[learning rate: 0.00053368]
	Learning Rate: 0.000533681
	LOSS [training: 0.11234223063733868 | validation: 0.11933555504685106]
	TIME [epoch: 8.54 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10523694984851177		[learning rate: 0.00053242]
	Learning Rate: 0.000532422
	LOSS [training: 0.10523694984851177 | validation: 0.09741400961356855]
	TIME [epoch: 8.52 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09413607073084419		[learning rate: 0.00053117]
	Learning Rate: 0.000531167
	LOSS [training: 0.09413607073084419 | validation: 0.0905507284021491]
	TIME [epoch: 8.52 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09886501477029601		[learning rate: 0.00052991]
	Learning Rate: 0.000529914
	LOSS [training: 0.09886501477029601 | validation: 0.09655841572120843]
	TIME [epoch: 8.52 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1210503973730589		[learning rate: 0.00052866]
	Learning Rate: 0.000528664
	LOSS [training: 0.1210503973730589 | validation: 0.13773627433400093]
	TIME [epoch: 8.54 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12209546716041397		[learning rate: 0.00052742]
	Learning Rate: 0.000527417
	LOSS [training: 0.12209546716041397 | validation: 0.10182969303434602]
	TIME [epoch: 8.52 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10134285922551634		[learning rate: 0.00052617]
	Learning Rate: 0.000526173
	LOSS [training: 0.10134285922551634 | validation: 0.11604446792400623]
	TIME [epoch: 8.51 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10412288961528741		[learning rate: 0.00052493]
	Learning Rate: 0.000524931
	LOSS [training: 0.10412288961528741 | validation: 0.08167880577637314]
	TIME [epoch: 8.52 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09358847052320182		[learning rate: 0.00052369]
	Learning Rate: 0.000523693
	LOSS [training: 0.09358847052320182 | validation: 0.10905184690912048]
	TIME [epoch: 8.53 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09264595324046736		[learning rate: 0.00052246]
	Learning Rate: 0.000522458
	LOSS [training: 0.09264595324046736 | validation: 0.08552372953951318]
	TIME [epoch: 8.52 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08707999733041513		[learning rate: 0.00052123]
	Learning Rate: 0.000521225
	LOSS [training: 0.08707999733041513 | validation: 0.09624225397745281]
	TIME [epoch: 8.51 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09713789118049146		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.09713789118049146 | validation: 0.09593548628814795]
	TIME [epoch: 8.53 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09079434107995794		[learning rate: 0.00051877]
	Learning Rate: 0.000518769
	LOSS [training: 0.09079434107995794 | validation: 0.11084339289513068]
	TIME [epoch: 8.52 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.123268797280442		[learning rate: 0.00051755]
	Learning Rate: 0.000517546
	LOSS [training: 0.123268797280442 | validation: 0.09648157479042449]
	TIME [epoch: 8.52 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10283793689937351		[learning rate: 0.00051632]
	Learning Rate: 0.000516325
	LOSS [training: 0.10283793689937351 | validation: 0.13473218620305077]
	TIME [epoch: 8.51 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10256069894190853		[learning rate: 0.00051511]
	Learning Rate: 0.000515107
	LOSS [training: 0.10256069894190853 | validation: 0.11154477365013504]
	TIME [epoch: 8.54 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09673841512372107		[learning rate: 0.00051389]
	Learning Rate: 0.000513892
	LOSS [training: 0.09673841512372107 | validation: 0.11499376192811842]
	TIME [epoch: 8.52 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10240243007675716		[learning rate: 0.00051268]
	Learning Rate: 0.00051268
	LOSS [training: 0.10240243007675716 | validation: 0.08730745902888962]
	TIME [epoch: 8.52 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09280806741893037		[learning rate: 0.00051147]
	Learning Rate: 0.00051147
	LOSS [training: 0.09280806741893037 | validation: 0.0774380275534761]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_1309.pth
	Model improved!!!
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08218449985562919		[learning rate: 0.00051026]
	Learning Rate: 0.000510264
	LOSS [training: 0.08218449985562919 | validation: 0.09326236454881692]
	TIME [epoch: 8.53 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09855422867878678		[learning rate: 0.00050906]
	Learning Rate: 0.00050906
	LOSS [training: 0.09855422867878678 | validation: 0.10587299122345252]
	TIME [epoch: 8.52 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08646393037773469		[learning rate: 0.00050786]
	Learning Rate: 0.000507859
	LOSS [training: 0.08646393037773469 | validation: 0.09055714013260663]
	TIME [epoch: 8.51 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0913272391371565		[learning rate: 0.00050666]
	Learning Rate: 0.000506662
	LOSS [training: 0.0913272391371565 | validation: 0.10006965626945818]
	TIME [epoch: 8.51 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10769280182076349		[learning rate: 0.00050547]
	Learning Rate: 0.000505466
	LOSS [training: 0.10769280182076349 | validation: 0.1299362631495979]
	TIME [epoch: 8.53 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08838517586535484		[learning rate: 0.00050427]
	Learning Rate: 0.000504274
	LOSS [training: 0.08838517586535484 | validation: 0.08089906043441296]
	TIME [epoch: 8.51 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08988640177595666		[learning rate: 0.00050308]
	Learning Rate: 0.000503085
	LOSS [training: 0.08988640177595666 | validation: 0.08602081558858304]
	TIME [epoch: 8.51 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1107390244241496		[learning rate: 0.0005019]
	Learning Rate: 0.000501898
	LOSS [training: 0.1107390244241496 | validation: 0.09548851012217861]
	TIME [epoch: 8.51 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08687477739023419		[learning rate: 0.00050071]
	Learning Rate: 0.000500714
	LOSS [training: 0.08687477739023419 | validation: 0.09123553759421796]
	TIME [epoch: 8.54 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.103156843330381		[learning rate: 0.00049953]
	Learning Rate: 0.000499533
	LOSS [training: 0.103156843330381 | validation: 0.11076459727655874]
	TIME [epoch: 8.51 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09058874354597703		[learning rate: 0.00049835]
	Learning Rate: 0.000498355
	LOSS [training: 0.09058874354597703 | validation: 0.0931454633631093]
	TIME [epoch: 8.51 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10213961878569293		[learning rate: 0.00049718]
	Learning Rate: 0.000497179
	LOSS [training: 0.10213961878569293 | validation: 0.09252100279431681]
	TIME [epoch: 8.51 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10006693737529233		[learning rate: 0.00049601]
	Learning Rate: 0.000496006
	LOSS [training: 0.10006693737529233 | validation: 0.1160091358506949]
	TIME [epoch: 8.54 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09398621340573046		[learning rate: 0.00049484]
	Learning Rate: 0.000494836
	LOSS [training: 0.09398621340573046 | validation: 0.09212769969249031]
	TIME [epoch: 8.51 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12805943778828577		[learning rate: 0.00049367]
	Learning Rate: 0.000493669
	LOSS [training: 0.12805943778828577 | validation: 0.09363226272282135]
	TIME [epoch: 8.51 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09932514790602884		[learning rate: 0.0004925]
	Learning Rate: 0.000492505
	LOSS [training: 0.09932514790602884 | validation: 0.13214876943092202]
	TIME [epoch: 8.51 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10237798245083093		[learning rate: 0.00049134]
	Learning Rate: 0.000491343
	LOSS [training: 0.10237798245083093 | validation: 0.08088860980341236]
	TIME [epoch: 8.53 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09323340072363208		[learning rate: 0.00049018]
	Learning Rate: 0.000490184
	LOSS [training: 0.09323340072363208 | validation: 0.10348517702761528]
	TIME [epoch: 8.51 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10723900995228512		[learning rate: 0.00048903]
	Learning Rate: 0.000489027
	LOSS [training: 0.10723900995228512 | validation: 0.10893702052928003]
	TIME [epoch: 8.51 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10024352956696854		[learning rate: 0.00048787]
	Learning Rate: 0.000487874
	LOSS [training: 0.10024352956696854 | validation: 0.10583743959331857]
	TIME [epoch: 8.52 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09490690715736802		[learning rate: 0.00048672]
	Learning Rate: 0.000486723
	LOSS [training: 0.09490690715736802 | validation: 0.07985438800730373]
	TIME [epoch: 8.52 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09044907773221122		[learning rate: 0.00048558]
	Learning Rate: 0.000485575
	LOSS [training: 0.09044907773221122 | validation: 0.08652585249100195]
	TIME [epoch: 8.51 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08529979840166287		[learning rate: 0.00048443]
	Learning Rate: 0.00048443
	LOSS [training: 0.08529979840166287 | validation: 0.08835989003467158]
	TIME [epoch: 8.51 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09041030029861241		[learning rate: 0.00048329]
	Learning Rate: 0.000483287
	LOSS [training: 0.09041030029861241 | validation: 0.07372317428745406]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_1333.pth
	Model improved!!!
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0961930233896589		[learning rate: 0.00048215]
	Learning Rate: 0.000482147
	LOSS [training: 0.0961930233896589 | validation: 0.11399875921043146]
	TIME [epoch: 8.52 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11021747764169673		[learning rate: 0.00048101]
	Learning Rate: 0.00048101
	LOSS [training: 0.11021747764169673 | validation: 0.1214443055137133]
	TIME [epoch: 8.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09954070419913028		[learning rate: 0.00047988]
	Learning Rate: 0.000479875
	LOSS [training: 0.09954070419913028 | validation: 0.1029830873418331]
	TIME [epoch: 8.51 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10659966701302351		[learning rate: 0.00047874]
	Learning Rate: 0.000478743
	LOSS [training: 0.10659966701302351 | validation: 0.08744455508875847]
	TIME [epoch: 8.52 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0953122254848744		[learning rate: 0.00047761]
	Learning Rate: 0.000477614
	LOSS [training: 0.0953122254848744 | validation: 0.10003702744564649]
	TIME [epoch: 8.52 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10072182673775916		[learning rate: 0.00047649]
	Learning Rate: 0.000476487
	LOSS [training: 0.10072182673775916 | validation: 0.07554219892276838]
	TIME [epoch: 8.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09489583499221096		[learning rate: 0.00047536]
	Learning Rate: 0.000475363
	LOSS [training: 0.09489583499221096 | validation: 0.09598800070060032]
	TIME [epoch: 8.51 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11683790578434447		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.11683790578434447 | validation: 0.12309238678673692]
	TIME [epoch: 8.53 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11799733268768176		[learning rate: 0.00047312]
	Learning Rate: 0.000473123
	LOSS [training: 0.11799733268768176 | validation: 0.11158206195772376]
	TIME [epoch: 8.51 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09736060252971634		[learning rate: 0.00047201]
	Learning Rate: 0.000472007
	LOSS [training: 0.09736060252971634 | validation: 0.0986601062804815]
	TIME [epoch: 8.51 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10801557738536507		[learning rate: 0.00047089]
	Learning Rate: 0.000470894
	LOSS [training: 0.10801557738536507 | validation: 0.09953061533782304]
	TIME [epoch: 8.51 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11129259607049638		[learning rate: 0.00046978]
	Learning Rate: 0.000469783
	LOSS [training: 0.11129259607049638 | validation: 0.11355300908491131]
	TIME [epoch: 8.53 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10548578208355017		[learning rate: 0.00046867]
	Learning Rate: 0.000468675
	LOSS [training: 0.10548578208355017 | validation: 0.1040321818841328]
	TIME [epoch: 8.51 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0948289850236339		[learning rate: 0.00046757]
	Learning Rate: 0.000467569
	LOSS [training: 0.0948289850236339 | validation: 0.10214365717682579]
	TIME [epoch: 8.51 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09658555739586856		[learning rate: 0.00046647]
	Learning Rate: 0.000466467
	LOSS [training: 0.09658555739586856 | validation: 0.11395879767249076]
	TIME [epoch: 8.51 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09430617532800988		[learning rate: 0.00046537]
	Learning Rate: 0.000465366
	LOSS [training: 0.09430617532800988 | validation: 0.1088920238536395]
	TIME [epoch: 8.53 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08632295698663293		[learning rate: 0.00046427]
	Learning Rate: 0.000464269
	LOSS [training: 0.08632295698663293 | validation: 0.10335661998879216]
	TIME [epoch: 8.51 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09069974504304411		[learning rate: 0.00046317]
	Learning Rate: 0.000463173
	LOSS [training: 0.09069974504304411 | validation: 0.12504819985463822]
	TIME [epoch: 8.51 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09856879656098658		[learning rate: 0.00046208]
	Learning Rate: 0.000462081
	LOSS [training: 0.09856879656098658 | validation: 0.08694327102625364]
	TIME [epoch: 8.51 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11398267762303926		[learning rate: 0.00046099]
	Learning Rate: 0.000460991
	LOSS [training: 0.11398267762303926 | validation: 0.0942175743636314]
	TIME [epoch: 8.54 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0852761608948649		[learning rate: 0.0004599]
	Learning Rate: 0.000459903
	LOSS [training: 0.0852761608948649 | validation: 0.09202270155367043]
	TIME [epoch: 8.52 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08331962782011545		[learning rate: 0.00045882]
	Learning Rate: 0.000458819
	LOSS [training: 0.08331962782011545 | validation: 0.08694390546347847]
	TIME [epoch: 8.51 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.089529220071457		[learning rate: 0.00045774]
	Learning Rate: 0.000457736
	LOSS [training: 0.089529220071457 | validation: 0.08213127652426944]
	TIME [epoch: 8.51 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09924445406990792		[learning rate: 0.00045666]
	Learning Rate: 0.000456657
	LOSS [training: 0.09924445406990792 | validation: 0.0966370124032224]
	TIME [epoch: 8.53 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09442326007368308		[learning rate: 0.00045558]
	Learning Rate: 0.000455579
	LOSS [training: 0.09442326007368308 | validation: 0.07545024476129718]
	TIME [epoch: 8.51 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09178089475848872		[learning rate: 0.0004545]
	Learning Rate: 0.000454505
	LOSS [training: 0.09178089475848872 | validation: 0.10518701386299364]
	TIME [epoch: 8.51 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08720183937717921		[learning rate: 0.00045343]
	Learning Rate: 0.000453433
	LOSS [training: 0.08720183937717921 | validation: 0.09118156185890541]
	TIME [epoch: 8.52 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09690157219384345		[learning rate: 0.00045236]
	Learning Rate: 0.000452363
	LOSS [training: 0.09690157219384345 | validation: 0.09006085395598545]
	TIME [epoch: 8.53 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08332303669764694		[learning rate: 0.0004513]
	Learning Rate: 0.000451296
	LOSS [training: 0.08332303669764694 | validation: 0.07471838879307963]
	TIME [epoch: 8.51 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11284742566967876		[learning rate: 0.00045023]
	Learning Rate: 0.000450232
	LOSS [training: 0.11284742566967876 | validation: 0.07907820123450432]
	TIME [epoch: 8.51 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09900796654948023		[learning rate: 0.00044917]
	Learning Rate: 0.000449169
	LOSS [training: 0.09900796654948023 | validation: 0.0964048259148842]
	TIME [epoch: 8.53 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12116925118549764		[learning rate: 0.00044811]
	Learning Rate: 0.00044811
	LOSS [training: 0.12116925118549764 | validation: 0.09279640993891342]
	TIME [epoch: 8.52 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.091647899443728		[learning rate: 0.00044705]
	Learning Rate: 0.000447053
	LOSS [training: 0.091647899443728 | validation: 0.11417308402742939]
	TIME [epoch: 8.51 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09032692111718797		[learning rate: 0.000446]
	Learning Rate: 0.000445998
	LOSS [training: 0.09032692111718797 | validation: 0.10103440582056178]
	TIME [epoch: 8.51 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09334167294173416		[learning rate: 0.00044495]
	Learning Rate: 0.000444946
	LOSS [training: 0.09334167294173416 | validation: 0.12263527425435661]
	TIME [epoch: 8.53 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09572259249680999		[learning rate: 0.0004439]
	Learning Rate: 0.000443897
	LOSS [training: 0.09572259249680999 | validation: 0.13410841028490011]
	TIME [epoch: 8.51 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10110327075385059		[learning rate: 0.00044285]
	Learning Rate: 0.00044285
	LOSS [training: 0.10110327075385059 | validation: 0.08908779981152677]
	TIME [epoch: 8.51 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09455440184224947		[learning rate: 0.00044181]
	Learning Rate: 0.000441805
	LOSS [training: 0.09455440184224947 | validation: 0.09452125665852618]
	TIME [epoch: 8.51 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09740795102333105		[learning rate: 0.00044076]
	Learning Rate: 0.000440763
	LOSS [training: 0.09740795102333105 | validation: 0.09906808515726395]
	TIME [epoch: 8.53 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1022969827987998		[learning rate: 0.00043972]
	Learning Rate: 0.000439723
	LOSS [training: 0.1022969827987998 | validation: 0.10081715302353055]
	TIME [epoch: 8.52 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0946750993661663		[learning rate: 0.00043869]
	Learning Rate: 0.000438686
	LOSS [training: 0.0946750993661663 | validation: 0.10748182653973434]
	TIME [epoch: 8.51 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0863047196880222		[learning rate: 0.00043765]
	Learning Rate: 0.000437651
	LOSS [training: 0.0863047196880222 | validation: 0.07992563563950983]
	TIME [epoch: 8.51 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09360967567525855		[learning rate: 0.00043662]
	Learning Rate: 0.000436619
	LOSS [training: 0.09360967567525855 | validation: 0.07832173908452267]
	TIME [epoch: 8.53 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09982100841164178		[learning rate: 0.00043559]
	Learning Rate: 0.000435589
	LOSS [training: 0.09982100841164178 | validation: 0.10411393739966877]
	TIME [epoch: 8.51 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09812011945254177		[learning rate: 0.00043456]
	Learning Rate: 0.000434562
	LOSS [training: 0.09812011945254177 | validation: 0.10239516805444063]
	TIME [epoch: 8.51 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10004515748603218		[learning rate: 0.00043354]
	Learning Rate: 0.000433536
	LOSS [training: 0.10004515748603218 | validation: 0.08793763690962751]
	TIME [epoch: 8.51 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08533914973157986		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.08533914973157986 | validation: 0.12354048630270581]
	TIME [epoch: 8.53 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11184396877970962		[learning rate: 0.00043149]
	Learning Rate: 0.000431494
	LOSS [training: 0.11184396877970962 | validation: 0.09633336701457179]
	TIME [epoch: 8.51 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09331434264706748		[learning rate: 0.00043048]
	Learning Rate: 0.000430476
	LOSS [training: 0.09331434264706748 | validation: 0.12461385286172007]
	TIME [epoch: 8.51 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11668805844671948		[learning rate: 0.00042946]
	Learning Rate: 0.00042946
	LOSS [training: 0.11668805844671948 | validation: 0.10912552371547875]
	TIME [epoch: 8.51 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12985992423598908		[learning rate: 0.00042845]
	Learning Rate: 0.000428447
	LOSS [training: 0.12985992423598908 | validation: 0.09548322127768827]
	TIME [epoch: 8.53 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09180513619635025		[learning rate: 0.00042744]
	Learning Rate: 0.000427437
	LOSS [training: 0.09180513619635025 | validation: 0.08624569059827177]
	TIME [epoch: 8.51 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08033634826037404		[learning rate: 0.00042643]
	Learning Rate: 0.000426428
	LOSS [training: 0.08033634826037404 | validation: 0.09887224088274915]
	TIME [epoch: 8.51 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0878865194883373		[learning rate: 0.00042542]
	Learning Rate: 0.000425423
	LOSS [training: 0.0878865194883373 | validation: 0.09337981001017175]
	TIME [epoch: 8.51 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0931424389877967		[learning rate: 0.00042442]
	Learning Rate: 0.000424419
	LOSS [training: 0.0931424389877967 | validation: 0.10899760923119557]
	TIME [epoch: 8.53 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0944032510620844		[learning rate: 0.00042342]
	Learning Rate: 0.000423418
	LOSS [training: 0.0944032510620844 | validation: 0.08982105029891874]
	TIME [epoch: 8.51 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09917958499166629		[learning rate: 0.00042242]
	Learning Rate: 0.000422419
	LOSS [training: 0.09917958499166629 | validation: 0.09081558805826453]
	TIME [epoch: 8.51 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08573675024174982		[learning rate: 0.00042142]
	Learning Rate: 0.000421423
	LOSS [training: 0.08573675024174982 | validation: 0.07740760710334081]
	TIME [epoch: 8.51 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0811978325627282		[learning rate: 0.00042043]
	Learning Rate: 0.000420429
	LOSS [training: 0.0811978325627282 | validation: 0.09274659326394773]
	TIME [epoch: 8.53 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0829749683904235		[learning rate: 0.00041944]
	Learning Rate: 0.000419437
	LOSS [training: 0.0829749683904235 | validation: 0.09749939028240351]
	TIME [epoch: 8.51 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09466479506161274		[learning rate: 0.00041845]
	Learning Rate: 0.000418448
	LOSS [training: 0.09466479506161274 | validation: 0.0904420231634593]
	TIME [epoch: 8.51 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08920880744204303		[learning rate: 0.00041746]
	Learning Rate: 0.00041746
	LOSS [training: 0.08920880744204303 | validation: 0.08674085817156281]
	TIME [epoch: 8.52 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08868549484216871		[learning rate: 0.00041648]
	Learning Rate: 0.000416476
	LOSS [training: 0.08868549484216871 | validation: 0.13273915248902213]
	TIME [epoch: 8.53 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09761856233193364		[learning rate: 0.00041549]
	Learning Rate: 0.000415493
	LOSS [training: 0.09761856233193364 | validation: 0.08776607815082402]
	TIME [epoch: 8.51 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08106556244508109		[learning rate: 0.00041451]
	Learning Rate: 0.000414513
	LOSS [training: 0.08106556244508109 | validation: 0.09397029596575429]
	TIME [epoch: 8.51 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08856519939294671		[learning rate: 0.00041354]
	Learning Rate: 0.000413535
	LOSS [training: 0.08856519939294671 | validation: 0.12675476069304148]
	TIME [epoch: 8.53 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08464159287921288		[learning rate: 0.00041256]
	Learning Rate: 0.00041256
	LOSS [training: 0.08464159287921288 | validation: 0.09071757854461075]
	TIME [epoch: 8.51 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08848244867655464		[learning rate: 0.00041159]
	Learning Rate: 0.000411587
	LOSS [training: 0.08848244867655464 | validation: 0.09493075446908844]
	TIME [epoch: 8.51 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09516792820834871		[learning rate: 0.00041062]
	Learning Rate: 0.000410616
	LOSS [training: 0.09516792820834871 | validation: 0.07383163732343537]
	TIME [epoch: 8.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08746333812738816		[learning rate: 0.00040965]
	Learning Rate: 0.000409647
	LOSS [training: 0.08746333812738816 | validation: 0.09123079867859715]
	TIME [epoch: 8.52 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09482140047090445		[learning rate: 0.00040868]
	Learning Rate: 0.000408681
	LOSS [training: 0.09482140047090445 | validation: 0.10915982548953869]
	TIME [epoch: 8.51 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09387406866886762		[learning rate: 0.00040772]
	Learning Rate: 0.000407717
	LOSS [training: 0.09387406866886762 | validation: 0.08745036139010695]
	TIME [epoch: 8.51 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0913917699012032		[learning rate: 0.00040676]
	Learning Rate: 0.000406755
	LOSS [training: 0.0913917699012032 | validation: 0.09856286853248097]
	TIME [epoch: 8.5 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10503827045676994		[learning rate: 0.0004058]
	Learning Rate: 0.000405796
	LOSS [training: 0.10503827045676994 | validation: 0.10376536094621823]
	TIME [epoch: 8.53 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09319306344503056		[learning rate: 0.00040484]
	Learning Rate: 0.000404839
	LOSS [training: 0.09319306344503056 | validation: 0.10606460316889191]
	TIME [epoch: 8.51 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09970323131529044		[learning rate: 0.00040388]
	Learning Rate: 0.000403884
	LOSS [training: 0.09970323131529044 | validation: 0.10801787611254726]
	TIME [epoch: 8.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09397712200507938		[learning rate: 0.00040293]
	Learning Rate: 0.000402931
	LOSS [training: 0.09397712200507938 | validation: 0.08149335072514508]
	TIME [epoch: 8.51 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0874526952239842		[learning rate: 0.00040198]
	Learning Rate: 0.000401981
	LOSS [training: 0.0874526952239842 | validation: 0.08767222286303433]
	TIME [epoch: 8.53 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09993554391521023		[learning rate: 0.00040103]
	Learning Rate: 0.000401032
	LOSS [training: 0.09993554391521023 | validation: 0.13958926014090497]
	TIME [epoch: 8.51 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10055637505250763		[learning rate: 0.00040009]
	Learning Rate: 0.000400086
	LOSS [training: 0.10055637505250763 | validation: 0.09408918606481081]
	TIME [epoch: 8.51 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09817077031689082		[learning rate: 0.00039914]
	Learning Rate: 0.000399143
	LOSS [training: 0.09817077031689082 | validation: 0.08568041448553246]
	TIME [epoch: 8.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07836359571472984		[learning rate: 0.0003982]
	Learning Rate: 0.000398201
	LOSS [training: 0.07836359571472984 | validation: 0.08542141383352146]
	TIME [epoch: 8.53 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09642352769629707		[learning rate: 0.00039726]
	Learning Rate: 0.000397262
	LOSS [training: 0.09642352769629707 | validation: 0.10245843693341701]
	TIME [epoch: 8.51 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09875928994948138		[learning rate: 0.00039632]
	Learning Rate: 0.000396325
	LOSS [training: 0.09875928994948138 | validation: 0.10647984220269585]
	TIME [epoch: 8.51 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09029128660662081		[learning rate: 0.00039539]
	Learning Rate: 0.00039539
	LOSS [training: 0.09029128660662081 | validation: 0.07331986017482653]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_1418.pth
	Model improved!!!
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08507311696274336		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.08507311696274336 | validation: 0.09077393397361848]
	TIME [epoch: 8.53 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0893094821880595		[learning rate: 0.00039353]
	Learning Rate: 0.000393527
	LOSS [training: 0.0893094821880595 | validation: 0.08760069012669718]
	TIME [epoch: 8.51 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08461512481390884		[learning rate: 0.0003926]
	Learning Rate: 0.000392599
	LOSS [training: 0.08461512481390884 | validation: 0.0735189857098525]
	TIME [epoch: 8.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09632098001492462		[learning rate: 0.00039167]
	Learning Rate: 0.000391672
	LOSS [training: 0.09632098001492462 | validation: 0.08131196839413202]
	TIME [epoch: 8.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09715601892559293		[learning rate: 0.00039075]
	Learning Rate: 0.000390748
	LOSS [training: 0.09715601892559293 | validation: 0.07979921673422104]
	TIME [epoch: 8.53 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09968691048812912		[learning rate: 0.00038983]
	Learning Rate: 0.000389827
	LOSS [training: 0.09968691048812912 | validation: 0.07858776577589147]
	TIME [epoch: 8.51 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08154443262532296		[learning rate: 0.00038891]
	Learning Rate: 0.000388907
	LOSS [training: 0.08154443262532296 | validation: 0.09199395936117359]
	TIME [epoch: 8.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08169987280066784		[learning rate: 0.00038799]
	Learning Rate: 0.00038799
	LOSS [training: 0.08169987280066784 | validation: 0.08109217038830062]
	TIME [epoch: 8.51 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08179552327561035		[learning rate: 0.00038707]
	Learning Rate: 0.000387075
	LOSS [training: 0.08179552327561035 | validation: 0.0596371707244158]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_1427.pth
	Model improved!!!
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08707239116988005		[learning rate: 0.00038616]
	Learning Rate: 0.000386162
	LOSS [training: 0.08707239116988005 | validation: 0.08816438627279599]
	TIME [epoch: 8.51 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08788384992503803		[learning rate: 0.00038525]
	Learning Rate: 0.000385251
	LOSS [training: 0.08788384992503803 | validation: 0.0883804745895826]
	TIME [epoch: 8.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09368968409245984		[learning rate: 0.00038434]
	Learning Rate: 0.000384342
	LOSS [training: 0.09368968409245984 | validation: 0.08368605515632024]
	TIME [epoch: 8.52 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08846251255890658		[learning rate: 0.00038344]
	Learning Rate: 0.000383435
	LOSS [training: 0.08846251255890658 | validation: 0.0805010881076427]
	TIME [epoch: 8.51 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08600645190820241		[learning rate: 0.00038253]
	Learning Rate: 0.000382531
	LOSS [training: 0.08600645190820241 | validation: 0.08861356966684183]
	TIME [epoch: 8.51 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08706023706264568		[learning rate: 0.00038163]
	Learning Rate: 0.000381629
	LOSS [training: 0.08706023706264568 | validation: 0.07643153943930227]
	TIME [epoch: 8.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0886322647847236		[learning rate: 0.00038073]
	Learning Rate: 0.000380729
	LOSS [training: 0.0886322647847236 | validation: 0.10940524492278851]
	TIME [epoch: 8.53 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09892872400759734		[learning rate: 0.00037983]
	Learning Rate: 0.00037983
	LOSS [training: 0.09892872400759734 | validation: 0.05756209325202287]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_1435.pth
	Model improved!!!
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09084770692048037		[learning rate: 0.00037893]
	Learning Rate: 0.000378934
	LOSS [training: 0.09084770692048037 | validation: 0.08617485522534714]
	TIME [epoch: 8.51 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0755560427135317		[learning rate: 0.00037804]
	Learning Rate: 0.000378041
	LOSS [training: 0.0755560427135317 | validation: 0.09905193890238509]
	TIME [epoch: 8.51 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10285453250928533		[learning rate: 0.00037715]
	Learning Rate: 0.000377149
	LOSS [training: 0.10285453250928533 | validation: 0.09620758597319565]
	TIME [epoch: 8.53 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09900924593634362		[learning rate: 0.00037626]
	Learning Rate: 0.000376259
	LOSS [training: 0.09900924593634362 | validation: 0.12289526586027874]
	TIME [epoch: 8.51 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0944122836931444		[learning rate: 0.00037537]
	Learning Rate: 0.000375372
	LOSS [training: 0.0944122836931444 | validation: 0.09460032588243418]
	TIME [epoch: 8.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07935889695109297		[learning rate: 0.00037449]
	Learning Rate: 0.000374486
	LOSS [training: 0.07935889695109297 | validation: 0.08165453854563201]
	TIME [epoch: 8.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09176336170154233		[learning rate: 0.0003736]
	Learning Rate: 0.000373603
	LOSS [training: 0.09176336170154233 | validation: 0.09964857586367092]
	TIME [epoch: 8.53 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08268404432914378		[learning rate: 0.00037272]
	Learning Rate: 0.000372722
	LOSS [training: 0.08268404432914378 | validation: 0.07593034053429884]
	TIME [epoch: 8.51 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08337422866976704		[learning rate: 0.00037184]
	Learning Rate: 0.000371842
	LOSS [training: 0.08337422866976704 | validation: 0.07237662483865286]
	TIME [epoch: 8.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08432686560575459		[learning rate: 0.00037097]
	Learning Rate: 0.000370965
	LOSS [training: 0.08432686560575459 | validation: 0.07658338866819497]
	TIME [epoch: 8.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07402432539407547		[learning rate: 0.00037009]
	Learning Rate: 0.00037009
	LOSS [training: 0.07402432539407547 | validation: 0.08286739945148656]
	TIME [epoch: 8.53 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08814105924812457		[learning rate: 0.00036922]
	Learning Rate: 0.000369217
	LOSS [training: 0.08814105924812457 | validation: 0.09298388827155887]
	TIME [epoch: 8.51 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08947057355796881		[learning rate: 0.00036835]
	Learning Rate: 0.000368346
	LOSS [training: 0.08947057355796881 | validation: 0.11111544613183752]
	TIME [epoch: 8.5 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0866744312349961		[learning rate: 0.00036748]
	Learning Rate: 0.000367477
	LOSS [training: 0.0866744312349961 | validation: 0.1000780368021216]
	TIME [epoch: 8.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09267214171664842		[learning rate: 0.00036661]
	Learning Rate: 0.000366611
	LOSS [training: 0.09267214171664842 | validation: 0.08050000634388361]
	TIME [epoch: 8.52 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08168500245630116		[learning rate: 0.00036575]
	Learning Rate: 0.000365746
	LOSS [training: 0.08168500245630116 | validation: 0.09787434983041986]
	TIME [epoch: 8.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09459357909962664		[learning rate: 0.00036488]
	Learning Rate: 0.000364883
	LOSS [training: 0.09459357909962664 | validation: 0.12724172830316527]
	TIME [epoch: 8.51 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08817234458317783		[learning rate: 0.00036402]
	Learning Rate: 0.000364022
	LOSS [training: 0.08817234458317783 | validation: 0.08291259425610073]
	TIME [epoch: 8.51 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07917530320287078		[learning rate: 0.00036316]
	Learning Rate: 0.000363164
	LOSS [training: 0.07917530320287078 | validation: 0.08567614372085619]
	TIME [epoch: 8.52 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09107957315714724		[learning rate: 0.00036231]
	Learning Rate: 0.000362307
	LOSS [training: 0.09107957315714724 | validation: 0.10811309564852918]
	TIME [epoch: 8.51 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08981846721700373		[learning rate: 0.00036145]
	Learning Rate: 0.000361452
	LOSS [training: 0.08981846721700373 | validation: 0.08375179777420586]
	TIME [epoch: 8.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08270553923867636		[learning rate: 0.0003606]
	Learning Rate: 0.0003606
	LOSS [training: 0.08270553923867636 | validation: 0.08050212543992369]
	TIME [epoch: 8.51 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0952298710600868		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.0952298710600868 | validation: 0.0830670396235454]
	TIME [epoch: 8.52 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09019870763392686		[learning rate: 0.0003589]
	Learning Rate: 0.000358901
	LOSS [training: 0.09019870763392686 | validation: 0.07785898051268571]
	TIME [epoch: 8.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09012095265975958		[learning rate: 0.00035805]
	Learning Rate: 0.000358054
	LOSS [training: 0.09012095265975958 | validation: 0.0970430981999637]
	TIME [epoch: 8.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10100062768397422		[learning rate: 0.00035721]
	Learning Rate: 0.00035721
	LOSS [training: 0.10100062768397422 | validation: 0.08652026789660128]
	TIME [epoch: 8.52 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10091402982319317		[learning rate: 0.00035637]
	Learning Rate: 0.000356367
	LOSS [training: 0.10091402982319317 | validation: 0.12753404530479096]
	TIME [epoch: 8.52 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0818410920302314		[learning rate: 0.00035553]
	Learning Rate: 0.000355526
	LOSS [training: 0.0818410920302314 | validation: 0.0814803634868524]
	TIME [epoch: 8.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07472315660848203		[learning rate: 0.00035469]
	Learning Rate: 0.000354688
	LOSS [training: 0.07472315660848203 | validation: 0.12106195646225712]
	TIME [epoch: 8.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09105004899797378		[learning rate: 0.00035385]
	Learning Rate: 0.000353851
	LOSS [training: 0.09105004899797378 | validation: 0.0744118364187197]
	TIME [epoch: 8.52 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09297197258053261		[learning rate: 0.00035302]
	Learning Rate: 0.000353016
	LOSS [training: 0.09297197258053261 | validation: 0.08774168775770913]
	TIME [epoch: 8.51 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0810485916201005		[learning rate: 0.00035218]
	Learning Rate: 0.000352184
	LOSS [training: 0.0810485916201005 | validation: 0.08918246179793968]
	TIME [epoch: 8.51 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08529489161805803		[learning rate: 0.00035135]
	Learning Rate: 0.000351353
	LOSS [training: 0.08529489161805803 | validation: 0.07613423415234742]
	TIME [epoch: 8.51 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0756880522708054		[learning rate: 0.00035052]
	Learning Rate: 0.000350524
	LOSS [training: 0.0756880522708054 | validation: 0.09482564064414017]
	TIME [epoch: 8.52 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09324057795324403		[learning rate: 0.0003497]
	Learning Rate: 0.000349697
	LOSS [training: 0.09324057795324403 | validation: 0.09834273417585541]
	TIME [epoch: 8.51 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08420720475484328		[learning rate: 0.00034887]
	Learning Rate: 0.000348872
	LOSS [training: 0.08420720475484328 | validation: 0.08601088171354093]
	TIME [epoch: 8.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08783573043444279		[learning rate: 0.00034805]
	Learning Rate: 0.000348049
	LOSS [training: 0.08783573043444279 | validation: 0.09278772678484942]
	TIME [epoch: 8.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07973868149660697		[learning rate: 0.00034723]
	Learning Rate: 0.000347228
	LOSS [training: 0.07973868149660697 | validation: 0.11350330328634872]
	TIME [epoch: 8.53 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09772866447577203		[learning rate: 0.00034641]
	Learning Rate: 0.000346409
	LOSS [training: 0.09772866447577203 | validation: 0.09464497513378689]
	TIME [epoch: 8.51 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09251681840595635		[learning rate: 0.00034559]
	Learning Rate: 0.000345592
	LOSS [training: 0.09251681840595635 | validation: 0.10247284904153306]
	TIME [epoch: 8.51 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09897725612210552		[learning rate: 0.00034478]
	Learning Rate: 0.000344777
	LOSS [training: 0.09897725612210552 | validation: 0.08076151871047847]
	TIME [epoch: 8.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08595598389245171		[learning rate: 0.00034396]
	Learning Rate: 0.000343964
	LOSS [training: 0.08595598389245171 | validation: 0.09428947824027462]
	TIME [epoch: 8.52 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08418306696905288		[learning rate: 0.00034315]
	Learning Rate: 0.000343152
	LOSS [training: 0.08418306696905288 | validation: 0.09799583693068888]
	TIME [epoch: 8.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0847335592544565		[learning rate: 0.00034234]
	Learning Rate: 0.000342343
	LOSS [training: 0.0847335592544565 | validation: 0.07966241419957024]
	TIME [epoch: 8.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08818972695230565		[learning rate: 0.00034154]
	Learning Rate: 0.000341536
	LOSS [training: 0.08818972695230565 | validation: 0.08929420311454964]
	TIME [epoch: 8.5 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08321219530487248		[learning rate: 0.00034073]
	Learning Rate: 0.00034073
	LOSS [training: 0.08321219530487248 | validation: 0.1241695207177394]
	TIME [epoch: 8.53 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07760050229927572		[learning rate: 0.00033993]
	Learning Rate: 0.000339926
	LOSS [training: 0.07760050229927572 | validation: 0.08659003195247986]
	TIME [epoch: 8.51 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08710761683964167		[learning rate: 0.00033912]
	Learning Rate: 0.000339124
	LOSS [training: 0.08710761683964167 | validation: 0.08800916076434923]
	TIME [epoch: 8.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08823560954605367		[learning rate: 0.00033832]
	Learning Rate: 0.000338324
	LOSS [training: 0.08823560954605367 | validation: 0.08092426447738232]
	TIME [epoch: 8.51 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08634703927026444		[learning rate: 0.00033753]
	Learning Rate: 0.000337526
	LOSS [training: 0.08634703927026444 | validation: 0.10853479928237306]
	TIME [epoch: 8.53 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09110821158544945		[learning rate: 0.00033673]
	Learning Rate: 0.00033673
	LOSS [training: 0.09110821158544945 | validation: 0.10239558021149794]
	TIME [epoch: 8.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10521039544210642		[learning rate: 0.00033594]
	Learning Rate: 0.000335936
	LOSS [training: 0.10521039544210642 | validation: 0.0946552843758674]
	TIME [epoch: 8.51 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0790999907561238		[learning rate: 0.00033514]
	Learning Rate: 0.000335143
	LOSS [training: 0.0790999907561238 | validation: 0.07224907189501734]
	TIME [epoch: 8.52 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08038496003553867		[learning rate: 0.00033435]
	Learning Rate: 0.000334353
	LOSS [training: 0.08038496003553867 | validation: 0.07089080046570606]
	TIME [epoch: 8.52 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07992546414499466		[learning rate: 0.00033356]
	Learning Rate: 0.000333564
	LOSS [training: 0.07992546414499466 | validation: 0.12526450109938986]
	TIME [epoch: 8.51 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08393143647823553		[learning rate: 0.00033278]
	Learning Rate: 0.000332777
	LOSS [training: 0.08393143647823553 | validation: 0.10498767574673026]
	TIME [epoch: 8.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08857476842736413		[learning rate: 0.00033199]
	Learning Rate: 0.000331992
	LOSS [training: 0.08857476842736413 | validation: 0.08372718443255808]
	TIME [epoch: 8.53 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0846264408862872		[learning rate: 0.00033121]
	Learning Rate: 0.000331209
	LOSS [training: 0.0846264408862872 | validation: 0.08917084419452662]
	TIME [epoch: 8.51 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08819936759368008		[learning rate: 0.00033043]
	Learning Rate: 0.000330428
	LOSS [training: 0.08819936759368008 | validation: 0.0718186759458786]
	TIME [epoch: 8.51 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09336889711784092		[learning rate: 0.00032965]
	Learning Rate: 0.000329649
	LOSS [training: 0.09336889711784092 | validation: 0.06929025604597934]
	TIME [epoch: 8.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09134340661725388		[learning rate: 0.00032887]
	Learning Rate: 0.000328871
	LOSS [training: 0.09134340661725388 | validation: 0.08607493227298149]
	TIME [epoch: 8.52 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09624265535429508		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.09624265535429508 | validation: 0.08530231946750223]
	TIME [epoch: 8.51 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08039504966866548		[learning rate: 0.00032732]
	Learning Rate: 0.000327321
	LOSS [training: 0.08039504966866548 | validation: 0.08760385353501157]
	TIME [epoch: 8.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07840482981375932		[learning rate: 0.00032655]
	Learning Rate: 0.000326549
	LOSS [training: 0.07840482981375932 | validation: 0.07116586523038643]
	TIME [epoch: 8.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08011998667906142		[learning rate: 0.00032578]
	Learning Rate: 0.000325779
	LOSS [training: 0.08011998667906142 | validation: 0.08904053160099314]
	TIME [epoch: 8.52 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08185875650552675		[learning rate: 0.00032501]
	Learning Rate: 0.000325011
	LOSS [training: 0.08185875650552675 | validation: 0.08615564070888723]
	TIME [epoch: 8.51 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09510418079187405		[learning rate: 0.00032424]
	Learning Rate: 0.000324244
	LOSS [training: 0.09510418079187405 | validation: 0.11123908534030527]
	TIME [epoch: 8.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09757360096387169		[learning rate: 0.00032348]
	Learning Rate: 0.000323479
	LOSS [training: 0.09757360096387169 | validation: 0.07069965179014004]
	TIME [epoch: 8.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08596558139514507		[learning rate: 0.00032272]
	Learning Rate: 0.000322716
	LOSS [training: 0.08596558139514507 | validation: 0.09318072334620545]
	TIME [epoch: 8.53 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08552338624123575		[learning rate: 0.00032195]
	Learning Rate: 0.000321955
	LOSS [training: 0.08552338624123575 | validation: 0.11040708249261572]
	TIME [epoch: 8.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08096054425076407		[learning rate: 0.0003212]
	Learning Rate: 0.000321195
	LOSS [training: 0.08096054425076407 | validation: 0.07964115450736897]
	TIME [epoch: 8.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08597221867884974		[learning rate: 0.00032044]
	Learning Rate: 0.000320438
	LOSS [training: 0.08597221867884974 | validation: 0.10362706036347075]
	TIME [epoch: 8.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10210013517095406		[learning rate: 0.00031968]
	Learning Rate: 0.000319682
	LOSS [training: 0.10210013517095406 | validation: 0.09588350598837385]
	TIME [epoch: 8.53 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07330824144181376		[learning rate: 0.00031893]
	Learning Rate: 0.000318928
	LOSS [training: 0.07330824144181376 | validation: 0.09918147510783973]
	TIME [epoch: 8.51 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08923768507090224		[learning rate: 0.00031818]
	Learning Rate: 0.000318175
	LOSS [training: 0.08923768507090224 | validation: 0.08441540186194314]
	TIME [epoch: 8.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07865016752062322		[learning rate: 0.00031742]
	Learning Rate: 0.000317425
	LOSS [training: 0.07865016752062322 | validation: 0.08670958419424853]
	TIME [epoch: 8.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0803257089874412		[learning rate: 0.00031668]
	Learning Rate: 0.000316676
	LOSS [training: 0.0803257089874412 | validation: 0.06952736705938252]
	TIME [epoch: 8.52 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07818809282910699		[learning rate: 0.00031593]
	Learning Rate: 0.000315929
	LOSS [training: 0.07818809282910699 | validation: 0.07066754705531679]
	TIME [epoch: 8.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0718542899063349		[learning rate: 0.00031518]
	Learning Rate: 0.000315184
	LOSS [training: 0.0718542899063349 | validation: 0.09340410348189632]
	TIME [epoch: 8.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07935971035311258		[learning rate: 0.00031444]
	Learning Rate: 0.00031444
	LOSS [training: 0.07935971035311258 | validation: 0.08883910183589794]
	TIME [epoch: 8.51 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0786967454700914		[learning rate: 0.0003137]
	Learning Rate: 0.000313699
	LOSS [training: 0.0786967454700914 | validation: 0.07640085801486679]
	TIME [epoch: 8.53 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07623879205320985		[learning rate: 0.00031296]
	Learning Rate: 0.000312959
	LOSS [training: 0.07623879205320985 | validation: 0.08411077327388253]
	TIME [epoch: 8.51 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07947830965925451		[learning rate: 0.00031222]
	Learning Rate: 0.000312221
	LOSS [training: 0.07947830965925451 | validation: 0.097482962842736]
	TIME [epoch: 8.51 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08499413270360566		[learning rate: 0.00031148]
	Learning Rate: 0.000311484
	LOSS [training: 0.08499413270360566 | validation: 0.10813442239400693]
	TIME [epoch: 8.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08513876855207911		[learning rate: 0.00031075]
	Learning Rate: 0.000310749
	LOSS [training: 0.08513876855207911 | validation: 0.08455515142117254]
	TIME [epoch: 8.53 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0849065679376236		[learning rate: 0.00031002]
	Learning Rate: 0.000310016
	LOSS [training: 0.0849065679376236 | validation: 0.1255272393031767]
	TIME [epoch: 8.51 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08735246070539385		[learning rate: 0.00030929]
	Learning Rate: 0.000309285
	LOSS [training: 0.08735246070539385 | validation: 0.06980708408545207]
	TIME [epoch: 8.5 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0786857465653635		[learning rate: 0.00030856]
	Learning Rate: 0.000308555
	LOSS [training: 0.0786857465653635 | validation: 0.07374425100306627]
	TIME [epoch: 8.51 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08807676718132881		[learning rate: 0.00030783]
	Learning Rate: 0.000307828
	LOSS [training: 0.08807676718132881 | validation: 0.09776584486566153]
	TIME [epoch: 8.52 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08268282952728492		[learning rate: 0.0003071]
	Learning Rate: 0.000307102
	LOSS [training: 0.08268282952728492 | validation: 0.08667940581580111]
	TIME [epoch: 8.51 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.084486315672415		[learning rate: 0.00030638]
	Learning Rate: 0.000306377
	LOSS [training: 0.084486315672415 | validation: 0.07765298166848815]
	TIME [epoch: 8.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08791455022176012		[learning rate: 0.00030565]
	Learning Rate: 0.000305654
	LOSS [training: 0.08791455022176012 | validation: 0.08867334411541404]
	TIME [epoch: 8.52 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08002014907252687		[learning rate: 0.00030493]
	Learning Rate: 0.000304933
	LOSS [training: 0.08002014907252687 | validation: 0.08486489400931604]
	TIME [epoch: 8.51 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0856228127460789		[learning rate: 0.00030421]
	Learning Rate: 0.000304214
	LOSS [training: 0.0856228127460789 | validation: 0.07892694898626834]
	TIME [epoch: 8.51 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08354109338542655		[learning rate: 0.0003035]
	Learning Rate: 0.000303497
	LOSS [training: 0.08354109338542655 | validation: 0.0764949294895087]
	TIME [epoch: 8.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08515001500378404		[learning rate: 0.00030278]
	Learning Rate: 0.000302781
	LOSS [training: 0.08515001500378404 | validation: 0.06646866912622026]
	TIME [epoch: 8.52 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08391091376503348		[learning rate: 0.00030207]
	Learning Rate: 0.000302066
	LOSS [training: 0.08391091376503348 | validation: 0.08058776227478517]
	TIME [epoch: 8.51 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09277305214691302		[learning rate: 0.00030135]
	Learning Rate: 0.000301354
	LOSS [training: 0.09277305214691302 | validation: 0.08983209162865344]
	TIME [epoch: 8.51 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08554752260788524		[learning rate: 0.00030064]
	Learning Rate: 0.000300643
	LOSS [training: 0.08554752260788524 | validation: 0.06517888985789072]
	TIME [epoch: 8.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07636912405049284		[learning rate: 0.00029993]
	Learning Rate: 0.000299934
	LOSS [training: 0.07636912405049284 | validation: 0.08986892469779416]
	TIME [epoch: 8.53 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08210411672079806		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.08210411672079806 | validation: 0.09288715806293144]
	TIME [epoch: 8.51 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07644300456996739		[learning rate: 0.00029852]
	Learning Rate: 0.000298521
	LOSS [training: 0.07644300456996739 | validation: 0.08739203545852933]
	TIME [epoch: 8.51 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10546559488231004		[learning rate: 0.00029782]
	Learning Rate: 0.000297816
	LOSS [training: 0.10546559488231004 | validation: 0.07563594888905376]
	TIME [epoch: 8.51 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08749223612444604		[learning rate: 0.00029711]
	Learning Rate: 0.000297114
	LOSS [training: 0.08749223612444604 | validation: 0.08349531740379135]
	TIME [epoch: 8.53 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07821572928116569		[learning rate: 0.00029641]
	Learning Rate: 0.000296413
	LOSS [training: 0.07821572928116569 | validation: 0.08122905049175516]
	TIME [epoch: 8.51 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08613648733794477		[learning rate: 0.00029571]
	Learning Rate: 0.000295714
	LOSS [training: 0.08613648733794477 | validation: 0.09543810265765254]
	TIME [epoch: 8.51 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08544309770288697		[learning rate: 0.00029502]
	Learning Rate: 0.000295016
	LOSS [training: 0.08544309770288697 | validation: 0.08156083353583779]
	TIME [epoch: 8.51 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08257755729869633		[learning rate: 0.00029432]
	Learning Rate: 0.00029432
	LOSS [training: 0.08257755729869633 | validation: 0.08711659983418578]
	TIME [epoch: 8.52 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08099850314920284		[learning rate: 0.00029363]
	Learning Rate: 0.000293626
	LOSS [training: 0.08099850314920284 | validation: 0.09167507621531684]
	TIME [epoch: 8.51 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08289661210950311		[learning rate: 0.00029293]
	Learning Rate: 0.000292934
	LOSS [training: 0.08289661210950311 | validation: 0.07432974337359233]
	TIME [epoch: 8.51 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08975389984765418		[learning rate: 0.00029224]
	Learning Rate: 0.000292243
	LOSS [training: 0.08975389984765418 | validation: 0.08178581029770465]
	TIME [epoch: 8.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08984338016806984		[learning rate: 0.00029155]
	Learning Rate: 0.000291553
	LOSS [training: 0.08984338016806984 | validation: 0.07436186073796228]
	TIME [epoch: 8.53 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08253545943493006		[learning rate: 0.00029087]
	Learning Rate: 0.000290866
	LOSS [training: 0.08253545943493006 | validation: 0.09003559571361416]
	TIME [epoch: 8.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09116313528503668		[learning rate: 0.00029018]
	Learning Rate: 0.000290179
	LOSS [training: 0.09116313528503668 | validation: 0.08892145549268365]
	TIME [epoch: 8.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07859795774961922		[learning rate: 0.00028949]
	Learning Rate: 0.000289495
	LOSS [training: 0.07859795774961922 | validation: 0.08616933768652241]
	TIME [epoch: 8.51 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08490972904353095		[learning rate: 0.00028881]
	Learning Rate: 0.000288812
	LOSS [training: 0.08490972904353095 | validation: 0.09189184422429315]
	TIME [epoch: 8.53 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0857982304134265		[learning rate: 0.00028813]
	Learning Rate: 0.000288131
	LOSS [training: 0.0857982304134265 | validation: 0.07470767327530661]
	TIME [epoch: 8.51 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07296670433851322		[learning rate: 0.00028745]
	Learning Rate: 0.000287451
	LOSS [training: 0.07296670433851322 | validation: 0.08515927751750041]
	TIME [epoch: 8.51 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0853020002682423		[learning rate: 0.00028677]
	Learning Rate: 0.000286773
	LOSS [training: 0.0853020002682423 | validation: 0.09123910955254155]
	TIME [epoch: 8.51 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0875753252829283		[learning rate: 0.0002861]
	Learning Rate: 0.000286097
	LOSS [training: 0.0875753252829283 | validation: 0.09266432849933562]
	TIME [epoch: 8.52 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08914181073047212		[learning rate: 0.00028542]
	Learning Rate: 0.000285422
	LOSS [training: 0.08914181073047212 | validation: 0.0928593966395537]
	TIME [epoch: 8.51 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07906946313196098		[learning rate: 0.00028475]
	Learning Rate: 0.000284749
	LOSS [training: 0.07906946313196098 | validation: 0.07496541571102402]
	TIME [epoch: 8.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07369480870283207		[learning rate: 0.00028408]
	Learning Rate: 0.000284077
	LOSS [training: 0.07369480870283207 | validation: 0.07695999668514114]
	TIME [epoch: 8.53 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09897210188521667		[learning rate: 0.00028341]
	Learning Rate: 0.000283407
	LOSS [training: 0.09897210188521667 | validation: 0.1073102045496847]
	TIME [epoch: 8.52 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07930488284785829		[learning rate: 0.00028274]
	Learning Rate: 0.000282738
	LOSS [training: 0.07930488284785829 | validation: 0.0784146504232546]
	TIME [epoch: 8.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08536606694651991		[learning rate: 0.00028207]
	Learning Rate: 0.000282071
	LOSS [training: 0.08536606694651991 | validation: 0.08556277414725061]
	TIME [epoch: 8.51 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08383434947019036		[learning rate: 0.00028141]
	Learning Rate: 0.000281406
	LOSS [training: 0.08383434947019036 | validation: 0.08219342555233419]
	TIME [epoch: 8.52 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.078907533085024		[learning rate: 0.00028074]
	Learning Rate: 0.000280742
	LOSS [training: 0.078907533085024 | validation: 0.0895201877579299]
	TIME [epoch: 8.52 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0775275817102494		[learning rate: 0.00028008]
	Learning Rate: 0.00028008
	LOSS [training: 0.0775275817102494 | validation: 0.07158741797318699]
	TIME [epoch: 8.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10746653850427315		[learning rate: 0.00027942]
	Learning Rate: 0.000279419
	LOSS [training: 0.10746653850427315 | validation: 0.09443008653620988]
	TIME [epoch: 8.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.083427402254773		[learning rate: 0.00027876]
	Learning Rate: 0.00027876
	LOSS [training: 0.083427402254773 | validation: 0.08404159994869048]
	TIME [epoch: 8.53 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08209760855699444		[learning rate: 0.0002781]
	Learning Rate: 0.000278103
	LOSS [training: 0.08209760855699444 | validation: 0.07712877328478054]
	TIME [epoch: 8.51 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08558252287085978		[learning rate: 0.00027745]
	Learning Rate: 0.000277447
	LOSS [training: 0.08558252287085978 | validation: 0.0780427423517139]
	TIME [epoch: 8.51 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0790221162430034		[learning rate: 0.00027679]
	Learning Rate: 0.000276792
	LOSS [training: 0.0790221162430034 | validation: 0.08037860589283918]
	TIME [epoch: 8.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07514228793169125		[learning rate: 0.00027614]
	Learning Rate: 0.000276139
	LOSS [training: 0.07514228793169125 | validation: 0.09106828898027453]
	TIME [epoch: 8.52 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07746201215168205		[learning rate: 0.00027549]
	Learning Rate: 0.000275488
	LOSS [training: 0.07746201215168205 | validation: 0.07726767618896357]
	TIME [epoch: 8.51 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08024743340453358		[learning rate: 0.00027484]
	Learning Rate: 0.000274838
	LOSS [training: 0.08024743340453358 | validation: 0.0875228758718491]
	TIME [epoch: 8.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09501550816282381		[learning rate: 0.00027419]
	Learning Rate: 0.00027419
	LOSS [training: 0.09501550816282381 | validation: 0.10422731543727562]
	TIME [epoch: 8.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09239555155773546		[learning rate: 0.00027354]
	Learning Rate: 0.000273543
	LOSS [training: 0.09239555155773546 | validation: 0.08730212776934851]
	TIME [epoch: 8.52 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0814700674419879		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.0814700674419879 | validation: 0.10998813945313515]
	TIME [epoch: 8.51 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09222647843131142		[learning rate: 0.00027225]
	Learning Rate: 0.000272254
	LOSS [training: 0.09222647843131142 | validation: 0.10893333494408672]
	TIME [epoch: 8.49 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10009118588977024		[learning rate: 0.00027161]
	Learning Rate: 0.000271612
	LOSS [training: 0.10009118588977024 | validation: 0.09853434757172556]
	TIME [epoch: 8.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09253714577592856		[learning rate: 0.00027097]
	Learning Rate: 0.000270971
	LOSS [training: 0.09253714577592856 | validation: 0.08307495281110674]
	TIME [epoch: 8.53 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08401974101479956		[learning rate: 0.00027033]
	Learning Rate: 0.000270332
	LOSS [training: 0.08401974101479956 | validation: 0.06996936217586777]
	TIME [epoch: 8.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08420157764953447		[learning rate: 0.00026969]
	Learning Rate: 0.000269694
	LOSS [training: 0.08420157764953447 | validation: 0.08760987426039654]
	TIME [epoch: 8.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09271273926730646		[learning rate: 0.00026906]
	Learning Rate: 0.000269058
	LOSS [training: 0.09271273926730646 | validation: 0.08137547912367554]
	TIME [epoch: 8.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08775446540617263		[learning rate: 0.00026842]
	Learning Rate: 0.000268423
	LOSS [training: 0.08775446540617263 | validation: 0.07461583178938191]
	TIME [epoch: 8.52 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08485569363817533		[learning rate: 0.00026779]
	Learning Rate: 0.00026779
	LOSS [training: 0.08485569363817533 | validation: 0.09268723612145463]
	TIME [epoch: 8.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08753475030913536		[learning rate: 0.00026716]
	Learning Rate: 0.000267159
	LOSS [training: 0.08753475030913536 | validation: 0.08346999168759711]
	TIME [epoch: 8.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07980047647658832		[learning rate: 0.00026653]
	Learning Rate: 0.000266528
	LOSS [training: 0.07980047647658832 | validation: 0.0774905195151046]
	TIME [epoch: 8.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08327390448532625		[learning rate: 0.0002659]
	Learning Rate: 0.0002659
	LOSS [training: 0.08327390448532625 | validation: 0.07603424955351806]
	TIME [epoch: 8.53 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07950009794171495		[learning rate: 0.00026527]
	Learning Rate: 0.000265273
	LOSS [training: 0.07950009794171495 | validation: 0.07760084654040521]
	TIME [epoch: 8.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08334271710204685		[learning rate: 0.00026465]
	Learning Rate: 0.000264647
	LOSS [training: 0.08334271710204685 | validation: 0.07677345083893883]
	TIME [epoch: 8.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08243512022695208		[learning rate: 0.00026402]
	Learning Rate: 0.000264022
	LOSS [training: 0.08243512022695208 | validation: 0.08473121819605943]
	TIME [epoch: 8.51 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07888940122086992		[learning rate: 0.0002634]
	Learning Rate: 0.0002634
	LOSS [training: 0.07888940122086992 | validation: 0.0864203024881549]
	TIME [epoch: 8.52 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08623840929430282		[learning rate: 0.00026278]
	Learning Rate: 0.000262778
	LOSS [training: 0.08623840929430282 | validation: 0.08799335902288571]
	TIME [epoch: 8.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08539253831206216		[learning rate: 0.00026216]
	Learning Rate: 0.000262159
	LOSS [training: 0.08539253831206216 | validation: 0.0859775807755661]
	TIME [epoch: 8.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07771569649258599		[learning rate: 0.00026154]
	Learning Rate: 0.00026154
	LOSS [training: 0.07771569649258599 | validation: 0.08562978897761725]
	TIME [epoch: 8.52 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08074631386225072		[learning rate: 0.00026092]
	Learning Rate: 0.000260923
	LOSS [training: 0.08074631386225072 | validation: 0.07964754932248044]
	TIME [epoch: 8.51 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08960224906565886		[learning rate: 0.00026031]
	Learning Rate: 0.000260308
	LOSS [training: 0.08960224906565886 | validation: 0.0888864439725634]
	TIME [epoch: 8.51 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07995128828716909		[learning rate: 0.00025969]
	Learning Rate: 0.000259694
	LOSS [training: 0.07995128828716909 | validation: 0.08566626156538373]
	TIME [epoch: 8.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0765772746741609		[learning rate: 0.00025908]
	Learning Rate: 0.000259081
	LOSS [training: 0.0765772746741609 | validation: 0.0893106577016379]
	TIME [epoch: 8.52 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07996842444219257		[learning rate: 0.00025847]
	Learning Rate: 0.00025847
	LOSS [training: 0.07996842444219257 | validation: 0.0772231609565822]
	TIME [epoch: 8.51 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07890945203586011		[learning rate: 0.00025786]
	Learning Rate: 0.00025786
	LOSS [training: 0.07890945203586011 | validation: 0.08552526957022856]
	TIME [epoch: 8.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07472056436912321		[learning rate: 0.00025725]
	Learning Rate: 0.000257252
	LOSS [training: 0.07472056436912321 | validation: 0.08188896044644028]
	TIME [epoch: 8.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08375594436011054		[learning rate: 0.00025665]
	Learning Rate: 0.000256645
	LOSS [training: 0.08375594436011054 | validation: 0.06731567182473755]
	TIME [epoch: 8.53 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07908826756229723		[learning rate: 0.00025604]
	Learning Rate: 0.00025604
	LOSS [training: 0.07908826756229723 | validation: 0.0816327609611664]
	TIME [epoch: 8.51 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08436374084446116		[learning rate: 0.00025544]
	Learning Rate: 0.000255436
	LOSS [training: 0.08436374084446116 | validation: 0.08754035474961963]
	TIME [epoch: 8.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08197878357693608		[learning rate: 0.00025483]
	Learning Rate: 0.000254833
	LOSS [training: 0.08197878357693608 | validation: 0.10259142427406606]
	TIME [epoch: 8.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09139303372277859		[learning rate: 0.00025423]
	Learning Rate: 0.000254232
	LOSS [training: 0.09139303372277859 | validation: 0.09434425713312272]
	TIME [epoch: 8.52 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08116624935238494		[learning rate: 0.00025363]
	Learning Rate: 0.000253633
	LOSS [training: 0.08116624935238494 | validation: 0.09643066522689077]
	TIME [epoch: 8.51 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08571340330518903		[learning rate: 0.00025303]
	Learning Rate: 0.000253034
	LOSS [training: 0.08571340330518903 | validation: 0.0764585679283283]
	TIME [epoch: 8.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08094197577711464		[learning rate: 0.00025244]
	Learning Rate: 0.000252437
	LOSS [training: 0.08094197577711464 | validation: 0.0834513608564519]
	TIME [epoch: 8.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07768283497991106		[learning rate: 0.00025184]
	Learning Rate: 0.000251842
	LOSS [training: 0.07768283497991106 | validation: 0.07244132393210476]
	TIME [epoch: 8.53 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08183967303651098		[learning rate: 0.00025125]
	Learning Rate: 0.000251248
	LOSS [training: 0.08183967303651098 | validation: 0.09375081669058388]
	TIME [epoch: 8.51 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08158252632027573		[learning rate: 0.00025066]
	Learning Rate: 0.000250655
	LOSS [training: 0.08158252632027573 | validation: 0.06312607261358912]
	TIME [epoch: 8.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08824498127238982		[learning rate: 0.00025006]
	Learning Rate: 0.000250064
	LOSS [training: 0.08824498127238982 | validation: 0.08196219141954425]
	TIME [epoch: 8.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07773732242950171		[learning rate: 0.00024947]
	Learning Rate: 0.000249474
	LOSS [training: 0.07773732242950171 | validation: 0.09247576425604981]
	TIME [epoch: 8.53 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07760069984766065		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.07760069984766065 | validation: 0.10118572288994025]
	TIME [epoch: 8.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08242154606077853		[learning rate: 0.0002483]
	Learning Rate: 0.000248299
	LOSS [training: 0.08242154606077853 | validation: 0.07878494050495714]
	TIME [epoch: 8.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08059409730267028		[learning rate: 0.00024771]
	Learning Rate: 0.000247713
	LOSS [training: 0.08059409730267028 | validation: 0.09303253509577289]
	TIME [epoch: 8.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07834740988247428		[learning rate: 0.00024713]
	Learning Rate: 0.000247129
	LOSS [training: 0.07834740988247428 | validation: 0.08223440552865927]
	TIME [epoch: 8.53 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07604847201434464		[learning rate: 0.00024655]
	Learning Rate: 0.000246546
	LOSS [training: 0.07604847201434464 | validation: 0.06910972390506576]
	TIME [epoch: 8.51 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08060558767715396		[learning rate: 0.00024596]
	Learning Rate: 0.000245964
	LOSS [training: 0.08060558767715396 | validation: 0.09491618252905248]
	TIME [epoch: 8.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08354010027306216		[learning rate: 0.00024538]
	Learning Rate: 0.000245384
	LOSS [training: 0.08354010027306216 | validation: 0.0786442841694203]
	TIME [epoch: 8.51 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08315546064182108		[learning rate: 0.00024481]
	Learning Rate: 0.000244805
	LOSS [training: 0.08315546064182108 | validation: 0.08600522895640066]
	TIME [epoch: 8.52 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07692621175705265		[learning rate: 0.00024423]
	Learning Rate: 0.000244228
	LOSS [training: 0.07692621175705265 | validation: 0.08485519332490118]
	TIME [epoch: 8.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07358464382983525		[learning rate: 0.00024365]
	Learning Rate: 0.000243652
	LOSS [training: 0.07358464382983525 | validation: 0.07434888738855484]
	TIME [epoch: 8.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08150775495029768		[learning rate: 0.00024308]
	Learning Rate: 0.000243077
	LOSS [training: 0.08150775495029768 | validation: 0.09085976365334887]
	TIME [epoch: 8.52 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08078588660006816		[learning rate: 0.0002425]
	Learning Rate: 0.000242503
	LOSS [training: 0.08078588660006816 | validation: 0.0702166489597344]
	TIME [epoch: 8.51 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09059009091498861		[learning rate: 0.00024193]
	Learning Rate: 0.000241931
	LOSS [training: 0.09059009091498861 | validation: 0.09797768869137803]
	TIME [epoch: 8.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0822972407694276		[learning rate: 0.00024136]
	Learning Rate: 0.000241361
	LOSS [training: 0.0822972407694276 | validation: 0.09324519585353426]
	TIME [epoch: 8.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08108768782300099		[learning rate: 0.00024079]
	Learning Rate: 0.000240791
	LOSS [training: 0.08108768782300099 | validation: 0.09484863631983592]
	TIME [epoch: 8.52 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0808833654212516		[learning rate: 0.00024022]
	Learning Rate: 0.000240223
	LOSS [training: 0.0808833654212516 | validation: 0.09532807557226966]
	TIME [epoch: 8.51 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08547643172725217		[learning rate: 0.00023966]
	Learning Rate: 0.000239657
	LOSS [training: 0.08547643172725217 | validation: 0.0931236039922152]
	TIME [epoch: 8.49 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08184969967689723		[learning rate: 0.00023909]
	Learning Rate: 0.000239091
	LOSS [training: 0.08184969967689723 | validation: 0.08525706456511792]
	TIME [epoch: 8.51 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07791551399176948		[learning rate: 0.00023853]
	Learning Rate: 0.000238527
	LOSS [training: 0.07791551399176948 | validation: 0.07630309253499785]
	TIME [epoch: 8.52 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07558846001672351		[learning rate: 0.00023796]
	Learning Rate: 0.000237965
	LOSS [training: 0.07558846001672351 | validation: 0.10746593034642375]
	TIME [epoch: 8.51 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08382857891269935		[learning rate: 0.0002374]
	Learning Rate: 0.000237404
	LOSS [training: 0.08382857891269935 | validation: 0.08432005066608803]
	TIME [epoch: 8.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0810660730967577		[learning rate: 0.00023684]
	Learning Rate: 0.000236844
	LOSS [training: 0.0810660730967577 | validation: 0.07085932246932453]
	TIME [epoch: 8.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07574925156223702		[learning rate: 0.00023628]
	Learning Rate: 0.000236285
	LOSS [training: 0.07574925156223702 | validation: 0.09287652435461063]
	TIME [epoch: 8.52 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08107113821990554		[learning rate: 0.00023573]
	Learning Rate: 0.000235728
	LOSS [training: 0.08107113821990554 | validation: 0.07177503590159089]
	TIME [epoch: 8.51 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07264770639371354		[learning rate: 0.00023517]
	Learning Rate: 0.000235171
	LOSS [training: 0.07264770639371354 | validation: 0.08787500606623674]
	TIME [epoch: 8.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08124181424127633		[learning rate: 0.00023462]
	Learning Rate: 0.000234617
	LOSS [training: 0.08124181424127633 | validation: 0.08373786337773813]
	TIME [epoch: 8.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0789430242369092		[learning rate: 0.00023406]
	Learning Rate: 0.000234063
	LOSS [training: 0.0789430242369092 | validation: 0.07938961656156272]
	TIME [epoch: 8.52 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07656549695057312		[learning rate: 0.00023351]
	Learning Rate: 0.000233511
	LOSS [training: 0.07656549695057312 | validation: 0.0876538915482952]
	TIME [epoch: 8.51 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06887038743535875		[learning rate: 0.00023296]
	Learning Rate: 0.00023296
	LOSS [training: 0.06887038743535875 | validation: 0.0753085402629205]
	TIME [epoch: 8.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08013980945412358		[learning rate: 0.00023241]
	Learning Rate: 0.000232411
	LOSS [training: 0.08013980945412358 | validation: 0.09322513778290004]
	TIME [epoch: 8.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07959103405685372		[learning rate: 0.00023186]
	Learning Rate: 0.000231863
	LOSS [training: 0.07959103405685372 | validation: 0.08566738295528291]
	TIME [epoch: 8.52 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0702775501757694		[learning rate: 0.00023132]
	Learning Rate: 0.000231316
	LOSS [training: 0.0702775501757694 | validation: 0.07003786022040712]
	TIME [epoch: 8.51 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07411084965515492		[learning rate: 0.00023077]
	Learning Rate: 0.00023077
	LOSS [training: 0.07411084965515492 | validation: 0.07993117227275248]
	TIME [epoch: 8.49 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08263981206773832		[learning rate: 0.00023023]
	Learning Rate: 0.000230226
	LOSS [training: 0.08263981206773832 | validation: 0.0981500868626436]
	TIME [epoch: 8.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07604323393022547		[learning rate: 0.00022968]
	Learning Rate: 0.000229683
	LOSS [training: 0.07604323393022547 | validation: 0.08553843925149218]
	TIME [epoch: 8.52 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07653834723565464		[learning rate: 0.00022914]
	Learning Rate: 0.000229141
	LOSS [training: 0.07653834723565464 | validation: 0.07873261873901251]
	TIME [epoch: 8.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0808488407320159		[learning rate: 0.0002286]
	Learning Rate: 0.0002286
	LOSS [training: 0.0808488407320159 | validation: 0.08015896889404166]
	TIME [epoch: 8.49 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08517272584630532		[learning rate: 0.00022806]
	Learning Rate: 0.000228061
	LOSS [training: 0.08517272584630532 | validation: 0.07888464811394094]
	TIME [epoch: 8.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07883363532322345		[learning rate: 0.00022752]
	Learning Rate: 0.000227523
	LOSS [training: 0.07883363532322345 | validation: 0.08648129387612642]
	TIME [epoch: 8.53 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07589664914860901		[learning rate: 0.00022699]
	Learning Rate: 0.000226986
	LOSS [training: 0.07589664914860901 | validation: 0.07360545885746991]
	TIME [epoch: 8.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08227413902374489		[learning rate: 0.00022645]
	Learning Rate: 0.000226451
	LOSS [training: 0.08227413902374489 | validation: 0.09848272091429236]
	TIME [epoch: 8.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08582465796133402		[learning rate: 0.00022592]
	Learning Rate: 0.000225917
	LOSS [training: 0.08582465796133402 | validation: 0.09582289705009456]
	TIME [epoch: 8.51 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08122324495358392		[learning rate: 0.00022538]
	Learning Rate: 0.000225384
	LOSS [training: 0.08122324495358392 | validation: 0.08159244568285556]
	TIME [epoch: 8.51 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08157088555320603		[learning rate: 0.00022485]
	Learning Rate: 0.000224852
	LOSS [training: 0.08157088555320603 | validation: 0.07388394972964733]
	TIME [epoch: 8.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08513373171494698		[learning rate: 0.00022432]
	Learning Rate: 0.000224322
	LOSS [training: 0.08513373171494698 | validation: 0.08449791107372091]
	TIME [epoch: 8.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08739137176545214		[learning rate: 0.00022379]
	Learning Rate: 0.000223793
	LOSS [training: 0.08739137176545214 | validation: 0.0633136174798376]
	TIME [epoch: 8.52 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08365310960955584		[learning rate: 0.00022326]
	Learning Rate: 0.000223265
	LOSS [training: 0.08365310960955584 | validation: 0.07247499169761819]
	TIME [epoch: 8.51 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08224858807549774		[learning rate: 0.00022274]
	Learning Rate: 0.000222738
	LOSS [training: 0.08224858807549774 | validation: 0.06545775082717704]
	TIME [epoch: 8.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07976547263208357		[learning rate: 0.00022221]
	Learning Rate: 0.000222213
	LOSS [training: 0.07976547263208357 | validation: 0.08352305297880652]
	TIME [epoch: 8.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07595933416503961		[learning rate: 0.00022169]
	Learning Rate: 0.000221689
	LOSS [training: 0.07595933416503961 | validation: 0.07620904465860914]
	TIME [epoch: 8.52 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07671648749201113		[learning rate: 0.00022117]
	Learning Rate: 0.000221166
	LOSS [training: 0.07671648749201113 | validation: 0.08059647268833575]
	TIME [epoch: 8.51 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07391178135836127		[learning rate: 0.00022064]
	Learning Rate: 0.000220644
	LOSS [training: 0.07391178135836127 | validation: 0.07494764891655362]
	TIME [epoch: 8.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08143124073529191		[learning rate: 0.00022012]
	Learning Rate: 0.000220124
	LOSS [training: 0.08143124073529191 | validation: 0.07650704385198329]
	TIME [epoch: 8.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07576964381461938		[learning rate: 0.0002196]
	Learning Rate: 0.000219604
	LOSS [training: 0.07576964381461938 | validation: 0.08621739704503739]
	TIME [epoch: 8.53 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07625011371396884		[learning rate: 0.00021909]
	Learning Rate: 0.000219086
	LOSS [training: 0.07625011371396884 | validation: 0.08484839789867774]
	TIME [epoch: 8.51 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07941744888857658		[learning rate: 0.00021857]
	Learning Rate: 0.00021857
	LOSS [training: 0.07941744888857658 | validation: 0.076666873470259]
	TIME [epoch: 8.49 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08321069221781766		[learning rate: 0.00021805]
	Learning Rate: 0.000218054
	LOSS [training: 0.08321069221781766 | validation: 0.08557658171200683]
	TIME [epoch: 8.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08202923601740929		[learning rate: 0.00021754]
	Learning Rate: 0.00021754
	LOSS [training: 0.08202923601740929 | validation: 0.09406137160708741]
	TIME [epoch: 8.53 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07691111624458666		[learning rate: 0.00021703]
	Learning Rate: 0.000217027
	LOSS [training: 0.07691111624458666 | validation: 0.07205145897371788]
	TIME [epoch: 8.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07753760615214601		[learning rate: 0.00021651]
	Learning Rate: 0.000216515
	LOSS [training: 0.07753760615214601 | validation: 0.09180459011945417]
	TIME [epoch: 8.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0837817394183088		[learning rate: 0.000216]
	Learning Rate: 0.000216004
	LOSS [training: 0.0837817394183088 | validation: 0.08039166610306606]
	TIME [epoch: 8.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08385883582343662		[learning rate: 0.00021549]
	Learning Rate: 0.000215494
	LOSS [training: 0.08385883582343662 | validation: 0.08697408095578513]
	TIME [epoch: 8.52 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07004004928719748		[learning rate: 0.00021499]
	Learning Rate: 0.000214986
	LOSS [training: 0.07004004928719748 | validation: 0.0851801469062327]
	TIME [epoch: 8.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0774802857004403		[learning rate: 0.00021448]
	Learning Rate: 0.000214479
	LOSS [training: 0.0774802857004403 | validation: 0.06747293985212642]
	TIME [epoch: 8.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08665784655765833		[learning rate: 0.00021397]
	Learning Rate: 0.000213973
	LOSS [training: 0.08665784655765833 | validation: 0.07016890766566035]
	TIME [epoch: 8.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07080043477348595		[learning rate: 0.00021347]
	Learning Rate: 0.000213468
	LOSS [training: 0.07080043477348595 | validation: 0.06692151457237874]
	TIME [epoch: 8.53 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07739959053586523		[learning rate: 0.00021296]
	Learning Rate: 0.000212965
	LOSS [training: 0.07739959053586523 | validation: 0.10048587112247417]
	TIME [epoch: 8.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08268179465825833		[learning rate: 0.00021246]
	Learning Rate: 0.000212462
	LOSS [training: 0.08268179465825833 | validation: 0.11680078866510749]
	TIME [epoch: 8.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09637688197799191		[learning rate: 0.00021196]
	Learning Rate: 0.000211961
	LOSS [training: 0.09637688197799191 | validation: 0.08014982607887848]
	TIME [epoch: 8.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07681833392431177		[learning rate: 0.00021146]
	Learning Rate: 0.000211461
	LOSS [training: 0.07681833392431177 | validation: 0.07966136643998714]
	TIME [epoch: 8.53 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07355841640564267		[learning rate: 0.00021096]
	Learning Rate: 0.000210962
	LOSS [training: 0.07355841640564267 | validation: 0.07465793497673273]
	TIME [epoch: 8.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07536808562294707		[learning rate: 0.00021046]
	Learning Rate: 0.000210465
	LOSS [training: 0.07536808562294707 | validation: 0.0750044002759514]
	TIME [epoch: 8.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07493056265844442		[learning rate: 0.00020997]
	Learning Rate: 0.000209968
	LOSS [training: 0.07493056265844442 | validation: 0.07033948446269611]
	TIME [epoch: 8.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07288029354705373		[learning rate: 0.00020947]
	Learning Rate: 0.000209473
	LOSS [training: 0.07288029354705373 | validation: 0.0815298592643546]
	TIME [epoch: 8.52 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08119401333892522		[learning rate: 0.00020898]
	Learning Rate: 0.000208979
	LOSS [training: 0.08119401333892522 | validation: 0.07193824119130357]
	TIME [epoch: 8.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07607535863138286		[learning rate: 0.00020849]
	Learning Rate: 0.000208486
	LOSS [training: 0.07607535863138286 | validation: 0.08237669066783435]
	TIME [epoch: 8.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07812539760318696		[learning rate: 0.00020799]
	Learning Rate: 0.000207994
	LOSS [training: 0.07812539760318696 | validation: 0.09676053569974594]
	TIME [epoch: 8.51 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08039978677023665		[learning rate: 0.0002075]
	Learning Rate: 0.000207504
	LOSS [training: 0.08039978677023665 | validation: 0.07370657781551673]
	TIME [epoch: 8.52 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07360925491150021		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.07360925491150021 | validation: 0.08317528032831875]
	TIME [epoch: 8.51 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07579695466359015		[learning rate: 0.00020653]
	Learning Rate: 0.000206526
	LOSS [training: 0.07579695466359015 | validation: 0.08564622619127354]
	TIME [epoch: 8.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07809308489166697		[learning rate: 0.00020604]
	Learning Rate: 0.000206039
	LOSS [training: 0.07809308489166697 | validation: 0.07704172255495222]
	TIME [epoch: 8.52 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07389664209974499		[learning rate: 0.00020555]
	Learning Rate: 0.000205553
	LOSS [training: 0.07389664209974499 | validation: 0.08584233875973346]
	TIME [epoch: 8.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07361078858053996		[learning rate: 0.00020507]
	Learning Rate: 0.000205068
	LOSS [training: 0.07361078858053996 | validation: 0.07488343403851946]
	TIME [epoch: 8.49 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0721760452441563		[learning rate: 0.00020458]
	Learning Rate: 0.000204584
	LOSS [training: 0.0721760452441563 | validation: 0.07822262653606496]
	TIME [epoch: 8.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07626632670523376		[learning rate: 0.0002041]
	Learning Rate: 0.000204101
	LOSS [training: 0.07626632670523376 | validation: 0.08773539455088028]
	TIME [epoch: 8.52 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07550871863603241		[learning rate: 0.00020362]
	Learning Rate: 0.00020362
	LOSS [training: 0.07550871863603241 | validation: 0.08347986521857992]
	TIME [epoch: 8.51 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07500087501993155		[learning rate: 0.00020314]
	Learning Rate: 0.00020314
	LOSS [training: 0.07500087501993155 | validation: 0.07560315868242772]
	TIME [epoch: 8.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0850633737212031		[learning rate: 0.00020266]
	Learning Rate: 0.000202661
	LOSS [training: 0.0850633737212031 | validation: 0.08441411775750746]
	TIME [epoch: 8.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07549874121026663		[learning rate: 0.00020218]
	Learning Rate: 0.000202182
	LOSS [training: 0.07549874121026663 | validation: 0.08381487293600301]
	TIME [epoch: 8.52 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07357200005607538		[learning rate: 0.00020171]
	Learning Rate: 0.000201706
	LOSS [training: 0.07357200005607538 | validation: 0.09290332225548233]
	TIME [epoch: 8.51 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07499497418779748		[learning rate: 0.00020123]
	Learning Rate: 0.00020123
	LOSS [training: 0.07499497418779748 | validation: 0.07359618869472581]
	TIME [epoch: 8.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07605527710589287		[learning rate: 0.00020076]
	Learning Rate: 0.000200755
	LOSS [training: 0.07605527710589287 | validation: 0.06677208066558006]
	TIME [epoch: 8.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0728944454125829		[learning rate: 0.00020028]
	Learning Rate: 0.000200282
	LOSS [training: 0.0728944454125829 | validation: 0.07654994894832196]
	TIME [epoch: 8.52 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08446551583348971		[learning rate: 0.00019981]
	Learning Rate: 0.000199809
	LOSS [training: 0.08446551583348971 | validation: 0.0920139359916059]
	TIME [epoch: 8.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0761902312677736		[learning rate: 0.00019934]
	Learning Rate: 0.000199338
	LOSS [training: 0.0761902312677736 | validation: 0.0762528318534143]
	TIME [epoch: 8.51 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07557916970706431		[learning rate: 0.00019887]
	Learning Rate: 0.000198868
	LOSS [training: 0.07557916970706431 | validation: 0.07298818725094734]
	TIME [epoch: 8.51 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0742498899591329		[learning rate: 0.0001984]
	Learning Rate: 0.000198398
	LOSS [training: 0.0742498899591329 | validation: 0.08494463988125389]
	TIME [epoch: 8.53 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07516453428424313		[learning rate: 0.00019793]
	Learning Rate: 0.000197931
	LOSS [training: 0.07516453428424313 | validation: 0.07804258564043082]
	TIME [epoch: 8.51 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06784537018207795		[learning rate: 0.00019746]
	Learning Rate: 0.000197464
	LOSS [training: 0.06784537018207795 | validation: 0.1040370980599976]
	TIME [epoch: 8.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07813465119989106		[learning rate: 0.000197]
	Learning Rate: 0.000196998
	LOSS [training: 0.07813465119989106 | validation: 0.09030776113888453]
	TIME [epoch: 8.51 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07516517676091236		[learning rate: 0.00019653]
	Learning Rate: 0.000196533
	LOSS [training: 0.07516517676091236 | validation: 0.07367468198390885]
	TIME [epoch: 8.53 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07240612626798056		[learning rate: 0.00019607]
	Learning Rate: 0.00019607
	LOSS [training: 0.07240612626798056 | validation: 0.08685218297674974]
	TIME [epoch: 8.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08487104920805918		[learning rate: 0.00019561]
	Learning Rate: 0.000195607
	LOSS [training: 0.08487104920805918 | validation: 0.07088115874516271]
	TIME [epoch: 8.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07563797030640335		[learning rate: 0.00019515]
	Learning Rate: 0.000195146
	LOSS [training: 0.07563797030640335 | validation: 0.07575247620711204]
	TIME [epoch: 8.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0806191545528986		[learning rate: 0.00019469]
	Learning Rate: 0.000194685
	LOSS [training: 0.0806191545528986 | validation: 0.08049944067649387]
	TIME [epoch: 8.53 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08177027400028344		[learning rate: 0.00019423]
	Learning Rate: 0.000194226
	LOSS [training: 0.08177027400028344 | validation: 0.08094237737128315]
	TIME [epoch: 8.51 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07562862541480524		[learning rate: 0.00019377]
	Learning Rate: 0.000193768
	LOSS [training: 0.07562862541480524 | validation: 0.054746567814381863]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_1720.pth
	Model improved!!!
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07144780606725805		[learning rate: 0.00019331]
	Learning Rate: 0.000193311
	LOSS [training: 0.07144780606725805 | validation: 0.07099161360627271]
	TIME [epoch: 8.51 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07330480604285725		[learning rate: 0.00019285]
	Learning Rate: 0.000192855
	LOSS [training: 0.07330480604285725 | validation: 0.07167127915140063]
	TIME [epoch: 8.52 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07716828220141296		[learning rate: 0.0001924]
	Learning Rate: 0.0001924
	LOSS [training: 0.07716828220141296 | validation: 0.071179381389769]
	TIME [epoch: 8.51 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0812360477550575		[learning rate: 0.00019195]
	Learning Rate: 0.000191946
	LOSS [training: 0.0812360477550575 | validation: 0.07486976161377801]
	TIME [epoch: 8.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07825826276513678		[learning rate: 0.00019149]
	Learning Rate: 0.000191493
	LOSS [training: 0.07825826276513678 | validation: 0.0616283897493477]
	TIME [epoch: 8.52 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08288923049530489		[learning rate: 0.00019104]
	Learning Rate: 0.000191042
	LOSS [training: 0.08288923049530489 | validation: 0.06266053752192019]
	TIME [epoch: 8.52 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0752743627838785		[learning rate: 0.00019059]
	Learning Rate: 0.000190591
	LOSS [training: 0.0752743627838785 | validation: 0.07171868516935873]
	TIME [epoch: 8.51 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07881234459047276		[learning rate: 0.00019014]
	Learning Rate: 0.000190141
	LOSS [training: 0.07881234459047276 | validation: 0.08874275347078606]
	TIME [epoch: 8.5 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07233196115757043		[learning rate: 0.00018969]
	Learning Rate: 0.000189693
	LOSS [training: 0.07233196115757043 | validation: 0.06409680700950571]
	TIME [epoch: 8.52 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07491056471731775		[learning rate: 0.00018925]
	Learning Rate: 0.000189245
	LOSS [training: 0.07491056471731775 | validation: 0.07409840772568883]
	TIME [epoch: 8.51 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07218691656370146		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.07218691656370146 | validation: 0.08029119916785382]
	TIME [epoch: 8.51 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07325731852765745		[learning rate: 0.00018835]
	Learning Rate: 0.000188354
	LOSS [training: 0.07325731852765745 | validation: 0.06629299722588898]
	TIME [epoch: 8.51 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07616787298345895		[learning rate: 0.00018791]
	Learning Rate: 0.000187909
	LOSS [training: 0.07616787298345895 | validation: 0.07277481452260838]
	TIME [epoch: 8.57 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08676229994206713		[learning rate: 0.00018747]
	Learning Rate: 0.000187466
	LOSS [training: 0.08676229994206713 | validation: 0.06563755696714695]
	TIME [epoch: 8.51 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08166218784295784		[learning rate: 0.00018702]
	Learning Rate: 0.000187024
	LOSS [training: 0.08166218784295784 | validation: 0.06726158336705987]
	TIME [epoch: 8.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07532355222667361		[learning rate: 0.00018658]
	Learning Rate: 0.000186583
	LOSS [training: 0.07532355222667361 | validation: 0.07079311909531993]
	TIME [epoch: 8.51 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07784013329953464		[learning rate: 0.00018614]
	Learning Rate: 0.000186143
	LOSS [training: 0.07784013329953464 | validation: 0.07387039095440062]
	TIME [epoch: 8.52 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0706383668590846		[learning rate: 0.0001857]
	Learning Rate: 0.000185704
	LOSS [training: 0.0706383668590846 | validation: 0.06064571209381986]
	TIME [epoch: 8.51 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07509886743494809		[learning rate: 0.00018527]
	Learning Rate: 0.000185266
	LOSS [training: 0.07509886743494809 | validation: 0.08101395725536295]
	TIME [epoch: 8.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07993327208061195		[learning rate: 0.00018483]
	Learning Rate: 0.000184829
	LOSS [training: 0.07993327208061195 | validation: 0.09374502780483245]
	TIME [epoch: 8.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08550781247685613		[learning rate: 0.00018439]
	Learning Rate: 0.000184393
	LOSS [training: 0.08550781247685613 | validation: 0.0792987862013338]
	TIME [epoch: 8.53 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07897370515417772		[learning rate: 0.00018396]
	Learning Rate: 0.000183958
	LOSS [training: 0.07897370515417772 | validation: 0.0608490061773478]
	TIME [epoch: 8.51 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0852036278776371		[learning rate: 0.00018352]
	Learning Rate: 0.000183524
	LOSS [training: 0.0852036278776371 | validation: 0.08179901563906]
	TIME [epoch: 8.51 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09059528491674552		[learning rate: 0.00018309]
	Learning Rate: 0.000183091
	LOSS [training: 0.09059528491674552 | validation: 0.08267419842287582]
	TIME [epoch: 8.51 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08272972856932381		[learning rate: 0.00018266]
	Learning Rate: 0.000182659
	LOSS [training: 0.08272972856932381 | validation: 0.07856705831396425]
	TIME [epoch: 8.53 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07048505822210918		[learning rate: 0.00018223]
	Learning Rate: 0.000182228
	LOSS [training: 0.07048505822210918 | validation: 0.08942310055427849]
	TIME [epoch: 8.51 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08002207087845695		[learning rate: 0.0001818]
	Learning Rate: 0.000181798
	LOSS [training: 0.08002207087845695 | validation: 0.08822219534849281]
	TIME [epoch: 8.51 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07678504025414525		[learning rate: 0.00018137]
	Learning Rate: 0.000181369
	LOSS [training: 0.07678504025414525 | validation: 0.08342387201064552]
	TIME [epoch: 8.51 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0785386447784393		[learning rate: 0.00018094]
	Learning Rate: 0.000180942
	LOSS [training: 0.0785386447784393 | validation: 0.07500395220633341]
	TIME [epoch: 8.53 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0826223449691916		[learning rate: 0.00018051]
	Learning Rate: 0.000180515
	LOSS [training: 0.0826223449691916 | validation: 0.08485600016559082]
	TIME [epoch: 8.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07299753710745485		[learning rate: 0.00018009]
	Learning Rate: 0.000180089
	LOSS [training: 0.07299753710745485 | validation: 0.07703600460179777]
	TIME [epoch: 8.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07770148415224268		[learning rate: 0.00017966]
	Learning Rate: 0.000179664
	LOSS [training: 0.07770148415224268 | validation: 0.08155402772499055]
	TIME [epoch: 8.51 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07937267942364509		[learning rate: 0.00017924]
	Learning Rate: 0.00017924
	LOSS [training: 0.07937267942364509 | validation: 0.07324803269658352]
	TIME [epoch: 8.51 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07734680386156474		[learning rate: 0.00017882]
	Learning Rate: 0.000178818
	LOSS [training: 0.07734680386156474 | validation: 0.07678997638367678]
	TIME [epoch: 8.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07607665518678104		[learning rate: 0.0001784]
	Learning Rate: 0.000178396
	LOSS [training: 0.07607665518678104 | validation: 0.07245907269161664]
	TIME [epoch: 8.51 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0734090631147821		[learning rate: 0.00017797]
	Learning Rate: 0.000177975
	LOSS [training: 0.0734090631147821 | validation: 0.05762764519607706]
	TIME [epoch: 8.52 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07678870925819588		[learning rate: 0.00017756]
	Learning Rate: 0.000177555
	LOSS [training: 0.07678870925819588 | validation: 0.06690109246884454]
	TIME [epoch: 8.51 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07178406659626153		[learning rate: 0.00017714]
	Learning Rate: 0.000177136
	LOSS [training: 0.07178406659626153 | validation: 0.07691152515159069]
	TIME [epoch: 8.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07924911286828237		[learning rate: 0.00017672]
	Learning Rate: 0.000176718
	LOSS [training: 0.07924911286828237 | validation: 0.08633994345420422]
	TIME [epoch: 8.51 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08418954636768466		[learning rate: 0.0001763]
	Learning Rate: 0.000176302
	LOSS [training: 0.08418954636768466 | validation: 0.06834006288975847]
	TIME [epoch: 8.53 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07533379858256911		[learning rate: 0.00017589]
	Learning Rate: 0.000175886
	LOSS [training: 0.07533379858256911 | validation: 0.07747667848088348]
	TIME [epoch: 8.51 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07274551385841668		[learning rate: 0.00017547]
	Learning Rate: 0.000175471
	LOSS [training: 0.07274551385841668 | validation: 0.07679036507724665]
	TIME [epoch: 8.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07978568408589039		[learning rate: 0.00017506]
	Learning Rate: 0.000175057
	LOSS [training: 0.07978568408589039 | validation: 0.06290948772178251]
	TIME [epoch: 8.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07248150547317823		[learning rate: 0.00017464]
	Learning Rate: 0.000174644
	LOSS [training: 0.07248150547317823 | validation: 0.07399933794152028]
	TIME [epoch: 8.53 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07181580214078277		[learning rate: 0.00017423]
	Learning Rate: 0.000174232
	LOSS [training: 0.07181580214078277 | validation: 0.0649020563504703]
	TIME [epoch: 8.51 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07965550508783285		[learning rate: 0.00017382]
	Learning Rate: 0.000173821
	LOSS [training: 0.07965550508783285 | validation: 0.06339380251196247]
	TIME [epoch: 8.51 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07452753999192381		[learning rate: 0.00017341]
	Learning Rate: 0.000173411
	LOSS [training: 0.07452753999192381 | validation: 0.07106812184204364]
	TIME [epoch: 8.51 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07781642442216123		[learning rate: 0.000173]
	Learning Rate: 0.000173002
	LOSS [training: 0.07781642442216123 | validation: 0.07773233808854109]
	TIME [epoch: 8.53 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08276146186915181		[learning rate: 0.00017259]
	Learning Rate: 0.000172594
	LOSS [training: 0.08276146186915181 | validation: 0.06852668694806156]
	TIME [epoch: 8.51 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07192817563725665		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.07192817563725665 | validation: 0.07741745233253008]
	TIME [epoch: 8.5 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07960660562837031		[learning rate: 0.00017178]
	Learning Rate: 0.000171781
	LOSS [training: 0.07960660562837031 | validation: 0.09171044194763535]
	TIME [epoch: 8.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07637011002842957		[learning rate: 0.00017138]
	Learning Rate: 0.000171375
	LOSS [training: 0.07637011002842957 | validation: 0.07747990704216512]
	TIME [epoch: 8.53 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07676531787872304		[learning rate: 0.00017097]
	Learning Rate: 0.000170971
	LOSS [training: 0.07676531787872304 | validation: 0.08835992442783155]
	TIME [epoch: 8.51 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07324068272126698		[learning rate: 0.00017057]
	Learning Rate: 0.000170568
	LOSS [training: 0.07324068272126698 | validation: 0.07741894409487285]
	TIME [epoch: 8.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07675591907396463		[learning rate: 0.00017017]
	Learning Rate: 0.000170166
	LOSS [training: 0.07675591907396463 | validation: 0.05400974133455732]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240219_184940/states/model_tr_study3_1775.pth
	Model improved!!!
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0722698147870171		[learning rate: 0.00016976]
	Learning Rate: 0.000169764
	LOSS [training: 0.0722698147870171 | validation: 0.07411401768425534]
	TIME [epoch: 8.53 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07668115875815998		[learning rate: 0.00016936]
	Learning Rate: 0.000169364
	LOSS [training: 0.07668115875815998 | validation: 0.06891714954497961]
	TIME [epoch: 8.51 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07141660093283375		[learning rate: 0.00016896]
	Learning Rate: 0.000168964
	LOSS [training: 0.07141660093283375 | validation: 0.06867076547937265]
	TIME [epoch: 8.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0745327324632529		[learning rate: 0.00016857]
	Learning Rate: 0.000168566
	LOSS [training: 0.0745327324632529 | validation: 0.07453200401058586]
	TIME [epoch: 8.51 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08112166860102484		[learning rate: 0.00016817]
	Learning Rate: 0.000168168
	LOSS [training: 0.08112166860102484 | validation: 0.07645206022578101]
	TIME [epoch: 8.53 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08434637358542381		[learning rate: 0.00016777]
	Learning Rate: 0.000167771
	LOSS [training: 0.08434637358542381 | validation: 0.07994920064771771]
	TIME [epoch: 8.51 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07565312338886214		[learning rate: 0.00016738]
	Learning Rate: 0.000167376
	LOSS [training: 0.07565312338886214 | validation: 0.0701921289740508]
	TIME [epoch: 8.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07143824452533426		[learning rate: 0.00016698]
	Learning Rate: 0.000166981
	LOSS [training: 0.07143824452533426 | validation: 0.06800634332400662]
	TIME [epoch: 8.51 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0761504447018673		[learning rate: 0.00016659]
	Learning Rate: 0.000166587
	LOSS [training: 0.0761504447018673 | validation: 0.06897900585414646]
	TIME [epoch: 8.52 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07083322269139466		[learning rate: 0.00016619]
	Learning Rate: 0.000166194
	LOSS [training: 0.07083322269139466 | validation: 0.07089838959278358]
	TIME [epoch: 8.51 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07474348817414173		[learning rate: 0.0001658]
	Learning Rate: 0.000165802
	LOSS [training: 0.07474348817414173 | validation: 0.08654370183449211]
	TIME [epoch: 8.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0739000082680762		[learning rate: 0.00016541]
	Learning Rate: 0.000165411
	LOSS [training: 0.0739000082680762 | validation: 0.07065001063736971]
	TIME [epoch: 8.52 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07167221309753562		[learning rate: 0.00016502]
	Learning Rate: 0.000165021
	LOSS [training: 0.07167221309753562 | validation: 0.07369630144517532]
	TIME [epoch: 8.51 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07536551962736274		[learning rate: 0.00016463]
	Learning Rate: 0.000164631
	LOSS [training: 0.07536551962736274 | validation: 0.07576637133621028]
	TIME [epoch: 8.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07450307885006649		[learning rate: 0.00016424]
	Learning Rate: 0.000164243
	LOSS [training: 0.07450307885006649 | validation: 0.06787685045931252]
	TIME [epoch: 8.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0718652910215518		[learning rate: 0.00016386]
	Learning Rate: 0.000163856
	LOSS [training: 0.0718652910215518 | validation: 0.08729073488395506]
	TIME [epoch: 8.51 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07416575430169743		[learning rate: 0.00016347]
	Learning Rate: 0.000163469
	LOSS [training: 0.07416575430169743 | validation: 0.08219399376721229]
	TIME [epoch: 8.51 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07411338275987894		[learning rate: 0.00016308]
	Learning Rate: 0.000163084
	LOSS [training: 0.07411338275987894 | validation: 0.08825717605698759]
	TIME [epoch: 8.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0728645218466997		[learning rate: 0.0001627]
	Learning Rate: 0.000162699
	LOSS [training: 0.0728645218466997 | validation: 0.06895594120040527]
	TIME [epoch: 8.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0682564109040428		[learning rate: 0.00016232]
	Learning Rate: 0.000162315
	LOSS [training: 0.0682564109040428 | validation: 0.07511630319204465]
	TIME [epoch: 8.52 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07826217277351018		[learning rate: 0.00016193]
	Learning Rate: 0.000161932
	LOSS [training: 0.07826217277351018 | validation: 0.08582810763247262]
	TIME [epoch: 8.5 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0718062226675384		[learning rate: 0.00016155]
	Learning Rate: 0.00016155
	LOSS [training: 0.0718062226675384 | validation: 0.06931934273251804]
	TIME [epoch: 8.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07251463190064836		[learning rate: 0.00016117]
	Learning Rate: 0.000161169
	LOSS [training: 0.07251463190064836 | validation: 0.07026966167902517]
	TIME [epoch: 8.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0691879469640946		[learning rate: 0.00016079]
	Learning Rate: 0.000160789
	LOSS [training: 0.0691879469640946 | validation: 0.07209469841998908]
	TIME [epoch: 8.52 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07695001463998052		[learning rate: 0.00016041]
	Learning Rate: 0.00016041
	LOSS [training: 0.07695001463998052 | validation: 0.08471016735316647]
	TIME [epoch: 8.51 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07834337162786123		[learning rate: 0.00016003]
	Learning Rate: 0.000160031
	LOSS [training: 0.07834337162786123 | validation: 0.07048813551233929]
	TIME [epoch: 8.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07300287633485619		[learning rate: 0.00015965]
	Learning Rate: 0.000159654
	LOSS [training: 0.07300287633485619 | validation: 0.07447248313889801]
	TIME [epoch: 8.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07624822138959204		[learning rate: 0.00015928]
	Learning Rate: 0.000159277
	LOSS [training: 0.07624822138959204 | validation: 0.08251988930906347]
	TIME [epoch: 8.53 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07317373038640693		[learning rate: 0.0001589]
	Learning Rate: 0.000158902
	LOSS [training: 0.07317373038640693 | validation: 0.07059981366144423]
	TIME [epoch: 8.51 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07073224281251295		[learning rate: 0.00015853]
	Learning Rate: 0.000158527
	LOSS [training: 0.07073224281251295 | validation: 0.06503301695944579]
	TIME [epoch: 8.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07889298784992571		[learning rate: 0.00015815]
	Learning Rate: 0.000158153
	LOSS [training: 0.07889298784992571 | validation: 0.08116149960050714]
	TIME [epoch: 8.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08042890751343043		[learning rate: 0.00015778]
	Learning Rate: 0.00015778
	LOSS [training: 0.08042890751343043 | validation: 0.08456829521264898]
	TIME [epoch: 8.54 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07799850710717557		[learning rate: 0.00015741]
	Learning Rate: 0.000157408
	LOSS [training: 0.07799850710717557 | validation: 0.07766110538054646]
	TIME [epoch: 8.51 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07787731887834186		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.07787731887834186 | validation: 0.09361312772048927]
	TIME [epoch: 8.5 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08052200124491145		[learning rate: 0.00015667]
	Learning Rate: 0.000156666
	LOSS [training: 0.08052200124491145 | validation: 0.09709827816586905]
	TIME [epoch: 8.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07762070808893141		[learning rate: 0.0001563]
	Learning Rate: 0.000156296
	LOSS [training: 0.07762070808893141 | validation: 0.06737555945293072]
	TIME [epoch: 8.53 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08265654117083399		[learning rate: 0.00015593]
	Learning Rate: 0.000155928
	LOSS [training: 0.08265654117083399 | validation: 0.07309182267462125]
	TIME [epoch: 8.5 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07834818772438024		[learning rate: 0.00015556]
	Learning Rate: 0.00015556
	LOSS [training: 0.07834818772438024 | validation: 0.06874780047075431]
	TIME [epoch: 8.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07851763487061209		[learning rate: 0.00015519]
	Learning Rate: 0.000155193
	LOSS [training: 0.07851763487061209 | validation: 0.08644868283049613]
	TIME [epoch: 8.51 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07964092689637182		[learning rate: 0.00015483]
	Learning Rate: 0.000154827
	LOSS [training: 0.07964092689637182 | validation: 0.07723240793246282]
	TIME [epoch: 8.52 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08205237943022614		[learning rate: 0.00015446]
	Learning Rate: 0.000154462
	LOSS [training: 0.08205237943022614 | validation: 0.10670905855451945]
	TIME [epoch: 8.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07650651733415217		[learning rate: 0.0001541]
	Learning Rate: 0.000154097
	LOSS [training: 0.07650651733415217 | validation: 0.07711777667065636]
	TIME [epoch: 8.51 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07867133670173845		[learning rate: 0.00015373]
	Learning Rate: 0.000153734
	LOSS [training: 0.07867133670173845 | validation: 0.07996734046106341]
	TIME [epoch: 8.51 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07377132130505357		[learning rate: 0.00015337]
	Learning Rate: 0.000153371
	LOSS [training: 0.07377132130505357 | validation: 0.0751537874133401]
	TIME [epoch: 8.51 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07647897418421594		[learning rate: 0.00015301]
	Learning Rate: 0.000153009
	LOSS [training: 0.07647897418421594 | validation: 0.08610666696400705]
	TIME [epoch: 8.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08002604458401817		[learning rate: 0.00015265]
	Learning Rate: 0.000152648
	LOSS [training: 0.08002604458401817 | validation: 0.08277930903935003]
	TIME [epoch: 8.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07643287541291376		[learning rate: 0.00015229]
	Learning Rate: 0.000152288
	LOSS [training: 0.07643287541291376 | validation: 0.07026919495574735]
	TIME [epoch: 8.51 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07559774381214221		[learning rate: 0.00015193]
	Learning Rate: 0.000151929
	LOSS [training: 0.07559774381214221 | validation: 0.07699508506317469]
	TIME [epoch: 8.51 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07220027138945137		[learning rate: 0.00015157]
	Learning Rate: 0.000151571
	LOSS [training: 0.07220027138945137 | validation: 0.08120267192334682]
	TIME [epoch: 8.51 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08106356104377907		[learning rate: 0.00015121]
	Learning Rate: 0.000151213
	LOSS [training: 0.08106356104377907 | validation: 0.07123277669787584]
	TIME [epoch: 8.51 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0727837387101687		[learning rate: 0.00015086]
	Learning Rate: 0.000150857
	LOSS [training: 0.0727837387101687 | validation: 0.06855495566680009]
	TIME [epoch: 8.52 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06821489093759373		[learning rate: 0.0001505]
	Learning Rate: 0.000150501
	LOSS [training: 0.06821489093759373 | validation: 0.07124359671041992]
	TIME [epoch: 8.51 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07478051193574722		[learning rate: 0.00015015]
	Learning Rate: 0.000150146
	LOSS [training: 0.07478051193574722 | validation: 0.08566090398704447]
	TIME [epoch: 8.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07402613945481182		[learning rate: 0.00014979]
	Learning Rate: 0.000149791
	LOSS [training: 0.07402613945481182 | validation: 0.09813420214613565]
	TIME [epoch: 8.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08726725805163416		[learning rate: 0.00014944]
	Learning Rate: 0.000149438
	LOSS [training: 0.08726725805163416 | validation: 0.07639833418457427]
	TIME [epoch: 8.52 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07532495158218569		[learning rate: 0.00014909]
	Learning Rate: 0.000149086
	LOSS [training: 0.07532495158218569 | validation: 0.08186784382605615]
	TIME [epoch: 8.51 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07977105789534752		[learning rate: 0.00014873]
	Learning Rate: 0.000148734
	LOSS [training: 0.07977105789534752 | validation: 0.10197793151553788]
	TIME [epoch: 8.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07613131351298964		[learning rate: 0.00014838]
	Learning Rate: 0.000148383
	LOSS [training: 0.07613131351298964 | validation: 0.08111247746785152]
	TIME [epoch: 8.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07928808197168147		[learning rate: 0.00014803]
	Learning Rate: 0.000148033
	LOSS [training: 0.07928808197168147 | validation: 0.08374768769053785]
	TIME [epoch: 8.53 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07756292018850634		[learning rate: 0.00014768]
	Learning Rate: 0.000147684
	LOSS [training: 0.07756292018850634 | validation: 0.07351804952382744]
	TIME [epoch: 8.51 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07478304897613243		[learning rate: 0.00014734]
	Learning Rate: 0.000147336
	LOSS [training: 0.07478304897613243 | validation: 0.08843572875545462]
	TIME [epoch: 8.51 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08528417937054733		[learning rate: 0.00014699]
	Learning Rate: 0.000146988
	LOSS [training: 0.08528417937054733 | validation: 0.0688556401372787]
	TIME [epoch: 8.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07367750601678026		[learning rate: 0.00014664]
	Learning Rate: 0.000146641
	LOSS [training: 0.07367750601678026 | validation: 0.09099187742424905]
	TIME [epoch: 8.52 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0791098443407128		[learning rate: 0.0001463]
	Learning Rate: 0.000146295
	LOSS [training: 0.0791098443407128 | validation: 0.07712003742569948]
	TIME [epoch: 8.49 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08329526131700335		[learning rate: 0.00014595]
	Learning Rate: 0.00014595
	LOSS [training: 0.08329526131700335 | validation: 0.07660401546745]
	TIME [epoch: 8.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08086800312576474		[learning rate: 0.00014561]
	Learning Rate: 0.000145606
	LOSS [training: 0.08086800312576474 | validation: 0.08042960570690805]
	TIME [epoch: 8.5 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08536035409106678		[learning rate: 0.00014526]
	Learning Rate: 0.000145263
	LOSS [training: 0.08536035409106678 | validation: 0.08900597288908235]
	TIME [epoch: 8.53 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07802094611898638		[learning rate: 0.00014492]
	Learning Rate: 0.00014492
	LOSS [training: 0.07802094611898638 | validation: 0.08689271930589809]
	TIME [epoch: 8.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09656968839800431		[learning rate: 0.00014458]
	Learning Rate: 0.000144578
	LOSS [training: 0.09656968839800431 | validation: 0.08183846717716584]
	TIME [epoch: 8.5 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08186712129379997		[learning rate: 0.00014424]
	Learning Rate: 0.000144237
	LOSS [training: 0.08186712129379997 | validation: 0.09047669791343904]
	TIME [epoch: 8.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07398376783520116		[learning rate: 0.0001439]
	Learning Rate: 0.000143897
	LOSS [training: 0.07398376783520116 | validation: 0.07995408198450091]
	TIME [epoch: 8.53 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07855769458776776		[learning rate: 0.00014356]
	Learning Rate: 0.000143557
	LOSS [training: 0.07855769458776776 | validation: 0.07622571750918201]
	TIME [epoch: 8.5 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08479636889241512		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.08479636889241512 | validation: 0.0851487288599892]
	TIME [epoch: 8.51 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08066389938331439		[learning rate: 0.00014288]
	Learning Rate: 0.000142881
	LOSS [training: 0.08066389938331439 | validation: 0.08275413348921333]
	TIME [epoch: 8.51 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08073859229434113		[learning rate: 0.00014254]
	Learning Rate: 0.000142544
	LOSS [training: 0.08073859229434113 | validation: 0.07696008908070873]
	TIME [epoch: 8.52 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07764392169316195		[learning rate: 0.00014221]
	Learning Rate: 0.000142208
	LOSS [training: 0.07764392169316195 | validation: 0.07990300263671807]
	TIME [epoch: 8.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07548627493548796		[learning rate: 0.00014187]
	Learning Rate: 0.000141872
	LOSS [training: 0.07548627493548796 | validation: 0.08564408333861775]
	TIME [epoch: 8.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07525658179664144		[learning rate: 0.00014154]
	Learning Rate: 0.000141538
	LOSS [training: 0.07525658179664144 | validation: 0.06706104995356191]
	TIME [epoch: 8.52 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08470419455266417		[learning rate: 0.0001412]
	Learning Rate: 0.000141204
	LOSS [training: 0.08470419455266417 | validation: 0.08767617983767803]
	TIME [epoch: 8.51 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.079934401934041		[learning rate: 0.00014087]
	Learning Rate: 0.000140871
	LOSS [training: 0.079934401934041 | validation: 0.07381184579614802]
	TIME [epoch: 8.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08149287787147794		[learning rate: 0.00014054]
	Learning Rate: 0.000140538
	LOSS [training: 0.08149287787147794 | validation: 0.08446725315618614]
	TIME [epoch: 8.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0765512082125031		[learning rate: 0.00014021]
	Learning Rate: 0.000140207
	LOSS [training: 0.0765512082125031 | validation: 0.08291784287111104]
	TIME [epoch: 8.52 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08506618112373736		[learning rate: 0.00013988]
	Learning Rate: 0.000139876
	LOSS [training: 0.08506618112373736 | validation: 0.07600063326868639]
	TIME [epoch: 8.51 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.074846455466373		[learning rate: 0.00013955]
	Learning Rate: 0.000139546
	LOSS [training: 0.074846455466373 | validation: 0.0780084101912695]
	TIME [epoch: 8.51 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07173172632380784		[learning rate: 0.00013922]
	Learning Rate: 0.000139217
	LOSS [training: 0.07173172632380784 | validation: 0.07330412864276037]
	TIME [epoch: 8.5 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07158739348196583		[learning rate: 0.00013889]
	Learning Rate: 0.000138889
	LOSS [training: 0.07158739348196583 | validation: 0.07897935546415005]
	TIME [epoch: 8.52 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0828935743787288		[learning rate: 0.00013856]
	Learning Rate: 0.000138561
	LOSS [training: 0.0828935743787288 | validation: 0.10580542738995533]
	TIME [epoch: 8.51 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08801623223158841		[learning rate: 0.00013823]
	Learning Rate: 0.000138234
	LOSS [training: 0.08801623223158841 | validation: 0.08464878881813347]
	TIME [epoch: 8.51 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07417786703633869		[learning rate: 0.00013791]
	Learning Rate: 0.000137908
	LOSS [training: 0.07417786703633869 | validation: 0.0769075544274258]
	TIME [epoch: 8.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07150206937208001		[learning rate: 0.00013758]
	Learning Rate: 0.000137583
	LOSS [training: 0.07150206937208001 | validation: 0.08413111692108291]
	TIME [epoch: 8.53 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07375345975764987		[learning rate: 0.00013726]
	Learning Rate: 0.000137258
	LOSS [training: 0.07375345975764987 | validation: 0.07440066592751932]
	TIME [epoch: 8.51 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07667236177129028		[learning rate: 0.00013693]
	Learning Rate: 0.000136934
	LOSS [training: 0.07667236177129028 | validation: 0.08609740603337766]
	TIME [epoch: 8.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07865140608609444		[learning rate: 0.00013661]
	Learning Rate: 0.000136611
	LOSS [training: 0.07865140608609444 | validation: 0.07258827593944259]
	TIME [epoch: 8.51 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07940560186265723		[learning rate: 0.00013629]
	Learning Rate: 0.000136289
	LOSS [training: 0.07940560186265723 | validation: 0.07595306554448963]
	TIME [epoch: 8.53 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08747791151795989		[learning rate: 0.00013597]
	Learning Rate: 0.000135968
	LOSS [training: 0.08747791151795989 | validation: 0.08016827814324543]
	TIME [epoch: 8.51 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07654925109817975		[learning rate: 0.00013565]
	Learning Rate: 0.000135647
	LOSS [training: 0.07654925109817975 | validation: 0.08306832575338528]
	TIME [epoch: 8.51 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07485751721842274		[learning rate: 0.00013533]
	Learning Rate: 0.000135327
	LOSS [training: 0.07485751721842274 | validation: 0.08251638886833117]
	TIME [epoch: 8.51 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08156536217731807		[learning rate: 0.00013501]
	Learning Rate: 0.000135008
	LOSS [training: 0.08156536217731807 | validation: 0.09337160436672942]
	TIME [epoch: 8.53 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08203929654485857		[learning rate: 0.00013469]
	Learning Rate: 0.000134689
	LOSS [training: 0.08203929654485857 | validation: 0.06789414888493314]
	TIME [epoch: 8.51 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07762309223252964		[learning rate: 0.00013437]
	Learning Rate: 0.000134372
	LOSS [training: 0.07762309223252964 | validation: 0.09411892549386214]
	TIME [epoch: 8.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08566717917952751		[learning rate: 0.00013405]
	Learning Rate: 0.000134055
	LOSS [training: 0.08566717917952751 | validation: 0.08495870004999957]
	TIME [epoch: 8.51 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07108129196097945		[learning rate: 0.00013374]
	Learning Rate: 0.000133738
	LOSS [training: 0.07108129196097945 | validation: 0.0834362716301704]
	TIME [epoch: 8.53 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07408741120120507		[learning rate: 0.00013342]
	Learning Rate: 0.000133423
	LOSS [training: 0.07408741120120507 | validation: 0.0853544037004148]
	TIME [epoch: 8.51 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07930251687126075		[learning rate: 0.00013311]
	Learning Rate: 0.000133108
	LOSS [training: 0.07930251687126075 | validation: 0.08190558382120221]
	TIME [epoch: 8.51 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07422550173305918		[learning rate: 0.00013279]
	Learning Rate: 0.000132794
	LOSS [training: 0.07422550173305918 | validation: 0.09144441442175372]
	TIME [epoch: 8.52 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07763867838061973		[learning rate: 0.00013248]
	Learning Rate: 0.000132481
	LOSS [training: 0.07763867838061973 | validation: 0.0921062693976442]
	TIME [epoch: 8.53 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08362036949082782		[learning rate: 0.00013217]
	Learning Rate: 0.000132169
	LOSS [training: 0.08362036949082782 | validation: 0.08903272222785374]
	TIME [epoch: 8.51 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07956743821622865		[learning rate: 0.00013186]
	Learning Rate: 0.000131857
	LOSS [training: 0.07956743821622865 | validation: 0.0638369532376708]
	TIME [epoch: 8.52 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07667446738671282		[learning rate: 0.00013155]
	Learning Rate: 0.000131546
	LOSS [training: 0.07667446738671282 | validation: 0.07970902293571841]
	TIME [epoch: 8.53 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08070200522221274		[learning rate: 0.00013124]
	Learning Rate: 0.000131235
	LOSS [training: 0.08070200522221274 | validation: 0.1094576668928356]
	TIME [epoch: 8.52 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07875238261999906		[learning rate: 0.00013093]
	Learning Rate: 0.000130926
	LOSS [training: 0.07875238261999906 | validation: 0.09006357680859672]
	TIME [epoch: 8.51 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07437655703259168		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.07437655703259168 | validation: 0.07603267835343049]
	TIME [epoch: 8.52 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07592542422847516		[learning rate: 0.00013031]
	Learning Rate: 0.000130309
	LOSS [training: 0.07592542422847516 | validation: 0.08549073996785905]
	TIME [epoch: 8.53 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.072595772998072		[learning rate: 0.00013]
	Learning Rate: 0.000130002
	LOSS [training: 0.072595772998072 | validation: 0.08230500009575377]
	TIME [epoch: 8.52 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07816017511293996		[learning rate: 0.00012969]
	Learning Rate: 0.000129695
	LOSS [training: 0.07816017511293996 | validation: 0.09457773875384064]
	TIME [epoch: 8.51 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08113566783864608		[learning rate: 0.00012939]
	Learning Rate: 0.000129389
	LOSS [training: 0.08113566783864608 | validation: 0.08208582437829505]
	TIME [epoch: 8.51 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08055318846140543		[learning rate: 0.00012908]
	Learning Rate: 0.000129084
	LOSS [training: 0.08055318846140543 | validation: 0.08829204674840747]
	TIME [epoch: 8.53 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07178879832229176		[learning rate: 0.00012878]
	Learning Rate: 0.000128779
	LOSS [training: 0.07178879832229176 | validation: 0.0840621347043132]
	TIME [epoch: 8.52 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0780532280813173		[learning rate: 0.00012848]
	Learning Rate: 0.000128476
	LOSS [training: 0.0780532280813173 | validation: 0.08185441208157188]
	TIME [epoch: 8.51 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07374603464237092		[learning rate: 0.00012817]
	Learning Rate: 0.000128172
	LOSS [training: 0.07374603464237092 | validation: 0.07874950635184522]
	TIME [epoch: 8.51 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07599993041615599		[learning rate: 0.00012787]
	Learning Rate: 0.00012787
	LOSS [training: 0.07599993041615599 | validation: 0.08397191714191429]
	TIME [epoch: 8.53 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0768033646002919		[learning rate: 0.00012757]
	Learning Rate: 0.000127569
	LOSS [training: 0.0768033646002919 | validation: 0.08795000137385559]
	TIME [epoch: 8.52 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06628481769086882		[learning rate: 0.00012727]
	Learning Rate: 0.000127268
	LOSS [training: 0.06628481769086882 | validation: 0.07648470767813767]
	TIME [epoch: 8.51 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06902657597702665		[learning rate: 0.00012697]
	Learning Rate: 0.000126967
	LOSS [training: 0.06902657597702665 | validation: 0.08290770649140863]
	TIME [epoch: 8.51 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07709504747328542		[learning rate: 0.00012667]
	Learning Rate: 0.000126668
	LOSS [training: 0.07709504747328542 | validation: 0.0778677959255732]
	TIME [epoch: 8.53 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06822492885320933		[learning rate: 0.00012637]
	Learning Rate: 0.000126369
	LOSS [training: 0.06822492885320933 | validation: 0.08761263026698561]
	TIME [epoch: 8.52 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07662660646092534		[learning rate: 0.00012607]
	Learning Rate: 0.000126071
	LOSS [training: 0.07662660646092534 | validation: 0.08419209673097479]
	TIME [epoch: 8.51 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0828910646760176		[learning rate: 0.00012577]
	Learning Rate: 0.000125774
	LOSS [training: 0.0828910646760176 | validation: 0.08486361417664948]
	TIME [epoch: 8.51 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06915242001089825		[learning rate: 0.00012548]
	Learning Rate: 0.000125477
	LOSS [training: 0.06915242001089825 | validation: 0.07019762730786523]
	TIME [epoch: 8.54 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07082776034107298		[learning rate: 0.00012518]
	Learning Rate: 0.000125181
	LOSS [training: 0.07082776034107298 | validation: 0.08549029547367773]
	TIME [epoch: 8.51 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07431325587993494		[learning rate: 0.00012489]
	Learning Rate: 0.000124886
	LOSS [training: 0.07431325587993494 | validation: 0.08593311104851217]
	TIME [epoch: 8.51 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07195546884025435		[learning rate: 0.00012459]
	Learning Rate: 0.000124591
	LOSS [training: 0.07195546884025435 | validation: 0.08253761879506752]
	TIME [epoch: 8.51 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07633436168062192		[learning rate: 0.0001243]
	Learning Rate: 0.000124297
	LOSS [training: 0.07633436168062192 | validation: 0.07938099147190622]
	TIME [epoch: 8.53 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0771241565543466		[learning rate: 0.000124]
	Learning Rate: 0.000124004
	LOSS [training: 0.0771241565543466 | validation: 0.08268451825600504]
	TIME [epoch: 8.51 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07937068508535179		[learning rate: 0.00012371]
	Learning Rate: 0.000123712
	LOSS [training: 0.07937068508535179 | validation: 0.08778752656271782]
	TIME [epoch: 8.51 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07333731579773826		[learning rate: 0.00012342]
	Learning Rate: 0.00012342
	LOSS [training: 0.07333731579773826 | validation: 0.07376596151893167]
	TIME [epoch: 8.51 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07444529243528876		[learning rate: 0.00012313]
	Learning Rate: 0.000123129
	LOSS [training: 0.07444529243528876 | validation: 0.08079539579645945]
	TIME [epoch: 8.52 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07437011082330512		[learning rate: 0.00012284]
	Learning Rate: 0.000122838
	LOSS [training: 0.07437011082330512 | validation: 0.08515255648449112]
	TIME [epoch: 8.51 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07244324460901323		[learning rate: 0.00012255]
	Learning Rate: 0.000122548
	LOSS [training: 0.07244324460901323 | validation: 0.06703660649173787]
	TIME [epoch: 8.51 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0764531731236558		[learning rate: 0.00012226]
	Learning Rate: 0.000122259
	LOSS [training: 0.0764531731236558 | validation: 0.09326158191442435]
	TIME [epoch: 8.53 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07028991279643138		[learning rate: 0.00012197]
	Learning Rate: 0.000121971
	LOSS [training: 0.07028991279643138 | validation: 0.06685361436617554]
	TIME [epoch: 8.52 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0753278076770756		[learning rate: 0.00012168]
	Learning Rate: 0.000121683
	LOSS [training: 0.0753278076770756 | validation: 0.07893756577197605]
	TIME [epoch: 8.51 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07210624422094312		[learning rate: 0.0001214]
	Learning Rate: 0.000121396
	LOSS [training: 0.07210624422094312 | validation: 0.07626045851747268]
	TIME [epoch: 8.51 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07774333008457113		[learning rate: 0.00012111]
	Learning Rate: 0.00012111
	LOSS [training: 0.07774333008457113 | validation: 0.06982580286098504]
	TIME [epoch: 8.52 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07701803515896022		[learning rate: 0.00012082]
	Learning Rate: 0.000120824
	LOSS [training: 0.07701803515896022 | validation: 0.07119126990228906]
	TIME [epoch: 8.51 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07824737690702778		[learning rate: 0.00012054]
	Learning Rate: 0.000120539
	LOSS [training: 0.07824737690702778 | validation: 0.07552750916781875]
	TIME [epoch: 8.51 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07064750365521846		[learning rate: 0.00012025]
	Learning Rate: 0.000120255
	LOSS [training: 0.07064750365521846 | validation: 0.07201114083319636]
	TIME [epoch: 8.51 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06793974894881655		[learning rate: 0.00011997]
	Learning Rate: 0.000119971
	LOSS [training: 0.06793974894881655 | validation: 0.07080042006573546]
	TIME [epoch: 8.53 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06937218227181599		[learning rate: 0.00011969]
	Learning Rate: 0.000119688
	LOSS [training: 0.06937218227181599 | validation: 0.07502656876925613]
	TIME [epoch: 8.51 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07183732650897623		[learning rate: 0.00011941]
	Learning Rate: 0.000119406
	LOSS [training: 0.07183732650897623 | validation: 0.07919255762517781]
	TIME [epoch: 8.51 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0705724788144512		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.0705724788144512 | validation: 0.07441686816229967]
	TIME [epoch: 8.5 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06706099777055152		[learning rate: 0.00011884]
	Learning Rate: 0.000118843
	LOSS [training: 0.06706099777055152 | validation: 0.06369590051251597]
	TIME [epoch: 8.53 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06839305917421143		[learning rate: 0.00011856]
	Learning Rate: 0.000118563
	LOSS [training: 0.06839305917421143 | validation: 0.08380253666995119]
	TIME [epoch: 8.51 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07122750333329311		[learning rate: 0.00011828]
	Learning Rate: 0.000118283
	LOSS [training: 0.07122750333329311 | validation: 0.06760533871748696]
	TIME [epoch: 8.51 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07082493729125906		[learning rate: 0.000118]
	Learning Rate: 0.000118004
	LOSS [training: 0.07082493729125906 | validation: 0.06749153284559034]
	TIME [epoch: 8.51 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06802391718569706		[learning rate: 0.00011773]
	Learning Rate: 0.000117726
	LOSS [training: 0.06802391718569706 | validation: 0.06891475418026533]
	TIME [epoch: 8.52 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06860389271635649		[learning rate: 0.00011745]
	Learning Rate: 0.000117448
	LOSS [training: 0.06860389271635649 | validation: 0.07210213952294495]
	TIME [epoch: 8.51 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06595508529273028		[learning rate: 0.00011717]
	Learning Rate: 0.000117171
	LOSS [training: 0.06595508529273028 | validation: 0.06526274025746165]
	TIME [epoch: 8.5 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07164372388508125		[learning rate: 0.00011689]
	Learning Rate: 0.000116895
	LOSS [training: 0.07164372388508125 | validation: 0.06902969692993244]
	TIME [epoch: 8.51 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07208945299414081		[learning rate: 0.00011662]
	Learning Rate: 0.000116619
	LOSS [training: 0.07208945299414081 | validation: 0.08641558339493888]
	TIME [epoch: 8.53 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07056404492022306		[learning rate: 0.00011634]
	Learning Rate: 0.000116344
	LOSS [training: 0.07056404492022306 | validation: 0.07250637289153314]
	TIME [epoch: 8.51 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07325452221542009		[learning rate: 0.00011607]
	Learning Rate: 0.000116069
	LOSS [training: 0.07325452221542009 | validation: 0.06949781119587008]
	TIME [epoch: 8.51 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0669766567031928		[learning rate: 0.0001158]
	Learning Rate: 0.000115796
	LOSS [training: 0.0669766567031928 | validation: 0.0711614451857484]
	TIME [epoch: 8.51 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07095335682405392		[learning rate: 0.00011552]
	Learning Rate: 0.000115523
	LOSS [training: 0.07095335682405392 | validation: 0.07595012021025237]
	TIME [epoch: 8.53 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06803669806080268		[learning rate: 0.00011525]
	Learning Rate: 0.00011525
	LOSS [training: 0.06803669806080268 | validation: 0.06599242154575297]
	TIME [epoch: 8.51 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0662090939107671		[learning rate: 0.00011498]
	Learning Rate: 0.000114978
	LOSS [training: 0.0662090939107671 | validation: 0.06892925304781913]
	TIME [epoch: 8.51 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0679019714752337		[learning rate: 0.00011471]
	Learning Rate: 0.000114707
	LOSS [training: 0.0679019714752337 | validation: 0.07457918540996143]
	TIME [epoch: 8.51 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07122667060399619		[learning rate: 0.00011444]
	Learning Rate: 0.000114436
	LOSS [training: 0.07122667060399619 | validation: 0.06952102113067579]
	TIME [epoch: 8.53 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0794568525474947		[learning rate: 0.00011417]
	Learning Rate: 0.000114166
	LOSS [training: 0.0794568525474947 | validation: 0.08052792856159537]
	TIME [epoch: 8.51 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08261412141397749		[learning rate: 0.0001139]
	Learning Rate: 0.000113897
	LOSS [training: 0.08261412141397749 | validation: 0.07234735293376957]
	TIME [epoch: 8.51 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07707832766768824		[learning rate: 0.00011363]
	Learning Rate: 0.000113628
	LOSS [training: 0.07707832766768824 | validation: 0.07293295393618163]
	TIME [epoch: 8.51 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06550030923302283		[learning rate: 0.00011336]
	Learning Rate: 0.00011336
	LOSS [training: 0.06550030923302283 | validation: 0.07389787585520073]
	TIME [epoch: 8.52 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07071606523487053		[learning rate: 0.00011309]
	Learning Rate: 0.000113093
	LOSS [training: 0.07071606523487053 | validation: 0.07597771021877323]
	TIME [epoch: 8.51 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07017521222840403		[learning rate: 0.00011283]
	Learning Rate: 0.000112826
	LOSS [training: 0.07017521222840403 | validation: 0.07269971876917536]
	TIME [epoch: 8.51 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06726098554032904		[learning rate: 0.00011256]
	Learning Rate: 0.00011256
	LOSS [training: 0.06726098554032904 | validation: 0.0783152657902003]
	TIME [epoch: 8.53 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0681934244983919		[learning rate: 0.00011229]
	Learning Rate: 0.000112295
	LOSS [training: 0.0681934244983919 | validation: 0.08068133344653314]
	TIME [epoch: 8.51 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07427456464974308		[learning rate: 0.00011203]
	Learning Rate: 0.00011203
	LOSS [training: 0.07427456464974308 | validation: 0.07111630328754592]
	TIME [epoch: 8.51 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07137367570487191		[learning rate: 0.00011177]
	Learning Rate: 0.000111765
	LOSS [training: 0.07137367570487191 | validation: 0.07219603751921756]
	TIME [epoch: 8.51 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06686261364743089		[learning rate: 0.0001115]
	Learning Rate: 0.000111502
	LOSS [training: 0.06686261364743089 | validation: 0.06794569051698246]
	TIME [epoch: 8.53 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07017516785368037		[learning rate: 0.00011124]
	Learning Rate: 0.000111239
	LOSS [training: 0.07017516785368037 | validation: 0.08197189924818421]
	TIME [epoch: 8.52 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07551656977961786		[learning rate: 0.00011098]
	Learning Rate: 0.000110976
	LOSS [training: 0.07551656977961786 | validation: 0.0715553655754096]
	TIME [epoch: 8.51 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06843052094588906		[learning rate: 0.00011071]
	Learning Rate: 0.000110715
	LOSS [training: 0.06843052094588906 | validation: 0.0861940877656348]
	TIME [epoch: 8.51 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06846366167374356		[learning rate: 0.00011045]
	Learning Rate: 0.000110453
	LOSS [training: 0.06846366167374356 | validation: 0.0786740327711773]
	TIME [epoch: 8.53 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07300655808855674		[learning rate: 0.00011019]
	Learning Rate: 0.000110193
	LOSS [training: 0.07300655808855674 | validation: 0.07849922676080104]
	TIME [epoch: 8.5 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06736519472642702		[learning rate: 0.00010993]
	Learning Rate: 0.000109933
	LOSS [training: 0.06736519472642702 | validation: 0.054243796013262464]
	TIME [epoch: 8.51 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06846424581033031		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.06846424581033031 | validation: 0.06743900654595841]
	TIME [epoch: 8.53 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06913238418056504		[learning rate: 0.00010942]
	Learning Rate: 0.000109415
	LOSS [training: 0.06913238418056504 | validation: 0.09416995185577268]
	TIME [epoch: 8.55 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07326219365744314		[learning rate: 0.00010916]
	Learning Rate: 0.000109157
	LOSS [training: 0.07326219365744314 | validation: 0.08746701447695357]
	TIME [epoch: 8.53 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07003593444146985		[learning rate: 0.0001089]
	Learning Rate: 0.000108899
	LOSS [training: 0.07003593444146985 | validation: 0.0722673681562732]
	TIME [epoch: 8.52 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07004900795119332		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.07004900795119332 | validation: 0.07706118863867055]
	TIME [epoch: 8.53 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06671272791635448		[learning rate: 0.00010839]
	Learning Rate: 0.000108386
	LOSS [training: 0.06671272791635448 | validation: 0.08753361583975683]
	TIME [epoch: 8.55 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07058481653586161		[learning rate: 0.00010813]
	Learning Rate: 0.000108131
	LOSS [training: 0.07058481653586161 | validation: 0.07371257213507336]
	TIME [epoch: 8.53 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08259504321202563		[learning rate: 0.00010788]
	Learning Rate: 0.000107876
	LOSS [training: 0.08259504321202563 | validation: 0.07432588440943094]
	TIME [epoch: 8.54 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07816512296641588		[learning rate: 0.00010762]
	Learning Rate: 0.000107621
	LOSS [training: 0.07816512296641588 | validation: 0.0765778609954951]
	TIME [epoch: 8.53 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07289887035745081		[learning rate: 0.00010737]
	Learning Rate: 0.000107367
	LOSS [training: 0.07289887035745081 | validation: 0.07409264276518522]
	TIME [epoch: 8.56 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06784996345828007		[learning rate: 0.00010711]
	Learning Rate: 0.000107114
	LOSS [training: 0.06784996345828007 | validation: 0.06243842827879756]
	TIME [epoch: 8.53 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07013990849789191		[learning rate: 0.00010686]
	Learning Rate: 0.000106861
	LOSS [training: 0.07013990849789191 | validation: 0.06698221615987342]
	TIME [epoch: 8.54 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07092999950796959		[learning rate: 0.00010661]
	Learning Rate: 0.000106609
	LOSS [training: 0.07092999950796959 | validation: 0.06235536912588659]
	TIME [epoch: 8.54 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07203025639302292		[learning rate: 0.00010636]
	Learning Rate: 0.000106358
	LOSS [training: 0.07203025639302292 | validation: 0.06459190128610873]
	TIME [epoch: 8.56 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07268555891951281		[learning rate: 0.00010611]
	Learning Rate: 0.000106107
	LOSS [training: 0.07268555891951281 | validation: 0.0881272045672854]
	TIME [epoch: 8.53 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0678118281476438		[learning rate: 0.00010586]
	Learning Rate: 0.000105857
	LOSS [training: 0.0678118281476438 | validation: 0.08432749037155744]
	TIME [epoch: 8.53 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07119984682314962		[learning rate: 0.00010561]
	Learning Rate: 0.000105607
	LOSS [training: 0.07119984682314962 | validation: 0.0766584378158782]
	TIME [epoch: 8.55 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06950448896650915		[learning rate: 0.00010536]
	Learning Rate: 0.000105358
	LOSS [training: 0.06950448896650915 | validation: 0.07113428649910271]
	TIME [epoch: 8.54 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06909121145802152		[learning rate: 0.00010511]
	Learning Rate: 0.000105109
	LOSS [training: 0.06909121145802152 | validation: 0.07966564285943369]
	TIME [epoch: 8.54 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06599890282406817		[learning rate: 0.00010486]
	Learning Rate: 0.000104861
	LOSS [training: 0.06599890282406817 | validation: 0.07340994080513565]
	TIME [epoch: 8.54 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0720906481864329		[learning rate: 0.00010461]
	Learning Rate: 0.000104614
	LOSS [training: 0.0720906481864329 | validation: 0.07453712228508895]
	TIME [epoch: 8.56 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07406196286329983		[learning rate: 0.00010437]
	Learning Rate: 0.000104367
	LOSS [training: 0.07406196286329983 | validation: 0.0829528768637907]
	TIME [epoch: 8.54 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07091710057751067		[learning rate: 0.00010412]
	Learning Rate: 0.000104121
	LOSS [training: 0.07091710057751067 | validation: 0.06636220458128689]
	TIME [epoch: 8.55 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06991010254580007		[learning rate: 0.00010388]
	Learning Rate: 0.000103875
	LOSS [training: 0.06991010254580007 | validation: 0.061315741201978746]
	TIME [epoch: 8.54 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06529841389638		[learning rate: 0.00010363]
	Learning Rate: 0.00010363
	LOSS [training: 0.06529841389638 | validation: 0.06267740108906739]
	TIME [epoch: 8.56 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07067541548463215		[learning rate: 0.00010339]
	Learning Rate: 0.000103386
	LOSS [training: 0.07067541548463215 | validation: 0.07313163473455953]
	TIME [epoch: 8.54 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07049779638125094		[learning rate: 0.00010314]
	Learning Rate: 0.000103142
	LOSS [training: 0.07049779638125094 | validation: 0.07365475709454941]
	TIME [epoch: 8.53 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07169982335577654		[learning rate: 0.0001029]
	Learning Rate: 0.000102899
	LOSS [training: 0.07169982335577654 | validation: 0.07632927396369335]
	TIME [epoch: 8.54 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07121477845592869		[learning rate: 0.00010266]
	Learning Rate: 0.000102656
	LOSS [training: 0.07121477845592869 | validation: 0.08144153349973961]
	TIME [epoch: 8.57 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06685293465635644		[learning rate: 0.00010241]
	Learning Rate: 0.000102414
	LOSS [training: 0.06685293465635644 | validation: 0.08162626159885428]
	TIME [epoch: 8.55 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07477654877522864		[learning rate: 0.00010217]
	Learning Rate: 0.000102172
	LOSS [training: 0.07477654877522864 | validation: 0.07162748216346815]
	TIME [epoch: 8.54 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06772058473447726		[learning rate: 0.00010193]
	Learning Rate: 0.000101931
	LOSS [training: 0.06772058473447726 | validation: 0.07031103715535922]
	TIME [epoch: 8.54 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07407011754327532		[learning rate: 0.00010169]
	Learning Rate: 0.000101691
	LOSS [training: 0.07407011754327532 | validation: 0.07837226544870451]
	TIME [epoch: 8.55 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07375378557476941		[learning rate: 0.00010145]
	Learning Rate: 0.000101451
	LOSS [training: 0.07375378557476941 | validation: 0.07789830783594513]
	TIME [epoch: 8.54 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07055863957969163		[learning rate: 0.00010121]
	Learning Rate: 0.000101212
	LOSS [training: 0.07055863957969163 | validation: 0.07947403345297947]
	TIME [epoch: 8.53 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07038106848541253		[learning rate: 0.00010097]
	Learning Rate: 0.000100973
	LOSS [training: 0.07038106848541253 | validation: 0.06999467353486406]
	TIME [epoch: 8.53 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06470529188496589		[learning rate: 0.00010073]
	Learning Rate: 0.000100735
	LOSS [training: 0.06470529188496589 | validation: 0.06839740739387683]
	TIME [epoch: 8.56 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06362112996431787		[learning rate: 0.0001005]
	Learning Rate: 0.000100497
	LOSS [training: 0.06362112996431787 | validation: 0.0654017594894363]
	TIME [epoch: 8.54 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07086313344674053		[learning rate: 0.00010026]
	Learning Rate: 0.00010026
	LOSS [training: 0.07086313344674053 | validation: 0.07763800133735929]
	TIME [epoch: 8.54 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07537186480838656		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.07537186480838656 | validation: 0.08013403646090884]
	TIME [epoch: 8.53 sec]
Finished training in 17194.846 seconds.
