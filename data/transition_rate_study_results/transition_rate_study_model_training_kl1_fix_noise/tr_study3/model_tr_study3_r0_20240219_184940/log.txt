Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r0', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3435634069

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.10865050731893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.10865050731893 | validation: 8.592249978744675]
	TIME [epoch: 78.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.529208858629511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.529208858629511 | validation: 7.948458762852512]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.711957939733009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.711957939733009 | validation: 8.099484023528909]
	TIME [epoch: 8.53 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.742582355998339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.742582355998339 | validation: 7.889181630252583]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.81306208017299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.81306208017299 | validation: 7.808555529786226]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.615170050319989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.615170050319989 | validation: 8.005488920784856]
	TIME [epoch: 8.51 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.663602663143749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.663602663143749 | validation: 7.879875894783831]
	TIME [epoch: 8.52 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.868723610334241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.868723610334241 | validation: 12.141607642580045]
	TIME [epoch: 8.5 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 11.877062930401845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.877062930401845 | validation: 8.68623044209098]
	TIME [epoch: 8.53 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.859391109453374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.859391109453374 | validation: 7.77434338094454]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.538854574343205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.538854574343205 | validation: 7.778575880771891]
	TIME [epoch: 8.53 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.21268108170803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.21268108170803 | validation: 7.571357507795852]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.271918323973869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.271918323973869 | validation: 7.363670665666993]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.363858139519647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.363858139519647 | validation: 7.508216115811335]
	TIME [epoch: 8.51 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.301829922853227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.301829922853227 | validation: 7.263025309786737]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.968438180003072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.968438180003072 | validation: 7.632102466112441]
	TIME [epoch: 8.5 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.975927268316951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.975927268316951 | validation: 6.8678835038523385]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.748879514712155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.748879514712155 | validation: 7.18023215748317]
	TIME [epoch: 8.53 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.934203117176014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.934203117176014 | validation: 6.70154408864045]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.304973064945626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.304973064945626 | validation: 6.759830734660494]
	TIME [epoch: 8.51 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.341774401156504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.341774401156504 | validation: 6.866126285198921]
	TIME [epoch: 8.52 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.218363764965678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.218363764965678 | validation: 6.387960962595609]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.002556891346197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.002556891346197 | validation: 6.314695397188554]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.748908019577511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.748908019577511 | validation: 6.411328940373868]
	TIME [epoch: 8.51 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.93734816431939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.93734816431939 | validation: 5.546903619802464]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.531840675328388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.531840675328388 | validation: 5.713984925154533]
	TIME [epoch: 8.54 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.024686017862669		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.024686017862669 | validation: 6.688778320699106]
	TIME [epoch: 8.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.423904821411975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.423904821411975 | validation: 5.216486254604295]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.613653033404814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.613653033404814 | validation: 7.079959541455615]
	TIME [epoch: 8.5 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.300405627271255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.300405627271255 | validation: 3.7057775441017213]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.678288805401561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.678288805401561 | validation: 5.368140937471927]
	TIME [epoch: 8.5 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.755031850225495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.755031850225495 | validation: 2.2433633528056096]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9362938627196873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9362938627196873 | validation: 2.416854203310777]
	TIME [epoch: 8.51 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6295357177679994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6295357177679994 | validation: 2.827317993835109]
	TIME [epoch: 8.54 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.428226306763332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.428226306763332 | validation: 2.0092827440650045]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2729999681574853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2729999681574853 | validation: 2.2403992012823792]
	TIME [epoch: 8.49 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.766610007278003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.766610007278003 | validation: 2.2414655612580865]
	TIME [epoch: 8.51 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9986091970231077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9986091970231077 | validation: 2.199440374323175]
	TIME [epoch: 8.53 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0451840770370664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0451840770370664 | validation: 1.9598834343660017]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0330797947544816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0330797947544816 | validation: 2.702480796796798]
	TIME [epoch: 8.49 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9598717816220237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9598717816220237 | validation: 2.184780669285287]
	TIME [epoch: 8.5 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9639009186495433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9639009186495433 | validation: 1.872738024816652]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9277937434799994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9277937434799994 | validation: 2.765323600065961]
	TIME [epoch: 8.49 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.343513776516823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.343513776516823 | validation: 2.060623631474786]
	TIME [epoch: 8.49 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8401891057124478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8401891057124478 | validation: 1.5799791259051994]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9162630193731574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9162630193731574 | validation: 1.7546931913354222]
	TIME [epoch: 8.52 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7916434234051397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7916434234051397 | validation: 1.5873498626791571]
	TIME [epoch: 8.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7470820983274518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7470820983274518 | validation: 2.192479725663592]
	TIME [epoch: 8.49 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2969374607185946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2969374607185946 | validation: 1.6052694067655002]
	TIME [epoch: 8.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6944701071298103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6944701071298103 | validation: 2.0317060147760833]
	TIME [epoch: 8.49 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.769113074176369		[learning rate: 0.0099788]
	Learning Rate: 0.00997877
	LOSS [training: 1.769113074176369 | validation: 1.6572056723405755]
	TIME [epoch: 8.51 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7278826550157915		[learning rate: 0.0099552]
	Learning Rate: 0.00995523
	LOSS [training: 1.7278826550157915 | validation: 1.9134445664631308]
	TIME [epoch: 8.49 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6900088701083351		[learning rate: 0.0099317]
	Learning Rate: 0.00993175
	LOSS [training: 1.6900088701083351 | validation: 1.6582746081126807]
	TIME [epoch: 8.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6473811085896313		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 1.6473811085896313 | validation: 2.4784587151950226]
	TIME [epoch: 8.48 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8519183322482065		[learning rate: 0.0098849]
	Learning Rate: 0.00988495
	LOSS [training: 1.8519183322482065 | validation: 1.929049143831718]
	TIME [epoch: 8.5 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6706034004732295		[learning rate: 0.0098616]
	Learning Rate: 0.00986163
	LOSS [training: 1.6706034004732295 | validation: 1.5825569321705133]
	TIME [epoch: 8.48 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7338843207381611		[learning rate: 0.0098384]
	Learning Rate: 0.00983837
	LOSS [training: 1.7338843207381611 | validation: 1.6198977083016928]
	TIME [epoch: 8.51 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.785563360320714		[learning rate: 0.0098152]
	Learning Rate: 0.00981516
	LOSS [training: 1.785563360320714 | validation: 1.59989399527064]
	TIME [epoch: 8.49 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6391282429038558		[learning rate: 0.009792]
	Learning Rate: 0.00979201
	LOSS [training: 1.6391282429038558 | validation: 1.645609985872682]
	TIME [epoch: 8.51 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6775650043770836		[learning rate: 0.0097689]
	Learning Rate: 0.00976891
	LOSS [training: 1.6775650043770836 | validation: 1.6578448402503185]
	TIME [epoch: 8.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6461134534581223		[learning rate: 0.0097459]
	Learning Rate: 0.00974587
	LOSS [training: 1.6461134534581223 | validation: 1.7561811676268664]
	TIME [epoch: 8.51 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7850340042782282		[learning rate: 0.0097229]
	Learning Rate: 0.00972288
	LOSS [training: 1.7850340042782282 | validation: 1.622088814568112]
	TIME [epoch: 8.51 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6602911549168962		[learning rate: 0.0096999]
	Learning Rate: 0.00969994
	LOSS [training: 1.6602911549168962 | validation: 1.6773535767340948]
	TIME [epoch: 8.5 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.602953818263293		[learning rate: 0.0096771]
	Learning Rate: 0.00967706
	LOSS [training: 1.602953818263293 | validation: 1.7849924067251821]
	TIME [epoch: 8.51 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6280135735060306		[learning rate: 0.0096542]
	Learning Rate: 0.00965424
	LOSS [training: 1.6280135735060306 | validation: 1.5931329814905335]
	TIME [epoch: 8.5 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6263803974279796		[learning rate: 0.0096315]
	Learning Rate: 0.00963146
	LOSS [training: 1.6263803974279796 | validation: 1.8376634576570163]
	TIME [epoch: 8.49 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.599114435058478		[learning rate: 0.0096087]
	Learning Rate: 0.00960874
	LOSS [training: 1.599114435058478 | validation: 1.5996105849753381]
	TIME [epoch: 8.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5898751538937659		[learning rate: 0.0095861]
	Learning Rate: 0.00958608
	LOSS [training: 1.5898751538937659 | validation: 1.7311416201572687]
	TIME [epoch: 8.51 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.625214381522957		[learning rate: 0.0095635]
	Learning Rate: 0.00956347
	LOSS [training: 1.625214381522957 | validation: 1.5417696872500053]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5449614840252146		[learning rate: 0.0095409]
	Learning Rate: 0.00954091
	LOSS [training: 1.5449614840252146 | validation: 1.6487071532085298]
	TIME [epoch: 8.52 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7139513817491232		[learning rate: 0.0095184]
	Learning Rate: 0.0095184
	LOSS [training: 1.7139513817491232 | validation: 1.4768330530406644]
	TIME [epoch: 8.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6252894382524254		[learning rate: 0.009496]
	Learning Rate: 0.00949595
	LOSS [training: 1.6252894382524254 | validation: 1.5140356264112522]
	TIME [epoch: 8.55 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.478028586241845		[learning rate: 0.0094736]
	Learning Rate: 0.00947355
	LOSS [training: 1.478028586241845 | validation: 1.5536934355580243]
	TIME [epoch: 8.52 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4991655100622279		[learning rate: 0.0094512]
	Learning Rate: 0.0094512
	LOSS [training: 1.4991655100622279 | validation: 1.514105375425811]
	TIME [epoch: 8.54 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4780493860001986		[learning rate: 0.0094289]
	Learning Rate: 0.00942891
	LOSS [training: 1.4780493860001986 | validation: 1.5298021365741823]
	TIME [epoch: 8.54 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.972481341557447		[learning rate: 0.0094067]
	Learning Rate: 0.00940667
	LOSS [training: 1.972481341557447 | validation: 1.6983076223726394]
	TIME [epoch: 8.54 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.476388337811388		[learning rate: 0.0093845]
	Learning Rate: 0.00938448
	LOSS [training: 1.476388337811388 | validation: 1.3574316029860125]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4144168638021593		[learning rate: 0.0093623]
	Learning Rate: 0.00936234
	LOSS [training: 1.4144168638021593 | validation: 1.450064447906898]
	TIME [epoch: 8.52 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6186984533184414		[learning rate: 0.0093403]
	Learning Rate: 0.00934026
	LOSS [training: 1.6186984533184414 | validation: 1.4229882867579229]
	TIME [epoch: 8.54 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4687717740102224		[learning rate: 0.0093182]
	Learning Rate: 0.00931823
	LOSS [training: 1.4687717740102224 | validation: 1.4301823631495383]
	TIME [epoch: 8.52 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4531849223694886		[learning rate: 0.0092962]
	Learning Rate: 0.00929625
	LOSS [training: 1.4531849223694886 | validation: 1.5217365425841707]
	TIME [epoch: 8.5 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5866633603273024		[learning rate: 0.0092743]
	Learning Rate: 0.00927432
	LOSS [training: 1.5866633603273024 | validation: 1.3899077623389624]
	TIME [epoch: 8.52 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3705279996500574		[learning rate: 0.0092524]
	Learning Rate: 0.00925244
	LOSS [training: 1.3705279996500574 | validation: 1.394515164343923]
	TIME [epoch: 8.56 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3935772845871564		[learning rate: 0.0092306]
	Learning Rate: 0.00923062
	LOSS [training: 1.3935772845871564 | validation: 1.3813829387955971]
	TIME [epoch: 8.53 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4119037056875425		[learning rate: 0.0092088]
	Learning Rate: 0.00920884
	LOSS [training: 1.4119037056875425 | validation: 1.360450680678324]
	TIME [epoch: 8.51 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3599647097213667		[learning rate: 0.0091871]
	Learning Rate: 0.00918712
	LOSS [training: 1.3599647097213667 | validation: 1.352878465369255]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.452802764686115		[learning rate: 0.0091655]
	Learning Rate: 0.00916545
	LOSS [training: 1.452802764686115 | validation: 1.334100794693883]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3711583632837656		[learning rate: 0.0091438]
	Learning Rate: 0.00914383
	LOSS [training: 1.3711583632837656 | validation: 1.3116223217220457]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3811849175520161		[learning rate: 0.0091223]
	Learning Rate: 0.00912226
	LOSS [training: 1.3811849175520161 | validation: 1.4545320182782633]
	TIME [epoch: 8.5 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.461671940050455		[learning rate: 0.0091007]
	Learning Rate: 0.00910074
	LOSS [training: 1.461671940050455 | validation: 1.5624771475392465]
	TIME [epoch: 8.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4316011692033397		[learning rate: 0.0090793]
	Learning Rate: 0.00907928
	LOSS [training: 1.4316011692033397 | validation: 2.067780729163733]
	TIME [epoch: 8.53 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.498716425419434		[learning rate: 0.0090579]
	Learning Rate: 0.00905786
	LOSS [training: 1.498716425419434 | validation: 1.322419870372363]
	TIME [epoch: 8.49 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3409076698418407		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 1.3409076698418407 | validation: 1.2645162597629658]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5339300113307075		[learning rate: 0.0090152]
	Learning Rate: 0.00901518
	LOSS [training: 1.5339300113307075 | validation: 1.470182745293615]
	TIME [epoch: 8.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3588375859953694		[learning rate: 0.0089939]
	Learning Rate: 0.00899391
	LOSS [training: 1.3588375859953694 | validation: 1.3566594755773036]
	TIME [epoch: 8.53 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4053495334673574		[learning rate: 0.0089727]
	Learning Rate: 0.0089727
	LOSS [training: 1.4053495334673574 | validation: 1.7138962777023576]
	TIME [epoch: 8.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.409162884998314		[learning rate: 0.0089515]
	Learning Rate: 0.00895153
	LOSS [training: 1.409162884998314 | validation: 1.430907576471436]
	TIME [epoch: 8.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2892966239085035		[learning rate: 0.0089304]
	Learning Rate: 0.00893042
	LOSS [training: 1.2892966239085035 | validation: 1.3786232612773552]
	TIME [epoch: 8.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3223468179800164		[learning rate: 0.0089094]
	Learning Rate: 0.00890935
	LOSS [training: 1.3223468179800164 | validation: 1.174986477685791]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3683217037070665		[learning rate: 0.0088883]
	Learning Rate: 0.00888834
	LOSS [training: 1.3683217037070665 | validation: 1.262929919950306]
	TIME [epoch: 8.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3711106057949052		[learning rate: 0.0088674]
	Learning Rate: 0.00886737
	LOSS [training: 1.3711106057949052 | validation: 1.3443715398288623]
	TIME [epoch: 8.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4624824984046338		[learning rate: 0.0088465]
	Learning Rate: 0.00884645
	LOSS [training: 1.4624824984046338 | validation: 1.3505882252608488]
	TIME [epoch: 8.51 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4494254392270336		[learning rate: 0.0088256]
	Learning Rate: 0.00882559
	LOSS [training: 1.4494254392270336 | validation: 2.275425674567586]
	TIME [epoch: 8.52 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4247140244958163		[learning rate: 0.0088048]
	Learning Rate: 0.00880477
	LOSS [training: 1.4247140244958163 | validation: 1.2629208445072315]
	TIME [epoch: 8.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3294055046594055		[learning rate: 0.008784]
	Learning Rate: 0.008784
	LOSS [training: 1.3294055046594055 | validation: 1.3408789074902856]
	TIME [epoch: 8.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4041143539856775		[learning rate: 0.0087633]
	Learning Rate: 0.00876328
	LOSS [training: 1.4041143539856775 | validation: 2.0247501446779808]
	TIME [epoch: 8.51 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3736017011895467		[learning rate: 0.0087426]
	Learning Rate: 0.00874261
	LOSS [training: 1.3736017011895467 | validation: 1.247360269469456]
	TIME [epoch: 8.51 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.317558042668478		[learning rate: 0.008722]
	Learning Rate: 0.00872199
	LOSS [training: 1.317558042668478 | validation: 1.327650010257616]
	TIME [epoch: 8.51 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3046561524684428		[learning rate: 0.0087014]
	Learning Rate: 0.00870141
	LOSS [training: 1.3046561524684428 | validation: 1.2518609589972547]
	TIME [epoch: 8.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3866887649113104		[learning rate: 0.0086809]
	Learning Rate: 0.00868089
	LOSS [training: 1.3866887649113104 | validation: 1.4302839232323692]
	TIME [epoch: 8.52 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3072581004067658		[learning rate: 0.0086604]
	Learning Rate: 0.00866041
	LOSS [training: 1.3072581004067658 | validation: 1.5575605079318897]
	TIME [epoch: 8.52 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3659322159494667		[learning rate: 0.00864]
	Learning Rate: 0.00863998
	LOSS [training: 1.3659322159494667 | validation: 1.2030727163672643]
	TIME [epoch: 8.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7948747559279083		[learning rate: 0.0086196]
	Learning Rate: 0.0086196
	LOSS [training: 1.7948747559279083 | validation: 1.2421602410569785]
	TIME [epoch: 8.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.094719848888084		[learning rate: 0.0085993]
	Learning Rate: 0.00859927
	LOSS [training: 2.094719848888084 | validation: 1.1627463471376773]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2011698337678136		[learning rate: 0.008579]
	Learning Rate: 0.00857898
	LOSS [training: 1.2011698337678136 | validation: 1.1357292667942356]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2049451638668962		[learning rate: 0.0085587]
	Learning Rate: 0.00855875
	LOSS [training: 1.2049451638668962 | validation: 1.5131851625375385]
	TIME [epoch: 8.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5674700100019927		[learning rate: 0.0085386]
	Learning Rate: 0.00853856
	LOSS [training: 1.5674700100019927 | validation: 1.281519578135001]
	TIME [epoch: 8.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2480791246646175		[learning rate: 0.0085184]
	Learning Rate: 0.00851842
	LOSS [training: 1.2480791246646175 | validation: 1.1852080945373604]
	TIME [epoch: 8.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.212563323286222		[learning rate: 0.0084983]
	Learning Rate: 0.00849833
	LOSS [training: 1.212563323286222 | validation: 1.1816582375577056]
	TIME [epoch: 8.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5695448046407896		[learning rate: 0.0084783]
	Learning Rate: 0.00847828
	LOSS [training: 1.5695448046407896 | validation: 1.7414455414312942]
	TIME [epoch: 8.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.250585915891158		[learning rate: 0.0084583]
	Learning Rate: 0.00845828
	LOSS [training: 1.250585915891158 | validation: 1.3788258243008669]
	TIME [epoch: 8.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3246265903414913		[learning rate: 0.0084383]
	Learning Rate: 0.00843833
	LOSS [training: 1.3246265903414913 | validation: 1.1591981213645837]
	TIME [epoch: 8.49 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2241695334570424		[learning rate: 0.0084184]
	Learning Rate: 0.00841842
	LOSS [training: 1.2241695334570424 | validation: 1.3658137621162039]
	TIME [epoch: 8.51 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2544306438128763		[learning rate: 0.0083986]
	Learning Rate: 0.00839857
	LOSS [training: 1.2544306438128763 | validation: 2.94288240937684]
	TIME [epoch: 8.49 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4571302993537434		[learning rate: 0.0083788]
	Learning Rate: 0.00837875
	LOSS [training: 1.4571302993537434 | validation: 1.2442870831525208]
	TIME [epoch: 8.49 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1970670608499534		[learning rate: 0.008359]
	Learning Rate: 0.00835899
	LOSS [training: 1.1970670608499534 | validation: 1.2066380866005888]
	TIME [epoch: 8.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2239172797671753		[learning rate: 0.0083393]
	Learning Rate: 0.00833927
	LOSS [training: 1.2239172797671753 | validation: 1.1148590271852181]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3107965667953727		[learning rate: 0.0083196]
	Learning Rate: 0.0083196
	LOSS [training: 1.3107965667953727 | validation: 1.3813537980358959]
	TIME [epoch: 8.51 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1840388078955821		[learning rate: 0.0083]
	Learning Rate: 0.00829998
	LOSS [training: 1.1840388078955821 | validation: 1.2042078730240116]
	TIME [epoch: 8.51 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.157517279382674		[learning rate: 0.0082804]
	Learning Rate: 0.0082804
	LOSS [training: 1.157517279382674 | validation: 1.0942495848560043]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1606368603162378		[learning rate: 0.0082609]
	Learning Rate: 0.00826087
	LOSS [training: 1.1606368603162378 | validation: 1.1472175740619726]
	TIME [epoch: 8.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2220976467675648		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 1.2220976467675648 | validation: 1.3094773824794341]
	TIME [epoch: 8.49 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.17105868672548		[learning rate: 0.0082219]
	Learning Rate: 0.00822194
	LOSS [training: 1.17105868672548 | validation: 1.6276411215620166]
	TIME [epoch: 8.51 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3886629987715202		[learning rate: 0.0082025]
	Learning Rate: 0.00820255
	LOSS [training: 1.3886629987715202 | validation: 1.318376720934805]
	TIME [epoch: 8.49 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0807196322330135		[learning rate: 0.0081832]
	Learning Rate: 0.0081832
	LOSS [training: 1.0807196322330135 | validation: 0.9394885569758473]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0844916042733705		[learning rate: 0.0081639]
	Learning Rate: 0.00816389
	LOSS [training: 1.0844916042733705 | validation: 0.9177613266298115]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0549083216351975		[learning rate: 0.0081446]
	Learning Rate: 0.00814464
	LOSS [training: 1.0549083216351975 | validation: 1.207400085896777]
	TIME [epoch: 8.52 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1391716472365416		[learning rate: 0.0081254]
	Learning Rate: 0.00812543
	LOSS [training: 1.1391716472365416 | validation: 1.0534440910661955]
	TIME [epoch: 8.51 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7459252082410845		[learning rate: 0.0081063]
	Learning Rate: 0.00810626
	LOSS [training: 1.7459252082410845 | validation: 1.2837380507465443]
	TIME [epoch: 8.51 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1887955241657095		[learning rate: 0.0080871]
	Learning Rate: 0.00808714
	LOSS [training: 1.1887955241657095 | validation: 1.1739143427193262]
	TIME [epoch: 8.52 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1094684357455908		[learning rate: 0.0080681]
	Learning Rate: 0.00806806
	LOSS [training: 1.1094684357455908 | validation: 1.259947585815034]
	TIME [epoch: 8.53 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0467233833876275		[learning rate: 0.008049]
	Learning Rate: 0.00804903
	LOSS [training: 1.0467233833876275 | validation: 1.0790959170729366]
	TIME [epoch: 8.51 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1359343506702135		[learning rate: 0.00803]
	Learning Rate: 0.00803004
	LOSS [training: 1.1359343506702135 | validation: 1.03237678951196]
	TIME [epoch: 8.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.112134185263188		[learning rate: 0.0080111]
	Learning Rate: 0.0080111
	LOSS [training: 1.112134185263188 | validation: 0.8493117484429893]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7335776597521662		[learning rate: 0.0079922]
	Learning Rate: 0.00799221
	LOSS [training: 1.7335776597521662 | validation: 0.898299312626466]
	TIME [epoch: 8.52 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8410776284376492		[learning rate: 0.0079734]
	Learning Rate: 0.00797335
	LOSS [training: 0.8410776284376492 | validation: 0.7651267030099257]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9914460888144964		[learning rate: 0.0079545]
	Learning Rate: 0.00795455
	LOSS [training: 0.9914460888144964 | validation: 0.8521261803314762]
	TIME [epoch: 8.51 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.333631682537049		[learning rate: 0.0079358]
	Learning Rate: 0.00793578
	LOSS [training: 1.333631682537049 | validation: 0.9242462705595772]
	TIME [epoch: 8.55 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.044493499265253		[learning rate: 0.0079171]
	Learning Rate: 0.00791706
	LOSS [training: 1.044493499265253 | validation: 0.6908451233218287]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9279807926333443		[learning rate: 0.0078984]
	Learning Rate: 0.00789839
	LOSS [training: 0.9279807926333443 | validation: 0.9850686923360668]
	TIME [epoch: 8.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.262235764032786		[learning rate: 0.0078798]
	Learning Rate: 0.00787976
	LOSS [training: 1.262235764032786 | validation: 0.7589471879070244]
	TIME [epoch: 8.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9555995975064745		[learning rate: 0.0078612]
	Learning Rate: 0.00786117
	LOSS [training: 0.9555995975064745 | validation: 0.8153746172231189]
	TIME [epoch: 8.55 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8632215078858227		[learning rate: 0.0078426]
	Learning Rate: 0.00784263
	LOSS [training: 0.8632215078858227 | validation: 1.0042043143427273]
	TIME [epoch: 8.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.026263712699576		[learning rate: 0.0078241]
	Learning Rate: 0.00782413
	LOSS [training: 1.026263712699576 | validation: 0.7544729831210502]
	TIME [epoch: 8.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9859402364847447		[learning rate: 0.0078057]
	Learning Rate: 0.00780567
	LOSS [training: 0.9859402364847447 | validation: 0.6956572210816396]
	TIME [epoch: 8.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9592527138862913		[learning rate: 0.0077873]
	Learning Rate: 0.00778726
	LOSS [training: 0.9592527138862913 | validation: 0.9134911692632864]
	TIME [epoch: 8.54 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7601597625460653		[learning rate: 0.0077689]
	Learning Rate: 0.00776889
	LOSS [training: 0.7601597625460653 | validation: 0.7355490500863093]
	TIME [epoch: 8.51 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9104998826231462		[learning rate: 0.0077506]
	Learning Rate: 0.00775056
	LOSS [training: 0.9104998826231462 | validation: 0.5547460777058575]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0859902652769535		[learning rate: 0.0077323]
	Learning Rate: 0.00773228
	LOSS [training: 1.0859902652769535 | validation: 0.779473912518502]
	TIME [epoch: 8.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7729956807746934		[learning rate: 0.007714]
	Learning Rate: 0.00771404
	LOSS [training: 0.7729956807746934 | validation: 0.8485788479376117]
	TIME [epoch: 8.56 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.032861302050647		[learning rate: 0.0076958]
	Learning Rate: 0.00769585
	LOSS [training: 1.032861302050647 | validation: 0.6493175012713781]
	TIME [epoch: 8.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9495697681293755		[learning rate: 0.0076777]
	Learning Rate: 0.00767769
	LOSS [training: 0.9495697681293755 | validation: 0.8584178891852662]
	TIME [epoch: 8.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9234160264772937		[learning rate: 0.0076596]
	Learning Rate: 0.00765958
	LOSS [training: 0.9234160264772937 | validation: 0.8365707536586529]
	TIME [epoch: 8.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9575173938840076		[learning rate: 0.0076415]
	Learning Rate: 0.00764151
	LOSS [training: 0.9575173938840076 | validation: 1.094417143355507]
	TIME [epoch: 8.53 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8800634348986207		[learning rate: 0.0076235]
	Learning Rate: 0.00762349
	LOSS [training: 0.8800634348986207 | validation: 0.8604422303204621]
	TIME [epoch: 8.51 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9489983432312986		[learning rate: 0.0076055]
	Learning Rate: 0.00760551
	LOSS [training: 0.9489983432312986 | validation: 1.6940164393617203]
	TIME [epoch: 8.49 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0377660536277842		[learning rate: 0.0075876]
	Learning Rate: 0.00758757
	LOSS [training: 1.0377660536277842 | validation: 2.2872007800773293]
	TIME [epoch: 8.51 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1560234601913075		[learning rate: 0.0075697]
	Learning Rate: 0.00756967
	LOSS [training: 1.1560234601913075 | validation: 1.0535351390524663]
	TIME [epoch: 8.52 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0513476150537582		[learning rate: 0.0075518]
	Learning Rate: 0.00755181
	LOSS [training: 1.0513476150537582 | validation: 0.9918327212896809]
	TIME [epoch: 8.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.265940701360551		[learning rate: 0.007534]
	Learning Rate: 0.007534
	LOSS [training: 1.265940701360551 | validation: 0.8646765447085706]
	TIME [epoch: 8.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7892975985607658		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.7892975985607658 | validation: 1.1152045099603796]
	TIME [epoch: 8.52 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7876409426229418		[learning rate: 0.0074985]
	Learning Rate: 0.0074985
	LOSS [training: 0.7876409426229418 | validation: 1.1178021485157945]
	TIME [epoch: 8.52 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6937236819695285		[learning rate: 0.0074808]
	Learning Rate: 0.00748081
	LOSS [training: 0.6937236819695285 | validation: 0.5470915950994376]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7417754120313482		[learning rate: 0.0074632]
	Learning Rate: 0.00746317
	LOSS [training: 0.7417754120313482 | validation: 1.1787230692638264]
	TIME [epoch: 8.49 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8257983044122291		[learning rate: 0.0074456]
	Learning Rate: 0.00744556
	LOSS [training: 0.8257983044122291 | validation: 0.8139168257121308]
	TIME [epoch: 8.52 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0934595786948875		[learning rate: 0.007428]
	Learning Rate: 0.007428
	LOSS [training: 1.0934595786948875 | validation: 0.7337550801379211]
	TIME [epoch: 8.52 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2054573145659089		[learning rate: 0.0074105]
	Learning Rate: 0.00741048
	LOSS [training: 1.2054573145659089 | validation: 0.7537580101780466]
	TIME [epoch: 8.49 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7388992929052117		[learning rate: 0.007393]
	Learning Rate: 0.007393
	LOSS [training: 0.7388992929052117 | validation: 0.6202118809021483]
	TIME [epoch: 8.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3669001874236912		[learning rate: 0.0073756]
	Learning Rate: 0.00737556
	LOSS [training: 1.3669001874236912 | validation: 0.8401476558399594]
	TIME [epoch: 8.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8405244624671127		[learning rate: 0.0073582]
	Learning Rate: 0.00735816
	LOSS [training: 0.8405244624671127 | validation: 0.7317031772297407]
	TIME [epoch: 8.52 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0742645940192534		[learning rate: 0.0073408]
	Learning Rate: 0.0073408
	LOSS [training: 1.0742645940192534 | validation: 0.833027726769037]
	TIME [epoch: 8.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6987594670773494		[learning rate: 0.0073235]
	Learning Rate: 0.00732349
	LOSS [training: 0.6987594670773494 | validation: 0.5860290044562069]
	TIME [epoch: 8.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.897482553378928		[learning rate: 0.0073062]
	Learning Rate: 0.00730621
	LOSS [training: 0.897482553378928 | validation: 0.5047125750415508]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7060769130428856		[learning rate: 0.007289]
	Learning Rate: 0.00728898
	LOSS [training: 0.7060769130428856 | validation: 0.8052106694246771]
	TIME [epoch: 8.52 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8384885328812898		[learning rate: 0.0072718]
	Learning Rate: 0.00727178
	LOSS [training: 0.8384885328812898 | validation: 2.2638021318579704]
	TIME [epoch: 8.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.008869792802188		[learning rate: 0.0072546]
	Learning Rate: 0.00725463
	LOSS [training: 3.008869792802188 | validation: 1.286972699346077]
	TIME [epoch: 8.52 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3667377798099263		[learning rate: 0.0072375]
	Learning Rate: 0.00723752
	LOSS [training: 1.3667377798099263 | validation: 1.2121955872103358]
	TIME [epoch: 8.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8887968561353455		[learning rate: 0.0072204]
	Learning Rate: 0.00722045
	LOSS [training: 0.8887968561353455 | validation: 0.6401584837826262]
	TIME [epoch: 8.52 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7970957635900193		[learning rate: 0.0072034]
	Learning Rate: 0.00720342
	LOSS [training: 0.7970957635900193 | validation: 0.5567891423718196]
	TIME [epoch: 8.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5077701193283546		[learning rate: 0.0071864]
	Learning Rate: 0.00718642
	LOSS [training: 1.5077701193283546 | validation: 0.5299446264035859]
	TIME [epoch: 8.52 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7420384064692125		[learning rate: 0.0071695]
	Learning Rate: 0.00716947
	LOSS [training: 0.7420384064692125 | validation: 0.667263734361004]
	TIME [epoch: 8.49 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.773167690992976		[learning rate: 0.0071526]
	Learning Rate: 0.00715256
	LOSS [training: 0.773167690992976 | validation: 0.5586138626380738]
	TIME [epoch: 8.51 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6571612018790216		[learning rate: 0.0071357]
	Learning Rate: 0.00713569
	LOSS [training: 0.6571612018790216 | validation: 0.9433270324707577]
	TIME [epoch: 8.51 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7847268107148344		[learning rate: 0.0071189]
	Learning Rate: 0.00711886
	LOSS [training: 0.7847268107148344 | validation: 0.7434573234362227]
	TIME [epoch: 8.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6523116822810973		[learning rate: 0.0071021]
	Learning Rate: 0.00710206
	LOSS [training: 0.6523116822810973 | validation: 0.6532469843343255]
	TIME [epoch: 8.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.086147259187574		[learning rate: 0.0070853]
	Learning Rate: 0.00708531
	LOSS [training: 1.086147259187574 | validation: 1.4269865504090895]
	TIME [epoch: 8.52 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0787200531600258		[learning rate: 0.0070686]
	Learning Rate: 0.0070686
	LOSS [training: 1.0787200531600258 | validation: 1.1131144555205097]
	TIME [epoch: 8.52 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6908120563248192		[learning rate: 0.0070519]
	Learning Rate: 0.00705192
	LOSS [training: 0.6908120563248192 | validation: 0.7225299140368786]
	TIME [epoch: 8.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1957628821898334		[learning rate: 0.0070353]
	Learning Rate: 0.00703529
	LOSS [training: 1.1957628821898334 | validation: 0.5577637629943499]
	TIME [epoch: 8.49 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6405889526243824		[learning rate: 0.0070187]
	Learning Rate: 0.0070187
	LOSS [training: 0.6405889526243824 | validation: 0.6340394171898038]
	TIME [epoch: 8.52 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1251830008728496		[learning rate: 0.0070021]
	Learning Rate: 0.00700214
	LOSS [training: 1.1251830008728496 | validation: 1.3278369407878137]
	TIME [epoch: 8.52 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0376587241667308		[learning rate: 0.0069856]
	Learning Rate: 0.00698562
	LOSS [training: 1.0376587241667308 | validation: 1.3293743896515129]
	TIME [epoch: 8.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8071035791416398		[learning rate: 0.0069691]
	Learning Rate: 0.00696914
	LOSS [training: 0.8071035791416398 | validation: 0.9213459245563005]
	TIME [epoch: 8.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7966149871228712		[learning rate: 0.0069527]
	Learning Rate: 0.00695271
	LOSS [training: 0.7966149871228712 | validation: 0.5745718986722964]
	TIME [epoch: 8.52 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6957601685492684		[learning rate: 0.0069363]
	Learning Rate: 0.00693631
	LOSS [training: 0.6957601685492684 | validation: 1.539888368550192]
	TIME [epoch: 8.51 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8032333002631287		[learning rate: 0.0069199]
	Learning Rate: 0.00691994
	LOSS [training: 0.8032333002631287 | validation: 0.7855460707453983]
	TIME [epoch: 8.49 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7804434885747207		[learning rate: 0.0069036]
	Learning Rate: 0.00690362
	LOSS [training: 0.7804434885747207 | validation: 1.13980152172372]
	TIME [epoch: 8.49 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7117469807656149		[learning rate: 0.0068873]
	Learning Rate: 0.00688734
	LOSS [training: 0.7117469807656149 | validation: 0.6547640056801123]
	TIME [epoch: 8.52 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.873164276769602		[learning rate: 0.0068711]
	Learning Rate: 0.00687109
	LOSS [training: 0.873164276769602 | validation: 0.4855273628968315]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8524652056418931		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.8524652056418931 | validation: 0.5291416151648844]
	TIME [epoch: 8.49 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7050468596536053		[learning rate: 0.0068387]
	Learning Rate: 0.00683871
	LOSS [training: 0.7050468596536053 | validation: 0.8985522608940089]
	TIME [epoch: 8.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1305234497184955		[learning rate: 0.0068226]
	Learning Rate: 0.00682258
	LOSS [training: 1.1305234497184955 | validation: 1.0676326025728757]
	TIME [epoch: 8.52 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9316261505171541		[learning rate: 0.0068065]
	Learning Rate: 0.00680649
	LOSS [training: 0.9316261505171541 | validation: 1.1890429018245177]
	TIME [epoch: 8.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1151123432476342		[learning rate: 0.0067904]
	Learning Rate: 0.00679043
	LOSS [training: 1.1151123432476342 | validation: 2.209784512120182]
	TIME [epoch: 8.49 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7448527051303402		[learning rate: 0.0067744]
	Learning Rate: 0.00677441
	LOSS [training: 1.7448527051303402 | validation: 0.5203067209002469]
	TIME [epoch: 8.49 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.312132026397457		[learning rate: 0.0067584]
	Learning Rate: 0.00675843
	LOSS [training: 1.312132026397457 | validation: 0.8607707155653965]
	TIME [epoch: 8.53 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.807624564106565		[learning rate: 0.0067425]
	Learning Rate: 0.00674249
	LOSS [training: 0.807624564106565 | validation: 0.5318259006421096]
	TIME [epoch: 8.51 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9577154949644726		[learning rate: 0.0067266]
	Learning Rate: 0.00672659
	LOSS [training: 0.9577154949644726 | validation: 1.4450389778330974]
	TIME [epoch: 8.49 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7674908306473496		[learning rate: 0.0067107]
	Learning Rate: 0.00671072
	LOSS [training: 0.7674908306473496 | validation: 0.8635599196329318]
	TIME [epoch: 8.49 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7421127587103113		[learning rate: 0.0066949]
	Learning Rate: 0.00669489
	LOSS [training: 0.7421127587103113 | validation: 1.798393812619935]
	TIME [epoch: 8.54 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9563819976928482		[learning rate: 0.0066791]
	Learning Rate: 0.0066791
	LOSS [training: 0.9563819976928482 | validation: 1.0067289064993168]
	TIME [epoch: 8.5 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9432877044636723		[learning rate: 0.0066633]
	Learning Rate: 0.00666334
	LOSS [training: 0.9432877044636723 | validation: 0.8514808698916683]
	TIME [epoch: 8.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0004081640742593		[learning rate: 0.0066476]
	Learning Rate: 0.00664763
	LOSS [training: 2.0004081640742593 | validation: 1.735976057515812]
	TIME [epoch: 8.49 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9677785561166667		[learning rate: 0.0066319]
	Learning Rate: 0.00663195
	LOSS [training: 0.9677785561166667 | validation: 0.6005380837289518]
	TIME [epoch: 8.53 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5820034635621749		[learning rate: 0.0066163]
	Learning Rate: 0.0066163
	LOSS [training: 0.5820034635621749 | validation: 0.8465539717330057]
	TIME [epoch: 8.49 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8156496933074692		[learning rate: 0.0066007]
	Learning Rate: 0.0066007
	LOSS [training: 0.8156496933074692 | validation: 0.5386778860227468]
	TIME [epoch: 8.49 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.758129612504154		[learning rate: 0.0065851]
	Learning Rate: 0.00658513
	LOSS [training: 0.758129612504154 | validation: 0.7395763670428939]
	TIME [epoch: 8.51 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.372774821418201		[learning rate: 0.0065696]
	Learning Rate: 0.00656959
	LOSS [training: 1.372774821418201 | validation: 0.7245872134719562]
	TIME [epoch: 8.53 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6204026432435492		[learning rate: 0.0065541]
	Learning Rate: 0.0065541
	LOSS [training: 0.6204026432435492 | validation: 0.7617216768109045]
	TIME [epoch: 8.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8421532609251349		[learning rate: 0.0065386]
	Learning Rate: 0.00653864
	LOSS [training: 0.8421532609251349 | validation: 0.8428641987313624]
	TIME [epoch: 8.49 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.737679077968088		[learning rate: 0.0065232]
	Learning Rate: 0.00652321
	LOSS [training: 0.737679077968088 | validation: 2.3805278996336785]
	TIME [epoch: 8.52 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4772825228060598		[learning rate: 0.0065078]
	Learning Rate: 0.00650783
	LOSS [training: 1.4772825228060598 | validation: 1.1992385029262334]
	TIME [epoch: 8.53 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.015694261106902		[learning rate: 0.0064925]
	Learning Rate: 0.00649247
	LOSS [training: 1.015694261106902 | validation: 0.6071752102337592]
	TIME [epoch: 8.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9353616298557051		[learning rate: 0.0064772]
	Learning Rate: 0.00647716
	LOSS [training: 0.9353616298557051 | validation: 0.5986068108912572]
	TIME [epoch: 8.49 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6390076422326721		[learning rate: 0.0064619]
	Learning Rate: 0.00646188
	LOSS [training: 0.6390076422326721 | validation: 0.7039301457980911]
	TIME [epoch: 8.51 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6853672391830224		[learning rate: 0.0064466]
	Learning Rate: 0.00644664
	LOSS [training: 0.6853672391830224 | validation: 1.3665697204437115]
	TIME [epoch: 8.53 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9028154386434922		[learning rate: 0.0064314]
	Learning Rate: 0.00643143
	LOSS [training: 0.9028154386434922 | validation: 0.500916627255238]
	TIME [epoch: 8.49 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8300230197943724		[learning rate: 0.0064163]
	Learning Rate: 0.00641626
	LOSS [training: 0.8300230197943724 | validation: 2.1315566408520628]
	TIME [epoch: 8.49 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3936457339960324		[learning rate: 0.0064011]
	Learning Rate: 0.00640113
	LOSS [training: 1.3936457339960324 | validation: 0.8491839908475944]
	TIME [epoch: 8.52 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9643663566843479		[learning rate: 0.006386]
	Learning Rate: 0.00638603
	LOSS [training: 0.9643663566843479 | validation: 1.1361387467144775]
	TIME [epoch: 8.51 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9418685568756986		[learning rate: 0.006371]
	Learning Rate: 0.00637096
	LOSS [training: 0.9418685568756986 | validation: 0.685513504488695]
	TIME [epoch: 8.49 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7098574522017382		[learning rate: 0.0063559]
	Learning Rate: 0.00635594
	LOSS [training: 0.7098574522017382 | validation: 1.2651685042322196]
	TIME [epoch: 8.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9604332164887428		[learning rate: 0.0063409]
	Learning Rate: 0.00634094
	LOSS [training: 0.9604332164887428 | validation: 0.6981060451011855]
	TIME [epoch: 8.54 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6734695137719768		[learning rate: 0.006326]
	Learning Rate: 0.00632599
	LOSS [training: 0.6734695137719768 | validation: 0.8315707652279614]
	TIME [epoch: 8.51 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8291789261935231		[learning rate: 0.0063111]
	Learning Rate: 0.00631106
	LOSS [training: 0.8291789261935231 | validation: 0.42597057907066493]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8779365372393609		[learning rate: 0.0062962]
	Learning Rate: 0.00629618
	LOSS [training: 0.8779365372393609 | validation: 0.712262442753672]
	TIME [epoch: 8.49 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8774041322950001		[learning rate: 0.0062813]
	Learning Rate: 0.00628133
	LOSS [training: 0.8774041322950001 | validation: 1.1033498026571162]
	TIME [epoch: 8.53 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6256130190062225		[learning rate: 0.0062665]
	Learning Rate: 0.00626651
	LOSS [training: 0.6256130190062225 | validation: 0.6668339522975941]
	TIME [epoch: 8.49 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.80716678068601		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.80716678068601 | validation: 1.3600982470556895]
	TIME [epoch: 8.48 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9420839899062337		[learning rate: 0.006237]
	Learning Rate: 0.00623698
	LOSS [training: 0.9420839899062337 | validation: 0.8231036771916023]
	TIME [epoch: 8.49 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7154224699292693		[learning rate: 0.0062223]
	Learning Rate: 0.00622227
	LOSS [training: 0.7154224699292693 | validation: 1.0097331921298918]
	TIME [epoch: 8.52 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0064782461179147		[learning rate: 0.0062076]
	Learning Rate: 0.00620759
	LOSS [training: 1.0064782461179147 | validation: 0.5965182216107119]
	TIME [epoch: 8.49 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8625167603663652		[learning rate: 0.0061929]
	Learning Rate: 0.00619295
	LOSS [training: 0.8625167603663652 | validation: 0.74166224207339]
	TIME [epoch: 8.48 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5856327941414078		[learning rate: 0.0061783]
	Learning Rate: 0.00617834
	LOSS [training: 0.5856327941414078 | validation: 0.603926472995012]
	TIME [epoch: 8.49 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9395806781654988		[learning rate: 0.0061638]
	Learning Rate: 0.00616377
	LOSS [training: 0.9395806781654988 | validation: 1.4119326443472455]
	TIME [epoch: 8.53 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7523052668225841		[learning rate: 0.0061492]
	Learning Rate: 0.00614923
	LOSS [training: 0.7523052668225841 | validation: 0.967900523203394]
	TIME [epoch: 8.49 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8042699052195618		[learning rate: 0.0061347]
	Learning Rate: 0.00613472
	LOSS [training: 0.8042699052195618 | validation: 0.7526964069460578]
	TIME [epoch: 8.48 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9402926424429486		[learning rate: 0.0061203]
	Learning Rate: 0.00612025
	LOSS [training: 0.9402926424429486 | validation: 0.8368666546981199]
	TIME [epoch: 8.49 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0449184648688654		[learning rate: 0.0061058]
	Learning Rate: 0.00610581
	LOSS [training: 1.0449184648688654 | validation: 0.9319135355787713]
	TIME [epoch: 8.53 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8395885656512091		[learning rate: 0.0060914]
	Learning Rate: 0.00609141
	LOSS [training: 0.8395885656512091 | validation: 0.6015624357859]
	TIME [epoch: 8.49 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9660017940167511		[learning rate: 0.006077]
	Learning Rate: 0.00607704
	LOSS [training: 0.9660017940167511 | validation: 0.9785633976654184]
	TIME [epoch: 8.49 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9612547407809862		[learning rate: 0.0060627]
	Learning Rate: 0.00606271
	LOSS [training: 0.9612547407809862 | validation: 0.6304259217944156]
	TIME [epoch: 8.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8857972984945051		[learning rate: 0.0060484]
	Learning Rate: 0.00604841
	LOSS [training: 0.8857972984945051 | validation: 0.8288204069018963]
	TIME [epoch: 8.52 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8176336019758578		[learning rate: 0.0060341]
	Learning Rate: 0.00603414
	LOSS [training: 0.8176336019758578 | validation: 0.6819550292912288]
	TIME [epoch: 8.48 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6915714090267862		[learning rate: 0.0060199]
	Learning Rate: 0.00601991
	LOSS [training: 0.6915714090267862 | validation: 1.2019649550383904]
	TIME [epoch: 8.49 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9789242976009218		[learning rate: 0.0060057]
	Learning Rate: 0.00600571
	LOSS [training: 0.9789242976009218 | validation: 0.5597647876053662]
	TIME [epoch: 8.49 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6393207610681081		[learning rate: 0.0059915]
	Learning Rate: 0.00599154
	LOSS [training: 0.6393207610681081 | validation: 1.175006736487997]
	TIME [epoch: 8.52 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9566523351770913		[learning rate: 0.0059774]
	Learning Rate: 0.00597741
	LOSS [training: 0.9566523351770913 | validation: 0.5084894319054813]
	TIME [epoch: 8.48 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.617200891612233		[learning rate: 0.0059633]
	Learning Rate: 0.00596331
	LOSS [training: 0.617200891612233 | validation: 1.5605617874133308]
	TIME [epoch: 8.49 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1241562271623071		[learning rate: 0.0059492]
	Learning Rate: 0.00594924
	LOSS [training: 1.1241562271623071 | validation: 0.5662228992767788]
	TIME [epoch: 8.51 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5872371602400268		[learning rate: 0.0059352]
	Learning Rate: 0.00593521
	LOSS [training: 0.5872371602400268 | validation: 0.7790359679045409]
	TIME [epoch: 8.51 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7883055177355007		[learning rate: 0.0059212]
	Learning Rate: 0.00592121
	LOSS [training: 0.7883055177355007 | validation: 1.5154734509943584]
	TIME [epoch: 8.49 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9403583809196576		[learning rate: 0.0059072]
	Learning Rate: 0.00590724
	LOSS [training: 0.9403583809196576 | validation: 0.7074017074536986]
	TIME [epoch: 8.49 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.767746876708325		[learning rate: 0.0058933]
	Learning Rate: 0.00589331
	LOSS [training: 0.767746876708325 | validation: 0.814026186936814]
	TIME [epoch: 8.51 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0141601048753457		[learning rate: 0.0058794]
	Learning Rate: 0.0058794
	LOSS [training: 1.0141601048753457 | validation: 0.8457733676074879]
	TIME [epoch: 8.51 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6778126770041526		[learning rate: 0.0058655]
	Learning Rate: 0.00586554
	LOSS [training: 0.6778126770041526 | validation: 2.3685641737776493]
	TIME [epoch: 8.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7493146203140557		[learning rate: 0.0058517]
	Learning Rate: 0.0058517
	LOSS [training: 1.7493146203140557 | validation: 0.6812142206128038]
	TIME [epoch: 8.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6964163010407438		[learning rate: 0.0058379]
	Learning Rate: 0.0058379
	LOSS [training: 0.6964163010407438 | validation: 0.5986326020436582]
	TIME [epoch: 8.52 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9362726268457123		[learning rate: 0.0058241]
	Learning Rate: 0.00582413
	LOSS [training: 0.9362726268457123 | validation: 1.1675088803590419]
	TIME [epoch: 8.52 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8320009698953881		[learning rate: 0.0058104]
	Learning Rate: 0.00581039
	LOSS [training: 0.8320009698953881 | validation: 0.7741329478075845]
	TIME [epoch: 8.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8197839205771329		[learning rate: 0.0057967]
	Learning Rate: 0.00579668
	LOSS [training: 0.8197839205771329 | validation: 0.7483217250469774]
	TIME [epoch: 8.49 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7095224442189982		[learning rate: 0.005783]
	Learning Rate: 0.00578301
	LOSS [training: 0.7095224442189982 | validation: 0.4512097321553601]
	TIME [epoch: 8.53 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6362595243793666		[learning rate: 0.0057694]
	Learning Rate: 0.00576937
	LOSS [training: 0.6362595243793666 | validation: 0.501784050349369]
	TIME [epoch: 8.51 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1804461145798941		[learning rate: 0.0057558]
	Learning Rate: 0.00575576
	LOSS [training: 1.1804461145798941 | validation: 1.0455594253049942]
	TIME [epoch: 8.49 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7403821986835945		[learning rate: 0.0057422]
	Learning Rate: 0.00574218
	LOSS [training: 0.7403821986835945 | validation: 0.8579245737099699]
	TIME [epoch: 8.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.789502942144275		[learning rate: 0.0057286]
	Learning Rate: 0.00572864
	LOSS [training: 0.789502942144275 | validation: 0.8915111231431199]
	TIME [epoch: 8.52 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8098427374588164		[learning rate: 0.0057151]
	Learning Rate: 0.00571512
	LOSS [training: 0.8098427374588164 | validation: 0.5187539524355993]
	TIME [epoch: 8.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6619552585335005		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.6619552585335005 | validation: 0.8954043348492862]
	TIME [epoch: 8.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8101541018883307		[learning rate: 0.0056882]
	Learning Rate: 0.00568819
	LOSS [training: 0.8101541018883307 | validation: 0.5588914717009141]
	TIME [epoch: 8.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8418705655079373		[learning rate: 0.0056748]
	Learning Rate: 0.00567478
	LOSS [training: 0.8418705655079373 | validation: 0.4542940727076371]
	TIME [epoch: 8.54 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46256352112125104		[learning rate: 0.0056614]
	Learning Rate: 0.00566139
	LOSS [training: 0.46256352112125104 | validation: 0.46696442081950096]
	TIME [epoch: 8.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8573527714513618		[learning rate: 0.005648]
	Learning Rate: 0.00564804
	LOSS [training: 0.8573527714513618 | validation: 0.8634910110392551]
	TIME [epoch: 8.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6990681973612957		[learning rate: 0.0056347]
	Learning Rate: 0.00563471
	LOSS [training: 0.6990681973612957 | validation: 0.4984213634920913]
	TIME [epoch: 8.52 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7646902042475124		[learning rate: 0.0056214]
	Learning Rate: 0.00562142
	LOSS [training: 0.7646902042475124 | validation: 0.7195992559344502]
	TIME [epoch: 8.51 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6593877244353139		[learning rate: 0.0056082]
	Learning Rate: 0.00560816
	LOSS [training: 0.6593877244353139 | validation: 0.7989332445970323]
	TIME [epoch: 8.49 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9299081081602777		[learning rate: 0.0055949]
	Learning Rate: 0.00559493
	LOSS [training: 0.9299081081602777 | validation: 0.6667477314048644]
	TIME [epoch: 8.49 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.664020742048377		[learning rate: 0.0055817]
	Learning Rate: 0.00558173
	LOSS [training: 0.664020742048377 | validation: 1.1564171068163591]
	TIME [epoch: 8.51 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7236019161855842		[learning rate: 0.0055686]
	Learning Rate: 0.00556857
	LOSS [training: 0.7236019161855842 | validation: 0.5764730346400222]
	TIME [epoch: 8.51 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5334992742717227		[learning rate: 0.0055554]
	Learning Rate: 0.00555543
	LOSS [training: 0.5334992742717227 | validation: 0.541726863350271]
	TIME [epoch: 8.48 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7546465500746721		[learning rate: 0.0055423]
	Learning Rate: 0.00554233
	LOSS [training: 0.7546465500746721 | validation: 0.34924438102645017]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_300.pth
	Model improved!!!
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.819405593714877		[learning rate: 0.0055293]
	Learning Rate: 0.00552926
	LOSS [training: 0.819405593714877 | validation: 0.33659840381257994]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.808818100691656		[learning rate: 0.0055162]
	Learning Rate: 0.00551621
	LOSS [training: 0.808818100691656 | validation: 0.5122529079447256]
	TIME [epoch: 8.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5785844761129917		[learning rate: 0.0055032]
	Learning Rate: 0.0055032
	LOSS [training: 0.5785844761129917 | validation: 0.7985922004148783]
	TIME [epoch: 8.47 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8515737756626491		[learning rate: 0.0054902]
	Learning Rate: 0.00549022
	LOSS [training: 0.8515737756626491 | validation: 1.399157286940987]
	TIME [epoch: 8.49 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4062065258047558		[learning rate: 0.0054773]
	Learning Rate: 0.00547727
	LOSS [training: 1.4062065258047558 | validation: 0.4528878063182156]
	TIME [epoch: 8.48 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6514529867800419		[learning rate: 0.0054643]
	Learning Rate: 0.00546435
	LOSS [training: 0.6514529867800419 | validation: 0.6194820783580353]
	TIME [epoch: 8.5 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6956743682607677		[learning rate: 0.0054515]
	Learning Rate: 0.00545146
	LOSS [training: 0.6956743682607677 | validation: 0.7811534679671127]
	TIME [epoch: 8.47 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6499732369337993		[learning rate: 0.0054386]
	Learning Rate: 0.0054386
	LOSS [training: 0.6499732369337993 | validation: 0.5720270257143556]
	TIME [epoch: 8.49 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.802826968708894		[learning rate: 0.0054258]
	Learning Rate: 0.00542577
	LOSS [training: 0.802826968708894 | validation: 0.47913449587969836]
	TIME [epoch: 8.48 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8491056367108213		[learning rate: 0.005413]
	Learning Rate: 0.00541297
	LOSS [training: 0.8491056367108213 | validation: 1.2023341313604456]
	TIME [epoch: 8.51 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7623955734189691		[learning rate: 0.0054002]
	Learning Rate: 0.00540021
	LOSS [training: 0.7623955734189691 | validation: 1.126587746157486]
	TIME [epoch: 8.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9638124138545775		[learning rate: 0.0053875]
	Learning Rate: 0.00538747
	LOSS [training: 0.9638124138545775 | validation: 0.5839009854922288]
	TIME [epoch: 8.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.824430141927393		[learning rate: 0.0053748]
	Learning Rate: 0.00537476
	LOSS [training: 0.824430141927393 | validation: 1.1964662235033612]
	TIME [epoch: 8.49 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7885681323302836		[learning rate: 0.0053621]
	Learning Rate: 0.00536208
	LOSS [training: 0.7885681323302836 | validation: 0.442408989398839]
	TIME [epoch: 8.52 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.932498869565457		[learning rate: 0.0053494]
	Learning Rate: 0.00534943
	LOSS [training: 0.932498869565457 | validation: 0.5433193632034383]
	TIME [epoch: 8.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7253780067279789		[learning rate: 0.0053368]
	Learning Rate: 0.00533681
	LOSS [training: 0.7253780067279789 | validation: 0.6015927373265464]
	TIME [epoch: 8.51 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7714876286959262		[learning rate: 0.0053242]
	Learning Rate: 0.00532423
	LOSS [training: 0.7714876286959262 | validation: 0.46412601392888153]
	TIME [epoch: 8.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8670512921655347		[learning rate: 0.0053117]
	Learning Rate: 0.00531167
	LOSS [training: 0.8670512921655347 | validation: 0.39583665812473556]
	TIME [epoch: 8.51 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49942378214647853		[learning rate: 0.0052991]
	Learning Rate: 0.00529914
	LOSS [training: 0.49942378214647853 | validation: 0.42942227140614425]
	TIME [epoch: 8.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6567505466948462		[learning rate: 0.0052866]
	Learning Rate: 0.00528664
	LOSS [training: 0.6567505466948462 | validation: 0.8308663413156536]
	TIME [epoch: 8.49 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8561913984384727		[learning rate: 0.0052742]
	Learning Rate: 0.00527417
	LOSS [training: 0.8561913984384727 | validation: 1.150448120247786]
	TIME [epoch: 8.49 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7239352393181228		[learning rate: 0.0052617]
	Learning Rate: 0.00526173
	LOSS [training: 0.7239352393181228 | validation: 0.6419732398156133]
	TIME [epoch: 8.51 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6459734774149978		[learning rate: 0.0052493]
	Learning Rate: 0.00524931
	LOSS [training: 0.6459734774149978 | validation: 0.44293658539687597]
	TIME [epoch: 8.51 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7793937785014365		[learning rate: 0.0052369]
	Learning Rate: 0.00523693
	LOSS [training: 0.7793937785014365 | validation: 0.7413338769510613]
	TIME [epoch: 8.49 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8073111345005479		[learning rate: 0.0052246]
	Learning Rate: 0.00522458
	LOSS [training: 0.8073111345005479 | validation: 0.7680475051031894]
	TIME [epoch: 8.49 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7923670644312588		[learning rate: 0.0052123]
	Learning Rate: 0.00521225
	LOSS [training: 0.7923670644312588 | validation: 0.5260679886959829]
	TIME [epoch: 8.51 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0406774079402459		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 1.0406774079402459 | validation: 1.7766936880321715]
	TIME [epoch: 8.51 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9540944905431873		[learning rate: 0.0051877]
	Learning Rate: 0.00518769
	LOSS [training: 0.9540944905431873 | validation: 0.8274497641892433]
	TIME [epoch: 8.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9675388306496077		[learning rate: 0.0051755]
	Learning Rate: 0.00517546
	LOSS [training: 0.9675388306496077 | validation: 1.33098031839303]
	TIME [epoch: 8.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8373133306151136		[learning rate: 0.0051632]
	Learning Rate: 0.00516325
	LOSS [training: 0.8373133306151136 | validation: 0.5211758591957143]
	TIME [epoch: 8.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8855695808040871		[learning rate: 0.0051511]
	Learning Rate: 0.00515107
	LOSS [training: 0.8855695808040871 | validation: 0.588595857345938]
	TIME [epoch: 8.51 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7611157977801197		[learning rate: 0.0051389]
	Learning Rate: 0.00513892
	LOSS [training: 0.7611157977801197 | validation: 0.3945379645420637]
	TIME [epoch: 8.48 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7125968596074091		[learning rate: 0.0051268]
	Learning Rate: 0.0051268
	LOSS [training: 0.7125968596074091 | validation: 1.0132384492282323]
	TIME [epoch: 8.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9058218654519411		[learning rate: 0.0051147]
	Learning Rate: 0.0051147
	LOSS [training: 0.9058218654519411 | validation: 0.6812212528507562]
	TIME [epoch: 8.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8624331377348179		[learning rate: 0.0051026]
	Learning Rate: 0.00510264
	LOSS [training: 0.8624331377348179 | validation: 0.6681359093307405]
	TIME [epoch: 8.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5406899105883142		[learning rate: 0.0050906]
	Learning Rate: 0.0050906
	LOSS [training: 0.5406899105883142 | validation: 0.6328228423989637]
	TIME [epoch: 8.49 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5882904425632258		[learning rate: 0.0050786]
	Learning Rate: 0.00507859
	LOSS [training: 0.5882904425632258 | validation: 0.5263174205746148]
	TIME [epoch: 8.51 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5531920383208105		[learning rate: 0.0050666]
	Learning Rate: 0.00506661
	LOSS [training: 0.5531920383208105 | validation: 0.7151714346557174]
	TIME [epoch: 8.51 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8094809890287766		[learning rate: 0.0050547]
	Learning Rate: 0.00505466
	LOSS [training: 0.8094809890287766 | validation: 0.7261225266132103]
	TIME [epoch: 8.51 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6653132149373391		[learning rate: 0.0050427]
	Learning Rate: 0.00504274
	LOSS [training: 0.6653132149373391 | validation: 1.0373426206157927]
	TIME [epoch: 8.49 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8939503531943844		[learning rate: 0.0050308]
	Learning Rate: 0.00503085
	LOSS [training: 0.8939503531943844 | validation: 0.636790186994636]
	TIME [epoch: 8.52 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7085517679898474		[learning rate: 0.005019]
	Learning Rate: 0.00501898
	LOSS [training: 0.7085517679898474 | validation: 0.7020401855759109]
	TIME [epoch: 8.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.80379756682138		[learning rate: 0.0050071]
	Learning Rate: 0.00500714
	LOSS [training: 0.80379756682138 | validation: 0.5771218124007286]
	TIME [epoch: 8.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6999175499262488		[learning rate: 0.0049953]
	Learning Rate: 0.00499533
	LOSS [training: 0.6999175499262488 | validation: 0.4314842994610103]
	TIME [epoch: 8.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1064161690045342		[learning rate: 0.0049835]
	Learning Rate: 0.00498355
	LOSS [training: 1.1064161690045342 | validation: 1.5722390273506544]
	TIME [epoch: 8.52 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8164702452417935		[learning rate: 0.0049718]
	Learning Rate: 0.00497179
	LOSS [training: 0.8164702452417935 | validation: 0.7858073108498647]
	TIME [epoch: 8.51 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9073046523859682		[learning rate: 0.0049601]
	Learning Rate: 0.00496006
	LOSS [training: 0.9073046523859682 | validation: 0.6943127249268476]
	TIME [epoch: 8.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7404216905566263		[learning rate: 0.0049484]
	Learning Rate: 0.00494836
	LOSS [training: 0.7404216905566263 | validation: 0.9652712386163307]
	TIME [epoch: 8.49 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6286329724882174		[learning rate: 0.0049367]
	Learning Rate: 0.00493669
	LOSS [training: 0.6286329724882174 | validation: 0.5283251387876182]
	TIME [epoch: 8.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.606054436279073		[learning rate: 0.004925]
	Learning Rate: 0.00492505
	LOSS [training: 0.606054436279073 | validation: 0.9335691330241]
	TIME [epoch: 8.51 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6051885382649151		[learning rate: 0.0049134]
	Learning Rate: 0.00491343
	LOSS [training: 0.6051885382649151 | validation: 0.8872858067686284]
	TIME [epoch: 8.49 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6023196115869242		[learning rate: 0.0049018]
	Learning Rate: 0.00490184
	LOSS [training: 0.6023196115869242 | validation: 0.5581624553431457]
	TIME [epoch: 8.49 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6541461782882715		[learning rate: 0.0048903]
	Learning Rate: 0.00489028
	LOSS [training: 0.6541461782882715 | validation: 0.7102777177368689]
	TIME [epoch: 8.52 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7311201186471903		[learning rate: 0.0048787]
	Learning Rate: 0.00487874
	LOSS [training: 0.7311201186471903 | validation: 0.6055497950701598]
	TIME [epoch: 8.51 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8395569126880723		[learning rate: 0.0048672]
	Learning Rate: 0.00486723
	LOSS [training: 0.8395569126880723 | validation: 1.0280541422193017]
	TIME [epoch: 8.49 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6192814464079843		[learning rate: 0.0048558]
	Learning Rate: 0.00485575
	LOSS [training: 0.6192814464079843 | validation: 0.4878698641947555]
	TIME [epoch: 8.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7768123024471425		[learning rate: 0.0048443]
	Learning Rate: 0.0048443
	LOSS [training: 0.7768123024471425 | validation: 1.14475128440882]
	TIME [epoch: 8.53 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8130614642829836		[learning rate: 0.0048329]
	Learning Rate: 0.00483287
	LOSS [training: 0.8130614642829836 | validation: 0.8571460633047661]
	TIME [epoch: 8.49 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7451649644934315		[learning rate: 0.0048215]
	Learning Rate: 0.00482147
	LOSS [training: 0.7451649644934315 | validation: 0.7225859522549996]
	TIME [epoch: 8.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8683966261045157		[learning rate: 0.0048101]
	Learning Rate: 0.0048101
	LOSS [training: 0.8683966261045157 | validation: 0.6926544029854682]
	TIME [epoch: 8.48 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5944412883999588		[learning rate: 0.0047988]
	Learning Rate: 0.00479875
	LOSS [training: 0.5944412883999588 | validation: 0.6648276630037298]
	TIME [epoch: 8.52 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.613353516626318		[learning rate: 0.0047874]
	Learning Rate: 0.00478743
	LOSS [training: 0.613353516626318 | validation: 0.4465484433063547]
	TIME [epoch: 8.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0013799499439517		[learning rate: 0.0047761]
	Learning Rate: 0.00477614
	LOSS [training: 1.0013799499439517 | validation: 0.7037925299973584]
	TIME [epoch: 8.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6812200962967979		[learning rate: 0.0047649]
	Learning Rate: 0.00476487
	LOSS [training: 0.6812200962967979 | validation: 1.109055470863695]
	TIME [epoch: 8.49 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8081818023205087		[learning rate: 0.0047536]
	Learning Rate: 0.00475363
	LOSS [training: 0.8081818023205087 | validation: 0.5180498570634979]
	TIME [epoch: 8.53 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7152350619946917		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.7152350619946917 | validation: 0.5737174381687321]
	TIME [epoch: 8.49 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6104246067923388		[learning rate: 0.0047312]
	Learning Rate: 0.00473123
	LOSS [training: 0.6104246067923388 | validation: 0.516650479038657]
	TIME [epoch: 8.49 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6098937407379503		[learning rate: 0.0047201]
	Learning Rate: 0.00472007
	LOSS [training: 0.6098937407379503 | validation: 0.6343376775716386]
	TIME [epoch: 8.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6563061563890933		[learning rate: 0.0047089]
	Learning Rate: 0.00470894
	LOSS [training: 0.6563061563890933 | validation: 0.8754663825758425]
	TIME [epoch: 8.52 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3710305923704493		[learning rate: 0.0046978]
	Learning Rate: 0.00469783
	LOSS [training: 1.3710305923704493 | validation: 6.478658136954811]
	TIME [epoch: 8.49 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.20897963241237		[learning rate: 0.0046868]
	Learning Rate: 0.00468675
	LOSS [training: 2.20897963241237 | validation: 0.9459769331997482]
	TIME [epoch: 8.48 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0126126430145557		[learning rate: 0.0046757]
	Learning Rate: 0.00467569
	LOSS [training: 1.0126126430145557 | validation: 1.285477448584515]
	TIME [epoch: 8.51 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8065214498521065		[learning rate: 0.0046647]
	Learning Rate: 0.00466467
	LOSS [training: 0.8065214498521065 | validation: 0.5403504795874724]
	TIME [epoch: 8.52 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5175297388898643		[learning rate: 0.0046537]
	Learning Rate: 0.00465366
	LOSS [training: 0.5175297388898643 | validation: 0.42482503182515746]
	TIME [epoch: 8.49 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5283778635029932		[learning rate: 0.0046427]
	Learning Rate: 0.00464268
	LOSS [training: 0.5283778635029932 | validation: 0.4769664106909076]
	TIME [epoch: 8.49 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8288332422388682		[learning rate: 0.0046317]
	Learning Rate: 0.00463173
	LOSS [training: 0.8288332422388682 | validation: 0.9025280915763676]
	TIME [epoch: 8.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9381201106206152		[learning rate: 0.0046208]
	Learning Rate: 0.00462081
	LOSS [training: 0.9381201106206152 | validation: 0.6653633026775806]
	TIME [epoch: 8.51 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6640771030972933		[learning rate: 0.0046099]
	Learning Rate: 0.00460991
	LOSS [training: 0.6640771030972933 | validation: 0.6816719852721295]
	TIME [epoch: 8.49 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6179332846963761		[learning rate: 0.004599]
	Learning Rate: 0.00459903
	LOSS [training: 0.6179332846963761 | validation: 1.0587910142856742]
	TIME [epoch: 8.48 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.115051394190113		[learning rate: 0.0045882]
	Learning Rate: 0.00458819
	LOSS [training: 1.115051394190113 | validation: 1.1494928759656877]
	TIME [epoch: 8.51 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6892881690528292		[learning rate: 0.0045774]
	Learning Rate: 0.00457736
	LOSS [training: 0.6892881690528292 | validation: 0.7481104258372011]
	TIME [epoch: 8.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5551554504465082		[learning rate: 0.0045666]
	Learning Rate: 0.00456657
	LOSS [training: 0.5551554504465082 | validation: 0.5101783820430369]
	TIME [epoch: 8.49 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6313287105582837		[learning rate: 0.0045558]
	Learning Rate: 0.00455579
	LOSS [training: 0.6313287105582837 | validation: 0.42280060436687866]
	TIME [epoch: 8.48 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7610205317188085		[learning rate: 0.004545]
	Learning Rate: 0.00454505
	LOSS [training: 0.7610205317188085 | validation: 0.7229561103917218]
	TIME [epoch: 8.52 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7021094516060173		[learning rate: 0.0045343]
	Learning Rate: 0.00453433
	LOSS [training: 0.7021094516060173 | validation: 0.5456218973314758]
	TIME [epoch: 8.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6849396635220548		[learning rate: 0.0045236]
	Learning Rate: 0.00452363
	LOSS [training: 0.6849396635220548 | validation: 0.6136550571128709]
	TIME [epoch: 8.49 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6496908269297748		[learning rate: 0.004513]
	Learning Rate: 0.00451296
	LOSS [training: 0.6496908269297748 | validation: 0.7186982986590496]
	TIME [epoch: 8.48 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.868072880219969		[learning rate: 0.0045023]
	Learning Rate: 0.00450232
	LOSS [training: 0.868072880219969 | validation: 1.2202982613561577]
	TIME [epoch: 8.52 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8261073353420743		[learning rate: 0.0044917]
	Learning Rate: 0.00449169
	LOSS [training: 0.8261073353420743 | validation: 0.6337237834251996]
	TIME [epoch: 8.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7170065364187026		[learning rate: 0.0044811]
	Learning Rate: 0.0044811
	LOSS [training: 0.7170065364187026 | validation: 0.7121276219686905]
	TIME [epoch: 8.48 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5070367032056875		[learning rate: 0.0044705]
	Learning Rate: 0.00447053
	LOSS [training: 0.5070367032056875 | validation: 0.718041353707079]
	TIME [epoch: 8.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7303485925914327		[learning rate: 0.00446]
	Learning Rate: 0.00445998
	LOSS [training: 0.7303485925914327 | validation: 0.5344882801129234]
	TIME [epoch: 8.52 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5787758120582933		[learning rate: 0.0044495]
	Learning Rate: 0.00444946
	LOSS [training: 0.5787758120582933 | validation: 0.4756269620419422]
	TIME [epoch: 8.49 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.069663565146881		[learning rate: 0.004439]
	Learning Rate: 0.00443897
	LOSS [training: 1.069663565146881 | validation: 0.8654235030028341]
	TIME [epoch: 8.49 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6238805671140926		[learning rate: 0.0044285]
	Learning Rate: 0.0044285
	LOSS [training: 0.6238805671140926 | validation: 0.7161392299153211]
	TIME [epoch: 8.49 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6972729023430262		[learning rate: 0.0044181]
	Learning Rate: 0.00441805
	LOSS [training: 0.6972729023430262 | validation: 0.6616420070712686]
	TIME [epoch: 8.53 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.550447382139678		[learning rate: 0.0044076]
	Learning Rate: 0.00440763
	LOSS [training: 0.550447382139678 | validation: 0.5404038374548269]
	TIME [epoch: 8.48 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4921803059753137		[learning rate: 0.0043972]
	Learning Rate: 0.00439723
	LOSS [training: 0.4921803059753137 | validation: 0.46543395389807807]
	TIME [epoch: 8.48 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7419542435153426		[learning rate: 0.0043869]
	Learning Rate: 0.00438686
	LOSS [training: 0.7419542435153426 | validation: 0.8127308490252187]
	TIME [epoch: 8.48 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6527431438911445		[learning rate: 0.0043765]
	Learning Rate: 0.00437651
	LOSS [training: 0.6527431438911445 | validation: 0.42803706505774486]
	TIME [epoch: 8.54 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6115363545144864		[learning rate: 0.0043662]
	Learning Rate: 0.00436619
	LOSS [training: 0.6115363545144864 | validation: 0.5408532769264631]
	TIME [epoch: 8.49 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7074002773973402		[learning rate: 0.0043559]
	Learning Rate: 0.00435589
	LOSS [training: 0.7074002773973402 | validation: 0.964107456478997]
	TIME [epoch: 8.48 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7791516574863927		[learning rate: 0.0043456]
	Learning Rate: 0.00434561
	LOSS [training: 0.7791516574863927 | validation: 0.5482294352049253]
	TIME [epoch: 8.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8603813217830425		[learning rate: 0.0043354]
	Learning Rate: 0.00433536
	LOSS [training: 0.8603813217830425 | validation: 0.5364559362279597]
	TIME [epoch: 8.52 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8196487228492243		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.8196487228492243 | validation: 0.5902032231676194]
	TIME [epoch: 8.48 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6123030251097555		[learning rate: 0.0043149]
	Learning Rate: 0.00431494
	LOSS [training: 0.6123030251097555 | validation: 0.5147594378996769]
	TIME [epoch: 8.49 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5902597632501021		[learning rate: 0.0043048]
	Learning Rate: 0.00430476
	LOSS [training: 0.5902597632501021 | validation: 0.5952903256204477]
	TIME [epoch: 8.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6254170715717231		[learning rate: 0.0042946]
	Learning Rate: 0.0042946
	LOSS [training: 0.6254170715717231 | validation: 0.6773622322804033]
	TIME [epoch: 8.51 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.575976472946301		[learning rate: 0.0042845]
	Learning Rate: 0.00428447
	LOSS [training: 0.575976472946301 | validation: 0.5328667428007643]
	TIME [epoch: 8.48 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6496391036093293		[learning rate: 0.0042744]
	Learning Rate: 0.00427437
	LOSS [training: 0.6496391036093293 | validation: 0.8554756780198176]
	TIME [epoch: 8.48 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6924099980847676		[learning rate: 0.0042643]
	Learning Rate: 0.00426428
	LOSS [training: 0.6924099980847676 | validation: 0.3757025492761642]
	TIME [epoch: 8.51 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.833829283293019		[learning rate: 0.0042542]
	Learning Rate: 0.00425423
	LOSS [training: 0.833829283293019 | validation: 0.47683820636723107]
	TIME [epoch: 8.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5361831740488232		[learning rate: 0.0042442]
	Learning Rate: 0.00424419
	LOSS [training: 0.5361831740488232 | validation: 0.42504395524268623]
	TIME [epoch: 8.48 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.580904721779999		[learning rate: 0.0042342]
	Learning Rate: 0.00423418
	LOSS [training: 0.580904721779999 | validation: 0.5556271670240718]
	TIME [epoch: 8.49 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0960201790074398		[learning rate: 0.0042242]
	Learning Rate: 0.00422419
	LOSS [training: 1.0960201790074398 | validation: 0.6546429115928916]
	TIME [epoch: 8.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8057820038140076		[learning rate: 0.0042142]
	Learning Rate: 0.00421423
	LOSS [training: 0.8057820038140076 | validation: 0.7334867697491927]
	TIME [epoch: 8.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0147411237920392		[learning rate: 0.0042043]
	Learning Rate: 0.00420429
	LOSS [training: 1.0147411237920392 | validation: 0.6810520723327389]
	TIME [epoch: 8.47 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8472059923512093		[learning rate: 0.0041944]
	Learning Rate: 0.00419437
	LOSS [training: 0.8472059923512093 | validation: 0.7219168939582085]
	TIME [epoch: 8.48 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.62038643270503		[learning rate: 0.0041845]
	Learning Rate: 0.00418448
	LOSS [training: 0.62038643270503 | validation: 0.5307229476920825]
	TIME [epoch: 8.52 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.535764647418925		[learning rate: 0.0041746]
	Learning Rate: 0.0041746
	LOSS [training: 0.535764647418925 | validation: 0.41904520507025894]
	TIME [epoch: 8.48 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5319906981958297		[learning rate: 0.0041648]
	Learning Rate: 0.00416476
	LOSS [training: 0.5319906981958297 | validation: 0.4076403092236582]
	TIME [epoch: 8.48 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7908074233424267		[learning rate: 0.0041549]
	Learning Rate: 0.00415493
	LOSS [training: 0.7908074233424267 | validation: 0.872653503840755]
	TIME [epoch: 8.49 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7722417812306637		[learning rate: 0.0041451]
	Learning Rate: 0.00414513
	LOSS [training: 0.7722417812306637 | validation: 0.682101337165457]
	TIME [epoch: 8.51 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7893660915225961		[learning rate: 0.0041354]
	Learning Rate: 0.00413535
	LOSS [training: 0.7893660915225961 | validation: 1.3092516234489755]
	TIME [epoch: 8.48 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0036086187851103		[learning rate: 0.0041256]
	Learning Rate: 0.0041256
	LOSS [training: 1.0036086187851103 | validation: 0.6549804944047031]
	TIME [epoch: 8.47 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7575473649522398		[learning rate: 0.0041159]
	Learning Rate: 0.00411587
	LOSS [training: 0.7575473649522398 | validation: 0.9762965095356848]
	TIME [epoch: 8.49 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.836982462079159		[learning rate: 0.0041062]
	Learning Rate: 0.00410616
	LOSS [training: 0.836982462079159 | validation: 0.555614402194401]
	TIME [epoch: 8.51 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7709167836375037		[learning rate: 0.0040965]
	Learning Rate: 0.00409647
	LOSS [training: 0.7709167836375037 | validation: 0.6566780915389459]
	TIME [epoch: 8.49 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8287395126117465		[learning rate: 0.0040868]
	Learning Rate: 0.00408681
	LOSS [training: 0.8287395126117465 | validation: 0.6443938797601069]
	TIME [epoch: 8.47 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7460355179103806		[learning rate: 0.0040772]
	Learning Rate: 0.00407717
	LOSS [training: 0.7460355179103806 | validation: 0.8209612020947981]
	TIME [epoch: 8.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7032793531139893		[learning rate: 0.0040676]
	Learning Rate: 0.00406755
	LOSS [training: 0.7032793531139893 | validation: 0.5926074409091373]
	TIME [epoch: 8.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5569748975755131		[learning rate: 0.004058]
	Learning Rate: 0.00405796
	LOSS [training: 0.5569748975755131 | validation: 0.4417175447407628]
	TIME [epoch: 8.48 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.550540771352283		[learning rate: 0.0040484]
	Learning Rate: 0.00404839
	LOSS [training: 0.550540771352283 | validation: 0.5554369658157692]
	TIME [epoch: 8.47 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5661168071593059		[learning rate: 0.0040388]
	Learning Rate: 0.00403884
	LOSS [training: 0.5661168071593059 | validation: 1.080802962392116]
	TIME [epoch: 8.48 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6983904626263209		[learning rate: 0.0040293]
	Learning Rate: 0.00402931
	LOSS [training: 0.6983904626263209 | validation: 0.6138477626006944]
	TIME [epoch: 8.49 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5391174774378118		[learning rate: 0.0040198]
	Learning Rate: 0.00401981
	LOSS [training: 0.5391174774378118 | validation: 0.5233662462663234]
	TIME [epoch: 8.47 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8835092760486484		[learning rate: 0.0040103]
	Learning Rate: 0.00401032
	LOSS [training: 0.8835092760486484 | validation: 0.6256925284829189]
	TIME [epoch: 8.47 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7023107225154821		[learning rate: 0.0040009]
	Learning Rate: 0.00400086
	LOSS [training: 0.7023107225154821 | validation: 0.7002082412291479]
	TIME [epoch: 8.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6185708797468861		[learning rate: 0.0039914]
	Learning Rate: 0.00399143
	LOSS [training: 0.6185708797468861 | validation: 0.5961350019138834]
	TIME [epoch: 8.49 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5995365998217712		[learning rate: 0.003982]
	Learning Rate: 0.00398201
	LOSS [training: 0.5995365998217712 | validation: 0.5617043537222428]
	TIME [epoch: 8.48 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7194360202029232		[learning rate: 0.0039726]
	Learning Rate: 0.00397262
	LOSS [training: 0.7194360202029232 | validation: 0.9294372120829291]
	TIME [epoch: 8.49 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5372789088195902		[learning rate: 0.0039632]
	Learning Rate: 0.00396325
	LOSS [training: 0.5372789088195902 | validation: 0.5707065059387559]
	TIME [epoch: 8.49 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6364711185198468		[learning rate: 0.0039539]
	Learning Rate: 0.0039539
	LOSS [training: 0.6364711185198468 | validation: 0.5373472273946504]
	TIME [epoch: 8.49 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5296092912048677		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.5296092912048677 | validation: 0.4889031352489576]
	TIME [epoch: 8.47 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6767546017634719		[learning rate: 0.0039353]
	Learning Rate: 0.00393527
	LOSS [training: 0.6767546017634719 | validation: 0.5196975214234]
	TIME [epoch: 8.48 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46838982987196404		[learning rate: 0.003926]
	Learning Rate: 0.00392599
	LOSS [training: 0.46838982987196404 | validation: 0.6497051161911547]
	TIME [epoch: 8.49 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5660449393114422		[learning rate: 0.0039167]
	Learning Rate: 0.00391672
	LOSS [training: 0.5660449393114422 | validation: 0.9665523270283533]
	TIME [epoch: 8.49 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6223006149178089		[learning rate: 0.0039075]
	Learning Rate: 0.00390749
	LOSS [training: 0.6223006149178089 | validation: 0.4959129068537626]
	TIME [epoch: 8.47 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.782219568650141		[learning rate: 0.0038983]
	Learning Rate: 0.00389827
	LOSS [training: 0.782219568650141 | validation: 0.690835454393491]
	TIME [epoch: 8.49 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6879259099137642		[learning rate: 0.0038891]
	Learning Rate: 0.00388907
	LOSS [training: 0.6879259099137642 | validation: 0.5436793772086499]
	TIME [epoch: 8.48 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4525199985720458		[learning rate: 0.0038799]
	Learning Rate: 0.0038799
	LOSS [training: 0.4525199985720458 | validation: 0.7684664914637751]
	TIME [epoch: 8.49 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7914067883098823		[learning rate: 0.0038707]
	Learning Rate: 0.00387075
	LOSS [training: 0.7914067883098823 | validation: 0.8286491836937124]
	TIME [epoch: 8.47 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5692739090405604		[learning rate: 0.0038616]
	Learning Rate: 0.00386162
	LOSS [training: 0.5692739090405604 | validation: 0.8149509667700532]
	TIME [epoch: 8.49 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9572103703015271		[learning rate: 0.0038525]
	Learning Rate: 0.00385251
	LOSS [training: 0.9572103703015271 | validation: 0.8818719771941119]
	TIME [epoch: 8.49 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6692065745983127		[learning rate: 0.0038434]
	Learning Rate: 0.00384342
	LOSS [training: 0.6692065745983127 | validation: 0.43676552819409226]
	TIME [epoch: 8.49 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5064828450083281		[learning rate: 0.0038344]
	Learning Rate: 0.00383435
	LOSS [training: 0.5064828450083281 | validation: 0.5679168351507469]
	TIME [epoch: 8.47 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6084092615221481		[learning rate: 0.0038253]
	Learning Rate: 0.00382531
	LOSS [training: 0.6084092615221481 | validation: 0.9765932072221408]
	TIME [epoch: 8.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.696133254208533		[learning rate: 0.0038163]
	Learning Rate: 0.00381629
	LOSS [training: 0.696133254208533 | validation: 0.4855546286356351]
	TIME [epoch: 8.49 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.531482666885825		[learning rate: 0.0038073]
	Learning Rate: 0.00380728
	LOSS [training: 0.531482666885825 | validation: 1.039852366502409]
	TIME [epoch: 8.48 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6382134712826357		[learning rate: 0.0037983]
	Learning Rate: 0.0037983
	LOSS [training: 0.6382134712826357 | validation: 0.40257461449259924]
	TIME [epoch: 8.49 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8668371215170708		[learning rate: 0.0037893]
	Learning Rate: 0.00378934
	LOSS [training: 0.8668371215170708 | validation: 0.7800823913455921]
	TIME [epoch: 8.48 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8503480409748025		[learning rate: 0.0037804]
	Learning Rate: 0.00378041
	LOSS [training: 0.8503480409748025 | validation: 1.1286261855447102]
	TIME [epoch: 8.5 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7436702056378213		[learning rate: 0.0037715]
	Learning Rate: 0.00377149
	LOSS [training: 0.7436702056378213 | validation: 0.6132443873223785]
	TIME [epoch: 8.48 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6068383166754474		[learning rate: 0.0037626]
	Learning Rate: 0.00376259
	LOSS [training: 0.6068383166754474 | validation: 0.4912512315152124]
	TIME [epoch: 8.49 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6327345570230504		[learning rate: 0.0037537]
	Learning Rate: 0.00375372
	LOSS [training: 0.6327345570230504 | validation: 0.5106503620419443]
	TIME [epoch: 8.49 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5672850386516536		[learning rate: 0.0037449]
	Learning Rate: 0.00374486
	LOSS [training: 0.5672850386516536 | validation: 0.42937580959664967]
	TIME [epoch: 8.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49057447602454946		[learning rate: 0.003736]
	Learning Rate: 0.00373603
	LOSS [training: 0.49057447602454946 | validation: 0.6011604890844227]
	TIME [epoch: 8.48 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8114225563551317		[learning rate: 0.0037272]
	Learning Rate: 0.00372722
	LOSS [training: 0.8114225563551317 | validation: 0.5595265154804057]
	TIME [epoch: 8.49 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6445103984040134		[learning rate: 0.0037184]
	Learning Rate: 0.00371842
	LOSS [training: 0.6445103984040134 | validation: 0.46696522339242386]
	TIME [epoch: 8.47 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6258652171690082		[learning rate: 0.0037097]
	Learning Rate: 0.00370965
	LOSS [training: 0.6258652171690082 | validation: 0.34430166597235473]
	TIME [epoch: 8.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5652138510312182		[learning rate: 0.0037009]
	Learning Rate: 0.0037009
	LOSS [training: 0.5652138510312182 | validation: 0.4518057203370128]
	TIME [epoch: 8.48 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5185923788341347		[learning rate: 0.0036922]
	Learning Rate: 0.00369217
	LOSS [training: 0.5185923788341347 | validation: 0.7189463790585777]
	TIME [epoch: 8.49 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6168962689010703		[learning rate: 0.0036835]
	Learning Rate: 0.00368346
	LOSS [training: 0.6168962689010703 | validation: 0.4601928028224017]
	TIME [epoch: 8.48 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6226910354035956		[learning rate: 0.0036748]
	Learning Rate: 0.00367478
	LOSS [training: 0.6226910354035956 | validation: 0.8777940975886629]
	TIME [epoch: 8.49 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.631145954760967		[learning rate: 0.0036661]
	Learning Rate: 0.00366611
	LOSS [training: 0.631145954760967 | validation: 0.7674325386554348]
	TIME [epoch: 8.48 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4907949587715287		[learning rate: 0.0036575]
	Learning Rate: 0.00365746
	LOSS [training: 0.4907949587715287 | validation: 0.4301098297027671]
	TIME [epoch: 8.49 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5503210793246408		[learning rate: 0.0036488]
	Learning Rate: 0.00364883
	LOSS [training: 0.5503210793246408 | validation: 0.4219896931260897]
	TIME [epoch: 8.47 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46273719668376784		[learning rate: 0.0036402]
	Learning Rate: 0.00364022
	LOSS [training: 0.46273719668376784 | validation: 0.4545209119775338]
	TIME [epoch: 8.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9221960405006252		[learning rate: 0.0036316]
	Learning Rate: 0.00363164
	LOSS [training: 0.9221960405006252 | validation: 0.4554592257481081]
	TIME [epoch: 8.48 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5448045841955617		[learning rate: 0.0036231]
	Learning Rate: 0.00362307
	LOSS [training: 0.5448045841955617 | validation: 0.3620602710935368]
	TIME [epoch: 8.48 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7076244573566648		[learning rate: 0.0036145]
	Learning Rate: 0.00361453
	LOSS [training: 0.7076244573566648 | validation: 0.697877659919989]
	TIME [epoch: 8.47 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5659500295261994		[learning rate: 0.003606]
	Learning Rate: 0.003606
	LOSS [training: 0.5659500295261994 | validation: 0.4932191894817137]
	TIME [epoch: 8.49 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4889768116593885		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.4889768116593885 | validation: 0.47863438139228653]
	TIME [epoch: 8.49 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8165682166539767		[learning rate: 0.003589]
	Learning Rate: 0.00358901
	LOSS [training: 0.8165682166539767 | validation: 0.8522195885651799]
	TIME [epoch: 8.48 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8452981995847072		[learning rate: 0.0035805]
	Learning Rate: 0.00358054
	LOSS [training: 0.8452981995847072 | validation: 0.4248232097158571]
	TIME [epoch: 8.47 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5632713794596507		[learning rate: 0.0035721]
	Learning Rate: 0.0035721
	LOSS [training: 0.5632713794596507 | validation: 0.369747731560988]
	TIME [epoch: 8.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47415759498360427		[learning rate: 0.0035637]
	Learning Rate: 0.00356367
	LOSS [training: 0.47415759498360427 | validation: 0.8761028846448491]
	TIME [epoch: 8.48 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5824767163564237		[learning rate: 0.0035553]
	Learning Rate: 0.00355526
	LOSS [training: 0.5824767163564237 | validation: 0.521957039841398]
	TIME [epoch: 8.48 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45763951624483246		[learning rate: 0.0035469]
	Learning Rate: 0.00354688
	LOSS [training: 0.45763951624483246 | validation: 0.5011374875858615]
	TIME [epoch: 8.48 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5350496489813108		[learning rate: 0.0035385]
	Learning Rate: 0.00353851
	LOSS [training: 0.5350496489813108 | validation: 0.4180294096744273]
	TIME [epoch: 8.49 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5175363075597452		[learning rate: 0.0035302]
	Learning Rate: 0.00353016
	LOSS [training: 0.5175363075597452 | validation: 0.3833094662264559]
	TIME [epoch: 8.48 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5812366372163685		[learning rate: 0.0035218]
	Learning Rate: 0.00352184
	LOSS [training: 0.5812366372163685 | validation: 0.38682885180025295]
	TIME [epoch: 8.48 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4080569955533699		[learning rate: 0.0035135]
	Learning Rate: 0.00351353
	LOSS [training: 0.4080569955533699 | validation: 0.37619482996292164]
	TIME [epoch: 8.48 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5532910521980068		[learning rate: 0.0035052]
	Learning Rate: 0.00350524
	LOSS [training: 0.5532910521980068 | validation: 0.7156176398994106]
	TIME [epoch: 8.49 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5552397484961848		[learning rate: 0.003497]
	Learning Rate: 0.00349697
	LOSS [training: 0.5552397484961848 | validation: 0.3586483052520708]
	TIME [epoch: 8.49 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9021269969893668		[learning rate: 0.0034887]
	Learning Rate: 0.00348872
	LOSS [training: 0.9021269969893668 | validation: 1.16431801523337]
	TIME [epoch: 8.47 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6314593092053794		[learning rate: 0.0034805]
	Learning Rate: 0.00348049
	LOSS [training: 0.6314593092053794 | validation: 0.30102589618512543]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_497.pth
	Model improved!!!
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6171162505867209		[learning rate: 0.0034723]
	Learning Rate: 0.00347228
	LOSS [training: 0.6171162505867209 | validation: 2.0470222469941506]
	TIME [epoch: 8.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9761287391769213		[learning rate: 0.0034641]
	Learning Rate: 0.00346409
	LOSS [training: 0.9761287391769213 | validation: 0.5861939749041847]
	TIME [epoch: 8.48 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6726572304031777		[learning rate: 0.0034559]
	Learning Rate: 0.00345592
	LOSS [training: 0.6726572304031777 | validation: 0.630913764671863]
	TIME [epoch: 8.47 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5875137212695891		[learning rate: 0.0034478]
	Learning Rate: 0.00344777
	LOSS [training: 0.5875137212695891 | validation: 0.5734042438222172]
	TIME [epoch: 8.47 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6019550738493303		[learning rate: 0.0034396]
	Learning Rate: 0.00343964
	LOSS [training: 0.6019550738493303 | validation: 0.49316312757543224]
	TIME [epoch: 8.51 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5393694067934358		[learning rate: 0.0034315]
	Learning Rate: 0.00343152
	LOSS [training: 0.5393694067934358 | validation: 0.4653149102985281]
	TIME [epoch: 8.47 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4891513123672655		[learning rate: 0.0034234]
	Learning Rate: 0.00342343
	LOSS [training: 0.4891513123672655 | validation: 0.6067159972812131]
	TIME [epoch: 8.47 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5921735958510983		[learning rate: 0.0034154]
	Learning Rate: 0.00341535
	LOSS [training: 0.5921735958510983 | validation: 0.7424582415188459]
	TIME [epoch: 8.48 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6050755125802112		[learning rate: 0.0034073]
	Learning Rate: 0.0034073
	LOSS [training: 0.6050755125802112 | validation: 0.6029249589274681]
	TIME [epoch: 8.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5197535316714158		[learning rate: 0.0033993]
	Learning Rate: 0.00339926
	LOSS [training: 0.5197535316714158 | validation: 0.604280237444853]
	TIME [epoch: 8.47 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7028584955634936		[learning rate: 0.0033912]
	Learning Rate: 0.00339124
	LOSS [training: 0.7028584955634936 | validation: 0.5716691616829741]
	TIME [epoch: 8.47 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4347817299285898		[learning rate: 0.0033832]
	Learning Rate: 0.00338324
	LOSS [training: 0.4347817299285898 | validation: 0.5628560461492593]
	TIME [epoch: 8.49 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6186124519892766		[learning rate: 0.0033753]
	Learning Rate: 0.00337526
	LOSS [training: 0.6186124519892766 | validation: 0.364332919488433]
	TIME [epoch: 8.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5127465011599711		[learning rate: 0.0033673]
	Learning Rate: 0.0033673
	LOSS [training: 0.5127465011599711 | validation: 1.4582890832618243]
	TIME [epoch: 8.47 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.06070841772604		[learning rate: 0.0033594]
	Learning Rate: 0.00335936
	LOSS [training: 1.06070841772604 | validation: 0.7008204597375647]
	TIME [epoch: 8.47 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5832564666948246		[learning rate: 0.0033514]
	Learning Rate: 0.00335143
	LOSS [training: 0.5832564666948246 | validation: 0.43547830905746354]
	TIME [epoch: 8.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5289615400788736		[learning rate: 0.0033435]
	Learning Rate: 0.00334353
	LOSS [training: 0.5289615400788736 | validation: 0.5917260102725803]
	TIME [epoch: 8.49 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5192584653352009		[learning rate: 0.0033356]
	Learning Rate: 0.00333564
	LOSS [training: 0.5192584653352009 | validation: 0.5379803090657098]
	TIME [epoch: 8.47 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5032477933516647		[learning rate: 0.0033278]
	Learning Rate: 0.00332777
	LOSS [training: 0.5032477933516647 | validation: 0.5953372174263656]
	TIME [epoch: 8.47 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7525294495990706		[learning rate: 0.0033199]
	Learning Rate: 0.00331992
	LOSS [training: 0.7525294495990706 | validation: 0.4650386228831612]
	TIME [epoch: 8.51 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8001873080785378		[learning rate: 0.0033121]
	Learning Rate: 0.00331209
	LOSS [training: 0.8001873080785378 | validation: 0.5480633159858073]
	TIME [epoch: 8.48 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6043140526299295		[learning rate: 0.0033043]
	Learning Rate: 0.00330428
	LOSS [training: 0.6043140526299295 | validation: 0.5730716199716788]
	TIME [epoch: 8.47 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4823299830245791		[learning rate: 0.0032965]
	Learning Rate: 0.00329649
	LOSS [training: 0.4823299830245791 | validation: 0.689500970122741]
	TIME [epoch: 8.45 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7967845773404234		[learning rate: 0.0032887]
	Learning Rate: 0.00328871
	LOSS [training: 0.7967845773404234 | validation: 0.7207080235298473]
	TIME [epoch: 8.51 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5223742482464682		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.5223742482464682 | validation: 0.5887437849148098]
	TIME [epoch: 8.48 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5212282035010255		[learning rate: 0.0032732]
	Learning Rate: 0.00327321
	LOSS [training: 0.5212282035010255 | validation: 0.4909111641164558]
	TIME [epoch: 8.46 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49798554399471007		[learning rate: 0.0032655]
	Learning Rate: 0.00326549
	LOSS [training: 0.49798554399471007 | validation: 0.9066487573099054]
	TIME [epoch: 8.46 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5450337612362863		[learning rate: 0.0032578]
	Learning Rate: 0.00325779
	LOSS [training: 0.5450337612362863 | validation: 0.41137494162166227]
	TIME [epoch: 8.51 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45454698067034344		[learning rate: 0.0032501]
	Learning Rate: 0.00325011
	LOSS [training: 0.45454698067034344 | validation: 0.4846679648234409]
	TIME [epoch: 8.46 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6252550785895109		[learning rate: 0.0032424]
	Learning Rate: 0.00324244
	LOSS [training: 0.6252550785895109 | validation: 0.9337903269433607]
	TIME [epoch: 8.46 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6433346202608716		[learning rate: 0.0032348]
	Learning Rate: 0.00323479
	LOSS [training: 0.6433346202608716 | validation: 0.6138759180391797]
	TIME [epoch: 8.46 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6622870842129936		[learning rate: 0.0032272]
	Learning Rate: 0.00322716
	LOSS [training: 0.6622870842129936 | validation: 0.6097050950511588]
	TIME [epoch: 8.49 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5268641399374648		[learning rate: 0.0032195]
	Learning Rate: 0.00321955
	LOSS [training: 0.5268641399374648 | validation: 0.4308206833253886]
	TIME [epoch: 8.47 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4881739002230175		[learning rate: 0.003212]
	Learning Rate: 0.00321195
	LOSS [training: 0.4881739002230175 | validation: 0.544423673733101]
	TIME [epoch: 8.47 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5568537258908727		[learning rate: 0.0032044]
	Learning Rate: 0.00320438
	LOSS [training: 0.5568537258908727 | validation: 0.4109987584590678]
	TIME [epoch: 8.46 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4969802133329983		[learning rate: 0.0031968]
	Learning Rate: 0.00319682
	LOSS [training: 0.4969802133329983 | validation: 0.6355334256462233]
	TIME [epoch: 8.48 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6738716109990989		[learning rate: 0.0031893]
	Learning Rate: 0.00318928
	LOSS [training: 0.6738716109990989 | validation: 0.5349443163825072]
	TIME [epoch: 8.47 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5103047312222493		[learning rate: 0.0031818]
	Learning Rate: 0.00318175
	LOSS [training: 0.5103047312222493 | validation: 0.4524150757692072]
	TIME [epoch: 8.49 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7027549044243087		[learning rate: 0.0031742]
	Learning Rate: 0.00317425
	LOSS [training: 0.7027549044243087 | validation: 1.2272381359566336]
	TIME [epoch: 8.47 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7276153539305451		[learning rate: 0.0031668]
	Learning Rate: 0.00316676
	LOSS [training: 0.7276153539305451 | validation: 0.5581235117181691]
	TIME [epoch: 8.49 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6252860279226643		[learning rate: 0.0031593]
	Learning Rate: 0.00315929
	LOSS [training: 0.6252860279226643 | validation: 0.7929082072900435]
	TIME [epoch: 8.48 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4940658519196412		[learning rate: 0.0031518]
	Learning Rate: 0.00315184
	LOSS [training: 0.4940658519196412 | validation: 0.5083634813625677]
	TIME [epoch: 8.48 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47088712687427875		[learning rate: 0.0031444]
	Learning Rate: 0.0031444
	LOSS [training: 0.47088712687427875 | validation: 0.5068320378507265]
	TIME [epoch: 8.47 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6216530100812436		[learning rate: 0.003137]
	Learning Rate: 0.00313699
	LOSS [training: 0.6216530100812436 | validation: 1.055395490181661]
	TIME [epoch: 8.49 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4969094223953351		[learning rate: 0.0031296]
	Learning Rate: 0.00312959
	LOSS [training: 0.4969094223953351 | validation: 0.5091460240850173]
	TIME [epoch: 8.48 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43083713919524935		[learning rate: 0.0031222]
	Learning Rate: 0.00312221
	LOSS [training: 0.43083713919524935 | validation: 0.4377363692355908]
	TIME [epoch: 8.47 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4708092525204788		[learning rate: 0.0031148]
	Learning Rate: 0.00311484
	LOSS [training: 0.4708092525204788 | validation: 0.49538908985757046]
	TIME [epoch: 8.46 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48877030074104877		[learning rate: 0.0031075]
	Learning Rate: 0.00310749
	LOSS [training: 0.48877030074104877 | validation: 0.45428905783517204]
	TIME [epoch: 8.48 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5174941602486135		[learning rate: 0.0031002]
	Learning Rate: 0.00310016
	LOSS [training: 0.5174941602486135 | validation: 0.39549719724619725]
	TIME [epoch: 8.49 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45985861563878283		[learning rate: 0.0030929]
	Learning Rate: 0.00309285
	LOSS [training: 0.45985861563878283 | validation: 0.533099310666092]
	TIME [epoch: 8.46 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8476546771848661		[learning rate: 0.0030856]
	Learning Rate: 0.00308556
	LOSS [training: 0.8476546771848661 | validation: 0.7465536816594842]
	TIME [epoch: 8.48 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5198692560579576		[learning rate: 0.0030783]
	Learning Rate: 0.00307828
	LOSS [training: 0.5198692560579576 | validation: 0.8596877066731068]
	TIME [epoch: 8.48 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47216032713616124		[learning rate: 0.003071]
	Learning Rate: 0.00307102
	LOSS [training: 0.47216032713616124 | validation: 0.4285046590852094]
	TIME [epoch: 8.49 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46486148458972226		[learning rate: 0.0030638]
	Learning Rate: 0.00306377
	LOSS [training: 0.46486148458972226 | validation: 0.6174380698688329]
	TIME [epoch: 8.47 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5962501829252005		[learning rate: 0.0030565]
	Learning Rate: 0.00305654
	LOSS [training: 0.5962501829252005 | validation: 0.5276477606577931]
	TIME [epoch: 8.48 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5353391662711627		[learning rate: 0.0030493]
	Learning Rate: 0.00304933
	LOSS [training: 0.5353391662711627 | validation: 0.7035049137207309]
	TIME [epoch: 8.48 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5249991669330265		[learning rate: 0.0030421]
	Learning Rate: 0.00304214
	LOSS [training: 0.5249991669330265 | validation: 0.4857390818003008]
	TIME [epoch: 8.48 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5849270820972452		[learning rate: 0.003035]
	Learning Rate: 0.00303497
	LOSS [training: 0.5849270820972452 | validation: 0.7306587383598152]
	TIME [epoch: 8.46 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.646221777892855		[learning rate: 0.0030278]
	Learning Rate: 0.00302781
	LOSS [training: 0.646221777892855 | validation: 0.4873202579359015]
	TIME [epoch: 8.48 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6434547397007251		[learning rate: 0.0030207]
	Learning Rate: 0.00302066
	LOSS [training: 0.6434547397007251 | validation: 0.6489675444874301]
	TIME [epoch: 8.49 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5868267975509733		[learning rate: 0.0030135]
	Learning Rate: 0.00301354
	LOSS [training: 0.5868267975509733 | validation: 0.6436850722064287]
	TIME [epoch: 8.47 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6253961928598415		[learning rate: 0.0030064]
	Learning Rate: 0.00300643
	LOSS [training: 0.6253961928598415 | validation: 0.5303846814651803]
	TIME [epoch: 8.47 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5703842624371612		[learning rate: 0.0029993]
	Learning Rate: 0.00299934
	LOSS [training: 0.5703842624371612 | validation: 0.6270783434404834]
	TIME [epoch: 8.48 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8922565621312121		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.8922565621312121 | validation: 0.5947871108421979]
	TIME [epoch: 8.48 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5614097078434541		[learning rate: 0.0029852]
	Learning Rate: 0.00298521
	LOSS [training: 0.5614097078434541 | validation: 0.5377262381687915]
	TIME [epoch: 8.48 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.529927337116438		[learning rate: 0.0029782]
	Learning Rate: 0.00297816
	LOSS [training: 0.529927337116438 | validation: 0.43245157059545225]
	TIME [epoch: 8.47 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39489583828123964		[learning rate: 0.0029711]
	Learning Rate: 0.00297114
	LOSS [training: 0.39489583828123964 | validation: 0.4380722239794186]
	TIME [epoch: 8.48 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5862608475366189		[learning rate: 0.0029641]
	Learning Rate: 0.00296413
	LOSS [training: 0.5862608475366189 | validation: 1.0088306024055744]
	TIME [epoch: 8.49 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6255162966355748		[learning rate: 0.0029571]
	Learning Rate: 0.00295714
	LOSS [training: 0.6255162966355748 | validation: 0.6144352512786433]
	TIME [epoch: 8.47 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46056562115381955		[learning rate: 0.0029502]
	Learning Rate: 0.00295016
	LOSS [training: 0.46056562115381955 | validation: 0.44096914548944066]
	TIME [epoch: 8.47 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43455311190587487		[learning rate: 0.0029432]
	Learning Rate: 0.0029432
	LOSS [training: 0.43455311190587487 | validation: 0.756887698430333]
	TIME [epoch: 8.49 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.527717234520356		[learning rate: 0.0029363]
	Learning Rate: 0.00293626
	LOSS [training: 0.527717234520356 | validation: 0.45215838287510324]
	TIME [epoch: 8.49 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5830246519845066		[learning rate: 0.0029293]
	Learning Rate: 0.00292934
	LOSS [training: 0.5830246519845066 | validation: 0.6477460128828955]
	TIME [epoch: 8.47 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5500355647049501		[learning rate: 0.0029224]
	Learning Rate: 0.00292243
	LOSS [training: 0.5500355647049501 | validation: 0.37772980251478283]
	TIME [epoch: 8.46 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4972080973077867		[learning rate: 0.0029155]
	Learning Rate: 0.00291553
	LOSS [training: 0.4972080973077867 | validation: 0.40799370918532374]
	TIME [epoch: 8.48 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5098890575276002		[learning rate: 0.0029087]
	Learning Rate: 0.00290866
	LOSS [training: 0.5098890575276002 | validation: 0.4671037203240837]
	TIME [epoch: 8.49 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6295123109628145		[learning rate: 0.0029018]
	Learning Rate: 0.00290179
	LOSS [training: 0.6295123109628145 | validation: 0.6436501101750614]
	TIME [epoch: 8.47 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5953704799495684		[learning rate: 0.0028949]
	Learning Rate: 0.00289495
	LOSS [training: 0.5953704799495684 | validation: 0.6862648905221036]
	TIME [epoch: 8.47 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3979480116594975		[learning rate: 0.0028881]
	Learning Rate: 0.00288812
	LOSS [training: 0.3979480116594975 | validation: 0.39009556021594805]
	TIME [epoch: 8.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41426405797827187		[learning rate: 0.0028813]
	Learning Rate: 0.00288131
	LOSS [training: 0.41426405797827187 | validation: 0.3864789875499183]
	TIME [epoch: 8.48 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43874471292959144		[learning rate: 0.0028745]
	Learning Rate: 0.00287451
	LOSS [training: 0.43874471292959144 | validation: 0.6978679411069952]
	TIME [epoch: 8.47 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47375415740473964		[learning rate: 0.0028677]
	Learning Rate: 0.00286773
	LOSS [training: 0.47375415740473964 | validation: 0.4818799323776083]
	TIME [epoch: 8.47 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5289122176095796		[learning rate: 0.002861]
	Learning Rate: 0.00286097
	LOSS [training: 0.5289122176095796 | validation: 0.4536878185241251]
	TIME [epoch: 8.51 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42173113025995457		[learning rate: 0.0028542]
	Learning Rate: 0.00285422
	LOSS [training: 0.42173113025995457 | validation: 0.5840095029288357]
	TIME [epoch: 8.47 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6148632102238212		[learning rate: 0.0028475]
	Learning Rate: 0.00284749
	LOSS [training: 0.6148632102238212 | validation: 0.5940622972432829]
	TIME [epoch: 8.47 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4833563675304727		[learning rate: 0.0028408]
	Learning Rate: 0.00284077
	LOSS [training: 0.4833563675304727 | validation: 0.6089383654972764]
	TIME [epoch: 8.46 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45878632599033053		[learning rate: 0.0028341]
	Learning Rate: 0.00283407
	LOSS [training: 0.45878632599033053 | validation: 0.45907885466463955]
	TIME [epoch: 8.51 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5986842349923069		[learning rate: 0.0028274]
	Learning Rate: 0.00282738
	LOSS [training: 0.5986842349923069 | validation: 0.5522986196358252]
	TIME [epoch: 8.47 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40659292842836275		[learning rate: 0.0028207]
	Learning Rate: 0.00282071
	LOSS [training: 0.40659292842836275 | validation: 0.36590108937627697]
	TIME [epoch: 8.46 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4834003602787032		[learning rate: 0.0028141]
	Learning Rate: 0.00281406
	LOSS [training: 0.4834003602787032 | validation: 0.43545079335120596]
	TIME [epoch: 8.46 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3905423657886717		[learning rate: 0.0028074]
	Learning Rate: 0.00280742
	LOSS [training: 0.3905423657886717 | validation: 0.3804765480550897]
	TIME [epoch: 8.51 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5243895826415029		[learning rate: 0.0028008]
	Learning Rate: 0.0028008
	LOSS [training: 0.5243895826415029 | validation: 0.33163951775398537]
	TIME [epoch: 8.47 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4328236149280439		[learning rate: 0.0027942]
	Learning Rate: 0.00279419
	LOSS [training: 0.4328236149280439 | validation: 0.5366665217281611]
	TIME [epoch: 8.47 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5601477124469378		[learning rate: 0.0027876]
	Learning Rate: 0.0027876
	LOSS [training: 0.5601477124469378 | validation: 0.5593120042491293]
	TIME [epoch: 8.48 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.469519199395575		[learning rate: 0.002781]
	Learning Rate: 0.00278103
	LOSS [training: 0.469519199395575 | validation: 0.5418681609107425]
	TIME [epoch: 8.49 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5089896088566164		[learning rate: 0.0027745]
	Learning Rate: 0.00277447
	LOSS [training: 0.5089896088566164 | validation: 0.5466557633796002]
	TIME [epoch: 8.47 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42558184674623245		[learning rate: 0.0027679]
	Learning Rate: 0.00276792
	LOSS [training: 0.42558184674623245 | validation: 0.355227983169959]
	TIME [epoch: 8.48 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.735206593589756		[learning rate: 0.0027614]
	Learning Rate: 0.00276139
	LOSS [training: 0.735206593589756 | validation: 0.4562409630121047]
	TIME [epoch: 8.49 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5378935213755554		[learning rate: 0.0027549]
	Learning Rate: 0.00275488
	LOSS [training: 0.5378935213755554 | validation: 0.4597582255835849]
	TIME [epoch: 8.49 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40057920191723434		[learning rate: 0.0027484]
	Learning Rate: 0.00274838
	LOSS [training: 0.40057920191723434 | validation: 0.3182318387656322]
	TIME [epoch: 8.48 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3604340494988017		[learning rate: 0.0027419]
	Learning Rate: 0.0027419
	LOSS [training: 0.3604340494988017 | validation: 0.4441013672331298]
	TIME [epoch: 8.47 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47281664005185614		[learning rate: 0.0027354]
	Learning Rate: 0.00273543
	LOSS [training: 0.47281664005185614 | validation: 0.6757986202187463]
	TIME [epoch: 8.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.502684570610542		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.502684570610542 | validation: 0.5965341263056139]
	TIME [epoch: 8.48 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5218390839542388		[learning rate: 0.0027225]
	Learning Rate: 0.00272254
	LOSS [training: 0.5218390839542388 | validation: 0.42737498736552115]
	TIME [epoch: 8.46 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48534326993292154		[learning rate: 0.0027161]
	Learning Rate: 0.00271612
	LOSS [training: 0.48534326993292154 | validation: 0.5244433969250271]
	TIME [epoch: 8.47 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6575625262083611		[learning rate: 0.0027097]
	Learning Rate: 0.00270971
	LOSS [training: 0.6575625262083611 | validation: 0.44402248721768256]
	TIME [epoch: 8.82 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5454707206143792		[learning rate: 0.0027033]
	Learning Rate: 0.00270332
	LOSS [training: 0.5454707206143792 | validation: 0.5504894084069007]
	TIME [epoch: 8.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46903640139687486		[learning rate: 0.0026969]
	Learning Rate: 0.00269694
	LOSS [training: 0.46903640139687486 | validation: 0.3871543205086887]
	TIME [epoch: 8.49 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49542082703710666		[learning rate: 0.0026906]
	Learning Rate: 0.00269058
	LOSS [training: 0.49542082703710666 | validation: 0.46107919998051505]
	TIME [epoch: 8.48 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6358064285668785		[learning rate: 0.0026842]
	Learning Rate: 0.00268423
	LOSS [training: 0.6358064285668785 | validation: 0.4453091937804525]
	TIME [epoch: 8.52 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4514210166512312		[learning rate: 0.0026779]
	Learning Rate: 0.0026779
	LOSS [training: 0.4514210166512312 | validation: 0.4077295803675034]
	TIME [epoch: 8.51 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6294815648776182		[learning rate: 0.0026716]
	Learning Rate: 0.00267159
	LOSS [training: 0.6294815648776182 | validation: 0.48622724367666836]
	TIME [epoch: 8.49 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4811849046599644		[learning rate: 0.0026653]
	Learning Rate: 0.00266528
	LOSS [training: 0.4811849046599644 | validation: 0.7434736233765116]
	TIME [epoch: 8.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5007081240716499		[learning rate: 0.002659]
	Learning Rate: 0.002659
	LOSS [training: 0.5007081240716499 | validation: 0.39536927446848635]
	TIME [epoch: 8.51 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.519685326074271		[learning rate: 0.0026527]
	Learning Rate: 0.00265273
	LOSS [training: 0.519685326074271 | validation: 0.3936385045034131]
	TIME [epoch: 8.49 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4236215456808923		[learning rate: 0.0026465]
	Learning Rate: 0.00264647
	LOSS [training: 0.4236215456808923 | validation: 0.4391103112642466]
	TIME [epoch: 8.49 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44347438588839483		[learning rate: 0.0026402]
	Learning Rate: 0.00264023
	LOSS [training: 0.44347438588839483 | validation: 0.34349025135481737]
	TIME [epoch: 8.51 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36419985546317896		[learning rate: 0.002634]
	Learning Rate: 0.002634
	LOSS [training: 0.36419985546317896 | validation: 0.38489789569719446]
	TIME [epoch: 8.51 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43455302730457984		[learning rate: 0.0026278]
	Learning Rate: 0.00262778
	LOSS [training: 0.43455302730457984 | validation: 0.3919210121754092]
	TIME [epoch: 8.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.686519492945611		[learning rate: 0.0026216]
	Learning Rate: 0.00262159
	LOSS [training: 0.686519492945611 | validation: 0.3640821948116141]
	TIME [epoch: 8.49 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46852623397316445		[learning rate: 0.0026154]
	Learning Rate: 0.0026154
	LOSS [training: 0.46852623397316445 | validation: 0.3654578163830934]
	TIME [epoch: 8.51 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3555142041745142		[learning rate: 0.0026092]
	Learning Rate: 0.00260923
	LOSS [training: 0.3555142041745142 | validation: 0.41846561404240684]
	TIME [epoch: 8.51 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6561694255546693		[learning rate: 0.0026031]
	Learning Rate: 0.00260308
	LOSS [training: 0.6561694255546693 | validation: 0.7591376410076949]
	TIME [epoch: 8.49 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5180899723284657		[learning rate: 0.0025969]
	Learning Rate: 0.00259694
	LOSS [training: 0.5180899723284657 | validation: 0.5438275649832229]
	TIME [epoch: 8.49 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5511829909915891		[learning rate: 0.0025908]
	Learning Rate: 0.00259081
	LOSS [training: 0.5511829909915891 | validation: 0.46826657306776187]
	TIME [epoch: 8.51 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42403781984019107		[learning rate: 0.0025847]
	Learning Rate: 0.0025847
	LOSS [training: 0.42403781984019107 | validation: 0.38625503847371306]
	TIME [epoch: 8.51 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4530432087138906		[learning rate: 0.0025786]
	Learning Rate: 0.0025786
	LOSS [training: 0.4530432087138906 | validation: 0.3516360213813819]
	TIME [epoch: 8.49 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4760939240051606		[learning rate: 0.0025725]
	Learning Rate: 0.00257252
	LOSS [training: 0.4760939240051606 | validation: 0.3519304366259859]
	TIME [epoch: 8.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7235059970651746		[learning rate: 0.0025665]
	Learning Rate: 0.00256645
	LOSS [training: 0.7235059970651746 | validation: 0.582662430990866]
	TIME [epoch: 8.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5255282296615985		[learning rate: 0.0025604]
	Learning Rate: 0.0025604
	LOSS [training: 0.5255282296615985 | validation: 0.6629360626863915]
	TIME [epoch: 8.51 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5242818403918921		[learning rate: 0.0025544]
	Learning Rate: 0.00255436
	LOSS [training: 0.5242818403918921 | validation: 0.5192990789267236]
	TIME [epoch: 8.49 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5456262757292323		[learning rate: 0.0025483]
	Learning Rate: 0.00254833
	LOSS [training: 0.5456262757292323 | validation: 0.3729779251785454]
	TIME [epoch: 8.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4866538397523518		[learning rate: 0.0025423]
	Learning Rate: 0.00254232
	LOSS [training: 0.4866538397523518 | validation: 0.5236101596126814]
	TIME [epoch: 8.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4567926414692768		[learning rate: 0.0025363]
	Learning Rate: 0.00253633
	LOSS [training: 0.4567926414692768 | validation: 0.5879613095631983]
	TIME [epoch: 8.51 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5191488704483691		[learning rate: 0.0025303]
	Learning Rate: 0.00253034
	LOSS [training: 0.5191488704483691 | validation: 0.8527243858124378]
	TIME [epoch: 8.49 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.738384353366776		[learning rate: 0.0025244]
	Learning Rate: 0.00252437
	LOSS [training: 0.738384353366776 | validation: 0.7154701235027725]
	TIME [epoch: 8.51 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5611441595302316		[learning rate: 0.0025184]
	Learning Rate: 0.00251842
	LOSS [training: 0.5611441595302316 | validation: 0.5261947170776777]
	TIME [epoch: 8.49 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49386300311029185		[learning rate: 0.0025125]
	Learning Rate: 0.00251248
	LOSS [training: 0.49386300311029185 | validation: 0.5215457049547474]
	TIME [epoch: 8.51 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5411849850563273		[learning rate: 0.0025066]
	Learning Rate: 0.00250655
	LOSS [training: 0.5411849850563273 | validation: 0.7187894401936252]
	TIME [epoch: 8.49 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47979382845130114		[learning rate: 0.0025006]
	Learning Rate: 0.00250064
	LOSS [training: 0.47979382845130114 | validation: 0.5464726912901319]
	TIME [epoch: 8.51 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4512203605882802		[learning rate: 0.0024947]
	Learning Rate: 0.00249474
	LOSS [training: 0.4512203605882802 | validation: 0.49442858350394275]
	TIME [epoch: 8.49 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45736087427041944		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.45736087427041944 | validation: 0.5482538117767388]
	TIME [epoch: 8.51 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38386757350745043		[learning rate: 0.002483]
	Learning Rate: 0.00248299
	LOSS [training: 0.38386757350745043 | validation: 0.6302017409152343]
	TIME [epoch: 8.49 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.586073161934998		[learning rate: 0.0024771]
	Learning Rate: 0.00247713
	LOSS [training: 0.586073161934998 | validation: 0.4498497112706009]
	TIME [epoch: 8.51 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49580667516154486		[learning rate: 0.0024713]
	Learning Rate: 0.00247129
	LOSS [training: 0.49580667516154486 | validation: 0.6231373643831144]
	TIME [epoch: 8.49 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5921514714594345		[learning rate: 0.0024655]
	Learning Rate: 0.00246546
	LOSS [training: 0.5921514714594345 | validation: 0.3598275188484565]
	TIME [epoch: 8.51 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33229394560106357		[learning rate: 0.0024596]
	Learning Rate: 0.00245964
	LOSS [training: 0.33229394560106357 | validation: 0.439896744208651]
	TIME [epoch: 8.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5305976552247544		[learning rate: 0.0024538]
	Learning Rate: 0.00245384
	LOSS [training: 0.5305976552247544 | validation: 0.851703267772645]
	TIME [epoch: 8.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4687890586351111		[learning rate: 0.0024481]
	Learning Rate: 0.00244805
	LOSS [training: 0.4687890586351111 | validation: 0.6275921223480678]
	TIME [epoch: 8.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47615754939252886		[learning rate: 0.0024423]
	Learning Rate: 0.00244228
	LOSS [training: 0.47615754939252886 | validation: 0.3717083543837849]
	TIME [epoch: 8.51 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47950489148971676		[learning rate: 0.0024365]
	Learning Rate: 0.00243652
	LOSS [training: 0.47950489148971676 | validation: 0.3441784558339376]
	TIME [epoch: 8.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3662867842837213		[learning rate: 0.0024308]
	Learning Rate: 0.00243077
	LOSS [training: 0.3662867842837213 | validation: 0.566689212229565]
	TIME [epoch: 8.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6535911691448197		[learning rate: 0.002425]
	Learning Rate: 0.00242503
	LOSS [training: 0.6535911691448197 | validation: 0.5926969535729194]
	TIME [epoch: 8.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4401445646301988		[learning rate: 0.0024193]
	Learning Rate: 0.00241931
	LOSS [training: 0.4401445646301988 | validation: 0.3230167674514258]
	TIME [epoch: 8.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4591710102441833		[learning rate: 0.0024136]
	Learning Rate: 0.00241361
	LOSS [training: 0.4591710102441833 | validation: 0.5748967502586765]
	TIME [epoch: 8.51 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5042038939481353		[learning rate: 0.0024079]
	Learning Rate: 0.00240791
	LOSS [training: 0.5042038939481353 | validation: 0.3843873951115844]
	TIME [epoch: 8.49 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5863979071479923		[learning rate: 0.0024022]
	Learning Rate: 0.00240223
	LOSS [training: 0.5863979071479923 | validation: 0.27487150136880356]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_654.pth
	Model improved!!!
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29492836151192175		[learning rate: 0.0023966]
	Learning Rate: 0.00239657
	LOSS [training: 0.29492836151192175 | validation: 0.2874800380715353]
	TIME [epoch: 8.51 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3327743430210461		[learning rate: 0.0023909]
	Learning Rate: 0.00239092
	LOSS [training: 0.3327743430210461 | validation: 0.3501683333480967]
	TIME [epoch: 8.52 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4142948870945367		[learning rate: 0.0023853]
	Learning Rate: 0.00238527
	LOSS [training: 0.4142948870945367 | validation: 0.47365462659882596]
	TIME [epoch: 8.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.703937941372877		[learning rate: 0.0023796]
	Learning Rate: 0.00237965
	LOSS [training: 0.703937941372877 | validation: 0.526626086287691]
	TIME [epoch: 8.5 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4580252549689746		[learning rate: 0.002374]
	Learning Rate: 0.00237404
	LOSS [training: 0.4580252549689746 | validation: 0.3486487486928893]
	TIME [epoch: 8.51 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45576502061670865		[learning rate: 0.0023684]
	Learning Rate: 0.00236844
	LOSS [training: 0.45576502061670865 | validation: 0.6584401949083896]
	TIME [epoch: 8.52 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4033194966992097		[learning rate: 0.0023628]
	Learning Rate: 0.00236285
	LOSS [training: 0.4033194966992097 | validation: 0.2998630731891026]
	TIME [epoch: 8.49 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33216435684458684		[learning rate: 0.0023573]
	Learning Rate: 0.00235727
	LOSS [training: 0.33216435684458684 | validation: 0.3803835873470899]
	TIME [epoch: 8.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4407707262308243		[learning rate: 0.0023517]
	Learning Rate: 0.00235171
	LOSS [training: 0.4407707262308243 | validation: 0.33832941542451933]
	TIME [epoch: 8.52 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38628873250312734		[learning rate: 0.0023462]
	Learning Rate: 0.00234617
	LOSS [training: 0.38628873250312734 | validation: 0.31993479618562415]
	TIME [epoch: 8.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3967105688158946		[learning rate: 0.0023406]
	Learning Rate: 0.00234063
	LOSS [training: 0.3967105688158946 | validation: 0.3159415346992336]
	TIME [epoch: 8.49 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46335481336789897		[learning rate: 0.0023351]
	Learning Rate: 0.00233511
	LOSS [training: 0.46335481336789897 | validation: 0.4879404139671465]
	TIME [epoch: 8.51 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.412566370846278		[learning rate: 0.0023296]
	Learning Rate: 0.0023296
	LOSS [training: 0.412566370846278 | validation: 0.35498606467224814]
	TIME [epoch: 8.52 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3948299071939885		[learning rate: 0.0023241]
	Learning Rate: 0.00232411
	LOSS [training: 0.3948299071939885 | validation: 0.31366935334576596]
	TIME [epoch: 8.51 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4392717833015409		[learning rate: 0.0023186]
	Learning Rate: 0.00231863
	LOSS [training: 0.4392717833015409 | validation: 0.4264889634315878]
	TIME [epoch: 8.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37661700219895355		[learning rate: 0.0023132]
	Learning Rate: 0.00231316
	LOSS [training: 0.37661700219895355 | validation: 0.5661532532376785]
	TIME [epoch: 8.52 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6117220938246707		[learning rate: 0.0023077]
	Learning Rate: 0.0023077
	LOSS [training: 0.6117220938246707 | validation: 0.5154678737148863]
	TIME [epoch: 8.52 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40252281127150813		[learning rate: 0.0023023]
	Learning Rate: 0.00230226
	LOSS [training: 0.40252281127150813 | validation: 0.35875745727781394]
	TIME [epoch: 8.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3425692691876716		[learning rate: 0.0022968]
	Learning Rate: 0.00229683
	LOSS [training: 0.3425692691876716 | validation: 0.3351539158796869]
	TIME [epoch: 8.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4505373202859116		[learning rate: 0.0022914]
	Learning Rate: 0.00229141
	LOSS [training: 0.4505373202859116 | validation: 0.6117935201121498]
	TIME [epoch: 8.52 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5561056779611		[learning rate: 0.002286]
	Learning Rate: 0.002286
	LOSS [training: 0.5561056779611 | validation: 0.8400981996619519]
	TIME [epoch: 8.53 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.540884614923866		[learning rate: 0.0022806]
	Learning Rate: 0.00228061
	LOSS [training: 0.540884614923866 | validation: 0.4648177643144452]
	TIME [epoch: 8.49 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4059739568994282		[learning rate: 0.0022752]
	Learning Rate: 0.00227523
	LOSS [training: 0.4059739568994282 | validation: 0.36255553695243603]
	TIME [epoch: 8.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4788503669465438		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.4788503669465438 | validation: 0.3772399299647031]
	TIME [epoch: 8.53 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3888303565426587		[learning rate: 0.0022645]
	Learning Rate: 0.00226451
	LOSS [training: 0.3888303565426587 | validation: 0.4054979195127315]
	TIME [epoch: 8.51 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48359498222272795		[learning rate: 0.0022592]
	Learning Rate: 0.00225917
	LOSS [training: 0.48359498222272795 | validation: 0.3472979261718442]
	TIME [epoch: 8.49 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5953884601716902		[learning rate: 0.0022538]
	Learning Rate: 0.00225384
	LOSS [training: 0.5953884601716902 | validation: 0.44099336935027167]
	TIME [epoch: 8.49 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44960525532293677		[learning rate: 0.0022485]
	Learning Rate: 0.00224852
	LOSS [training: 0.44960525532293677 | validation: 0.5345357660837734]
	TIME [epoch: 8.53 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3937948498588219		[learning rate: 0.0022432]
	Learning Rate: 0.00224322
	LOSS [training: 0.3937948498588219 | validation: 0.32957443660507935]
	TIME [epoch: 8.51 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39820388880582314		[learning rate: 0.0022379]
	Learning Rate: 0.00223793
	LOSS [training: 0.39820388880582314 | validation: 0.36985756030546146]
	TIME [epoch: 8.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36738404956798043		[learning rate: 0.0022326]
	Learning Rate: 0.00223265
	LOSS [training: 0.36738404956798043 | validation: 0.2923172972082916]
	TIME [epoch: 8.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.345931969317839		[learning rate: 0.0022274]
	Learning Rate: 0.00222738
	LOSS [training: 0.345931969317839 | validation: 0.40243927629909454]
	TIME [epoch: 8.53 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43615185974863646		[learning rate: 0.0022221]
	Learning Rate: 0.00222213
	LOSS [training: 0.43615185974863646 | validation: 0.3521599451626207]
	TIME [epoch: 8.51 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33810544061562414		[learning rate: 0.0022169]
	Learning Rate: 0.00221689
	LOSS [training: 0.33810544061562414 | validation: 0.5121463752559203]
	TIME [epoch: 8.49 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4527897890696912		[learning rate: 0.0022117]
	Learning Rate: 0.00221166
	LOSS [training: 0.4527897890696912 | validation: 0.35684684029116054]
	TIME [epoch: 8.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34298817274276205		[learning rate: 0.0022064]
	Learning Rate: 0.00220644
	LOSS [training: 0.34298817274276205 | validation: 0.4253669004202919]
	TIME [epoch: 8.54 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3815392559002565		[learning rate: 0.0022012]
	Learning Rate: 0.00220124
	LOSS [training: 0.3815392559002565 | validation: 0.4672170604503315]
	TIME [epoch: 8.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4506564150073279		[learning rate: 0.002196]
	Learning Rate: 0.00219604
	LOSS [training: 0.4506564150073279 | validation: 0.7335811239435028]
	TIME [epoch: 8.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5454561160337903		[learning rate: 0.0021909]
	Learning Rate: 0.00219086
	LOSS [training: 0.5454561160337903 | validation: 0.6082537428358463]
	TIME [epoch: 8.51 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42484747826402397		[learning rate: 0.0021857]
	Learning Rate: 0.0021857
	LOSS [training: 0.42484747826402397 | validation: 0.8375901304633645]
	TIME [epoch: 8.54 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.593295497195698		[learning rate: 0.0021805]
	Learning Rate: 0.00218054
	LOSS [training: 0.593295497195698 | validation: 0.5470311782108184]
	TIME [epoch: 8.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5170063410033376		[learning rate: 0.0021754]
	Learning Rate: 0.0021754
	LOSS [training: 0.5170063410033376 | validation: 0.4544049547897878]
	TIME [epoch: 8.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39715621448182664		[learning rate: 0.0021703]
	Learning Rate: 0.00217027
	LOSS [training: 0.39715621448182664 | validation: 0.3886369457024371]
	TIME [epoch: 8.52 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49012236146850013		[learning rate: 0.0021651]
	Learning Rate: 0.00216515
	LOSS [training: 0.49012236146850013 | validation: 0.9638769939679033]
	TIME [epoch: 8.51 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5300356610888436		[learning rate: 0.00216]
	Learning Rate: 0.00216004
	LOSS [training: 0.5300356610888436 | validation: 0.6846161084245397]
	TIME [epoch: 8.49 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6664823462910475		[learning rate: 0.0021549]
	Learning Rate: 0.00215494
	LOSS [training: 0.6664823462910475 | validation: 0.9450203260724267]
	TIME [epoch: 8.49 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6962452887322729		[learning rate: 0.0021499]
	Learning Rate: 0.00214986
	LOSS [training: 0.6962452887322729 | validation: 0.5977446880832723]
	TIME [epoch: 8.52 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5797101797990147		[learning rate: 0.0021448]
	Learning Rate: 0.00214479
	LOSS [training: 0.5797101797990147 | validation: 0.8354319095329787]
	TIME [epoch: 8.52 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5752352243898188		[learning rate: 0.0021397]
	Learning Rate: 0.00213973
	LOSS [training: 0.5752352243898188 | validation: 0.3846788032559262]
	TIME [epoch: 8.49 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5120533367819167		[learning rate: 0.0021347]
	Learning Rate: 0.00213468
	LOSS [training: 0.5120533367819167 | validation: 0.5279194162185721]
	TIME [epoch: 8.5 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5113733119257029		[learning rate: 0.0021296]
	Learning Rate: 0.00212965
	LOSS [training: 0.5113733119257029 | validation: 0.5001646363561824]
	TIME [epoch: 8.53 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5525176185306234		[learning rate: 0.0021246]
	Learning Rate: 0.00212462
	LOSS [training: 0.5525176185306234 | validation: 0.5784694650351245]
	TIME [epoch: 8.5 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42829430429378623		[learning rate: 0.0021196]
	Learning Rate: 0.00211961
	LOSS [training: 0.42829430429378623 | validation: 0.3943429481304732]
	TIME [epoch: 8.49 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3800020089680337		[learning rate: 0.0021146]
	Learning Rate: 0.00211461
	LOSS [training: 0.3800020089680337 | validation: 0.3547490795108817]
	TIME [epoch: 8.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3379766071691506		[learning rate: 0.0021096]
	Learning Rate: 0.00210962
	LOSS [training: 0.3379766071691506 | validation: 0.4041115612329787]
	TIME [epoch: 8.55 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41596571151815265		[learning rate: 0.0021046]
	Learning Rate: 0.00210465
	LOSS [training: 0.41596571151815265 | validation: 0.517967700774722]
	TIME [epoch: 8.51 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39544778396797964		[learning rate: 0.0020997]
	Learning Rate: 0.00209968
	LOSS [training: 0.39544778396797964 | validation: 0.28816465998185203]
	TIME [epoch: 8.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38568320940434875		[learning rate: 0.0020947]
	Learning Rate: 0.00209473
	LOSS [training: 0.38568320940434875 | validation: 0.9071511392577637]
	TIME [epoch: 8.51 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6187797017345613		[learning rate: 0.0020898]
	Learning Rate: 0.00208979
	LOSS [training: 0.6187797017345613 | validation: 0.40869051776476417]
	TIME [epoch: 8.53 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5086970274486149		[learning rate: 0.0020849]
	Learning Rate: 0.00208486
	LOSS [training: 0.5086970274486149 | validation: 0.5301915278346353]
	TIME [epoch: 8.51 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3679636868155913		[learning rate: 0.0020799]
	Learning Rate: 0.00207994
	LOSS [training: 0.3679636868155913 | validation: 0.6188997479531317]
	TIME [epoch: 8.51 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4768695378140193		[learning rate: 0.002075]
	Learning Rate: 0.00207504
	LOSS [training: 0.4768695378140193 | validation: 0.36462036804718395]
	TIME [epoch: 8.51 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5160950269943227		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.5160950269943227 | validation: 0.3215407612737224]
	TIME [epoch: 8.53 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31991581088580084		[learning rate: 0.0020653]
	Learning Rate: 0.00206526
	LOSS [training: 0.31991581088580084 | validation: 0.306595306801006]
	TIME [epoch: 8.51 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3501828420429287		[learning rate: 0.0020604]
	Learning Rate: 0.00206039
	LOSS [training: 0.3501828420429287 | validation: 0.6915640133221957]
	TIME [epoch: 8.51 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3605956700788321		[learning rate: 0.0020555]
	Learning Rate: 0.00205553
	LOSS [training: 0.3605956700788321 | validation: 0.2542787626933064]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_720.pth
	Model improved!!!
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3520981041289562		[learning rate: 0.0020507]
	Learning Rate: 0.00205068
	LOSS [training: 0.3520981041289562 | validation: 0.4537280493118174]
	TIME [epoch: 8.51 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47564137587256844		[learning rate: 0.0020458]
	Learning Rate: 0.00204584
	LOSS [training: 0.47564137587256844 | validation: 0.4826465960230396]
	TIME [epoch: 8.48 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37485827852937686		[learning rate: 0.002041]
	Learning Rate: 0.00204101
	LOSS [training: 0.37485827852937686 | validation: 0.38247507026807637]
	TIME [epoch: 8.48 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5061906254945538		[learning rate: 0.0020362]
	Learning Rate: 0.0020362
	LOSS [training: 0.5061906254945538 | validation: 0.4669878094601326]
	TIME [epoch: 8.55 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34484961182494234		[learning rate: 0.0020314]
	Learning Rate: 0.0020314
	LOSS [training: 0.34484961182494234 | validation: 0.29024971121036214]
	TIME [epoch: 8.53 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3085052340551524		[learning rate: 0.0020266]
	Learning Rate: 0.00202661
	LOSS [training: 0.3085052340551524 | validation: 0.27316581325451694]
	TIME [epoch: 8.49 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3141337401504015		[learning rate: 0.0020218]
	Learning Rate: 0.00202182
	LOSS [training: 0.3141337401504015 | validation: 0.46240599564598817]
	TIME [epoch: 8.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31023285662802		[learning rate: 0.0020171]
	Learning Rate: 0.00201706
	LOSS [training: 0.31023285662802 | validation: 0.24563657131861863]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_728.pth
	Model improved!!!
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32809207111089406		[learning rate: 0.0020123]
	Learning Rate: 0.0020123
	LOSS [training: 0.32809207111089406 | validation: 0.48363089778336854]
	TIME [epoch: 8.51 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4157932642646801		[learning rate: 0.0020076]
	Learning Rate: 0.00200755
	LOSS [training: 0.4157932642646801 | validation: 0.37581888910005534]
	TIME [epoch: 8.49 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4100146161441113		[learning rate: 0.0020028]
	Learning Rate: 0.00200282
	LOSS [training: 0.4100146161441113 | validation: 0.5274254069663074]
	TIME [epoch: 8.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6188206451177497		[learning rate: 0.0019981]
	Learning Rate: 0.00199809
	LOSS [training: 0.6188206451177497 | validation: 0.3568770710204166]
	TIME [epoch: 8.49 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.534984316697496		[learning rate: 0.0019934]
	Learning Rate: 0.00199338
	LOSS [training: 0.534984316697496 | validation: 0.2820079644003266]
	TIME [epoch: 8.51 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5236349023005542		[learning rate: 0.0019887]
	Learning Rate: 0.00198868
	LOSS [training: 0.5236349023005542 | validation: 0.39404638856154595]
	TIME [epoch: 8.49 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3651742847311624		[learning rate: 0.001984]
	Learning Rate: 0.00198399
	LOSS [training: 0.3651742847311624 | validation: 0.3269462496606364]
	TIME [epoch: 8.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36537790953529037		[learning rate: 0.0019793]
	Learning Rate: 0.00197931
	LOSS [training: 0.36537790953529037 | validation: 0.35980511855117486]
	TIME [epoch: 8.49 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3005389201814438		[learning rate: 0.0019746]
	Learning Rate: 0.00197464
	LOSS [training: 0.3005389201814438 | validation: 0.3547367099095513]
	TIME [epoch: 8.51 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3798738612728503		[learning rate: 0.00197]
	Learning Rate: 0.00196998
	LOSS [training: 0.3798738612728503 | validation: 0.571534109258268]
	TIME [epoch: 8.48 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3360369722056377		[learning rate: 0.0019653]
	Learning Rate: 0.00196533
	LOSS [training: 0.3360369722056377 | validation: 0.4218117131345889]
	TIME [epoch: 8.51 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38106237577101176		[learning rate: 0.0019607]
	Learning Rate: 0.0019607
	LOSS [training: 0.38106237577101176 | validation: 0.3156942890888414]
	TIME [epoch: 8.49 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4237015386219153		[learning rate: 0.0019561]
	Learning Rate: 0.00195607
	LOSS [training: 0.4237015386219153 | validation: 0.4560987157188372]
	TIME [epoch: 8.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.397838489697878		[learning rate: 0.0019515]
	Learning Rate: 0.00195146
	LOSS [training: 0.397838489697878 | validation: 0.3421061202003939]
	TIME [epoch: 8.48 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2889037043402492		[learning rate: 0.0019469]
	Learning Rate: 0.00194685
	LOSS [training: 0.2889037043402492 | validation: 0.33609271908112015]
	TIME [epoch: 8.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32596326723370855		[learning rate: 0.0019423]
	Learning Rate: 0.00194226
	LOSS [training: 0.32596326723370855 | validation: 0.2921538364466185]
	TIME [epoch: 8.48 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3581649042753544		[learning rate: 0.0019377]
	Learning Rate: 0.00193768
	LOSS [training: 0.3581649042753544 | validation: 0.9950161808105245]
	TIME [epoch: 8.51 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5890215738663865		[learning rate: 0.0019331]
	Learning Rate: 0.00193311
	LOSS [training: 0.5890215738663865 | validation: 0.2869945444838965]
	TIME [epoch: 8.48 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5179590404379525		[learning rate: 0.0019285]
	Learning Rate: 0.00192855
	LOSS [training: 0.5179590404379525 | validation: 0.32685234065144575]
	TIME [epoch: 8.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45330356106076763		[learning rate: 0.001924]
	Learning Rate: 0.001924
	LOSS [training: 0.45330356106076763 | validation: 0.34237037342875465]
	TIME [epoch: 8.49 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3943445230004768		[learning rate: 0.0019195]
	Learning Rate: 0.00191946
	LOSS [training: 0.3943445230004768 | validation: 0.3925842647545208]
	TIME [epoch: 8.51 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37517304614231123		[learning rate: 0.0019149]
	Learning Rate: 0.00191493
	LOSS [training: 0.37517304614231123 | validation: 0.3074938604208277]
	TIME [epoch: 8.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37420400146232063		[learning rate: 0.0019104]
	Learning Rate: 0.00191042
	LOSS [training: 0.37420400146232063 | validation: 0.29629629996778106]
	TIME [epoch: 8.49 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28049949516417094		[learning rate: 0.0019059]
	Learning Rate: 0.00190591
	LOSS [training: 0.28049949516417094 | validation: 0.31169774293238917]
	TIME [epoch: 8.48 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.474221296865508		[learning rate: 0.0019014]
	Learning Rate: 0.00190141
	LOSS [training: 0.474221296865508 | validation: 0.41732129951906605]
	TIME [epoch: 8.51 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5227408164565361		[learning rate: 0.0018969]
	Learning Rate: 0.00189693
	LOSS [training: 0.5227408164565361 | validation: 0.45538475529954087]
	TIME [epoch: 8.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3517989612033017		[learning rate: 0.0018925]
	Learning Rate: 0.00189246
	LOSS [training: 0.3517989612033017 | validation: 0.3920513158274789]
	TIME [epoch: 8.49 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.411877074903639		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.411877074903639 | validation: 0.4000639242883346]
	TIME [epoch: 8.49 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34369299713844353		[learning rate: 0.0018835]
	Learning Rate: 0.00188354
	LOSS [training: 0.34369299713844353 | validation: 0.27403665736154365]
	TIME [epoch: 8.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3576010967794675		[learning rate: 0.0018791]
	Learning Rate: 0.00187909
	LOSS [training: 0.3576010967794675 | validation: 0.502940309178646]
	TIME [epoch: 8.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4095803670223721		[learning rate: 0.0018747]
	Learning Rate: 0.00187466
	LOSS [training: 0.4095803670223721 | validation: 0.6285136981659515]
	TIME [epoch: 8.49 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4652353599276159		[learning rate: 0.0018702]
	Learning Rate: 0.00187024
	LOSS [training: 0.4652353599276159 | validation: 0.40800311833929076]
	TIME [epoch: 8.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33394138356684394		[learning rate: 0.0018658]
	Learning Rate: 0.00186583
	LOSS [training: 0.33394138356684394 | validation: 0.32959122165112004]
	TIME [epoch: 8.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35592219408894665		[learning rate: 0.0018614]
	Learning Rate: 0.00186143
	LOSS [training: 0.35592219408894665 | validation: 0.379182443817935]
	TIME [epoch: 8.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30457423978003434		[learning rate: 0.001857]
	Learning Rate: 0.00185704
	LOSS [training: 0.30457423978003434 | validation: 0.3575061461301229]
	TIME [epoch: 8.48 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4172608993396774		[learning rate: 0.0018527]
	Learning Rate: 0.00185266
	LOSS [training: 0.4172608993396774 | validation: 0.40164541750539595]
	TIME [epoch: 8.49 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6341339755508446		[learning rate: 0.0018483]
	Learning Rate: 0.00184829
	LOSS [training: 0.6341339755508446 | validation: 1.2084564401349311]
	TIME [epoch: 8.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5574594691184935		[learning rate: 0.0018439]
	Learning Rate: 0.00184393
	LOSS [training: 0.5574594691184935 | validation: 0.3240184019097361]
	TIME [epoch: 8.49 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41070877158174257		[learning rate: 0.0018396]
	Learning Rate: 0.00183958
	LOSS [training: 0.41070877158174257 | validation: 0.34356321041890325]
	TIME [epoch: 8.48 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45074520534217977		[learning rate: 0.0018352]
	Learning Rate: 0.00183524
	LOSS [training: 0.45074520534217977 | validation: 0.32897460063908424]
	TIME [epoch: 8.51 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34540800543862654		[learning rate: 0.0018309]
	Learning Rate: 0.00183091
	LOSS [training: 0.34540800543862654 | validation: 0.3204306310401389]
	TIME [epoch: 8.49 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.484744741329851		[learning rate: 0.0018266]
	Learning Rate: 0.00182659
	LOSS [training: 0.484744741329851 | validation: 0.5744518246472976]
	TIME [epoch: 8.49 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3683000600661884		[learning rate: 0.0018223]
	Learning Rate: 0.00182228
	LOSS [training: 0.3683000600661884 | validation: 0.26547848330595347]
	TIME [epoch: 8.48 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.507265340892568		[learning rate: 0.001818]
	Learning Rate: 0.00181798
	LOSS [training: 0.507265340892568 | validation: 0.7154288925903565]
	TIME [epoch: 8.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6629487967953465		[learning rate: 0.0018137]
	Learning Rate: 0.00181369
	LOSS [training: 0.6629487967953465 | validation: 0.27101160512986044]
	TIME [epoch: 8.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4195717821967483		[learning rate: 0.0018094]
	Learning Rate: 0.00180942
	LOSS [training: 0.4195717821967483 | validation: 0.4191402791983032]
	TIME [epoch: 8.48 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3462507394452733		[learning rate: 0.0018051]
	Learning Rate: 0.00180515
	LOSS [training: 0.3462507394452733 | validation: 0.34612066881938913]
	TIME [epoch: 8.48 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3314471240835885		[learning rate: 0.0018009]
	Learning Rate: 0.00180089
	LOSS [training: 0.3314471240835885 | validation: 0.3439529668601359]
	TIME [epoch: 8.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4950675350736648		[learning rate: 0.0017966]
	Learning Rate: 0.00179664
	LOSS [training: 0.4950675350736648 | validation: 0.8489613228044124]
	TIME [epoch: 8.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44867655426473163		[learning rate: 0.0017924]
	Learning Rate: 0.0017924
	LOSS [training: 0.44867655426473163 | validation: 0.3170973801807856]
	TIME [epoch: 8.48 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33325913941411656		[learning rate: 0.0017882]
	Learning Rate: 0.00178818
	LOSS [training: 0.33325913941411656 | validation: 0.377528513689665]
	TIME [epoch: 8.48 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.551136499202871		[learning rate: 0.001784]
	Learning Rate: 0.00178396
	LOSS [training: 0.551136499202871 | validation: 0.2999386718419881]
	TIME [epoch: 8.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3104602044977786		[learning rate: 0.0017797]
	Learning Rate: 0.00177975
	LOSS [training: 0.3104602044977786 | validation: 0.5712348780443908]
	TIME [epoch: 8.51 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35532847443381377		[learning rate: 0.0017756]
	Learning Rate: 0.00177555
	LOSS [training: 0.35532847443381377 | validation: 0.3278435448089585]
	TIME [epoch: 8.48 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37693985591410606		[learning rate: 0.0017714]
	Learning Rate: 0.00177136
	LOSS [training: 0.37693985591410606 | validation: 0.56912048359205]
	TIME [epoch: 8.48 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32927369742579654		[learning rate: 0.0017672]
	Learning Rate: 0.00176719
	LOSS [training: 0.32927369742579654 | validation: 0.2653287452075247]
	TIME [epoch: 8.51 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3768649480537559		[learning rate: 0.001763]
	Learning Rate: 0.00176302
	LOSS [training: 0.3768649480537559 | validation: 0.376127384586225]
	TIME [epoch: 8.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48355668519921774		[learning rate: 0.0017589]
	Learning Rate: 0.00175886
	LOSS [training: 0.48355668519921774 | validation: 0.46354467956406753]
	TIME [epoch: 8.48 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5701688097405613		[learning rate: 0.0017547]
	Learning Rate: 0.00175471
	LOSS [training: 0.5701688097405613 | validation: 0.5815108735970445]
	TIME [epoch: 8.48 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38871035593403314		[learning rate: 0.0017506]
	Learning Rate: 0.00175057
	LOSS [training: 0.38871035593403314 | validation: 0.29089460207963536]
	TIME [epoch: 8.51 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38305643093510017		[learning rate: 0.0017464]
	Learning Rate: 0.00174644
	LOSS [training: 0.38305643093510017 | validation: 0.3259936418872914]
	TIME [epoch: 8.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3088836943439455		[learning rate: 0.0017423]
	Learning Rate: 0.00174232
	LOSS [training: 0.3088836943439455 | validation: 0.4635369782780435]
	TIME [epoch: 8.48 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3462206173226006		[learning rate: 0.0017382]
	Learning Rate: 0.00173821
	LOSS [training: 0.3462206173226006 | validation: 0.3854418379817497]
	TIME [epoch: 8.48 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3611640254552372		[learning rate: 0.0017341]
	Learning Rate: 0.00173411
	LOSS [training: 0.3611640254552372 | validation: 0.3015252930853869]
	TIME [epoch: 8.52 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4617671297273545		[learning rate: 0.00173]
	Learning Rate: 0.00173002
	LOSS [training: 0.4617671297273545 | validation: 0.4715482609853584]
	TIME [epoch: 8.49 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36319910794090365		[learning rate: 0.0017259]
	Learning Rate: 0.00172594
	LOSS [training: 0.36319910794090365 | validation: 0.27687025873934584]
	TIME [epoch: 8.48 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2716647561624466		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.2716647561624466 | validation: 0.2685481661637187]
	TIME [epoch: 8.48 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38220705651055714		[learning rate: 0.0017178]
	Learning Rate: 0.00171781
	LOSS [training: 0.38220705651055714 | validation: 0.4523694241980091]
	TIME [epoch: 8.51 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41404346369738426		[learning rate: 0.0017138]
	Learning Rate: 0.00171375
	LOSS [training: 0.41404346369738426 | validation: 0.3469011638549217]
	TIME [epoch: 8.49 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35182132621630186		[learning rate: 0.0017097]
	Learning Rate: 0.00170971
	LOSS [training: 0.35182132621630186 | validation: 0.3395704690559917]
	TIME [epoch: 8.48 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38953417695665277		[learning rate: 0.0017057]
	Learning Rate: 0.00170568
	LOSS [training: 0.38953417695665277 | validation: 0.8047274304987109]
	TIME [epoch: 8.49 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5383135544414208		[learning rate: 0.0017017]
	Learning Rate: 0.00170166
	LOSS [training: 0.5383135544414208 | validation: 0.5530869860324998]
	TIME [epoch: 8.51 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40278505395214437		[learning rate: 0.0016976]
	Learning Rate: 0.00169764
	LOSS [training: 0.40278505395214437 | validation: 0.26610597369562583]
	TIME [epoch: 8.48 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30570809215051875		[learning rate: 0.0016936]
	Learning Rate: 0.00169364
	LOSS [training: 0.30570809215051875 | validation: 0.2522041616272667]
	TIME [epoch: 8.48 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35223785264333335		[learning rate: 0.0016896]
	Learning Rate: 0.00168964
	LOSS [training: 0.35223785264333335 | validation: 0.34081261075576513]
	TIME [epoch: 8.49 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3572784822355518		[learning rate: 0.0016857]
	Learning Rate: 0.00168566
	LOSS [training: 0.3572784822355518 | validation: 0.47317862921992415]
	TIME [epoch: 8.51 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5255159359231351		[learning rate: 0.0016817]
	Learning Rate: 0.00168168
	LOSS [training: 0.5255159359231351 | validation: 0.31757884177880835]
	TIME [epoch: 8.47 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35723730887180094		[learning rate: 0.0016777]
	Learning Rate: 0.00167771
	LOSS [training: 0.35723730887180094 | validation: 0.4521099977477867]
	TIME [epoch: 8.48 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35874608460018215		[learning rate: 0.0016738]
	Learning Rate: 0.00167376
	LOSS [training: 0.35874608460018215 | validation: 0.28549609627267825]
	TIME [epoch: 8.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33853015941003856		[learning rate: 0.0016698]
	Learning Rate: 0.00166981
	LOSS [training: 0.33853015941003856 | validation: 0.6226978069669145]
	TIME [epoch: 8.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48761104792877985		[learning rate: 0.0016659]
	Learning Rate: 0.00166587
	LOSS [training: 0.48761104792877985 | validation: 0.3591041351647636]
	TIME [epoch: 8.48 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30913043149069497		[learning rate: 0.0016619]
	Learning Rate: 0.00166194
	LOSS [training: 0.30913043149069497 | validation: 0.2952296712094178]
	TIME [epoch: 8.48 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32519482034004243		[learning rate: 0.001658]
	Learning Rate: 0.00165802
	LOSS [training: 0.32519482034004243 | validation: 0.3082367548516947]
	TIME [epoch: 8.51 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3675021081780928		[learning rate: 0.0016541]
	Learning Rate: 0.00165411
	LOSS [training: 0.3675021081780928 | validation: 0.5306890637863476]
	TIME [epoch: 8.49 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42098175234503443		[learning rate: 0.0016502]
	Learning Rate: 0.00165021
	LOSS [training: 0.42098175234503443 | validation: 0.49411004875833636]
	TIME [epoch: 8.48 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5656500301289225		[learning rate: 0.0016463]
	Learning Rate: 0.00164631
	LOSS [training: 0.5656500301289225 | validation: 0.6182416852863624]
	TIME [epoch: 8.48 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5542041755079479		[learning rate: 0.0016424]
	Learning Rate: 0.00164243
	LOSS [training: 0.5542041755079479 | validation: 0.49021050649130105]
	TIME [epoch: 8.52 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4609544754331093		[learning rate: 0.0016386]
	Learning Rate: 0.00163856
	LOSS [training: 0.4609544754331093 | validation: 0.4754512289196638]
	TIME [epoch: 8.48 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5760371148780383		[learning rate: 0.0016347]
	Learning Rate: 0.00163469
	LOSS [training: 0.5760371148780383 | validation: 0.3859469099446175]
	TIME [epoch: 8.48 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36134753465851277		[learning rate: 0.0016308]
	Learning Rate: 0.00163084
	LOSS [training: 0.36134753465851277 | validation: 0.3322909470593773]
	TIME [epoch: 8.47 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33641819035837256		[learning rate: 0.001627]
	Learning Rate: 0.00162699
	LOSS [training: 0.33641819035837256 | validation: 0.4335677558730961]
	TIME [epoch: 8.52 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3830838778902692		[learning rate: 0.0016232]
	Learning Rate: 0.00162315
	LOSS [training: 0.3830838778902692 | validation: 0.6887910108951778]
	TIME [epoch: 8.48 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5461685613907818		[learning rate: 0.0016193]
	Learning Rate: 0.00161932
	LOSS [training: 0.5461685613907818 | validation: 0.7260111409554373]
	TIME [epoch: 8.48 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5340563237228514		[learning rate: 0.0016155]
	Learning Rate: 0.0016155
	LOSS [training: 0.5340563237228514 | validation: 0.5715094138444113]
	TIME [epoch: 8.47 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49381657868246104		[learning rate: 0.0016117]
	Learning Rate: 0.00161169
	LOSS [training: 0.49381657868246104 | validation: 0.476359907508874]
	TIME [epoch: 8.51 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44274078084665247		[learning rate: 0.0016079]
	Learning Rate: 0.00160789
	LOSS [training: 0.44274078084665247 | validation: 0.37214451457959574]
	TIME [epoch: 8.47 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4153368165960326		[learning rate: 0.0016041]
	Learning Rate: 0.0016041
	LOSS [training: 0.4153368165960326 | validation: 0.3022765453035119]
	TIME [epoch: 8.47 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31148014549890723		[learning rate: 0.0016003]
	Learning Rate: 0.00160031
	LOSS [training: 0.31148014549890723 | validation: 0.3631711601465254]
	TIME [epoch: 8.49 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4679587121038734		[learning rate: 0.0015965]
	Learning Rate: 0.00159654
	LOSS [training: 0.4679587121038734 | validation: 0.27188205133156673]
	TIME [epoch: 8.51 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30323766031798305		[learning rate: 0.0015928]
	Learning Rate: 0.00159277
	LOSS [training: 0.30323766031798305 | validation: 0.5026365534898443]
	TIME [epoch: 8.48 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3761647406321057		[learning rate: 0.001589]
	Learning Rate: 0.00158902
	LOSS [training: 0.3761647406321057 | validation: 0.4027516979310647]
	TIME [epoch: 8.47 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29215526775224715		[learning rate: 0.0015853]
	Learning Rate: 0.00158527
	LOSS [training: 0.29215526775224715 | validation: 0.38640616366658453]
	TIME [epoch: 8.49 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33451003173350896		[learning rate: 0.0015815]
	Learning Rate: 0.00158153
	LOSS [training: 0.33451003173350896 | validation: 0.2647946888500825]
	TIME [epoch: 8.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2769564074123947		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.2769564074123947 | validation: 0.2953709846041284]
	TIME [epoch: 8.48 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2862398111619249		[learning rate: 0.0015741]
	Learning Rate: 0.00157408
	LOSS [training: 0.2862398111619249 | validation: 0.2999175958153977]
	TIME [epoch: 8.48 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3278896604008033		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.3278896604008033 | validation: 0.26519506950686134]
	TIME [epoch: 8.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26889652576574313		[learning rate: 0.0015667]
	Learning Rate: 0.00156666
	LOSS [training: 0.26889652576574313 | validation: 0.3583228241934594]
	TIME [epoch: 8.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3846680596705913		[learning rate: 0.001563]
	Learning Rate: 0.00156296
	LOSS [training: 0.3846680596705913 | validation: 0.6118900834149308]
	TIME [epoch: 8.47 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4485464783511072		[learning rate: 0.0015593]
	Learning Rate: 0.00155928
	LOSS [training: 0.4485464783511072 | validation: 0.7060798054595903]
	TIME [epoch: 8.48 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.390239137393056		[learning rate: 0.0015556]
	Learning Rate: 0.0015556
	LOSS [training: 0.390239137393056 | validation: 0.25077558530969657]
	TIME [epoch: 8.51 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2936979189626281		[learning rate: 0.0015519]
	Learning Rate: 0.00155193
	LOSS [training: 0.2936979189626281 | validation: 0.62985725623973]
	TIME [epoch: 8.48 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39020709558365607		[learning rate: 0.0015483]
	Learning Rate: 0.00154827
	LOSS [training: 0.39020709558365607 | validation: 0.2333796717477496]
	TIME [epoch: 8.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_840.pth
	Model improved!!!
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3029712954090281		[learning rate: 0.0015446]
	Learning Rate: 0.00154462
	LOSS [training: 0.3029712954090281 | validation: 0.48411378204705297]
	TIME [epoch: 8.47 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4137428411295911		[learning rate: 0.001541]
	Learning Rate: 0.00154097
	LOSS [training: 0.4137428411295911 | validation: 0.3872551751351475]
	TIME [epoch: 8.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40864120991035674		[learning rate: 0.0015373]
	Learning Rate: 0.00153734
	LOSS [training: 0.40864120991035674 | validation: 0.4310691996365919]
	TIME [epoch: 8.48 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33237583554515104		[learning rate: 0.0015337]
	Learning Rate: 0.00153371
	LOSS [training: 0.33237583554515104 | validation: 0.2715092951602537]
	TIME [epoch: 8.47 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27913293490702995		[learning rate: 0.0015301]
	Learning Rate: 0.00153009
	LOSS [training: 0.27913293490702995 | validation: 0.30358006890255046]
	TIME [epoch: 8.49 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2682305094735557		[learning rate: 0.0015265]
	Learning Rate: 0.00152648
	LOSS [training: 0.2682305094735557 | validation: 0.33032429388422224]
	TIME [epoch: 8.49 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3126934029754636		[learning rate: 0.0015229]
	Learning Rate: 0.00152288
	LOSS [training: 0.3126934029754636 | validation: 0.31146613327940503]
	TIME [epoch: 8.49 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36851295382740723		[learning rate: 0.0015193]
	Learning Rate: 0.00151929
	LOSS [training: 0.36851295382740723 | validation: 0.37359531253614]
	TIME [epoch: 8.47 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4569819718674736		[learning rate: 0.0015157]
	Learning Rate: 0.00151571
	LOSS [training: 0.4569819718674736 | validation: 0.6850709011503695]
	TIME [epoch: 8.49 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4884682393138272		[learning rate: 0.0015121]
	Learning Rate: 0.00151213
	LOSS [training: 0.4884682393138272 | validation: 0.32894846522247734]
	TIME [epoch: 8.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28889429860605914		[learning rate: 0.0015086]
	Learning Rate: 0.00150857
	LOSS [training: 0.28889429860605914 | validation: 0.3860905951379511]
	TIME [epoch: 8.49 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33359756191405915		[learning rate: 0.001505]
	Learning Rate: 0.00150501
	LOSS [training: 0.33359756191405915 | validation: 0.41622450002465183]
	TIME [epoch: 8.47 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26789300563305624		[learning rate: 0.0015015]
	Learning Rate: 0.00150146
	LOSS [training: 0.26789300563305624 | validation: 0.24474894379571926]
	TIME [epoch: 8.49 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35867577837917386		[learning rate: 0.0014979]
	Learning Rate: 0.00149791
	LOSS [training: 0.35867577837917386 | validation: 0.31516167963054853]
	TIME [epoch: 8.49 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3944860956726103		[learning rate: 0.0014944]
	Learning Rate: 0.00149438
	LOSS [training: 0.3944860956726103 | validation: 0.40008787694195463]
	TIME [epoch: 8.48 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3469033973706678		[learning rate: 0.0014909]
	Learning Rate: 0.00149086
	LOSS [training: 0.3469033973706678 | validation: 0.2375315642383413]
	TIME [epoch: 8.48 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2863820404941554		[learning rate: 0.0014873]
	Learning Rate: 0.00148734
	LOSS [training: 0.2863820404941554 | validation: 0.29809633734563074]
	TIME [epoch: 8.49 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2886411603975685		[learning rate: 0.0014838]
	Learning Rate: 0.00148383
	LOSS [training: 0.2886411603975685 | validation: 0.3183401607289936]
	TIME [epoch: 8.49 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25062290273987553		[learning rate: 0.0014803]
	Learning Rate: 0.00148033
	LOSS [training: 0.25062290273987553 | validation: 0.2325148907445151]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_859.pth
	Model improved!!!
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24172806230770805		[learning rate: 0.0014768]
	Learning Rate: 0.00147684
	LOSS [training: 0.24172806230770805 | validation: 0.26184091728174275]
	TIME [epoch: 8.49 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37355951170181		[learning rate: 0.0014734]
	Learning Rate: 0.00147336
	LOSS [training: 0.37355951170181 | validation: 0.38015588325696287]
	TIME [epoch: 8.49 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34966607129687427		[learning rate: 0.0014699]
	Learning Rate: 0.00146988
	LOSS [training: 0.34966607129687427 | validation: 0.3698947276477002]
	TIME [epoch: 8.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28773964302342503		[learning rate: 0.0014664]
	Learning Rate: 0.00146641
	LOSS [training: 0.28773964302342503 | validation: 0.22587740544108126]
	TIME [epoch: 8.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_863.pth
	Model improved!!!
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2838479940498264		[learning rate: 0.001463]
	Learning Rate: 0.00146295
	LOSS [training: 0.2838479940498264 | validation: 0.4803444145837046]
	TIME [epoch: 8.48 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4766948709394785		[learning rate: 0.0014595]
	Learning Rate: 0.0014595
	LOSS [training: 0.4766948709394785 | validation: 0.6301083691929673]
	TIME [epoch: 8.48 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36883243572910096		[learning rate: 0.0014561]
	Learning Rate: 0.00145606
	LOSS [training: 0.36883243572910096 | validation: 0.2590344170631354]
	TIME [epoch: 8.48 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3100400778595297		[learning rate: 0.0014526]
	Learning Rate: 0.00145263
	LOSS [training: 0.3100400778595297 | validation: 0.45872753622936424]
	TIME [epoch: 8.49 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3546469915004383		[learning rate: 0.0014492]
	Learning Rate: 0.0014492
	LOSS [training: 0.3546469915004383 | validation: 0.27661707775267164]
	TIME [epoch: 8.48 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2802179686869157		[learning rate: 0.0014458]
	Learning Rate: 0.00144578
	LOSS [training: 0.2802179686869157 | validation: 0.2775016955277259]
	TIME [epoch: 8.47 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.277486705151884		[learning rate: 0.0014424]
	Learning Rate: 0.00144237
	LOSS [training: 0.277486705151884 | validation: 0.3080284532568681]
	TIME [epoch: 8.48 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4208465037720626		[learning rate: 0.001439]
	Learning Rate: 0.00143897
	LOSS [training: 0.4208465037720626 | validation: 0.26225635865730157]
	TIME [epoch: 8.48 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37463991565097476		[learning rate: 0.0014356]
	Learning Rate: 0.00143557
	LOSS [training: 0.37463991565097476 | validation: 0.4238253046426199]
	TIME [epoch: 8.49 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2838878345710939		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.2838878345710939 | validation: 0.2756961324488399]
	TIME [epoch: 8.47 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34082445103364545		[learning rate: 0.0014288]
	Learning Rate: 0.00142881
	LOSS [training: 0.34082445103364545 | validation: 0.9532383583675221]
	TIME [epoch: 8.47 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7796708084969982		[learning rate: 0.0014254]
	Learning Rate: 0.00142544
	LOSS [training: 0.7796708084969982 | validation: 0.5122360865522118]
	TIME [epoch: 8.49 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34357613955228067		[learning rate: 0.0014221]
	Learning Rate: 0.00142208
	LOSS [training: 0.34357613955228067 | validation: 0.367207212520982]
	TIME [epoch: 8.48 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.345443804993952		[learning rate: 0.0014187]
	Learning Rate: 0.00141872
	LOSS [training: 0.345443804993952 | validation: 0.2791858237556686]
	TIME [epoch: 8.47 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4318770380678515		[learning rate: 0.0014154]
	Learning Rate: 0.00141538
	LOSS [training: 0.4318770380678515 | validation: 0.43253708433026367]
	TIME [epoch: 8.48 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3221633736601016		[learning rate: 0.001412]
	Learning Rate: 0.00141204
	LOSS [training: 0.3221633736601016 | validation: 0.2402631369294156]
	TIME [epoch: 8.48 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3306806586194785		[learning rate: 0.0014087]
	Learning Rate: 0.00140871
	LOSS [training: 0.3306806586194785 | validation: 0.3309659528869589]
	TIME [epoch: 8.48 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3161268636778174		[learning rate: 0.0014054]
	Learning Rate: 0.00140538
	LOSS [training: 0.3161268636778174 | validation: 0.3699038654385989]
	TIME [epoch: 8.47 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.367218556264404		[learning rate: 0.0014021]
	Learning Rate: 0.00140207
	LOSS [training: 0.367218556264404 | validation: 0.2062606435724499]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_882.pth
	Model improved!!!
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4290410567897231		[learning rate: 0.0013988]
	Learning Rate: 0.00139876
	LOSS [training: 0.4290410567897231 | validation: 0.27282264963262703]
	TIME [epoch: 8.48 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30190292953845776		[learning rate: 0.0013955]
	Learning Rate: 0.00139546
	LOSS [training: 0.30190292953845776 | validation: 0.3665756158235636]
	TIME [epoch: 8.49 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25136124027003026		[learning rate: 0.0013922]
	Learning Rate: 0.00139217
	LOSS [training: 0.25136124027003026 | validation: 0.29240390291486207]
	TIME [epoch: 8.47 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3164152471820266		[learning rate: 0.0013889]
	Learning Rate: 0.00138889
	LOSS [training: 0.3164152471820266 | validation: 0.395157703899361]
	TIME [epoch: 8.48 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32847498985762724		[learning rate: 0.0013856]
	Learning Rate: 0.00138561
	LOSS [training: 0.32847498985762724 | validation: 0.32814669533232327]
	TIME [epoch: 8.51 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4016661830956486		[learning rate: 0.0013823]
	Learning Rate: 0.00138234
	LOSS [training: 0.4016661830956486 | validation: 0.28037380773325093]
	TIME [epoch: 8.49 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31854601000150107		[learning rate: 0.0013791]
	Learning Rate: 0.00137908
	LOSS [training: 0.31854601000150107 | validation: 0.38778117026955805]
	TIME [epoch: 8.48 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3261628851116996		[learning rate: 0.0013758]
	Learning Rate: 0.00137583
	LOSS [training: 0.3261628851116996 | validation: 0.5473030759336028]
	TIME [epoch: 8.48 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40319717924613807		[learning rate: 0.0013726]
	Learning Rate: 0.00137258
	LOSS [training: 0.40319717924613807 | validation: 0.3950333505669557]
	TIME [epoch: 8.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49647193861082906		[learning rate: 0.0013693]
	Learning Rate: 0.00136934
	LOSS [training: 0.49647193861082906 | validation: 0.3576101021795465]
	TIME [epoch: 8.48 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.390380306605672		[learning rate: 0.0013661]
	Learning Rate: 0.00136611
	LOSS [training: 0.390380306605672 | validation: 0.38092114928097054]
	TIME [epoch: 8.48 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3689443442792396		[learning rate: 0.0013629]
	Learning Rate: 0.00136289
	LOSS [training: 0.3689443442792396 | validation: 0.4405848428645268]
	TIME [epoch: 8.49 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3816510612519449		[learning rate: 0.0013597]
	Learning Rate: 0.00135968
	LOSS [training: 0.3816510612519449 | validation: 0.2909277327171821]
	TIME [epoch: 8.51 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3132566203126832		[learning rate: 0.0013565]
	Learning Rate: 0.00135647
	LOSS [training: 0.3132566203126832 | validation: 0.32426054028636153]
	TIME [epoch: 8.47 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36272434551369315		[learning rate: 0.0013533]
	Learning Rate: 0.00135327
	LOSS [training: 0.36272434551369315 | validation: 0.27315373372863566]
	TIME [epoch: 8.48 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32626063781216585		[learning rate: 0.0013501]
	Learning Rate: 0.00135008
	LOSS [training: 0.32626063781216585 | validation: 0.3066918734300139]
	TIME [epoch: 8.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36043704434985163		[learning rate: 0.0013469]
	Learning Rate: 0.00134689
	LOSS [training: 0.36043704434985163 | validation: 0.27053987562363957]
	TIME [epoch: 8.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25834274770336424		[learning rate: 0.0013437]
	Learning Rate: 0.00134372
	LOSS [training: 0.25834274770336424 | validation: 0.2499140798422734]
	TIME [epoch: 8.49 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2367233690939102		[learning rate: 0.0013405]
	Learning Rate: 0.00134055
	LOSS [training: 0.2367233690939102 | validation: 0.24864677446923636]
	TIME [epoch: 8.48 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2855764586848431		[learning rate: 0.0013374]
	Learning Rate: 0.00133738
	LOSS [training: 0.2855764586848431 | validation: 0.38037240179114457]
	TIME [epoch: 8.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36111623725362013		[learning rate: 0.0013342]
	Learning Rate: 0.00133423
	LOSS [training: 0.36111623725362013 | validation: 0.27815282915721795]
	TIME [epoch: 8.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23798991579445006		[learning rate: 0.0013311]
	Learning Rate: 0.00133108
	LOSS [training: 0.23798991579445006 | validation: 0.20559893533351814]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_904.pth
	Model improved!!!
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22843679415222273		[learning rate: 0.0013279]
	Learning Rate: 0.00132794
	LOSS [training: 0.22843679415222273 | validation: 0.24163747140085928]
	TIME [epoch: 8.49 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3093475411393713		[learning rate: 0.0013248]
	Learning Rate: 0.00132481
	LOSS [training: 0.3093475411393713 | validation: 0.3542396517226552]
	TIME [epoch: 8.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35024301448481754		[learning rate: 0.0013217]
	Learning Rate: 0.00132169
	LOSS [training: 0.35024301448481754 | validation: 0.42641983920060433]
	TIME [epoch: 8.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33685536637734714		[learning rate: 0.0013186]
	Learning Rate: 0.00131857
	LOSS [training: 0.33685536637734714 | validation: 0.36297073349563325]
	TIME [epoch: 8.48 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4899694546372479		[learning rate: 0.0013155]
	Learning Rate: 0.00131546
	LOSS [training: 0.4899694546372479 | validation: 0.30601346697740534]
	TIME [epoch: 8.47 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27422816229082403		[learning rate: 0.0013124]
	Learning Rate: 0.00131235
	LOSS [training: 0.27422816229082403 | validation: 0.34902050729597484]
	TIME [epoch: 8.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41845396347290575		[learning rate: 0.0013093]
	Learning Rate: 0.00130926
	LOSS [training: 0.41845396347290575 | validation: 0.34212285405048837]
	TIME [epoch: 8.49 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44687429422081937		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.44687429422081937 | validation: 0.41590989805442924]
	TIME [epoch: 8.47 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39268119263978113		[learning rate: 0.0013031]
	Learning Rate: 0.00130309
	LOSS [training: 0.39268119263978113 | validation: 0.3709161916678426]
	TIME [epoch: 8.48 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35722392643699735		[learning rate: 0.0013]
	Learning Rate: 0.00130002
	LOSS [training: 0.35722392643699735 | validation: 0.44454247078026277]
	TIME [epoch: 8.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4439932751749048		[learning rate: 0.0012969]
	Learning Rate: 0.00129695
	LOSS [training: 0.4439932751749048 | validation: 0.3736990094625376]
	TIME [epoch: 8.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4165748242761966		[learning rate: 0.0012939]
	Learning Rate: 0.00129389
	LOSS [training: 0.4165748242761966 | validation: 0.3718708864100566]
	TIME [epoch: 8.48 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.447823101656072		[learning rate: 0.0012908]
	Learning Rate: 0.00129084
	LOSS [training: 0.447823101656072 | validation: 0.4977918195625217]
	TIME [epoch: 8.48 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38884223880233715		[learning rate: 0.0012878]
	Learning Rate: 0.00128779
	LOSS [training: 0.38884223880233715 | validation: 0.344153116858262]
	TIME [epoch: 8.52 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33691989249606874		[learning rate: 0.0012848]
	Learning Rate: 0.00128476
	LOSS [training: 0.33691989249606874 | validation: 0.26650307404076207]
	TIME [epoch: 8.49 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.338939187935185		[learning rate: 0.0012817]
	Learning Rate: 0.00128173
	LOSS [training: 0.338939187935185 | validation: 0.44631249115330823]
	TIME [epoch: 8.48 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36758277262615346		[learning rate: 0.0012787]
	Learning Rate: 0.0012787
	LOSS [training: 0.36758277262615346 | validation: 0.35701932023515237]
	TIME [epoch: 8.47 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4047688267815448		[learning rate: 0.0012757]
	Learning Rate: 0.00127569
	LOSS [training: 0.4047688267815448 | validation: 0.32672954703974527]
	TIME [epoch: 8.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30128022635796514		[learning rate: 0.0012727]
	Learning Rate: 0.00127268
	LOSS [training: 0.30128022635796514 | validation: 0.33193262850637806]
	TIME [epoch: 8.49 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2539398094103238		[learning rate: 0.0012697]
	Learning Rate: 0.00126967
	LOSS [training: 0.2539398094103238 | validation: 0.26945435610291935]
	TIME [epoch: 8.47 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26752366069804473		[learning rate: 0.0012667]
	Learning Rate: 0.00126668
	LOSS [training: 0.26752366069804473 | validation: 0.482377469485895]
	TIME [epoch: 8.47 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4107576380886937		[learning rate: 0.0012637]
	Learning Rate: 0.00126369
	LOSS [training: 0.4107576380886937 | validation: 0.37898549243621144]
	TIME [epoch: 8.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3083961471296104		[learning rate: 0.0012607]
	Learning Rate: 0.00126071
	LOSS [training: 0.3083961471296104 | validation: 0.4742765257397135]
	TIME [epoch: 8.48 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3055901613834724		[learning rate: 0.0012577]
	Learning Rate: 0.00125774
	LOSS [training: 0.3055901613834724 | validation: 0.29385260718283746]
	TIME [epoch: 8.47 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2770886999532351		[learning rate: 0.0012548]
	Learning Rate: 0.00125477
	LOSS [training: 0.2770886999532351 | validation: 0.23725383101823727]
	TIME [epoch: 8.47 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26246530459552725		[learning rate: 0.0012518]
	Learning Rate: 0.00125181
	LOSS [training: 0.26246530459552725 | validation: 0.34059600440785737]
	TIME [epoch: 8.51 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3158215810821621		[learning rate: 0.0012489]
	Learning Rate: 0.00124886
	LOSS [training: 0.3158215810821621 | validation: 0.33370185747365466]
	TIME [epoch: 8.47 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3350762685417516		[learning rate: 0.0012459]
	Learning Rate: 0.00124591
	LOSS [training: 0.3350762685417516 | validation: 0.4273688858612237]
	TIME [epoch: 8.47 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3470217386943007		[learning rate: 0.001243]
	Learning Rate: 0.00124297
	LOSS [training: 0.3470217386943007 | validation: 0.34500354500957453]
	TIME [epoch: 8.47 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2854602594380479		[learning rate: 0.00124]
	Learning Rate: 0.00124004
	LOSS [training: 0.2854602594380479 | validation: 0.23648480682391176]
	TIME [epoch: 8.52 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24334400545443485		[learning rate: 0.0012371]
	Learning Rate: 0.00123712
	LOSS [training: 0.24334400545443485 | validation: 0.2900757215478011]
	TIME [epoch: 8.48 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3225984297684351		[learning rate: 0.0012342]
	Learning Rate: 0.0012342
	LOSS [training: 0.3225984297684351 | validation: 0.300420426809339]
	TIME [epoch: 8.46 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23528244439006185		[learning rate: 0.0012313]
	Learning Rate: 0.00123129
	LOSS [training: 0.23528244439006185 | validation: 0.35381820889474824]
	TIME [epoch: 8.49 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3442503991382629		[learning rate: 0.0012284]
	Learning Rate: 0.00122838
	LOSS [training: 0.3442503991382629 | validation: 0.24678090990729462]
	TIME [epoch: 8.5 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2873846235197122		[learning rate: 0.0012255]
	Learning Rate: 0.00122548
	LOSS [training: 0.2873846235197122 | validation: 0.34755038227185625]
	TIME [epoch: 8.47 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30775480187435067		[learning rate: 0.0012226]
	Learning Rate: 0.00122259
	LOSS [training: 0.30775480187435067 | validation: 0.3138433970090009]
	TIME [epoch: 8.49 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3518765035365051		[learning rate: 0.0012197]
	Learning Rate: 0.00121971
	LOSS [training: 0.3518765035365051 | validation: 0.2953469649534535]
	TIME [epoch: 8.49 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4236650111323832		[learning rate: 0.0012168]
	Learning Rate: 0.00121683
	LOSS [training: 0.4236650111323832 | validation: 0.42177679840320276]
	TIME [epoch: 8.48 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45013440610776945		[learning rate: 0.001214]
	Learning Rate: 0.00121396
	LOSS [training: 0.45013440610776945 | validation: 0.327684204401256]
	TIME [epoch: 8.49 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37787820564199215		[learning rate: 0.0012111]
	Learning Rate: 0.0012111
	LOSS [training: 0.37787820564199215 | validation: 0.21781296397409866]
	TIME [epoch: 8.47 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36727491411538205		[learning rate: 0.0012082]
	Learning Rate: 0.00120824
	LOSS [training: 0.36727491411538205 | validation: 0.28897261241424954]
	TIME [epoch: 8.49 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2759702111638411		[learning rate: 0.0012054]
	Learning Rate: 0.00120539
	LOSS [training: 0.2759702111638411 | validation: 0.21978301636811365]
	TIME [epoch: 8.48 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28241246734549436		[learning rate: 0.0012025]
	Learning Rate: 0.00120255
	LOSS [training: 0.28241246734549436 | validation: 0.2845287387277308]
	TIME [epoch: 8.47 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36382389523525344		[learning rate: 0.0011997]
	Learning Rate: 0.00119971
	LOSS [training: 0.36382389523525344 | validation: 0.4247332864540978]
	TIME [epoch: 8.47 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31434928258870554		[learning rate: 0.0011969]
	Learning Rate: 0.00119688
	LOSS [training: 0.31434928258870554 | validation: 0.257369147728857]
	TIME [epoch: 8.51 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2513945754625586		[learning rate: 0.0011941]
	Learning Rate: 0.00119406
	LOSS [training: 0.2513945754625586 | validation: 0.453764104647766]
	TIME [epoch: 8.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3270239378292795		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.3270239378292795 | validation: 0.33036874252913656]
	TIME [epoch: 8.47 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.310290309311243		[learning rate: 0.0011884]
	Learning Rate: 0.00118843
	LOSS [training: 0.310290309311243 | validation: 0.2886273731134784]
	TIME [epoch: 8.47 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29315776491029216		[learning rate: 0.0011856]
	Learning Rate: 0.00118563
	LOSS [training: 0.29315776491029216 | validation: 0.23797558621705595]
	TIME [epoch: 8.51 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23056743014306727		[learning rate: 0.0011828]
	Learning Rate: 0.00118283
	LOSS [training: 0.23056743014306727 | validation: 0.25779188378903295]
	TIME [epoch: 8.48 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26953226339109543		[learning rate: 0.00118]
	Learning Rate: 0.00118004
	LOSS [training: 0.26953226339109543 | validation: 0.5026865771654846]
	TIME [epoch: 8.48 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3333003349299774		[learning rate: 0.0011773]
	Learning Rate: 0.00117726
	LOSS [training: 0.3333003349299774 | validation: 0.34598442208173663]
	TIME [epoch: 8.47 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2845426968191216		[learning rate: 0.0011745]
	Learning Rate: 0.00117448
	LOSS [training: 0.2845426968191216 | validation: 0.3084437760568706]
	TIME [epoch: 8.51 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2834103421108116		[learning rate: 0.0011717]
	Learning Rate: 0.00117171
	LOSS [training: 0.2834103421108116 | validation: 0.2327546082358634]
	TIME [epoch: 8.48 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3104646527304401		[learning rate: 0.0011689]
	Learning Rate: 0.00116895
	LOSS [training: 0.3104646527304401 | validation: 0.3665490713166405]
	TIME [epoch: 8.47 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.317135269188547		[learning rate: 0.0011662]
	Learning Rate: 0.00116619
	LOSS [training: 0.317135269188547 | validation: 0.33820258967365685]
	TIME [epoch: 8.47 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29898476161144394		[learning rate: 0.0011634]
	Learning Rate: 0.00116344
	LOSS [training: 0.29898476161144394 | validation: 0.24188270779088658]
	TIME [epoch: 8.51 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24034980296304614		[learning rate: 0.0011607]
	Learning Rate: 0.00116069
	LOSS [training: 0.24034980296304614 | validation: 0.21571668259498725]
	TIME [epoch: 8.48 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3344789183601239		[learning rate: 0.001158]
	Learning Rate: 0.00115796
	LOSS [training: 0.3344789183601239 | validation: 0.26779013740334007]
	TIME [epoch: 8.48 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30670978335051513		[learning rate: 0.0011552]
	Learning Rate: 0.00115523
	LOSS [training: 0.30670978335051513 | validation: 0.2735954267319455]
	TIME [epoch: 8.48 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2539898280336822		[learning rate: 0.0011525]
	Learning Rate: 0.0011525
	LOSS [training: 0.2539898280336822 | validation: 0.2679790959812206]
	TIME [epoch: 8.52 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30922998523774564		[learning rate: 0.0011498]
	Learning Rate: 0.00114978
	LOSS [training: 0.30922998523774564 | validation: 0.4170915045246426]
	TIME [epoch: 8.49 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3477326275138009		[learning rate: 0.0011471]
	Learning Rate: 0.00114707
	LOSS [training: 0.3477326275138009 | validation: 0.24214141586141438]
	TIME [epoch: 8.47 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3078103305826896		[learning rate: 0.0011444]
	Learning Rate: 0.00114436
	LOSS [training: 0.3078103305826896 | validation: 0.21188222640175994]
	TIME [epoch: 8.47 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.300351011776655		[learning rate: 0.0011417]
	Learning Rate: 0.00114166
	LOSS [training: 0.300351011776655 | validation: 0.27398287914281444]
	TIME [epoch: 8.52 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32855607919795793		[learning rate: 0.001139]
	Learning Rate: 0.00113897
	LOSS [training: 0.32855607919795793 | validation: 0.30183332838766685]
	TIME [epoch: 8.48 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40908480600772307		[learning rate: 0.0011363]
	Learning Rate: 0.00113628
	LOSS [training: 0.40908480600772307 | validation: 0.26048408946740725]
	TIME [epoch: 8.47 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37968069685990474		[learning rate: 0.0011336]
	Learning Rate: 0.0011336
	LOSS [training: 0.37968069685990474 | validation: 0.33826467227737206]
	TIME [epoch: 8.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4194093794106034		[learning rate: 0.0011309]
	Learning Rate: 0.00113093
	LOSS [training: 0.4194093794106034 | validation: 0.30068121722347807]
	TIME [epoch: 8.51 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29245065480967036		[learning rate: 0.0011283]
	Learning Rate: 0.00112826
	LOSS [training: 0.29245065480967036 | validation: 0.24409376903660002]
	TIME [epoch: 8.48 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6384051613213293		[learning rate: 0.0011256]
	Learning Rate: 0.0011256
	LOSS [training: 0.6384051613213293 | validation: 0.7656233820291274]
	TIME [epoch: 8.48 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33384741961754		[learning rate: 0.0011229]
	Learning Rate: 0.00112295
	LOSS [training: 0.33384741961754 | validation: 0.21190475159454064]
	TIME [epoch: 8.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22049173208600367		[learning rate: 0.0011203]
	Learning Rate: 0.0011203
	LOSS [training: 0.22049173208600367 | validation: 0.3015936840950444]
	TIME [epoch: 8.51 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2683693099706273		[learning rate: 0.0011177]
	Learning Rate: 0.00111765
	LOSS [training: 0.2683693099706273 | validation: 0.21281052232844105]
	TIME [epoch: 8.48 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2125993142379174		[learning rate: 0.001115]
	Learning Rate: 0.00111502
	LOSS [training: 0.2125993142379174 | validation: 0.21391595558423093]
	TIME [epoch: 8.47 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24419874968512584		[learning rate: 0.0011124]
	Learning Rate: 0.00111239
	LOSS [training: 0.24419874968512584 | validation: 0.27032213753709]
	TIME [epoch: 8.49 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2353021343247653		[learning rate: 0.0011098]
	Learning Rate: 0.00110976
	LOSS [training: 0.2353021343247653 | validation: 0.2629265300158189]
	TIME [epoch: 8.49 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3166706049699161		[learning rate: 0.0011071]
	Learning Rate: 0.00110715
	LOSS [training: 0.3166706049699161 | validation: 0.29303172692256124]
	TIME [epoch: 8.49 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3144760240243233		[learning rate: 0.0011045]
	Learning Rate: 0.00110453
	LOSS [training: 0.3144760240243233 | validation: 0.339163569528547]
	TIME [epoch: 8.47 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36507955855769225		[learning rate: 0.0011019]
	Learning Rate: 0.00110193
	LOSS [training: 0.36507955855769225 | validation: 0.3797616487312117]
	TIME [epoch: 8.49 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3182594225206724		[learning rate: 0.0010993]
	Learning Rate: 0.00109933
	LOSS [training: 0.3182594225206724 | validation: 0.3775394813372537]
	TIME [epoch: 8.49 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2850154097398486		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.2850154097398486 | validation: 0.2359309402057364]
	TIME [epoch: 8.47 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33893171994555793		[learning rate: 0.0010942]
	Learning Rate: 0.00109415
	LOSS [training: 0.33893171994555793 | validation: 0.3294457530548486]
	TIME [epoch: 8.48 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28098837810692906		[learning rate: 0.0010916]
	Learning Rate: 0.00109157
	LOSS [training: 0.28098837810692906 | validation: 0.23774552755546746]
	TIME [epoch: 8.49 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23866392603882997		[learning rate: 0.001089]
	Learning Rate: 0.00108899
	LOSS [training: 0.23866392603882997 | validation: 0.257947994480896]
	TIME [epoch: 8.48 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23980094599736104		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.23980094599736104 | validation: 0.25588818324361795]
	TIME [epoch: 8.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2895431690897168		[learning rate: 0.0010839]
	Learning Rate: 0.00108386
	LOSS [training: 0.2895431690897168 | validation: 0.22226944550627037]
	TIME [epoch: 8.48 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21928703099608432		[learning rate: 0.0010813]
	Learning Rate: 0.00108131
	LOSS [training: 0.21928703099608432 | validation: 0.23926892630203234]
	TIME [epoch: 8.49 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2494201768954214		[learning rate: 0.0010788]
	Learning Rate: 0.00107876
	LOSS [training: 0.2494201768954214 | validation: 0.44303474993843794]
	TIME [epoch: 8.47 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.349046829134144		[learning rate: 0.0010762]
	Learning Rate: 0.00107621
	LOSS [training: 0.349046829134144 | validation: 0.22879328227722961]
	TIME [epoch: 8.49 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2204030146880675		[learning rate: 0.0010737]
	Learning Rate: 0.00107367
	LOSS [training: 0.2204030146880675 | validation: 0.2617428712519567]
	TIME [epoch: 8.47 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2643304918272761		[learning rate: 0.0010711]
	Learning Rate: 0.00107114
	LOSS [training: 0.2643304918272761 | validation: 0.24528259602082367]
	TIME [epoch: 8.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3228100125443428		[learning rate: 0.0010686]
	Learning Rate: 0.00106861
	LOSS [training: 0.3228100125443428 | validation: 0.3323230302745785]
	TIME [epoch: 8.48 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2537519047243702		[learning rate: 0.0010661]
	Learning Rate: 0.00106609
	LOSS [training: 0.2537519047243702 | validation: 0.22554999097094086]
	TIME [epoch: 8.49 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2818261767359299		[learning rate: 0.0010636]
	Learning Rate: 0.00106358
	LOSS [training: 0.2818261767359299 | validation: 0.3967187000722334]
	TIME [epoch: 8.47 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3232961484968969		[learning rate: 0.0010611]
	Learning Rate: 0.00106107
	LOSS [training: 0.3232961484968969 | validation: 0.24161695631670493]
	TIME [epoch: 8.49 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49708399285686766		[learning rate: 0.0010586]
	Learning Rate: 0.00105857
	LOSS [training: 0.49708399285686766 | validation: 0.2934112040506681]
	TIME [epoch: 8.48 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22346516189593352		[learning rate: 0.0010561]
	Learning Rate: 0.00105607
	LOSS [training: 0.22346516189593352 | validation: 0.22984842455549634]
	TIME [epoch: 8.47 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23662471947775088		[learning rate: 0.0010536]
	Learning Rate: 0.00105358
	LOSS [training: 0.23662471947775088 | validation: 0.28450064502276906]
	TIME [epoch: 8.47 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2690054200602162		[learning rate: 0.0010511]
	Learning Rate: 0.00105109
	LOSS [training: 0.2690054200602162 | validation: 0.34753246219272804]
	TIME [epoch: 8.49 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3526529744846246		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.3526529744846246 | validation: 0.2469766360694483]
	TIME [epoch: 8.48 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24598515898976975		[learning rate: 0.0010461]
	Learning Rate: 0.00104614
	LOSS [training: 0.24598515898976975 | validation: 0.20055211586912886]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1006.pth
	Model improved!!!
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24309553185687466		[learning rate: 0.0010437]
	Learning Rate: 0.00104367
	LOSS [training: 0.24309553185687466 | validation: 0.21693438039990537]
	TIME [epoch: 8.48 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23936375532608506		[learning rate: 0.0010412]
	Learning Rate: 0.00104121
	LOSS [training: 0.23936375532608506 | validation: 0.26705037264031606]
	TIME [epoch: 8.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3205627978574787		[learning rate: 0.0010388]
	Learning Rate: 0.00103875
	LOSS [training: 0.3205627978574787 | validation: 0.2000797905697316]
	TIME [epoch: 8.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1009.pth
	Model improved!!!
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2568828753345171		[learning rate: 0.0010363]
	Learning Rate: 0.0010363
	LOSS [training: 0.2568828753345171 | validation: 0.22720812857314543]
	TIME [epoch: 8.47 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3475211810212132		[learning rate: 0.0010339]
	Learning Rate: 0.00103386
	LOSS [training: 0.3475211810212132 | validation: 0.33650964726403443]
	TIME [epoch: 8.48 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3157874643915806		[learning rate: 0.0010314]
	Learning Rate: 0.00103142
	LOSS [training: 0.3157874643915806 | validation: 0.309345220930365]
	TIME [epoch: 8.49 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3011764885723123		[learning rate: 0.001029]
	Learning Rate: 0.00102899
	LOSS [training: 0.3011764885723123 | validation: 0.21969562477940763]
	TIME [epoch: 8.48 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2902264340459953		[learning rate: 0.0010266]
	Learning Rate: 0.00102656
	LOSS [training: 0.2902264340459953 | validation: 0.4067834530668951]
	TIME [epoch: 8.49 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35309280389496367		[learning rate: 0.0010241]
	Learning Rate: 0.00102414
	LOSS [training: 0.35309280389496367 | validation: 0.24235902664101225]
	TIME [epoch: 8.48 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2155840602916675		[learning rate: 0.0010217]
	Learning Rate: 0.00102172
	LOSS [training: 0.2155840602916675 | validation: 0.22708365018286067]
	TIME [epoch: 8.48 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2878981156910268		[learning rate: 0.0010193]
	Learning Rate: 0.00101931
	LOSS [training: 0.2878981156910268 | validation: 0.22383070983661013]
	TIME [epoch: 8.47 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3856975677100545		[learning rate: 0.0010169]
	Learning Rate: 0.00101691
	LOSS [training: 0.3856975677100545 | validation: 0.2801399071448022]
	TIME [epoch: 8.48 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21615332556439792		[learning rate: 0.0010145]
	Learning Rate: 0.00101451
	LOSS [training: 0.21615332556439792 | validation: 0.3440089056649823]
	TIME [epoch: 8.47 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3215477749996347		[learning rate: 0.0010121]
	Learning Rate: 0.00101212
	LOSS [training: 0.3215477749996347 | validation: 0.36931779123826197]
	TIME [epoch: 8.49 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3898244061565137		[learning rate: 0.0010097]
	Learning Rate: 0.00100973
	LOSS [training: 0.3898244061565137 | validation: 0.2602605420024695]
	TIME [epoch: 8.48 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25161922371153683		[learning rate: 0.0010073]
	Learning Rate: 0.00100735
	LOSS [training: 0.25161922371153683 | validation: 0.21146904867377947]
	TIME [epoch: 8.49 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2972641242867239		[learning rate: 0.001005]
	Learning Rate: 0.00100497
	LOSS [training: 0.2972641242867239 | validation: 0.32885664755786564]
	TIME [epoch: 8.47 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2596184412107485		[learning rate: 0.0010026]
	Learning Rate: 0.0010026
	LOSS [training: 0.2596184412107485 | validation: 0.2460766357865448]
	TIME [epoch: 8.49 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22988232992272603		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.22988232992272603 | validation: 0.25121715391560584]
	TIME [epoch: 8.48 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26176517061551546		[learning rate: 0.00099788]
	Learning Rate: 0.000997877
	LOSS [training: 0.26176517061551546 | validation: 0.19523292809327036]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1026.pth
	Model improved!!!
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36987458883275887		[learning rate: 0.00099552]
	Learning Rate: 0.000995523
	LOSS [training: 0.36987458883275887 | validation: 0.4620533328327366]
	TIME [epoch: 8.46 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29090085903877516		[learning rate: 0.00099317]
	Learning Rate: 0.000993175
	LOSS [training: 0.29090085903877516 | validation: 0.19796010608174747]
	TIME [epoch: 8.49 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26648955097600846		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.26648955097600846 | validation: 0.3756606419757821]
	TIME [epoch: 8.48 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27801270636359154		[learning rate: 0.00098849]
	Learning Rate: 0.000988495
	LOSS [training: 0.27801270636359154 | validation: 0.20852194591761547]
	TIME [epoch: 8.46 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21998279734217743		[learning rate: 0.00098616]
	Learning Rate: 0.000986163
	LOSS [training: 0.21998279734217743 | validation: 0.3294504836901332]
	TIME [epoch: 8.46 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3430359015211985		[learning rate: 0.00098384]
	Learning Rate: 0.000983837
	LOSS [training: 0.3430359015211985 | validation: 0.21405793942399082]
	TIME [epoch: 8.48 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2684993992613598		[learning rate: 0.00098152]
	Learning Rate: 0.000981516
	LOSS [training: 0.2684993992613598 | validation: 0.33551966869516886]
	TIME [epoch: 8.48 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31055292956102415		[learning rate: 0.0009792]
	Learning Rate: 0.000979201
	LOSS [training: 0.31055292956102415 | validation: 0.32184340252073573]
	TIME [epoch: 8.47 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23763090130370473		[learning rate: 0.00097689]
	Learning Rate: 0.000976891
	LOSS [training: 0.23763090130370473 | validation: 0.2015599940438445]
	TIME [epoch: 8.46 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23927543901259046		[learning rate: 0.00097459]
	Learning Rate: 0.000974587
	LOSS [training: 0.23927543901259046 | validation: 0.18891574958719365]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1036.pth
	Model improved!!!
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24262318426191695		[learning rate: 0.00097229]
	Learning Rate: 0.000972288
	LOSS [training: 0.24262318426191695 | validation: 0.20430511259450052]
	TIME [epoch: 8.51 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3113306919886562		[learning rate: 0.00096999]
	Learning Rate: 0.000969994
	LOSS [training: 0.3113306919886562 | validation: 0.20769602885864336]
	TIME [epoch: 8.48 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2626216692502875		[learning rate: 0.00096771]
	Learning Rate: 0.000967706
	LOSS [training: 0.2626216692502875 | validation: 0.5343363580154937]
	TIME [epoch: 8.48 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4524881032778142		[learning rate: 0.00096542]
	Learning Rate: 0.000965424
	LOSS [training: 0.4524881032778142 | validation: 0.26589321295333723]
	TIME [epoch: 8.51 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3446072893432017		[learning rate: 0.00096315]
	Learning Rate: 0.000963146
	LOSS [training: 0.3446072893432017 | validation: 0.2926782678730288]
	TIME [epoch: 8.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23778785712637768		[learning rate: 0.00096087]
	Learning Rate: 0.000960874
	LOSS [training: 0.23778785712637768 | validation: 0.21463703500676362]
	TIME [epoch: 8.48 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22938415830278197		[learning rate: 0.00095861]
	Learning Rate: 0.000958608
	LOSS [training: 0.22938415830278197 | validation: 0.2694714772767458]
	TIME [epoch: 8.48 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24718185255010544		[learning rate: 0.00095635]
	Learning Rate: 0.000956347
	LOSS [training: 0.24718185255010544 | validation: 0.21110754489103611]
	TIME [epoch: 8.51 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20617239035076934		[learning rate: 0.00095409]
	Learning Rate: 0.000954091
	LOSS [training: 0.20617239035076934 | validation: 0.21684342561817857]
	TIME [epoch: 8.49 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21328235088918004		[learning rate: 0.00095184]
	Learning Rate: 0.00095184
	LOSS [training: 0.21328235088918004 | validation: 0.2064761170567462]
	TIME [epoch: 8.49 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1972617057707253		[learning rate: 0.0009496]
	Learning Rate: 0.000949595
	LOSS [training: 0.1972617057707253 | validation: 0.20087927350426177]
	TIME [epoch: 8.48 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2461357545790685		[learning rate: 0.00094736]
	Learning Rate: 0.000947355
	LOSS [training: 0.2461357545790685 | validation: 0.2971795929751907]
	TIME [epoch: 8.53 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30971489291781606		[learning rate: 0.00094512]
	Learning Rate: 0.000945121
	LOSS [training: 0.30971489291781606 | validation: 0.5683357712344947]
	TIME [epoch: 8.49 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31062524254758006		[learning rate: 0.00094289]
	Learning Rate: 0.000942891
	LOSS [training: 0.31062524254758006 | validation: 0.18565302340792106]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1050.pth
	Model improved!!!
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27461332564960744		[learning rate: 0.00094067]
	Learning Rate: 0.000940667
	LOSS [training: 0.27461332564960744 | validation: 0.39351430847010127]
	TIME [epoch: 8.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33624254452854385		[learning rate: 0.00093845]
	Learning Rate: 0.000938448
	LOSS [training: 0.33624254452854385 | validation: 0.4269031721479606]
	TIME [epoch: 8.51 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2556113576542785		[learning rate: 0.00093623]
	Learning Rate: 0.000936234
	LOSS [training: 0.2556113576542785 | validation: 0.20424095768987394]
	TIME [epoch: 8.48 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21122722570155966		[learning rate: 0.00093403]
	Learning Rate: 0.000934026
	LOSS [training: 0.21122722570155966 | validation: 0.3719071911155396]
	TIME [epoch: 8.48 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28799652302731704		[learning rate: 0.00093182]
	Learning Rate: 0.000931823
	LOSS [training: 0.28799652302731704 | validation: 0.2954200950940543]
	TIME [epoch: 8.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28753439027229283		[learning rate: 0.00092962]
	Learning Rate: 0.000929625
	LOSS [training: 0.28753439027229283 | validation: 0.19210238608954755]
	TIME [epoch: 8.52 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28714177450701606		[learning rate: 0.00092743]
	Learning Rate: 0.000927432
	LOSS [training: 0.28714177450701606 | validation: 0.26093473040959536]
	TIME [epoch: 8.49 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26391306335522474		[learning rate: 0.00092524]
	Learning Rate: 0.000925244
	LOSS [training: 0.26391306335522474 | validation: 0.4153635369374986]
	TIME [epoch: 8.48 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3027090170738759		[learning rate: 0.00092306]
	Learning Rate: 0.000923062
	LOSS [training: 0.3027090170738759 | validation: 0.22529751800860473]
	TIME [epoch: 8.51 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21256468768115933		[learning rate: 0.00092088]
	Learning Rate: 0.000920884
	LOSS [training: 0.21256468768115933 | validation: 0.24981649616201507]
	TIME [epoch: 8.51 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28666197721479075		[learning rate: 0.00091871]
	Learning Rate: 0.000918712
	LOSS [training: 0.28666197721479075 | validation: 0.3518136437203246]
	TIME [epoch: 8.49 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34132931441917885		[learning rate: 0.00091654]
	Learning Rate: 0.000916545
	LOSS [training: 0.34132931441917885 | validation: 0.2647157868419711]
	TIME [epoch: 8.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3113650624322365		[learning rate: 0.00091438]
	Learning Rate: 0.000914383
	LOSS [training: 0.3113650624322365 | validation: 0.24532033374723503]
	TIME [epoch: 8.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2572924017520091		[learning rate: 0.00091223]
	Learning Rate: 0.000912226
	LOSS [training: 0.2572924017520091 | validation: 0.32353822714674985]
	TIME [epoch: 8.51 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3336971151828251		[learning rate: 0.00091007]
	Learning Rate: 0.000910074
	LOSS [training: 0.3336971151828251 | validation: 0.23850985882248824]
	TIME [epoch: 8.49 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2839491868586478		[learning rate: 0.00090793]
	Learning Rate: 0.000907928
	LOSS [training: 0.2839491868586478 | validation: 0.21092746466918513]
	TIME [epoch: 8.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25350400199150736		[learning rate: 0.00090579]
	Learning Rate: 0.000905786
	LOSS [training: 0.25350400199150736 | validation: 0.243427052146039]
	TIME [epoch: 8.5 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24736048701982377		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.24736048701982377 | validation: 0.22480743095930866]
	TIME [epoch: 8.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24072117199249785		[learning rate: 0.00090152]
	Learning Rate: 0.000901518
	LOSS [training: 0.24072117199249785 | validation: 0.262024575210107]
	TIME [epoch: 8.49 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30422729477274685		[learning rate: 0.00089939]
	Learning Rate: 0.000899391
	LOSS [training: 0.30422729477274685 | validation: 0.27448669208271925]
	TIME [epoch: 8.51 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2806133272046399		[learning rate: 0.00089727]
	Learning Rate: 0.00089727
	LOSS [training: 0.2806133272046399 | validation: 0.2428199955238936]
	TIME [epoch: 8.49 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24902928740313363		[learning rate: 0.00089515]
	Learning Rate: 0.000895153
	LOSS [training: 0.24902928740313363 | validation: 0.3524155690927504]
	TIME [epoch: 8.51 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25410936328787936		[learning rate: 0.00089304]
	Learning Rate: 0.000893042
	LOSS [training: 0.25410936328787936 | validation: 0.23219702780744073]
	TIME [epoch: 8.48 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23663138850436102		[learning rate: 0.00089094]
	Learning Rate: 0.000890935
	LOSS [training: 0.23663138850436102 | validation: 0.21625104933852451]
	TIME [epoch: 8.51 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22816056410601834		[learning rate: 0.00088883]
	Learning Rate: 0.000888834
	LOSS [training: 0.22816056410601834 | validation: 0.21843142389569686]
	TIME [epoch: 8.49 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20475484291610507		[learning rate: 0.00088674]
	Learning Rate: 0.000886737
	LOSS [training: 0.20475484291610507 | validation: 0.22934935157222963]
	TIME [epoch: 8.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22790931817050503		[learning rate: 0.00088465]
	Learning Rate: 0.000884645
	LOSS [training: 0.22790931817050503 | validation: 0.22576463579162814]
	TIME [epoch: 8.49 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28483563840404813		[learning rate: 0.00088256]
	Learning Rate: 0.000882559
	LOSS [training: 0.28483563840404813 | validation: 0.26540617639320474]
	TIME [epoch: 8.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2493766655572692		[learning rate: 0.00088048]
	Learning Rate: 0.000880477
	LOSS [training: 0.2493766655572692 | validation: 0.24484486449911738]
	TIME [epoch: 8.49 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.256041113316099		[learning rate: 0.0008784]
	Learning Rate: 0.0008784
	LOSS [training: 0.256041113316099 | validation: 0.1789815704573194]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1080.pth
	Model improved!!!
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25883226225265316		[learning rate: 0.00087633]
	Learning Rate: 0.000876328
	LOSS [training: 0.25883226225265316 | validation: 0.3106329039938179]
	TIME [epoch: 8.49 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3006983986329975		[learning rate: 0.00087426]
	Learning Rate: 0.000874261
	LOSS [training: 0.3006983986329975 | validation: 0.3404809793127007]
	TIME [epoch: 8.48 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2760363497186168		[learning rate: 0.0008722]
	Learning Rate: 0.000872199
	LOSS [training: 0.2760363497186168 | validation: 0.30784442605566453]
	TIME [epoch: 8.49 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31683348712055615		[learning rate: 0.00087014]
	Learning Rate: 0.000870141
	LOSS [training: 0.31683348712055615 | validation: 0.40807413618092614]
	TIME [epoch: 8.49 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4604398066039221		[learning rate: 0.00086809]
	Learning Rate: 0.000868089
	LOSS [training: 0.4604398066039221 | validation: 0.41117819844554626]
	TIME [epoch: 8.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2583654341134137		[learning rate: 0.00086604]
	Learning Rate: 0.000866041
	LOSS [training: 0.2583654341134137 | validation: 0.22943511925802973]
	TIME [epoch: 8.48 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2802749050962582		[learning rate: 0.000864]
	Learning Rate: 0.000863998
	LOSS [training: 0.2802749050962582 | validation: 0.30996174833123846]
	TIME [epoch: 8.49 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3840036200222181		[learning rate: 0.00086196]
	Learning Rate: 0.00086196
	LOSS [training: 0.3840036200222181 | validation: 0.2790591680229174]
	TIME [epoch: 8.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24838192336754403		[learning rate: 0.00085993]
	Learning Rate: 0.000859927
	LOSS [training: 0.24838192336754403 | validation: 0.2606558937029154]
	TIME [epoch: 8.52 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23934630881913446		[learning rate: 0.0008579]
	Learning Rate: 0.000857898
	LOSS [training: 0.23934630881913446 | validation: 0.24238941896206717]
	TIME [epoch: 8.48 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23267314698752767		[learning rate: 0.00085587]
	Learning Rate: 0.000855875
	LOSS [training: 0.23267314698752767 | validation: 0.20583044299029804]
	TIME [epoch: 8.49 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26233358085829783		[learning rate: 0.00085386]
	Learning Rate: 0.000853856
	LOSS [training: 0.26233358085829783 | validation: 0.27347012390761793]
	TIME [epoch: 8.51 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32039920336155825		[learning rate: 0.00085184]
	Learning Rate: 0.000851842
	LOSS [training: 0.32039920336155825 | validation: 0.49842459477907886]
	TIME [epoch: 8.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32854720832536743		[learning rate: 0.00084983]
	Learning Rate: 0.000849832
	LOSS [training: 0.32854720832536743 | validation: 0.3124933843356915]
	TIME [epoch: 8.48 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2837785843006252		[learning rate: 0.00084783]
	Learning Rate: 0.000847828
	LOSS [training: 0.2837785843006252 | validation: 0.19373431682117565]
	TIME [epoch: 8.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18870096090513336		[learning rate: 0.00084583]
	Learning Rate: 0.000845828
	LOSS [training: 0.18870096090513336 | validation: 0.2635772293674236]
	TIME [epoch: 8.52 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26493839364538796		[learning rate: 0.00084383]
	Learning Rate: 0.000843833
	LOSS [training: 0.26493839364538796 | validation: 0.2577720918053462]
	TIME [epoch: 8.49 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25206505951114544		[learning rate: 0.00084184]
	Learning Rate: 0.000841842
	LOSS [training: 0.25206505951114544 | validation: 0.3274735753045972]
	TIME [epoch: 8.48 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29337869768835556		[learning rate: 0.00083986]
	Learning Rate: 0.000839856
	LOSS [training: 0.29337869768835556 | validation: 0.43329687520369375]
	TIME [epoch: 8.5 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3416297647487707		[learning rate: 0.00083788]
	Learning Rate: 0.000837876
	LOSS [training: 0.3416297647487707 | validation: 0.2330710163131339]
	TIME [epoch: 8.52 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28591858469969644		[learning rate: 0.0008359]
	Learning Rate: 0.000835899
	LOSS [training: 0.28591858469969644 | validation: 0.2419159886236924]
	TIME [epoch: 8.49 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24476380336292594		[learning rate: 0.00083393]
	Learning Rate: 0.000833927
	LOSS [training: 0.24476380336292594 | validation: 0.2738473308860063]
	TIME [epoch: 8.49 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.385468171517099		[learning rate: 0.00083196]
	Learning Rate: 0.00083196
	LOSS [training: 0.385468171517099 | validation: 0.19380030325944442]
	TIME [epoch: 8.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23146825393120024		[learning rate: 0.00083]
	Learning Rate: 0.000829998
	LOSS [training: 0.23146825393120024 | validation: 0.18039263201997102]
	TIME [epoch: 8.52 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34471871378294805		[learning rate: 0.00082804]
	Learning Rate: 0.00082804
	LOSS [training: 0.34471871378294805 | validation: 0.4126424641928995]
	TIME [epoch: 8.49 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30394178426170926		[learning rate: 0.00082609]
	Learning Rate: 0.000826087
	LOSS [training: 0.30394178426170926 | validation: 0.2371602104603418]
	TIME [epoch: 8.48 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4291012531065078		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.4291012531065078 | validation: 0.27854450145244936]
	TIME [epoch: 8.52 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2799023887184941		[learning rate: 0.00082219]
	Learning Rate: 0.000822194
	LOSS [training: 0.2799023887184941 | validation: 0.40308686020413087]
	TIME [epoch: 8.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.294377850856702		[learning rate: 0.00082025]
	Learning Rate: 0.000820254
	LOSS [training: 0.294377850856702 | validation: 0.22608177746529273]
	TIME [epoch: 8.48 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20954685648042584		[learning rate: 0.00081832]
	Learning Rate: 0.00081832
	LOSS [training: 0.20954685648042584 | validation: 0.20778787529820314]
	TIME [epoch: 8.48 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23734478502314232		[learning rate: 0.00081639]
	Learning Rate: 0.000816389
	LOSS [training: 0.23734478502314232 | validation: 0.364699216776624]
	TIME [epoch: 8.52 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3229890903151906		[learning rate: 0.00081446]
	Learning Rate: 0.000814464
	LOSS [training: 0.3229890903151906 | validation: 0.35354885313194717]
	TIME [epoch: 8.49 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2907366124257		[learning rate: 0.00081254]
	Learning Rate: 0.000812543
	LOSS [training: 0.2907366124257 | validation: 0.2525504990456431]
	TIME [epoch: 8.48 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31909036650396944		[learning rate: 0.00081063]
	Learning Rate: 0.000810626
	LOSS [training: 0.31909036650396944 | validation: 0.29791980287911074]
	TIME [epoch: 8.47 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2547350288992415		[learning rate: 0.00080871]
	Learning Rate: 0.000808714
	LOSS [training: 0.2547350288992415 | validation: 0.29333786754202584]
	TIME [epoch: 8.51 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21580673947599993		[learning rate: 0.00080681]
	Learning Rate: 0.000806806
	LOSS [training: 0.21580673947599993 | validation: 0.2677841977721115]
	TIME [epoch: 8.49 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3547066396365044		[learning rate: 0.0008049]
	Learning Rate: 0.000804903
	LOSS [training: 0.3547066396365044 | validation: 0.3051552771928715]
	TIME [epoch: 8.48 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2727676593659047		[learning rate: 0.000803]
	Learning Rate: 0.000803004
	LOSS [training: 0.2727676593659047 | validation: 0.31070045374136357]
	TIME [epoch: 8.48 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23395711914999434		[learning rate: 0.00080111]
	Learning Rate: 0.00080111
	LOSS [training: 0.23395711914999434 | validation: 0.2995222568829836]
	TIME [epoch: 8.52 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3338850159349601		[learning rate: 0.00079922]
	Learning Rate: 0.000799221
	LOSS [training: 0.3338850159349601 | validation: 0.3533339828581924]
	TIME [epoch: 8.48 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3394056809772099		[learning rate: 0.00079734]
	Learning Rate: 0.000797335
	LOSS [training: 0.3394056809772099 | validation: 0.2683212272487946]
	TIME [epoch: 8.48 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2800872397431184		[learning rate: 0.00079545]
	Learning Rate: 0.000795454
	LOSS [training: 0.2800872397431184 | validation: 0.26705190815144164]
	TIME [epoch: 8.48 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30566011344517385		[learning rate: 0.00079358]
	Learning Rate: 0.000793578
	LOSS [training: 0.30566011344517385 | validation: 0.3007651972518978]
	TIME [epoch: 8.52 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3093811348220681		[learning rate: 0.00079171]
	Learning Rate: 0.000791706
	LOSS [training: 0.3093811348220681 | validation: 0.3817786014799411]
	TIME [epoch: 8.47 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37365548209498933		[learning rate: 0.00078984]
	Learning Rate: 0.000789839
	LOSS [training: 0.37365548209498933 | validation: 0.2993366594786565]
	TIME [epoch: 8.48 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24614488535248574		[learning rate: 0.00078798]
	Learning Rate: 0.000787976
	LOSS [training: 0.24614488535248574 | validation: 0.21487168141801125]
	TIME [epoch: 8.49 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22891602184662915		[learning rate: 0.00078612]
	Learning Rate: 0.000786117
	LOSS [training: 0.22891602184662915 | validation: 0.2578269940674838]
	TIME [epoch: 8.51 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2993977838899039		[learning rate: 0.00078426]
	Learning Rate: 0.000784263
	LOSS [training: 0.2993977838899039 | validation: 0.29156153346719293]
	TIME [epoch: 8.47 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2850944082697473		[learning rate: 0.00078241]
	Learning Rate: 0.000782413
	LOSS [training: 0.2850944082697473 | validation: 0.302533639725377]
	TIME [epoch: 8.47 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24011950923070402		[learning rate: 0.00078057]
	Learning Rate: 0.000780567
	LOSS [training: 0.24011950923070402 | validation: 0.3689381243304527]
	TIME [epoch: 8.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32164466532757663		[learning rate: 0.00077873]
	Learning Rate: 0.000778726
	LOSS [training: 0.32164466532757663 | validation: 0.23593071200329852]
	TIME [epoch: 8.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30142736081196303		[learning rate: 0.00077689]
	Learning Rate: 0.000776889
	LOSS [training: 0.30142736081196303 | validation: 0.2562711905748685]
	TIME [epoch: 8.48 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27377951324738414		[learning rate: 0.00077506]
	Learning Rate: 0.000775056
	LOSS [training: 0.27377951324738414 | validation: 0.2800380915915278]
	TIME [epoch: 8.48 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24724820951819065		[learning rate: 0.00077323]
	Learning Rate: 0.000773228
	LOSS [training: 0.24724820951819065 | validation: 0.2880816870415136]
	TIME [epoch: 8.51 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2452902480249492		[learning rate: 0.0007714]
	Learning Rate: 0.000771404
	LOSS [training: 0.2452902480249492 | validation: 0.277477769620688]
	TIME [epoch: 8.48 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25694730177263225		[learning rate: 0.00076958]
	Learning Rate: 0.000769585
	LOSS [training: 0.25694730177263225 | validation: 0.3748241806832556]
	TIME [epoch: 8.48 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.330271169031446		[learning rate: 0.00076777]
	Learning Rate: 0.000767769
	LOSS [training: 0.330271169031446 | validation: 0.24776709674024994]
	TIME [epoch: 8.48 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23698210417263593		[learning rate: 0.00076596]
	Learning Rate: 0.000765958
	LOSS [training: 0.23698210417263593 | validation: 0.36730812066753016]
	TIME [epoch: 8.52 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3055369706200273		[learning rate: 0.00076415]
	Learning Rate: 0.000764151
	LOSS [training: 0.3055369706200273 | validation: 0.3491024280479905]
	TIME [epoch: 8.49 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32847379062170534		[learning rate: 0.00076235]
	Learning Rate: 0.000762349
	LOSS [training: 0.32847379062170534 | validation: 0.2816028398450271]
	TIME [epoch: 8.48 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2782924789404092		[learning rate: 0.00076055]
	Learning Rate: 0.000760551
	LOSS [training: 0.2782924789404092 | validation: 0.307319477447143]
	TIME [epoch: 8.49 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23527082361511767		[learning rate: 0.00075876]
	Learning Rate: 0.000758757
	LOSS [training: 0.23527082361511767 | validation: 0.21335130909550382]
	TIME [epoch: 8.49 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2171452658701308		[learning rate: 0.00075697]
	Learning Rate: 0.000756967
	LOSS [training: 0.2171452658701308 | validation: 0.31927770116154863]
	TIME [epoch: 8.49 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26218448637344843		[learning rate: 0.00075518]
	Learning Rate: 0.000755181
	LOSS [training: 0.26218448637344843 | validation: 0.2551443308965614]
	TIME [epoch: 8.49 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2261205445132403		[learning rate: 0.0007534]
	Learning Rate: 0.0007534
	LOSS [training: 0.2261205445132403 | validation: 0.21062200247399554]
	TIME [epoch: 8.48 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2691520384402886		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.2691520384402886 | validation: 0.33023735415216215]
	TIME [epoch: 8.51 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21842139125144447		[learning rate: 0.00074985]
	Learning Rate: 0.00074985
	LOSS [training: 0.21842139125144447 | validation: 0.2221904918495209]
	TIME [epoch: 8.49 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2092301966176397		[learning rate: 0.00074808]
	Learning Rate: 0.000748081
	LOSS [training: 0.2092301966176397 | validation: 0.2250977268337604]
	TIME [epoch: 8.48 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21557420268330815		[learning rate: 0.00074632]
	Learning Rate: 0.000746316
	LOSS [training: 0.21557420268330815 | validation: 0.2561617085102163]
	TIME [epoch: 8.48 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24118962743578942		[learning rate: 0.00074456]
	Learning Rate: 0.000744556
	LOSS [training: 0.24118962743578942 | validation: 0.23849527536701481]
	TIME [epoch: 8.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24954402645840262		[learning rate: 0.0007428]
	Learning Rate: 0.0007428
	LOSS [training: 0.24954402645840262 | validation: 0.3628695464135784]
	TIME [epoch: 8.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3085081178282546		[learning rate: 0.00074105]
	Learning Rate: 0.000741048
	LOSS [training: 0.3085081178282546 | validation: 0.23666802684111599]
	TIME [epoch: 8.48 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23121124994311862		[learning rate: 0.0007393]
	Learning Rate: 0.0007393
	LOSS [training: 0.23121124994311862 | validation: 0.24219546243838158]
	TIME [epoch: 8.47 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24735182337391687		[learning rate: 0.00073756]
	Learning Rate: 0.000737556
	LOSS [training: 0.24735182337391687 | validation: 0.22671308878334406]
	TIME [epoch: 8.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3809607276703723		[learning rate: 0.00073582]
	Learning Rate: 0.000735816
	LOSS [training: 0.3809607276703723 | validation: 0.36834359011319484]
	TIME [epoch: 8.49 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3175773723671262		[learning rate: 0.00073408]
	Learning Rate: 0.00073408
	LOSS [training: 0.3175773723671262 | validation: 0.3238030736667919]
	TIME [epoch: 8.48 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35011586160494135		[learning rate: 0.00073235]
	Learning Rate: 0.000732349
	LOSS [training: 0.35011586160494135 | validation: 0.2684973720303984]
	TIME [epoch: 8.47 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.261987049404534		[learning rate: 0.00073062]
	Learning Rate: 0.000730621
	LOSS [training: 0.261987049404534 | validation: 0.2841138255430766]
	TIME [epoch: 8.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26130676399955977		[learning rate: 0.0007289]
	Learning Rate: 0.000728898
	LOSS [training: 0.26130676399955977 | validation: 0.2820474257974747]
	TIME [epoch: 8.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2616393551308435		[learning rate: 0.00072718]
	Learning Rate: 0.000727178
	LOSS [training: 0.2616393551308435 | validation: 0.2432006975601556]
	TIME [epoch: 8.48 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25995856427707953		[learning rate: 0.00072546]
	Learning Rate: 0.000725463
	LOSS [training: 0.25995856427707953 | validation: 0.2698710973532331]
	TIME [epoch: 8.48 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2670442463899817		[learning rate: 0.00072375]
	Learning Rate: 0.000723752
	LOSS [training: 0.2670442463899817 | validation: 0.27871419255624125]
	TIME [epoch: 8.51 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28748476591706534		[learning rate: 0.00072204]
	Learning Rate: 0.000722045
	LOSS [training: 0.28748476591706534 | validation: 0.24544395878467812]
	TIME [epoch: 8.47 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23844367880573253		[learning rate: 0.00072034]
	Learning Rate: 0.000720342
	LOSS [training: 0.23844367880573253 | validation: 0.2559912516650155]
	TIME [epoch: 8.48 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2482202174514287		[learning rate: 0.00071864]
	Learning Rate: 0.000718642
	LOSS [training: 0.2482202174514287 | validation: 0.25618027212144245]
	TIME [epoch: 8.48 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22616349955201037		[learning rate: 0.00071695]
	Learning Rate: 0.000716947
	LOSS [training: 0.22616349955201037 | validation: 0.3343197212530722]
	TIME [epoch: 8.49 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2717056723553345		[learning rate: 0.00071526]
	Learning Rate: 0.000715256
	LOSS [training: 0.2717056723553345 | validation: 0.2607564460390687]
	TIME [epoch: 8.48 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2391194224394079		[learning rate: 0.00071357]
	Learning Rate: 0.000713569
	LOSS [training: 0.2391194224394079 | validation: 0.23216694713309202]
	TIME [epoch: 8.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22396327844632902		[learning rate: 0.00071189]
	Learning Rate: 0.000711886
	LOSS [training: 0.22396327844632902 | validation: 0.33520635394759335]
	TIME [epoch: 8.48 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28586347706395066		[learning rate: 0.00071021]
	Learning Rate: 0.000710206
	LOSS [training: 0.28586347706395066 | validation: 0.2730983079209801]
	TIME [epoch: 8.49 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30687158836429973		[learning rate: 0.00070853]
	Learning Rate: 0.000708531
	LOSS [training: 0.30687158836429973 | validation: 0.4601312569124659]
	TIME [epoch: 8.48 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3047463435192899		[learning rate: 0.00070686]
	Learning Rate: 0.00070686
	LOSS [training: 0.3047463435192899 | validation: 0.21488810426527885]
	TIME [epoch: 8.49 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2415373854450936		[learning rate: 0.00070519]
	Learning Rate: 0.000705193
	LOSS [training: 0.2415373854450936 | validation: 0.23631551547931312]
	TIME [epoch: 8.49 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20286196671270984		[learning rate: 0.00070353]
	Learning Rate: 0.000703529
	LOSS [training: 0.20286196671270984 | validation: 0.31342956926577337]
	TIME [epoch: 8.48 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2295043982635525		[learning rate: 0.00070187]
	Learning Rate: 0.000701869
	LOSS [training: 0.2295043982635525 | validation: 0.29478961222496786]
	TIME [epoch: 8.49 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3190488624033339		[learning rate: 0.00070021]
	Learning Rate: 0.000700214
	LOSS [training: 0.3190488624033339 | validation: 0.2524805204641776]
	TIME [epoch: 8.48 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2321978507136218		[learning rate: 0.00069856]
	Learning Rate: 0.000698562
	LOSS [training: 0.2321978507136218 | validation: 0.24976792262803382]
	TIME [epoch: 8.49 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23125534693704708		[learning rate: 0.00069691]
	Learning Rate: 0.000696914
	LOSS [training: 0.23125534693704708 | validation: 0.34788178129352665]
	TIME [epoch: 8.48 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3022620403052136		[learning rate: 0.00069527]
	Learning Rate: 0.00069527
	LOSS [training: 0.3022620403052136 | validation: 0.22717029587113585]
	TIME [epoch: 8.49 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2588100868376546		[learning rate: 0.00069363]
	Learning Rate: 0.000693631
	LOSS [training: 0.2588100868376546 | validation: 0.27091886953184985]
	TIME [epoch: 8.48 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22826116967818896		[learning rate: 0.00069199]
	Learning Rate: 0.000691994
	LOSS [training: 0.22826116967818896 | validation: 0.2352303547990938]
	TIME [epoch: 8.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23266263389972539		[learning rate: 0.00069036]
	Learning Rate: 0.000690362
	LOSS [training: 0.23266263389972539 | validation: 0.22155883288481149]
	TIME [epoch: 8.48 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21890788816674286		[learning rate: 0.00068873]
	Learning Rate: 0.000688734
	LOSS [training: 0.21890788816674286 | validation: 0.21918937063010668]
	TIME [epoch: 8.49 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20664532496376609		[learning rate: 0.00068711]
	Learning Rate: 0.000687109
	LOSS [training: 0.20664532496376609 | validation: 0.26524743282068997]
	TIME [epoch: 8.47 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20403074830111242		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.20403074830111242 | validation: 0.21595876154595167]
	TIME [epoch: 8.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20706930487164224		[learning rate: 0.00068387]
	Learning Rate: 0.000683871
	LOSS [training: 0.20706930487164224 | validation: 0.21030130891810794]
	TIME [epoch: 8.48 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20016639479874326		[learning rate: 0.00068226]
	Learning Rate: 0.000682258
	LOSS [training: 0.20016639479874326 | validation: 0.20714258007604242]
	TIME [epoch: 8.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18524485353677994		[learning rate: 0.00068065]
	Learning Rate: 0.000680649
	LOSS [training: 0.18524485353677994 | validation: 0.2161912579038784]
	TIME [epoch: 8.47 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1928885198741941		[learning rate: 0.00067904]
	Learning Rate: 0.000679043
	LOSS [training: 0.1928885198741941 | validation: 0.2188761499629072]
	TIME [epoch: 8.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21405624642111074		[learning rate: 0.00067744]
	Learning Rate: 0.000677442
	LOSS [training: 0.21405624642111074 | validation: 0.20570342600755254]
	TIME [epoch: 8.49 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.312800274119189		[learning rate: 0.00067584]
	Learning Rate: 0.000675844
	LOSS [training: 0.312800274119189 | validation: 0.31145074620058005]
	TIME [epoch: 8.48 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2716822480031619		[learning rate: 0.00067425]
	Learning Rate: 0.000674249
	LOSS [training: 0.2716822480031619 | validation: 0.217795587896862]
	TIME [epoch: 8.47 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21130623427736853		[learning rate: 0.00067266]
	Learning Rate: 0.000672659
	LOSS [training: 0.21130623427736853 | validation: 0.2149139628702207]
	TIME [epoch: 8.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20288715223406287		[learning rate: 0.00067107]
	Learning Rate: 0.000671072
	LOSS [training: 0.20288715223406287 | validation: 0.2766079831550512]
	TIME [epoch: 8.49 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24727553682812067		[learning rate: 0.00066949]
	Learning Rate: 0.000669489
	LOSS [training: 0.24727553682812067 | validation: 0.25188827282304216]
	TIME [epoch: 8.47 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24324988114715113		[learning rate: 0.00066791]
	Learning Rate: 0.00066791
	LOSS [training: 0.24324988114715113 | validation: 0.2491081230812736]
	TIME [epoch: 8.47 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19641077380861807		[learning rate: 0.00066633]
	Learning Rate: 0.000666335
	LOSS [training: 0.19641077380861807 | validation: 0.20406053058959697]
	TIME [epoch: 8.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24493270054380653		[learning rate: 0.00066476]
	Learning Rate: 0.000664763
	LOSS [training: 0.24493270054380653 | validation: 0.2804602296235931]
	TIME [epoch: 8.48 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2347160777193778		[learning rate: 0.00066319]
	Learning Rate: 0.000663195
	LOSS [training: 0.2347160777193778 | validation: 0.23244284876908744]
	TIME [epoch: 8.47 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25590818528384507		[learning rate: 0.00066163]
	Learning Rate: 0.00066163
	LOSS [training: 0.25590818528384507 | validation: 0.25254329958829536]
	TIME [epoch: 8.52 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3107330171864039		[learning rate: 0.00066007]
	Learning Rate: 0.00066007
	LOSS [training: 0.3107330171864039 | validation: 0.23999717515297506]
	TIME [epoch: 8.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2028904711217562		[learning rate: 0.00065851]
	Learning Rate: 0.000658513
	LOSS [training: 0.2028904711217562 | validation: 0.25724604982085664]
	TIME [epoch: 8.47 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24114930304418752		[learning rate: 0.00065696]
	Learning Rate: 0.000656959
	LOSS [training: 0.24114930304418752 | validation: 0.27885767090488145]
	TIME [epoch: 8.48 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21434891698740355		[learning rate: 0.00065541]
	Learning Rate: 0.00065541
	LOSS [training: 0.21434891698740355 | validation: 0.25451817090025214]
	TIME [epoch: 8.48 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24049685449534305		[learning rate: 0.00065386]
	Learning Rate: 0.000653864
	LOSS [training: 0.24049685449534305 | validation: 0.25412866777036125]
	TIME [epoch: 8.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29393816722671895		[learning rate: 0.00065232]
	Learning Rate: 0.000652321
	LOSS [training: 0.29393816722671895 | validation: 0.35291553773073103]
	TIME [epoch: 8.48 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26352524668379457		[learning rate: 0.00065078]
	Learning Rate: 0.000650783
	LOSS [training: 0.26352524668379457 | validation: 0.2631149086075436]
	TIME [epoch: 8.49 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23238132174092466		[learning rate: 0.00064925]
	Learning Rate: 0.000649247
	LOSS [training: 0.23238132174092466 | validation: 0.2709608826626275]
	TIME [epoch: 8.48 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2244838844723366		[learning rate: 0.00064772]
	Learning Rate: 0.000647716
	LOSS [training: 0.2244838844723366 | validation: 0.22211522658653138]
	TIME [epoch: 8.49 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24511893750925068		[learning rate: 0.00064619]
	Learning Rate: 0.000646188
	LOSS [training: 0.24511893750925068 | validation: 0.2656523995898114]
	TIME [epoch: 8.47 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26001728269840785		[learning rate: 0.00064466]
	Learning Rate: 0.000644664
	LOSS [training: 0.26001728269840785 | validation: 0.28859371144244705]
	TIME [epoch: 8.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28090374650841526		[learning rate: 0.00064314]
	Learning Rate: 0.000643143
	LOSS [training: 0.28090374650841526 | validation: 0.3374620291671086]
	TIME [epoch: 8.49 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23953496804643182		[learning rate: 0.00064163]
	Learning Rate: 0.000641626
	LOSS [training: 0.23953496804643182 | validation: 0.2180298068152019]
	TIME [epoch: 8.48 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22786468499377893		[learning rate: 0.00064011]
	Learning Rate: 0.000640113
	LOSS [training: 0.22786468499377893 | validation: 0.23460255255815682]
	TIME [epoch: 8.48 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2369047226059957		[learning rate: 0.0006386]
	Learning Rate: 0.000638603
	LOSS [training: 0.2369047226059957 | validation: 0.24162600984086152]
	TIME [epoch: 8.48 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2645321248939211		[learning rate: 0.0006371]
	Learning Rate: 0.000637096
	LOSS [training: 0.2645321248939211 | validation: 0.25069991249951457]
	TIME [epoch: 8.48 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31075790217436583		[learning rate: 0.00063559]
	Learning Rate: 0.000635594
	LOSS [training: 0.31075790217436583 | validation: 0.3205470303898811]
	TIME [epoch: 8.48 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2994120993091077		[learning rate: 0.00063409]
	Learning Rate: 0.000634094
	LOSS [training: 0.2994120993091077 | validation: 0.37010787539790113]
	TIME [epoch: 8.49 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31746712110106506		[learning rate: 0.0006326]
	Learning Rate: 0.000632598
	LOSS [training: 0.31746712110106506 | validation: 0.3360667623833755]
	TIME [epoch: 8.48 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30749814377850754		[learning rate: 0.00063111]
	Learning Rate: 0.000631106
	LOSS [training: 0.30749814377850754 | validation: 0.28856923147061103]
	TIME [epoch: 8.49 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2753333337632099		[learning rate: 0.00062962]
	Learning Rate: 0.000629618
	LOSS [training: 0.2753333337632099 | validation: 0.2102773738252628]
	TIME [epoch: 8.47 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1954004118717472		[learning rate: 0.00062813]
	Learning Rate: 0.000628132
	LOSS [training: 0.1954004118717472 | validation: 0.20249744353327165]
	TIME [epoch: 8.49 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20831182838397258		[learning rate: 0.00062665]
	Learning Rate: 0.000626651
	LOSS [training: 0.20831182838397258 | validation: 0.25857086095425696]
	TIME [epoch: 8.47 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26968508179643064		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.26968508179643064 | validation: 0.4117618521898388]
	TIME [epoch: 8.49 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38573598220075067		[learning rate: 0.0006237]
	Learning Rate: 0.000623698
	LOSS [training: 0.38573598220075067 | validation: 0.25353245662135104]
	TIME [epoch: 8.48 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26403447054986573		[learning rate: 0.00062223]
	Learning Rate: 0.000622227
	LOSS [training: 0.26403447054986573 | validation: 0.2870260679853603]
	TIME [epoch: 8.49 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2799124321060518		[learning rate: 0.00062076]
	Learning Rate: 0.000620759
	LOSS [training: 0.2799124321060518 | validation: 0.23680588387730034]
	TIME [epoch: 8.47 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2410787045322793		[learning rate: 0.00061929]
	Learning Rate: 0.000619295
	LOSS [training: 0.2410787045322793 | validation: 0.23835358560196013]
	TIME [epoch: 8.49 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.221262652135663		[learning rate: 0.00061783]
	Learning Rate: 0.000617834
	LOSS [training: 0.221262652135663 | validation: 0.2815146845589678]
	TIME [epoch: 8.47 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20410095946840565		[learning rate: 0.00061638]
	Learning Rate: 0.000616377
	LOSS [training: 0.20410095946840565 | validation: 0.18816394374218762]
	TIME [epoch: 8.49 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19724512910795602		[learning rate: 0.00061492]
	Learning Rate: 0.000614923
	LOSS [training: 0.19724512910795602 | validation: 0.18905499616179577]
	TIME [epoch: 8.47 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2736972919846393		[learning rate: 0.00061347]
	Learning Rate: 0.000613472
	LOSS [training: 0.2736972919846393 | validation: 0.32659500773799877]
	TIME [epoch: 8.49 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25918133196957094		[learning rate: 0.00061203]
	Learning Rate: 0.000612025
	LOSS [training: 0.25918133196957094 | validation: 0.22767574920861888]
	TIME [epoch: 8.48 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23918905007161156		[learning rate: 0.00061058]
	Learning Rate: 0.000610581
	LOSS [training: 0.23918905007161156 | validation: 0.27673636983202177]
	TIME [epoch: 8.49 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25922614689315915		[learning rate: 0.00060914]
	Learning Rate: 0.000609141
	LOSS [training: 0.25922614689315915 | validation: 0.2455656479342917]
	TIME [epoch: 8.47 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20971739819571922		[learning rate: 0.0006077]
	Learning Rate: 0.000607704
	LOSS [training: 0.20971739819571922 | validation: 0.20034898562406445]
	TIME [epoch: 8.49 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22649729938354562		[learning rate: 0.00060627]
	Learning Rate: 0.000606271
	LOSS [training: 0.22649729938354562 | validation: 0.2679282191176918]
	TIME [epoch: 8.48 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23928079553189652		[learning rate: 0.00060484]
	Learning Rate: 0.000604841
	LOSS [training: 0.23928079553189652 | validation: 0.19175184199358347]
	TIME [epoch: 8.48 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2811751209495073		[learning rate: 0.00060341]
	Learning Rate: 0.000603414
	LOSS [training: 0.2811751209495073 | validation: 0.2953923946714973]
	TIME [epoch: 8.47 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23449917180870639		[learning rate: 0.00060199]
	Learning Rate: 0.000601991
	LOSS [training: 0.23449917180870639 | validation: 0.20094243199869588]
	TIME [epoch: 8.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25869792091080485		[learning rate: 0.00060057]
	Learning Rate: 0.000600571
	LOSS [training: 0.25869792091080485 | validation: 0.25650148168574094]
	TIME [epoch: 8.49 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2630324201709381		[learning rate: 0.00059915]
	Learning Rate: 0.000599154
	LOSS [training: 0.2630324201709381 | validation: 0.3406999427629062]
	TIME [epoch: 8.48 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23150573023297522		[learning rate: 0.00059774]
	Learning Rate: 0.000597741
	LOSS [training: 0.23150573023297522 | validation: 0.18725859300691122]
	TIME [epoch: 8.47 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18467620557187098		[learning rate: 0.00059633]
	Learning Rate: 0.000596331
	LOSS [training: 0.18467620557187098 | validation: 0.1763307207125427]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1244.pth
	Model improved!!!
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2289406351268716		[learning rate: 0.00059492]
	Learning Rate: 0.000594924
	LOSS [training: 0.2289406351268716 | validation: 0.339096164519597]
	TIME [epoch: 8.49 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2785497497579753		[learning rate: 0.00059352]
	Learning Rate: 0.000593521
	LOSS [training: 0.2785497497579753 | validation: 0.2572682748533467]
	TIME [epoch: 8.47 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29140759768516633		[learning rate: 0.00059212]
	Learning Rate: 0.000592121
	LOSS [training: 0.29140759768516633 | validation: 0.25487939296079876]
	TIME [epoch: 8.47 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25164087559119674		[learning rate: 0.00059072]
	Learning Rate: 0.000590724
	LOSS [training: 0.25164087559119674 | validation: 0.2435340522729847]
	TIME [epoch: 8.48 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2645630587595163		[learning rate: 0.00058933]
	Learning Rate: 0.000589331
	LOSS [training: 0.2645630587595163 | validation: 0.3285883600195163]
	TIME [epoch: 8.48 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3349198479505114		[learning rate: 0.00058794]
	Learning Rate: 0.00058794
	LOSS [training: 0.3349198479505114 | validation: 0.29645885764904234]
	TIME [epoch: 8.46 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37288091514188526		[learning rate: 0.00058655]
	Learning Rate: 0.000586554
	LOSS [training: 0.37288091514188526 | validation: 0.3738759473825155]
	TIME [epoch: 8.46 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2868062456045031		[learning rate: 0.00058517]
	Learning Rate: 0.00058517
	LOSS [training: 0.2868062456045031 | validation: 0.24057268943721144]
	TIME [epoch: 8.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22903701899816192		[learning rate: 0.00058379]
	Learning Rate: 0.00058379
	LOSS [training: 0.22903701899816192 | validation: 0.21608901422394938]
	TIME [epoch: 8.48 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23788055643652894		[learning rate: 0.00058241]
	Learning Rate: 0.000582413
	LOSS [training: 0.23788055643652894 | validation: 0.27765743064776627]
	TIME [epoch: 8.46 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24075912054296075		[learning rate: 0.00058104]
	Learning Rate: 0.000581039
	LOSS [training: 0.24075912054296075 | validation: 0.27281632209419726]
	TIME [epoch: 8.47 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2284586408674397		[learning rate: 0.00057967]
	Learning Rate: 0.000579668
	LOSS [training: 0.2284586408674397 | validation: 0.21328761232348484]
	TIME [epoch: 8.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31600523224421645		[learning rate: 0.0005783]
	Learning Rate: 0.000578301
	LOSS [training: 0.31600523224421645 | validation: 0.38961856813194257]
	TIME [epoch: 8.47 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3168328831142508		[learning rate: 0.00057694]
	Learning Rate: 0.000576937
	LOSS [training: 0.3168328831142508 | validation: 0.25777699630445755]
	TIME [epoch: 8.48 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25463821638055595		[learning rate: 0.00057558]
	Learning Rate: 0.000575576
	LOSS [training: 0.25463821638055595 | validation: 0.21984507514745252]
	TIME [epoch: 8.48 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22226432463541101		[learning rate: 0.00057422]
	Learning Rate: 0.000574218
	LOSS [training: 0.22226432463541101 | validation: 0.2069100175271077]
	TIME [epoch: 8.49 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18220908155678894		[learning rate: 0.00057286]
	Learning Rate: 0.000572864
	LOSS [training: 0.18220908155678894 | validation: 0.19507261343545712]
	TIME [epoch: 8.48 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18241488559674104		[learning rate: 0.00057151]
	Learning Rate: 0.000571512
	LOSS [training: 0.18241488559674104 | validation: 0.21261379160701]
	TIME [epoch: 8.46 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18502619687110727		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.18502619687110727 | validation: 0.22360091354609926]
	TIME [epoch: 8.49 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22535312066526725		[learning rate: 0.00056882]
	Learning Rate: 0.000568819
	LOSS [training: 0.22535312066526725 | validation: 0.28399617198976657]
	TIME [epoch: 8.47 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3188367295008625		[learning rate: 0.00056748]
	Learning Rate: 0.000567478
	LOSS [training: 0.3188367295008625 | validation: 0.315565758296353]
	TIME [epoch: 8.47 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22107183818874673		[learning rate: 0.00056614]
	Learning Rate: 0.000566139
	LOSS [training: 0.22107183818874673 | validation: 0.21428623059678562]
	TIME [epoch: 8.48 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1916383388838818		[learning rate: 0.0005648]
	Learning Rate: 0.000564804
	LOSS [training: 0.1916383388838818 | validation: 0.2412419900368764]
	TIME [epoch: 8.49 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2011988928568234		[learning rate: 0.00056347]
	Learning Rate: 0.000563471
	LOSS [training: 0.2011988928568234 | validation: 0.19589635592996243]
	TIME [epoch: 8.48 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2250660662735239		[learning rate: 0.00056214]
	Learning Rate: 0.000562142
	LOSS [training: 0.2250660662735239 | validation: 0.2383444282031074]
	TIME [epoch: 8.47 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26397558940634336		[learning rate: 0.00056082]
	Learning Rate: 0.000560816
	LOSS [training: 0.26397558940634336 | validation: 0.2706645383830241]
	TIME [epoch: 8.49 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2682452947641313		[learning rate: 0.00055949]
	Learning Rate: 0.000559493
	LOSS [training: 0.2682452947641313 | validation: 0.2341889392147058]
	TIME [epoch: 8.48 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26287812774097885		[learning rate: 0.00055817]
	Learning Rate: 0.000558173
	LOSS [training: 0.26287812774097885 | validation: 0.22237082954283804]
	TIME [epoch: 8.48 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22175923874885323		[learning rate: 0.00055686]
	Learning Rate: 0.000556857
	LOSS [training: 0.22175923874885323 | validation: 0.3181260781084644]
	TIME [epoch: 8.46 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2175571348586267		[learning rate: 0.00055554]
	Learning Rate: 0.000555543
	LOSS [training: 0.2175571348586267 | validation: 0.19253304009010125]
	TIME [epoch: 8.49 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22344389013625326		[learning rate: 0.00055423]
	Learning Rate: 0.000554233
	LOSS [training: 0.22344389013625326 | validation: 0.220391275936189]
	TIME [epoch: 8.49 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21487266748846506		[learning rate: 0.00055293]
	Learning Rate: 0.000552925
	LOSS [training: 0.21487266748846506 | validation: 0.22547713406974695]
	TIME [epoch: 8.48 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22809403458004684		[learning rate: 0.00055162]
	Learning Rate: 0.000551621
	LOSS [training: 0.22809403458004684 | validation: 0.2159565194913832]
	TIME [epoch: 8.47 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21289365206422645		[learning rate: 0.00055032]
	Learning Rate: 0.00055032
	LOSS [training: 0.21289365206422645 | validation: 0.2141409404952726]
	TIME [epoch: 8.48 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22551226024954132		[learning rate: 0.00054902]
	Learning Rate: 0.000549022
	LOSS [training: 0.22551226024954132 | validation: 0.2975167743231676]
	TIME [epoch: 8.49 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21437858515002875		[learning rate: 0.00054773]
	Learning Rate: 0.000547727
	LOSS [training: 0.21437858515002875 | validation: 0.24802770938515784]
	TIME [epoch: 8.47 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25272556539905894		[learning rate: 0.00054643]
	Learning Rate: 0.000546435
	LOSS [training: 0.25272556539905894 | validation: 0.21939891522391614]
	TIME [epoch: 8.47 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19902365392983568		[learning rate: 0.00054515]
	Learning Rate: 0.000545146
	LOSS [training: 0.19902365392983568 | validation: 0.19495964809793276]
	TIME [epoch: 8.48 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21743279321868422		[learning rate: 0.00054386]
	Learning Rate: 0.00054386
	LOSS [training: 0.21743279321868422 | validation: 0.2217925301567245]
	TIME [epoch: 8.48 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2642638074211038		[learning rate: 0.00054258]
	Learning Rate: 0.000542577
	LOSS [training: 0.2642638074211038 | validation: 0.2521473912857028]
	TIME [epoch: 8.47 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30860137350984945		[learning rate: 0.0005413]
	Learning Rate: 0.000541297
	LOSS [training: 0.30860137350984945 | validation: 0.37284531879685845]
	TIME [epoch: 8.48 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31363228469828613		[learning rate: 0.00054002]
	Learning Rate: 0.00054002
	LOSS [training: 0.31363228469828613 | validation: 0.3259434930198373]
	TIME [epoch: 8.46 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2772729077867478		[learning rate: 0.00053875]
	Learning Rate: 0.000538747
	LOSS [training: 0.2772729077867478 | validation: 0.25309022338351717]
	TIME [epoch: 8.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1957927472832273		[learning rate: 0.00053748]
	Learning Rate: 0.000537476
	LOSS [training: 0.1957927472832273 | validation: 0.19025070400268873]
	TIME [epoch: 8.47 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21532256521433224		[learning rate: 0.00053621]
	Learning Rate: 0.000536208
	LOSS [training: 0.21532256521433224 | validation: 0.2805500160118689]
	TIME [epoch: 8.48 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25530127647673834		[learning rate: 0.00053494]
	Learning Rate: 0.000534943
	LOSS [training: 0.25530127647673834 | validation: 0.38021122460895385]
	TIME [epoch: 8.47 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28848170600380674		[learning rate: 0.00053368]
	Learning Rate: 0.000533681
	LOSS [training: 0.28848170600380674 | validation: 0.21863891906352098]
	TIME [epoch: 8.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23818362537434745		[learning rate: 0.00053242]
	Learning Rate: 0.000532422
	LOSS [training: 0.23818362537434745 | validation: 0.21249033813285417]
	TIME [epoch: 8.48 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2394183626917256		[learning rate: 0.00053117]
	Learning Rate: 0.000531167
	LOSS [training: 0.2394183626917256 | validation: 0.21603537358078317]
	TIME [epoch: 8.48 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21641228601093299		[learning rate: 0.00052991]
	Learning Rate: 0.000529914
	LOSS [training: 0.21641228601093299 | validation: 0.21593123398088326]
	TIME [epoch: 8.47 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21613441179683884		[learning rate: 0.00052866]
	Learning Rate: 0.000528664
	LOSS [training: 0.21613441179683884 | validation: 0.19093345373932596]
	TIME [epoch: 8.49 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2115546510748761		[learning rate: 0.00052742]
	Learning Rate: 0.000527417
	LOSS [training: 0.2115546510748761 | validation: 0.21957015542091238]
	TIME [epoch: 8.48 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.197602582644434		[learning rate: 0.00052617]
	Learning Rate: 0.000526173
	LOSS [training: 0.197602582644434 | validation: 0.21312732043784735]
	TIME [epoch: 8.47 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19089708394640345		[learning rate: 0.00052493]
	Learning Rate: 0.000524931
	LOSS [training: 0.19089708394640345 | validation: 0.2039916831738383]
	TIME [epoch: 8.47 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2611526530377436		[learning rate: 0.00052369]
	Learning Rate: 0.000523693
	LOSS [training: 0.2611526530377436 | validation: 0.33481321403590225]
	TIME [epoch: 8.48 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3040268516904109		[learning rate: 0.00052246]
	Learning Rate: 0.000522458
	LOSS [training: 0.3040268516904109 | validation: 0.3208888809554868]
	TIME [epoch: 8.49 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29176287528416295		[learning rate: 0.00052123]
	Learning Rate: 0.000521225
	LOSS [training: 0.29176287528416295 | validation: 0.28490709206225395]
	TIME [epoch: 8.47 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2765720297769118		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.2765720297769118 | validation: 0.22687647510839484]
	TIME [epoch: 8.48 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19445898584887533		[learning rate: 0.00051877]
	Learning Rate: 0.000518769
	LOSS [training: 0.19445898584887533 | validation: 0.20592925885600777]
	TIME [epoch: 8.49 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21058561677208085		[learning rate: 0.00051755]
	Learning Rate: 0.000517546
	LOSS [training: 0.21058561677208085 | validation: 0.2254793140973703]
	TIME [epoch: 8.49 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17651933393856362		[learning rate: 0.00051632]
	Learning Rate: 0.000516325
	LOSS [training: 0.17651933393856362 | validation: 0.20218413530611506]
	TIME [epoch: 8.47 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17706219393292805		[learning rate: 0.00051511]
	Learning Rate: 0.000515107
	LOSS [training: 0.17706219393292805 | validation: 0.1976721318530748]
	TIME [epoch: 8.48 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20072632379738317		[learning rate: 0.00051389]
	Learning Rate: 0.000513892
	LOSS [training: 0.20072632379738317 | validation: 0.2414662430377414]
	TIME [epoch: 8.49 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23481983760158953		[learning rate: 0.00051268]
	Learning Rate: 0.00051268
	LOSS [training: 0.23481983760158953 | validation: 0.2821212511259974]
	TIME [epoch: 8.48 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26368965952055434		[learning rate: 0.00051147]
	Learning Rate: 0.00051147
	LOSS [training: 0.26368965952055434 | validation: 0.21590887880850645]
	TIME [epoch: 8.46 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21404548537113027		[learning rate: 0.00051026]
	Learning Rate: 0.000510264
	LOSS [training: 0.21404548537113027 | validation: 0.2146685887819626]
	TIME [epoch: 8.48 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21041771811294		[learning rate: 0.00050906]
	Learning Rate: 0.00050906
	LOSS [training: 0.21041771811294 | validation: 0.18556885215776198]
	TIME [epoch: 8.48 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17770544054747828		[learning rate: 0.00050786]
	Learning Rate: 0.000507859
	LOSS [training: 0.17770544054747828 | validation: 0.2192357087944124]
	TIME [epoch: 8.47 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20125837572081226		[learning rate: 0.00050666]
	Learning Rate: 0.000506662
	LOSS [training: 0.20125837572081226 | validation: 0.18979417168979942]
	TIME [epoch: 8.46 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1861489983868027		[learning rate: 0.00050547]
	Learning Rate: 0.000505466
	LOSS [training: 0.1861489983868027 | validation: 0.1678142551923053]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1314.pth
	Model improved!!!
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1895697480498184		[learning rate: 0.00050427]
	Learning Rate: 0.000504274
	LOSS [training: 0.1895697480498184 | validation: 0.19782949104285932]
	TIME [epoch: 8.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18756617222280011		[learning rate: 0.00050308]
	Learning Rate: 0.000503085
	LOSS [training: 0.18756617222280011 | validation: 0.18796245361380048]
	TIME [epoch: 8.47 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1636199981234664		[learning rate: 0.0005019]
	Learning Rate: 0.000501898
	LOSS [training: 0.1636199981234664 | validation: 0.17581213402685708]
	TIME [epoch: 8.47 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17206061934161773		[learning rate: 0.00050071]
	Learning Rate: 0.000500714
	LOSS [training: 0.17206061934161773 | validation: 0.20074173768233328]
	TIME [epoch: 8.48 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1931192025084516		[learning rate: 0.00049953]
	Learning Rate: 0.000499533
	LOSS [training: 0.1931192025084516 | validation: 0.2964886289771924]
	TIME [epoch: 8.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2707549431511224		[learning rate: 0.00049835]
	Learning Rate: 0.000498355
	LOSS [training: 0.2707549431511224 | validation: 0.25361696336442446]
	TIME [epoch: 8.47 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22566278607354273		[learning rate: 0.00049718]
	Learning Rate: 0.000497179
	LOSS [training: 0.22566278607354273 | validation: 0.24625584800705325]
	TIME [epoch: 8.47 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26208158531700804		[learning rate: 0.00049601]
	Learning Rate: 0.000496006
	LOSS [training: 0.26208158531700804 | validation: 0.2637794840023281]
	TIME [epoch: 8.48 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20658911730596236		[learning rate: 0.00049484]
	Learning Rate: 0.000494836
	LOSS [training: 0.20658911730596236 | validation: 0.18209532043269366]
	TIME [epoch: 8.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31400604195775367		[learning rate: 0.00049367]
	Learning Rate: 0.000493669
	LOSS [training: 0.31400604195775367 | validation: 0.2399977158031142]
	TIME [epoch: 8.47 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17962977079788622		[learning rate: 0.0004925]
	Learning Rate: 0.000492505
	LOSS [training: 0.17962977079788622 | validation: 0.20610838484239374]
	TIME [epoch: 8.47 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20921226040967675		[learning rate: 0.00049134]
	Learning Rate: 0.000491343
	LOSS [training: 0.20921226040967675 | validation: 0.22182501007869568]
	TIME [epoch: 8.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19894732847567248		[learning rate: 0.00049018]
	Learning Rate: 0.000490184
	LOSS [training: 0.19894732847567248 | validation: 0.19269041773150372]
	TIME [epoch: 8.49 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1985664619754933		[learning rate: 0.00048903]
	Learning Rate: 0.000489027
	LOSS [training: 0.1985664619754933 | validation: 0.21772111568841257]
	TIME [epoch: 8.48 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21208534057235226		[learning rate: 0.00048787]
	Learning Rate: 0.000487874
	LOSS [training: 0.21208534057235226 | validation: 0.18488933838974164]
	TIME [epoch: 8.47 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2252786627427108		[learning rate: 0.00048672]
	Learning Rate: 0.000486723
	LOSS [training: 0.2252786627427108 | validation: 0.3077490088329958]
	TIME [epoch: 8.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22098719726479366		[learning rate: 0.00048558]
	Learning Rate: 0.000485575
	LOSS [training: 0.22098719726479366 | validation: 0.23579774807695847]
	TIME [epoch: 8.47 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18378462436532164		[learning rate: 0.00048443]
	Learning Rate: 0.00048443
	LOSS [training: 0.18378462436532164 | validation: 0.18981763251331546]
	TIME [epoch: 8.46 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17689871128974197		[learning rate: 0.00048329]
	Learning Rate: 0.000483287
	LOSS [training: 0.17689871128974197 | validation: 0.16911140742501796]
	TIME [epoch: 8.47 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17996538915377727		[learning rate: 0.00048215]
	Learning Rate: 0.000482147
	LOSS [training: 0.17996538915377727 | validation: 0.1748811988702313]
	TIME [epoch: 8.52 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17093448684677556		[learning rate: 0.00048101]
	Learning Rate: 0.00048101
	LOSS [training: 0.17093448684677556 | validation: 0.21128920987450317]
	TIME [epoch: 8.48 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18809660753273547		[learning rate: 0.00047988]
	Learning Rate: 0.000479875
	LOSS [training: 0.18809660753273547 | validation: 0.1753280013522207]
	TIME [epoch: 8.47 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17016541757376688		[learning rate: 0.00047874]
	Learning Rate: 0.000478743
	LOSS [training: 0.17016541757376688 | validation: 0.16948679680749684]
	TIME [epoch: 8.47 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16468304391297278		[learning rate: 0.00047761]
	Learning Rate: 0.000477614
	LOSS [training: 0.16468304391297278 | validation: 0.18368006479016696]
	TIME [epoch: 8.51 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1619927916039989		[learning rate: 0.00047649]
	Learning Rate: 0.000476487
	LOSS [training: 0.1619927916039989 | validation: 0.19772965345501864]
	TIME [epoch: 8.47 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18996574683754236		[learning rate: 0.00047536]
	Learning Rate: 0.000475363
	LOSS [training: 0.18996574683754236 | validation: 0.2239898469483138]
	TIME [epoch: 8.47 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22696781059357382		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.22696781059357382 | validation: 0.17625168717440645]
	TIME [epoch: 8.48 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17403797030460186		[learning rate: 0.00047312]
	Learning Rate: 0.000473123
	LOSS [training: 0.17403797030460186 | validation: 0.2168476533213844]
	TIME [epoch: 8.51 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23111114091325788		[learning rate: 0.00047201]
	Learning Rate: 0.000472007
	LOSS [training: 0.23111114091325788 | validation: 0.23163014895552245]
	TIME [epoch: 8.47 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1943367024441719		[learning rate: 0.00047089]
	Learning Rate: 0.000470894
	LOSS [training: 0.1943367024441719 | validation: 0.17347882388856128]
	TIME [epoch: 8.47 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.168973355648247		[learning rate: 0.00046978]
	Learning Rate: 0.000469783
	LOSS [training: 0.168973355648247 | validation: 0.1801471499236575]
	TIME [epoch: 8.48 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1664465970967728		[learning rate: 0.00046867]
	Learning Rate: 0.000468675
	LOSS [training: 0.1664465970967728 | validation: 0.20728136960916255]
	TIME [epoch: 8.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18003179464728022		[learning rate: 0.00046757]
	Learning Rate: 0.000467569
	LOSS [training: 0.18003179464728022 | validation: 0.1716752475508898]
	TIME [epoch: 8.46 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17051371615871255		[learning rate: 0.00046647]
	Learning Rate: 0.000466467
	LOSS [training: 0.17051371615871255 | validation: 0.1646764099501966]
	TIME [epoch: 8.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1348.pth
	Model improved!!!
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17126233821166914		[learning rate: 0.00046537]
	Learning Rate: 0.000465366
	LOSS [training: 0.17126233821166914 | validation: 0.17648077931868744]
	TIME [epoch: 8.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1627915399962785		[learning rate: 0.00046427]
	Learning Rate: 0.000464269
	LOSS [training: 0.1627915399962785 | validation: 0.15520984077764416]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1350.pth
	Model improved!!!
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16468061730051997		[learning rate: 0.00046317]
	Learning Rate: 0.000463173
	LOSS [training: 0.16468061730051997 | validation: 0.20411924950674187]
	TIME [epoch: 8.47 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.214620236715679		[learning rate: 0.00046208]
	Learning Rate: 0.000462081
	LOSS [training: 0.214620236715679 | validation: 0.22475825325533766]
	TIME [epoch: 8.46 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21399885249356299		[learning rate: 0.00046099]
	Learning Rate: 0.000460991
	LOSS [training: 0.21399885249356299 | validation: 0.2191879489698936]
	TIME [epoch: 8.48 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20790485815753396		[learning rate: 0.0004599]
	Learning Rate: 0.000459903
	LOSS [training: 0.20790485815753396 | validation: 0.1758199303926893]
	TIME [epoch: 8.48 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1679658751548665		[learning rate: 0.00045882]
	Learning Rate: 0.000458819
	LOSS [training: 0.1679658751548665 | validation: 0.16870088337406974]
	TIME [epoch: 8.46 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17231740582708657		[learning rate: 0.00045774]
	Learning Rate: 0.000457736
	LOSS [training: 0.17231740582708657 | validation: 0.22720794119323387]
	TIME [epoch: 8.47 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2429817228894037		[learning rate: 0.00045666]
	Learning Rate: 0.000456657
	LOSS [training: 0.2429817228894037 | validation: 0.34545986761408276]
	TIME [epoch: 8.48 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4121358424053888		[learning rate: 0.00045558]
	Learning Rate: 0.000455579
	LOSS [training: 0.4121358424053888 | validation: 0.48207844689273943]
	TIME [epoch: 8.49 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3331819682181473		[learning rate: 0.0004545]
	Learning Rate: 0.000454505
	LOSS [training: 0.3331819682181473 | validation: 0.3439605690123846]
	TIME [epoch: 8.47 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27983188025634753		[learning rate: 0.00045343]
	Learning Rate: 0.000453433
	LOSS [training: 0.27983188025634753 | validation: 0.23521735663344273]
	TIME [epoch: 8.48 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2258339743392903		[learning rate: 0.00045236]
	Learning Rate: 0.000452363
	LOSS [training: 0.2258339743392903 | validation: 0.20007225244620716]
	TIME [epoch: 8.47 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2055619211888849		[learning rate: 0.0004513]
	Learning Rate: 0.000451296
	LOSS [training: 0.2055619211888849 | validation: 0.24814554581848514]
	TIME [epoch: 8.49 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19079318115203045		[learning rate: 0.00045023]
	Learning Rate: 0.000450232
	LOSS [training: 0.19079318115203045 | validation: 0.20481298109439317]
	TIME [epoch: 8.48 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20938331862615112		[learning rate: 0.00044917]
	Learning Rate: 0.000449169
	LOSS [training: 0.20938331862615112 | validation: 0.19878046489019086]
	TIME [epoch: 8.49 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19506264169878357		[learning rate: 0.00044811]
	Learning Rate: 0.00044811
	LOSS [training: 0.19506264169878357 | validation: 0.23799814926491075]
	TIME [epoch: 8.47 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23343944678148806		[learning rate: 0.00044705]
	Learning Rate: 0.000447053
	LOSS [training: 0.23343944678148806 | validation: 0.18933952684892458]
	TIME [epoch: 8.49 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18191422667931248		[learning rate: 0.000446]
	Learning Rate: 0.000445998
	LOSS [training: 0.18191422667931248 | validation: 0.2636105220537762]
	TIME [epoch: 8.48 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2138005986376513		[learning rate: 0.00044495]
	Learning Rate: 0.000444946
	LOSS [training: 0.2138005986376513 | validation: 0.1962593656081431]
	TIME [epoch: 8.47 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23068677138149787		[learning rate: 0.0004439]
	Learning Rate: 0.000443897
	LOSS [training: 0.23068677138149787 | validation: 0.19647463315244879]
	TIME [epoch: 8.46 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18298471373015135		[learning rate: 0.00044285]
	Learning Rate: 0.00044285
	LOSS [training: 0.18298471373015135 | validation: 0.20496312769435604]
	TIME [epoch: 8.49 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18375677542502156		[learning rate: 0.00044181]
	Learning Rate: 0.000441805
	LOSS [training: 0.18375677542502156 | validation: 0.19036431702940573]
	TIME [epoch: 8.47 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17452719606551728		[learning rate: 0.00044076]
	Learning Rate: 0.000440763
	LOSS [training: 0.17452719606551728 | validation: 0.1770146178788652]
	TIME [epoch: 8.47 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17436165239065543		[learning rate: 0.00043972]
	Learning Rate: 0.000439723
	LOSS [training: 0.17436165239065543 | validation: 0.2260603757788441]
	TIME [epoch: 8.46 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20711161740032438		[learning rate: 0.00043869]
	Learning Rate: 0.000438686
	LOSS [training: 0.20711161740032438 | validation: 0.20232426529561215]
	TIME [epoch: 8.49 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18784197622790716		[learning rate: 0.00043765]
	Learning Rate: 0.000437651
	LOSS [training: 0.18784197622790716 | validation: 0.1832478421206953]
	TIME [epoch: 8.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19392686878084814		[learning rate: 0.00043662]
	Learning Rate: 0.000436619
	LOSS [training: 0.19392686878084814 | validation: 0.22741790583859617]
	TIME [epoch: 8.47 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24517799544914992		[learning rate: 0.00043559]
	Learning Rate: 0.000435589
	LOSS [training: 0.24517799544914992 | validation: 0.17075808504851311]
	TIME [epoch: 8.46 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19317800745499786		[learning rate: 0.00043456]
	Learning Rate: 0.000434562
	LOSS [training: 0.19317800745499786 | validation: 0.1846514648527572]
	TIME [epoch: 8.48 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18426185133849357		[learning rate: 0.00043354]
	Learning Rate: 0.000433536
	LOSS [training: 0.18426185133849357 | validation: 0.19895812241753433]
	TIME [epoch: 8.49 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2049643046654622		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.2049643046654622 | validation: 0.16973564216987486]
	TIME [epoch: 8.46 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17486742802741825		[learning rate: 0.00043149]
	Learning Rate: 0.000431494
	LOSS [training: 0.17486742802741825 | validation: 0.1903515475929161]
	TIME [epoch: 8.48 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20321871470159839		[learning rate: 0.00043048]
	Learning Rate: 0.000430476
	LOSS [training: 0.20321871470159839 | validation: 0.26063266635525517]
	TIME [epoch: 8.48 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20990704530382986		[learning rate: 0.00042946]
	Learning Rate: 0.00042946
	LOSS [training: 0.20990704530382986 | validation: 0.19167836766404328]
	TIME [epoch: 8.48 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17128479894617094		[learning rate: 0.00042845]
	Learning Rate: 0.000428447
	LOSS [training: 0.17128479894617094 | validation: 0.1788053379169517]
	TIME [epoch: 8.47 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1534862885659956		[learning rate: 0.00042744]
	Learning Rate: 0.000427437
	LOSS [training: 0.1534862885659956 | validation: 0.1765686234220693]
	TIME [epoch: 8.48 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17456374309255462		[learning rate: 0.00042643]
	Learning Rate: 0.000426428
	LOSS [training: 0.17456374309255462 | validation: 0.205908797654609]
	TIME [epoch: 8.49 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19705901138797566		[learning rate: 0.00042542]
	Learning Rate: 0.000425423
	LOSS [training: 0.19705901138797566 | validation: 0.171807062100627]
	TIME [epoch: 8.47 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19791018735502838		[learning rate: 0.00042442]
	Learning Rate: 0.000424419
	LOSS [training: 0.19791018735502838 | validation: 0.2213146216448748]
	TIME [epoch: 8.47 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1895003425424691		[learning rate: 0.00042342]
	Learning Rate: 0.000423418
	LOSS [training: 0.1895003425424691 | validation: 0.16722614432611954]
	TIME [epoch: 8.48 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1724977305589547		[learning rate: 0.00042242]
	Learning Rate: 0.000422419
	LOSS [training: 0.1724977305589547 | validation: 0.17588835309373896]
	TIME [epoch: 8.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18156974626863157		[learning rate: 0.00042142]
	Learning Rate: 0.000421423
	LOSS [training: 0.18156974626863157 | validation: 0.17067494803573857]
	TIME [epoch: 8.47 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16738347376248214		[learning rate: 0.00042043]
	Learning Rate: 0.000420429
	LOSS [training: 0.16738347376248214 | validation: 0.17750485235002067]
	TIME [epoch: 8.46 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1978945224491536		[learning rate: 0.00041944]
	Learning Rate: 0.000419437
	LOSS [training: 0.1978945224491536 | validation: 0.22271730852222732]
	TIME [epoch: 8.49 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1931382415146937		[learning rate: 0.00041845]
	Learning Rate: 0.000418448
	LOSS [training: 0.1931382415146937 | validation: 0.267279288712586]
	TIME [epoch: 8.49 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28749737771874995		[learning rate: 0.00041746]
	Learning Rate: 0.00041746
	LOSS [training: 0.28749737771874995 | validation: 0.20658323232419135]
	TIME [epoch: 8.47 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1907001019720537		[learning rate: 0.00041648]
	Learning Rate: 0.000416476
	LOSS [training: 0.1907001019720537 | validation: 0.1704665645167165]
	TIME [epoch: 8.47 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18311772526148887		[learning rate: 0.00041549]
	Learning Rate: 0.000415493
	LOSS [training: 0.18311772526148887 | validation: 0.19377270366217803]
	TIME [epoch: 8.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1707481467438739		[learning rate: 0.00041451]
	Learning Rate: 0.000414513
	LOSS [training: 0.1707481467438739 | validation: 0.1696330252247707]
	TIME [epoch: 8.49 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17272251709371073		[learning rate: 0.00041354]
	Learning Rate: 0.000413535
	LOSS [training: 0.17272251709371073 | validation: 0.20255452761704684]
	TIME [epoch: 8.47 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21494106355551562		[learning rate: 0.00041256]
	Learning Rate: 0.00041256
	LOSS [training: 0.21494106355551562 | validation: 0.2833150276996803]
	TIME [epoch: 8.46 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20890409921818817		[learning rate: 0.00041159]
	Learning Rate: 0.000411587
	LOSS [training: 0.20890409921818817 | validation: 0.1723592861394253]
	TIME [epoch: 8.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20636624057132574		[learning rate: 0.00041062]
	Learning Rate: 0.000410616
	LOSS [training: 0.20636624057132574 | validation: 0.2401120809244981]
	TIME [epoch: 8.48 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20401500121672372		[learning rate: 0.00040965]
	Learning Rate: 0.000409647
	LOSS [training: 0.20401500121672372 | validation: 0.22411855269485753]
	TIME [epoch: 8.46 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34701248943900126		[learning rate: 0.00040868]
	Learning Rate: 0.000408681
	LOSS [training: 0.34701248943900126 | validation: 0.31747229332234383]
	TIME [epoch: 8.47 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2292813305545351		[learning rate: 0.00040772]
	Learning Rate: 0.000407717
	LOSS [training: 0.2292813305545351 | validation: 0.20854265398242655]
	TIME [epoch: 8.51 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18933914677798142		[learning rate: 0.00040676]
	Learning Rate: 0.000406755
	LOSS [training: 0.18933914677798142 | validation: 0.18507423560467584]
	TIME [epoch: 8.46 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18059234650002842		[learning rate: 0.0004058]
	Learning Rate: 0.000405796
	LOSS [training: 0.18059234650002842 | validation: 0.17629167820732355]
	TIME [epoch: 8.47 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2002255782342465		[learning rate: 0.00040484]
	Learning Rate: 0.000404839
	LOSS [training: 0.2002255782342465 | validation: 0.18158212503941903]
	TIME [epoch: 8.47 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1749207856847262		[learning rate: 0.00040388]
	Learning Rate: 0.000403884
	LOSS [training: 0.1749207856847262 | validation: 0.1805185352444313]
	TIME [epoch: 8.52 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1717820543301886		[learning rate: 0.00040293]
	Learning Rate: 0.000402931
	LOSS [training: 0.1717820543301886 | validation: 0.17424411344639734]
	TIME [epoch: 8.47 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15431079454563196		[learning rate: 0.00040198]
	Learning Rate: 0.000401981
	LOSS [training: 0.15431079454563196 | validation: 0.1712669553764727]
	TIME [epoch: 8.47 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1771998813385965		[learning rate: 0.00040103]
	Learning Rate: 0.000401032
	LOSS [training: 0.1771998813385965 | validation: 0.2095213872251417]
	TIME [epoch: 8.47 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19029488107164527		[learning rate: 0.00040009]
	Learning Rate: 0.000400086
	LOSS [training: 0.19029488107164527 | validation: 0.19713572254407513]
	TIME [epoch: 8.51 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1885898485697804		[learning rate: 0.00039914]
	Learning Rate: 0.000399143
	LOSS [training: 0.1885898485697804 | validation: 0.16305125548952404]
	TIME [epoch: 8.47 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17914197687488712		[learning rate: 0.0003982]
	Learning Rate: 0.000398201
	LOSS [training: 0.17914197687488712 | validation: 0.16660446588321487]
	TIME [epoch: 8.47 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1627019184744797		[learning rate: 0.00039726]
	Learning Rate: 0.000397262
	LOSS [training: 0.1627019184744797 | validation: 0.1919413921054004]
	TIME [epoch: 8.48 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18951054518549448		[learning rate: 0.00039632]
	Learning Rate: 0.000396325
	LOSS [training: 0.18951054518549448 | validation: 0.16837848113988635]
	TIME [epoch: 8.49 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17259161133102208		[learning rate: 0.00039539]
	Learning Rate: 0.00039539
	LOSS [training: 0.17259161133102208 | validation: 0.18606893160385254]
	TIME [epoch: 8.47 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1809841238858092		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.1809841238858092 | validation: 0.1965329835881891]
	TIME [epoch: 8.47 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18669106456712653		[learning rate: 0.00039353]
	Learning Rate: 0.000393527
	LOSS [training: 0.18669106456712653 | validation: 0.15836085215662898]
	TIME [epoch: 8.49 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1610551356098985		[learning rate: 0.0003926]
	Learning Rate: 0.000392599
	LOSS [training: 0.1610551356098985 | validation: 0.1735823917341624]
	TIME [epoch: 8.49 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18227533461166828		[learning rate: 0.00039167]
	Learning Rate: 0.000391672
	LOSS [training: 0.18227533461166828 | validation: 0.2499153220960354]
	TIME [epoch: 8.47 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2223684599749977		[learning rate: 0.00039075]
	Learning Rate: 0.000390748
	LOSS [training: 0.2223684599749977 | validation: 0.14902480739234933]
	TIME [epoch: 8.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1423.pth
	Model improved!!!
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15322155459074047		[learning rate: 0.00038983]
	Learning Rate: 0.000389827
	LOSS [training: 0.15322155459074047 | validation: 0.16600444895201777]
	TIME [epoch: 8.51 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15680443153943976		[learning rate: 0.00038891]
	Learning Rate: 0.000388907
	LOSS [training: 0.15680443153943976 | validation: 0.16568489369024167]
	TIME [epoch: 8.49 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16558934694984453		[learning rate: 0.00038799]
	Learning Rate: 0.00038799
	LOSS [training: 0.16558934694984453 | validation: 0.18434513728204843]
	TIME [epoch: 8.48 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17304837078090354		[learning rate: 0.00038707]
	Learning Rate: 0.000387075
	LOSS [training: 0.17304837078090354 | validation: 0.15398400961363123]
	TIME [epoch: 8.46 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15427788787730468		[learning rate: 0.00038616]
	Learning Rate: 0.000386162
	LOSS [training: 0.15427788787730468 | validation: 0.16045530933630228]
	TIME [epoch: 8.49 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1587580905356915		[learning rate: 0.00038525]
	Learning Rate: 0.000385251
	LOSS [training: 0.1587580905356915 | validation: 0.19175603293698928]
	TIME [epoch: 8.47 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19419926267220664		[learning rate: 0.00038434]
	Learning Rate: 0.000384342
	LOSS [training: 0.19419926267220664 | validation: 0.1828099292462484]
	TIME [epoch: 8.48 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16564026083827335		[learning rate: 0.00038344]
	Learning Rate: 0.000383435
	LOSS [training: 0.16564026083827335 | validation: 0.17703586096292567]
	TIME [epoch: 8.48 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2842325079415647		[learning rate: 0.00038253]
	Learning Rate: 0.000382531
	LOSS [training: 0.2842325079415647 | validation: 0.5017878962799587]
	TIME [epoch: 8.48 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42215778788383734		[learning rate: 0.00038163]
	Learning Rate: 0.000381629
	LOSS [training: 0.42215778788383734 | validation: 0.32025833712012075]
	TIME [epoch: 8.48 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1988408120493582		[learning rate: 0.00038073]
	Learning Rate: 0.000380729
	LOSS [training: 0.1988408120493582 | validation: 0.18161634664584167]
	TIME [epoch: 8.47 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1718084036331254		[learning rate: 0.00037983]
	Learning Rate: 0.00037983
	LOSS [training: 0.1718084036331254 | validation: 0.17334126040292264]
	TIME [epoch: 8.49 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16845190646652938		[learning rate: 0.00037893]
	Learning Rate: 0.000378934
	LOSS [training: 0.16845190646652938 | validation: 0.1772047097385615]
	TIME [epoch: 8.48 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21900852535884657		[learning rate: 0.00037804]
	Learning Rate: 0.000378041
	LOSS [training: 0.21900852535884657 | validation: 0.19715561433285864]
	TIME [epoch: 8.47 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21327079478745753		[learning rate: 0.00037715]
	Learning Rate: 0.000377149
	LOSS [training: 0.21327079478745753 | validation: 0.25804066845396795]
	TIME [epoch: 8.46 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20799940707466752		[learning rate: 0.00037626]
	Learning Rate: 0.000376259
	LOSS [training: 0.20799940707466752 | validation: 0.1785670830042378]
	TIME [epoch: 8.49 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20526693308926164		[learning rate: 0.00037537]
	Learning Rate: 0.000375372
	LOSS [training: 0.20526693308926164 | validation: 0.1959961196083322]
	TIME [epoch: 8.48 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2270487557339776		[learning rate: 0.00037449]
	Learning Rate: 0.000374486
	LOSS [training: 0.2270487557339776 | validation: 0.18260817579266808]
	TIME [epoch: 8.47 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1828030701870331		[learning rate: 0.0003736]
	Learning Rate: 0.000373603
	LOSS [training: 0.1828030701870331 | validation: 0.17283709349326598]
	TIME [epoch: 8.48 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1663653599827048		[learning rate: 0.00037272]
	Learning Rate: 0.000372722
	LOSS [training: 0.1663653599827048 | validation: 0.1674898078854792]
	TIME [epoch: 8.48 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1740286876158647		[learning rate: 0.00037184]
	Learning Rate: 0.000371842
	LOSS [training: 0.1740286876158647 | validation: 0.20548503736573945]
	TIME [epoch: 8.49 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17678789463157957		[learning rate: 0.00037097]
	Learning Rate: 0.000370965
	LOSS [training: 0.17678789463157957 | validation: 0.17058501740948417]
	TIME [epoch: 8.47 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16537116149081776		[learning rate: 0.00037009]
	Learning Rate: 0.00037009
	LOSS [training: 0.16537116149081776 | validation: 0.17267135967932834]
	TIME [epoch: 8.48 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17579967388953935		[learning rate: 0.00036922]
	Learning Rate: 0.000369217
	LOSS [training: 0.17579967388953935 | validation: 0.17856011698092009]
	TIME [epoch: 8.48 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16799136099545783		[learning rate: 0.00036835]
	Learning Rate: 0.000368346
	LOSS [training: 0.16799136099545783 | validation: 0.17999497374159346]
	TIME [epoch: 8.49 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17392183701969732		[learning rate: 0.00036748]
	Learning Rate: 0.000367477
	LOSS [training: 0.17392183701969732 | validation: 0.16797713980249518]
	TIME [epoch: 8.47 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1664383350720457		[learning rate: 0.00036661]
	Learning Rate: 0.000366611
	LOSS [training: 0.1664383350720457 | validation: 0.16173163732172077]
	TIME [epoch: 8.49 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2050515530022492		[learning rate: 0.00036575]
	Learning Rate: 0.000365746
	LOSS [training: 0.2050515530022492 | validation: 0.23240456667614875]
	TIME [epoch: 8.46 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19404023854993138		[learning rate: 0.00036488]
	Learning Rate: 0.000364883
	LOSS [training: 0.19404023854993138 | validation: 0.16162293967307723]
	TIME [epoch: 8.48 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1620693405645221		[learning rate: 0.00036402]
	Learning Rate: 0.000364022
	LOSS [training: 0.1620693405645221 | validation: 0.17671108535045407]
	TIME [epoch: 8.47 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17340895422712288		[learning rate: 0.00036316]
	Learning Rate: 0.000363164
	LOSS [training: 0.17340895422712288 | validation: 0.1919716849936764]
	TIME [epoch: 8.48 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17979277768194415		[learning rate: 0.00036231]
	Learning Rate: 0.000362307
	LOSS [training: 0.17979277768194415 | validation: 0.18242178158919276]
	TIME [epoch: 8.46 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16365170419129518		[learning rate: 0.00036145]
	Learning Rate: 0.000361452
	LOSS [training: 0.16365170419129518 | validation: 0.15840323338168666]
	TIME [epoch: 8.49 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1617673641797554		[learning rate: 0.0003606]
	Learning Rate: 0.0003606
	LOSS [training: 0.1617673641797554 | validation: 0.15363227923817172]
	TIME [epoch: 8.48 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18136944826418605		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.18136944826418605 | validation: 0.2171671525721415]
	TIME [epoch: 8.48 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17457641049353617		[learning rate: 0.0003589]
	Learning Rate: 0.000358901
	LOSS [training: 0.17457641049353617 | validation: 0.16405648334260944]
	TIME [epoch: 8.47 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15986437310373253		[learning rate: 0.00035805]
	Learning Rate: 0.000358054
	LOSS [training: 0.15986437310373253 | validation: 0.18139535772143245]
	TIME [epoch: 8.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16626519611930238		[learning rate: 0.00035721]
	Learning Rate: 0.00035721
	LOSS [training: 0.16626519611930238 | validation: 0.17382243723685564]
	TIME [epoch: 8.49 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22988029503131183		[learning rate: 0.00035637]
	Learning Rate: 0.000356367
	LOSS [training: 0.22988029503131183 | validation: 0.3236739854222313]
	TIME [epoch: 8.48 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22081536100179563		[learning rate: 0.00035553]
	Learning Rate: 0.000355526
	LOSS [training: 0.22081536100179563 | validation: 0.1646863162486209]
	TIME [epoch: 8.47 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1607041279002618		[learning rate: 0.00035469]
	Learning Rate: 0.000354688
	LOSS [training: 0.1607041279002618 | validation: 0.17105988739679806]
	TIME [epoch: 8.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16774671825856807		[learning rate: 0.00035385]
	Learning Rate: 0.000353851
	LOSS [training: 0.16774671825856807 | validation: 0.16373472293313437]
	TIME [epoch: 8.49 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17885537574238503		[learning rate: 0.00035302]
	Learning Rate: 0.000353016
	LOSS [training: 0.17885537574238503 | validation: 0.15917630664137322]
	TIME [epoch: 8.47 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1651654085090441		[learning rate: 0.00035218]
	Learning Rate: 0.000352184
	LOSS [training: 0.1651654085090441 | validation: 0.18620727462386832]
	TIME [epoch: 8.47 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18950385263047337		[learning rate: 0.00035135]
	Learning Rate: 0.000351353
	LOSS [training: 0.18950385263047337 | validation: 0.16464598589607554]
	TIME [epoch: 8.49 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16187153888755565		[learning rate: 0.00035052]
	Learning Rate: 0.000350524
	LOSS [training: 0.16187153888755565 | validation: 0.19434309521097048]
	TIME [epoch: 8.49 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1865150955665463		[learning rate: 0.0003497]
	Learning Rate: 0.000349697
	LOSS [training: 0.1865150955665463 | validation: 0.2050478847004471]
	TIME [epoch: 8.47 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19822796741684612		[learning rate: 0.00034887]
	Learning Rate: 0.000348872
	LOSS [training: 0.19822796741684612 | validation: 0.20920281113676653]
	TIME [epoch: 8.48 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1981733515947491		[learning rate: 0.00034805]
	Learning Rate: 0.000348049
	LOSS [training: 0.1981733515947491 | validation: 0.19041219993206923]
	TIME [epoch: 8.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17993312892051083		[learning rate: 0.00034723]
	Learning Rate: 0.000347228
	LOSS [training: 0.17993312892051083 | validation: 0.1753538543174629]
	TIME [epoch: 8.47 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1947258834061469		[learning rate: 0.00034641]
	Learning Rate: 0.000346409
	LOSS [training: 0.1947258834061469 | validation: 0.1844638806829707]
	TIME [epoch: 8.47 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.184984344030058		[learning rate: 0.00034559]
	Learning Rate: 0.000345592
	LOSS [training: 0.184984344030058 | validation: 0.21311274330298796]
	TIME [epoch: 8.48 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25398794540744385		[learning rate: 0.00034478]
	Learning Rate: 0.000344777
	LOSS [training: 0.25398794540744385 | validation: 0.22371000254423634]
	TIME [epoch: 8.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2105072499137092		[learning rate: 0.00034396]
	Learning Rate: 0.000343964
	LOSS [training: 0.2105072499137092 | validation: 0.20761360204609958]
	TIME [epoch: 8.48 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19705973592222586		[learning rate: 0.00034315]
	Learning Rate: 0.000343152
	LOSS [training: 0.19705973592222586 | validation: 0.19580741105058874]
	TIME [epoch: 8.47 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1707986296094342		[learning rate: 0.00034234]
	Learning Rate: 0.000342343
	LOSS [training: 0.1707986296094342 | validation: 0.18028529050988523]
	TIME [epoch: 8.48 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1769230752201227		[learning rate: 0.00034154]
	Learning Rate: 0.000341536
	LOSS [training: 0.1769230752201227 | validation: 0.175960979209268]
	TIME [epoch: 8.49 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18640160030899605		[learning rate: 0.00034073]
	Learning Rate: 0.00034073
	LOSS [training: 0.18640160030899605 | validation: 0.23312075985739228]
	TIME [epoch: 8.47 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2446738756667623		[learning rate: 0.00033993]
	Learning Rate: 0.000339926
	LOSS [training: 0.2446738756667623 | validation: 0.24644774913158746]
	TIME [epoch: 8.46 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.205934270720905		[learning rate: 0.00033912]
	Learning Rate: 0.000339124
	LOSS [training: 0.205934270720905 | validation: 0.20612135602834958]
	TIME [epoch: 8.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19705886637250355		[learning rate: 0.00033832]
	Learning Rate: 0.000338324
	LOSS [training: 0.19705886637250355 | validation: 0.1877186720821503]
	TIME [epoch: 8.49 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18082765118695465		[learning rate: 0.00033753]
	Learning Rate: 0.000337526
	LOSS [training: 0.18082765118695465 | validation: 0.18140806758689398]
	TIME [epoch: 8.47 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17998180761739357		[learning rate: 0.00033673]
	Learning Rate: 0.00033673
	LOSS [training: 0.17998180761739357 | validation: 0.18769702718615014]
	TIME [epoch: 8.47 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17729193688080228		[learning rate: 0.00033594]
	Learning Rate: 0.000335936
	LOSS [training: 0.17729193688080228 | validation: 0.16535567828798778]
	TIME [epoch: 8.51 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1623200846871486		[learning rate: 0.00033514]
	Learning Rate: 0.000335143
	LOSS [training: 0.1623200846871486 | validation: 0.1801043835085705]
	TIME [epoch: 8.48 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19859685638184302		[learning rate: 0.00033435]
	Learning Rate: 0.000334353
	LOSS [training: 0.19859685638184302 | validation: 0.23190356269683898]
	TIME [epoch: 8.47 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23723514106305982		[learning rate: 0.00033356]
	Learning Rate: 0.000333564
	LOSS [training: 0.23723514106305982 | validation: 0.2127172655033614]
	TIME [epoch: 8.47 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22424850850356726		[learning rate: 0.00033278]
	Learning Rate: 0.000332777
	LOSS [training: 0.22424850850356726 | validation: 0.20540007606418917]
	TIME [epoch: 8.51 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19387225708367356		[learning rate: 0.00033199]
	Learning Rate: 0.000331992
	LOSS [training: 0.19387225708367356 | validation: 0.1823098413367023]
	TIME [epoch: 8.47 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18124882383952592		[learning rate: 0.00033121]
	Learning Rate: 0.000331209
	LOSS [training: 0.18124882383952592 | validation: 0.19215437253507145]
	TIME [epoch: 8.47 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18546552635033547		[learning rate: 0.00033043]
	Learning Rate: 0.000330428
	LOSS [training: 0.18546552635033547 | validation: 0.19321801319954424]
	TIME [epoch: 8.46 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20235735526721688		[learning rate: 0.00032965]
	Learning Rate: 0.000329649
	LOSS [training: 0.20235735526721688 | validation: 0.20965046174436835]
	TIME [epoch: 8.51 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20246566325068724		[learning rate: 0.00032887]
	Learning Rate: 0.000328871
	LOSS [training: 0.20246566325068724 | validation: 0.19417096893447228]
	TIME [epoch: 8.46 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18573148803677123		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.18573148803677123 | validation: 0.19016323184987713]
	TIME [epoch: 8.47 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21917389154445316		[learning rate: 0.00032732]
	Learning Rate: 0.000327321
	LOSS [training: 0.21917389154445316 | validation: 0.1889081306167863]
	TIME [epoch: 8.46 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16536490184034774		[learning rate: 0.00032655]
	Learning Rate: 0.000326549
	LOSS [training: 0.16536490184034774 | validation: 0.17806362798273012]
	TIME [epoch: 8.51 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15580798444343205		[learning rate: 0.00032578]
	Learning Rate: 0.000325779
	LOSS [training: 0.15580798444343205 | validation: 0.1692072780130957]
	TIME [epoch: 8.46 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1624412203606441		[learning rate: 0.00032501]
	Learning Rate: 0.000325011
	LOSS [training: 0.1624412203606441 | validation: 0.17868095589491345]
	TIME [epoch: 8.46 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1841380258992689		[learning rate: 0.00032424]
	Learning Rate: 0.000324244
	LOSS [training: 0.1841380258992689 | validation: 0.18233325895823108]
	TIME [epoch: 8.48 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17729222056451363		[learning rate: 0.00032348]
	Learning Rate: 0.000323479
	LOSS [training: 0.17729222056451363 | validation: 0.18467042463704236]
	TIME [epoch: 8.51 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1685716437722988		[learning rate: 0.00032272]
	Learning Rate: 0.000322716
	LOSS [training: 0.1685716437722988 | validation: 0.18343164990400465]
	TIME [epoch: 8.47 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15762039548166445		[learning rate: 0.00032195]
	Learning Rate: 0.000321955
	LOSS [training: 0.15762039548166445 | validation: 0.16930017160130828]
	TIME [epoch: 8.48 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1617594126666647		[learning rate: 0.0003212]
	Learning Rate: 0.000321195
	LOSS [training: 0.1617594126666647 | validation: 0.16711718466745618]
	TIME [epoch: 8.49 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17308723755995972		[learning rate: 0.00032044]
	Learning Rate: 0.000320438
	LOSS [training: 0.17308723755995972 | validation: 0.20490014867362455]
	TIME [epoch: 8.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2959278713662127		[learning rate: 0.00031968]
	Learning Rate: 0.000319682
	LOSS [training: 0.2959278713662127 | validation: 0.2513992299614459]
	TIME [epoch: 8.47 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22925211385365615		[learning rate: 0.00031893]
	Learning Rate: 0.000318928
	LOSS [training: 0.22925211385365615 | validation: 0.22275223721739906]
	TIME [epoch: 8.46 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2319033802716412		[learning rate: 0.00031818]
	Learning Rate: 0.000318175
	LOSS [training: 0.2319033802716412 | validation: 0.2248725259298267]
	TIME [epoch: 8.49 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20927432880662095		[learning rate: 0.00031742]
	Learning Rate: 0.000317425
	LOSS [training: 0.20927432880662095 | validation: 0.19536661754711543]
	TIME [epoch: 8.48 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17387303427990725		[learning rate: 0.00031668]
	Learning Rate: 0.000316676
	LOSS [training: 0.17387303427990725 | validation: 0.15420572966774537]
	TIME [epoch: 8.47 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16536552038920466		[learning rate: 0.00031593]
	Learning Rate: 0.000315929
	LOSS [training: 0.16536552038920466 | validation: 0.16979796839232314]
	TIME [epoch: 8.47 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18503771862052418		[learning rate: 0.00031518]
	Learning Rate: 0.000315184
	LOSS [training: 0.18503771862052418 | validation: 0.29332373397705935]
	TIME [epoch: 8.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33370799709472443		[learning rate: 0.00031444]
	Learning Rate: 0.00031444
	LOSS [training: 0.33370799709472443 | validation: 0.26608529414295534]
	TIME [epoch: 8.49 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21345048403701677		[learning rate: 0.0003137]
	Learning Rate: 0.000313699
	LOSS [training: 0.21345048403701677 | validation: 0.24615708225416216]
	TIME [epoch: 8.46 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17937032532813582		[learning rate: 0.00031296]
	Learning Rate: 0.000312959
	LOSS [training: 0.17937032532813582 | validation: 0.14794699970728825]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1517.pth
	Model improved!!!
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17724520657384607		[learning rate: 0.00031222]
	Learning Rate: 0.000312221
	LOSS [training: 0.17724520657384607 | validation: 0.23069709549036654]
	TIME [epoch: 8.49 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22672482723732248		[learning rate: 0.00031148]
	Learning Rate: 0.000311484
	LOSS [training: 0.22672482723732248 | validation: 0.31001325300868443]
	TIME [epoch: 8.47 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31884700360625257		[learning rate: 0.00031075]
	Learning Rate: 0.000310749
	LOSS [training: 0.31884700360625257 | validation: 0.2287400552402438]
	TIME [epoch: 8.46 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1890970487991535		[learning rate: 0.00031002]
	Learning Rate: 0.000310016
	LOSS [training: 0.1890970487991535 | validation: 0.16911913155251118]
	TIME [epoch: 8.48 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15621824786931365		[learning rate: 0.00030929]
	Learning Rate: 0.000309285
	LOSS [training: 0.15621824786931365 | validation: 0.15536899341365507]
	TIME [epoch: 8.46 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1534325350238753		[learning rate: 0.00030856]
	Learning Rate: 0.000308555
	LOSS [training: 0.1534325350238753 | validation: 0.16447513429713176]
	TIME [epoch: 8.48 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15912849664030312		[learning rate: 0.00030783]
	Learning Rate: 0.000307828
	LOSS [training: 0.15912849664030312 | validation: 0.16558234974664307]
	TIME [epoch: 8.46 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20185484025352984		[learning rate: 0.0003071]
	Learning Rate: 0.000307102
	LOSS [training: 0.20185484025352984 | validation: 0.24193504647520492]
	TIME [epoch: 8.48 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24524595029838622		[learning rate: 0.00030638]
	Learning Rate: 0.000306377
	LOSS [training: 0.24524595029838622 | validation: 0.23155799600023874]
	TIME [epoch: 8.48 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27191693306955333		[learning rate: 0.00030565]
	Learning Rate: 0.000305654
	LOSS [training: 0.27191693306955333 | validation: 0.2501888225487483]
	TIME [epoch: 8.49 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22995497012058638		[learning rate: 0.00030493]
	Learning Rate: 0.000304933
	LOSS [training: 0.22995497012058638 | validation: 0.2225471743473178]
	TIME [epoch: 8.48 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19644496463358666		[learning rate: 0.00030421]
	Learning Rate: 0.000304214
	LOSS [training: 0.19644496463358666 | validation: 0.19288943230946626]
	TIME [epoch: 8.48 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19635314157450925		[learning rate: 0.0003035]
	Learning Rate: 0.000303497
	LOSS [training: 0.19635314157450925 | validation: 0.2151009711315481]
	TIME [epoch: 8.48 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20165608888560654		[learning rate: 0.00030278]
	Learning Rate: 0.000302781
	LOSS [training: 0.20165608888560654 | validation: 0.20553856691336908]
	TIME [epoch: 8.48 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19087090950428595		[learning rate: 0.00030207]
	Learning Rate: 0.000302066
	LOSS [training: 0.19087090950428595 | validation: 0.17631634296828697]
	TIME [epoch: 8.49 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1695410521843674		[learning rate: 0.00030135]
	Learning Rate: 0.000301354
	LOSS [training: 0.1695410521843674 | validation: 0.17123311541666877]
	TIME [epoch: 8.47 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19512536757405474		[learning rate: 0.00030064]
	Learning Rate: 0.000300643
	LOSS [training: 0.19512536757405474 | validation: 0.18602392280620567]
	TIME [epoch: 8.49 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1942508091492992		[learning rate: 0.00029993]
	Learning Rate: 0.000299934
	LOSS [training: 0.1942508091492992 | validation: 0.1993531113385519]
	TIME [epoch: 8.47 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2025584639254911		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.2025584639254911 | validation: 0.21477523225103862]
	TIME [epoch: 8.49 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19427070201518165		[learning rate: 0.00029852]
	Learning Rate: 0.000298521
	LOSS [training: 0.19427070201518165 | validation: 0.20221783241122576]
	TIME [epoch: 8.47 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17474569135121568		[learning rate: 0.00029782]
	Learning Rate: 0.000297816
	LOSS [training: 0.17474569135121568 | validation: 0.17372219557063232]
	TIME [epoch: 8.48 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16198609736608938		[learning rate: 0.00029711]
	Learning Rate: 0.000297114
	LOSS [training: 0.16198609736608938 | validation: 0.16093342399940197]
	TIME [epoch: 8.47 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15374735051352267		[learning rate: 0.00029641]
	Learning Rate: 0.000296413
	LOSS [training: 0.15374735051352267 | validation: 0.1635035844866779]
	TIME [epoch: 8.49 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16940550277494554		[learning rate: 0.00029571]
	Learning Rate: 0.000295714
	LOSS [training: 0.16940550277494554 | validation: 0.18068574673407956]
	TIME [epoch: 8.46 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16581785286957715		[learning rate: 0.00029502]
	Learning Rate: 0.000295016
	LOSS [training: 0.16581785286957715 | validation: 0.1799095476066162]
	TIME [epoch: 8.48 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18286350675362942		[learning rate: 0.00029432]
	Learning Rate: 0.00029432
	LOSS [training: 0.18286350675362942 | validation: 0.18856038440025613]
	TIME [epoch: 8.48 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19050818465801944		[learning rate: 0.00029363]
	Learning Rate: 0.000293626
	LOSS [training: 0.19050818465801944 | validation: 0.2006787182729352]
	TIME [epoch: 8.47 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20860726676594554		[learning rate: 0.00029293]
	Learning Rate: 0.000292934
	LOSS [training: 0.20860726676594554 | validation: 0.20056429974559312]
	TIME [epoch: 8.47 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23427907448077984		[learning rate: 0.00029224]
	Learning Rate: 0.000292243
	LOSS [training: 0.23427907448077984 | validation: 0.25415310211519754]
	TIME [epoch: 8.49 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23544309874295433		[learning rate: 0.00029155]
	Learning Rate: 0.000291553
	LOSS [training: 0.23544309874295433 | validation: 0.284469989637658]
	TIME [epoch: 8.49 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23254149711296085		[learning rate: 0.00029087]
	Learning Rate: 0.000290866
	LOSS [training: 0.23254149711296085 | validation: 0.19782484990674604]
	TIME [epoch: 8.47 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20355657520247808		[learning rate: 0.00029018]
	Learning Rate: 0.000290179
	LOSS [training: 0.20355657520247808 | validation: 0.18730508778619137]
	TIME [epoch: 8.47 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.171026291500964		[learning rate: 0.00028949]
	Learning Rate: 0.000289495
	LOSS [training: 0.171026291500964 | validation: 0.17090589588352123]
	TIME [epoch: 8.49 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15552036316760698		[learning rate: 0.00028881]
	Learning Rate: 0.000288812
	LOSS [training: 0.15552036316760698 | validation: 0.1607406248636616]
	TIME [epoch: 8.49 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15504389231269922		[learning rate: 0.00028813]
	Learning Rate: 0.000288131
	LOSS [training: 0.15504389231269922 | validation: 0.15453884101298426]
	TIME [epoch: 8.47 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1646863453282806		[learning rate: 0.00028745]
	Learning Rate: 0.000287451
	LOSS [training: 0.1646863453282806 | validation: 0.17161095784308983]
	TIME [epoch: 8.47 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17755356478861947		[learning rate: 0.00028677]
	Learning Rate: 0.000286773
	LOSS [training: 0.17755356478861947 | validation: 0.18402623211585867]
	TIME [epoch: 8.49 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16688250380879993		[learning rate: 0.0002861]
	Learning Rate: 0.000286097
	LOSS [training: 0.16688250380879993 | validation: 0.16713537384202684]
	TIME [epoch: 8.48 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.176285412097945		[learning rate: 0.00028542]
	Learning Rate: 0.000285422
	LOSS [training: 0.176285412097945 | validation: 0.1850026070728796]
	TIME [epoch: 8.46 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1704483861060679		[learning rate: 0.00028475]
	Learning Rate: 0.000284749
	LOSS [training: 0.1704483861060679 | validation: 0.16178631635858615]
	TIME [epoch: 8.47 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16992746950134974		[learning rate: 0.00028408]
	Learning Rate: 0.000284077
	LOSS [training: 0.16992746950134974 | validation: 0.18741924078225064]
	TIME [epoch: 8.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17276853591105418		[learning rate: 0.00028341]
	Learning Rate: 0.000283407
	LOSS [training: 0.17276853591105418 | validation: 0.1778726237866794]
	TIME [epoch: 8.48 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19390663962661048		[learning rate: 0.00028274]
	Learning Rate: 0.000282738
	LOSS [training: 0.19390663962661048 | validation: 0.20839391569809937]
	TIME [epoch: 8.47 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21783234706278592		[learning rate: 0.00028207]
	Learning Rate: 0.000282071
	LOSS [training: 0.21783234706278592 | validation: 0.23577805143877825]
	TIME [epoch: 8.48 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22822194492698622		[learning rate: 0.00028141]
	Learning Rate: 0.000281406
	LOSS [training: 0.22822194492698622 | validation: 0.21777518243491711]
	TIME [epoch: 8.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20061040570671657		[learning rate: 0.00028074]
	Learning Rate: 0.000280742
	LOSS [training: 0.20061040570671657 | validation: 0.19874109445926785]
	TIME [epoch: 8.47 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2016989498236398		[learning rate: 0.00028008]
	Learning Rate: 0.00028008
	LOSS [training: 0.2016989498236398 | validation: 0.22545594370539984]
	TIME [epoch: 8.46 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1980810959212082		[learning rate: 0.00027942]
	Learning Rate: 0.000279419
	LOSS [training: 0.1980810959212082 | validation: 0.18399892997256945]
	TIME [epoch: 8.48 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16817235711775788		[learning rate: 0.00027876]
	Learning Rate: 0.00027876
	LOSS [training: 0.16817235711775788 | validation: 0.16836124555151466]
	TIME [epoch: 8.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18573283867826307		[learning rate: 0.0002781]
	Learning Rate: 0.000278103
	LOSS [training: 0.18573283867826307 | validation: 0.19317098183853487]
	TIME [epoch: 8.47 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18884437527878936		[learning rate: 0.00027745]
	Learning Rate: 0.000277447
	LOSS [training: 0.18884437527878936 | validation: 0.18361251712416055]
	TIME [epoch: 8.46 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17988654263392204		[learning rate: 0.00027679]
	Learning Rate: 0.000276792
	LOSS [training: 0.17988654263392204 | validation: 0.16923082027021114]
	TIME [epoch: 8.48 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16548850128016915		[learning rate: 0.00027614]
	Learning Rate: 0.000276139
	LOSS [training: 0.16548850128016915 | validation: 0.17165898454478581]
	TIME [epoch: 8.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1646643095342766		[learning rate: 0.00027549]
	Learning Rate: 0.000275488
	LOSS [training: 0.1646643095342766 | validation: 0.19520372831836535]
	TIME [epoch: 8.46 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1889667198159757		[learning rate: 0.00027484]
	Learning Rate: 0.000274838
	LOSS [training: 0.1889667198159757 | validation: 0.1701169877405872]
	TIME [epoch: 8.47 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15654636480536538		[learning rate: 0.00027419]
	Learning Rate: 0.00027419
	LOSS [training: 0.15654636480536538 | validation: 0.16998638613712003]
	TIME [epoch: 8.49 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15689364392138067		[learning rate: 0.00027354]
	Learning Rate: 0.000273543
	LOSS [training: 0.15689364392138067 | validation: 0.15165703540598752]
	TIME [epoch: 8.48 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1842626181529417		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.1842626181529417 | validation: 0.2799815994351156]
	TIME [epoch: 8.46 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26091278280969254		[learning rate: 0.00027225]
	Learning Rate: 0.000272254
	LOSS [training: 0.26091278280969254 | validation: 0.27228133361723617]
	TIME [epoch: 8.47 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22832498333124462		[learning rate: 0.00027161]
	Learning Rate: 0.000271612
	LOSS [training: 0.22832498333124462 | validation: 0.18220638580156095]
	TIME [epoch: 8.49 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17290035603933585		[learning rate: 0.00027097]
	Learning Rate: 0.000270971
	LOSS [training: 0.17290035603933585 | validation: 0.17140819956262046]
	TIME [epoch: 8.48 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15543216927738077		[learning rate: 0.00027033]
	Learning Rate: 0.000270332
	LOSS [training: 0.15543216927738077 | validation: 0.1628152835399227]
	TIME [epoch: 8.46 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15223838815801477		[learning rate: 0.00026969]
	Learning Rate: 0.000269694
	LOSS [training: 0.15223838815801477 | validation: 0.15730727084250623]
	TIME [epoch: 8.47 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15442186926335083		[learning rate: 0.00026906]
	Learning Rate: 0.000269058
	LOSS [training: 0.15442186926335083 | validation: 0.1522808212121184]
	TIME [epoch: 8.51 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15979239375217097		[learning rate: 0.00026842]
	Learning Rate: 0.000268423
	LOSS [training: 0.15979239375217097 | validation: 0.1711997013434162]
	TIME [epoch: 8.47 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15735198802003345		[learning rate: 0.00026779]
	Learning Rate: 0.00026779
	LOSS [training: 0.15735198802003345 | validation: 0.15869542124903255]
	TIME [epoch: 8.47 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20216134031973967		[learning rate: 0.00026716]
	Learning Rate: 0.000267159
	LOSS [training: 0.20216134031973967 | validation: 0.19755566401843502]
	TIME [epoch: 8.46 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17949964743163305		[learning rate: 0.00026653]
	Learning Rate: 0.000266528
	LOSS [training: 0.17949964743163305 | validation: 0.17096283968500117]
	TIME [epoch: 8.51 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16057467667007636		[learning rate: 0.0002659]
	Learning Rate: 0.0002659
	LOSS [training: 0.16057467667007636 | validation: 0.1575133830746267]
	TIME [epoch: 8.46 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18250365358331544		[learning rate: 0.00026527]
	Learning Rate: 0.000265273
	LOSS [training: 0.18250365358331544 | validation: 0.20269775590426262]
	TIME [epoch: 8.46 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20798327997038127		[learning rate: 0.00026465]
	Learning Rate: 0.000264647
	LOSS [training: 0.20798327997038127 | validation: 0.16353586729328706]
	TIME [epoch: 8.49 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15948511049598568		[learning rate: 0.00026402]
	Learning Rate: 0.000264022
	LOSS [training: 0.15948511049598568 | validation: 0.1661833324957145]
	TIME [epoch: 8.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15137133098378788		[learning rate: 0.0002634]
	Learning Rate: 0.0002634
	LOSS [training: 0.15137133098378788 | validation: 0.14965583121466908]
	TIME [epoch: 8.46 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1561095097552153		[learning rate: 0.00026278]
	Learning Rate: 0.000262778
	LOSS [training: 0.1561095097552153 | validation: 0.16396114915100427]
	TIME [epoch: 8.47 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1509115253809983		[learning rate: 0.00026216]
	Learning Rate: 0.000262159
	LOSS [training: 0.1509115253809983 | validation: 0.14855406659385748]
	TIME [epoch: 8.47 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1591630745379154		[learning rate: 0.00026154]
	Learning Rate: 0.00026154
	LOSS [training: 0.1591630745379154 | validation: 0.18011396004418884]
	TIME [epoch: 8.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.177731342410471		[learning rate: 0.00026092]
	Learning Rate: 0.000260923
	LOSS [training: 0.177731342410471 | validation: 0.2077285719299259]
	TIME [epoch: 8.46 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17907235153600048		[learning rate: 0.00026031]
	Learning Rate: 0.000260308
	LOSS [training: 0.17907235153600048 | validation: 0.1803050732254038]
	TIME [epoch: 8.46 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18121037902201703		[learning rate: 0.00025969]
	Learning Rate: 0.000259694
	LOSS [training: 0.18121037902201703 | validation: 0.18443465238033552]
	TIME [epoch: 8.49 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16484673398133948		[learning rate: 0.00025908]
	Learning Rate: 0.000259081
	LOSS [training: 0.16484673398133948 | validation: 0.15537940873547473]
	TIME [epoch: 8.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16030308952169464		[learning rate: 0.00025847]
	Learning Rate: 0.00025847
	LOSS [training: 0.16030308952169464 | validation: 0.16094276982905314]
	TIME [epoch: 8.46 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16560337262179478		[learning rate: 0.00025786]
	Learning Rate: 0.00025786
	LOSS [training: 0.16560337262179478 | validation: 0.1734805136327794]
	TIME [epoch: 8.46 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17750717747471184		[learning rate: 0.00025725]
	Learning Rate: 0.000257252
	LOSS [training: 0.17750717747471184 | validation: 0.16417976966587175]
	TIME [epoch: 8.49 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17944772457982258		[learning rate: 0.00025665]
	Learning Rate: 0.000256645
	LOSS [training: 0.17944772457982258 | validation: 0.1981614461997043]
	TIME [epoch: 8.48 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1849669036589068		[learning rate: 0.00025604]
	Learning Rate: 0.00025604
	LOSS [training: 0.1849669036589068 | validation: 0.18239673793887168]
	TIME [epoch: 8.46 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1656119243600101		[learning rate: 0.00025544]
	Learning Rate: 0.000255436
	LOSS [training: 0.1656119243600101 | validation: 0.16813097439917235]
	TIME [epoch: 8.47 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18472314291345862		[learning rate: 0.00025483]
	Learning Rate: 0.000254833
	LOSS [training: 0.18472314291345862 | validation: 0.16720837729147509]
	TIME [epoch: 8.49 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19831524448265966		[learning rate: 0.00025423]
	Learning Rate: 0.000254232
	LOSS [training: 0.19831524448265966 | validation: 0.20539447152329363]
	TIME [epoch: 8.48 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1762357688792712		[learning rate: 0.00025363]
	Learning Rate: 0.000253633
	LOSS [training: 0.1762357688792712 | validation: 0.1545340342178388]
	TIME [epoch: 8.47 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1613337134821986		[learning rate: 0.00025303]
	Learning Rate: 0.000253034
	LOSS [training: 0.1613337134821986 | validation: 0.18297673942389753]
	TIME [epoch: 8.48 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1668130671779054		[learning rate: 0.00025244]
	Learning Rate: 0.000252437
	LOSS [training: 0.1668130671779054 | validation: 0.14995234920469724]
	TIME [epoch: 8.49 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1482333718705233		[learning rate: 0.00025184]
	Learning Rate: 0.000251842
	LOSS [training: 0.1482333718705233 | validation: 0.1428630302960116]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1609.pth
	Model improved!!!
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15099820342987338		[learning rate: 0.00025125]
	Learning Rate: 0.000251248
	LOSS [training: 0.15099820342987338 | validation: 0.1605665142455453]
	TIME [epoch: 8.46 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16116810866418724		[learning rate: 0.00025066]
	Learning Rate: 0.000250655
	LOSS [training: 0.16116810866418724 | validation: 0.17474721301210427]
	TIME [epoch: 8.48 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15722908556327228		[learning rate: 0.00025006]
	Learning Rate: 0.000250064
	LOSS [training: 0.15722908556327228 | validation: 0.1629522540560246]
	TIME [epoch: 8.48 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15794801249091864		[learning rate: 0.00024947]
	Learning Rate: 0.000249474
	LOSS [training: 0.15794801249091864 | validation: 0.14683059060236214]
	TIME [epoch: 8.47 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1557627913401495		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.1557627913401495 | validation: 0.17328095390626472]
	TIME [epoch: 8.46 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18734381335913994		[learning rate: 0.0002483]
	Learning Rate: 0.000248299
	LOSS [training: 0.18734381335913994 | validation: 0.18676063697044185]
	TIME [epoch: 8.48 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.179371041372642		[learning rate: 0.00024771]
	Learning Rate: 0.000247713
	LOSS [training: 0.179371041372642 | validation: 0.15196228559358674]
	TIME [epoch: 8.48 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16252879924181401		[learning rate: 0.00024713]
	Learning Rate: 0.000247129
	LOSS [training: 0.16252879924181401 | validation: 0.15554331350270628]
	TIME [epoch: 8.47 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20652654453885452		[learning rate: 0.00024655]
	Learning Rate: 0.000246546
	LOSS [training: 0.20652654453885452 | validation: 0.18393382410456238]
	TIME [epoch: 8.48 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1648115275111039		[learning rate: 0.00024596]
	Learning Rate: 0.000245964
	LOSS [training: 0.1648115275111039 | validation: 0.14547040622842802]
	TIME [epoch: 8.48 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15305186465795212		[learning rate: 0.00024538]
	Learning Rate: 0.000245384
	LOSS [training: 0.15305186465795212 | validation: 0.17019785096887935]
	TIME [epoch: 8.48 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14793198631178478		[learning rate: 0.00024481]
	Learning Rate: 0.000244805
	LOSS [training: 0.14793198631178478 | validation: 0.16750365668529818]
	TIME [epoch: 8.48 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.156486907478886		[learning rate: 0.00024423]
	Learning Rate: 0.000244228
	LOSS [training: 0.156486907478886 | validation: 0.1612094475091681]
	TIME [epoch: 8.47 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1506772259407679		[learning rate: 0.00024365]
	Learning Rate: 0.000243652
	LOSS [training: 0.1506772259407679 | validation: 0.16176219198892544]
	TIME [epoch: 8.48 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16929948787264182		[learning rate: 0.00024308]
	Learning Rate: 0.000243077
	LOSS [training: 0.16929948787264182 | validation: 0.18131056893523664]
	TIME [epoch: 8.48 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15785879705475908		[learning rate: 0.0002425]
	Learning Rate: 0.000242503
	LOSS [training: 0.15785879705475908 | validation: 0.14560546572633323]
	TIME [epoch: 8.47 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15133794721650604		[learning rate: 0.00024193]
	Learning Rate: 0.000241931
	LOSS [training: 0.15133794721650604 | validation: 0.14861488226136083]
	TIME [epoch: 8.48 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15496303296562627		[learning rate: 0.00024136]
	Learning Rate: 0.000241361
	LOSS [training: 0.15496303296562627 | validation: 0.1682530063882749]
	TIME [epoch: 8.47 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14861068326521415		[learning rate: 0.00024079]
	Learning Rate: 0.000240791
	LOSS [training: 0.14861068326521415 | validation: 0.15715179151410608]
	TIME [epoch: 8.49 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16942193280975798		[learning rate: 0.00024022]
	Learning Rate: 0.000240223
	LOSS [training: 0.16942193280975798 | validation: 0.1958853116544123]
	TIME [epoch: 8.46 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19735935115956704		[learning rate: 0.00023966]
	Learning Rate: 0.000239657
	LOSS [training: 0.19735935115956704 | validation: 0.17514032989661935]
	TIME [epoch: 8.48 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16209691376198643		[learning rate: 0.00023909]
	Learning Rate: 0.000239091
	LOSS [training: 0.16209691376198643 | validation: 0.15478735061351678]
	TIME [epoch: 8.47 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17370013910604556		[learning rate: 0.00023853]
	Learning Rate: 0.000238527
	LOSS [training: 0.17370013910604556 | validation: 0.198244906322525]
	TIME [epoch: 8.49 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18313877598254247		[learning rate: 0.00023796]
	Learning Rate: 0.000237965
	LOSS [training: 0.18313877598254247 | validation: 0.18378478765807582]
	TIME [epoch: 8.47 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17379699141660127		[learning rate: 0.0002374]
	Learning Rate: 0.000237404
	LOSS [training: 0.17379699141660127 | validation: 0.1676420255095873]
	TIME [epoch: 8.49 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1604044127680732		[learning rate: 0.00023684]
	Learning Rate: 0.000236844
	LOSS [training: 0.1604044127680732 | validation: 0.15795205422196035]
	TIME [epoch: 8.46 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17482127839471082		[learning rate: 0.00023628]
	Learning Rate: 0.000236285
	LOSS [training: 0.17482127839471082 | validation: 0.16560886725743262]
	TIME [epoch: 8.48 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1505795366472505		[learning rate: 0.00023573]
	Learning Rate: 0.000235728
	LOSS [training: 0.1505795366472505 | validation: 0.1711076228949093]
	TIME [epoch: 8.48 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1556518906380278		[learning rate: 0.00023517]
	Learning Rate: 0.000235171
	LOSS [training: 0.1556518906380278 | validation: 0.1510473889745331]
	TIME [epoch: 8.48 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1624372606184124		[learning rate: 0.00023462]
	Learning Rate: 0.000234617
	LOSS [training: 0.1624372606184124 | validation: 0.1783889459536771]
	TIME [epoch: 8.46 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16602579575824997		[learning rate: 0.00023406]
	Learning Rate: 0.000234063
	LOSS [training: 0.16602579575824997 | validation: 0.1583049468782583]
	TIME [epoch: 8.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14657443846793777		[learning rate: 0.00023351]
	Learning Rate: 0.000233511
	LOSS [training: 0.14657443846793777 | validation: 0.15337722317478553]
	TIME [epoch: 8.47 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1815013077214912		[learning rate: 0.00023296]
	Learning Rate: 0.00023296
	LOSS [training: 0.1815013077214912 | validation: 0.21792441779891097]
	TIME [epoch: 8.48 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2329043024688049		[learning rate: 0.00023241]
	Learning Rate: 0.000232411
	LOSS [training: 0.2329043024688049 | validation: 0.2370491882856319]
	TIME [epoch: 8.47 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29664415328117094		[learning rate: 0.00023186]
	Learning Rate: 0.000231863
	LOSS [training: 0.29664415328117094 | validation: 0.39820257188745545]
	TIME [epoch: 8.49 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36223711010711124		[learning rate: 0.00023132]
	Learning Rate: 0.000231316
	LOSS [training: 0.36223711010711124 | validation: 0.23597240022124064]
	TIME [epoch: 8.48 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19116275901797936		[learning rate: 0.00023077]
	Learning Rate: 0.00023077
	LOSS [training: 0.19116275901797936 | validation: 0.1666269016182707]
	TIME [epoch: 8.47 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1640797732790668		[learning rate: 0.00023023]
	Learning Rate: 0.000230226
	LOSS [training: 0.1640797732790668 | validation: 0.165483561082028]
	TIME [epoch: 8.47 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16598355875437615		[learning rate: 0.00022968]
	Learning Rate: 0.000229683
	LOSS [training: 0.16598355875437615 | validation: 0.18040042450983468]
	TIME [epoch: 8.49 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16228865064210435		[learning rate: 0.00022914]
	Learning Rate: 0.000229141
	LOSS [training: 0.16228865064210435 | validation: 0.15227060836121306]
	TIME [epoch: 8.49 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1709554347530681		[learning rate: 0.0002286]
	Learning Rate: 0.0002286
	LOSS [training: 0.1709554347530681 | validation: 0.16109162437469035]
	TIME [epoch: 8.47 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17321339269530486		[learning rate: 0.00022806]
	Learning Rate: 0.000228061
	LOSS [training: 0.17321339269530486 | validation: 0.16639140672801814]
	TIME [epoch: 8.47 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16960942323118705		[learning rate: 0.00022752]
	Learning Rate: 0.000227523
	LOSS [training: 0.16960942323118705 | validation: 0.20178272911101477]
	TIME [epoch: 8.49 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17105460016291993		[learning rate: 0.00022699]
	Learning Rate: 0.000226986
	LOSS [training: 0.17105460016291993 | validation: 0.1646008946902763]
	TIME [epoch: 8.47 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1809181124137484		[learning rate: 0.00022645]
	Learning Rate: 0.000226451
	LOSS [training: 0.1809181124137484 | validation: 0.23925560127050066]
	TIME [epoch: 8.46 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24754607483682642		[learning rate: 0.00022592]
	Learning Rate: 0.000225917
	LOSS [training: 0.24754607483682642 | validation: 0.2946952992853765]
	TIME [epoch: 8.47 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2357178297113816		[learning rate: 0.00022538]
	Learning Rate: 0.000225384
	LOSS [training: 0.2357178297113816 | validation: 0.2308622270664232]
	TIME [epoch: 8.49 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19849724819713052		[learning rate: 0.00022485]
	Learning Rate: 0.000224852
	LOSS [training: 0.19849724819713052 | validation: 0.23239885029348772]
	TIME [epoch: 8.48 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23796339730018512		[learning rate: 0.00022432]
	Learning Rate: 0.000224322
	LOSS [training: 0.23796339730018512 | validation: 0.23540230977522159]
	TIME [epoch: 8.47 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21529846145214684		[learning rate: 0.00022379]
	Learning Rate: 0.000223793
	LOSS [training: 0.21529846145214684 | validation: 0.19406524530658195]
	TIME [epoch: 8.48 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18604356588110688		[learning rate: 0.00022326]
	Learning Rate: 0.000223265
	LOSS [training: 0.18604356588110688 | validation: 0.1663467367852465]
	TIME [epoch: 8.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1600483808224944		[learning rate: 0.00022274]
	Learning Rate: 0.000222738
	LOSS [training: 0.1600483808224944 | validation: 0.1668768508323401]
	TIME [epoch: 8.47 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17010858895947037		[learning rate: 0.00022221]
	Learning Rate: 0.000222213
	LOSS [training: 0.17010858895947037 | validation: 0.18684112274511772]
	TIME [epoch: 8.46 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16559390867405052		[learning rate: 0.00022169]
	Learning Rate: 0.000221689
	LOSS [training: 0.16559390867405052 | validation: 0.1397073528547783]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1663.pth
	Model improved!!!
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15309729488745566		[learning rate: 0.00022117]
	Learning Rate: 0.000221166
	LOSS [training: 0.15309729488745566 | validation: 0.16216478923599115]
	TIME [epoch: 8.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1500063854442134		[learning rate: 0.00022064]
	Learning Rate: 0.000220644
	LOSS [training: 0.1500063854442134 | validation: 0.1466223412663289]
	TIME [epoch: 8.47 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14386646573205764		[learning rate: 0.00022012]
	Learning Rate: 0.000220124
	LOSS [training: 0.14386646573205764 | validation: 0.15737390857598252]
	TIME [epoch: 8.47 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14823992240140862		[learning rate: 0.0002196]
	Learning Rate: 0.000219604
	LOSS [training: 0.14823992240140862 | validation: 0.14170872278748492]
	TIME [epoch: 8.48 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14463498046471518		[learning rate: 0.00021909]
	Learning Rate: 0.000219086
	LOSS [training: 0.14463498046471518 | validation: 0.16306726824483847]
	TIME [epoch: 8.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15965963935206062		[learning rate: 0.00021857]
	Learning Rate: 0.00021857
	LOSS [training: 0.15965963935206062 | validation: 0.16604849149401463]
	TIME [epoch: 8.47 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15201417764551764		[learning rate: 0.00021805]
	Learning Rate: 0.000218054
	LOSS [training: 0.15201417764551764 | validation: 0.16893159547470252]
	TIME [epoch: 8.47 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16165138400632464		[learning rate: 0.00021754]
	Learning Rate: 0.00021754
	LOSS [training: 0.16165138400632464 | validation: 0.15045729370254843]
	TIME [epoch: 8.49 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1665861086697151		[learning rate: 0.00021703]
	Learning Rate: 0.000217027
	LOSS [training: 0.1665861086697151 | validation: 0.1781107477451253]
	TIME [epoch: 8.49 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18062737905817866		[learning rate: 0.00021651]
	Learning Rate: 0.000216515
	LOSS [training: 0.18062737905817866 | validation: 0.17545609714225083]
	TIME [epoch: 8.48 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1591896979056254		[learning rate: 0.000216]
	Learning Rate: 0.000216004
	LOSS [training: 0.1591896979056254 | validation: 0.1443225253697737]
	TIME [epoch: 8.48 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1644121391257135		[learning rate: 0.00021549]
	Learning Rate: 0.000215494
	LOSS [training: 0.1644121391257135 | validation: 0.16543201813206304]
	TIME [epoch: 8.49 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18104900697374893		[learning rate: 0.00021499]
	Learning Rate: 0.000214986
	LOSS [training: 0.18104900697374893 | validation: 0.15670801487755953]
	TIME [epoch: 8.47 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14323871129719232		[learning rate: 0.00021448]
	Learning Rate: 0.000214479
	LOSS [training: 0.14323871129719232 | validation: 0.15014742100293288]
	TIME [epoch: 8.46 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14450613302327048		[learning rate: 0.00021397]
	Learning Rate: 0.000213973
	LOSS [training: 0.14450613302327048 | validation: 0.15975083946053598]
	TIME [epoch: 8.47 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15596485708374247		[learning rate: 0.00021347]
	Learning Rate: 0.000213468
	LOSS [training: 0.15596485708374247 | validation: 0.1603503322752481]
	TIME [epoch: 8.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15593248603089604		[learning rate: 0.00021296]
	Learning Rate: 0.000212965
	LOSS [training: 0.15593248603089604 | validation: 0.15031696655268356]
	TIME [epoch: 8.47 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15893969223612597		[learning rate: 0.00021246]
	Learning Rate: 0.000212462
	LOSS [training: 0.15893969223612597 | validation: 0.16194304249753316]
	TIME [epoch: 8.47 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1652102197590885		[learning rate: 0.00021196]
	Learning Rate: 0.000211961
	LOSS [training: 0.1652102197590885 | validation: 0.1799150143715028]
	TIME [epoch: 8.48 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17132307217319365		[learning rate: 0.00021146]
	Learning Rate: 0.000211461
	LOSS [training: 0.17132307217319365 | validation: 0.14799185303795276]
	TIME [epoch: 8.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16395309998478907		[learning rate: 0.00021096]
	Learning Rate: 0.000210962
	LOSS [training: 0.16395309998478907 | validation: 0.1851700106591191]
	TIME [epoch: 8.47 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21432182489237026		[learning rate: 0.00021046]
	Learning Rate: 0.000210465
	LOSS [training: 0.21432182489237026 | validation: 0.2004176278938039]
	TIME [epoch: 8.47 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17340457935580658		[learning rate: 0.00020997]
	Learning Rate: 0.000209968
	LOSS [training: 0.17340457935580658 | validation: 0.1758740824078893]
	TIME [epoch: 8.48 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1633059630427657		[learning rate: 0.00020947]
	Learning Rate: 0.000209473
	LOSS [training: 0.1633059630427657 | validation: 0.14854844502866565]
	TIME [epoch: 8.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15149258707332852		[learning rate: 0.00020898]
	Learning Rate: 0.000208979
	LOSS [training: 0.15149258707332852 | validation: 0.1466846339036033]
	TIME [epoch: 8.47 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17131257267333716		[learning rate: 0.00020849]
	Learning Rate: 0.000208486
	LOSS [training: 0.17131257267333716 | validation: 0.1657767796290972]
	TIME [epoch: 8.46 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1671231656348692		[learning rate: 0.00020799]
	Learning Rate: 0.000207994
	LOSS [training: 0.1671231656348692 | validation: 0.1556439793398789]
	TIME [epoch: 8.48 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15816635447120836		[learning rate: 0.0002075]
	Learning Rate: 0.000207504
	LOSS [training: 0.15816635447120836 | validation: 0.1590047357972177]
	TIME [epoch: 8.49 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16106576139435802		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.16106576139435802 | validation: 0.15831128423396063]
	TIME [epoch: 8.46 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15063753954209166		[learning rate: 0.00020653]
	Learning Rate: 0.000206526
	LOSS [training: 0.15063753954209166 | validation: 0.14242078398870134]
	TIME [epoch: 8.46 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14730806966325227		[learning rate: 0.00020604]
	Learning Rate: 0.000206039
	LOSS [training: 0.14730806966325227 | validation: 0.1626811867468691]
	TIME [epoch: 8.48 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17490908791110524		[learning rate: 0.00020555]
	Learning Rate: 0.000205553
	LOSS [training: 0.17490908791110524 | validation: 0.16013536204552556]
	TIME [epoch: 8.49 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1707406796402819		[learning rate: 0.00020507]
	Learning Rate: 0.000205068
	LOSS [training: 0.1707406796402819 | validation: 0.205307816883546]
	TIME [epoch: 8.46 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21127951540305934		[learning rate: 0.00020458]
	Learning Rate: 0.000204584
	LOSS [training: 0.21127951540305934 | validation: 0.1902564317815512]
	TIME [epoch: 8.47 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17854875882398735		[learning rate: 0.0002041]
	Learning Rate: 0.000204101
	LOSS [training: 0.17854875882398735 | validation: 0.16749829897306773]
	TIME [epoch: 8.49 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15351031204982096		[learning rate: 0.00020362]
	Learning Rate: 0.00020362
	LOSS [training: 0.15351031204982096 | validation: 0.16511109059200957]
	TIME [epoch: 8.48 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1447600080318754		[learning rate: 0.00020314]
	Learning Rate: 0.00020314
	LOSS [training: 0.1447600080318754 | validation: 0.14199726752774738]
	TIME [epoch: 8.46 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13597943309289368		[learning rate: 0.00020266]
	Learning Rate: 0.000202661
	LOSS [training: 0.13597943309289368 | validation: 0.144190272000148]
	TIME [epoch: 8.47 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15769969535186276		[learning rate: 0.00020218]
	Learning Rate: 0.000202182
	LOSS [training: 0.15769969535186276 | validation: 0.17374209401831614]
	TIME [epoch: 8.47 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15579252831051757		[learning rate: 0.00020171]
	Learning Rate: 0.000201706
	LOSS [training: 0.15579252831051757 | validation: 0.16182427439393243]
	TIME [epoch: 8.49 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15744674376767115		[learning rate: 0.00020123]
	Learning Rate: 0.00020123
	LOSS [training: 0.15744674376767115 | validation: 0.16106025853042072]
	TIME [epoch: 8.49 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15592074442434684		[learning rate: 0.00020076]
	Learning Rate: 0.000200755
	LOSS [training: 0.15592074442434684 | validation: 0.14824847477103448]
	TIME [epoch: 8.47 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14086265566370598		[learning rate: 0.00020028]
	Learning Rate: 0.000200282
	LOSS [training: 0.14086265566370598 | validation: 0.14982178654471823]
	TIME [epoch: 8.48 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.161015749791607		[learning rate: 0.00019981]
	Learning Rate: 0.000199809
	LOSS [training: 0.161015749791607 | validation: 0.17398770472784153]
	TIME [epoch: 8.48 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16461342554307465		[learning rate: 0.00019934]
	Learning Rate: 0.000199338
	LOSS [training: 0.16461342554307465 | validation: 0.20464411514853376]
	TIME [epoch: 8.47 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1862171170671619		[learning rate: 0.00019887]
	Learning Rate: 0.000198868
	LOSS [training: 0.1862171170671619 | validation: 0.20114864733521393]
	TIME [epoch: 8.48 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21104006207596857		[learning rate: 0.0001984]
	Learning Rate: 0.000198398
	LOSS [training: 0.21104006207596857 | validation: 0.2215402733525524]
	TIME [epoch: 8.48 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21690457564122978		[learning rate: 0.00019793]
	Learning Rate: 0.000197931
	LOSS [training: 0.21690457564122978 | validation: 0.18576491218374908]
	TIME [epoch: 8.48 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17897093852918658		[learning rate: 0.00019746]
	Learning Rate: 0.000197464
	LOSS [training: 0.17897093852918658 | validation: 0.16078255070860886]
	TIME [epoch: 8.46 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1492505108515354		[learning rate: 0.000197]
	Learning Rate: 0.000196998
	LOSS [training: 0.1492505108515354 | validation: 0.18809389937167803]
	TIME [epoch: 8.48 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16513481522852133		[learning rate: 0.00019653]
	Learning Rate: 0.000196533
	LOSS [training: 0.16513481522852133 | validation: 0.16650614874529285]
	TIME [epoch: 8.48 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18103872197266715		[learning rate: 0.00019607]
	Learning Rate: 0.00019607
	LOSS [training: 0.18103872197266715 | validation: 0.18762517558887892]
	TIME [epoch: 8.47 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1890632555829896		[learning rate: 0.00019561]
	Learning Rate: 0.000195607
	LOSS [training: 0.1890632555829896 | validation: 0.16718406067474725]
	TIME [epoch: 8.47 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15967382773313676		[learning rate: 0.00019515]
	Learning Rate: 0.000195146
	LOSS [training: 0.15967382773313676 | validation: 0.16627454054324445]
	TIME [epoch: 8.47 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17762901999296316		[learning rate: 0.00019469]
	Learning Rate: 0.000194685
	LOSS [training: 0.17762901999296316 | validation: 0.18508278085028868]
	TIME [epoch: 8.49 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17658551381414814		[learning rate: 0.00019423]
	Learning Rate: 0.000194226
	LOSS [training: 0.17658551381414814 | validation: 0.15188686288813216]
	TIME [epoch: 8.47 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1567369735896051		[learning rate: 0.00019377]
	Learning Rate: 0.000193768
	LOSS [training: 0.1567369735896051 | validation: 0.17412256535810489]
	TIME [epoch: 8.48 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18200308309861296		[learning rate: 0.00019331]
	Learning Rate: 0.000193311
	LOSS [training: 0.18200308309861296 | validation: 0.15135776951641378]
	TIME [epoch: 8.48 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.155743264531592		[learning rate: 0.00019285]
	Learning Rate: 0.000192855
	LOSS [training: 0.155743264531592 | validation: 0.17239413083519545]
	TIME [epoch: 8.49 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1725330344786593		[learning rate: 0.0001924]
	Learning Rate: 0.0001924
	LOSS [training: 0.1725330344786593 | validation: 0.1556484546817865]
	TIME [epoch: 8.46 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16052284364123554		[learning rate: 0.00019195]
	Learning Rate: 0.000191946
	LOSS [training: 0.16052284364123554 | validation: 0.1497794871448312]
	TIME [epoch: 8.48 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15386423255505927		[learning rate: 0.00019149]
	Learning Rate: 0.000191493
	LOSS [training: 0.15386423255505927 | validation: 0.1588031857986889]
	TIME [epoch: 8.47 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16647424974036365		[learning rate: 0.00019104]
	Learning Rate: 0.000191042
	LOSS [training: 0.16647424974036365 | validation: 0.1648152727088271]
	TIME [epoch: 8.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1669929009424618		[learning rate: 0.00019059]
	Learning Rate: 0.000190591
	LOSS [training: 0.1669929009424618 | validation: 0.17729221719130306]
	TIME [epoch: 8.47 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22048696207335466		[learning rate: 0.00019014]
	Learning Rate: 0.000190141
	LOSS [training: 0.22048696207335466 | validation: 0.21282597743843096]
	TIME [epoch: 8.49 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2295776253157385		[learning rate: 0.00018969]
	Learning Rate: 0.000189693
	LOSS [training: 0.2295776253157385 | validation: 0.17856789564916234]
	TIME [epoch: 8.47 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16626887651795724		[learning rate: 0.00018925]
	Learning Rate: 0.000189245
	LOSS [training: 0.16626887651795724 | validation: 0.18336946218886876]
	TIME [epoch: 8.49 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16082257641057113		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.16082257641057113 | validation: 0.1579758877829623]
	TIME [epoch: 8.47 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15891095274320696		[learning rate: 0.00018835]
	Learning Rate: 0.000188354
	LOSS [training: 0.15891095274320696 | validation: 0.16819238274556525]
	TIME [epoch: 8.48 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1462683812471027		[learning rate: 0.00018791]
	Learning Rate: 0.000187909
	LOSS [training: 0.1462683812471027 | validation: 0.1545118826049851]
	TIME [epoch: 8.47 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14831405065209566		[learning rate: 0.00018747]
	Learning Rate: 0.000187466
	LOSS [training: 0.14831405065209566 | validation: 0.16137795493993373]
	TIME [epoch: 8.49 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14367209144555412		[learning rate: 0.00018702]
	Learning Rate: 0.000187024
	LOSS [training: 0.14367209144555412 | validation: 0.15635393724934038]
	TIME [epoch: 8.48 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14438647595735848		[learning rate: 0.00018658]
	Learning Rate: 0.000186583
	LOSS [training: 0.14438647595735848 | validation: 0.14552632605913046]
	TIME [epoch: 8.47 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1511227478280269		[learning rate: 0.00018614]
	Learning Rate: 0.000186143
	LOSS [training: 0.1511227478280269 | validation: 0.15252490406131625]
	TIME [epoch: 8.47 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1489190952149548		[learning rate: 0.0001857]
	Learning Rate: 0.000185704
	LOSS [training: 0.1489190952149548 | validation: 0.1653559773152996]
	TIME [epoch: 8.49 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15899483575407897		[learning rate: 0.00018527]
	Learning Rate: 0.000185266
	LOSS [training: 0.15899483575407897 | validation: 0.16205823122255272]
	TIME [epoch: 8.49 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1489909342123794		[learning rate: 0.00018483]
	Learning Rate: 0.000184829
	LOSS [training: 0.1489909342123794 | validation: 0.1493809301988604]
	TIME [epoch: 8.47 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14287089317773444		[learning rate: 0.00018439]
	Learning Rate: 0.000184393
	LOSS [training: 0.14287089317773444 | validation: 0.15654005401197557]
	TIME [epoch: 8.47 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15207292256873403		[learning rate: 0.00018396]
	Learning Rate: 0.000183958
	LOSS [training: 0.15207292256873403 | validation: 0.148886599440055]
	TIME [epoch: 8.49 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1476449602942396		[learning rate: 0.00018352]
	Learning Rate: 0.000183524
	LOSS [training: 0.1476449602942396 | validation: 0.1542168878459542]
	TIME [epoch: 8.49 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15143967413216797		[learning rate: 0.00018309]
	Learning Rate: 0.000183091
	LOSS [training: 0.15143967413216797 | validation: 0.15298857638988886]
	TIME [epoch: 8.46 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1605166680413061		[learning rate: 0.00018266]
	Learning Rate: 0.000182659
	LOSS [training: 0.1605166680413061 | validation: 0.1696681175744518]
	TIME [epoch: 8.47 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14809126478541018		[learning rate: 0.00018223]
	Learning Rate: 0.000182228
	LOSS [training: 0.14809126478541018 | validation: 0.15342051503699236]
	TIME [epoch: 8.49 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1393166818495529		[learning rate: 0.0001818]
	Learning Rate: 0.000181798
	LOSS [training: 0.1393166818495529 | validation: 0.1471020430220594]
	TIME [epoch: 8.48 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1442325425954897		[learning rate: 0.00018137]
	Learning Rate: 0.000181369
	LOSS [training: 0.1442325425954897 | validation: 0.15343428361025235]
	TIME [epoch: 8.46 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14622446292350919		[learning rate: 0.00018094]
	Learning Rate: 0.000180942
	LOSS [training: 0.14622446292350919 | validation: 0.1613522413979484]
	TIME [epoch: 8.48 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15090286962783014		[learning rate: 0.00018051]
	Learning Rate: 0.000180515
	LOSS [training: 0.15090286962783014 | validation: 0.1533518569945979]
	TIME [epoch: 8.48 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1617765568393484		[learning rate: 0.00018009]
	Learning Rate: 0.000180089
	LOSS [training: 0.1617765568393484 | validation: 0.1605959857674647]
	TIME [epoch: 8.47 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14778339607933846		[learning rate: 0.00017966]
	Learning Rate: 0.000179664
	LOSS [training: 0.14778339607933846 | validation: 0.15878289532700873]
	TIME [epoch: 8.47 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14091954077414162		[learning rate: 0.00017924]
	Learning Rate: 0.00017924
	LOSS [training: 0.14091954077414162 | validation: 0.13916951372908337]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1753.pth
	Model improved!!!
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1407559373729802		[learning rate: 0.00017882]
	Learning Rate: 0.000178818
	LOSS [training: 0.1407559373729802 | validation: 0.15035429178374493]
	TIME [epoch: 8.51 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16341250605820207		[learning rate: 0.0001784]
	Learning Rate: 0.000178396
	LOSS [training: 0.16341250605820207 | validation: 0.14630213738550396]
	TIME [epoch: 8.48 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1445083595503618		[learning rate: 0.00017797]
	Learning Rate: 0.000177975
	LOSS [training: 0.1445083595503618 | validation: 0.1561396446011401]
	TIME [epoch: 8.48 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15766237384110565		[learning rate: 0.00017756]
	Learning Rate: 0.000177555
	LOSS [training: 0.15766237384110565 | validation: 0.1762413154582615]
	TIME [epoch: 8.49 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1628194364929258		[learning rate: 0.00017714]
	Learning Rate: 0.000177136
	LOSS [training: 0.1628194364929258 | validation: 0.17705617136944224]
	TIME [epoch: 8.51 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1503145726506914		[learning rate: 0.00017672]
	Learning Rate: 0.000176718
	LOSS [training: 0.1503145726506914 | validation: 0.1456145448498886]
	TIME [epoch: 8.48 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16483211105747644		[learning rate: 0.0001763]
	Learning Rate: 0.000176302
	LOSS [training: 0.16483211105747644 | validation: 0.18000075949113453]
	TIME [epoch: 8.48 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17378387169072146		[learning rate: 0.00017589]
	Learning Rate: 0.000175886
	LOSS [training: 0.17378387169072146 | validation: 0.16541587126330673]
	TIME [epoch: 8.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15576819857883872		[learning rate: 0.00017547]
	Learning Rate: 0.000175471
	LOSS [training: 0.15576819857883872 | validation: 0.149828658387029]
	TIME [epoch: 8.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14506568297941938		[learning rate: 0.00017506]
	Learning Rate: 0.000175057
	LOSS [training: 0.14506568297941938 | validation: 0.14915138693351804]
	TIME [epoch: 8.48 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15630197955906122		[learning rate: 0.00017464]
	Learning Rate: 0.000174644
	LOSS [training: 0.15630197955906122 | validation: 0.14913084975641777]
	TIME [epoch: 8.48 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15502624244036722		[learning rate: 0.00017423]
	Learning Rate: 0.000174232
	LOSS [training: 0.15502624244036722 | validation: 0.1833149359443082]
	TIME [epoch: 8.51 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19553541274248715		[learning rate: 0.00017382]
	Learning Rate: 0.000173821
	LOSS [training: 0.19553541274248715 | validation: 0.17674188951788128]
	TIME [epoch: 8.49 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15830866092225343		[learning rate: 0.00017341]
	Learning Rate: 0.000173411
	LOSS [training: 0.15830866092225343 | validation: 0.153405974033898]
	TIME [epoch: 8.48 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13859732071131792		[learning rate: 0.000173]
	Learning Rate: 0.000173002
	LOSS [training: 0.13859732071131792 | validation: 0.13825118240409914]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1768.pth
	Model improved!!!
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13697677898872124		[learning rate: 0.00017259]
	Learning Rate: 0.000172594
	LOSS [training: 0.13697677898872124 | validation: 0.1489698800100801]
	TIME [epoch: 8.53 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14372451703815298		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.14372451703815298 | validation: 0.16923959882077305]
	TIME [epoch: 8.48 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1409310400774978		[learning rate: 0.00017178]
	Learning Rate: 0.000171781
	LOSS [training: 0.1409310400774978 | validation: 0.1390642056812343]
	TIME [epoch: 8.48 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14414643138452868		[learning rate: 0.00017138]
	Learning Rate: 0.000171375
	LOSS [training: 0.14414643138452868 | validation: 0.16389126972203563]
	TIME [epoch: 8.49 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1834327732548115		[learning rate: 0.00017097]
	Learning Rate: 0.000170971
	LOSS [training: 0.1834327732548115 | validation: 0.20325709296874403]
	TIME [epoch: 8.52 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18995344129127134		[learning rate: 0.00017057]
	Learning Rate: 0.000170568
	LOSS [training: 0.18995344129127134 | validation: 0.17356107657059092]
	TIME [epoch: 8.49 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15392913693733212		[learning rate: 0.00017017]
	Learning Rate: 0.000170166
	LOSS [training: 0.15392913693733212 | validation: 0.13739300547399858]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1775.pth
	Model improved!!!
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13950109138486347		[learning rate: 0.00016976]
	Learning Rate: 0.000169764
	LOSS [training: 0.13950109138486347 | validation: 0.16118669604483737]
	TIME [epoch: 8.49 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17310865938242712		[learning rate: 0.00016936]
	Learning Rate: 0.000169364
	LOSS [training: 0.17310865938242712 | validation: 0.2101673575335469]
	TIME [epoch: 8.51 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20649614127020666		[learning rate: 0.00016896]
	Learning Rate: 0.000168964
	LOSS [training: 0.20649614127020666 | validation: 0.2074751503164362]
	TIME [epoch: 8.48 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19900033355771626		[learning rate: 0.00016857]
	Learning Rate: 0.000168566
	LOSS [training: 0.19900033355771626 | validation: 0.18992696558176997]
	TIME [epoch: 8.48 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16680601955999058		[learning rate: 0.00016817]
	Learning Rate: 0.000168168
	LOSS [training: 0.16680601955999058 | validation: 0.1405796667493776]
	TIME [epoch: 8.51 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15961027459633595		[learning rate: 0.00016777]
	Learning Rate: 0.000167771
	LOSS [training: 0.15961027459633595 | validation: 0.16944289002097782]
	TIME [epoch: 8.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1612443659933461		[learning rate: 0.00016738]
	Learning Rate: 0.000167376
	LOSS [training: 0.1612443659933461 | validation: 0.15442839937378705]
	TIME [epoch: 8.49 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15136929357288897		[learning rate: 0.00016698]
	Learning Rate: 0.000166981
	LOSS [training: 0.15136929357288897 | validation: 0.14653329889622313]
	TIME [epoch: 8.48 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14786205294258942		[learning rate: 0.00016659]
	Learning Rate: 0.000166587
	LOSS [training: 0.14786205294258942 | validation: 0.14587648329588188]
	TIME [epoch: 8.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1481586841595143		[learning rate: 0.00016619]
	Learning Rate: 0.000166194
	LOSS [training: 0.1481586841595143 | validation: 0.14531612770907093]
	TIME [epoch: 8.49 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14363525149391093		[learning rate: 0.0001658]
	Learning Rate: 0.000165802
	LOSS [training: 0.14363525149391093 | validation: 0.1509751043964731]
	TIME [epoch: 8.49 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15233801875665867		[learning rate: 0.00016541]
	Learning Rate: 0.000165411
	LOSS [training: 0.15233801875665867 | validation: 0.16228997768193795]
	TIME [epoch: 8.49 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14777637643603497		[learning rate: 0.00016502]
	Learning Rate: 0.000165021
	LOSS [training: 0.14777637643603497 | validation: 0.16122980770034023]
	TIME [epoch: 8.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1459399706530035		[learning rate: 0.00016463]
	Learning Rate: 0.000164631
	LOSS [training: 0.1459399706530035 | validation: 0.15823124439315278]
	TIME [epoch: 8.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14928226088295315		[learning rate: 0.00016424]
	Learning Rate: 0.000164243
	LOSS [training: 0.14928226088295315 | validation: 0.15377742827877128]
	TIME [epoch: 8.49 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1588159492037547		[learning rate: 0.00016386]
	Learning Rate: 0.000163856
	LOSS [training: 0.1588159492037547 | validation: 0.1616478913988526]
	TIME [epoch: 8.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15448203739899039		[learning rate: 0.00016347]
	Learning Rate: 0.000163469
	LOSS [training: 0.15448203739899039 | validation: 0.16433569919935795]
	TIME [epoch: 8.48 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15768053731465614		[learning rate: 0.00016308]
	Learning Rate: 0.000163084
	LOSS [training: 0.15768053731465614 | validation: 0.13538381319757556]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1793.pth
	Model improved!!!
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15015812561153177		[learning rate: 0.0001627]
	Learning Rate: 0.000162699
	LOSS [training: 0.15015812561153177 | validation: 0.16237494270064823]
	TIME [epoch: 8.48 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1542501823702647		[learning rate: 0.00016232]
	Learning Rate: 0.000162315
	LOSS [training: 0.1542501823702647 | validation: 0.15883175686193476]
	TIME [epoch: 8.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15537863601116153		[learning rate: 0.00016193]
	Learning Rate: 0.000161932
	LOSS [training: 0.15537863601116153 | validation: 0.15761556022424617]
	TIME [epoch: 8.48 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17355581872999093		[learning rate: 0.00016155]
	Learning Rate: 0.00016155
	LOSS [training: 0.17355581872999093 | validation: 0.17046622839579956]
	TIME [epoch: 8.49 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1666815328355445		[learning rate: 0.00016117]
	Learning Rate: 0.000161169
	LOSS [training: 0.1666815328355445 | validation: 0.15724988917382982]
	TIME [epoch: 8.49 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14861354991438458		[learning rate: 0.00016079]
	Learning Rate: 0.000160789
	LOSS [training: 0.14861354991438458 | validation: 0.15679905788614135]
	TIME [epoch: 8.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14858475962456297		[learning rate: 0.00016041]
	Learning Rate: 0.00016041
	LOSS [training: 0.14858475962456297 | validation: 0.14826261079661707]
	TIME [epoch: 8.48 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1515509670915085		[learning rate: 0.00016003]
	Learning Rate: 0.000160031
	LOSS [training: 0.1515509670915085 | validation: 0.14807550120804647]
	TIME [epoch: 8.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16124798517467717		[learning rate: 0.00015965]
	Learning Rate: 0.000159654
	LOSS [training: 0.16124798517467717 | validation: 0.18142003378792532]
	TIME [epoch: 8.49 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20698103832332246		[learning rate: 0.00015928]
	Learning Rate: 0.000159277
	LOSS [training: 0.20698103832332246 | validation: 0.24443883388118004]
	TIME [epoch: 8.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2145723898250455		[learning rate: 0.0001589]
	Learning Rate: 0.000158902
	LOSS [training: 0.2145723898250455 | validation: 0.1706130112576903]
	TIME [epoch: 8.47 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17363142331356532		[learning rate: 0.00015853]
	Learning Rate: 0.000158527
	LOSS [training: 0.17363142331356532 | validation: 0.154862648307795]
	TIME [epoch: 8.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1453518864056572		[learning rate: 0.00015815]
	Learning Rate: 0.000158153
	LOSS [training: 0.1453518864056572 | validation: 0.1424606943529551]
	TIME [epoch: 8.49 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13864980349541006		[learning rate: 0.00015778]
	Learning Rate: 0.00015778
	LOSS [training: 0.13864980349541006 | validation: 0.15511577681469518]
	TIME [epoch: 8.49 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1458394190473791		[learning rate: 0.00015741]
	Learning Rate: 0.000157408
	LOSS [training: 0.1458394190473791 | validation: 0.14904715208182912]
	TIME [epoch: 8.48 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1467293230194759		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.1467293230194759 | validation: 0.15436973826785744]
	TIME [epoch: 8.49 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1595587891258604		[learning rate: 0.00015667]
	Learning Rate: 0.000156666
	LOSS [training: 0.1595587891258604 | validation: 0.17603492880258198]
	TIME [epoch: 8.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17641514421638876		[learning rate: 0.0001563]
	Learning Rate: 0.000156296
	LOSS [training: 0.17641514421638876 | validation: 0.16836928848045776]
	TIME [epoch: 8.48 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17900835115939537		[learning rate: 0.00015593]
	Learning Rate: 0.000155928
	LOSS [training: 0.17900835115939537 | validation: 0.16471635038072155]
	TIME [epoch: 8.48 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1603065474503164		[learning rate: 0.00015556]
	Learning Rate: 0.00015556
	LOSS [training: 0.1603065474503164 | validation: 0.1457998802541952]
	TIME [epoch: 8.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14684614087580414		[learning rate: 0.00015519]
	Learning Rate: 0.000155193
	LOSS [training: 0.14684614087580414 | validation: 0.15411166686531538]
	TIME [epoch: 8.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15700226660094355		[learning rate: 0.00015483]
	Learning Rate: 0.000154827
	LOSS [training: 0.15700226660094355 | validation: 0.16065482974096018]
	TIME [epoch: 8.48 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15403852952773167		[learning rate: 0.00015446]
	Learning Rate: 0.000154462
	LOSS [training: 0.15403852952773167 | validation: 0.14435188952832845]
	TIME [epoch: 8.48 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14408268423517773		[learning rate: 0.0001541]
	Learning Rate: 0.000154097
	LOSS [training: 0.14408268423517773 | validation: 0.14838484692345139]
	TIME [epoch: 8.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14297542880530414		[learning rate: 0.00015373]
	Learning Rate: 0.000153734
	LOSS [training: 0.14297542880530414 | validation: 0.14247343806053375]
	TIME [epoch: 8.5 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14376087231602935		[learning rate: 0.00015337]
	Learning Rate: 0.000153371
	LOSS [training: 0.14376087231602935 | validation: 0.14901737120025021]
	TIME [epoch: 8.47 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14994955789725223		[learning rate: 0.00015301]
	Learning Rate: 0.000153009
	LOSS [training: 0.14994955789725223 | validation: 0.15879453280790615]
	TIME [epoch: 8.47 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15340391850599527		[learning rate: 0.00015265]
	Learning Rate: 0.000152648
	LOSS [training: 0.15340391850599527 | validation: 0.14856232747597184]
	TIME [epoch: 8.52 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1410365917278693		[learning rate: 0.00015229]
	Learning Rate: 0.000152288
	LOSS [training: 0.1410365917278693 | validation: 0.14616780696798026]
	TIME [epoch: 8.49 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13849990336791804		[learning rate: 0.00015193]
	Learning Rate: 0.000151929
	LOSS [training: 0.13849990336791804 | validation: 0.14959435811048383]
	TIME [epoch: 8.48 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.135326077413444		[learning rate: 0.00015157]
	Learning Rate: 0.000151571
	LOSS [training: 0.135326077413444 | validation: 0.1439686283605744]
	TIME [epoch: 8.48 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1501487880434462		[learning rate: 0.00015121]
	Learning Rate: 0.000151213
	LOSS [training: 0.1501487880434462 | validation: 0.15872449600151145]
	TIME [epoch: 8.51 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14191807177833102		[learning rate: 0.00015086]
	Learning Rate: 0.000150857
	LOSS [training: 0.14191807177833102 | validation: 0.15263563995651333]
	TIME [epoch: 8.47 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15926322895933787		[learning rate: 0.0001505]
	Learning Rate: 0.000150501
	LOSS [training: 0.15926322895933787 | validation: 0.17054069438102856]
	TIME [epoch: 8.47 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1565089852164268		[learning rate: 0.00015015]
	Learning Rate: 0.000150146
	LOSS [training: 0.1565089852164268 | validation: 0.14056879076090717]
	TIME [epoch: 8.49 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13827508290378004		[learning rate: 0.00014979]
	Learning Rate: 0.000149791
	LOSS [training: 0.13827508290378004 | validation: 0.14026358737829078]
	TIME [epoch: 8.51 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15038328876339474		[learning rate: 0.00014944]
	Learning Rate: 0.000149438
	LOSS [training: 0.15038328876339474 | validation: 0.15460048759121736]
	TIME [epoch: 8.48 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1663027701276623		[learning rate: 0.00014909]
	Learning Rate: 0.000149086
	LOSS [training: 0.1663027701276623 | validation: 0.18753439769603064]
	TIME [epoch: 8.47 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2003994524687959		[learning rate: 0.00014873]
	Learning Rate: 0.000148734
	LOSS [training: 0.2003994524687959 | validation: 0.16837302332738802]
	TIME [epoch: 8.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17152767435729216		[learning rate: 0.00014838]
	Learning Rate: 0.000148383
	LOSS [training: 0.17152767435729216 | validation: 0.17013211762713742]
	TIME [epoch: 8.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19882675652633236		[learning rate: 0.00014803]
	Learning Rate: 0.000148033
	LOSS [training: 0.19882675652633236 | validation: 0.2201458938013296]
	TIME [epoch: 8.47 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19682947437285536		[learning rate: 0.00014768]
	Learning Rate: 0.000147684
	LOSS [training: 0.19682947437285536 | validation: 0.1918405920355925]
	TIME [epoch: 8.48 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23582750747880077		[learning rate: 0.00014734]
	Learning Rate: 0.000147336
	LOSS [training: 0.23582750747880077 | validation: 0.22876853580003875]
	TIME [epoch: 8.51 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22153795709596205		[learning rate: 0.00014699]
	Learning Rate: 0.000146988
	LOSS [training: 0.22153795709596205 | validation: 0.20211096703665632]
	TIME [epoch: 8.49 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20289062334815866		[learning rate: 0.00014664]
	Learning Rate: 0.000146641
	LOSS [training: 0.20289062334815866 | validation: 0.19988826694199668]
	TIME [epoch: 8.48 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19007359645118643		[learning rate: 0.0001463]
	Learning Rate: 0.000146295
	LOSS [training: 0.19007359645118643 | validation: 0.17058698528307595]
	TIME [epoch: 8.47 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15618413234542966		[learning rate: 0.00014595]
	Learning Rate: 0.00014595
	LOSS [training: 0.15618413234542966 | validation: 0.1487791539711451]
	TIME [epoch: 8.52 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1442911382406022		[learning rate: 0.00014561]
	Learning Rate: 0.000145606
	LOSS [training: 0.1442911382406022 | validation: 0.13922381792281052]
	TIME [epoch: 8.48 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14851357773482243		[learning rate: 0.00014526]
	Learning Rate: 0.000145263
	LOSS [training: 0.14851357773482243 | validation: 0.16987364147197742]
	TIME [epoch: 8.47 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14708633666870427		[learning rate: 0.00014492]
	Learning Rate: 0.00014492
	LOSS [training: 0.14708633666870427 | validation: 0.14921245661936744]
	TIME [epoch: 8.47 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15605846274343443		[learning rate: 0.00014458]
	Learning Rate: 0.000144578
	LOSS [training: 0.15605846274343443 | validation: 0.17129456526709405]
	TIME [epoch: 8.52 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16175065554933543		[learning rate: 0.00014424]
	Learning Rate: 0.000144237
	LOSS [training: 0.16175065554933543 | validation: 0.14120742093869387]
	TIME [epoch: 8.48 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14269945681994073		[learning rate: 0.0001439]
	Learning Rate: 0.000143897
	LOSS [training: 0.14269945681994073 | validation: 0.1430609711642204]
	TIME [epoch: 8.48 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14782999326162788		[learning rate: 0.00014356]
	Learning Rate: 0.000143557
	LOSS [training: 0.14782999326162788 | validation: 0.15238100401821744]
	TIME [epoch: 8.48 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14868371411257808		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.14868371411257808 | validation: 0.1506908399537653]
	TIME [epoch: 8.51 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13803143496531683		[learning rate: 0.00014288]
	Learning Rate: 0.000142881
	LOSS [training: 0.13803143496531683 | validation: 0.1431841019037542]
	TIME [epoch: 8.47 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14668659431232514		[learning rate: 0.00014254]
	Learning Rate: 0.000142544
	LOSS [training: 0.14668659431232514 | validation: 0.14948256295033968]
	TIME [epoch: 8.48 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14862452174256555		[learning rate: 0.00014221]
	Learning Rate: 0.000142208
	LOSS [training: 0.14862452174256555 | validation: 0.1615786823206759]
	TIME [epoch: 8.48 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14710614612186138		[learning rate: 0.00014187]
	Learning Rate: 0.000141872
	LOSS [training: 0.14710614612186138 | validation: 0.13605367771151222]
	TIME [epoch: 8.51 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13451108300457196		[learning rate: 0.00014154]
	Learning Rate: 0.000141538
	LOSS [training: 0.13451108300457196 | validation: 0.14500000107033936]
	TIME [epoch: 8.47 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13586977515692472		[learning rate: 0.0001412]
	Learning Rate: 0.000141204
	LOSS [training: 0.13586977515692472 | validation: 0.13745848151008516]
	TIME [epoch: 8.48 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14195704049455748		[learning rate: 0.00014087]
	Learning Rate: 0.000140871
	LOSS [training: 0.14195704049455748 | validation: 0.14300743926210935]
	TIME [epoch: 8.49 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1449235322062542		[learning rate: 0.00014054]
	Learning Rate: 0.000140538
	LOSS [training: 0.1449235322062542 | validation: 0.1450782729629717]
	TIME [epoch: 8.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1418400229036833		[learning rate: 0.00014021]
	Learning Rate: 0.000140207
	LOSS [training: 0.1418400229036833 | validation: 0.14436301753525066]
	TIME [epoch: 8.47 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.142911880487049		[learning rate: 0.00013988]
	Learning Rate: 0.000139876
	LOSS [training: 0.142911880487049 | validation: 0.1470794052117797]
	TIME [epoch: 8.47 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15270843144415785		[learning rate: 0.00013955]
	Learning Rate: 0.000139546
	LOSS [training: 0.15270843144415785 | validation: 0.1509873493533918]
	TIME [epoch: 8.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1413449979492273		[learning rate: 0.00013922]
	Learning Rate: 0.000139217
	LOSS [training: 0.1413449979492273 | validation: 0.13683636427073786]
	TIME [epoch: 8.5 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1468946122080744		[learning rate: 0.00013889]
	Learning Rate: 0.000138889
	LOSS [training: 0.1468946122080744 | validation: 0.15658849128358815]
	TIME [epoch: 8.47 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1449937198898069		[learning rate: 0.00013856]
	Learning Rate: 0.000138561
	LOSS [training: 0.1449937198898069 | validation: 0.15888152737238068]
	TIME [epoch: 8.49 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14923260503110608		[learning rate: 0.00013823]
	Learning Rate: 0.000138234
	LOSS [training: 0.14923260503110608 | validation: 0.1532863520913769]
	TIME [epoch: 8.49 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15231618546476353		[learning rate: 0.00013791]
	Learning Rate: 0.000137908
	LOSS [training: 0.15231618546476353 | validation: 0.15129678364330973]
	TIME [epoch: 8.49 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14930575939268334		[learning rate: 0.00013758]
	Learning Rate: 0.000137583
	LOSS [training: 0.14930575939268334 | validation: 0.14996940643681025]
	TIME [epoch: 8.47 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14038995403715798		[learning rate: 0.00013726]
	Learning Rate: 0.000137258
	LOSS [training: 0.14038995403715798 | validation: 0.1484596610916166]
	TIME [epoch: 8.49 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14863386056632952		[learning rate: 0.00013693]
	Learning Rate: 0.000136934
	LOSS [training: 0.14863386056632952 | validation: 0.14532457328858403]
	TIME [epoch: 8.49 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14298149932221157		[learning rate: 0.00013661]
	Learning Rate: 0.000136611
	LOSS [training: 0.14298149932221157 | validation: 0.1520663887967605]
	TIME [epoch: 8.48 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14056469391373538		[learning rate: 0.00013629]
	Learning Rate: 0.000136289
	LOSS [training: 0.14056469391373538 | validation: 0.1553742703753081]
	TIME [epoch: 8.49 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15220197112636702		[learning rate: 0.00013597]
	Learning Rate: 0.000135968
	LOSS [training: 0.15220197112636702 | validation: 0.15275546853502175]
	TIME [epoch: 8.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17398001311988648		[learning rate: 0.00013565]
	Learning Rate: 0.000135647
	LOSS [training: 0.17398001311988648 | validation: 0.1779929448096912]
	TIME [epoch: 8.49 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15095094649188043		[learning rate: 0.00013533]
	Learning Rate: 0.000135327
	LOSS [training: 0.15095094649188043 | validation: 0.14185622376136758]
	TIME [epoch: 8.49 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14462447474049334		[learning rate: 0.00013501]
	Learning Rate: 0.000135008
	LOSS [training: 0.14462447474049334 | validation: 0.14130414794155752]
	TIME [epoch: 8.49 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14419861014556928		[learning rate: 0.00013469]
	Learning Rate: 0.000134689
	LOSS [training: 0.14419861014556928 | validation: 0.1371786203893452]
	TIME [epoch: 8.49 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14504348950980966		[learning rate: 0.00013437]
	Learning Rate: 0.000134372
	LOSS [training: 0.14504348950980966 | validation: 0.13622488900193636]
	TIME [epoch: 8.49 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1471815515942061		[learning rate: 0.00013405]
	Learning Rate: 0.000134055
	LOSS [training: 0.1471815515942061 | validation: 0.14580397880439447]
	TIME [epoch: 8.47 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14246161151736486		[learning rate: 0.00013374]
	Learning Rate: 0.000133738
	LOSS [training: 0.14246161151736486 | validation: 0.1476194932485262]
	TIME [epoch: 8.49 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15100700066780245		[learning rate: 0.00013342]
	Learning Rate: 0.000133423
	LOSS [training: 0.15100700066780245 | validation: 0.1615118624674367]
	TIME [epoch: 8.49 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17265633359541088		[learning rate: 0.00013311]
	Learning Rate: 0.000133108
	LOSS [training: 0.17265633359541088 | validation: 0.18483160615423488]
	TIME [epoch: 8.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17180269691232403		[learning rate: 0.00013279]
	Learning Rate: 0.000132794
	LOSS [training: 0.17180269691232403 | validation: 0.16313732037904385]
	TIME [epoch: 8.48 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16495797454500732		[learning rate: 0.00013248]
	Learning Rate: 0.000132481
	LOSS [training: 0.16495797454500732 | validation: 0.16006675796462316]
	TIME [epoch: 8.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14197020398427956		[learning rate: 0.00013217]
	Learning Rate: 0.000132169
	LOSS [training: 0.14197020398427956 | validation: 0.14070818491141177]
	TIME [epoch: 8.48 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14389398222375124		[learning rate: 0.00013186]
	Learning Rate: 0.000131857
	LOSS [training: 0.14389398222375124 | validation: 0.1465241656664335]
	TIME [epoch: 8.49 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1430132417728102		[learning rate: 0.00013155]
	Learning Rate: 0.000131546
	LOSS [training: 0.1430132417728102 | validation: 0.15749031023118293]
	TIME [epoch: 8.48 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14862523073530925		[learning rate: 0.00013124]
	Learning Rate: 0.000131235
	LOSS [training: 0.14862523073530925 | validation: 0.15402665920956377]
	TIME [epoch: 8.49 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16677523637287933		[learning rate: 0.00013093]
	Learning Rate: 0.000130926
	LOSS [training: 0.16677523637287933 | validation: 0.15531204495163933]
	TIME [epoch: 8.47 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14943252675553048		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.14943252675553048 | validation: 0.1600477118404504]
	TIME [epoch: 8.49 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14776365710945172		[learning rate: 0.00013031]
	Learning Rate: 0.000130309
	LOSS [training: 0.14776365710945172 | validation: 0.15307933107521188]
	TIME [epoch: 8.47 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1434137649229331		[learning rate: 0.00013]
	Learning Rate: 0.000130002
	LOSS [training: 0.1434137649229331 | validation: 0.13495199902629165]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1889.pth
	Model improved!!!
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1445492380089789		[learning rate: 0.00012969]
	Learning Rate: 0.000129695
	LOSS [training: 0.1445492380089789 | validation: 0.13181935640405804]
	TIME [epoch: 8.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1890.pth
	Model improved!!!
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13982431677510704		[learning rate: 0.00012939]
	Learning Rate: 0.000129389
	LOSS [training: 0.13982431677510704 | validation: 0.1514291875076979]
	TIME [epoch: 8.49 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14305119446469783		[learning rate: 0.00012908]
	Learning Rate: 0.000129084
	LOSS [training: 0.14305119446469783 | validation: 0.1459976593731656]
	TIME [epoch: 8.47 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1383765363751311		[learning rate: 0.00012878]
	Learning Rate: 0.000128779
	LOSS [training: 0.1383765363751311 | validation: 0.14229828902173808]
	TIME [epoch: 8.47 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1476967016558265		[learning rate: 0.00012848]
	Learning Rate: 0.000128476
	LOSS [training: 0.1476967016558265 | validation: 0.1534194445624335]
	TIME [epoch: 8.47 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1562364576776401		[learning rate: 0.00012817]
	Learning Rate: 0.000128172
	LOSS [training: 0.1562364576776401 | validation: 0.15182759576320679]
	TIME [epoch: 8.48 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14708371663593883		[learning rate: 0.00012787]
	Learning Rate: 0.00012787
	LOSS [training: 0.14708371663593883 | validation: 0.14537809958215214]
	TIME [epoch: 8.49 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13101274404227334		[learning rate: 0.00012757]
	Learning Rate: 0.000127569
	LOSS [training: 0.13101274404227334 | validation: 0.13701597164239263]
	TIME [epoch: 8.47 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14130880805331117		[learning rate: 0.00012727]
	Learning Rate: 0.000127268
	LOSS [training: 0.14130880805331117 | validation: 0.14719488701229821]
	TIME [epoch: 8.47 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14029069596129268		[learning rate: 0.00012697]
	Learning Rate: 0.000126967
	LOSS [training: 0.14029069596129268 | validation: 0.14480074649414548]
	TIME [epoch: 8.48 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13448046814660639		[learning rate: 0.00012667]
	Learning Rate: 0.000126668
	LOSS [training: 0.13448046814660639 | validation: 0.14340637867293804]
	TIME [epoch: 8.48 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13669347504558513		[learning rate: 0.00012637]
	Learning Rate: 0.000126369
	LOSS [training: 0.13669347504558513 | validation: 0.13569161734407142]
	TIME [epoch: 8.46 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13971172491396988		[learning rate: 0.00012607]
	Learning Rate: 0.000126071
	LOSS [training: 0.13971172491396988 | validation: 0.14428430368493156]
	TIME [epoch: 8.46 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.139049406779087		[learning rate: 0.00012577]
	Learning Rate: 0.000125774
	LOSS [training: 0.139049406779087 | validation: 0.14235536789981135]
	TIME [epoch: 8.5 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1457981446189303		[learning rate: 0.00012548]
	Learning Rate: 0.000125477
	LOSS [training: 0.1457981446189303 | validation: 0.1439538711534819]
	TIME [epoch: 8.48 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13766596656427446		[learning rate: 0.00012518]
	Learning Rate: 0.000125181
	LOSS [training: 0.13766596656427446 | validation: 0.1353297410855291]
	TIME [epoch: 8.47 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13951038823127135		[learning rate: 0.00012489]
	Learning Rate: 0.000124886
	LOSS [training: 0.13951038823127135 | validation: 0.1371807441500154]
	TIME [epoch: 8.46 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15536316308182155		[learning rate: 0.00012459]
	Learning Rate: 0.000124591
	LOSS [training: 0.15536316308182155 | validation: 0.17267044793080918]
	TIME [epoch: 8.5 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17385642433480153		[learning rate: 0.0001243]
	Learning Rate: 0.000124297
	LOSS [training: 0.17385642433480153 | validation: 0.18581746579013073]
	TIME [epoch: 8.47 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19352724629589171		[learning rate: 0.000124]
	Learning Rate: 0.000124004
	LOSS [training: 0.19352724629589171 | validation: 0.2000511906326245]
	TIME [epoch: 8.47 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19535307789379466		[learning rate: 0.00012371]
	Learning Rate: 0.000123712
	LOSS [training: 0.19535307789379466 | validation: 0.20084899342679696]
	TIME [epoch: 8.49 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18496667893423221		[learning rate: 0.00012342]
	Learning Rate: 0.00012342
	LOSS [training: 0.18496667893423221 | validation: 0.18681504708507218]
	TIME [epoch: 8.5 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15920203755240342		[learning rate: 0.00012313]
	Learning Rate: 0.000123129
	LOSS [training: 0.15920203755240342 | validation: 0.14275541205800532]
	TIME [epoch: 8.47 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14479172597178602		[learning rate: 0.00012284]
	Learning Rate: 0.000122838
	LOSS [training: 0.14479172597178602 | validation: 0.1427397375775758]
	TIME [epoch: 8.47 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1508336907853016		[learning rate: 0.00012255]
	Learning Rate: 0.000122548
	LOSS [training: 0.1508336907853016 | validation: 0.1612158714336895]
	TIME [epoch: 8.49 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15213960034538093		[learning rate: 0.00012226]
	Learning Rate: 0.000122259
	LOSS [training: 0.15213960034538093 | validation: 0.14503779803525707]
	TIME [epoch: 8.49 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15491118895659464		[learning rate: 0.00012197]
	Learning Rate: 0.000121971
	LOSS [training: 0.15491118895659464 | validation: 0.13699864998852623]
	TIME [epoch: 8.47 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14205159159384112		[learning rate: 0.00012168]
	Learning Rate: 0.000121683
	LOSS [training: 0.14205159159384112 | validation: 0.13110653611902018]
	TIME [epoch: 8.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1917.pth
	Model improved!!!
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14361197322438185		[learning rate: 0.0001214]
	Learning Rate: 0.000121396
	LOSS [training: 0.14361197322438185 | validation: 0.13823041532369718]
	TIME [epoch: 8.5 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13927925105156827		[learning rate: 0.00012111]
	Learning Rate: 0.00012111
	LOSS [training: 0.13927925105156827 | validation: 0.13909198411451384]
	TIME [epoch: 8.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13417452828663884		[learning rate: 0.00012082]
	Learning Rate: 0.000120824
	LOSS [training: 0.13417452828663884 | validation: 0.14352594264453333]
	TIME [epoch: 8.48 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13117306585875702		[learning rate: 0.00012054]
	Learning Rate: 0.000120539
	LOSS [training: 0.13117306585875702 | validation: 0.1417057203648998]
	TIME [epoch: 8.48 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13961911885854655		[learning rate: 0.00012025]
	Learning Rate: 0.000120255
	LOSS [training: 0.13961911885854655 | validation: 0.1488160408617254]
	TIME [epoch: 8.49 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1363240968616141		[learning rate: 0.00011997]
	Learning Rate: 0.000119971
	LOSS [training: 0.1363240968616141 | validation: 0.14371094606041318]
	TIME [epoch: 8.51 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14655450985829943		[learning rate: 0.00011969]
	Learning Rate: 0.000119688
	LOSS [training: 0.14655450985829943 | validation: 0.14813013618464987]
	TIME [epoch: 8.48 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14531033698233153		[learning rate: 0.00011941]
	Learning Rate: 0.000119406
	LOSS [training: 0.14531033698233153 | validation: 0.15536905513811733]
	TIME [epoch: 8.48 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1393136330140365		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.1393136330140365 | validation: 0.14139204233111516]
	TIME [epoch: 8.51 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13864950366042397		[learning rate: 0.00011884]
	Learning Rate: 0.000118843
	LOSS [training: 0.13864950366042397 | validation: 0.1387913565212448]
	TIME [epoch: 8.49 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1417570260777859		[learning rate: 0.00011856]
	Learning Rate: 0.000118563
	LOSS [training: 0.1417570260777859 | validation: 0.1391354349482964]
	TIME [epoch: 8.48 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.144273297948181		[learning rate: 0.00011828]
	Learning Rate: 0.000118283
	LOSS [training: 0.144273297948181 | validation: 0.15271132759853084]
	TIME [epoch: 8.48 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14361709610382264		[learning rate: 0.000118]
	Learning Rate: 0.000118004
	LOSS [training: 0.14361709610382264 | validation: 0.13226089717282688]
	TIME [epoch: 8.52 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13605334965521682		[learning rate: 0.00011773]
	Learning Rate: 0.000117726
	LOSS [training: 0.13605334965521682 | validation: 0.1494798701058965]
	TIME [epoch: 8.5 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1367398645172631		[learning rate: 0.00011745]
	Learning Rate: 0.000117448
	LOSS [training: 0.1367398645172631 | validation: 0.13195581921254218]
	TIME [epoch: 8.48 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13582745686067937		[learning rate: 0.00011717]
	Learning Rate: 0.000117171
	LOSS [training: 0.13582745686067937 | validation: 0.143380595323591]
	TIME [epoch: 8.48 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13967427201194474		[learning rate: 0.00011689]
	Learning Rate: 0.000116895
	LOSS [training: 0.13967427201194474 | validation: 0.13513813116375956]
	TIME [epoch: 8.53 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14238885599914636		[learning rate: 0.00011662]
	Learning Rate: 0.000116619
	LOSS [training: 0.14238885599914636 | validation: 0.13849923740601938]
	TIME [epoch: 8.51 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13637009521350218		[learning rate: 0.00011634]
	Learning Rate: 0.000116344
	LOSS [training: 0.13637009521350218 | validation: 0.14125861793635772]
	TIME [epoch: 8.49 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14295509132916515		[learning rate: 0.00011607]
	Learning Rate: 0.000116069
	LOSS [training: 0.14295509132916515 | validation: 0.14059194742617373]
	TIME [epoch: 8.51 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1458280334406284		[learning rate: 0.0001158]
	Learning Rate: 0.000115796
	LOSS [training: 0.1458280334406284 | validation: 0.14509725333542386]
	TIME [epoch: 8.52 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14684938891572633		[learning rate: 0.00011552]
	Learning Rate: 0.000115523
	LOSS [training: 0.14684938891572633 | validation: 0.148129766690749]
	TIME [epoch: 8.51 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1390893147668379		[learning rate: 0.00011525]
	Learning Rate: 0.00011525
	LOSS [training: 0.1390893147668379 | validation: 0.1360550567684667]
	TIME [epoch: 8.5 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14214790394785481		[learning rate: 0.00011498]
	Learning Rate: 0.000114978
	LOSS [training: 0.14214790394785481 | validation: 0.1314749097557102]
	TIME [epoch: 8.53 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13694845393460822		[learning rate: 0.00011471]
	Learning Rate: 0.000114707
	LOSS [training: 0.13694845393460822 | validation: 0.13941325484120132]
	TIME [epoch: 8.52 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1326074071193322		[learning rate: 0.00011444]
	Learning Rate: 0.000114436
	LOSS [training: 0.1326074071193322 | validation: 0.14744355952431057]
	TIME [epoch: 8.51 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14646908184498558		[learning rate: 0.00011417]
	Learning Rate: 0.000114166
	LOSS [training: 0.14646908184498558 | validation: 0.14014033710910084]
	TIME [epoch: 8.5 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1356199374013092		[learning rate: 0.0001139]
	Learning Rate: 0.000113897
	LOSS [training: 0.1356199374013092 | validation: 0.14233963609361855]
	TIME [epoch: 8.52 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13659305914621317		[learning rate: 0.00011363]
	Learning Rate: 0.000113628
	LOSS [training: 0.13659305914621317 | validation: 0.14074731930825513]
	TIME [epoch: 8.52 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14124738364698725		[learning rate: 0.00011336]
	Learning Rate: 0.00011336
	LOSS [training: 0.14124738364698725 | validation: 0.13347496319339403]
	TIME [epoch: 8.51 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13533838392586972		[learning rate: 0.00011309]
	Learning Rate: 0.000113093
	LOSS [training: 0.13533838392586972 | validation: 0.1385399717571837]
	TIME [epoch: 8.51 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13470554344390756		[learning rate: 0.00011283]
	Learning Rate: 0.000112826
	LOSS [training: 0.13470554344390756 | validation: 0.13052875498347216]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r0_20240219_184940/states/model_tr_study3_1949.pth
	Model improved!!!
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13395982630357617		[learning rate: 0.00011256]
	Learning Rate: 0.00011256
	LOSS [training: 0.13395982630357617 | validation: 0.15139723411621753]
	TIME [epoch: 8.52 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16644265801662497		[learning rate: 0.00011229]
	Learning Rate: 0.000112295
	LOSS [training: 0.16644265801662497 | validation: 0.1850591592884187]
	TIME [epoch: 8.49 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17176322009443368		[learning rate: 0.00011203]
	Learning Rate: 0.00011203
	LOSS [training: 0.17176322009443368 | validation: 0.14320762564986977]
	TIME [epoch: 8.5 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13546723308749573		[learning rate: 0.00011177]
	Learning Rate: 0.000111765
	LOSS [training: 0.13546723308749573 | validation: 0.13989058805922494]
	TIME [epoch: 8.5 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1489878059202775		[learning rate: 0.0001115]
	Learning Rate: 0.000111502
	LOSS [training: 0.1489878059202775 | validation: 0.1451848309885484]
	TIME [epoch: 8.52 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13898381267328383		[learning rate: 0.00011124]
	Learning Rate: 0.000111239
	LOSS [training: 0.13898381267328383 | validation: 0.14154670693297808]
	TIME [epoch: 8.49 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1381163732487874		[learning rate: 0.00011098]
	Learning Rate: 0.000110976
	LOSS [training: 0.1381163732487874 | validation: 0.1350678938238145]
	TIME [epoch: 8.51 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13756674805156105		[learning rate: 0.00011071]
	Learning Rate: 0.000110715
	LOSS [training: 0.13756674805156105 | validation: 0.13678410566468546]
	TIME [epoch: 8.5 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13563606741405143		[learning rate: 0.00011045]
	Learning Rate: 0.000110453
	LOSS [training: 0.13563606741405143 | validation: 0.13462036303230152]
	TIME [epoch: 8.52 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13852634347865458		[learning rate: 0.00011019]
	Learning Rate: 0.000110193
	LOSS [training: 0.13852634347865458 | validation: 0.15261714128089549]
	TIME [epoch: 8.49 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13632874657532545		[learning rate: 0.00010993]
	Learning Rate: 0.000109933
	LOSS [training: 0.13632874657532545 | validation: 0.13946303961300452]
	TIME [epoch: 8.51 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14268563458905945		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.14268563458905945 | validation: 0.15654545091347744]
	TIME [epoch: 8.5 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15103924467670965		[learning rate: 0.00010942]
	Learning Rate: 0.000109415
	LOSS [training: 0.15103924467670965 | validation: 0.13914595446431496]
	TIME [epoch: 8.52 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14412143993593685		[learning rate: 0.00010916]
	Learning Rate: 0.000109157
	LOSS [training: 0.14412143993593685 | validation: 0.1462356464619416]
	TIME [epoch: 8.5 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14610879415963077		[learning rate: 0.0001089]
	Learning Rate: 0.000108899
	LOSS [training: 0.14610879415963077 | validation: 0.1636037535141734]
	TIME [epoch: 8.51 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14701757054935077		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.14701757054935077 | validation: 0.15360235513673953]
	TIME [epoch: 8.5 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.149668426254589		[learning rate: 0.00010839]
	Learning Rate: 0.000108386
	LOSS [training: 0.149668426254589 | validation: 0.14846634342838466]
	TIME [epoch: 8.51 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14053997377397615		[learning rate: 0.00010813]
	Learning Rate: 0.000108131
	LOSS [training: 0.14053997377397615 | validation: 0.1366210049306496]
	TIME [epoch: 8.51 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13455960014303078		[learning rate: 0.00010788]
	Learning Rate: 0.000107876
	LOSS [training: 0.13455960014303078 | validation: 0.14112450793239298]
	TIME [epoch: 8.51 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13712214703521436		[learning rate: 0.00010762]
	Learning Rate: 0.000107621
	LOSS [training: 0.13712214703521436 | validation: 0.13489318117466323]
	TIME [epoch: 8.52 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14535569804845927		[learning rate: 0.00010737]
	Learning Rate: 0.000107367
	LOSS [training: 0.14535569804845927 | validation: 0.14871896233975518]
	TIME [epoch: 8.51 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14431447436962364		[learning rate: 0.00010711]
	Learning Rate: 0.000107114
	LOSS [training: 0.14431447436962364 | validation: 0.14547246835497843]
	TIME [epoch: 8.51 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14587913807349157		[learning rate: 0.00010686]
	Learning Rate: 0.000106861
	LOSS [training: 0.14587913807349157 | validation: 0.1393338810909145]
	TIME [epoch: 8.49 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13526060505075369		[learning rate: 0.00010661]
	Learning Rate: 0.000106609
	LOSS [training: 0.13526060505075369 | validation: 0.13303083353186929]
	TIME [epoch: 8.5 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14359692934134133		[learning rate: 0.00010636]
	Learning Rate: 0.000106358
	LOSS [training: 0.14359692934134133 | validation: 0.14174446294933818]
	TIME [epoch: 8.5 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14249882728422147		[learning rate: 0.00010611]
	Learning Rate: 0.000106107
	LOSS [training: 0.14249882728422147 | validation: 0.1510945287538353]
	TIME [epoch: 8.5 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1517114901663923		[learning rate: 0.00010586]
	Learning Rate: 0.000105857
	LOSS [training: 0.1517114901663923 | validation: 0.15249438419248665]
	TIME [epoch: 8.5 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1437666365504982		[learning rate: 0.00010561]
	Learning Rate: 0.000105607
	LOSS [training: 0.1437666365504982 | validation: 0.13490138202300236]
	TIME [epoch: 8.52 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14845464743129497		[learning rate: 0.00010536]
	Learning Rate: 0.000105358
	LOSS [training: 0.14845464743129497 | validation: 0.15757067112720985]
	TIME [epoch: 8.51 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18177187891485233		[learning rate: 0.00010511]
	Learning Rate: 0.000105109
	LOSS [training: 0.18177187891485233 | validation: 0.20775297549500266]
	TIME [epoch: 8.51 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19193295727990228		[learning rate: 0.00010486]
	Learning Rate: 0.000104861
	LOSS [training: 0.19193295727990228 | validation: 0.17371873980721814]
	TIME [epoch: 8.49 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17508818668846518		[learning rate: 0.00010461]
	Learning Rate: 0.000104614
	LOSS [training: 0.17508818668846518 | validation: 0.17945035615553845]
	TIME [epoch: 8.51 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16643742846023807		[learning rate: 0.00010437]
	Learning Rate: 0.000104367
	LOSS [training: 0.16643742846023807 | validation: 0.16047647918040103]
	TIME [epoch: 8.5 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15776603943630213		[learning rate: 0.00010412]
	Learning Rate: 0.000104121
	LOSS [training: 0.15776603943630213 | validation: 0.15931043944145049]
	TIME [epoch: 8.49 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16339983721259074		[learning rate: 0.00010388]
	Learning Rate: 0.000103875
	LOSS [training: 0.16339983721259074 | validation: 0.1603447218672885]
	TIME [epoch: 8.48 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15742501587587965		[learning rate: 0.00010363]
	Learning Rate: 0.00010363
	LOSS [training: 0.15742501587587965 | validation: 0.16110307941566293]
	TIME [epoch: 8.5 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1525265276900306		[learning rate: 0.00010339]
	Learning Rate: 0.000103386
	LOSS [training: 0.1525265276900306 | validation: 0.15335870138799657]
	TIME [epoch: 8.5 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15594187555497951		[learning rate: 0.00010314]
	Learning Rate: 0.000103142
	LOSS [training: 0.15594187555497951 | validation: 0.15229504905670416]
	TIME [epoch: 8.49 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15232598434422256		[learning rate: 0.0001029]
	Learning Rate: 0.000102899
	LOSS [training: 0.15232598434422256 | validation: 0.14890868001369606]
	TIME [epoch: 8.47 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14963249174334353		[learning rate: 0.00010266]
	Learning Rate: 0.000102656
	LOSS [training: 0.14963249174334353 | validation: 0.1393253144189716]
	TIME [epoch: 8.51 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15750845658505214		[learning rate: 0.00010241]
	Learning Rate: 0.000102414
	LOSS [training: 0.15750845658505214 | validation: 0.1431174552654394]
	TIME [epoch: 8.51 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15059474703529047		[learning rate: 0.00010217]
	Learning Rate: 0.000102172
	LOSS [training: 0.15059474703529047 | validation: 0.14671327734120718]
	TIME [epoch: 8.49 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14900240029819728		[learning rate: 0.00010193]
	Learning Rate: 0.000101931
	LOSS [training: 0.14900240029819728 | validation: 0.1448125476859532]
	TIME [epoch: 8.49 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1466072247182592		[learning rate: 0.00010169]
	Learning Rate: 0.000101691
	LOSS [training: 0.1466072247182592 | validation: 0.14698268443364948]
	TIME [epoch: 8.51 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14447067020393395		[learning rate: 0.00010145]
	Learning Rate: 0.000101451
	LOSS [training: 0.14447067020393395 | validation: 0.15571990694714613]
	TIME [epoch: 8.51 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1615480389199516		[learning rate: 0.00010121]
	Learning Rate: 0.000101212
	LOSS [training: 0.1615480389199516 | validation: 0.1714310567388534]
	TIME [epoch: 8.49 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1592783342808		[learning rate: 0.00010097]
	Learning Rate: 0.000100973
	LOSS [training: 0.1592783342808 | validation: 0.1639328424605838]
	TIME [epoch: 8.49 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1567003785652868		[learning rate: 0.00010073]
	Learning Rate: 0.000100735
	LOSS [training: 0.1567003785652868 | validation: 0.15308818585727613]
	TIME [epoch: 8.52 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15521619671567488		[learning rate: 0.0001005]
	Learning Rate: 0.000100497
	LOSS [training: 0.15521619671567488 | validation: 0.15621383276781875]
	TIME [epoch: 8.49 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16416467826561457		[learning rate: 0.00010026]
	Learning Rate: 0.00010026
	LOSS [training: 0.16416467826561457 | validation: 0.15467457747088442]
	TIME [epoch: 8.49 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.148335568953981		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.148335568953981 | validation: 0.15436201363444207]
	TIME [epoch: 8.49 sec]
Finished training in 17142.255 seconds.
