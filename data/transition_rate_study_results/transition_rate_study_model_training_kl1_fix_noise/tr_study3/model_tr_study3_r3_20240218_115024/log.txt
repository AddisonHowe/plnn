Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r3', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2016895777

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/10] avg loss: 9.891683307688153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.891683307688153 | validation: 9.639466183856975]
	TIME [epoch: 79.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.888888213181671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.888888213181671 | validation: 7.759861451501158]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.006158824443819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.006158824443819 | validation: 6.968420208143612]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.2067251637589065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.2067251637589065 | validation: 6.720907155936953]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.779079207659175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.779079207659175 | validation: 5.996274577118878]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.6291609766565385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6291609766565385 | validation: 6.231230454342119]
	TIME [epoch: 8.39 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.66489609039107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.66489609039107 | validation: 6.044948731705828]
	TIME [epoch: 8.38 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.752962086517096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.752962086517096 | validation: 5.9936486007120156]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.630266105668062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.630266105668062 | validation: 6.025517059212374]
	TIME [epoch: 8.4 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.687233751273494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.687233751273494 | validation: 6.136209894525936]
	TIME [epoch: 8.38 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.6187170388254914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6187170388254914 | validation: 6.31384443478726]
	TIME [epoch: 8.37 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.701289937012108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.701289937012108 | validation: 6.03495216726307]
	TIME [epoch: 8.38 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.6173241232910645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6173241232910645 | validation: 6.002333409542262]
	TIME [epoch: 8.4 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.706978795778133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.706978795778133 | validation: 6.126023328655874]
	TIME [epoch: 8.38 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.689169425162897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.689169425162897 | validation: 6.090390500787018]
	TIME [epoch: 8.38 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.647052537704182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.647052537704182 | validation: 6.066702658490302]
	TIME [epoch: 8.4 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.660095194897162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.660095194897162 | validation: 6.17692360332283]
	TIME [epoch: 8.39 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.696159800941173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.696159800941173 | validation: 6.022614161500346]
	TIME [epoch: 8.37 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.630642126834938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.630642126834938 | validation: 6.089623069011341]
	TIME [epoch: 8.37 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.628941302485297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.628941302485297 | validation: 6.040165893184666]
	TIME [epoch: 8.4 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.67042981142728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.67042981142728 | validation: 6.081578511881192]
	TIME [epoch: 8.4 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.615394785208544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.615394785208544 | validation: 6.201563757313831]
	TIME [epoch: 8.38 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.637399609990849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.637399609990849 | validation: 6.2773812326674445]
	TIME [epoch: 8.39 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.6601558833323695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6601558833323695 | validation: 6.111753606431174]
	TIME [epoch: 8.4 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.661701525359108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.661701525359108 | validation: 6.042262245783625]
	TIME [epoch: 8.39 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.64915327576918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.64915327576918 | validation: 6.08345994456358]
	TIME [epoch: 8.38 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.637475699171082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.637475699171082 | validation: 6.16344306153689]
	TIME [epoch: 8.38 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.620385601496598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.620385601496598 | validation: 6.137603451685697]
	TIME [epoch: 8.4 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.7240342115135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7240342115135 | validation: 6.101752588941786]
	TIME [epoch: 8.38 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.691892637018301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.691892637018301 | validation: 6.112260707212604]
	TIME [epoch: 8.37 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.6770323368463576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6770323368463576 | validation: 6.030892075088927]
	TIME [epoch: 8.38 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.6048984048734765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6048984048734765 | validation: 5.987945784421105]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.575751245276651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.575751245276651 | validation: 6.067655744045219]
	TIME [epoch: 8.38 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.779346456649482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.779346456649482 | validation: 6.151000454401718]
	TIME [epoch: 8.38 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.639048126098018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.639048126098018 | validation: 6.01772973471123]
	TIME [epoch: 8.39 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.583471519138984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.583471519138984 | validation: 6.014797467562012]
	TIME [epoch: 8.37 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.616368446933957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.616368446933957 | validation: 6.288818024290846]
	TIME [epoch: 8.37 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.728895209039203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.728895209039203 | validation: 6.097165586179397]
	TIME [epoch: 8.38 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.644681349714986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.644681349714986 | validation: 5.995276371286231]
	TIME [epoch: 8.4 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.579510950848201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.579510950848201 | validation: 6.140545618819694]
	TIME [epoch: 8.38 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.622087825970628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.622087825970628 | validation: 6.134152054129508]
	TIME [epoch: 8.37 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.620063701273814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.620063701273814 | validation: 6.076484409759875]
	TIME [epoch: 8.38 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.613549994851104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.613549994851104 | validation: 6.0298611901162005]
	TIME [epoch: 8.4 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.582543313077484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.582543313077484 | validation: 6.19023696597911]
	TIME [epoch: 8.38 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.665811969924382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.665811969924382 | validation: 6.045969956662271]
	TIME [epoch: 8.37 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.590097377278424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.590097377278424 | validation: 6.0574475704046575]
	TIME [epoch: 8.4 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.542006853799196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.542006853799196 | validation: 5.866093149411966]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_47.pth
	Model improved!!!
EPOCH 48/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.479008744495377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.479008744495377 | validation: 5.759828124424642]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.428331509108927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.428331509108927 | validation: 5.686932990113296]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_49.pth
	Model improved!!!
EPOCH 50/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.549794762948292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.549794762948292 | validation: 5.563178865674244]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_50.pth
	Model improved!!!
EPOCH 51/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.182268377795014		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 6.182268377795014 | validation: 5.313917487762248]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_51.pth
	Model improved!!!
EPOCH 52/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.938444086360391		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 5.938444086360391 | validation: 5.077549545560705]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_52.pth
	Model improved!!!
EPOCH 53/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.791008848111245		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 4.791008848111245 | validation: 3.8839689400300674]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_53.pth
	Model improved!!!
EPOCH 54/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.650312253254205		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 4.650312253254205 | validation: 4.552551877647427]
	TIME [epoch: 8.41 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.402887771841951		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 4.402887771841951 | validation: 3.5940221465615054]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_55.pth
	Model improved!!!
EPOCH 56/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.304745231325606		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 4.304745231325606 | validation: 3.5735202968328332]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_56.pth
	Model improved!!!
EPOCH 57/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.541788576896921		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 5.541788576896921 | validation: 5.9526992000680865]
	TIME [epoch: 8.39 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.46942995677247		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 6.46942995677247 | validation: 5.553040465510314]
	TIME [epoch: 8.4 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.401681642198757		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 6.401681642198757 | validation: 6.177930596269133]
	TIME [epoch: 8.37 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.457087708989175		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 6.457087708989175 | validation: 5.5993350511935684]
	TIME [epoch: 8.38 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.968728689673926		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 5.968728689673926 | validation: 4.053064306100287]
	TIME [epoch: 8.39 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.71241511429331		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 4.71241511429331 | validation: 3.1846235114975023]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_62.pth
	Model improved!!!
EPOCH 63/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.024417324599947		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 4.024417324599947 | validation: 3.1209919085063236]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_63.pth
	Model improved!!!
EPOCH 64/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.104192654888683		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 4.104192654888683 | validation: 3.552808373043505]
	TIME [epoch: 8.38 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.1756622881168		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 4.1756622881168 | validation: 3.236602924470704]
	TIME [epoch: 8.39 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.0396961846875445		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 4.0396961846875445 | validation: 3.4936703904652533]
	TIME [epoch: 8.38 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.141773236949637		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 4.141773236949637 | validation: 3.267913549529353]
	TIME [epoch: 8.38 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.912589616177967		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 3.912589616177967 | validation: 3.1954348855553762]
	TIME [epoch: 8.38 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.493837009103429		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 4.493837009103429 | validation: 3.2233407779887147]
	TIME [epoch: 8.39 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.905210142163475		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 3.905210142163475 | validation: 3.088042844298987]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_70.pth
	Model improved!!!
EPOCH 71/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.811983370860811		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 3.811983370860811 | validation: 3.2261860658886907]
	TIME [epoch: 8.38 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.8193852890394693		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 3.8193852890394693 | validation: 3.4439350925831658]
	TIME [epoch: 8.37 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.957402951126697		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 3.957402951126697 | validation: 3.152793886738739]
	TIME [epoch: 8.39 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.8188783722194666		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 3.8188783722194666 | validation: 3.054143188923149]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_74.pth
	Model improved!!!
EPOCH 75/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.8253485653679875		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 3.8253485653679875 | validation: 3.5459203093387943]
	TIME [epoch: 8.38 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.112068019688416		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 4.112068019688416 | validation: 3.6362556350262243]
	TIME [epoch: 8.38 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.702898999852617		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 5.702898999852617 | validation: 5.405233945146177]
	TIME [epoch: 8.4 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.241256515401519		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 6.241256515401519 | validation: 5.360969863729515]
	TIME [epoch: 8.38 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.1205589052979255		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 6.1205589052979255 | validation: 5.330497084269901]
	TIME [epoch: 8.37 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.123979983515332		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 6.123979983515332 | validation: 5.224508579447787]
	TIME [epoch: 8.37 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.046428918003315		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 6.046428918003315 | validation: 5.255317424434301]
	TIME [epoch: 8.41 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.089106312913818		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 6.089106312913818 | validation: 5.327522139183096]
	TIME [epoch: 8.37 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.84880925422267		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 5.84880925422267 | validation: 4.624851793142826]
	TIME [epoch: 8.38 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.328183624375786		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 5.328183624375786 | validation: 4.303754886935117]
	TIME [epoch: 8.36 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.460496330761242		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 4.460496330761242 | validation: 3.6235421298055277]
	TIME [epoch: 8.4 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.051768375833726		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 4.051768375833726 | validation: 3.024878055156144]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_86.pth
	Model improved!!!
EPOCH 87/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.943008191891741		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 3.943008191891741 | validation: 3.859315876734847]
	TIME [epoch: 8.38 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.9808835969026943		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 3.9808835969026943 | validation: 3.4688456121900906]
	TIME [epoch: 8.37 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.905291328709109		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 3.905291328709109 | validation: 4.167194120294688]
	TIME [epoch: 8.4 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.733317841795676		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 3.733317841795676 | validation: 3.4199281487294693]
	TIME [epoch: 8.38 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.4958539992981024		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 3.4958539992981024 | validation: 2.8419560576071756]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_91.pth
	Model improved!!!
EPOCH 92/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.3738719405758686		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 3.3738719405758686 | validation: 2.783622117970613]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_92.pth
	Model improved!!!
EPOCH 93/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.5226857592525413		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 2.5226857592525413 | validation: 2.457165619908435]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_93.pth
	Model improved!!!
EPOCH 94/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.043832330149611		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 2.043832330149611 | validation: 1.8248160742713324]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_94.pth
	Model improved!!!
EPOCH 95/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.190424136490822		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 2.190424136490822 | validation: 2.0119260280581663]
	TIME [epoch: 8.38 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9679105298484814		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 1.9679105298484814 | validation: 1.8865924875759612]
	TIME [epoch: 8.38 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.1433079162513957		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 2.1433079162513957 | validation: 1.7598364166971492]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_97.pth
	Model improved!!!
EPOCH 98/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8535517388780405		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 1.8535517388780405 | validation: 1.8885973206795006]
	TIME [epoch: 8.37 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8037037218421623		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 1.8037037218421623 | validation: 1.6606444970487777]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_99.pth
	Model improved!!!
EPOCH 100/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6464529597697877		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 1.6464529597697877 | validation: 2.0277339471024938]
	TIME [epoch: 8.39 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7095246434413371		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 1.7095246434413371 | validation: 1.486752294615706]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_101.pth
	Model improved!!!
EPOCH 102/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6545338545266937		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 1.6545338545266937 | validation: 1.3800309978509597]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_102.pth
	Model improved!!!
EPOCH 103/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6116656261094313		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 1.6116656261094313 | validation: 2.390473427694407]
	TIME [epoch: 8.37 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.82467437970367		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 1.82467437970367 | validation: 2.209270235114586]
	TIME [epoch: 8.39 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9371677346097893		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 1.9371677346097893 | validation: 1.4220401854089917]
	TIME [epoch: 8.38 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5375875059537152		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 1.5375875059537152 | validation: 1.4056577975094002]
	TIME [epoch: 8.37 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.471894960989979		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 1.471894960989979 | validation: 1.3223268349811077]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_107.pth
	Model improved!!!
EPOCH 108/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5981973955582636		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 1.5981973955582636 | validation: 1.6257445398924038]
	TIME [epoch: 8.41 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5277591763711176		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 1.5277591763711176 | validation: 1.8060171589313616]
	TIME [epoch: 8.38 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3984930049742734		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 1.3984930049742734 | validation: 1.8174758362960408]
	TIME [epoch: 8.38 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.464070058849563		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 1.464070058849563 | validation: 1.4931621048486936]
	TIME [epoch: 8.37 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4875458414273675		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 1.4875458414273675 | validation: 1.2857801353251612]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_112.pth
	Model improved!!!
EPOCH 113/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4221246474259053		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 1.4221246474259053 | validation: 1.4629828919661394]
	TIME [epoch: 8.39 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4397281301584481		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 1.4397281301584481 | validation: 1.6658823611314064]
	TIME [epoch: 8.38 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4024918931872024		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 1.4024918931872024 | validation: 1.2685454698689127]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_115.pth
	Model improved!!!
EPOCH 116/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3245338009459722		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 1.3245338009459722 | validation: 1.5326254420676975]
	TIME [epoch: 8.4 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4282442897577812		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 1.4282442897577812 | validation: 2.029451626889932]
	TIME [epoch: 8.37 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.559032868957848		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 1.559032868957848 | validation: 1.324413906997663]
	TIME [epoch: 8.37 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3296482237337766		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 1.3296482237337766 | validation: 1.2104615227725217]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_119.pth
	Model improved!!!
EPOCH 120/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4198589406610131		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 1.4198589406610131 | validation: 1.1917857677409636]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_120.pth
	Model improved!!!
EPOCH 121/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2222590380240845		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 1.2222590380240845 | validation: 1.3332004726646547]
	TIME [epoch: 8.37 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1725208639953313		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 1.1725208639953313 | validation: 1.4781370455473013]
	TIME [epoch: 8.36 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2977689080775607		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 1.2977689080775607 | validation: 1.4373535305597334]
	TIME [epoch: 8.36 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2894285453410101		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 1.2894285453410101 | validation: 1.126528305612248]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_124.pth
	Model improved!!!
EPOCH 125/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2110470413958228		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 1.2110470413958228 | validation: 1.1672492414397375]
	TIME [epoch: 8.37 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.135411919117883		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 1.135411919117883 | validation: 1.466882994892218]
	TIME [epoch: 8.36 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.593783935999088		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 1.593783935999088 | validation: 2.045072461220646]
	TIME [epoch: 8.36 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2433007145847907		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 1.2433007145847907 | validation: 1.0671908170505233]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_128.pth
	Model improved!!!
EPOCH 129/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2430101698635903		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 1.2430101698635903 | validation: 1.0451404045637487]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_129.pth
	Model improved!!!
EPOCH 130/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1209108566166488		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 1.1209108566166488 | validation: 1.0022907885862704]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_130.pth
	Model improved!!!
EPOCH 131/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3746918056531965		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 1.3746918056531965 | validation: 1.1599122300247915]
	TIME [epoch: 8.37 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.204194325407818		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 1.204194325407818 | validation: 0.8552144377534849]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_132.pth
	Model improved!!!
EPOCH 133/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.055583837518801		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 1.055583837518801 | validation: 1.1872008329630561]
	TIME [epoch: 8.36 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.148110576700919		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 1.148110576700919 | validation: 1.3481085919835416]
	TIME [epoch: 8.36 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0927532470952437		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 1.0927532470952437 | validation: 1.1715148495498517]
	TIME [epoch: 8.36 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0374442548168328		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 1.0374442548168328 | validation: 0.9520535184369254]
	TIME [epoch: 8.38 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0079034373092455		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 1.0079034373092455 | validation: 1.0369306937713294]
	TIME [epoch: 8.36 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0329554604861		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 1.0329554604861 | validation: 1.1026136032811853]
	TIME [epoch: 8.36 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9908939604943118		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 0.9908939604943118 | validation: 1.2544621965382303]
	TIME [epoch: 8.35 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0869096544623054		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 1.0869096544623054 | validation: 0.8685167866042045]
	TIME [epoch: 8.38 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9226482643247973		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 0.9226482643247973 | validation: 1.1064419748195937]
	TIME [epoch: 8.36 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.952382744480512		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 0.952382744480512 | validation: 0.8027215322164987]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_142.pth
	Model improved!!!
EPOCH 143/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0082636374643403		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 1.0082636374643403 | validation: 1.1801919431015981]
	TIME [epoch: 8.39 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9799469606989797		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 0.9799469606989797 | validation: 1.009159333021477]
	TIME [epoch: 8.37 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9352411262735009		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 0.9352411262735009 | validation: 0.9066210212500816]
	TIME [epoch: 8.37 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9814558352629092		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 0.9814558352629092 | validation: 0.902867748206848]
	TIME [epoch: 8.37 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9382805632409669		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.9382805632409669 | validation: 0.7763450095399105]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_147.pth
	Model improved!!!
EPOCH 148/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9757492256363276		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 0.9757492256363276 | validation: 0.8518411217962025]
	TIME [epoch: 8.37 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0429930452122227		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 1.0429930452122227 | validation: 0.8194986052828377]
	TIME [epoch: 8.37 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8018434258879076		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 0.8018434258879076 | validation: 0.8282996480449458]
	TIME [epoch: 8.36 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7276500221871777		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 0.7276500221871777 | validation: 0.665629373753303]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_151.pth
	Model improved!!!
EPOCH 152/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8752566338889082		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 0.8752566338889082 | validation: 1.0648308577990135]
	TIME [epoch: 8.38 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7302693724514615		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 0.7302693724514615 | validation: 0.991574937422515]
	TIME [epoch: 8.37 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8576748533959595		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 0.8576748533959595 | validation: 1.1050451226911004]
	TIME [epoch: 8.37 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8079042999652757		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 0.8079042999652757 | validation: 0.7777859822751605]
	TIME [epoch: 8.39 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8472882347464882		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 0.8472882347464882 | validation: 0.7165475920690414]
	TIME [epoch: 8.37 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.952455305963203		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 0.952455305963203 | validation: 0.6762316061743903]
	TIME [epoch: 8.37 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6718093206608002		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 0.6718093206608002 | validation: 0.7381369128931766]
	TIME [epoch: 8.37 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7700043030879955		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 0.7700043030879955 | validation: 0.8186347772881237]
	TIME [epoch: 8.39 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.890313286904053		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 0.890313286904053 | validation: 1.1290103797045927]
	TIME [epoch: 8.37 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.848179497079923		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 0.848179497079923 | validation: 0.6321399758148318]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_161.pth
	Model improved!!!
EPOCH 162/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7976293282975954		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 0.7976293282975954 | validation: 1.0356407438234858]
	TIME [epoch: 8.37 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8013228092395597		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 0.8013228092395597 | validation: 0.558440733281085]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_163.pth
	Model improved!!!
EPOCH 164/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6664541401037283		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 0.6664541401037283 | validation: 0.7107873553554973]
	TIME [epoch: 8.37 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7163334907277898		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 0.7163334907277898 | validation: 0.6812009042404845]
	TIME [epoch: 8.37 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7810649039762796		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.7810649039762796 | validation: 0.7320668879045769]
	TIME [epoch: 8.36 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6913374954467992		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 0.6913374954467992 | validation: 0.7984644321349299]
	TIME [epoch: 8.39 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8529127083832242		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 0.8529127083832242 | validation: 1.0430205822204839]
	TIME [epoch: 8.37 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9031865380288361		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 0.9031865380288361 | validation: 0.6440749950498263]
	TIME [epoch: 8.37 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6718836478091754		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 0.6718836478091754 | validation: 0.5672598098355202]
	TIME [epoch: 8.37 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5849174011076765		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 0.5849174011076765 | validation: 0.6682572678139265]
	TIME [epoch: 8.39 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2575215185960964		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 1.2575215185960964 | validation: 0.8394100373779031]
	TIME [epoch: 8.37 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5871891859775695		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 0.5871891859775695 | validation: 0.5473070904467161]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_173.pth
	Model improved!!!
EPOCH 174/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8334107361701804		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 0.8334107361701804 | validation: 0.865872541956198]
	TIME [epoch: 8.4 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8025472407229183		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 0.8025472407229183 | validation: 0.7322494955644758]
	TIME [epoch: 8.38 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5497950732890868		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.5497950732890868 | validation: 0.6870772814694157]
	TIME [epoch: 8.38 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7582456536771135		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 0.7582456536771135 | validation: 0.8305655442840967]
	TIME [epoch: 8.38 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8137885230132454		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 0.8137885230132454 | validation: 0.5395917382196227]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_178.pth
	Model improved!!!
EPOCH 179/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7057203984536178		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.7057203984536178 | validation: 0.5307954054883981]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_179.pth
	Model improved!!!
EPOCH 180/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7064172423390727		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 0.7064172423390727 | validation: 0.421444780695006]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_180.pth
	Model improved!!!
EPOCH 181/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6029948983339406		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 0.6029948983339406 | validation: 0.7752119046270127]
	TIME [epoch: 8.37 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6472530095101562		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.6472530095101562 | validation: 0.7126478314544108]
	TIME [epoch: 8.4 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6894973191414964		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 0.6894973191414964 | validation: 0.5117344949498708]
	TIME [epoch: 8.37 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7179784522882738		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 0.7179784522882738 | validation: 0.8513686994622656]
	TIME [epoch: 8.38 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.608361076352768		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.608361076352768 | validation: 0.5900292276053292]
	TIME [epoch: 8.37 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7575987569170224		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.7575987569170224 | validation: 0.7292107130997911]
	TIME [epoch: 8.4 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5813814065610805		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 0.5813814065610805 | validation: 0.6849530606878934]
	TIME [epoch: 8.38 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5657910056849461		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 0.5657910056849461 | validation: 0.5246474895058713]
	TIME [epoch: 8.37 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6922031803569388		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 0.6922031803569388 | validation: 0.630052678894863]
	TIME [epoch: 8.38 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7382030849585572		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.7382030849585572 | validation: 0.7060666101758953]
	TIME [epoch: 8.4 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6616553052093374		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 0.6616553052093374 | validation: 0.5905890363018464]
	TIME [epoch: 8.38 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7763433522027412		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 0.7763433522027412 | validation: 0.7247660262717847]
	TIME [epoch: 8.37 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7244498473242124		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 0.7244498473242124 | validation: 0.7243160817710423]
	TIME [epoch: 8.38 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.84641432016673		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.84641432016673 | validation: 0.8649290384096642]
	TIME [epoch: 8.4 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.661246962774316		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.661246962774316 | validation: 0.7396016384167349]
	TIME [epoch: 8.37 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7099588574527923		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.7099588574527923 | validation: 0.42295418145248653]
	TIME [epoch: 8.37 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5573530696337691		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.5573530696337691 | validation: 0.7233089258403009]
	TIME [epoch: 8.39 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6286123424813133		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 0.6286123424813133 | validation: 0.4995783970611527]
	TIME [epoch: 8.38 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.600314036901257		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.600314036901257 | validation: 0.6580887477184799]
	TIME [epoch: 8.37 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6222525075565415		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.6222525075565415 | validation: 0.5120514759654851]
	TIME [epoch: 8.37 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5999077978513373		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.5999077978513373 | validation: 0.5977957393948425]
	TIME [epoch: 8.4 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6659043166324194		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.6659043166324194 | validation: 0.4480361946210021]
	TIME [epoch: 8.38 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6297347005977633		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 0.6297347005977633 | validation: 0.8895633421096245]
	TIME [epoch: 8.36 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7458210724014668		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.7458210724014668 | validation: 0.4778891887671308]
	TIME [epoch: 8.39 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5776931712376944		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.5776931712376944 | validation: 0.48420761081471786]
	TIME [epoch: 8.38 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.551959472402437		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 0.551959472402437 | validation: 0.948530170525024]
	TIME [epoch: 8.38 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.656095921531026		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.656095921531026 | validation: 0.6759600559118548]
	TIME [epoch: 8.37 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6498798254832592		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.6498798254832592 | validation: 0.44554670786916784]
	TIME [epoch: 8.39 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47890899502126		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.47890899502126 | validation: 0.7300116180209859]
	TIME [epoch: 8.38 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7115273167823639		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.7115273167823639 | validation: 0.4956281511083489]
	TIME [epoch: 8.37 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7434514838981297		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.7434514838981297 | validation: 0.7079578436756353]
	TIME [epoch: 8.37 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6339091365216218		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.6339091365216218 | validation: 0.9430145042251941]
	TIME [epoch: 8.39 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5730312875458665		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.5730312875458665 | validation: 0.5894254201795046]
	TIME [epoch: 8.37 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7637962697455675		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.7637962697455675 | validation: 0.8570907769787468]
	TIME [epoch: 8.37 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5526445067642541		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.5526445067642541 | validation: 0.5324290515990274]
	TIME [epoch: 8.39 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5807107820571262		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.5807107820571262 | validation: 0.6942380152556068]
	TIME [epoch: 8.38 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6565138708497817		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.6565138708497817 | validation: 0.4477169845075132]
	TIME [epoch: 8.37 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6006373472102733		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.6006373472102733 | validation: 0.7006235998613107]
	TIME [epoch: 8.37 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5776117218884742		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.5776117218884742 | validation: 0.46374232035799745]
	TIME [epoch: 8.4 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5743184979199657		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.5743184979199657 | validation: 0.41442141274847577]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_220.pth
	Model improved!!!
EPOCH 221/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5163472861944968		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.5163472861944968 | validation: 0.36241881939921705]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_221.pth
	Model improved!!!
EPOCH 222/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.507668069085337		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.507668069085337 | validation: 0.8617669487832371]
	TIME [epoch: 8.39 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6481719240733608		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.6481719240733608 | validation: 0.8819705572849098]
	TIME [epoch: 8.38 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6022844456047078		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.6022844456047078 | validation: 0.9001450679707127]
	TIME [epoch: 8.37 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6802329407081152		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.6802329407081152 | validation: 0.7176872757430968]
	TIME [epoch: 8.37 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5646867266889017		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.5646867266889017 | validation: 0.9179179357319776]
	TIME [epoch: 8.38 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5012690650865576		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.5012690650865576 | validation: 0.5664252560294472]
	TIME [epoch: 8.39 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6396035727087349		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.6396035727087349 | validation: 0.6399047817779666]
	TIME [epoch: 8.37 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4878531452429155		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.4878531452429155 | validation: 0.7031921813720412]
	TIME [epoch: 8.37 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6292414431673954		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.6292414431673954 | validation: 0.4591114591149521]
	TIME [epoch: 8.39 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46610370864600004		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.46610370864600004 | validation: 0.3705129560491447]
	TIME [epoch: 8.38 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49460719058938707		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.49460719058938707 | validation: 0.7564193128541798]
	TIME [epoch: 8.38 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5998260784389016		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.5998260784389016 | validation: 0.709982353363954]
	TIME [epoch: 8.37 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6671997463622938		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.6671997463622938 | validation: 0.5424164219869008]
	TIME [epoch: 8.39 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6049431414323876		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.6049431414323876 | validation: 0.4998227951608002]
	TIME [epoch: 8.37 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4959068525476155		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.4959068525476155 | validation: 0.5000897563703537]
	TIME [epoch: 8.37 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4754743363239358		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.4754743363239358 | validation: 0.42054897512060085]
	TIME [epoch: 8.4 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5452007364072298		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.5452007364072298 | validation: 0.3559479748528782]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_238.pth
	Model improved!!!
EPOCH 239/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46927379024410254		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.46927379024410254 | validation: 0.36401186287112686]
	TIME [epoch: 8.38 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4645534351135491		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.4645534351135491 | validation: 0.880621296079999]
	TIME [epoch: 8.37 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5213072501631846		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.5213072501631846 | validation: 0.39751853138680715]
	TIME [epoch: 8.4 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47856203973681544		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.47856203973681544 | validation: 0.8323188716376972]
	TIME [epoch: 8.37 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6135144051744721		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.6135144051744721 | validation: 0.5058715802150531]
	TIME [epoch: 8.38 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5670170258077311		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.5670170258077311 | validation: 0.6834668738181643]
	TIME [epoch: 8.37 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5389099998156436		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.5389099998156436 | validation: 0.5200885598482702]
	TIME [epoch: 8.4 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45829843166371587		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.45829843166371587 | validation: 1.0070939128762535]
	TIME [epoch: 8.37 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5134250831599221		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.5134250831599221 | validation: 0.5711375479220914]
	TIME [epoch: 8.37 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48309639508809754		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.48309639508809754 | validation: 0.3654633678102285]
	TIME [epoch: 8.39 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4873246478585111		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.4873246478585111 | validation: 0.48619135921886514]
	TIME [epoch: 8.38 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5863496063581672		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.5863496063581672 | validation: 0.5822428619870752]
	TIME [epoch: 8.37 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5129111886069425		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.5129111886069425 | validation: 0.4432870351488718]
	TIME [epoch: 8.37 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4572831645468895		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.4572831645468895 | validation: 0.6033388808833827]
	TIME [epoch: 8.39 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.577591871597494		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.577591871597494 | validation: 0.4564415194253352]
	TIME [epoch: 8.38 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4615816468583347		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.4615816468583347 | validation: 0.5634313447778359]
	TIME [epoch: 8.36 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5376551234437674		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.5376551234437674 | validation: 0.6136969849464657]
	TIME [epoch: 8.38 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47081258112814445		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.47081258112814445 | validation: 0.3505978434770351]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_256.pth
	Model improved!!!
EPOCH 257/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4997747332038244		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.4997747332038244 | validation: 0.43333451591085204]
	TIME [epoch: 8.37 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39986718382202296		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.39986718382202296 | validation: 0.37792184977052434]
	TIME [epoch: 8.37 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3730520235934914		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.3730520235934914 | validation: 0.4832921471611604]
	TIME [epoch: 8.39 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4572773161544763		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.4572773161544763 | validation: 0.6089917097933147]
	TIME [epoch: 8.37 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4792024263932054		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.4792024263932054 | validation: 0.5538341428788163]
	TIME [epoch: 8.37 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4965731420217705		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.4965731420217705 | validation: 0.3756432739043244]
	TIME [epoch: 8.37 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4338724766283989		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.4338724766283989 | validation: 0.40856977670734684]
	TIME [epoch: 8.39 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4092661056956556		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.4092661056956556 | validation: 0.4475088541215385]
	TIME [epoch: 8.37 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4295330568489194		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.4295330568489194 | validation: 0.4043393835917378]
	TIME [epoch: 8.37 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47126519715386506		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.47126519715386506 | validation: 0.5121802036452946]
	TIME [epoch: 8.37 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4248254225823354		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.4248254225823354 | validation: 0.5231157705872347]
	TIME [epoch: 8.39 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4214359684541108		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.4214359684541108 | validation: 0.48563757758322557]
	TIME [epoch: 8.36 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42954850189451765		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.42954850189451765 | validation: 0.6415597175133911]
	TIME [epoch: 8.36 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4243499202663342		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.4243499202663342 | validation: 0.46335473154075296]
	TIME [epoch: 8.38 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46374382100345796		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.46374382100345796 | validation: 0.47701855358353173]
	TIME [epoch: 8.38 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49848549219275107		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.49848549219275107 | validation: 0.45229398239702745]
	TIME [epoch: 8.37 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41349554859307275		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.41349554859307275 | validation: 0.43785132415023276]
	TIME [epoch: 8.37 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.568625180068606		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.568625180068606 | validation: 0.34935959175601305]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_274.pth
	Model improved!!!
EPOCH 275/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45498058853423984		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.45498058853423984 | validation: 0.2811764759896386]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_275.pth
	Model improved!!!
EPOCH 276/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3655899983501797		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.3655899983501797 | validation: 0.40988161645320254]
	TIME [epoch: 8.37 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35661851703516856		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.35661851703516856 | validation: 0.5645004330562431]
	TIME [epoch: 8.38 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5362703457269763		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.5362703457269763 | validation: 0.5055737705418161]
	TIME [epoch: 8.37 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5008912380173494		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.5008912380173494 | validation: 0.7115076368087884]
	TIME [epoch: 8.37 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4383631769670583		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.4383631769670583 | validation: 0.40067375487199564]
	TIME [epoch: 8.36 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4268130289393806		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.4268130289393806 | validation: 0.8883990903749763]
	TIME [epoch: 8.38 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4427593284985757		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.4427593284985757 | validation: 0.5340808182433013]
	TIME [epoch: 8.38 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44324014930969896		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.44324014930969896 | validation: 1.0340411584319247]
	TIME [epoch: 8.37 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47161935916231357		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.47161935916231357 | validation: 0.38438415295210826]
	TIME [epoch: 8.37 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4831869512724512		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.4831869512724512 | validation: 1.1349639605450068]
	TIME [epoch: 8.38 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43469225490422597		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.43469225490422597 | validation: 0.3005350656935494]
	TIME [epoch: 8.36 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3575134337233522		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.3575134337233522 | validation: 0.4567579264584196]
	TIME [epoch: 8.36 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45336763203481106		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.45336763203481106 | validation: 0.245286697350892]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_288.pth
	Model improved!!!
EPOCH 289/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3188144078184928		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.3188144078184928 | validation: 0.3040413941171555]
	TIME [epoch: 8.39 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3534197178368989		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.3534197178368989 | validation: 0.37864712110337423]
	TIME [epoch: 8.37 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34272518918201855		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.34272518918201855 | validation: 0.44337664306028635]
	TIME [epoch: 8.37 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5996022682506476		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.5996022682506476 | validation: 0.3793001229292291]
	TIME [epoch: 8.38 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43033003820074683		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.43033003820074683 | validation: 0.4090715852935715]
	TIME [epoch: 8.39 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44576405515469625		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.44576405515469625 | validation: 0.5462809194309698]
	TIME [epoch: 8.37 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45605122072317766		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.45605122072317766 | validation: 1.1547851672026428]
	TIME [epoch: 8.36 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47420613332510025		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.47420613332510025 | validation: 0.38120518732642117]
	TIME [epoch: 8.39 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3669405359703175		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.3669405359703175 | validation: 0.35125941612475026]
	TIME [epoch: 8.37 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3464839049724784		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.3464839049724784 | validation: 0.33074543418550784]
	TIME [epoch: 8.37 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45330864412531424		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.45330864412531424 | validation: 0.3473290750211335]
	TIME [epoch: 8.37 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36839187267526724		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.36839187267526724 | validation: 0.44241090540758643]
	TIME [epoch: 8.4 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4614811510788625		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.4614811510788625 | validation: 0.7148649708248981]
	TIME [epoch: 8.36 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.460732481863377		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.460732481863377 | validation: 0.3288564809694538]
	TIME [epoch: 8.36 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43410117873879644		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.43410117873879644 | validation: 0.4610945001763519]
	TIME [epoch: 8.39 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34884359878457294		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.34884359878457294 | validation: 0.2926074537402726]
	TIME [epoch: 8.38 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4045518860131548		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.4045518860131548 | validation: 0.46893416902097307]
	TIME [epoch: 8.37 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4637495822856826		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.4637495822856826 | validation: 0.30283605407719716]
	TIME [epoch: 8.36 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3975096316250457		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.3975096316250457 | validation: 0.2726077643279964]
	TIME [epoch: 8.39 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34228127788453777		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.34228127788453777 | validation: 0.8667015256002302]
	TIME [epoch: 8.37 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40258710289443966		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.40258710289443966 | validation: 0.4718580863572699]
	TIME [epoch: 8.37 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36256461005814133		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.36256461005814133 | validation: 0.4562464848739528]
	TIME [epoch: 8.38 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4116764965549917		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.4116764965549917 | validation: 0.390142775371909]
	TIME [epoch: 8.39 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3411641690136892		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.3411641690136892 | validation: 0.255530246643739]
	TIME [epoch: 8.37 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32682218059036316		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.32682218059036316 | validation: 0.27064763009221066]
	TIME [epoch: 8.36 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3947905002443873		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.3947905002443873 | validation: 0.4833134597495867]
	TIME [epoch: 8.38 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4624684704906086		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.4624684704906086 | validation: 0.3951152295151422]
	TIME [epoch: 8.37 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34671652162460725		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.34671652162460725 | validation: 0.9872772833760064]
	TIME [epoch: 8.37 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5168335703752832		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.5168335703752832 | validation: 0.2737607988243751]
	TIME [epoch: 8.37 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3295800039257899		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.3295800039257899 | validation: 0.40550503223375356]
	TIME [epoch: 8.39 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31866091828973425		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.31866091828973425 | validation: 0.37603851558151524]
	TIME [epoch: 8.36 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3489076799992571		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.3489076799992571 | validation: 0.28017815385868533]
	TIME [epoch: 8.36 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3334632937208438		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.3334632937208438 | validation: 0.3330123061183007]
	TIME [epoch: 8.37 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29315581654748113		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.29315581654748113 | validation: 0.3543445637896921]
	TIME [epoch: 8.39 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3619282165128407		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.3619282165128407 | validation: 0.3635771955741971]
	TIME [epoch: 8.37 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3911768495850046		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.3911768495850046 | validation: 0.4320766697871934]
	TIME [epoch: 8.37 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3911664055251808		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.3911664055251808 | validation: 0.2846839283030175]
	TIME [epoch: 8.38 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36991052618384096		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.36991052618384096 | validation: 0.3499656915701176]
	TIME [epoch: 8.38 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34264194740212284		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.34264194740212284 | validation: 0.36461577178966376]
	TIME [epoch: 8.37 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40297903565318877		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.40297903565318877 | validation: 0.241605803903338]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_328.pth
	Model improved!!!
EPOCH 329/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.334832375869513		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.334832375869513 | validation: 0.5929185492084724]
	TIME [epoch: 8.39 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4014522145866545		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.4014522145866545 | validation: 0.26356174672492383]
	TIME [epoch: 8.37 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37314534941976085		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.37314534941976085 | validation: 0.6684722936720122]
	TIME [epoch: 8.37 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4030215232528834		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.4030215232528834 | validation: 0.4209266270883059]
	TIME [epoch: 8.36 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3418070599074622		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.3418070599074622 | validation: 0.27291452912303116]
	TIME [epoch: 8.4 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28983447517318506		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.28983447517318506 | validation: 0.2618952173798362]
	TIME [epoch: 8.37 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3362339161035005		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.3362339161035005 | validation: 0.269828443714145]
	TIME [epoch: 8.36 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2954765616777292		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.2954765616777292 | validation: 0.35583287753794257]
	TIME [epoch: 8.37 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3303301157370117		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.3303301157370117 | validation: 0.4323763009532668]
	TIME [epoch: 8.39 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3454138823648017		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.3454138823648017 | validation: 0.4337114621842502]
	TIME [epoch: 8.37 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31025094594609015		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.31025094594609015 | validation: 0.26563998565491187]
	TIME [epoch: 8.37 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28792034071905503		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.28792034071905503 | validation: 0.519418207876538]
	TIME [epoch: 8.38 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32063999766877554		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.32063999766877554 | validation: 0.3588607320712798]
	TIME [epoch: 8.37 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2884756596597088		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.2884756596597088 | validation: 0.27277792354145314]
	TIME [epoch: 8.36 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30346380687186997		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.30346380687186997 | validation: 0.33737521429744777]
	TIME [epoch: 8.37 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3508949048548082		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.3508949048548082 | validation: 0.34380563185357127]
	TIME [epoch: 8.39 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3511551419199238		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.3511551419199238 | validation: 0.261697931009108]
	TIME [epoch: 8.37 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3725623141964352		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.3725623141964352 | validation: 0.2979179490248234]
	TIME [epoch: 8.36 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36428773739919684		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.36428773739919684 | validation: 0.6005297357218177]
	TIME [epoch: 8.36 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29630985356899614		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.29630985356899614 | validation: 0.43189971025218427]
	TIME [epoch: 8.4 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32128476413803836		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.32128476413803836 | validation: 0.5695516191581915]
	TIME [epoch: 8.37 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40510043535844015		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.40510043535844015 | validation: 0.34971375701392315]
	TIME [epoch: 8.36 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35904123236077873		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.35904123236077873 | validation: 0.3256272621640308]
	TIME [epoch: 8.39 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.300728139286969		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.300728139286969 | validation: 0.20274325346998312]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_352.pth
	Model improved!!!
EPOCH 353/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27728114884218147		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.27728114884218147 | validation: 0.38964052369325164]
	TIME [epoch: 8.37 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2618513131538734		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.2618513131538734 | validation: 0.39106125522496316]
	TIME [epoch: 8.36 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2979566365643066		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.2979566365643066 | validation: 0.3275610316365255]
	TIME [epoch: 8.39 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30619374525834014		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.30619374525834014 | validation: 0.24392746769183854]
	TIME [epoch: 8.37 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2850011549553955		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.2850011549553955 | validation: 0.2878980847194408]
	TIME [epoch: 8.36 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3162734930012902		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.3162734930012902 | validation: 0.3018685274036505]
	TIME [epoch: 8.36 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31574796067378896		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.31574796067378896 | validation: 0.2584367679282169]
	TIME [epoch: 8.39 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3098662425695864		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.3098662425695864 | validation: 0.2613383051651632]
	TIME [epoch: 8.36 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27643009274941904		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.27643009274941904 | validation: 0.22658788853307965]
	TIME [epoch: 8.37 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27321546133080077		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.27321546133080077 | validation: 0.20147430082763146]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_362.pth
	Model improved!!!
EPOCH 363/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34994504978307417		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.34994504978307417 | validation: 0.3923759080220077]
	TIME [epoch: 8.37 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3056075261533791		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.3056075261533791 | validation: 0.4142923858144445]
	TIME [epoch: 8.36 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28719403882068106		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.28719403882068106 | validation: 0.3125351981657623]
	TIME [epoch: 8.36 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31227656689425803		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.31227656689425803 | validation: 0.19935327223702132]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_366.pth
	Model improved!!!
EPOCH 367/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2525773000971062		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.2525773000971062 | validation: 0.30456791393978305]
	TIME [epoch: 8.37 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24626722599999348		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.24626722599999348 | validation: 0.22487632332026877]
	TIME [epoch: 8.37 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3582408980927362		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.3582408980927362 | validation: 0.35658735938656116]
	TIME [epoch: 8.36 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37807317714822575		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.37807317714822575 | validation: 0.21262652597195353]
	TIME [epoch: 8.38 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2830248028445313		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.2830248028445313 | validation: 0.23154941039524413]
	TIME [epoch: 8.38 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23840040227958842		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.23840040227958842 | validation: 0.3020072303644358]
	TIME [epoch: 8.36 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27023204623732544		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.27023204623732544 | validation: 0.3083882606385364]
	TIME [epoch: 8.37 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3028320174466281		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.3028320174466281 | validation: 0.25643372460398245]
	TIME [epoch: 8.38 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29075240456786006		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.29075240456786006 | validation: 0.4208567244959811]
	TIME [epoch: 8.36 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2471267515818118		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.2471267515818118 | validation: 0.24366252808505995]
	TIME [epoch: 8.36 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45427606730557857		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.45427606730557857 | validation: 0.18414984606266577]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_377.pth
	Model improved!!!
EPOCH 378/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2600533205871807		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.2600533205871807 | validation: 0.22155001126655136]
	TIME [epoch: 8.38 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3323487233506027		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.3323487233506027 | validation: 0.26348476649677177]
	TIME [epoch: 8.36 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2794979495826697		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.2794979495826697 | validation: 0.2942192714587647]
	TIME [epoch: 8.37 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26522062812079306		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.26522062812079306 | validation: 0.25113890419907986]
	TIME [epoch: 8.38 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2243717545343728		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.2243717545343728 | validation: 0.3612416065012988]
	TIME [epoch: 8.37 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26414385307866345		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.26414385307866345 | validation: 0.2710162155983834]
	TIME [epoch: 8.37 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24853009757946726		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.24853009757946726 | validation: 0.30071851972861674]
	TIME [epoch: 8.37 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3142280146631743		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.3142280146631743 | validation: 0.28057877495203065]
	TIME [epoch: 8.39 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27003879665835473		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.27003879665835473 | validation: 0.49356775041298523]
	TIME [epoch: 8.36 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30074879946126115		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.30074879946126115 | validation: 0.27009881536214053]
	TIME [epoch: 8.36 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22212989830628463		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.22212989830628463 | validation: 0.26807017076984324]
	TIME [epoch: 8.37 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24962883120678353		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.24962883120678353 | validation: 0.45871863758304]
	TIME [epoch: 8.38 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2722334521809687		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.2722334521809687 | validation: 0.24040052965710987]
	TIME [epoch: 8.37 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23389768043050765		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.23389768043050765 | validation: 0.3420218846541372]
	TIME [epoch: 8.36 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24719197049658437		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.24719197049658437 | validation: 0.2588658109412455]
	TIME [epoch: 8.39 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28480117436869085		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.28480117436869085 | validation: 0.33234028653074343]
	TIME [epoch: 8.37 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25192912166447945		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.25192912166447945 | validation: 0.33075081369248505]
	TIME [epoch: 8.36 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21064259491539672		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.21064259491539672 | validation: 0.1841817796200011]
	TIME [epoch: 8.36 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2000241746241783		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.2000241746241783 | validation: 0.3417555255931234]
	TIME [epoch: 8.39 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23745058634644756		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.23745058634644756 | validation: 0.18297204389979282]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_397.pth
	Model improved!!!
EPOCH 398/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23391193292813015		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.23391193292813015 | validation: 0.25571108910223134]
	TIME [epoch: 8.37 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24385991525690048		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.24385991525690048 | validation: 0.4210973151213885]
	TIME [epoch: 8.38 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28471527769160376		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.28471527769160376 | validation: 0.22442868140120786]
	TIME [epoch: 8.37 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2495620426023101		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.2495620426023101 | validation: 0.29963533367714146]
	TIME [epoch: 8.36 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23729908223614865		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.23729908223614865 | validation: 0.33814078275759785]
	TIME [epoch: 8.36 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2702821771766863		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.2702821771766863 | validation: 0.25366089554338106]
	TIME [epoch: 8.38 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24456307890572426		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.24456307890572426 | validation: 0.2429954418366844]
	TIME [epoch: 8.37 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2959396377277744		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.2959396377277744 | validation: 0.27732865662747175]
	TIME [epoch: 8.36 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24024798146319867		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.24024798146319867 | validation: 0.3196462224958143]
	TIME [epoch: 8.36 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21118421939978527		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.21118421939978527 | validation: 0.24558312736285837]
	TIME [epoch: 8.39 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20395569434460792		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.20395569434460792 | validation: 0.33056316191605994]
	TIME [epoch: 8.36 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24483922982334305		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.24483922982334305 | validation: 0.24538189552033085]
	TIME [epoch: 8.37 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2931584854981032		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.2931584854981032 | validation: 0.6733136809152468]
	TIME [epoch: 8.36 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3177863963771692		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.3177863963771692 | validation: 0.2635301521379275]
	TIME [epoch: 8.38 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2090554497989245		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.2090554497989245 | validation: 0.17408107226395597]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_412.pth
	Model improved!!!
EPOCH 413/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2459520070757381		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.2459520070757381 | validation: 0.22057515331632477]
	TIME [epoch: 8.36 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2285329406204178		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.2285329406204178 | validation: 0.22023080956024504]
	TIME [epoch: 8.38 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2832890621107154		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.2832890621107154 | validation: 0.269325029601307]
	TIME [epoch: 8.36 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2540295565727896		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.2540295565727896 | validation: 0.2282455717104116]
	TIME [epoch: 8.37 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40320205652199415		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.40320205652199415 | validation: 0.2918379828817669]
	TIME [epoch: 8.36 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21662284235561263		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.21662284235561263 | validation: 0.20632721764960293]
	TIME [epoch: 8.39 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2250140591311464		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.2250140591311464 | validation: 0.17384908290448564]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_419.pth
	Model improved!!!
EPOCH 420/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19039409719064496		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.19039409719064496 | validation: 0.18613868350620927]
	TIME [epoch: 8.37 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23120284064051533		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.23120284064051533 | validation: 0.2769053877071067]
	TIME [epoch: 8.37 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3377206985520945		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.3377206985520945 | validation: 0.2545582983376905]
	TIME [epoch: 8.38 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2524656992213379		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.2524656992213379 | validation: 0.32636732564685483]
	TIME [epoch: 8.37 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2208471134968016		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.2208471134968016 | validation: 0.227063819334704]
	TIME [epoch: 8.36 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2772839109109963		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.2772839109109963 | validation: 0.21346281416928703]
	TIME [epoch: 8.38 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23860698259815455		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.23860698259815455 | validation: 0.3307343446488536]
	TIME [epoch: 8.38 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2875405484209898		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.2875405484209898 | validation: 0.25675295101756823]
	TIME [epoch: 8.36 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21526404329729015		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.21526404329729015 | validation: 0.22262009215613174]
	TIME [epoch: 8.36 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28046513736736234		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.28046513736736234 | validation: 0.2945210221891473]
	TIME [epoch: 8.39 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2698954398413089		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.2698954398413089 | validation: 0.23046976885049242]
	TIME [epoch: 8.37 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2704265589468895		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.2704265589468895 | validation: 0.2839686465543906]
	TIME [epoch: 8.36 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33360490532766746		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.33360490532766746 | validation: 0.25794814318315457]
	TIME [epoch: 8.37 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2616489935627496		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.2616489935627496 | validation: 0.4303139727918624]
	TIME [epoch: 8.39 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2537453802044676		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.2537453802044676 | validation: 0.3189267064132854]
	TIME [epoch: 8.36 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24147481443752855		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.24147481443752855 | validation: 0.3545751555273898]
	TIME [epoch: 8.36 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25561636083626177		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.25561636083626177 | validation: 0.22838914107258826]
	TIME [epoch: 8.38 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2145064914874133		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.2145064914874133 | validation: 0.3935559490161429]
	TIME [epoch: 8.38 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31716853820735263		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.31716853820735263 | validation: 0.26423823682236025]
	TIME [epoch: 8.36 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28620677266157335		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.28620677266157335 | validation: 0.22568581503931437]
	TIME [epoch: 8.36 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23501629482703806		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.23501629482703806 | validation: 0.20607027159221042]
	TIME [epoch: 8.39 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2348684333692772		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.2348684333692772 | validation: 0.28915778886570487]
	TIME [epoch: 8.37 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2156107429327648		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.2156107429327648 | validation: 0.21671235698698954]
	TIME [epoch: 8.37 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21912123289164823		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.21912123289164823 | validation: 0.24482808873522677]
	TIME [epoch: 8.37 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23365946918375688		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.23365946918375688 | validation: 0.25359536793453763]
	TIME [epoch: 8.39 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28009239289645044		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.28009239289645044 | validation: 0.22861083112992137]
	TIME [epoch: 8.37 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24864338098140365		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.24864338098140365 | validation: 0.22390823901617973]
	TIME [epoch: 8.36 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22944550590420318		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.22944550590420318 | validation: 0.2893624194774206]
	TIME [epoch: 8.38 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20742632834572405		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.20742632834572405 | validation: 0.22103521385625657]
	TIME [epoch: 8.36 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21713215773244315		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.21713215773244315 | validation: 0.20688736797244378]
	TIME [epoch: 8.37 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2342215188001468		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.2342215188001468 | validation: 0.18260028712408305]
	TIME [epoch: 8.35 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22269206379202727		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.22269206379202727 | validation: 0.27284109414738733]
	TIME [epoch: 8.38 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.230386233807757		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.230386233807757 | validation: 0.25029789223986354]
	TIME [epoch: 8.36 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23954651608574862		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.23954651608574862 | validation: 0.21419606248030712]
	TIME [epoch: 8.36 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18848055705624842		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.18848055705624842 | validation: 0.20819275806071824]
	TIME [epoch: 8.36 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21073472897152348		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.21073472897152348 | validation: 0.23122016225384448]
	TIME [epoch: 8.38 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18782595984139488		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.18782595984139488 | validation: 0.25922273143190405]
	TIME [epoch: 8.37 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21597991675195582		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.21597991675195582 | validation: 0.2674764617352827]
	TIME [epoch: 8.36 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21644401156962542		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.21644401156962542 | validation: 0.21697849095824362]
	TIME [epoch: 8.38 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22263657265911285		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.22263657265911285 | validation: 0.16821604761569148]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_459.pth
	Model improved!!!
EPOCH 460/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22033505904636447		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.22033505904636447 | validation: 0.18541180276242317]
	TIME [epoch: 8.37 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18795092220648202		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.18795092220648202 | validation: 0.1732773675662938]
	TIME [epoch: 8.36 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19511859592289488		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.19511859592289488 | validation: 0.17965435076823674]
	TIME [epoch: 8.38 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23242911700096505		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.23242911700096505 | validation: 0.18734417207088322]
	TIME [epoch: 8.37 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22478756448939122		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.22478756448939122 | validation: 0.20267400380048248]
	TIME [epoch: 8.36 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19881314565357372		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.19881314565357372 | validation: 0.20138126545031237]
	TIME [epoch: 8.36 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20778975204881264		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.20778975204881264 | validation: 0.19570581384875083]
	TIME [epoch: 8.39 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24374812409603827		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.24374812409603827 | validation: 0.19246845520397143]
	TIME [epoch: 8.37 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19178966039636727		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.19178966039636727 | validation: 0.2273985000222497]
	TIME [epoch: 8.36 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20942245642831234		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.20942245642831234 | validation: 0.2768303615813784]
	TIME [epoch: 8.38 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2396009999364556		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.2396009999364556 | validation: 0.24491007591810074]
	TIME [epoch: 8.38 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19814609356062668		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.19814609356062668 | validation: 0.18308124608194776]
	TIME [epoch: 8.36 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20430327831017725		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.20430327831017725 | validation: 0.1842303592526276]
	TIME [epoch: 8.36 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22244835370548097		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.22244835370548097 | validation: 0.2469768183949827]
	TIME [epoch: 8.37 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2542825169966093		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.2542825169966093 | validation: 0.20474362036296434]
	TIME [epoch: 8.38 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22467302306050416		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.22467302306050416 | validation: 0.1719888272777906]
	TIME [epoch: 8.36 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1993220098889404		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.1993220098889404 | validation: 0.20311155214348087]
	TIME [epoch: 8.36 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22065101562545789		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.22065101562545789 | validation: 0.24901989709954003]
	TIME [epoch: 8.38 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22504168896486285		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.22504168896486285 | validation: 0.2280240020220946]
	TIME [epoch: 8.36 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22739953242310396		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.22739953242310396 | validation: 0.2817776457329485]
	TIME [epoch: 8.36 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21150651711739638		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.21150651711739638 | validation: 0.19428815079231224]
	TIME [epoch: 8.36 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19881111715411828		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.19881111715411828 | validation: 0.21344307904649357]
	TIME [epoch: 8.38 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22258945955646495		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.22258945955646495 | validation: 0.18116661532444545]
	TIME [epoch: 8.36 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17938224689133442		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.17938224689133442 | validation: 0.24574287885066695]
	TIME [epoch: 8.36 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17867719724652956		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.17867719724652956 | validation: 0.20589987073486868]
	TIME [epoch: 8.38 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17122964865900375		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.17122964865900375 | validation: 0.22500109003808616]
	TIME [epoch: 8.38 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2213651829191888		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.2213651829191888 | validation: 0.24754920987107198]
	TIME [epoch: 8.36 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17995286928031054		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.17995286928031054 | validation: 0.25396896463950996]
	TIME [epoch: 8.37 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20486116047973074		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.20486116047973074 | validation: 0.18193007206727585]
	TIME [epoch: 8.38 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21795397722177906		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.21795397722177906 | validation: 0.2345688469050899]
	TIME [epoch: 8.36 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18210796212500976		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.18210796212500976 | validation: 0.26422142957424977]
	TIME [epoch: 8.36 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18734542942953564		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.18734542942953564 | validation: 0.32692182151944155]
	TIME [epoch: 8.37 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2646634919937767		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.2646634919937767 | validation: 0.2527683541846759]
	TIME [epoch: 8.38 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.207564214907677		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.207564214907677 | validation: 0.16501916110205783]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_493.pth
	Model improved!!!
EPOCH 494/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1915793393622474		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.1915793393622474 | validation: 0.19674398392994025]
	TIME [epoch: 8.38 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1871081150915302		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.1871081150915302 | validation: 0.2723618031143917]
	TIME [epoch: 8.4 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20944611687087966		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.20944611687087966 | validation: 0.22579098813663845]
	TIME [epoch: 8.37 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2053032882012479		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.2053032882012479 | validation: 0.1582220167743334]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_497.pth
	Model improved!!!
EPOCH 498/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18544819475569696		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.18544819475569696 | validation: 0.16743046726424227]
	TIME [epoch: 8.38 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20536285800111434		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.20536285800111434 | validation: 0.18303153268223044]
	TIME [epoch: 8.39 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18286410172713488		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.18286410172713488 | validation: 0.28911483251465375]
	TIME [epoch: 8.37 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20387740431868143		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.20387740431868143 | validation: 0.22181121791428848]
	TIME [epoch: 8.37 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19596341628437078		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.19596341628437078 | validation: 0.20227913141044396]
	TIME [epoch: 8.37 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1838559433103896		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.1838559433103896 | validation: 0.15114819527895595]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_503.pth
	Model improved!!!
EPOCH 504/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19052892559098045		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.19052892559098045 | validation: 0.22137637743453592]
	TIME [epoch: 8.37 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1946431774549886		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.1946431774549886 | validation: 0.4270557497457682]
	TIME [epoch: 8.37 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22533095798616629		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.22533095798616629 | validation: 0.25175187590500586]
	TIME [epoch: 8.37 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19985556400336907		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.19985556400336907 | validation: 0.16845093247646353]
	TIME [epoch: 8.39 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16376899736397882		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.16376899736397882 | validation: 0.2778500668237792]
	TIME [epoch: 8.37 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20951983299999352		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.20951983299999352 | validation: 0.16801422984177838]
	TIME [epoch: 8.38 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19020323120688545		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.19020323120688545 | validation: 0.1557531939217166]
	TIME [epoch: 8.36 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17116557516362613		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.17116557516362613 | validation: 0.2317165958400817]
	TIME [epoch: 8.39 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21525591680055745		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.21525591680055745 | validation: 0.21732126506182303]
	TIME [epoch: 8.36 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24019362016609608		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.24019362016609608 | validation: 0.19955049915592737]
	TIME [epoch: 8.37 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1976767868855942		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.1976767868855942 | validation: 0.3263667499072337]
	TIME [epoch: 8.37 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19206401926843591		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.19206401926843591 | validation: 0.17584588238046817]
	TIME [epoch: 8.4 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16719259873660502		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.16719259873660502 | validation: 0.26673187873700444]
	TIME [epoch: 8.37 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2098691373005528		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.2098691373005528 | validation: 0.1930522320768463]
	TIME [epoch: 8.37 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18583916773760206		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.18583916773760206 | validation: 0.30780459882841305]
	TIME [epoch: 8.38 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2172855573235189		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.2172855573235189 | validation: 0.29235200066864253]
	TIME [epoch: 8.38 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2143817900704618		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.2143817900704618 | validation: 0.22966697524813173]
	TIME [epoch: 8.37 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2316727303519039		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.2316727303519039 | validation: 0.2467416923731891]
	TIME [epoch: 8.37 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1728075127795142		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.1728075127795142 | validation: 0.18203103650289623]
	TIME [epoch: 8.39 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2060197452590677		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.2060197452590677 | validation: 0.21133038143662708]
	TIME [epoch: 8.37 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1771759054208339		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.1771759054208339 | validation: 0.16159565629056105]
	TIME [epoch: 8.37 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18364547789060517		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.18364547789060517 | validation: 0.21222097709940285]
	TIME [epoch: 8.37 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19105840136797358		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.19105840136797358 | validation: 0.2113792809466047]
	TIME [epoch: 8.4 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15808871093509907		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.15808871093509907 | validation: 0.2729739300486368]
	TIME [epoch: 8.37 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18991726294958317		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.18991726294958317 | validation: 0.23461867418592525]
	TIME [epoch: 8.37 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23415759229026983		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.23415759229026983 | validation: 0.19387767804424322]
	TIME [epoch: 8.39 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20522873020368423		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.20522873020368423 | validation: 0.20612324061813464]
	TIME [epoch: 8.38 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1906685258138998		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.1906685258138998 | validation: 0.19708092537079225]
	TIME [epoch: 8.37 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2018966244040345		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.2018966244040345 | validation: 0.254136953211053]
	TIME [epoch: 8.36 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19112383680400158		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.19112383680400158 | validation: 0.1875169913985348]
	TIME [epoch: 8.4 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1981733441068732		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.1981733441068732 | validation: 0.16561267002988106]
	TIME [epoch: 8.37 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1665931597915578		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.1665931597915578 | validation: 0.21917910011922587]
	TIME [epoch: 8.36 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.177817404226249		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.177817404226249 | validation: 0.25588650709540306]
	TIME [epoch: 8.38 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1843799114347945		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.1843799114347945 | validation: 0.21843247010061073]
	TIME [epoch: 8.38 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19657691617485046		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.19657691617485046 | validation: 0.35676263912534845]
	TIME [epoch: 8.36 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18318782004506		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.18318782004506 | validation: 0.18263681392156034]
	TIME [epoch: 8.37 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1663788788226365		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.1663788788226365 | validation: 0.188876373186535]
	TIME [epoch: 8.39 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16997016387481634		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.16997016387481634 | validation: 0.23306216003918967]
	TIME [epoch: 8.38 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16593998981340524		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.16593998981340524 | validation: 0.19027812924053267]
	TIME [epoch: 8.37 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15255180247252173		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.15255180247252173 | validation: 0.19411643144638652]
	TIME [epoch: 8.37 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20016308355735674		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.20016308355735674 | validation: 0.16383362573460697]
	TIME [epoch: 8.39 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15409366749764586		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.15409366749764586 | validation: 0.19334526701408564]
	TIME [epoch: 8.37 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17519561647024462		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.17519561647024462 | validation: 0.21080400963137758]
	TIME [epoch: 8.37 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19396008271969561		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.19396008271969561 | validation: 0.17097030102123667]
	TIME [epoch: 8.39 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1418138448478025		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.1418138448478025 | validation: 0.16722303259635157]
	TIME [epoch: 8.38 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17399410871631343		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.17399410871631343 | validation: 0.18726346149464934]
	TIME [epoch: 8.36 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1728809912829046		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.1728809912829046 | validation: 0.2786565757948794]
	TIME [epoch: 8.36 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20928672912766025		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.20928672912766025 | validation: 0.1538091170989167]
	TIME [epoch: 8.39 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14911659591472773		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.14911659591472773 | validation: 0.2037240718810362]
	TIME [epoch: 8.37 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18205442162956031		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.18205442162956031 | validation: 0.16220780267507703]
	TIME [epoch: 8.36 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15666922579467019		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.15666922579467019 | validation: 0.19272107869259444]
	TIME [epoch: 8.38 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1922114960831635		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.1922114960831635 | validation: 0.17234706635835742]
	TIME [epoch: 8.37 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14777987348474522		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.14777987348474522 | validation: 0.14586220687848753]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_556.pth
	Model improved!!!
EPOCH 557/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.155677502068126		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.155677502068126 | validation: 0.1758295722909169]
	TIME [epoch: 8.36 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16938318211529435		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.16938318211529435 | validation: 0.17567211759770995]
	TIME [epoch: 8.39 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17155292872465275		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.17155292872465275 | validation: 0.1793931415828905]
	TIME [epoch: 8.37 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19997859050285613		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.19997859050285613 | validation: 0.2936103767323056]
	TIME [epoch: 8.36 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1921046186329564		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.1921046186329564 | validation: 0.21013534486804225]
	TIME [epoch: 8.37 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18294254557212675		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.18294254557212675 | validation: 0.20307702284923895]
	TIME [epoch: 8.39 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1763043469361279		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.1763043469361279 | validation: 0.1947166082345116]
	TIME [epoch: 8.37 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17985910910340047		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.17985910910340047 | validation: 0.21902920341253052]
	TIME [epoch: 8.36 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18776542954006575		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.18776542954006575 | validation: 0.2210288722157369]
	TIME [epoch: 8.36 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1798969798826498		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.1798969798826498 | validation: 0.22604516663229512]
	TIME [epoch: 8.39 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19568948157974578		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.19568948157974578 | validation: 0.18119033485410996]
	TIME [epoch: 8.37 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19106814397996527		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.19106814397996527 | validation: 0.2195404759168087]
	TIME [epoch: 8.36 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20598533550012		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.20598533550012 | validation: 0.18979931894500013]
	TIME [epoch: 8.39 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16318412675552316		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.16318412675552316 | validation: 0.1805577645669991]
	TIME [epoch: 8.37 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16450779603947918		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.16450779603947918 | validation: 0.1836873928350008]
	TIME [epoch: 8.37 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15460900947692985		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.15460900947692985 | validation: 0.20983391677483623]
	TIME [epoch: 8.36 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16624248046272644		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.16624248046272644 | validation: 0.14421049484339032]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_573.pth
	Model improved!!!
EPOCH 574/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17002726024664933		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.17002726024664933 | validation: 0.21432376605434011]
	TIME [epoch: 8.37 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1611928582429548		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.1611928582429548 | validation: 0.18128382509099902]
	TIME [epoch: 8.37 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18357882091188363		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.18357882091188363 | validation: 0.1689226705189268]
	TIME [epoch: 8.36 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17833653077954184		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.17833653077954184 | validation: 0.20155286159137292]
	TIME [epoch: 8.39 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16785568006905277		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.16785568006905277 | validation: 0.16637610725720178]
	TIME [epoch: 8.37 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1653178759151372		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.1653178759151372 | validation: 0.18466451717205393]
	TIME [epoch: 8.36 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1656127550275355		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.1656127550275355 | validation: 0.18585078230205293]
	TIME [epoch: 8.37 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14606700841180648		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.14606700841180648 | validation: 0.16937721966191643]
	TIME [epoch: 8.39 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15198701925024571		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.15198701925024571 | validation: 0.16824679191775815]
	TIME [epoch: 8.37 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.139662443950187		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.139662443950187 | validation: 0.14022901223955303]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_583.pth
	Model improved!!!
EPOCH 584/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14248766319010042		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.14248766319010042 | validation: 0.1808830824414993]
	TIME [epoch: 8.4 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15504498846107673		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.15504498846107673 | validation: 0.20209801110302633]
	TIME [epoch: 8.38 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1596541348109857		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.1596541348109857 | validation: 0.18014996606098949]
	TIME [epoch: 8.37 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15558591477522818		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.15558591477522818 | validation: 0.14715130467041482]
	TIME [epoch: 8.37 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15126732937829346		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.15126732937829346 | validation: 0.13317304593797202]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_588.pth
	Model improved!!!
EPOCH 589/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14973458427347278		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.14973458427347278 | validation: 0.21169624103195983]
	TIME [epoch: 8.37 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1837277073943251		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.1837277073943251 | validation: 0.1593430922416512]
	TIME [epoch: 8.37 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13957286524778853		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.13957286524778853 | validation: 0.15767916835166812]
	TIME [epoch: 8.37 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1567938599685511		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.1567938599685511 | validation: 0.14576914840327554]
	TIME [epoch: 8.39 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15743717804813356		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.15743717804813356 | validation: 0.17069235265392868]
	TIME [epoch: 8.37 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15322246593204153		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.15322246593204153 | validation: 0.1619268219841617]
	TIME [epoch: 8.37 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13299427238196826		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.13299427238196826 | validation: 0.1681602898072735]
	TIME [epoch: 8.37 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14504399750322167		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.14504399750322167 | validation: 0.15614721419416197]
	TIME [epoch: 8.4 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15973774000632518		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.15973774000632518 | validation: 0.15545709913421257]
	TIME [epoch: 8.37 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13190500654219733		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.13190500654219733 | validation: 0.1785485752444404]
	TIME [epoch: 8.37 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1562881019275329		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.1562881019275329 | validation: 0.17769967793230002]
	TIME [epoch: 8.37 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17124756589908952		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.17124756589908952 | validation: 0.184887816822918]
	TIME [epoch: 8.4 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1634899333988294		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.1634899333988294 | validation: 0.2781410749102713]
	TIME [epoch: 8.37 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1892843385306463		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.1892843385306463 | validation: 0.14408822382851355]
	TIME [epoch: 8.37 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15386454375832037		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.15386454375832037 | validation: 0.16399053657693688]
	TIME [epoch: 8.39 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14739321724862503		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.14739321724862503 | validation: 0.14517113185028163]
	TIME [epoch: 8.38 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15838018434359852		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.15838018434359852 | validation: 0.18498918299193562]
	TIME [epoch: 8.37 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14574553257491438		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.14574553257491438 | validation: 0.14255343426876757]
	TIME [epoch: 8.37 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1362926773888183		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.1362926773888183 | validation: 0.15443236103898264]
	TIME [epoch: 8.39 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17060781154821741		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.17060781154821741 | validation: 0.22473427068140236]
	TIME [epoch: 8.38 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14734030417009042		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.14734030417009042 | validation: 0.16443335894954092]
	TIME [epoch: 8.37 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20190348646774736		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.20190348646774736 | validation: 0.21533542115690668]
	TIME [epoch: 8.38 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1666262726022345		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.1666262726022345 | validation: 0.14449743149735353]
	TIME [epoch: 8.38 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16645920258976474		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.16645920258976474 | validation: 0.16976023341508356]
	TIME [epoch: 8.37 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17398864232520095		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.17398864232520095 | validation: 0.14534995715365495]
	TIME [epoch: 8.37 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14795491091952911		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.14795491091952911 | validation: 0.1867675892557022]
	TIME [epoch: 8.39 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14663628769939663		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.14663628769939663 | validation: 0.19513885729080976]
	TIME [epoch: 8.37 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13789275246728214		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.13789275246728214 | validation: 0.14839724538692123]
	TIME [epoch: 8.37 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13103103718717643		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.13103103718717643 | validation: 0.19091907307468134]
	TIME [epoch: 8.37 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15065115226324205		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.15065115226324205 | validation: 0.12832663363448463]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_618.pth
	Model improved!!!
EPOCH 619/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15132047354886943		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.15132047354886943 | validation: 0.17935812487373182]
	TIME [epoch: 8.37 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1512323355538913		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.1512323355538913 | validation: 0.15578069893196955]
	TIME [epoch: 8.36 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16060441281978588		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.16060441281978588 | validation: 0.25644211136738215]
	TIME [epoch: 8.38 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13347122742029321		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.13347122742029321 | validation: 0.12801636136845154]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_622.pth
	Model improved!!!
EPOCH 623/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1285694692212375		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.1285694692212375 | validation: 0.1377828910095551]
	TIME [epoch: 8.38 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16575786897114037		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.16575786897114037 | validation: 0.1482923809673197]
	TIME [epoch: 8.37 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1452625977896334		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.1452625977896334 | validation: 0.1370579700497836]
	TIME [epoch: 8.4 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14494817797653817		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.14494817797653817 | validation: 0.14825558836651345]
	TIME [epoch: 8.37 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18186694734115713		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.18186694734115713 | validation: 0.17819778402636435]
	TIME [epoch: 8.37 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15017742051282018		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.15017742051282018 | validation: 0.18027056433472397]
	TIME [epoch: 8.36 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13518492707386914		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.13518492707386914 | validation: 0.1412270494463364]
	TIME [epoch: 8.39 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.132167989375721		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.132167989375721 | validation: 0.15616501355889387]
	TIME [epoch: 8.37 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14938163887320127		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.14938163887320127 | validation: 0.16169817671487016]
	TIME [epoch: 8.37 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14596255167773725		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.14596255167773725 | validation: 0.13233344024335303]
	TIME [epoch: 8.36 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13817216212951253		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.13817216212951253 | validation: 0.16314396721217872]
	TIME [epoch: 8.39 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13465028970493048		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.13465028970493048 | validation: 0.15772755890879106]
	TIME [epoch: 8.37 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1527598614742311		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.1527598614742311 | validation: 0.13994739547615986]
	TIME [epoch: 8.36 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13085631134411954		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.13085631134411954 | validation: 0.1583433369125502]
	TIME [epoch: 8.38 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14918492073243458		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.14918492073243458 | validation: 0.15726489860479917]
	TIME [epoch: 8.37 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15832575490612583		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.15832575490612583 | validation: 0.17478162321547003]
	TIME [epoch: 8.37 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17080823634350348		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.17080823634350348 | validation: 0.15810200861119106]
	TIME [epoch: 8.36 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16536136997519585		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.16536136997519585 | validation: 0.2087648391835008]
	TIME [epoch: 8.39 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1404029020724437		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.1404029020724437 | validation: 0.174557297407223]
	TIME [epoch: 8.37 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1625415437488016		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.1625415437488016 | validation: 0.14758378047087511]
	TIME [epoch: 8.36 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1746096550399973		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.1746096550399973 | validation: 0.18932692161826797]
	TIME [epoch: 8.38 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15214403633456913		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.15214403633456913 | validation: 0.14908779592823893]
	TIME [epoch: 8.38 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14569571855221689		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.14569571855221689 | validation: 0.1345171880776149]
	TIME [epoch: 8.37 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16659394270605776		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.16659394270605776 | validation: 0.1516232776263371]
	TIME [epoch: 8.36 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1505276524970856		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.1505276524970856 | validation: 0.1680981138345602]
	TIME [epoch: 8.37 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1328276139426278		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.1328276139426278 | validation: 0.17371413380818387]
	TIME [epoch: 8.39 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13727304387840872		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.13727304387840872 | validation: 0.17684346370080622]
	TIME [epoch: 8.36 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1671885955652384		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.1671885955652384 | validation: 0.16138511573491374]
	TIME [epoch: 8.36 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14889302127889742		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.14889302127889742 | validation: 0.1507546011836179]
	TIME [epoch: 8.39 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14348792045683745		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.14348792045683745 | validation: 0.16685820189649492]
	TIME [epoch: 8.37 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13884725991285846		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.13884725991285846 | validation: 0.15613000963686843]
	TIME [epoch: 8.37 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13870484700039354		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.13870484700039354 | validation: 0.21416832390099053]
	TIME [epoch: 8.37 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19152967565013101		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.19152967565013101 | validation: 0.17040217709953245]
	TIME [epoch: 8.39 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12743831660808477		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.12743831660808477 | validation: 0.1801704131046143]
	TIME [epoch: 8.36 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14639795910966652		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.14639795910966652 | validation: 0.18281955540175132]
	TIME [epoch: 8.36 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14962188969257265		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.14962188969257265 | validation: 0.171231111171814]
	TIME [epoch: 8.38 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14252490068731985		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.14252490068731985 | validation: 0.14268964627353814]
	TIME [epoch: 8.37 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16227702212316492		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.16227702212316492 | validation: 0.14432432406648407]
	TIME [epoch: 8.36 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17047960327470738		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.17047960327470738 | validation: 0.33739187341488086]
	TIME [epoch: 8.37 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16650073395081028		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.16650073395081028 | validation: 0.16138960953947615]
	TIME [epoch: 8.38 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1728276906076804		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.1728276906076804 | validation: 0.17352300921062552]
	TIME [epoch: 8.37 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1720628456960384		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.1720628456960384 | validation: 0.26451006522555054]
	TIME [epoch: 8.36 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16804280021109336		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.16804280021109336 | validation: 0.1488303190352633]
	TIME [epoch: 8.37 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13119524511901218		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.13119524511901218 | validation: 0.15066732102355493]
	TIME [epoch: 8.38 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12597667876088053		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.12597667876088053 | validation: 0.12804823608706328]
	TIME [epoch: 8.36 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13420579251189738		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.13420579251189738 | validation: 0.15088002478040616]
	TIME [epoch: 8.36 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1372127021943697		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.1372127021943697 | validation: 0.14411470016515981]
	TIME [epoch: 8.39 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1281883846658267		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.1281883846658267 | validation: 0.16541581967011826]
	TIME [epoch: 8.37 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12829226768438726		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.12829226768438726 | validation: 0.14409794496851033]
	TIME [epoch: 8.36 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15315518693521882		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.15315518693521882 | validation: 0.18600127889981452]
	TIME [epoch: 8.36 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13051757897849786		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.13051757897849786 | validation: 0.17258687488891267]
	TIME [epoch: 8.39 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1285042952059962		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.1285042952059962 | validation: 0.13560519681605024]
	TIME [epoch: 8.37 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1162797080764695		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.1162797080764695 | validation: 0.1333889149428276]
	TIME [epoch: 8.36 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13053922988519018		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.13053922988519018 | validation: 0.16465409352304222]
	TIME [epoch: 8.38 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12516008957383767		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.12516008957383767 | validation: 0.13062005937898183]
	TIME [epoch: 8.37 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12358025549659171		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.12358025549659171 | validation: 0.135464351766016]
	TIME [epoch: 8.36 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1339876905256518		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.1339876905256518 | validation: 0.16747249154552188]
	TIME [epoch: 8.36 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1355413612250465		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.1355413612250465 | validation: 0.15313836041474438]
	TIME [epoch: 8.38 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13561191885690366		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.13561191885690366 | validation: 0.1363916668586234]
	TIME [epoch: 8.36 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13934108204569182		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.13934108204569182 | validation: 0.14766044885981836]
	TIME [epoch: 8.36 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1385604930350339		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.1385604930350339 | validation: 0.1694765636370791]
	TIME [epoch: 8.37 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1501613206137234		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.1501613206137234 | validation: 0.15968519116540725]
	TIME [epoch: 8.38 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14744392213843047		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.14744392213843047 | validation: 0.15017121190872565]
	TIME [epoch: 8.37 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1401216760285961		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.1401216760285961 | validation: 0.22735508283877576]
	TIME [epoch: 8.35 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19321914298931347		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.19321914298931347 | validation: 0.1706017177989061]
	TIME [epoch: 8.39 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18596295497887072		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.18596295497887072 | validation: 0.17451573400944592]
	TIME [epoch: 8.37 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1715978616718178		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.1715978616718178 | validation: 0.17327787013479606]
	TIME [epoch: 8.36 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13936967356384738		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.13936967356384738 | validation: 0.1497572462711193]
	TIME [epoch: 8.36 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14615575742580805		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.14615575742580805 | validation: 0.13563639602344763]
	TIME [epoch: 8.38 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1367073177397639		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.1367073177397639 | validation: 0.13817115988422035]
	TIME [epoch: 8.36 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.125669511046883		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.125669511046883 | validation: 0.1592751690897953]
	TIME [epoch: 8.37 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1322761056442426		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.1322761056442426 | validation: 0.16510334556602946]
	TIME [epoch: 8.38 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12601973240089626		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.12601973240089626 | validation: 0.14989702927373952]
	TIME [epoch: 8.37 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13373854187410256		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.13373854187410256 | validation: 0.135771063421501]
	TIME [epoch: 8.36 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1195328830534634		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.1195328830534634 | validation: 0.13005149159063667]
	TIME [epoch: 8.36 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1250077779696528		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.1250077779696528 | validation: 0.14127487507771433]
	TIME [epoch: 8.39 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13289333164462241		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.13289333164462241 | validation: 0.12858748850842178]
	TIME [epoch: 8.36 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1484137270315839		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.1484137270315839 | validation: 0.13742899217926632]
	TIME [epoch: 8.36 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1322012377097063		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.1322012377097063 | validation: 0.14941858415043563]
	TIME [epoch: 8.36 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13255071801466095		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.13255071801466095 | validation: 0.14344689599573018]
	TIME [epoch: 8.39 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1280706029123468		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.1280706029123468 | validation: 0.14174872119731444]
	TIME [epoch: 8.36 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1289018675948182		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.1289018675948182 | validation: 0.1679734815552477]
	TIME [epoch: 8.37 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1576609604398069		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.1576609604398069 | validation: 0.1393486135733082]
	TIME [epoch: 8.39 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13921089349164764		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.13921089349164764 | validation: 0.15496999635784225]
	TIME [epoch: 8.36 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14898207156318985		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.14898207156318985 | validation: 0.14442630892343813]
	TIME [epoch: 8.37 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1317158614460203		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.1317158614460203 | validation: 0.138029686808609]
	TIME [epoch: 8.36 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13367727322814119		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.13367727322814119 | validation: 0.18008513088192268]
	TIME [epoch: 8.39 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13909283824152502		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.13909283824152502 | validation: 0.1866391962866693]
	TIME [epoch: 8.36 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1324694404032722		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.1324694404032722 | validation: 0.13583748040327842]
	TIME [epoch: 8.36 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11716087030626932		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.11716087030626932 | validation: 0.1331746311097324]
	TIME [epoch: 8.38 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12975565874624112		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.12975565874624112 | validation: 0.13075459769879924]
	TIME [epoch: 8.37 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11929001436150428		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.11929001436150428 | validation: 0.12789075932446733]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_714.pth
	Model improved!!!
EPOCH 715/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11856236578936026		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.11856236578936026 | validation: 0.1441240070624205]
	TIME [epoch: 8.37 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11826921488743762		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.11826921488743762 | validation: 0.15125414790965738]
	TIME [epoch: 8.4 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11464664470327243		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.11464664470327243 | validation: 0.1290164491823566]
	TIME [epoch: 8.36 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13500820164640331		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.13500820164640331 | validation: 0.12150080602962879]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_718.pth
	Model improved!!!
EPOCH 719/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12443763158457104		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.12443763158457104 | validation: 0.16723092654545874]
	TIME [epoch: 8.37 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1370817083356234		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.1370817083356234 | validation: 0.14439878945450452]
	TIME [epoch: 8.38 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12968055190339173		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.12968055190339173 | validation: 0.14797520690019217]
	TIME [epoch: 8.36 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12246238899281511		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.12246238899281511 | validation: 0.13422837242754398]
	TIME [epoch: 8.36 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12814646402425092		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.12814646402425092 | validation: 0.16143980827065638]
	TIME [epoch: 8.37 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13728887089098796		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.13728887089098796 | validation: 0.1275430617457789]
	TIME [epoch: 8.39 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11297732659308282		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.11297732659308282 | validation: 0.12414894066693424]
	TIME [epoch: 8.37 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12898385193509593		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.12898385193509593 | validation: 0.1379732755065231]
	TIME [epoch: 8.36 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13431896070225172		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.13431896070225172 | validation: 0.14024260170241384]
	TIME [epoch: 8.39 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12736460596598914		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.12736460596598914 | validation: 0.13265374260357418]
	TIME [epoch: 8.37 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11215750030085321		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.11215750030085321 | validation: 0.16015863612437004]
	TIME [epoch: 8.37 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1372696962465558		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.1372696962465558 | validation: 0.1376902051362286]
	TIME [epoch: 8.36 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11443428022780737		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.11443428022780737 | validation: 0.13325398353072052]
	TIME [epoch: 8.39 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11436011435499913		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.11436011435499913 | validation: 0.12858082765965648]
	TIME [epoch: 8.36 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10911468378355674		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.10911468378355674 | validation: 0.12882904391841193]
	TIME [epoch: 8.36 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14455260818350227		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.14455260818350227 | validation: 0.13780847048535846]
	TIME [epoch: 8.37 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11072747884293652		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.11072747884293652 | validation: 0.10477104943367668]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_735.pth
	Model improved!!!
EPOCH 736/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11145901304669026		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.11145901304669026 | validation: 0.1205849317923754]
	TIME [epoch: 8.37 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13970946844917273		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.13970946844917273 | validation: 0.1702961859225923]
	TIME [epoch: 8.36 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12150240022971733		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.12150240022971733 | validation: 0.12447318860418868]
	TIME [epoch: 8.37 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12022875382434069		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.12022875382434069 | validation: 0.12379159501393852]
	TIME [epoch: 8.36 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11799464003943794		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.11799464003943794 | validation: 0.14653055489451972]
	TIME [epoch: 8.36 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12654338576625124		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.12654338576625124 | validation: 0.11116961948518192]
	TIME [epoch: 8.36 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10970655199276862		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.10970655199276862 | validation: 0.12658668550720537]
	TIME [epoch: 8.38 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11708721407542293		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.11708721407542293 | validation: 0.13585517816050396]
	TIME [epoch: 8.37 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10677163670013971		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.10677163670013971 | validation: 0.14392926190279243]
	TIME [epoch: 8.36 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15752918923841408		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.15752918923841408 | validation: 0.15052480212297648]
	TIME [epoch: 8.36 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1622257001506166		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.1622257001506166 | validation: 0.16645500523382672]
	TIME [epoch: 8.38 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12739853986563615		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.12739853986563615 | validation: 0.1617215704875871]
	TIME [epoch: 8.36 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12561206737768638		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.12561206737768638 | validation: 0.12090634547111301]
	TIME [epoch: 8.36 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12211397140998075		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.12211397140998075 | validation: 0.13397929273578266]
	TIME [epoch: 8.38 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11321452882946637		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.11321452882946637 | validation: 0.1262939003520227]
	TIME [epoch: 8.36 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11747492341151636		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.11747492341151636 | validation: 0.12314190290240165]
	TIME [epoch: 8.36 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11263431375511654		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.11263431375511654 | validation: 0.13266739351440526]
	TIME [epoch: 8.36 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11084475481545424		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.11084475481545424 | validation: 0.13228305753146075]
	TIME [epoch: 8.38 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11435744927761775		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.11435744927761775 | validation: 0.15325979327578929]
	TIME [epoch: 8.37 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1216654065622611		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.1216654065622611 | validation: 0.1256558843061317]
	TIME [epoch: 8.36 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11246923967999034		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.11246923967999034 | validation: 0.13558946019882573]
	TIME [epoch: 8.36 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12426814788425226		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.12426814788425226 | validation: 0.15185190139584853]
	TIME [epoch: 8.39 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1234256234208061		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.1234256234208061 | validation: 0.1494030461328128]
	TIME [epoch: 8.36 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14243309037617657		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.14243309037617657 | validation: 0.14693141932159265]
	TIME [epoch: 8.36 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12123761922621487		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.12123761922621487 | validation: 0.14471639084617535]
	TIME [epoch: 8.38 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12658926638721213		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.12658926638721213 | validation: 0.13389729155704577]
	TIME [epoch: 8.37 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12013100519546863		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.12013100519546863 | validation: 0.12062404804388863]
	TIME [epoch: 8.36 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10794900667383907		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.10794900667383907 | validation: 0.12008241407731812]
	TIME [epoch: 8.37 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10983489822757933		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.10983489822757933 | validation: 0.1260172153878995]
	TIME [epoch: 8.39 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11825788669550845		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.11825788669550845 | validation: 0.13947708963431776]
	TIME [epoch: 8.36 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11491852307580283		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.11491852307580283 | validation: 0.13077332800920183]
	TIME [epoch: 8.36 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12745474393985004		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.12745474393985004 | validation: 0.12958946845855004]
	TIME [epoch: 8.39 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.127301074716567		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.127301074716567 | validation: 0.16467863391595905]
	TIME [epoch: 8.37 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1300705864997979		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.1300705864997979 | validation: 0.14742845167283994]
	TIME [epoch: 8.36 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1376104750099967		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.1376104750099967 | validation: 0.152416943203465]
	TIME [epoch: 8.36 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11760181189496428		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.11760181189496428 | validation: 0.13363052612484197]
	TIME [epoch: 8.37 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11089729130172857		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.11089729130172857 | validation: 0.14257489775337462]
	TIME [epoch: 8.37 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11830417519145475		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.11830417519145475 | validation: 0.12653250482856476]
	TIME [epoch: 8.37 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11101498563313614		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.11101498563313614 | validation: 0.11594299164498806]
	TIME [epoch: 8.36 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10900241993559559		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.10900241993559559 | validation: 0.12259323527046001]
	TIME [epoch: 8.38 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10671102801607601		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.10671102801607601 | validation: 0.11759777579427312]
	TIME [epoch: 8.37 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11331394288678369		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.11331394288678369 | validation: 0.20546911342948243]
	TIME [epoch: 8.36 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13640740210462096		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.13640740210462096 | validation: 0.18645466786088083]
	TIME [epoch: 8.36 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1139196755295369		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.1139196755295369 | validation: 0.11967254551589768]
	TIME [epoch: 8.39 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.108790184759099		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.108790184759099 | validation: 0.13422325549851752]
	TIME [epoch: 8.37 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11927481186699282		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.11927481186699282 | validation: 0.1204489962380755]
	TIME [epoch: 8.36 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13281683039212042		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.13281683039212042 | validation: 0.14171598972183963]
	TIME [epoch: 8.38 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11828649391534081		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.11828649391534081 | validation: 0.1552664689065779]
	TIME [epoch: 8.36 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12983445867782648		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.12983445867782648 | validation: 0.13454666296819767]
	TIME [epoch: 8.36 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1143878426737028		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.1143878426737028 | validation: 0.14295702052401354]
	TIME [epoch: 8.36 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12327140604111067		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.12327140604111067 | validation: 0.14010801074129697]
	TIME [epoch: 8.38 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1182578298745891		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.1182578298745891 | validation: 0.14316140551737203]
	TIME [epoch: 8.36 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11049857168915163		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.11049857168915163 | validation: 0.13393371849902586]
	TIME [epoch: 8.36 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1208541184209178		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.1208541184209178 | validation: 0.12706018219646087]
	TIME [epoch: 8.38 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13795951297921943		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.13795951297921943 | validation: 0.14298571996411974]
	TIME [epoch: 8.37 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1183185778200955		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.1183185778200955 | validation: 0.15536737047338323]
	TIME [epoch: 8.36 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11705783779336172		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.11705783779336172 | validation: 0.13543545341254942]
	TIME [epoch: 8.36 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1052833208652905		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.1052833208652905 | validation: 0.1442812110535403]
	TIME [epoch: 8.38 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1137983916754944		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.1137983916754944 | validation: 0.12999818077154726]
	TIME [epoch: 8.36 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11927561250680396		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.11927561250680396 | validation: 0.1451671592233199]
	TIME [epoch: 8.36 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13593153915510908		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.13593153915510908 | validation: 0.20813825516082035]
	TIME [epoch: 8.36 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14347983259904767		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.14347983259904767 | validation: 0.14870998236906086]
	TIME [epoch: 8.38 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12298027487586197		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.12298027487586197 | validation: 0.14801510099831655]
	TIME [epoch: 8.36 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11484164754930562		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.11484164754930562 | validation: 0.12370806583272206]
	TIME [epoch: 8.35 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12330038475245106		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.12330038475245106 | validation: 0.14279958849594232]
	TIME [epoch: 8.38 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14996801869400758		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.14996801869400758 | validation: 0.12525887426101803]
	TIME [epoch: 8.36 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10610169285223423		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.10610169285223423 | validation: 0.14599198641624972]
	TIME [epoch: 8.36 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12108379758770156		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.12108379758770156 | validation: 0.13175939679899273]
	TIME [epoch: 8.36 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11421730983841874		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.11421730983841874 | validation: 0.12598887088866043]
	TIME [epoch: 8.38 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1100861646688898		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.1100861646688898 | validation: 0.1363599259632998]
	TIME [epoch: 8.36 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10881687882350119		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.10881687882350119 | validation: 0.11346470150101667]
	TIME [epoch: 8.36 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11794504398812711		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.11794504398812711 | validation: 0.13122406977868906]
	TIME [epoch: 8.37 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11640663286224032		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.11640663286224032 | validation: 0.1169721587443739]
	TIME [epoch: 8.37 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11431144229651129		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.11431144229651129 | validation: 0.11730388550234916]
	TIME [epoch: 8.36 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11050860477957966		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.11050860477957966 | validation: 0.1335627679824665]
	TIME [epoch: 8.36 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11279236954634113		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.11279236954634113 | validation: 0.13061898820320297]
	TIME [epoch: 8.39 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10784189084999937		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.10784189084999937 | validation: 0.14114295348130657]
	TIME [epoch: 8.36 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10844857172918135		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.10844857172918135 | validation: 0.1269755206558109]
	TIME [epoch: 8.36 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1097319020367857		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.1097319020367857 | validation: 0.13119240096356866]
	TIME [epoch: 8.36 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10637311389146595		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.10637311389146595 | validation: 0.12797734262951346]
	TIME [epoch: 8.39 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1034793813577505		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.1034793813577505 | validation: 0.1260247150250517]
	TIME [epoch: 8.37 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11785942050535539		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.11785942050535539 | validation: 0.11357867329290566]
	TIME [epoch: 8.36 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11401075451930609		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.11401075451930609 | validation: 0.1305327577606743]
	TIME [epoch: 8.38 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11228226867911491		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.11228226867911491 | validation: 0.13021057736052968]
	TIME [epoch: 8.37 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10416469779681507		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.10416469779681507 | validation: 0.12157530237528061]
	TIME [epoch: 8.36 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10277398336757748		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.10277398336757748 | validation: 0.12919229288100165]
	TIME [epoch: 8.37 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10993109918164892		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.10993109918164892 | validation: 0.12332142667866783]
	TIME [epoch: 8.39 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11541956911322518		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.11541956911322518 | validation: 0.12143411757769673]
	TIME [epoch: 8.36 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10201318231743348		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.10201318231743348 | validation: 0.10509795735278496]
	TIME [epoch: 8.36 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11601746670553954		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.11601746670553954 | validation: 0.12813743911621794]
	TIME [epoch: 8.38 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10692268115048001		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.10692268115048001 | validation: 0.12924250179556743]
	TIME [epoch: 8.38 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10348033904274105		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.10348033904274105 | validation: 0.14151069616301168]
	TIME [epoch: 8.35 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.116797607086646		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.116797607086646 | validation: 0.13443114877760548]
	TIME [epoch: 8.36 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11291225577933935		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.11291225577933935 | validation: 0.13970488981686208]
	TIME [epoch: 8.38 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1173821006669391		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.1173821006669391 | validation: 0.15286238637860855]
	TIME [epoch: 8.37 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11422816163375707		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.11422816163375707 | validation: 0.140183901073913]
	TIME [epoch: 8.36 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11218547001955739		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.11218547001955739 | validation: 0.11953285743821536]
	TIME [epoch: 8.36 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10254659362927945		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.10254659362927945 | validation: 0.10198183346087428]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_833.pth
	Model improved!!!
EPOCH 834/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10218002874490888		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.10218002874490888 | validation: 0.11791981060626117]
	TIME [epoch: 8.37 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1113280890286594		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.1113280890286594 | validation: 0.1259704619870708]
	TIME [epoch: 8.36 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10415667928065035		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.10415667928065035 | validation: 0.11402626812659467]
	TIME [epoch: 8.38 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09614924230138902		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.09614924230138902 | validation: 0.12519848803268518]
	TIME [epoch: 8.37 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10850991830125227		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.10850991830125227 | validation: 0.12538862225879327]
	TIME [epoch: 8.36 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10474314138521831		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.10474314138521831 | validation: 0.1256097002588969]
	TIME [epoch: 8.36 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11097926560066784		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.11097926560066784 | validation: 0.11821888042108836]
	TIME [epoch: 8.38 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10355756649518177		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.10355756649518177 | validation: 0.10801103367480858]
	TIME [epoch: 8.37 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09778654025082739		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.09778654025082739 | validation: 0.12288173594555304]
	TIME [epoch: 8.36 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09692698504178177		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.09692698504178177 | validation: 0.11590941895599008]
	TIME [epoch: 8.37 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10596416796156934		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.10596416796156934 | validation: 0.12381140479841063]
	TIME [epoch: 8.39 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11101803135910153		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.11101803135910153 | validation: 0.1315764958658293]
	TIME [epoch: 8.37 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10185637818806956		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.10185637818806956 | validation: 0.12790938566206023]
	TIME [epoch: 8.35 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11108841810597274		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.11108841810597274 | validation: 0.11064098169622869]
	TIME [epoch: 8.36 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10068412030515461		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.10068412030515461 | validation: 0.11882935424246602]
	TIME [epoch: 8.38 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1100692921916456		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.1100692921916456 | validation: 0.11893467467902535]
	TIME [epoch: 8.36 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10099823374464534		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.10099823374464534 | validation: 0.12407609565873398]
	TIME [epoch: 8.36 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11447963353271055		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.11447963353271055 | validation: 0.10604498087600636]
	TIME [epoch: 8.38 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09621266949944227		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.09621266949944227 | validation: 0.1225144891992543]
	TIME [epoch: 8.37 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0988764311198818		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.0988764311198818 | validation: 0.12286511518430646]
	TIME [epoch: 8.36 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10427104568555783		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.10427104568555783 | validation: 0.12410779815965123]
	TIME [epoch: 8.35 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11004532333378225		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.11004532333378225 | validation: 0.126760262894902]
	TIME [epoch: 8.38 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09723906670211113		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.09723906670211113 | validation: 0.13893696739435624]
	TIME [epoch: 8.35 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0947159084881032		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.0947159084881032 | validation: 0.11701581677898512]
	TIME [epoch: 8.35 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1033910674152992		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.1033910674152992 | validation: 0.1093886523589408]
	TIME [epoch: 8.36 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09637412938379644		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.09637412938379644 | validation: 0.11769648807616272]
	TIME [epoch: 8.38 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1029494669083052		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.1029494669083052 | validation: 0.11668893793678028]
	TIME [epoch: 8.35 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10288468619509945		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.10288468619509945 | validation: 0.10984638741151653]
	TIME [epoch: 8.36 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11130665215997622		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.11130665215997622 | validation: 0.13596122891778417]
	TIME [epoch: 8.38 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10107196450173188		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.10107196450173188 | validation: 0.11390764350205274]
	TIME [epoch: 8.36 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09583180660983236		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.09583180660983236 | validation: 0.11864586136945632]
	TIME [epoch: 8.36 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10405092373026863		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.10405092373026863 | validation: 0.13494953543767882]
	TIME [epoch: 8.36 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11158913886358804		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.11158913886358804 | validation: 0.11755341757855695]
	TIME [epoch: 8.39 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10638101416324808		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.10638101416324808 | validation: 0.12604507689538624]
	TIME [epoch: 8.36 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10967921977383881		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.10967921977383881 | validation: 0.1385790799553125]
	TIME [epoch: 8.36 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12236308855987695		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.12236308855987695 | validation: 0.11327897698819238]
	TIME [epoch: 8.37 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10748443008692661		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.10748443008692661 | validation: 0.11905291642462157]
	TIME [epoch: 8.37 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10909310038582672		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.10909310038582672 | validation: 0.130317240154753]
	TIME [epoch: 8.37 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10688693584984418		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.10688693584984418 | validation: 0.10545000766168586]
	TIME [epoch: 8.36 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09811703351548531		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.09811703351548531 | validation: 0.12489020975463225]
	TIME [epoch: 8.38 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1034661963960342		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.1034661963960342 | validation: 0.13812521117973545]
	TIME [epoch: 8.36 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10536304158679348		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.10536304158679348 | validation: 0.1151277029099965]
	TIME [epoch: 8.36 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10251381101618777		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.10251381101618777 | validation: 0.11685847565078694]
	TIME [epoch: 8.35 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10332937956095962		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.10332937956095962 | validation: 0.1177898440088153]
	TIME [epoch: 8.38 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10856153051249692		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.10856153051249692 | validation: 0.10174244752737976]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_878.pth
	Model improved!!!
EPOCH 879/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10494954489009174		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.10494954489009174 | validation: 0.13970383013475896]
	TIME [epoch: 8.36 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10808007133422567		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.10808007133422567 | validation: 0.1287442809072554]
	TIME [epoch: 8.38 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10913012315525103		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.10913012315525103 | validation: 0.10505938711756413]
	TIME [epoch: 8.37 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1002483748334638		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.1002483748334638 | validation: 0.12141669615812506]
	TIME [epoch: 8.36 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10749386713620349		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.10749386713620349 | validation: 0.11809963474548603]
	TIME [epoch: 8.37 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10898592881881049		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.10898592881881049 | validation: 0.13747785787723754]
	TIME [epoch: 8.38 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11443069287862595		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.11443069287862595 | validation: 0.14264695153511217]
	TIME [epoch: 8.36 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10570750654413923		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.10570750654413923 | validation: 0.11649830111329633]
	TIME [epoch: 8.36 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1065754194216069		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.1065754194216069 | validation: 0.11266876314219121]
	TIME [epoch: 8.36 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10364089473910072		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.10364089473910072 | validation: 0.10460964338699336]
	TIME [epoch: 8.39 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0967288922037877		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.0967288922037877 | validation: 0.10078378078822006]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_889.pth
	Model improved!!!
EPOCH 890/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09362207975090615		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.09362207975090615 | validation: 0.12249156229411431]
	TIME [epoch: 8.37 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10863330694405901		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.10863330694405901 | validation: 0.13847002705249406]
	TIME [epoch: 8.37 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11583041621529973		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.11583041621529973 | validation: 0.12553381537468955]
	TIME [epoch: 8.39 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11187028277320221		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.11187028277320221 | validation: 0.10955681811705592]
	TIME [epoch: 8.36 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09974909388064489		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.09974909388064489 | validation: 0.1123510818506337]
	TIME [epoch: 8.36 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10070029347620309		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.10070029347620309 | validation: 0.12443663364326484]
	TIME [epoch: 8.37 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10621357868165567		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.10621357868165567 | validation: 0.14468612760254623]
	TIME [epoch: 8.39 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1084673039434682		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.1084673039434682 | validation: 0.12869986846602166]
	TIME [epoch: 8.36 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10534085320654418		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.10534085320654418 | validation: 0.12564612421451146]
	TIME [epoch: 8.36 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10421986405813972		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.10421986405813972 | validation: 0.13228083825097603]
	TIME [epoch: 8.39 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10369898643727053		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.10369898643727053 | validation: 0.12084642627090403]
	TIME [epoch: 8.37 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10280170515739925		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.10280170515739925 | validation: 0.13346525439384715]
	TIME [epoch: 8.36 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10799953283920508		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.10799953283920508 | validation: 0.11689503707311455]
	TIME [epoch: 8.37 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1003889651373902		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.1003889651373902 | validation: 0.11347725860757081]
	TIME [epoch: 8.39 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09416378117183404		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.09416378117183404 | validation: 0.12495882912660294]
	TIME [epoch: 8.36 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10183217560099651		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.10183217560099651 | validation: 0.12766318710771188]
	TIME [epoch: 8.37 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0997553413941361		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.0997553413941361 | validation: 0.12227905762946244]
	TIME [epoch: 8.38 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10187743771156481		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.10187743771156481 | validation: 0.11513455379535492]
	TIME [epoch: 8.37 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09649734647579929		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.09649734647579929 | validation: 0.11237154165444252]
	TIME [epoch: 8.36 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0998434109467424		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.0998434109467424 | validation: 0.12537343370327825]
	TIME [epoch: 8.36 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10776470854608915		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.10776470854608915 | validation: 0.11324917974953161]
	TIME [epoch: 8.39 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1030051594940562		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.1030051594940562 | validation: 0.10884870815697008]
	TIME [epoch: 8.37 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09808856635469106		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.09808856635469106 | validation: 0.11680311817362415]
	TIME [epoch: 8.36 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10384522080154486		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.10384522080154486 | validation: 0.11519164933225406]
	TIME [epoch: 8.35 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09498117294908985		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.09498117294908985 | validation: 0.10794827993673264]
	TIME [epoch: 8.39 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10461897406199416		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.10461897406199416 | validation: 0.10225071400733113]
	TIME [epoch: 8.36 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1030183803443788		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.1030183803443788 | validation: 0.11664892738434506]
	TIME [epoch: 8.35 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10029962849512072		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.10029962849512072 | validation: 0.11794594862794541]
	TIME [epoch: 8.39 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10074273050421327		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.10074273050421327 | validation: 0.12178511058181055]
	TIME [epoch: 8.38 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1004813154346846		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.1004813154346846 | validation: 0.13361659573901374]
	TIME [epoch: 8.36 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09995308259220366		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.09995308259220366 | validation: 0.1068275317264138]
	TIME [epoch: 8.36 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09864779398824161		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.09864779398824161 | validation: 0.1341305336172383]
	TIME [epoch: 8.38 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10250695800421912		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.10250695800421912 | validation: 0.11602052605638771]
	TIME [epoch: 8.37 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09907993832374185		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.09907993832374185 | validation: 0.10781938028357263]
	TIME [epoch: 8.36 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09639112230956937		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.09639112230956937 | validation: 0.11195976026422266]
	TIME [epoch: 8.38 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1025310855585343		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.1025310855585343 | validation: 0.10777317539994503]
	TIME [epoch: 8.36 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10430457135801596		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.10430457135801596 | validation: 0.1193755085242412]
	TIME [epoch: 8.36 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10865480999142882		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.10865480999142882 | validation: 0.10502993039310227]
	TIME [epoch: 8.36 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09923715634887466		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.09923715634887466 | validation: 0.10799288763059803]
	TIME [epoch: 8.37 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10247462194703502		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.10247462194703502 | validation: 0.11296973303033819]
	TIME [epoch: 8.37 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1037405573081861		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.1037405573081861 | validation: 0.12673179948184293]
	TIME [epoch: 8.37 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10624417355337654		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.10624417355337654 | validation: 0.12729474017379183]
	TIME [epoch: 8.36 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10389754738951729		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.10389754738951729 | validation: 0.11294703562534102]
	TIME [epoch: 8.39 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10655730576490348		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.10655730576490348 | validation: 0.13475866813976298]
	TIME [epoch: 8.36 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1194815741540641		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.1194815741540641 | validation: 0.11851236219219041]
	TIME [epoch: 8.35 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09783064765558491		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.09783064765558491 | validation: 0.12801829550672936]
	TIME [epoch: 8.36 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10986407383934169		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.10986407383934169 | validation: 0.12737280211511276]
	TIME [epoch: 8.38 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10377044235669922		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.10377044235669922 | validation: 0.11238288838761207]
	TIME [epoch: 8.35 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10616131365893042		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.10616131365893042 | validation: 0.11510497461448246]
	TIME [epoch: 8.37 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10326777368112774		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.10326777368112774 | validation: 0.11591844056940595]
	TIME [epoch: 8.4 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10178121236348583		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.10178121236348583 | validation: 0.12482235324638538]
	TIME [epoch: 8.37 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10461146550427172		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.10461146550427172 | validation: 0.12359998220480062]
	TIME [epoch: 8.36 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10278697241075907		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.10278697241075907 | validation: 0.11033071376552506]
	TIME [epoch: 8.37 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09809502640729964		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.09809502640729964 | validation: 0.12024843151790207]
	TIME [epoch: 8.39 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10797146075333738		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.10797146075333738 | validation: 0.13276100566513546]
	TIME [epoch: 8.37 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11520141522867236		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.11520141522867236 | validation: 0.13189931039875064]
	TIME [epoch: 8.36 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10746775688014432		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.10746775688014432 | validation: 0.1047307432930949]
	TIME [epoch: 8.38 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10338663530209236		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.10338663530209236 | validation: 0.10980962950647072]
	TIME [epoch: 8.38 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10140023276025575		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.10140023276025575 | validation: 0.11561738118258738]
	TIME [epoch: 8.36 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10983327983842235		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.10983327983842235 | validation: 0.10992030791075402]
	TIME [epoch: 8.36 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10696357972141408		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.10696357972141408 | validation: 0.12603978187572965]
	TIME [epoch: 8.39 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10014024992115045		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.10014024992115045 | validation: 0.11675620383388173]
	TIME [epoch: 8.37 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10428923642090973		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.10428923642090973 | validation: 0.11621958413165441]
	TIME [epoch: 8.35 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0992652331185489		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.0992652331185489 | validation: 0.11509223855478758]
	TIME [epoch: 8.37 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10078349878790646		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.10078349878790646 | validation: 0.11764265906025036]
	TIME [epoch: 8.38 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09845855662362259		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.09845855662362259 | validation: 0.1363668806017717]
	TIME [epoch: 8.35 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10726804112933441		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.10726804112933441 | validation: 0.11982583119151967]
	TIME [epoch: 8.35 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10150623247381965		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.10150623247381965 | validation: 0.0988059555199867]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r3_20240218_115024/states/model_tr_study3_957.pth
	Model improved!!!
EPOCH 958/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1003770291704584		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.1003770291704584 | validation: 0.10537574953972847]
	TIME [epoch: 8.37 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10119252367011136		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.10119252367011136 | validation: 0.12167845048630066]
	TIME [epoch: 8.36 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09413284045177994		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.09413284045177994 | validation: 0.10778274727839551]
	TIME [epoch: 8.36 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10305671687741824		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.10305671687741824 | validation: 0.11421860925200134]
	TIME [epoch: 8.38 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10733924599848935		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.10733924599848935 | validation: 0.11551610499943951]
	TIME [epoch: 8.36 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11059869434733889		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.11059869434733889 | validation: 0.1279735691524791]
	TIME [epoch: 8.35 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10606181602447469		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.10606181602447469 | validation: 0.1172982074351013]
	TIME [epoch: 8.35 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10257818517625075		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.10257818517625075 | validation: 0.12851878763105648]
	TIME [epoch: 8.38 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10592806850338403		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.10592806850338403 | validation: 0.12027344719465616]
	TIME [epoch: 8.36 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10119509745821939		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.10119509745821939 | validation: 0.11163801996497541]
	TIME [epoch: 8.36 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10668234932292966		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.10668234932292966 | validation: 0.125491192753855]
	TIME [epoch: 8.37 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10622271678863227		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.10622271678863227 | validation: 0.12692415773309604]
	TIME [epoch: 8.37 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1040013993121525		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.1040013993121525 | validation: 0.10973526363637139]
	TIME [epoch: 8.37 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1012468086669005		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.1012468086669005 | validation: 0.11215148692610805]
	TIME [epoch: 8.37 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1089736559712341		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.1089736559712341 | validation: 0.11699303441386102]
	TIME [epoch: 8.38 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10011948143413685		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.10011948143413685 | validation: 0.10657340713317891]
	TIME [epoch: 8.36 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10256585029836998		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.10256585029836998 | validation: 0.11652937757455614]
	TIME [epoch: 8.34 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10722608468588675		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.10722608468588675 | validation: 0.11476851017612805]
	TIME [epoch: 8.38 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10274835280624244		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.10274835280624244 | validation: 0.10652906491280073]
	TIME [epoch: 8.37 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10098734817000665		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.10098734817000665 | validation: 0.10864846629029087]
	TIME [epoch: 8.36 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10114182139555843		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.10114182139555843 | validation: 0.10482523267736792]
	TIME [epoch: 8.37 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10364553826701221		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.10364553826701221 | validation: 0.1059577252420613]
	TIME [epoch: 8.36 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09753371947937588		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.09753371947937588 | validation: 0.10760425647779395]
	TIME [epoch: 8.38 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10124790309941549		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.10124790309941549 | validation: 0.10444906619659773]
	TIME [epoch: 8.36 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09759909081966404		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.09759909081966404 | validation: 0.11016585159909394]
	TIME [epoch: 8.35 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10102091996103826		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.10102091996103826 | validation: 0.11358394232157387]
	TIME [epoch: 8.38 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1039516641293237		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.1039516641293237 | validation: 0.11958127310465053]
	TIME [epoch: 8.36 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09890927444786066		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.09890927444786066 | validation: 0.10803168156553161]
	TIME [epoch: 8.35 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09840215667553345		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.09840215667553345 | validation: 0.11184995982367918]
	TIME [epoch: 8.36 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10517361941559986		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.10517361941559986 | validation: 0.1199010804753295]
	TIME [epoch: 8.39 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09830002261271197		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.09830002261271197 | validation: 0.11172104320705398]
	TIME [epoch: 8.37 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09736711251715482		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.09736711251715482 | validation: 0.11012741229956757]
	TIME [epoch: 8.37 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10333022266072778		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.10333022266072778 | validation: 0.11825630581872049]
	TIME [epoch: 8.38 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10466695717791455		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.10466695717791455 | validation: 0.10642128540911747]
	TIME [epoch: 8.37 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0921382167725224		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.0921382167725224 | validation: 0.11161719290795019]
	TIME [epoch: 8.38 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09969143788760074		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.09969143788760074 | validation: 0.1139273980952913]
	TIME [epoch: 8.35 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0960843161030004		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.0960843161030004 | validation: 0.11299235302811904]
	TIME [epoch: 8.38 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09873493949477485		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.09873493949477485 | validation: 0.11926237934078418]
	TIME [epoch: 8.36 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10153671123338867		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.10153671123338867 | validation: 0.11267602038680065]
	TIME [epoch: 8.35 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10005763040898144		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.10005763040898144 | validation: 0.10700788961189323]
	TIME [epoch: 8.36 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09644279599376013		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.09644279599376013 | validation: 0.11769500916470485]
	TIME [epoch: 8.38 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10200383444938892		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.10200383444938892 | validation: 0.12106608216257]
	TIME [epoch: 8.35 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10600294152025014		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.10600294152025014 | validation: 0.10406930112301443]
	TIME [epoch: 8.36 sec]
Finished training in 8488.678 seconds.
