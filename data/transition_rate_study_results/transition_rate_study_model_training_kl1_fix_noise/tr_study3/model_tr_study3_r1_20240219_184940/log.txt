Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r1', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4073826996

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.442590706315862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.442590706315862 | validation: 10.648270100519909]
	TIME [epoch: 79.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.762066489497006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.762066489497006 | validation: 8.771875391059137]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.546756795449449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.546756795449449 | validation: 8.162074955177]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.656363999466315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.656363999466315 | validation: 6.543806938223394]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.742542197658146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.742542197658146 | validation: 8.334659778060356]
	TIME [epoch: 8.38 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.436981880509572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.436981880509572 | validation: 8.28329767588685]
	TIME [epoch: 8.37 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.8487682349530985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.8487682349530985 | validation: 5.552161727209297]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.227692969523036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.227692969523036 | validation: 5.674348205331931]
	TIME [epoch: 8.35 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.334549862928181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.334549862928181 | validation: 5.5650190405404025]
	TIME [epoch: 8.37 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.583263413772784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.583263413772784 | validation: 5.047708379566564]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.361061456492419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.361061456492419 | validation: 4.351028164478152]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.524397818510844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.524397818510844 | validation: 4.768246936953618]
	TIME [epoch: 8.34 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.2217357303621315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2217357303621315 | validation: 4.8423252705045865]
	TIME [epoch: 8.37 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.074703636643681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.074703636643681 | validation: 4.5585192840981605]
	TIME [epoch: 8.34 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.754401881806584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.754401881806584 | validation: 4.198687644223583]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.8197529234026355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8197529234026355 | validation: 6.410560442534559]
	TIME [epoch: 8.34 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.0111972080855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0111972080855 | validation: 4.477963432302533]
	TIME [epoch: 8.35 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.724826945113721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.724826945113721 | validation: 3.9956512814745677]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.1618702617687084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1618702617687084 | validation: 4.188297112886301]
	TIME [epoch: 8.36 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.623008366990755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.623008366990755 | validation: 4.023717055261726]
	TIME [epoch: 8.35 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.545763529737663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.545763529737663 | validation: 4.228574447164898]
	TIME [epoch: 8.35 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.666309391851215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.666309391851215 | validation: 4.064529129032305]
	TIME [epoch: 8.38 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.568493891132424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.568493891132424 | validation: 4.638583289105149]
	TIME [epoch: 8.35 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.347387191185478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.347387191185478 | validation: 4.139333765420009]
	TIME [epoch: 8.36 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.400937642596281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.400937642596281 | validation: 4.356237941565181]
	TIME [epoch: 8.35 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.377338957126159		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.377338957126159 | validation: 6.184116536504215]
	TIME [epoch: 8.37 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.550530338572495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.550530338572495 | validation: 6.363505483398788]
	TIME [epoch: 8.36 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.884953798578748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.884953798578748 | validation: 3.788357892681524]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.298895612456333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.298895612456333 | validation: 4.0584482048127954]
	TIME [epoch: 8.35 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.2260392393252415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2260392393252415 | validation: 3.8775313584267304]
	TIME [epoch: 8.35 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.408831169626026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.408831169626026 | validation: 3.7718735219906194]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.080107412691482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.080107412691482 | validation: 4.648138240110677]
	TIME [epoch: 8.35 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.318074500008476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.318074500008476 | validation: 3.519954021696063]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.048794013359744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.048794013359744 | validation: 3.679269251869029]
	TIME [epoch: 8.35 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.192792233591371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.192792233591371 | validation: 4.030210167468353]
	TIME [epoch: 8.37 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.8879336908811855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8879336908811855 | validation: 4.027318789178466]
	TIME [epoch: 8.35 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.165821509254367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.165821509254367 | validation: 4.108452562573738]
	TIME [epoch: 8.34 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.041030527244173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.041030527244173 | validation: 3.903828300287418]
	TIME [epoch: 8.35 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.874202755209998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.874202755209998 | validation: 7.963668344916124]
	TIME [epoch: 8.37 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.739405238319425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.739405238319425 | validation: 4.699514967456168]
	TIME [epoch: 8.34 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.532588586737346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.532588586737346 | validation: 3.707905850603609]
	TIME [epoch: 8.35 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.978206756822555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.978206756822555 | validation: 3.3625034062355974]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.715452255557578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.715452255557578 | validation: 3.6438881083237114]
	TIME [epoch: 8.37 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.097493364641331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.097493364641331 | validation: 3.6975431787458044]
	TIME [epoch: 8.36 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.231059782703594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.231059782703594 | validation: 4.518494646067346]
	TIME [epoch: 8.34 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.1991539586463915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1991539586463915 | validation: 3.223676811679756]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.792391945327624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.792391945327624 | validation: 3.3447512248798583]
	TIME [epoch: 8.34 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.04820782676425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.04820782676425 | validation: 3.0652730426333545]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.516146370065153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.516146370065153 | validation: 2.975680792197087]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7354754040549096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7354754040549096 | validation: 2.957188806316715]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2049525818271762		[learning rate: 0.0099788]
	Learning Rate: 0.00997877
	LOSS [training: 3.2049525818271762 | validation: 4.604919809203226]
	TIME [epoch: 8.34 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6702986143918706		[learning rate: 0.0099552]
	Learning Rate: 0.00995523
	LOSS [training: 3.6702986143918706 | validation: 2.6788552376228356]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4563895254510064		[learning rate: 0.0099317]
	Learning Rate: 0.00993175
	LOSS [training: 3.4563895254510064 | validation: 3.7343978189994425]
	TIME [epoch: 8.35 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9506093057022054		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 2.9506093057022054 | validation: 7.719800507088644]
	TIME [epoch: 8.34 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.78803033220943		[learning rate: 0.0098849]
	Learning Rate: 0.00988495
	LOSS [training: 4.78803033220943 | validation: 3.1688459262353894]
	TIME [epoch: 8.34 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8653038333145457		[learning rate: 0.0098616]
	Learning Rate: 0.00986163
	LOSS [training: 2.8653038333145457 | validation: 2.2160463761040132]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0401294439648856		[learning rate: 0.0098384]
	Learning Rate: 0.00983837
	LOSS [training: 3.0401294439648856 | validation: 2.556558478157638]
	TIME [epoch: 8.34 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.804865080531391		[learning rate: 0.0098152]
	Learning Rate: 0.00981516
	LOSS [training: 2.804865080531391 | validation: 3.680114730094319]
	TIME [epoch: 8.33 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.799146526600032		[learning rate: 0.009792]
	Learning Rate: 0.00979201
	LOSS [training: 2.799146526600032 | validation: 2.835630802280562]
	TIME [epoch: 8.33 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3093749718620225		[learning rate: 0.0097689]
	Learning Rate: 0.00976891
	LOSS [training: 2.3093749718620225 | validation: 1.700885998598415]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5647675623057653		[learning rate: 0.0097459]
	Learning Rate: 0.00974587
	LOSS [training: 2.5647675623057653 | validation: 2.07746852217525]
	TIME [epoch: 8.34 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8305966798058413		[learning rate: 0.0097229]
	Learning Rate: 0.00972288
	LOSS [training: 2.8305966798058413 | validation: 2.3326269531317103]
	TIME [epoch: 8.33 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4616032557944223		[learning rate: 0.0096999]
	Learning Rate: 0.00969994
	LOSS [training: 2.4616032557944223 | validation: 2.7994585279077135]
	TIME [epoch: 8.33 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5986324794668123		[learning rate: 0.0096771]
	Learning Rate: 0.00967706
	LOSS [training: 2.5986324794668123 | validation: 3.27901533409603]
	TIME [epoch: 8.33 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5535421747513602		[learning rate: 0.0096542]
	Learning Rate: 0.00965424
	LOSS [training: 2.5535421747513602 | validation: 1.743501532110837]
	TIME [epoch: 8.36 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.195807978032567		[learning rate: 0.0096315]
	Learning Rate: 0.00963146
	LOSS [training: 2.195807978032567 | validation: 1.7893387281764521]
	TIME [epoch: 8.33 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.981619504753926		[learning rate: 0.0096087]
	Learning Rate: 0.00960874
	LOSS [training: 2.981619504753926 | validation: 3.4973228026254963]
	TIME [epoch: 8.33 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.502357478289054		[learning rate: 0.0095861]
	Learning Rate: 0.00958608
	LOSS [training: 2.502357478289054 | validation: 2.2449292772506686]
	TIME [epoch: 8.33 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.296441702683393		[learning rate: 0.0095635]
	Learning Rate: 0.00956347
	LOSS [training: 2.296441702683393 | validation: 2.1942233886490787]
	TIME [epoch: 8.35 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4573279296975823		[learning rate: 0.0095409]
	Learning Rate: 0.00954091
	LOSS [training: 2.4573279296975823 | validation: 2.802216381278524]
	TIME [epoch: 8.33 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2140413684249127		[learning rate: 0.0095184]
	Learning Rate: 0.0095184
	LOSS [training: 2.2140413684249127 | validation: 1.9194167024371729]
	TIME [epoch: 8.34 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1947846154704225		[learning rate: 0.009496]
	Learning Rate: 0.00949595
	LOSS [training: 2.1947846154704225 | validation: 2.609229292717222]
	TIME [epoch: 8.33 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9530558141546124		[learning rate: 0.0094736]
	Learning Rate: 0.00947355
	LOSS [training: 1.9530558141546124 | validation: 2.3507863878055275]
	TIME [epoch: 8.35 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0661202890645254		[learning rate: 0.0094512]
	Learning Rate: 0.0094512
	LOSS [training: 2.0661202890645254 | validation: 2.2957959670334556]
	TIME [epoch: 8.35 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.245780761355501		[learning rate: 0.0094289]
	Learning Rate: 0.00942891
	LOSS [training: 2.245780761355501 | validation: 2.464367944511824]
	TIME [epoch: 8.33 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4692037878597572		[learning rate: 0.0094067]
	Learning Rate: 0.00940667
	LOSS [training: 2.4692037878597572 | validation: 3.027380871956676]
	TIME [epoch: 8.34 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9576883440236386		[learning rate: 0.0093845]
	Learning Rate: 0.00938448
	LOSS [training: 1.9576883440236386 | validation: 1.528151115651594]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9659896547913456		[learning rate: 0.0093623]
	Learning Rate: 0.00936234
	LOSS [training: 1.9659896547913456 | validation: 1.572855087406491]
	TIME [epoch: 8.36 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1287653293364373		[learning rate: 0.0093403]
	Learning Rate: 0.00934026
	LOSS [training: 2.1287653293364373 | validation: 1.9123082490656493]
	TIME [epoch: 8.33 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7824264872413114		[learning rate: 0.0093182]
	Learning Rate: 0.00931823
	LOSS [training: 1.7824264872413114 | validation: 2.1655708227671333]
	TIME [epoch: 8.33 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9858728756212884		[learning rate: 0.0092962]
	Learning Rate: 0.00929625
	LOSS [training: 1.9858728756212884 | validation: 1.4089923148864503]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.726282216673376		[learning rate: 0.0092743]
	Learning Rate: 0.00927432
	LOSS [training: 1.726282216673376 | validation: 1.8571961901060492]
	TIME [epoch: 8.38 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8767505387565329		[learning rate: 0.0092524]
	Learning Rate: 0.00925244
	LOSS [training: 1.8767505387565329 | validation: 1.9153565794563376]
	TIME [epoch: 8.36 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.68718709631343		[learning rate: 0.0092306]
	Learning Rate: 0.00923062
	LOSS [training: 1.68718709631343 | validation: 2.610345900290261]
	TIME [epoch: 8.35 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7653357283785849		[learning rate: 0.0092088]
	Learning Rate: 0.00920884
	LOSS [training: 1.7653357283785849 | validation: 2.3460746496282274]
	TIME [epoch: 8.35 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0390921742384553		[learning rate: 0.0091871]
	Learning Rate: 0.00918712
	LOSS [training: 2.0390921742384553 | validation: 1.5725535072647203]
	TIME [epoch: 8.37 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.11670594559586		[learning rate: 0.0091655]
	Learning Rate: 0.00916545
	LOSS [training: 2.11670594559586 | validation: 1.7890399353801736]
	TIME [epoch: 8.36 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.856463671212148		[learning rate: 0.0091438]
	Learning Rate: 0.00914383
	LOSS [training: 1.856463671212148 | validation: 1.453089189019888]
	TIME [epoch: 8.36 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7912129510579202		[learning rate: 0.0091223]
	Learning Rate: 0.00912226
	LOSS [training: 1.7912129510579202 | validation: 1.3966948068355887]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.595190158800077		[learning rate: 0.0091007]
	Learning Rate: 0.00910074
	LOSS [training: 1.595190158800077 | validation: 1.6613291139566901]
	TIME [epoch: 8.36 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7916580547894878		[learning rate: 0.0090793]
	Learning Rate: 0.00907928
	LOSS [training: 1.7916580547894878 | validation: 1.6198832749083005]
	TIME [epoch: 8.37 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7755187772820296		[learning rate: 0.0090579]
	Learning Rate: 0.00905786
	LOSS [training: 1.7755187772820296 | validation: 2.2085790164844985]
	TIME [epoch: 8.35 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7223452462248243		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 1.7223452462248243 | validation: 1.4385691595446506]
	TIME [epoch: 8.35 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7675840286389704		[learning rate: 0.0090152]
	Learning Rate: 0.00901518
	LOSS [training: 1.7675840286389704 | validation: 1.718148296163994]
	TIME [epoch: 8.35 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5981537282527487		[learning rate: 0.0089939]
	Learning Rate: 0.00899391
	LOSS [training: 1.5981537282527487 | validation: 2.040097650603588]
	TIME [epoch: 8.38 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.652220118609775		[learning rate: 0.0089727]
	Learning Rate: 0.0089727
	LOSS [training: 1.652220118609775 | validation: 1.453392888180447]
	TIME [epoch: 8.36 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7751067125486863		[learning rate: 0.0089515]
	Learning Rate: 0.00895153
	LOSS [training: 1.7751067125486863 | validation: 1.6884895787470882]
	TIME [epoch: 8.35 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5445169180309533		[learning rate: 0.0089304]
	Learning Rate: 0.00893042
	LOSS [training: 1.5445169180309533 | validation: 2.247923206441116]
	TIME [epoch: 8.35 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5376986018877399		[learning rate: 0.0089094]
	Learning Rate: 0.00890935
	LOSS [training: 1.5376986018877399 | validation: 1.476686780384684]
	TIME [epoch: 8.37 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5749410549249374		[learning rate: 0.0088883]
	Learning Rate: 0.00888834
	LOSS [training: 1.5749410549249374 | validation: 1.7614758029042896]
	TIME [epoch: 8.35 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.35478370524927		[learning rate: 0.0088674]
	Learning Rate: 0.00886737
	LOSS [training: 1.35478370524927 | validation: 1.3760428683903205]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7833313942175508		[learning rate: 0.0088465]
	Learning Rate: 0.00884645
	LOSS [training: 1.7833313942175508 | validation: 2.0855890231483465]
	TIME [epoch: 8.35 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.731178256927032		[learning rate: 0.0088256]
	Learning Rate: 0.00882559
	LOSS [training: 1.731178256927032 | validation: 1.3191712160654305]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.421205723128944		[learning rate: 0.0088048]
	Learning Rate: 0.00880477
	LOSS [training: 1.421205723128944 | validation: 2.163414118410171]
	TIME [epoch: 8.36 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4996343425600016		[learning rate: 0.008784]
	Learning Rate: 0.008784
	LOSS [training: 1.4996343425600016 | validation: 1.9797579684803868]
	TIME [epoch: 8.35 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1171593293387394		[learning rate: 0.0087633]
	Learning Rate: 0.00876328
	LOSS [training: 2.1171593293387394 | validation: 1.479381400695221]
	TIME [epoch: 8.35 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5004032163620178		[learning rate: 0.0087426]
	Learning Rate: 0.00874261
	LOSS [training: 1.5004032163620178 | validation: 1.242738757514635]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4061785237810598		[learning rate: 0.008722]
	Learning Rate: 0.00872199
	LOSS [training: 1.4061785237810598 | validation: 1.3992160915491083]
	TIME [epoch: 8.37 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6815454210001555		[learning rate: 0.0087014]
	Learning Rate: 0.00870141
	LOSS [training: 1.6815454210001555 | validation: 1.741059248202665]
	TIME [epoch: 8.35 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6013633647655308		[learning rate: 0.0086809]
	Learning Rate: 0.00868089
	LOSS [training: 1.6013633647655308 | validation: 1.7950271008076366]
	TIME [epoch: 8.34 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6907532197777833		[learning rate: 0.0086604]
	Learning Rate: 0.00866041
	LOSS [training: 1.6907532197777833 | validation: 2.088118292630609]
	TIME [epoch: 8.34 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5614249817193442		[learning rate: 0.00864]
	Learning Rate: 0.00863998
	LOSS [training: 1.5614249817193442 | validation: 1.1411911778360486]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4143231806175511		[learning rate: 0.0086196]
	Learning Rate: 0.0086196
	LOSS [training: 1.4143231806175511 | validation: 1.5999103618634618]
	TIME [epoch: 8.34 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3730875764508825		[learning rate: 0.0085993]
	Learning Rate: 0.00859927
	LOSS [training: 1.3730875764508825 | validation: 1.2587264613658395]
	TIME [epoch: 8.33 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.562201847513712		[learning rate: 0.008579]
	Learning Rate: 0.00857898
	LOSS [training: 1.562201847513712 | validation: 1.7457454803115038]
	TIME [epoch: 8.34 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6627251415652051		[learning rate: 0.0085587]
	Learning Rate: 0.00855875
	LOSS [training: 1.6627251415652051 | validation: 1.7554402916863956]
	TIME [epoch: 8.35 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3805750507073418		[learning rate: 0.0085386]
	Learning Rate: 0.00853856
	LOSS [training: 1.3805750507073418 | validation: 1.4739921003163063]
	TIME [epoch: 8.35 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5417151155325874		[learning rate: 0.0085184]
	Learning Rate: 0.00851842
	LOSS [training: 1.5417151155325874 | validation: 1.1980135063918564]
	TIME [epoch: 8.34 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2343371530110956		[learning rate: 0.0084983]
	Learning Rate: 0.00849833
	LOSS [training: 1.2343371530110956 | validation: 1.6696862415524818]
	TIME [epoch: 8.34 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6222350696541052		[learning rate: 0.0084783]
	Learning Rate: 0.00847828
	LOSS [training: 1.6222350696541052 | validation: 1.7730485835667924]
	TIME [epoch: 8.34 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3162881774760868		[learning rate: 0.0084583]
	Learning Rate: 0.00845828
	LOSS [training: 1.3162881774760868 | validation: 1.0605688181385]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2881849046883225		[learning rate: 0.0084383]
	Learning Rate: 0.00843833
	LOSS [training: 1.2881849046883225 | validation: 1.6820007277385405]
	TIME [epoch: 8.34 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4424351967872764		[learning rate: 0.0084184]
	Learning Rate: 0.00841842
	LOSS [training: 1.4424351967872764 | validation: 1.3262968845633396]
	TIME [epoch: 8.34 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2941266434274545		[learning rate: 0.0083986]
	Learning Rate: 0.00839857
	LOSS [training: 1.2941266434274545 | validation: 0.9764447543243997]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4322372837906654		[learning rate: 0.0083788]
	Learning Rate: 0.00837875
	LOSS [training: 1.4322372837906654 | validation: 0.8066185902173166]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3013655538920756		[learning rate: 0.008359]
	Learning Rate: 0.00835899
	LOSS [training: 1.3013655538920756 | validation: 1.0193774405831557]
	TIME [epoch: 8.34 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2459729461785538		[learning rate: 0.0083393]
	Learning Rate: 0.00833927
	LOSS [training: 1.2459729461785538 | validation: 1.4616955873798951]
	TIME [epoch: 8.34 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1588357075111413		[learning rate: 0.0083196]
	Learning Rate: 0.0083196
	LOSS [training: 1.1588357075111413 | validation: 1.4095443793065898]
	TIME [epoch: 8.34 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1515962769276264		[learning rate: 0.0083]
	Learning Rate: 0.00829998
	LOSS [training: 1.1515962769276264 | validation: 0.9577271321625835]
	TIME [epoch: 8.36 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.141213924426965		[learning rate: 0.0082804]
	Learning Rate: 0.0082804
	LOSS [training: 1.141213924426965 | validation: 0.9779509086088163]
	TIME [epoch: 8.34 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.091023864270752		[learning rate: 0.0082609]
	Learning Rate: 0.00826087
	LOSS [training: 1.091023864270752 | validation: 0.6937415869226244]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9555887404535894		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 0.9555887404535894 | validation: 1.3119929008663762]
	TIME [epoch: 8.33 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0637935066524524		[learning rate: 0.0082219]
	Learning Rate: 0.00822194
	LOSS [training: 1.0637935066524524 | validation: 1.2642861519950213]
	TIME [epoch: 8.35 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8724239910930771		[learning rate: 0.0082025]
	Learning Rate: 0.00820255
	LOSS [training: 0.8724239910930771 | validation: 0.9624294714253339]
	TIME [epoch: 8.34 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0879398730875114		[learning rate: 0.0081832]
	Learning Rate: 0.0081832
	LOSS [training: 1.0879398730875114 | validation: 1.107130437158692]
	TIME [epoch: 8.33 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3193031217893414		[learning rate: 0.0081639]
	Learning Rate: 0.00816389
	LOSS [training: 1.3193031217893414 | validation: 0.8740082750330473]
	TIME [epoch: 8.33 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0000447258984813		[learning rate: 0.0081446]
	Learning Rate: 0.00814464
	LOSS [training: 1.0000447258984813 | validation: 0.9050900203443075]
	TIME [epoch: 8.33 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.183751095202928		[learning rate: 0.0081254]
	Learning Rate: 0.00812543
	LOSS [training: 1.183751095202928 | validation: 1.030762245299504]
	TIME [epoch: 8.35 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0549967909740767		[learning rate: 0.0081063]
	Learning Rate: 0.00810626
	LOSS [training: 1.0549967909740767 | validation: 0.9003922520485627]
	TIME [epoch: 8.33 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9599620054854151		[learning rate: 0.0080871]
	Learning Rate: 0.00808714
	LOSS [training: 0.9599620054854151 | validation: 0.7157749879127911]
	TIME [epoch: 8.32 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8170538435774924		[learning rate: 0.0080681]
	Learning Rate: 0.00806806
	LOSS [training: 0.8170538435774924 | validation: 0.6198631150284705]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8474706751734811		[learning rate: 0.008049]
	Learning Rate: 0.00804903
	LOSS [training: 0.8474706751734811 | validation: 0.9704228607073728]
	TIME [epoch: 8.34 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7516372427694845		[learning rate: 0.00803]
	Learning Rate: 0.00803004
	LOSS [training: 0.7516372427694845 | validation: 1.0729235161322743]
	TIME [epoch: 8.33 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0402566707299978		[learning rate: 0.0080111]
	Learning Rate: 0.0080111
	LOSS [training: 1.0402566707299978 | validation: 0.5245123353631482]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7929831552956983		[learning rate: 0.0079922]
	Learning Rate: 0.00799221
	LOSS [training: 0.7929831552956983 | validation: 0.866706095610208]
	TIME [epoch: 8.34 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9307720593797484		[learning rate: 0.0079734]
	Learning Rate: 0.00797335
	LOSS [training: 0.9307720593797484 | validation: 0.7420593679330283]
	TIME [epoch: 8.36 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6910936047575992		[learning rate: 0.0079545]
	Learning Rate: 0.00795455
	LOSS [training: 0.6910936047575992 | validation: 0.6033988596732528]
	TIME [epoch: 8.36 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8046429634796468		[learning rate: 0.0079358]
	Learning Rate: 0.00793578
	LOSS [training: 0.8046429634796468 | validation: 0.7493486811860972]
	TIME [epoch: 8.35 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.817186794075823		[learning rate: 0.0079171]
	Learning Rate: 0.00791706
	LOSS [training: 0.817186794075823 | validation: 1.1470775029090152]
	TIME [epoch: 8.31 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9338466477144637		[learning rate: 0.0078984]
	Learning Rate: 0.00789839
	LOSS [training: 0.9338466477144637 | validation: 0.765257088683615]
	TIME [epoch: 8.33 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8086736314506963		[learning rate: 0.0078798]
	Learning Rate: 0.00787976
	LOSS [training: 0.8086736314506963 | validation: 1.1572917870999568]
	TIME [epoch: 8.35 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9229786621496203		[learning rate: 0.0078612]
	Learning Rate: 0.00786117
	LOSS [training: 0.9229786621496203 | validation: 0.6147567333034658]
	TIME [epoch: 8.33 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9454033776184627		[learning rate: 0.0078426]
	Learning Rate: 0.00784263
	LOSS [training: 0.9454033776184627 | validation: 2.054764262735369]
	TIME [epoch: 8.32 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1021408081736699		[learning rate: 0.0078241]
	Learning Rate: 0.00782413
	LOSS [training: 1.1021408081736699 | validation: 0.8212297475709196]
	TIME [epoch: 8.32 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7681595790026596		[learning rate: 0.0078057]
	Learning Rate: 0.00780567
	LOSS [training: 0.7681595790026596 | validation: 0.7604521730956706]
	TIME [epoch: 8.33 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7730291675302701		[learning rate: 0.0077873]
	Learning Rate: 0.00778726
	LOSS [training: 0.7730291675302701 | validation: 0.6764739574243435]
	TIME [epoch: 8.33 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7328776837882923		[learning rate: 0.0077689]
	Learning Rate: 0.00776889
	LOSS [training: 0.7328776837882923 | validation: 0.4657963020245152]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7965731328117072		[learning rate: 0.0077506]
	Learning Rate: 0.00775056
	LOSS [training: 0.7965731328117072 | validation: 0.6102607346786776]
	TIME [epoch: 8.68 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9455263321941386		[learning rate: 0.0077323]
	Learning Rate: 0.00773228
	LOSS [training: 0.9455263321941386 | validation: 1.0090540229600315]
	TIME [epoch: 8.37 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9318377654613249		[learning rate: 0.007714]
	Learning Rate: 0.00771404
	LOSS [training: 0.9318377654613249 | validation: 0.961395817881725]
	TIME [epoch: 8.36 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.890239522079675		[learning rate: 0.0076958]
	Learning Rate: 0.00769585
	LOSS [training: 0.890239522079675 | validation: 0.696572882718643]
	TIME [epoch: 8.35 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7945844051520263		[learning rate: 0.0076777]
	Learning Rate: 0.00767769
	LOSS [training: 0.7945844051520263 | validation: 0.5176249095869838]
	TIME [epoch: 8.35 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7669583865297175		[learning rate: 0.0076596]
	Learning Rate: 0.00765958
	LOSS [training: 0.7669583865297175 | validation: 0.731587166958631]
	TIME [epoch: 8.35 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6694825174683625		[learning rate: 0.0076415]
	Learning Rate: 0.00764151
	LOSS [training: 0.6694825174683625 | validation: 0.5935052074803159]
	TIME [epoch: 8.38 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7740101499267513		[learning rate: 0.0076235]
	Learning Rate: 0.00762349
	LOSS [training: 0.7740101499267513 | validation: 0.8051760408855008]
	TIME [epoch: 8.35 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8241875300634309		[learning rate: 0.0076055]
	Learning Rate: 0.00760551
	LOSS [training: 0.8241875300634309 | validation: 0.44316613351070067]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8992058296324998		[learning rate: 0.0075876]
	Learning Rate: 0.00758757
	LOSS [training: 0.8992058296324998 | validation: 0.5251149662340131]
	TIME [epoch: 8.35 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8321821945974103		[learning rate: 0.0075697]
	Learning Rate: 0.00756967
	LOSS [training: 0.8321821945974103 | validation: 0.7026016657581402]
	TIME [epoch: 8.38 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6995841188565444		[learning rate: 0.0075518]
	Learning Rate: 0.00755181
	LOSS [training: 0.6995841188565444 | validation: 0.3903234870621287]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9247056563195637		[learning rate: 0.007534]
	Learning Rate: 0.007534
	LOSS [training: 0.9247056563195637 | validation: 0.7643060582651893]
	TIME [epoch: 8.35 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8260800176244883		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.8260800176244883 | validation: 0.6684254400315942]
	TIME [epoch: 8.35 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7088606759216358		[learning rate: 0.0074985]
	Learning Rate: 0.0074985
	LOSS [training: 0.7088606759216358 | validation: 0.9654440959782328]
	TIME [epoch: 8.37 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.670551005396101		[learning rate: 0.0074808]
	Learning Rate: 0.00748081
	LOSS [training: 1.670551005396101 | validation: 7.08435439424506]
	TIME [epoch: 8.35 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.701644970075024		[learning rate: 0.0074632]
	Learning Rate: 0.00746317
	LOSS [training: 3.701644970075024 | validation: 0.8740464461745745]
	TIME [epoch: 8.34 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7800911300441193		[learning rate: 0.0074456]
	Learning Rate: 0.00744556
	LOSS [training: 0.7800911300441193 | validation: 0.49982042363074136]
	TIME [epoch: 8.34 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8279189557018249		[learning rate: 0.007428]
	Learning Rate: 0.007428
	LOSS [training: 0.8279189557018249 | validation: 3.3178193732279415]
	TIME [epoch: 8.35 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2993102046473246		[learning rate: 0.0074105]
	Learning Rate: 0.00741048
	LOSS [training: 1.2993102046473246 | validation: 0.9442586399408739]
	TIME [epoch: 8.37 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8036642350595475		[learning rate: 0.007393]
	Learning Rate: 0.007393
	LOSS [training: 0.8036642350595475 | validation: 0.7716321129830876]
	TIME [epoch: 8.35 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8118840035591143		[learning rate: 0.0073756]
	Learning Rate: 0.00737556
	LOSS [training: 0.8118840035591143 | validation: 0.9630337962192039]
	TIME [epoch: 8.35 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7286669950433297		[learning rate: 0.0073582]
	Learning Rate: 0.00735816
	LOSS [training: 0.7286669950433297 | validation: 1.1699351986538296]
	TIME [epoch: 8.35 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7465118634896484		[learning rate: 0.0073408]
	Learning Rate: 0.0073408
	LOSS [training: 0.7465118634896484 | validation: 0.6715924764988446]
	TIME [epoch: 8.38 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0709802189558744		[learning rate: 0.0073235]
	Learning Rate: 0.00732349
	LOSS [training: 1.0709802189558744 | validation: 1.1789086518106566]
	TIME [epoch: 8.35 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.849584617855054		[learning rate: 0.0073062]
	Learning Rate: 0.00730621
	LOSS [training: 0.849584617855054 | validation: 0.7275112156936034]
	TIME [epoch: 8.35 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7290765638245603		[learning rate: 0.007289]
	Learning Rate: 0.00728898
	LOSS [training: 0.7290765638245603 | validation: 0.5884255450460321]
	TIME [epoch: 8.35 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8597376591169847		[learning rate: 0.0072718]
	Learning Rate: 0.00727178
	LOSS [training: 0.8597376591169847 | validation: 0.5467014180102512]
	TIME [epoch: 8.37 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1378666529019192		[learning rate: 0.0072546]
	Learning Rate: 0.00725463
	LOSS [training: 1.1378666529019192 | validation: 0.8604243130305382]
	TIME [epoch: 8.35 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7020194268194164		[learning rate: 0.0072375]
	Learning Rate: 0.00723752
	LOSS [training: 0.7020194268194164 | validation: 0.5362254942482585]
	TIME [epoch: 8.34 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7478224932913327		[learning rate: 0.0072204]
	Learning Rate: 0.00722045
	LOSS [training: 0.7478224932913327 | validation: 0.5829993345262972]
	TIME [epoch: 8.35 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8026912298925659		[learning rate: 0.0072034]
	Learning Rate: 0.00720342
	LOSS [training: 0.8026912298925659 | validation: 0.5515856765569748]
	TIME [epoch: 8.36 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8136672955951505		[learning rate: 0.0071864]
	Learning Rate: 0.00718642
	LOSS [training: 0.8136672955951505 | validation: 1.3696095715449275]
	TIME [epoch: 8.37 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7777659807210429		[learning rate: 0.0071695]
	Learning Rate: 0.00716947
	LOSS [training: 0.7777659807210429 | validation: 0.47224040483958785]
	TIME [epoch: 8.34 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7774773226837206		[learning rate: 0.0071526]
	Learning Rate: 0.00715256
	LOSS [training: 0.7774773226837206 | validation: 0.7006082434920551]
	TIME [epoch: 8.35 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8068793132570192		[learning rate: 0.0071357]
	Learning Rate: 0.00713569
	LOSS [training: 0.8068793132570192 | validation: 0.9005381560201282]
	TIME [epoch: 8.35 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.715967052012058		[learning rate: 0.0071189]
	Learning Rate: 0.00711886
	LOSS [training: 0.715967052012058 | validation: 0.7252733754171029]
	TIME [epoch: 8.38 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6865436041578958		[learning rate: 0.0071021]
	Learning Rate: 0.00710206
	LOSS [training: 0.6865436041578958 | validation: 0.6985234672510199]
	TIME [epoch: 8.35 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.033410426028991		[learning rate: 0.0070853]
	Learning Rate: 0.00708531
	LOSS [training: 1.033410426028991 | validation: 2.5307116333974604]
	TIME [epoch: 8.35 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1141706531373459		[learning rate: 0.0070686]
	Learning Rate: 0.0070686
	LOSS [training: 1.1141706531373459 | validation: 0.7956139789369718]
	TIME [epoch: 8.35 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7737328515363634		[learning rate: 0.0070519]
	Learning Rate: 0.00705192
	LOSS [training: 0.7737328515363634 | validation: 0.7774956919819509]
	TIME [epoch: 8.37 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8242678621429486		[learning rate: 0.0070353]
	Learning Rate: 0.00703529
	LOSS [training: 0.8242678621429486 | validation: 0.6520350244378827]
	TIME [epoch: 8.35 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1075858275203578		[learning rate: 0.0070187]
	Learning Rate: 0.0070187
	LOSS [training: 1.1075858275203578 | validation: 1.5693022980276794]
	TIME [epoch: 8.35 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0455752178290445		[learning rate: 0.0070021]
	Learning Rate: 0.00700214
	LOSS [training: 1.0455752178290445 | validation: 0.7714846176280571]
	TIME [epoch: 8.35 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.002628850614443		[learning rate: 0.0069856]
	Learning Rate: 0.00698562
	LOSS [training: 1.002628850614443 | validation: 1.0526025801117624]
	TIME [epoch: 8.36 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.825660394683444		[learning rate: 0.0069691]
	Learning Rate: 0.00696914
	LOSS [training: 0.825660394683444 | validation: 0.6552505538958239]
	TIME [epoch: 8.36 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.935997223028445		[learning rate: 0.0069527]
	Learning Rate: 0.00695271
	LOSS [training: 0.935997223028445 | validation: 0.6892813158388096]
	TIME [epoch: 8.34 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9299612608624189		[learning rate: 0.0069363]
	Learning Rate: 0.00693631
	LOSS [training: 0.9299612608624189 | validation: 0.9129527087938778]
	TIME [epoch: 8.34 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7451476363478121		[learning rate: 0.0069199]
	Learning Rate: 0.00691994
	LOSS [training: 0.7451476363478121 | validation: 1.3142170878956128]
	TIME [epoch: 8.35 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9091108041073298		[learning rate: 0.0069036]
	Learning Rate: 0.00690362
	LOSS [training: 0.9091108041073298 | validation: 0.4778630365849762]
	TIME [epoch: 8.38 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0012069952282272		[learning rate: 0.0068873]
	Learning Rate: 0.00688734
	LOSS [training: 1.0012069952282272 | validation: 0.8341004231002125]
	TIME [epoch: 8.34 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0911750799568882		[learning rate: 0.0068711]
	Learning Rate: 0.00687109
	LOSS [training: 1.0911750799568882 | validation: 1.238240505337239]
	TIME [epoch: 8.35 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.259593336858132		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 1.259593336858132 | validation: 0.9908216842691724]
	TIME [epoch: 8.34 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9913205900881439		[learning rate: 0.0068387]
	Learning Rate: 0.00683871
	LOSS [training: 0.9913205900881439 | validation: 0.9576087272306548]
	TIME [epoch: 8.37 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.191878646178619		[learning rate: 0.0068226]
	Learning Rate: 0.00682258
	LOSS [training: 1.191878646178619 | validation: 0.9554852580093203]
	TIME [epoch: 8.35 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.965583832640799		[learning rate: 0.0068065]
	Learning Rate: 0.00680649
	LOSS [training: 0.965583832640799 | validation: 0.6828457661265341]
	TIME [epoch: 8.34 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7763681647938705		[learning rate: 0.0067904]
	Learning Rate: 0.00679043
	LOSS [training: 0.7763681647938705 | validation: 1.0596894538469588]
	TIME [epoch: 8.34 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9849276803124075		[learning rate: 0.0067744]
	Learning Rate: 0.00677441
	LOSS [training: 0.9849276803124075 | validation: 0.7690188134417696]
	TIME [epoch: 8.35 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0478076221561552		[learning rate: 0.0067584]
	Learning Rate: 0.00675843
	LOSS [training: 1.0478076221561552 | validation: 0.8204920983284745]
	TIME [epoch: 8.36 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8468529856527303		[learning rate: 0.0067425]
	Learning Rate: 0.00674249
	LOSS [training: 0.8468529856527303 | validation: 0.6111667500832523]
	TIME [epoch: 8.34 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9352905875102614		[learning rate: 0.0067266]
	Learning Rate: 0.00672659
	LOSS [training: 0.9352905875102614 | validation: 0.8514942565169334]
	TIME [epoch: 8.34 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8323638113733187		[learning rate: 0.0067107]
	Learning Rate: 0.00671072
	LOSS [training: 0.8323638113733187 | validation: 0.6468951094666986]
	TIME [epoch: 8.34 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9483926079606585		[learning rate: 0.0066949]
	Learning Rate: 0.00669489
	LOSS [training: 0.9483926079606585 | validation: 2.3865005225725295]
	TIME [epoch: 8.36 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2799243624933798		[learning rate: 0.0066791]
	Learning Rate: 0.0066791
	LOSS [training: 1.2799243624933798 | validation: 0.770858370566029]
	TIME [epoch: 8.34 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7945455192414779		[learning rate: 0.0066633]
	Learning Rate: 0.00666334
	LOSS [training: 0.7945455192414779 | validation: 0.8086610505459984]
	TIME [epoch: 8.34 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.165473737144838		[learning rate: 0.0066476]
	Learning Rate: 0.00664763
	LOSS [training: 1.165473737144838 | validation: 0.8085905068225017]
	TIME [epoch: 8.34 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8131539928676059		[learning rate: 0.0066319]
	Learning Rate: 0.00663195
	LOSS [training: 0.8131539928676059 | validation: 0.5245348087176618]
	TIME [epoch: 8.36 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9263557792433295		[learning rate: 0.0066163]
	Learning Rate: 0.0066163
	LOSS [training: 0.9263557792433295 | validation: 1.516152019553752]
	TIME [epoch: 8.35 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1165051263774641		[learning rate: 0.0066007]
	Learning Rate: 0.0066007
	LOSS [training: 1.1165051263774641 | validation: 0.6441169301251182]
	TIME [epoch: 8.34 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0034238486075873		[learning rate: 0.0065851]
	Learning Rate: 0.00658513
	LOSS [training: 1.0034238486075873 | validation: 0.5443758846892727]
	TIME [epoch: 8.34 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7774468957822976		[learning rate: 0.0065696]
	Learning Rate: 0.00656959
	LOSS [training: 0.7774468957822976 | validation: 0.5365094126574681]
	TIME [epoch: 8.35 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7643510463053025		[learning rate: 0.0065541]
	Learning Rate: 0.0065541
	LOSS [training: 0.7643510463053025 | validation: 0.5611974920002982]
	TIME [epoch: 8.36 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8147068811983174		[learning rate: 0.0065386]
	Learning Rate: 0.00653864
	LOSS [training: 0.8147068811983174 | validation: 1.2047409834386242]
	TIME [epoch: 8.34 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9256088155408552		[learning rate: 0.0065232]
	Learning Rate: 0.00652321
	LOSS [training: 0.9256088155408552 | validation: 0.8091468894511484]
	TIME [epoch: 8.34 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9716901891900906		[learning rate: 0.0065078]
	Learning Rate: 0.00650783
	LOSS [training: 0.9716901891900906 | validation: 1.0583036115108735]
	TIME [epoch: 8.34 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8063104300577265		[learning rate: 0.0064925]
	Learning Rate: 0.00649247
	LOSS [training: 0.8063104300577265 | validation: 1.5805942722696589]
	TIME [epoch: 8.36 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2102557501625744		[learning rate: 0.0064772]
	Learning Rate: 0.00647716
	LOSS [training: 1.2102557501625744 | validation: 1.3681790823366624]
	TIME [epoch: 8.34 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9834736526863906		[learning rate: 0.0064619]
	Learning Rate: 0.00646188
	LOSS [training: 0.9834736526863906 | validation: 1.1232459812669424]
	TIME [epoch: 8.34 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.025120457295529		[learning rate: 0.0064466]
	Learning Rate: 0.00644664
	LOSS [training: 1.025120457295529 | validation: 0.8574568274837466]
	TIME [epoch: 8.34 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9190166079523893		[learning rate: 0.0064314]
	Learning Rate: 0.00643143
	LOSS [training: 0.9190166079523893 | validation: 0.8765294338242995]
	TIME [epoch: 8.36 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9881327709946259		[learning rate: 0.0064163]
	Learning Rate: 0.00641626
	LOSS [training: 0.9881327709946259 | validation: 0.5509078564882417]
	TIME [epoch: 8.35 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0769120593081956		[learning rate: 0.0064011]
	Learning Rate: 0.00640113
	LOSS [training: 1.0769120593081956 | validation: 0.71550037938666]
	TIME [epoch: 8.34 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9172070009799598		[learning rate: 0.006386]
	Learning Rate: 0.00638603
	LOSS [training: 0.9172070009799598 | validation: 1.4661898797623203]
	TIME [epoch: 8.34 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9263973586941644		[learning rate: 0.006371]
	Learning Rate: 0.00637096
	LOSS [training: 0.9263973586941644 | validation: 0.5456649723380975]
	TIME [epoch: 8.35 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.690750510392567		[learning rate: 0.0063559]
	Learning Rate: 0.00635594
	LOSS [training: 0.690750510392567 | validation: 1.034759359244454]
	TIME [epoch: 8.36 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8714117659684024		[learning rate: 0.0063409]
	Learning Rate: 0.00634094
	LOSS [training: 0.8714117659684024 | validation: 0.6179198641860648]
	TIME [epoch: 8.34 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2436276952864769		[learning rate: 0.006326]
	Learning Rate: 0.00632599
	LOSS [training: 1.2436276952864769 | validation: 0.9409822622555515]
	TIME [epoch: 8.34 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4061562144840871		[learning rate: 0.0063111]
	Learning Rate: 0.00631106
	LOSS [training: 1.4061562144840871 | validation: 0.835143825980122]
	TIME [epoch: 8.34 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7658267446582477		[learning rate: 0.0062962]
	Learning Rate: 0.00629618
	LOSS [training: 0.7658267446582477 | validation: 0.6662506881839012]
	TIME [epoch: 8.37 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9445443894630111		[learning rate: 0.0062813]
	Learning Rate: 0.00628133
	LOSS [training: 0.9445443894630111 | validation: 0.8505550479432902]
	TIME [epoch: 8.35 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8665027201010966		[learning rate: 0.0062665]
	Learning Rate: 0.00626651
	LOSS [training: 0.8665027201010966 | validation: 0.7315609113485336]
	TIME [epoch: 8.34 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7452731388880349		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.7452731388880349 | validation: 0.8169631515621826]
	TIME [epoch: 8.35 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8370792591411338		[learning rate: 0.006237]
	Learning Rate: 0.00623698
	LOSS [training: 0.8370792591411338 | validation: 0.5444385212349663]
	TIME [epoch: 8.36 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9117778555276732		[learning rate: 0.0062223]
	Learning Rate: 0.00622227
	LOSS [training: 0.9117778555276732 | validation: 0.4520113615230241]
	TIME [epoch: 8.35 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7477326967599597		[learning rate: 0.0062076]
	Learning Rate: 0.00620759
	LOSS [training: 0.7477326967599597 | validation: 1.0019988946892544]
	TIME [epoch: 8.34 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7311358118147857		[learning rate: 0.0061929]
	Learning Rate: 0.00619295
	LOSS [training: 0.7311358118147857 | validation: 0.7570857001982556]
	TIME [epoch: 8.34 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7784044301148959		[learning rate: 0.0061783]
	Learning Rate: 0.00617834
	LOSS [training: 0.7784044301148959 | validation: 0.7027261010537688]
	TIME [epoch: 8.35 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.909156692796844		[learning rate: 0.0061638]
	Learning Rate: 0.00616377
	LOSS [training: 0.909156692796844 | validation: 0.9820445481492373]
	TIME [epoch: 8.36 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0449450437655323		[learning rate: 0.0061492]
	Learning Rate: 0.00614923
	LOSS [training: 1.0449450437655323 | validation: 1.1876224601497283]
	TIME [epoch: 8.34 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9775168886149576		[learning rate: 0.0061347]
	Learning Rate: 0.00613472
	LOSS [training: 0.9775168886149576 | validation: 0.840375416121589]
	TIME [epoch: 8.34 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6401363642406261		[learning rate: 0.0061203]
	Learning Rate: 0.00612025
	LOSS [training: 0.6401363642406261 | validation: 0.6779769485349045]
	TIME [epoch: 8.34 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3421333418180723		[learning rate: 0.0061058]
	Learning Rate: 0.00610581
	LOSS [training: 1.3421333418180723 | validation: 1.0097161293510406]
	TIME [epoch: 8.36 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9431336118634569		[learning rate: 0.0060914]
	Learning Rate: 0.00609141
	LOSS [training: 0.9431336118634569 | validation: 0.7296021680716704]
	TIME [epoch: 8.34 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8719974292105659		[learning rate: 0.006077]
	Learning Rate: 0.00607704
	LOSS [training: 0.8719974292105659 | validation: 0.6193436960088757]
	TIME [epoch: 8.34 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6790727240285221		[learning rate: 0.0060627]
	Learning Rate: 0.00606271
	LOSS [training: 0.6790727240285221 | validation: 0.4375066615885386]
	TIME [epoch: 8.34 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6748344277613288		[learning rate: 0.0060484]
	Learning Rate: 0.00604841
	LOSS [training: 0.6748344277613288 | validation: 0.6396107307635671]
	TIME [epoch: 8.36 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.081898283829572		[learning rate: 0.0060341]
	Learning Rate: 0.00603414
	LOSS [training: 1.081898283829572 | validation: 0.9306949088091201]
	TIME [epoch: 8.35 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8454604183708936		[learning rate: 0.0060199]
	Learning Rate: 0.00601991
	LOSS [training: 0.8454604183708936 | validation: 0.5290191626525406]
	TIME [epoch: 8.34 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7908055420559089		[learning rate: 0.0060057]
	Learning Rate: 0.00600571
	LOSS [training: 0.7908055420559089 | validation: 1.0688396620189566]
	TIME [epoch: 8.34 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7080983299341785		[learning rate: 0.0059915]
	Learning Rate: 0.00599154
	LOSS [training: 0.7080983299341785 | validation: 0.7495706570125436]
	TIME [epoch: 8.35 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6614940378138401		[learning rate: 0.0059774]
	Learning Rate: 0.00597741
	LOSS [training: 0.6614940378138401 | validation: 0.5383184938328518]
	TIME [epoch: 8.36 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6974002075491649		[learning rate: 0.0059633]
	Learning Rate: 0.00596331
	LOSS [training: 0.6974002075491649 | validation: 0.5252877752613837]
	TIME [epoch: 8.34 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.794720283949345		[learning rate: 0.0059492]
	Learning Rate: 0.00594924
	LOSS [training: 0.794720283949345 | validation: 1.5321974141326469]
	TIME [epoch: 8.34 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7312808813304754		[learning rate: 0.0059352]
	Learning Rate: 0.00593521
	LOSS [training: 0.7312808813304754 | validation: 0.538615271997385]
	TIME [epoch: 8.34 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8012436975131095		[learning rate: 0.0059212]
	Learning Rate: 0.00592121
	LOSS [training: 0.8012436975131095 | validation: 1.3115842883687074]
	TIME [epoch: 8.36 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7617240495348486		[learning rate: 0.0059072]
	Learning Rate: 0.00590724
	LOSS [training: 0.7617240495348486 | validation: 0.6541237199018575]
	TIME [epoch: 8.34 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6974872728498603		[learning rate: 0.0058933]
	Learning Rate: 0.00589331
	LOSS [training: 0.6974872728498603 | validation: 0.8538100065753824]
	TIME [epoch: 8.34 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8327215248474514		[learning rate: 0.0058794]
	Learning Rate: 0.0058794
	LOSS [training: 0.8327215248474514 | validation: 0.5288942138790594]
	TIME [epoch: 8.34 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8347338706370728		[learning rate: 0.0058655]
	Learning Rate: 0.00586554
	LOSS [training: 0.8347338706370728 | validation: 0.44558342718651944]
	TIME [epoch: 8.36 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6256443547290174		[learning rate: 0.0058517]
	Learning Rate: 0.0058517
	LOSS [training: 0.6256443547290174 | validation: 0.7445563305562674]
	TIME [epoch: 8.35 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7107910095289094		[learning rate: 0.0058379]
	Learning Rate: 0.0058379
	LOSS [training: 0.7107910095289094 | validation: 0.6017995229395874]
	TIME [epoch: 8.34 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5853096152602623		[learning rate: 0.0058241]
	Learning Rate: 0.00582413
	LOSS [training: 0.5853096152602623 | validation: 0.6596332091673135]
	TIME [epoch: 8.34 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.797439043883689		[learning rate: 0.0058104]
	Learning Rate: 0.00581039
	LOSS [training: 0.797439043883689 | validation: 0.4451609493964246]
	TIME [epoch: 8.34 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7410850789539227		[learning rate: 0.0057967]
	Learning Rate: 0.00579668
	LOSS [training: 0.7410850789539227 | validation: 0.462692172425175]
	TIME [epoch: 8.36 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6924225610798296		[learning rate: 0.005783]
	Learning Rate: 0.00578301
	LOSS [training: 0.6924225610798296 | validation: 0.3770601932019991]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8561647205352468		[learning rate: 0.0057694]
	Learning Rate: 0.00576937
	LOSS [training: 0.8561647205352468 | validation: 0.5430122141179198]
	TIME [epoch: 8.33 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7641765146177382		[learning rate: 0.0057558]
	Learning Rate: 0.00575576
	LOSS [training: 0.7641765146177382 | validation: 0.6264336120992069]
	TIME [epoch: 8.33 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6793678745129398		[learning rate: 0.0057422]
	Learning Rate: 0.00574218
	LOSS [training: 0.6793678745129398 | validation: 0.5091865386027423]
	TIME [epoch: 8.36 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6665207140461299		[learning rate: 0.0057286]
	Learning Rate: 0.00572864
	LOSS [training: 0.6665207140461299 | validation: 0.3959313432700922]
	TIME [epoch: 8.33 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5612912805692812		[learning rate: 0.0057151]
	Learning Rate: 0.00571512
	LOSS [training: 0.5612912805692812 | validation: 0.7993123811136019]
	TIME [epoch: 8.33 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9663958342437112		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.9663958342437112 | validation: 0.6190217242986711]
	TIME [epoch: 8.33 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6650466612208679		[learning rate: 0.0056882]
	Learning Rate: 0.00568819
	LOSS [training: 0.6650466612208679 | validation: 0.6115726217051243]
	TIME [epoch: 8.35 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6126041290972183		[learning rate: 0.0056748]
	Learning Rate: 0.00567478
	LOSS [training: 0.6126041290972183 | validation: 0.8172485760225179]
	TIME [epoch: 8.34 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6730375368099832		[learning rate: 0.0056614]
	Learning Rate: 0.00566139
	LOSS [training: 0.6730375368099832 | validation: 0.8798921888234292]
	TIME [epoch: 8.33 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9903105159032114		[learning rate: 0.005648]
	Learning Rate: 0.00564804
	LOSS [training: 0.9903105159032114 | validation: 0.6462075000371903]
	TIME [epoch: 8.33 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7749509089646875		[learning rate: 0.0056347]
	Learning Rate: 0.00563471
	LOSS [training: 0.7749509089646875 | validation: 0.4714881634773316]
	TIME [epoch: 8.35 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7211168378111411		[learning rate: 0.0056214]
	Learning Rate: 0.00562142
	LOSS [training: 0.7211168378111411 | validation: 0.7330812600811756]
	TIME [epoch: 8.35 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7884199486880534		[learning rate: 0.0056082]
	Learning Rate: 0.00560816
	LOSS [training: 0.7884199486880534 | validation: 0.6077555464827198]
	TIME [epoch: 8.33 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7096977601842892		[learning rate: 0.0055949]
	Learning Rate: 0.00559493
	LOSS [training: 0.7096977601842892 | validation: 0.9672248656070277]
	TIME [epoch: 8.33 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8388365690836842		[learning rate: 0.0055817]
	Learning Rate: 0.00558173
	LOSS [training: 0.8388365690836842 | validation: 0.7938218869295053]
	TIME [epoch: 8.33 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7884861402225026		[learning rate: 0.0055686]
	Learning Rate: 0.00556857
	LOSS [training: 0.7884861402225026 | validation: 1.1269283255523845]
	TIME [epoch: 8.36 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7570166805615737		[learning rate: 0.0055554]
	Learning Rate: 0.00555543
	LOSS [training: 0.7570166805615737 | validation: 0.650256998396336]
	TIME [epoch: 8.34 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6225129373111598		[learning rate: 0.0055423]
	Learning Rate: 0.00554233
	LOSS [training: 0.6225129373111598 | validation: 0.4546868699462572]
	TIME [epoch: 8.33 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7035513423732171		[learning rate: 0.0055293]
	Learning Rate: 0.00552926
	LOSS [training: 0.7035513423732171 | validation: 0.3748745779769914]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5705668745190987		[learning rate: 0.0055162]
	Learning Rate: 0.00551621
	LOSS [training: 0.5705668745190987 | validation: 0.9659206923038591]
	TIME [epoch: 8.36 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8329060474203744		[learning rate: 0.0055032]
	Learning Rate: 0.0055032
	LOSS [training: 0.8329060474203744 | validation: 0.5295050629754197]
	TIME [epoch: 8.34 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7606833531304419		[learning rate: 0.0054902]
	Learning Rate: 0.00549022
	LOSS [training: 0.7606833531304419 | validation: 0.4917893088632665]
	TIME [epoch: 8.33 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7064766180851593		[learning rate: 0.0054773]
	Learning Rate: 0.00547727
	LOSS [training: 0.7064766180851593 | validation: 0.4418749423385798]
	TIME [epoch: 8.33 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6366176647302447		[learning rate: 0.0054643]
	Learning Rate: 0.00546435
	LOSS [training: 0.6366176647302447 | validation: 1.2249594913593271]
	TIME [epoch: 8.34 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8285111937920728		[learning rate: 0.0054515]
	Learning Rate: 0.00545146
	LOSS [training: 0.8285111937920728 | validation: 0.779546586527281]
	TIME [epoch: 8.35 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6450463660284209		[learning rate: 0.0054386]
	Learning Rate: 0.0054386
	LOSS [training: 0.6450463660284209 | validation: 0.6411439141652981]
	TIME [epoch: 8.34 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6200564615621906		[learning rate: 0.0054258]
	Learning Rate: 0.00542577
	LOSS [training: 0.6200564615621906 | validation: 0.44043247206652325]
	TIME [epoch: 8.33 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9141990216560151		[learning rate: 0.005413]
	Learning Rate: 0.00541297
	LOSS [training: 0.9141990216560151 | validation: 0.616943285070747]
	TIME [epoch: 8.34 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9695243327187979		[learning rate: 0.0054002]
	Learning Rate: 0.00540021
	LOSS [training: 0.9695243327187979 | validation: 0.45577854499408277]
	TIME [epoch: 8.36 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6282815731106302		[learning rate: 0.0053875]
	Learning Rate: 0.00538747
	LOSS [training: 0.6282815731106302 | validation: 0.5990122594479868]
	TIME [epoch: 8.33 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.795586586210418		[learning rate: 0.0053748]
	Learning Rate: 0.00537476
	LOSS [training: 0.795586586210418 | validation: 1.3292061977779945]
	TIME [epoch: 8.33 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.694225649528159		[learning rate: 0.0053621]
	Learning Rate: 0.00536208
	LOSS [training: 0.694225649528159 | validation: 0.588704165860838]
	TIME [epoch: 8.33 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7692672332081059		[learning rate: 0.0053494]
	Learning Rate: 0.00534943
	LOSS [training: 0.7692672332081059 | validation: 0.5817533201588623]
	TIME [epoch: 8.35 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.523609214701733		[learning rate: 0.0053368]
	Learning Rate: 0.00533681
	LOSS [training: 0.523609214701733 | validation: 0.6357779391661673]
	TIME [epoch: 8.34 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6511395910822776		[learning rate: 0.0053242]
	Learning Rate: 0.00532423
	LOSS [training: 0.6511395910822776 | validation: 0.691873415569462]
	TIME [epoch: 8.33 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5753683264702845		[learning rate: 0.0053117]
	Learning Rate: 0.00531167
	LOSS [training: 0.5753683264702845 | validation: 1.114052271379332]
	TIME [epoch: 8.33 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8834783128121344		[learning rate: 0.0052991]
	Learning Rate: 0.00529914
	LOSS [training: 0.8834783128121344 | validation: 1.0281013790439886]
	TIME [epoch: 8.34 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6533709659551871		[learning rate: 0.0052866]
	Learning Rate: 0.00528664
	LOSS [training: 0.6533709659551871 | validation: 0.9645515125566884]
	TIME [epoch: 8.35 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8172878384756107		[learning rate: 0.0052742]
	Learning Rate: 0.00527417
	LOSS [training: 0.8172878384756107 | validation: 0.46823063335836934]
	TIME [epoch: 8.33 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5765437847519133		[learning rate: 0.0052617]
	Learning Rate: 0.00526173
	LOSS [training: 0.5765437847519133 | validation: 0.6574652908777523]
	TIME [epoch: 8.34 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7019261118731418		[learning rate: 0.0052493]
	Learning Rate: 0.00524931
	LOSS [training: 0.7019261118731418 | validation: 0.530492983123203]
	TIME [epoch: 8.33 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.519581155452432		[learning rate: 0.0052369]
	Learning Rate: 0.00523693
	LOSS [training: 2.519581155452432 | validation: 1.2049976919947611]
	TIME [epoch: 8.36 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7324606637142389		[learning rate: 0.0052246]
	Learning Rate: 0.00522458
	LOSS [training: 0.7324606637142389 | validation: 0.7144276000373952]
	TIME [epoch: 8.33 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6359333751847938		[learning rate: 0.0052123]
	Learning Rate: 0.00521225
	LOSS [training: 0.6359333751847938 | validation: 0.6938332327461585]
	TIME [epoch: 8.33 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5234070567196546		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.5234070567196546 | validation: 0.6815136047813832]
	TIME [epoch: 8.33 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5694369333550486		[learning rate: 0.0051877]
	Learning Rate: 0.00518769
	LOSS [training: 0.5694369333550486 | validation: 0.3931592332662879]
	TIME [epoch: 8.36 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6039821750072052		[learning rate: 0.0051755]
	Learning Rate: 0.00517546
	LOSS [training: 0.6039821750072052 | validation: 0.7604755145315862]
	TIME [epoch: 8.34 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47598623217133806		[learning rate: 0.0051632]
	Learning Rate: 0.00516325
	LOSS [training: 0.47598623217133806 | validation: 1.3519786582838016]
	TIME [epoch: 8.33 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8163373565617997		[learning rate: 0.0051511]
	Learning Rate: 0.00515107
	LOSS [training: 0.8163373565617997 | validation: 0.774693779161859]
	TIME [epoch: 8.33 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5948552703217344		[learning rate: 0.0051389]
	Learning Rate: 0.00513892
	LOSS [training: 0.5948552703217344 | validation: 0.4005439340517404]
	TIME [epoch: 8.34 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6046494719014348		[learning rate: 0.0051268]
	Learning Rate: 0.0051268
	LOSS [training: 0.6046494719014348 | validation: 0.5722155035136552]
	TIME [epoch: 8.35 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6479009594805162		[learning rate: 0.0051147]
	Learning Rate: 0.0051147
	LOSS [training: 0.6479009594805162 | validation: 0.5066214867193645]
	TIME [epoch: 8.34 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6399206321934028		[learning rate: 0.0051026]
	Learning Rate: 0.00510264
	LOSS [training: 0.6399206321934028 | validation: 0.7001763578253376]
	TIME [epoch: 8.33 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6090802001357574		[learning rate: 0.0050906]
	Learning Rate: 0.0050906
	LOSS [training: 0.6090802001357574 | validation: 0.4854835066085569]
	TIME [epoch: 8.33 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5138863906522112		[learning rate: 0.0050786]
	Learning Rate: 0.00507859
	LOSS [training: 0.5138863906522112 | validation: 0.46649352749130935]
	TIME [epoch: 8.36 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6468306412595848		[learning rate: 0.0050666]
	Learning Rate: 0.00506661
	LOSS [training: 0.6468306412595848 | validation: 1.1829908941901626]
	TIME [epoch: 8.34 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8200843860992905		[learning rate: 0.0050547]
	Learning Rate: 0.00505466
	LOSS [training: 0.8200843860992905 | validation: 0.6482296926980923]
	TIME [epoch: 8.33 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5577196500465349		[learning rate: 0.0050427]
	Learning Rate: 0.00504274
	LOSS [training: 0.5577196500465349 | validation: 0.4800488216983866]
	TIME [epoch: 8.33 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7350525687724051		[learning rate: 0.0050308]
	Learning Rate: 0.00503085
	LOSS [training: 0.7350525687724051 | validation: 0.3599490476728364]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_341.pth
	Model improved!!!
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8131695028761229		[learning rate: 0.005019]
	Learning Rate: 0.00501898
	LOSS [training: 0.8131695028761229 | validation: 0.3676493247253462]
	TIME [epoch: 8.34 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6267568696052225		[learning rate: 0.0050071]
	Learning Rate: 0.00500714
	LOSS [training: 0.6267568696052225 | validation: 0.6392507930415552]
	TIME [epoch: 8.34 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7233035412484967		[learning rate: 0.0049953]
	Learning Rate: 0.00499533
	LOSS [training: 0.7233035412484967 | validation: 0.702715663716468]
	TIME [epoch: 8.34 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5478511864836998		[learning rate: 0.0049835]
	Learning Rate: 0.00498355
	LOSS [training: 0.5478511864836998 | validation: 0.7572464654712412]
	TIME [epoch: 8.34 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5657169052662221		[learning rate: 0.0049718]
	Learning Rate: 0.00497179
	LOSS [training: 0.5657169052662221 | validation: 0.4761452171060417]
	TIME [epoch: 8.35 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7332493071122878		[learning rate: 0.0049601]
	Learning Rate: 0.00496006
	LOSS [training: 0.7332493071122878 | validation: 0.5124709779518282]
	TIME [epoch: 8.33 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7401072204108651		[learning rate: 0.0049484]
	Learning Rate: 0.00494836
	LOSS [training: 0.7401072204108651 | validation: 0.5220458224651155]
	TIME [epoch: 8.34 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.584420427018395		[learning rate: 0.0049367]
	Learning Rate: 0.00493669
	LOSS [training: 0.584420427018395 | validation: 0.8378455433427976]
	TIME [epoch: 8.33 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.538231420891974		[learning rate: 0.004925]
	Learning Rate: 0.00492505
	LOSS [training: 0.538231420891974 | validation: 0.6685032557237329]
	TIME [epoch: 8.36 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9661085602804087		[learning rate: 0.0049134]
	Learning Rate: 0.00491343
	LOSS [training: 0.9661085602804087 | validation: 0.7631497744025053]
	TIME [epoch: 8.33 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6546971400568192		[learning rate: 0.0049018]
	Learning Rate: 0.00490184
	LOSS [training: 0.6546971400568192 | validation: 0.3813836597143274]
	TIME [epoch: 8.34 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6883852963392834		[learning rate: 0.0048903]
	Learning Rate: 0.00489028
	LOSS [training: 0.6883852963392834 | validation: 0.7958111328503215]
	TIME [epoch: 8.34 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8124937384583681		[learning rate: 0.0048787]
	Learning Rate: 0.00487874
	LOSS [training: 0.8124937384583681 | validation: 0.7120203392055471]
	TIME [epoch: 8.35 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6540600114312574		[learning rate: 0.0048672]
	Learning Rate: 0.00486723
	LOSS [training: 0.6540600114312574 | validation: 0.6338516744979718]
	TIME [epoch: 8.34 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7260915589190755		[learning rate: 0.0048558]
	Learning Rate: 0.00485575
	LOSS [training: 0.7260915589190755 | validation: 0.5456124896492482]
	TIME [epoch: 8.34 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49659952298922505		[learning rate: 0.0048443]
	Learning Rate: 0.0048443
	LOSS [training: 0.49659952298922505 | validation: 0.6230831938925389]
	TIME [epoch: 8.33 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5800318381318141		[learning rate: 0.0048329]
	Learning Rate: 0.00483287
	LOSS [training: 0.5800318381318141 | validation: 0.6027112997991788]
	TIME [epoch: 8.34 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6639958053496698		[learning rate: 0.0048215]
	Learning Rate: 0.00482147
	LOSS [training: 0.6639958053496698 | validation: 0.6146301075012577]
	TIME [epoch: 8.35 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7589133601399343		[learning rate: 0.0048101]
	Learning Rate: 0.0048101
	LOSS [training: 0.7589133601399343 | validation: 0.9300511266058302]
	TIME [epoch: 8.34 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5725706825274005		[learning rate: 0.0047988]
	Learning Rate: 0.00479875
	LOSS [training: 0.5725706825274005 | validation: 0.4497283392561231]
	TIME [epoch: 8.33 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6449935399884151		[learning rate: 0.0047874]
	Learning Rate: 0.00478743
	LOSS [training: 0.6449935399884151 | validation: 0.8504839289777315]
	TIME [epoch: 8.33 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5601897336522123		[learning rate: 0.0047761]
	Learning Rate: 0.00477614
	LOSS [training: 0.5601897336522123 | validation: 0.5659850806747231]
	TIME [epoch: 8.36 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5727305081760374		[learning rate: 0.0047649]
	Learning Rate: 0.00476487
	LOSS [training: 0.5727305081760374 | validation: 0.4180799912537366]
	TIME [epoch: 8.34 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5870829420258257		[learning rate: 0.0047536]
	Learning Rate: 0.00475363
	LOSS [training: 0.5870829420258257 | validation: 0.9352284543501213]
	TIME [epoch: 8.34 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5332382707930708		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.5332382707930708 | validation: 0.38010940784845415]
	TIME [epoch: 8.33 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5224211350568273		[learning rate: 0.0047312]
	Learning Rate: 0.00473123
	LOSS [training: 0.5224211350568273 | validation: 0.7204692383343875]
	TIME [epoch: 8.36 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5132274592580969		[learning rate: 0.0047201]
	Learning Rate: 0.00472007
	LOSS [training: 0.5132274592580969 | validation: 0.3205831522013423]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_368.pth
	Model improved!!!
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6826351681734236		[learning rate: 0.0047089]
	Learning Rate: 0.00470894
	LOSS [training: 0.6826351681734236 | validation: 0.45153054312455043]
	TIME [epoch: 8.33 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6727765904640619		[learning rate: 0.0046978]
	Learning Rate: 0.00469783
	LOSS [training: 0.6727765904640619 | validation: 0.7955274963200514]
	TIME [epoch: 8.33 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.701528244687376		[learning rate: 0.0046868]
	Learning Rate: 0.00468675
	LOSS [training: 0.701528244687376 | validation: 0.5563850744950933]
	TIME [epoch: 8.34 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5868750308826403		[learning rate: 0.0046757]
	Learning Rate: 0.00467569
	LOSS [training: 0.5868750308826403 | validation: 0.7124255216399786]
	TIME [epoch: 8.35 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5569885119508978		[learning rate: 0.0046647]
	Learning Rate: 0.00466467
	LOSS [training: 0.5569885119508978 | validation: 0.5812239631294336]
	TIME [epoch: 8.33 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6115237424967049		[learning rate: 0.0046537]
	Learning Rate: 0.00465366
	LOSS [training: 0.6115237424967049 | validation: 0.54535277544004]
	TIME [epoch: 8.33 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6409013133586889		[learning rate: 0.0046427]
	Learning Rate: 0.00464268
	LOSS [training: 0.6409013133586889 | validation: 0.6367326104886641]
	TIME [epoch: 8.33 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.69667441786121		[learning rate: 0.0046317]
	Learning Rate: 0.00463173
	LOSS [training: 0.69667441786121 | validation: 0.43165205517278443]
	TIME [epoch: 8.36 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5380209992156993		[learning rate: 0.0046208]
	Learning Rate: 0.00462081
	LOSS [training: 0.5380209992156993 | validation: 0.5360124669634025]
	TIME [epoch: 8.33 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5625871591376067		[learning rate: 0.0046099]
	Learning Rate: 0.00460991
	LOSS [training: 0.5625871591376067 | validation: 0.4494728739678045]
	TIME [epoch: 8.34 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2055705735800555		[learning rate: 0.004599]
	Learning Rate: 0.00459903
	LOSS [training: 1.2055705735800555 | validation: 0.5952984248494563]
	TIME [epoch: 8.34 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7443551664937634		[learning rate: 0.0045882]
	Learning Rate: 0.00458819
	LOSS [training: 0.7443551664937634 | validation: 0.44496774296474756]
	TIME [epoch: 8.36 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5772819921304015		[learning rate: 0.0045774]
	Learning Rate: 0.00457736
	LOSS [training: 0.5772819921304015 | validation: 0.4790303212305755]
	TIME [epoch: 8.34 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5560638434267695		[learning rate: 0.0045666]
	Learning Rate: 0.00456657
	LOSS [training: 0.5560638434267695 | validation: 0.6494472771484445]
	TIME [epoch: 8.33 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6092131918767368		[learning rate: 0.0045558]
	Learning Rate: 0.00455579
	LOSS [training: 0.6092131918767368 | validation: 0.6259777287879569]
	TIME [epoch: 8.33 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5575545253840899		[learning rate: 0.004545]
	Learning Rate: 0.00454505
	LOSS [training: 0.5575545253840899 | validation: 0.5054858492209506]
	TIME [epoch: 8.35 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6707922821568806		[learning rate: 0.0045343]
	Learning Rate: 0.00453433
	LOSS [training: 0.6707922821568806 | validation: 0.47212532237876575]
	TIME [epoch: 8.35 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5769580152084053		[learning rate: 0.0045236]
	Learning Rate: 0.00452363
	LOSS [training: 0.5769580152084053 | validation: 0.5381500801493571]
	TIME [epoch: 8.33 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6524139807156053		[learning rate: 0.004513]
	Learning Rate: 0.00451296
	LOSS [training: 0.6524139807156053 | validation: 0.42500325220443524]
	TIME [epoch: 8.33 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7373462693059738		[learning rate: 0.0045023]
	Learning Rate: 0.00450232
	LOSS [training: 0.7373462693059738 | validation: 1.1226822571806072]
	TIME [epoch: 8.33 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6632845455942448		[learning rate: 0.0044917]
	Learning Rate: 0.00449169
	LOSS [training: 0.6632845455942448 | validation: 0.35645165067493745]
	TIME [epoch: 8.36 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4379198901489737		[learning rate: 0.0044811]
	Learning Rate: 0.0044811
	LOSS [training: 0.4379198901489737 | validation: 0.5197820767395164]
	TIME [epoch: 8.34 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6699469429074408		[learning rate: 0.0044705]
	Learning Rate: 0.00447053
	LOSS [training: 0.6699469429074408 | validation: 0.40092550033409813]
	TIME [epoch: 8.33 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7008030581096919		[learning rate: 0.00446]
	Learning Rate: 0.00445998
	LOSS [training: 0.7008030581096919 | validation: 0.4349416950953309]
	TIME [epoch: 8.33 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5660920960899263		[learning rate: 0.0044495]
	Learning Rate: 0.00444946
	LOSS [training: 0.5660920960899263 | validation: 0.4999075069512559]
	TIME [epoch: 8.36 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5241833921155934		[learning rate: 0.004439]
	Learning Rate: 0.00443897
	LOSS [training: 0.5241833921155934 | validation: 0.3880751666704232]
	TIME [epoch: 8.34 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5210683864408857		[learning rate: 0.0044285]
	Learning Rate: 0.0044285
	LOSS [training: 0.5210683864408857 | validation: 1.1456206197766314]
	TIME [epoch: 8.34 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.761989659516466		[learning rate: 0.0044181]
	Learning Rate: 0.00441805
	LOSS [training: 0.761989659516466 | validation: 0.4854095221771181]
	TIME [epoch: 8.34 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5152071758321639		[learning rate: 0.0044076]
	Learning Rate: 0.00440763
	LOSS [training: 0.5152071758321639 | validation: 0.4851730717053282]
	TIME [epoch: 8.34 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6001042309694365		[learning rate: 0.0043972]
	Learning Rate: 0.00439723
	LOSS [training: 0.6001042309694365 | validation: 0.5364028571819819]
	TIME [epoch: 8.35 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5615456507835835		[learning rate: 0.0043869]
	Learning Rate: 0.00438686
	LOSS [training: 0.5615456507835835 | validation: 0.6022077985751684]
	TIME [epoch: 8.33 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5607488376256736		[learning rate: 0.0043765]
	Learning Rate: 0.00437651
	LOSS [training: 0.5607488376256736 | validation: 0.3965844703184699]
	TIME [epoch: 8.33 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5775627417264048		[learning rate: 0.0043662]
	Learning Rate: 0.00436619
	LOSS [training: 0.5775627417264048 | validation: 0.35481464429560294]
	TIME [epoch: 8.34 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6116965391983074		[learning rate: 0.0043559]
	Learning Rate: 0.00435589
	LOSS [training: 0.6116965391983074 | validation: 0.5003549998016388]
	TIME [epoch: 8.36 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5148940591415352		[learning rate: 0.0043456]
	Learning Rate: 0.00434561
	LOSS [training: 0.5148940591415352 | validation: 0.9975968271792361]
	TIME [epoch: 8.34 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6251950159223638		[learning rate: 0.0043354]
	Learning Rate: 0.00433536
	LOSS [training: 0.6251950159223638 | validation: 0.664620751917576]
	TIME [epoch: 8.34 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6445810322937243		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.6445810322937243 | validation: 0.7643171984772341]
	TIME [epoch: 8.34 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7377845178369634		[learning rate: 0.0043149]
	Learning Rate: 0.00431494
	LOSS [training: 0.7377845178369634 | validation: 0.31369751677725805]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_406.pth
	Model improved!!!
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5574905051174313		[learning rate: 0.0043048]
	Learning Rate: 0.00430476
	LOSS [training: 0.5574905051174313 | validation: 0.5813937744578299]
	TIME [epoch: 8.33 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7550817814862746		[learning rate: 0.0042946]
	Learning Rate: 0.0042946
	LOSS [training: 0.7550817814862746 | validation: 0.5068480262480357]
	TIME [epoch: 8.32 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5674522515280116		[learning rate: 0.0042845]
	Learning Rate: 0.00428447
	LOSS [training: 0.5674522515280116 | validation: 0.7439503407665162]
	TIME [epoch: 8.33 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7750010026676531		[learning rate: 0.0042744]
	Learning Rate: 0.00427437
	LOSS [training: 0.7750010026676531 | validation: 0.7540771680565326]
	TIME [epoch: 8.33 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6074900060094857		[learning rate: 0.0042643]
	Learning Rate: 0.00426428
	LOSS [training: 0.6074900060094857 | validation: 0.3557519331719713]
	TIME [epoch: 8.34 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5414184050031481		[learning rate: 0.0042542]
	Learning Rate: 0.00425423
	LOSS [training: 0.5414184050031481 | validation: 0.6177948774669343]
	TIME [epoch: 8.32 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8879561607047372		[learning rate: 0.0042442]
	Learning Rate: 0.00424419
	LOSS [training: 0.8879561607047372 | validation: 0.6631332687436967]
	TIME [epoch: 8.32 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5631572944607559		[learning rate: 0.0042342]
	Learning Rate: 0.00423418
	LOSS [training: 0.5631572944607559 | validation: 0.7027547866860918]
	TIME [epoch: 8.33 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5452300217353205		[learning rate: 0.0042242]
	Learning Rate: 0.00422419
	LOSS [training: 0.5452300217353205 | validation: 0.423963245075599]
	TIME [epoch: 8.35 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6010252502620589		[learning rate: 0.0042142]
	Learning Rate: 0.00421423
	LOSS [training: 0.6010252502620589 | validation: 0.45999034072327194]
	TIME [epoch: 8.32 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8202730608532434		[learning rate: 0.0042043]
	Learning Rate: 0.00420429
	LOSS [training: 0.8202730608532434 | validation: 0.41861673062362775]
	TIME [epoch: 8.33 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5125706324020634		[learning rate: 0.0041944]
	Learning Rate: 0.00419437
	LOSS [training: 0.5125706324020634 | validation: 0.534096629287317]
	TIME [epoch: 8.32 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6382607050522894		[learning rate: 0.0041845]
	Learning Rate: 0.00418448
	LOSS [training: 0.6382607050522894 | validation: 0.5492196458876099]
	TIME [epoch: 8.34 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.60587254651593		[learning rate: 0.0041746]
	Learning Rate: 0.0041746
	LOSS [training: 0.60587254651593 | validation: 0.5025581276845361]
	TIME [epoch: 8.33 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7711395044551537		[learning rate: 0.0041648]
	Learning Rate: 0.00416476
	LOSS [training: 0.7711395044551537 | validation: 0.5815478937508249]
	TIME [epoch: 8.33 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5647890946342519		[learning rate: 0.0041549]
	Learning Rate: 0.00415493
	LOSS [training: 0.5647890946342519 | validation: 0.8471267736202388]
	TIME [epoch: 8.32 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5166272865038992		[learning rate: 0.0041451]
	Learning Rate: 0.00414513
	LOSS [training: 0.5166272865038992 | validation: 0.4231514171072269]
	TIME [epoch: 8.33 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.688441399421569		[learning rate: 0.0041354]
	Learning Rate: 0.00413535
	LOSS [training: 0.688441399421569 | validation: 0.469374823240023]
	TIME [epoch: 8.34 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6788895747645192		[learning rate: 0.0041256]
	Learning Rate: 0.0041256
	LOSS [training: 0.6788895747645192 | validation: 0.9728756150212805]
	TIME [epoch: 8.32 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.763030313727206		[learning rate: 0.0041159]
	Learning Rate: 0.00411587
	LOSS [training: 0.763030313727206 | validation: 0.9455902108434231]
	TIME [epoch: 8.32 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6980722920735895		[learning rate: 0.0041062]
	Learning Rate: 0.00410616
	LOSS [training: 0.6980722920735895 | validation: 0.6407343604881959]
	TIME [epoch: 8.32 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5347288981223194		[learning rate: 0.0040965]
	Learning Rate: 0.00409647
	LOSS [training: 0.5347288981223194 | validation: 0.4082476414884065]
	TIME [epoch: 8.34 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6510593718635725		[learning rate: 0.0040868]
	Learning Rate: 0.00408681
	LOSS [training: 0.6510593718635725 | validation: 0.7700078740860252]
	TIME [epoch: 8.32 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7987192749984434		[learning rate: 0.0040772]
	Learning Rate: 0.00407717
	LOSS [training: 0.7987192749984434 | validation: 0.7118089799543696]
	TIME [epoch: 8.33 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5377336601992775		[learning rate: 0.0040676]
	Learning Rate: 0.00406755
	LOSS [training: 0.5377336601992775 | validation: 0.6224088239212555]
	TIME [epoch: 8.32 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6407232107179106		[learning rate: 0.004058]
	Learning Rate: 0.00405796
	LOSS [training: 0.6407232107179106 | validation: 0.7204870267208772]
	TIME [epoch: 8.35 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7773193286143398		[learning rate: 0.0040484]
	Learning Rate: 0.00404839
	LOSS [training: 0.7773193286143398 | validation: 0.5679435892229955]
	TIME [epoch: 8.33 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6510390311237431		[learning rate: 0.0040388]
	Learning Rate: 0.00403884
	LOSS [training: 0.6510390311237431 | validation: 0.9856062442190541]
	TIME [epoch: 8.32 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.634709518280766		[learning rate: 0.0040293]
	Learning Rate: 0.00402931
	LOSS [training: 0.634709518280766 | validation: 0.6507598031662489]
	TIME [epoch: 8.32 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0067833317457948		[learning rate: 0.0040198]
	Learning Rate: 0.00401981
	LOSS [training: 1.0067833317457948 | validation: 1.3390646486311168]
	TIME [epoch: 8.33 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9737860460663539		[learning rate: 0.0040103]
	Learning Rate: 0.00401032
	LOSS [training: 0.9737860460663539 | validation: 0.6021730884775893]
	TIME [epoch: 8.34 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5845268773187318		[learning rate: 0.0040009]
	Learning Rate: 0.00400086
	LOSS [training: 0.5845268773187318 | validation: 0.9062806604580191]
	TIME [epoch: 8.33 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7740122288079926		[learning rate: 0.0039914]
	Learning Rate: 0.00399143
	LOSS [training: 0.7740122288079926 | validation: 0.3873767926874526]
	TIME [epoch: 8.32 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8063007780907885		[learning rate: 0.003982]
	Learning Rate: 0.00398201
	LOSS [training: 0.8063007780907885 | validation: 0.44682452862810196]
	TIME [epoch: 8.33 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6804281575608663		[learning rate: 0.0039726]
	Learning Rate: 0.00397262
	LOSS [training: 0.6804281575608663 | validation: 1.2009256967109563]
	TIME [epoch: 8.35 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7359702549596784		[learning rate: 0.0039632]
	Learning Rate: 0.00396325
	LOSS [training: 0.7359702549596784 | validation: 0.532268687872292]
	TIME [epoch: 8.32 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6324935636117501		[learning rate: 0.0039539]
	Learning Rate: 0.0039539
	LOSS [training: 0.6324935636117501 | validation: 0.4207272668011539]
	TIME [epoch: 8.33 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6845517289037487		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.6845517289037487 | validation: 0.4273654695100907]
	TIME [epoch: 8.32 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4744231288969785		[learning rate: 0.0039353]
	Learning Rate: 0.00393527
	LOSS [training: 0.4744231288969785 | validation: 0.3578572398758829]
	TIME [epoch: 8.34 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5484534678688162		[learning rate: 0.003926]
	Learning Rate: 0.00392599
	LOSS [training: 0.5484534678688162 | validation: 0.5085160553338439]
	TIME [epoch: 8.34 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5275146440992167		[learning rate: 0.0039167]
	Learning Rate: 0.00391672
	LOSS [training: 0.5275146440992167 | validation: 0.48102229245199213]
	TIME [epoch: 8.33 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44838152581453655		[learning rate: 0.0039075]
	Learning Rate: 0.00390749
	LOSS [training: 0.44838152581453655 | validation: 0.6052564970281709]
	TIME [epoch: 8.33 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6303091892179319		[learning rate: 0.0038983]
	Learning Rate: 0.00389827
	LOSS [training: 0.6303091892179319 | validation: 0.5509804593737069]
	TIME [epoch: 8.33 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9726295786121912		[learning rate: 0.0038891]
	Learning Rate: 0.00388907
	LOSS [training: 0.9726295786121912 | validation: 0.6365741554087319]
	TIME [epoch: 8.35 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5960373188469411		[learning rate: 0.0038799]
	Learning Rate: 0.0038799
	LOSS [training: 0.5960373188469411 | validation: 0.3741649828549562]
	TIME [epoch: 8.33 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5616124596048709		[learning rate: 0.0038707]
	Learning Rate: 0.00387075
	LOSS [training: 0.5616124596048709 | validation: 0.4040833653070257]
	TIME [epoch: 8.33 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5332353272690933		[learning rate: 0.0038616]
	Learning Rate: 0.00386162
	LOSS [training: 0.5332353272690933 | validation: 0.5880889166474376]
	TIME [epoch: 8.33 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6029830377003185		[learning rate: 0.0038525]
	Learning Rate: 0.00385251
	LOSS [training: 0.6029830377003185 | validation: 0.5539658234690326]
	TIME [epoch: 8.35 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48496921801837284		[learning rate: 0.0038434]
	Learning Rate: 0.00384342
	LOSS [training: 0.48496921801837284 | validation: 0.4317452140717497]
	TIME [epoch: 8.33 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4937933710848471		[learning rate: 0.0038344]
	Learning Rate: 0.00383435
	LOSS [training: 0.4937933710848471 | validation: 0.49848134109936126]
	TIME [epoch: 8.32 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5357376182015384		[learning rate: 0.0038253]
	Learning Rate: 0.00382531
	LOSS [training: 0.5357376182015384 | validation: 0.7837255921593488]
	TIME [epoch: 8.33 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7526487888621		[learning rate: 0.0038163]
	Learning Rate: 0.00381629
	LOSS [training: 0.7526487888621 | validation: 0.33911497187686845]
	TIME [epoch: 8.34 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4932543804194861		[learning rate: 0.0038073]
	Learning Rate: 0.00380728
	LOSS [training: 0.4932543804194861 | validation: 0.3707942791088337]
	TIME [epoch: 8.33 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5392314331162195		[learning rate: 0.0037983]
	Learning Rate: 0.0037983
	LOSS [training: 0.5392314331162195 | validation: 0.5132084045794114]
	TIME [epoch: 8.33 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9002041127483815		[learning rate: 0.0037893]
	Learning Rate: 0.00378934
	LOSS [training: 0.9002041127483815 | validation: 0.4272187274563565]
	TIME [epoch: 8.33 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46599403970652986		[learning rate: 0.0037804]
	Learning Rate: 0.00378041
	LOSS [training: 0.46599403970652986 | validation: 0.458651334651314]
	TIME [epoch: 8.33 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47850101762940983		[learning rate: 0.0037715]
	Learning Rate: 0.00377149
	LOSS [training: 0.47850101762940983 | validation: 0.5475111846544847]
	TIME [epoch: 8.36 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9677230405130766		[learning rate: 0.0037626]
	Learning Rate: 0.00376259
	LOSS [training: 0.9677230405130766 | validation: 0.615738525946318]
	TIME [epoch: 8.34 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48773234936230414		[learning rate: 0.0037537]
	Learning Rate: 0.00375372
	LOSS [training: 0.48773234936230414 | validation: 0.557032096099255]
	TIME [epoch: 8.33 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4476237761057703		[learning rate: 0.0037449]
	Learning Rate: 0.00374486
	LOSS [training: 0.4476237761057703 | validation: 0.3103447520642555]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_466.pth
	Model improved!!!
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7143806434190327		[learning rate: 0.003736]
	Learning Rate: 0.00373603
	LOSS [training: 0.7143806434190327 | validation: 0.4674284467518544]
	TIME [epoch: 8.35 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48143052229575745		[learning rate: 0.0037272]
	Learning Rate: 0.00372722
	LOSS [training: 0.48143052229575745 | validation: 0.3526838903432781]
	TIME [epoch: 8.33 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4729554043672989		[learning rate: 0.0037184]
	Learning Rate: 0.00371842
	LOSS [training: 0.4729554043672989 | validation: 0.4711454852772948]
	TIME [epoch: 8.33 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5066120871977784		[learning rate: 0.0037097]
	Learning Rate: 0.00370965
	LOSS [training: 0.5066120871977784 | validation: 1.0707290156876175]
	TIME [epoch: 8.32 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5867610107260064		[learning rate: 0.0037009]
	Learning Rate: 0.0037009
	LOSS [training: 0.5867610107260064 | validation: 0.3788515407137174]
	TIME [epoch: 8.34 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4861415857342002		[learning rate: 0.0036922]
	Learning Rate: 0.00369217
	LOSS [training: 0.4861415857342002 | validation: 0.24339753880507103]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_472.pth
	Model improved!!!
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48581479965331953		[learning rate: 0.0036835]
	Learning Rate: 0.00368346
	LOSS [training: 0.48581479965331953 | validation: 0.24545764143999366]
	TIME [epoch: 8.33 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3578263728013045		[learning rate: 0.0036748]
	Learning Rate: 0.00367478
	LOSS [training: 0.3578263728013045 | validation: 0.4921016756825273]
	TIME [epoch: 8.33 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5083987440584384		[learning rate: 0.0036661]
	Learning Rate: 0.00366611
	LOSS [training: 0.5083987440584384 | validation: 0.4057772576512191]
	TIME [epoch: 8.34 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7978047576022493		[learning rate: 0.0036575]
	Learning Rate: 0.00365746
	LOSS [training: 0.7978047576022493 | validation: 0.4524827261238158]
	TIME [epoch: 8.36 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4994395264353314		[learning rate: 0.0036488]
	Learning Rate: 0.00364883
	LOSS [training: 0.4994395264353314 | validation: 0.7000459937175294]
	TIME [epoch: 8.33 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6345852996731841		[learning rate: 0.0036402]
	Learning Rate: 0.00364022
	LOSS [training: 0.6345852996731841 | validation: 0.5706946143336707]
	TIME [epoch: 8.34 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5264285093889883		[learning rate: 0.0036316]
	Learning Rate: 0.00363164
	LOSS [training: 0.5264285093889883 | validation: 0.3061099056736489]
	TIME [epoch: 8.33 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5221898067430956		[learning rate: 0.0036231]
	Learning Rate: 0.00362307
	LOSS [training: 0.5221898067430956 | validation: 0.7209609504860512]
	TIME [epoch: 8.35 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6581308317960194		[learning rate: 0.0036145]
	Learning Rate: 0.00361453
	LOSS [training: 0.6581308317960194 | validation: 0.3835507924472581]
	TIME [epoch: 8.33 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49519220078862275		[learning rate: 0.003606]
	Learning Rate: 0.003606
	LOSS [training: 0.49519220078862275 | validation: 0.4124607833012882]
	TIME [epoch: 8.34 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5967582123905595		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.5967582123905595 | validation: 0.573559202283243]
	TIME [epoch: 8.33 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7946047078649088		[learning rate: 0.003589]
	Learning Rate: 0.00358901
	LOSS [training: 0.7946047078649088 | validation: 0.7908852359123214]
	TIME [epoch: 8.35 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6228982385793311		[learning rate: 0.0035805]
	Learning Rate: 0.00358054
	LOSS [training: 0.6228982385793311 | validation: 0.5656323686225058]
	TIME [epoch: 8.34 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6308147121220035		[learning rate: 0.0035721]
	Learning Rate: 0.0035721
	LOSS [training: 0.6308147121220035 | validation: 2.022520823487845]
	TIME [epoch: 8.34 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9716591931613534		[learning rate: 0.0035637]
	Learning Rate: 0.00356367
	LOSS [training: 0.9716591931613534 | validation: 0.5228275641238582]
	TIME [epoch: 8.33 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5012869579173244		[learning rate: 0.0035553]
	Learning Rate: 0.00355526
	LOSS [training: 0.5012869579173244 | validation: 0.37517955641152734]
	TIME [epoch: 8.35 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4177580330961265		[learning rate: 0.0035469]
	Learning Rate: 0.00354688
	LOSS [training: 0.4177580330961265 | validation: 0.32558201556088795]
	TIME [epoch: 8.37 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48318182285925737		[learning rate: 0.0035385]
	Learning Rate: 0.00353851
	LOSS [training: 0.48318182285925737 | validation: 0.5119282156193891]
	TIME [epoch: 8.33 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6203290004402419		[learning rate: 0.0035302]
	Learning Rate: 0.00353016
	LOSS [training: 0.6203290004402419 | validation: 0.6056918935832332]
	TIME [epoch: 8.34 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4352246873530949		[learning rate: 0.0035218]
	Learning Rate: 0.00352184
	LOSS [training: 0.4352246873530949 | validation: 0.553788744555824]
	TIME [epoch: 8.33 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7008560703966943		[learning rate: 0.0035135]
	Learning Rate: 0.00351353
	LOSS [training: 0.7008560703966943 | validation: 0.5694502222469717]
	TIME [epoch: 8.36 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45013579353564576		[learning rate: 0.0035052]
	Learning Rate: 0.00350524
	LOSS [training: 0.45013579353564576 | validation: 0.5676053306656039]
	TIME [epoch: 8.34 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5058670390077717		[learning rate: 0.003497]
	Learning Rate: 0.00349697
	LOSS [training: 0.5058670390077717 | validation: 0.4173062913175197]
	TIME [epoch: 8.34 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4821307395765155		[learning rate: 0.0034887]
	Learning Rate: 0.00348872
	LOSS [training: 0.4821307395765155 | validation: 0.6082232477719174]
	TIME [epoch: 8.34 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45736342345048187		[learning rate: 0.0034805]
	Learning Rate: 0.00348049
	LOSS [training: 0.45736342345048187 | validation: 0.7598357190498881]
	TIME [epoch: 8.36 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5856633692460305		[learning rate: 0.0034723]
	Learning Rate: 0.00347228
	LOSS [training: 0.5856633692460305 | validation: 0.40851002385708746]
	TIME [epoch: 8.35 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5959343370668664		[learning rate: 0.0034641]
	Learning Rate: 0.00346409
	LOSS [training: 0.5959343370668664 | validation: 0.5866078519176643]
	TIME [epoch: 8.34 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6687113510962174		[learning rate: 0.0034559]
	Learning Rate: 0.00345592
	LOSS [training: 0.6687113510962174 | validation: 0.7257611120667512]
	TIME [epoch: 8.34 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6146055507576854		[learning rate: 0.0034478]
	Learning Rate: 0.00344777
	LOSS [training: 0.6146055507576854 | validation: 0.6778972434363816]
	TIME [epoch: 8.34 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5928426952517769		[learning rate: 0.0034396]
	Learning Rate: 0.00343964
	LOSS [training: 0.5928426952517769 | validation: 0.5964588170603367]
	TIME [epoch: 8.36 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4527960643093919		[learning rate: 0.0034315]
	Learning Rate: 0.00343152
	LOSS [training: 0.4527960643093919 | validation: 0.8718346382628859]
	TIME [epoch: 8.34 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5341308227977775		[learning rate: 0.0034234]
	Learning Rate: 0.00342343
	LOSS [training: 0.5341308227977775 | validation: 0.4061876242050674]
	TIME [epoch: 8.34 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4313976180036674		[learning rate: 0.0034154]
	Learning Rate: 0.00341535
	LOSS [training: 0.4313976180036674 | validation: 0.3646423660953224]
	TIME [epoch: 8.33 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46397681327024304		[learning rate: 0.0034073]
	Learning Rate: 0.0034073
	LOSS [training: 0.46397681327024304 | validation: 0.6327183967812668]
	TIME [epoch: 8.35 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6015948457462569		[learning rate: 0.0033993]
	Learning Rate: 0.00339926
	LOSS [training: 0.6015948457462569 | validation: 0.43155252789839704]
	TIME [epoch: 8.33 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4986687396892916		[learning rate: 0.0033912]
	Learning Rate: 0.00339124
	LOSS [training: 0.4986687396892916 | validation: 0.4428577614242002]
	TIME [epoch: 8.33 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5525286570196052		[learning rate: 0.0033832]
	Learning Rate: 0.00338324
	LOSS [training: 0.5525286570196052 | validation: 0.4975470739235411]
	TIME [epoch: 8.34 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6363400470197516		[learning rate: 0.0033753]
	Learning Rate: 0.00337526
	LOSS [training: 0.6363400470197516 | validation: 0.7065951497985017]
	TIME [epoch: 8.36 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4718924995860035		[learning rate: 0.0033673]
	Learning Rate: 0.0033673
	LOSS [training: 0.4718924995860035 | validation: 0.2922775966136044]
	TIME [epoch: 8.34 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49413087324975		[learning rate: 0.0033594]
	Learning Rate: 0.00335936
	LOSS [training: 0.49413087324975 | validation: 0.5733066352739685]
	TIME [epoch: 8.34 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.793432944392258		[learning rate: 0.0033514]
	Learning Rate: 0.00335143
	LOSS [training: 0.793432944392258 | validation: 0.6176159127089222]
	TIME [epoch: 8.33 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6721126177831789		[learning rate: 0.0033435]
	Learning Rate: 0.00334353
	LOSS [training: 0.6721126177831789 | validation: 0.29563460497499583]
	TIME [epoch: 8.34 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6788093352281945		[learning rate: 0.0033356]
	Learning Rate: 0.00333564
	LOSS [training: 0.6788093352281945 | validation: 1.1352234780238994]
	TIME [epoch: 8.36 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7414457585432622		[learning rate: 0.0033278]
	Learning Rate: 0.00332777
	LOSS [training: 0.7414457585432622 | validation: 0.5435426427690602]
	TIME [epoch: 8.34 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5397960596295367		[learning rate: 0.0033199]
	Learning Rate: 0.00331992
	LOSS [training: 0.5397960596295367 | validation: 0.4021233349495549]
	TIME [epoch: 8.33 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5202446495137166		[learning rate: 0.0033121]
	Learning Rate: 0.00331209
	LOSS [training: 0.5202446495137166 | validation: 0.9104923512274782]
	TIME [epoch: 8.33 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6476524043608485		[learning rate: 0.0033043]
	Learning Rate: 0.00330428
	LOSS [training: 0.6476524043608485 | validation: 0.3534421981291009]
	TIME [epoch: 8.35 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4127723282125767		[learning rate: 0.0032965]
	Learning Rate: 0.00329649
	LOSS [training: 0.4127723282125767 | validation: 0.6460205642823351]
	TIME [epoch: 8.34 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5767029436494816		[learning rate: 0.0032887]
	Learning Rate: 0.00328871
	LOSS [training: 0.5767029436494816 | validation: 0.41800669701582227]
	TIME [epoch: 8.33 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6042531332418581		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.6042531332418581 | validation: 0.6542855305996638]
	TIME [epoch: 8.33 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6475053945601714		[learning rate: 0.0032732]
	Learning Rate: 0.00327321
	LOSS [training: 0.6475053945601714 | validation: 0.6226125222992289]
	TIME [epoch: 8.34 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6875422384839966		[learning rate: 0.0032655]
	Learning Rate: 0.00326549
	LOSS [training: 0.6875422384839966 | validation: 0.38189247400313425]
	TIME [epoch: 8.34 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4588791739598063		[learning rate: 0.0032578]
	Learning Rate: 0.00325779
	LOSS [training: 0.4588791739598063 | validation: 0.5734042775000872]
	TIME [epoch: 8.33 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6629212687732913		[learning rate: 0.0032501]
	Learning Rate: 0.00325011
	LOSS [training: 0.6629212687732913 | validation: 0.6019084277087497]
	TIME [epoch: 8.33 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6032983764824195		[learning rate: 0.0032424]
	Learning Rate: 0.00324244
	LOSS [training: 0.6032983764824195 | validation: 0.5329795652520999]
	TIME [epoch: 8.34 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6438184397495472		[learning rate: 0.0032348]
	Learning Rate: 0.00323479
	LOSS [training: 0.6438184397495472 | validation: 0.45291588900466345]
	TIME [epoch: 8.35 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9269693100232759		[learning rate: 0.0032272]
	Learning Rate: 0.00322716
	LOSS [training: 0.9269693100232759 | validation: 0.6735267025874547]
	TIME [epoch: 8.32 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4996432562153495		[learning rate: 0.0032195]
	Learning Rate: 0.00321955
	LOSS [training: 0.4996432562153495 | validation: 0.7602685466157835]
	TIME [epoch: 8.32 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4669862656169034		[learning rate: 0.003212]
	Learning Rate: 0.00321195
	LOSS [training: 0.4669862656169034 | validation: 0.5209770869778256]
	TIME [epoch: 8.33 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7206749087050689		[learning rate: 0.0032044]
	Learning Rate: 0.00320438
	LOSS [training: 0.7206749087050689 | validation: 0.627233136785916]
	TIME [epoch: 8.34 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.479439194918197		[learning rate: 0.0031968]
	Learning Rate: 0.00319682
	LOSS [training: 0.479439194918197 | validation: 0.4116108419681588]
	TIME [epoch: 8.32 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42680775848164565		[learning rate: 0.0031893]
	Learning Rate: 0.00318928
	LOSS [training: 0.42680775848164565 | validation: 0.32954778642990595]
	TIME [epoch: 8.32 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.452097030564352		[learning rate: 0.0031818]
	Learning Rate: 0.00318175
	LOSS [training: 0.452097030564352 | validation: 0.32706310716514025]
	TIME [epoch: 8.32 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38004595266112684		[learning rate: 0.0031742]
	Learning Rate: 0.00317425
	LOSS [training: 0.38004595266112684 | validation: 0.23813830258810365]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_536.pth
	Model improved!!!
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3923414428908995		[learning rate: 0.0031668]
	Learning Rate: 0.00316676
	LOSS [training: 0.3923414428908995 | validation: 0.3034153079666413]
	TIME [epoch: 8.33 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4437015867515613		[learning rate: 0.0031593]
	Learning Rate: 0.00315929
	LOSS [training: 0.4437015867515613 | validation: 0.2650428865951694]
	TIME [epoch: 8.33 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3510082448556303		[learning rate: 0.0031518]
	Learning Rate: 0.00315184
	LOSS [training: 0.3510082448556303 | validation: 0.985968122752118]
	TIME [epoch: 8.33 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4845040037469893		[learning rate: 0.0031444]
	Learning Rate: 0.0031444
	LOSS [training: 0.4845040037469893 | validation: 0.418976688182939]
	TIME [epoch: 8.33 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3320777690233586		[learning rate: 0.003137]
	Learning Rate: 0.00313699
	LOSS [training: 0.3320777690233586 | validation: 0.4334619922724954]
	TIME [epoch: 8.34 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.433860959940524		[learning rate: 0.0031296]
	Learning Rate: 0.00312959
	LOSS [training: 0.433860959940524 | validation: 0.8242833510670209]
	TIME [epoch: 8.32 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6405810361233755		[learning rate: 0.0031222]
	Learning Rate: 0.00312221
	LOSS [training: 0.6405810361233755 | validation: 0.6341014772066494]
	TIME [epoch: 8.32 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.479956771764952		[learning rate: 0.0031148]
	Learning Rate: 0.00311484
	LOSS [training: 0.479956771764952 | validation: 0.3793201861178558]
	TIME [epoch: 8.33 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5122202014738613		[learning rate: 0.0031075]
	Learning Rate: 0.00310749
	LOSS [training: 0.5122202014738613 | validation: 0.5405932024118625]
	TIME [epoch: 8.36 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6762206746533226		[learning rate: 0.0031002]
	Learning Rate: 0.00310016
	LOSS [training: 0.6762206746533226 | validation: 0.6824286817899609]
	TIME [epoch: 8.32 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4051484921794788		[learning rate: 0.0030929]
	Learning Rate: 0.00309285
	LOSS [training: 1.4051484921794788 | validation: 0.576910093454056]
	TIME [epoch: 8.32 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7567574166570995		[learning rate: 0.0030856]
	Learning Rate: 0.00308556
	LOSS [training: 0.7567574166570995 | validation: 0.5362679677871631]
	TIME [epoch: 8.32 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6498154298862683		[learning rate: 0.0030783]
	Learning Rate: 0.00307828
	LOSS [training: 0.6498154298862683 | validation: 0.44059816448230416]
	TIME [epoch: 8.34 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4770572670046695		[learning rate: 0.003071]
	Learning Rate: 0.00307102
	LOSS [training: 0.4770572670046695 | validation: 1.1803232123814118]
	TIME [epoch: 8.33 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7149998877594115		[learning rate: 0.0030638]
	Learning Rate: 0.00306377
	LOSS [training: 0.7149998877594115 | validation: 0.3360988364288927]
	TIME [epoch: 8.32 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47823867471632486		[learning rate: 0.0030565]
	Learning Rate: 0.00305654
	LOSS [training: 0.47823867471632486 | validation: 0.6152438461394618]
	TIME [epoch: 8.32 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7062934795793471		[learning rate: 0.0030493]
	Learning Rate: 0.00304933
	LOSS [training: 0.7062934795793471 | validation: 1.0123106792053433]
	TIME [epoch: 8.33 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5947619246246665		[learning rate: 0.0030421]
	Learning Rate: 0.00304214
	LOSS [training: 0.5947619246246665 | validation: 0.4486960330688421]
	TIME [epoch: 8.35 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6226628119470551		[learning rate: 0.003035]
	Learning Rate: 0.00303497
	LOSS [training: 0.6226628119470551 | validation: 0.4990359966133984]
	TIME [epoch: 8.33 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.591665958568256		[learning rate: 0.0030278]
	Learning Rate: 0.00302781
	LOSS [training: 0.591665958568256 | validation: 0.6093423183278095]
	TIME [epoch: 8.33 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5142703296096635		[learning rate: 0.0030207]
	Learning Rate: 0.00302066
	LOSS [training: 0.5142703296096635 | validation: 0.6666814032413029]
	TIME [epoch: 8.32 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6345999254229978		[learning rate: 0.0030135]
	Learning Rate: 0.00301354
	LOSS [training: 0.6345999254229978 | validation: 0.4451872501603211]
	TIME [epoch: 8.34 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.540546362992614		[learning rate: 0.0030064]
	Learning Rate: 0.00300643
	LOSS [training: 0.540546362992614 | validation: 0.5280345969444975]
	TIME [epoch: 8.32 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5351764451287061		[learning rate: 0.0029993]
	Learning Rate: 0.00299934
	LOSS [training: 0.5351764451287061 | validation: 0.7495131196134561]
	TIME [epoch: 8.32 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6160360931262079		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.6160360931262079 | validation: 0.42843924891660257]
	TIME [epoch: 8.32 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5031067187296956		[learning rate: 0.0029852]
	Learning Rate: 0.00298521
	LOSS [training: 0.5031067187296956 | validation: 0.610376493964934]
	TIME [epoch: 8.33 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6768253804666834		[learning rate: 0.0029782]
	Learning Rate: 0.00297816
	LOSS [training: 0.6768253804666834 | validation: 0.46568581357048744]
	TIME [epoch: 8.33 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39349503424824434		[learning rate: 0.0029711]
	Learning Rate: 0.00297114
	LOSS [training: 0.39349503424824434 | validation: 0.5253112019134393]
	TIME [epoch: 8.33 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4660166497168522		[learning rate: 0.0029641]
	Learning Rate: 0.00296413
	LOSS [training: 0.4660166497168522 | validation: 0.5264714399633026]
	TIME [epoch: 8.32 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4828862697994226		[learning rate: 0.0029571]
	Learning Rate: 0.00295714
	LOSS [training: 0.4828862697994226 | validation: 0.4199637111143272]
	TIME [epoch: 8.32 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.453263923016417		[learning rate: 0.0029502]
	Learning Rate: 0.00295016
	LOSS [training: 0.453263923016417 | validation: 0.362840404949064]
	TIME [epoch: 8.35 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49530171174850246		[learning rate: 0.0029432]
	Learning Rate: 0.0029432
	LOSS [training: 0.49530171174850246 | validation: 0.5417733017232357]
	TIME [epoch: 8.32 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47115511259175		[learning rate: 0.0029363]
	Learning Rate: 0.00293626
	LOSS [training: 0.47115511259175 | validation: 0.6050342903477974]
	TIME [epoch: 8.34 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3902915942204815		[learning rate: 0.0029293]
	Learning Rate: 0.00292934
	LOSS [training: 0.3902915942204815 | validation: 0.3083847621165061]
	TIME [epoch: 8.33 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3281603716494244		[learning rate: 0.0029224]
	Learning Rate: 0.00292243
	LOSS [training: 0.3281603716494244 | validation: 0.25352467868268036]
	TIME [epoch: 8.35 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3570341417560111		[learning rate: 0.0029155]
	Learning Rate: 0.00291553
	LOSS [training: 0.3570341417560111 | validation: 0.5125403552990565]
	TIME [epoch: 8.33 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45571708631082536		[learning rate: 0.0029087]
	Learning Rate: 0.00290866
	LOSS [training: 0.45571708631082536 | validation: 0.6382070982847164]
	TIME [epoch: 8.33 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5056647744854863		[learning rate: 0.0029018]
	Learning Rate: 0.00290179
	LOSS [training: 0.5056647744854863 | validation: 0.31415646822745014]
	TIME [epoch: 8.33 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4660235988398531		[learning rate: 0.0028949]
	Learning Rate: 0.00289495
	LOSS [training: 0.4660235988398531 | validation: 0.5150076625837505]
	TIME [epoch: 8.34 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48855640283491086		[learning rate: 0.0028881]
	Learning Rate: 0.00288812
	LOSS [training: 0.48855640283491086 | validation: 0.6069980752610624]
	TIME [epoch: 8.34 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5813518998668014		[learning rate: 0.0028813]
	Learning Rate: 0.00288131
	LOSS [training: 0.5813518998668014 | validation: 0.7034979782789657]
	TIME [epoch: 8.33 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5281092590256271		[learning rate: 0.0028745]
	Learning Rate: 0.00287451
	LOSS [training: 0.5281092590256271 | validation: 0.41034544433838244]
	TIME [epoch: 8.33 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5847743470910528		[learning rate: 0.0028677]
	Learning Rate: 0.00286773
	LOSS [training: 0.5847743470910528 | validation: 0.6185565540503322]
	TIME [epoch: 8.34 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4655698457788338		[learning rate: 0.002861]
	Learning Rate: 0.00286097
	LOSS [training: 0.4655698457788338 | validation: 0.4791060818344335]
	TIME [epoch: 8.35 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8314869196123575		[learning rate: 0.0028542]
	Learning Rate: 0.00285422
	LOSS [training: 0.8314869196123575 | validation: 0.7896946585693694]
	TIME [epoch: 8.32 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6643964166354585		[learning rate: 0.0028475]
	Learning Rate: 0.00284749
	LOSS [training: 0.6643964166354585 | validation: 0.3200825061345246]
	TIME [epoch: 8.33 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5488973230279592		[learning rate: 0.0028408]
	Learning Rate: 0.00284077
	LOSS [training: 0.5488973230279592 | validation: 0.5494416248057346]
	TIME [epoch: 8.33 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4433452506113431		[learning rate: 0.0028341]
	Learning Rate: 0.00283407
	LOSS [training: 0.4433452506113431 | validation: 0.6775695815970362]
	TIME [epoch: 8.35 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4570738491223293		[learning rate: 0.0028274]
	Learning Rate: 0.00282738
	LOSS [training: 0.4570738491223293 | validation: 0.45910107435997427]
	TIME [epoch: 8.32 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40501496137365917		[learning rate: 0.0028207]
	Learning Rate: 0.00282071
	LOSS [training: 0.40501496137365917 | validation: 0.3731835026755468]
	TIME [epoch: 8.33 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46207748562080375		[learning rate: 0.0028141]
	Learning Rate: 0.00281406
	LOSS [training: 0.46207748562080375 | validation: 0.4204173900788439]
	TIME [epoch: 8.33 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5139681730686679		[learning rate: 0.0028074]
	Learning Rate: 0.00280742
	LOSS [training: 0.5139681730686679 | validation: 0.3508357888434253]
	TIME [epoch: 8.34 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5691874811787043		[learning rate: 0.0028008]
	Learning Rate: 0.0028008
	LOSS [training: 0.5691874811787043 | validation: 0.3282994618784718]
	TIME [epoch: 8.33 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3985727080059022		[learning rate: 0.0027942]
	Learning Rate: 0.00279419
	LOSS [training: 0.3985727080059022 | validation: 0.4254178221163853]
	TIME [epoch: 8.34 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.576331781285475		[learning rate: 0.0027876]
	Learning Rate: 0.0027876
	LOSS [training: 0.576331781285475 | validation: 0.342898243291454]
	TIME [epoch: 8.34 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5280155107764257		[learning rate: 0.002781]
	Learning Rate: 0.00278103
	LOSS [training: 0.5280155107764257 | validation: 0.768597281707253]
	TIME [epoch: 8.33 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5287489609571484		[learning rate: 0.0027745]
	Learning Rate: 0.00277447
	LOSS [training: 0.5287489609571484 | validation: 0.477629368448768]
	TIME [epoch: 8.36 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6483357546647789		[learning rate: 0.0027679]
	Learning Rate: 0.00276792
	LOSS [training: 0.6483357546647789 | validation: 0.4976747259186436]
	TIME [epoch: 8.33 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4257668890364205		[learning rate: 0.0027614]
	Learning Rate: 0.00276139
	LOSS [training: 0.4257668890364205 | validation: 0.35926187061658754]
	TIME [epoch: 8.33 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5557657900417416		[learning rate: 0.0027549]
	Learning Rate: 0.00275488
	LOSS [training: 0.5557657900417416 | validation: 0.42332914961433277]
	TIME [epoch: 8.33 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5333608630828238		[learning rate: 0.0027484]
	Learning Rate: 0.00274838
	LOSS [training: 0.5333608630828238 | validation: 0.5550812222683308]
	TIME [epoch: 8.35 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4980351333597836		[learning rate: 0.0027419]
	Learning Rate: 0.0027419
	LOSS [training: 0.4980351333597836 | validation: 0.4134587559524586]
	TIME [epoch: 8.32 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3759773278298662		[learning rate: 0.0027354]
	Learning Rate: 0.00273543
	LOSS [training: 0.3759773278298662 | validation: 0.3304886097907012]
	TIME [epoch: 8.32 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3388776950594635		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.3388776950594635 | validation: 0.48897812975859867]
	TIME [epoch: 8.34 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49213469945046845		[learning rate: 0.0027225]
	Learning Rate: 0.00272254
	LOSS [training: 0.49213469945046845 | validation: 0.5197318865095284]
	TIME [epoch: 8.36 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45414191475142884		[learning rate: 0.0027161]
	Learning Rate: 0.00271612
	LOSS [training: 0.45414191475142884 | validation: 0.5688341056770144]
	TIME [epoch: 8.35 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5395512642430669		[learning rate: 0.0027097]
	Learning Rate: 0.00270971
	LOSS [training: 0.5395512642430669 | validation: 0.43669828553736173]
	TIME [epoch: 8.32 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38636241915078384		[learning rate: 0.0027033]
	Learning Rate: 0.00270332
	LOSS [training: 0.38636241915078384 | validation: 0.3432412997464258]
	TIME [epoch: 8.32 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4834866514570787		[learning rate: 0.0026969]
	Learning Rate: 0.00269694
	LOSS [training: 0.4834866514570787 | validation: 0.4215254186450313]
	TIME [epoch: 8.33 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4460226915905521		[learning rate: 0.0026906]
	Learning Rate: 0.00269058
	LOSS [training: 0.4460226915905521 | validation: 0.3970852008814047]
	TIME [epoch: 8.36 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5025060078655741		[learning rate: 0.0026842]
	Learning Rate: 0.00268423
	LOSS [training: 0.5025060078655741 | validation: 0.44303758615614125]
	TIME [epoch: 8.33 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.429297226859202		[learning rate: 0.0026779]
	Learning Rate: 0.0026779
	LOSS [training: 0.429297226859202 | validation: 0.5593050946068133]
	TIME [epoch: 8.33 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5082846853090988		[learning rate: 0.0026716]
	Learning Rate: 0.00267159
	LOSS [training: 0.5082846853090988 | validation: 0.2656279133116636]
	TIME [epoch: 8.33 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41048986536486237		[learning rate: 0.0026653]
	Learning Rate: 0.00266528
	LOSS [training: 0.41048986536486237 | validation: 0.48964093310721646]
	TIME [epoch: 8.36 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34084267282101993		[learning rate: 0.002659]
	Learning Rate: 0.002659
	LOSS [training: 0.34084267282101993 | validation: 0.3909853874285056]
	TIME [epoch: 8.34 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36711456584136454		[learning rate: 0.0026527]
	Learning Rate: 0.00265273
	LOSS [training: 0.36711456584136454 | validation: 0.23126019446375906]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_612.pth
	Model improved!!!
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5004241398173063		[learning rate: 0.0026465]
	Learning Rate: 0.00264647
	LOSS [training: 0.5004241398173063 | validation: 0.35700734743934864]
	TIME [epoch: 8.33 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2912134267965385		[learning rate: 0.0026402]
	Learning Rate: 0.00264023
	LOSS [training: 0.2912134267965385 | validation: 0.47143602145910357]
	TIME [epoch: 8.34 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5085852255749176		[learning rate: 0.002634]
	Learning Rate: 0.002634
	LOSS [training: 0.5085852255749176 | validation: 0.3721848160405895]
	TIME [epoch: 8.34 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3496525392668074		[learning rate: 0.0026278]
	Learning Rate: 0.00262778
	LOSS [training: 0.3496525392668074 | validation: 0.27281881004455827]
	TIME [epoch: 8.34 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4308394644194135		[learning rate: 0.0026216]
	Learning Rate: 0.00262159
	LOSS [training: 0.4308394644194135 | validation: 0.4317071061564435]
	TIME [epoch: 8.32 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4207864841496506		[learning rate: 0.0026154]
	Learning Rate: 0.0026154
	LOSS [training: 0.4207864841496506 | validation: 0.22507855305315583]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_618.pth
	Model improved!!!
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3489676377351236		[learning rate: 0.0026092]
	Learning Rate: 0.00260923
	LOSS [training: 0.3489676377351236 | validation: 0.26432915204064905]
	TIME [epoch: 8.37 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35906764764154697		[learning rate: 0.0026031]
	Learning Rate: 0.00260308
	LOSS [training: 0.35906764764154697 | validation: 0.2671223444509465]
	TIME [epoch: 8.34 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3313625758602489		[learning rate: 0.0025969]
	Learning Rate: 0.00259694
	LOSS [training: 0.3313625758602489 | validation: 0.3162629695264749]
	TIME [epoch: 8.34 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34870714079241516		[learning rate: 0.0025908]
	Learning Rate: 0.00259081
	LOSS [training: 0.34870714079241516 | validation: 0.488114143204974]
	TIME [epoch: 8.35 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3395498423307086		[learning rate: 0.0025847]
	Learning Rate: 0.0025847
	LOSS [training: 0.3395498423307086 | validation: 0.5486013003864527]
	TIME [epoch: 8.37 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3830194858445709		[learning rate: 0.0025786]
	Learning Rate: 0.0025786
	LOSS [training: 0.3830194858445709 | validation: 0.33841750856787145]
	TIME [epoch: 8.34 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37799246577853685		[learning rate: 0.0025725]
	Learning Rate: 0.00257252
	LOSS [training: 0.37799246577853685 | validation: 0.21391630889713234]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_625.pth
	Model improved!!!
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31217923629073374		[learning rate: 0.0025665]
	Learning Rate: 0.00256645
	LOSS [training: 0.31217923629073374 | validation: 0.38546808701817026]
	TIME [epoch: 8.34 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.383858183238317		[learning rate: 0.0025604]
	Learning Rate: 0.0025604
	LOSS [training: 0.383858183238317 | validation: 0.265792636567866]
	TIME [epoch: 8.36 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36129584559204836		[learning rate: 0.0025544]
	Learning Rate: 0.00255436
	LOSS [training: 0.36129584559204836 | validation: 0.4309363761253719]
	TIME [epoch: 8.34 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3607032702241165		[learning rate: 0.0025483]
	Learning Rate: 0.00254833
	LOSS [training: 0.3607032702241165 | validation: 0.2565996964591627]
	TIME [epoch: 8.34 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.376065288080307		[learning rate: 0.0025423]
	Learning Rate: 0.00254232
	LOSS [training: 0.376065288080307 | validation: 0.31223169509774484]
	TIME [epoch: 8.34 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3079547004404243		[learning rate: 0.0025363]
	Learning Rate: 0.00253633
	LOSS [training: 0.3079547004404243 | validation: 0.3926877329317889]
	TIME [epoch: 8.35 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3620309009243973		[learning rate: 0.0025303]
	Learning Rate: 0.00253034
	LOSS [training: 0.3620309009243973 | validation: 0.25805759312057075]
	TIME [epoch: 8.36 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32281098059017105		[learning rate: 0.0025244]
	Learning Rate: 0.00252437
	LOSS [training: 0.32281098059017105 | validation: 0.3542252592345821]
	TIME [epoch: 8.34 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.379221793225261		[learning rate: 0.0025184]
	Learning Rate: 0.00251842
	LOSS [training: 0.379221793225261 | validation: 0.2900780544003977]
	TIME [epoch: 8.34 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33259510120631475		[learning rate: 0.0025125]
	Learning Rate: 0.00251248
	LOSS [training: 0.33259510120631475 | validation: 0.4134295516979839]
	TIME [epoch: 8.34 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3717112964274053		[learning rate: 0.0025066]
	Learning Rate: 0.00250655
	LOSS [training: 0.3717112964274053 | validation: 0.4040038323383093]
	TIME [epoch: 8.37 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3511316421412046		[learning rate: 0.0025006]
	Learning Rate: 0.00250064
	LOSS [training: 0.3511316421412046 | validation: 0.22834078478883058]
	TIME [epoch: 8.34 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27224245328934277		[learning rate: 0.0024947]
	Learning Rate: 0.00249474
	LOSS [training: 0.27224245328934277 | validation: 0.4603296798238169]
	TIME [epoch: 8.34 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33279822436890777		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.33279822436890777 | validation: 0.3594913238530747]
	TIME [epoch: 8.34 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3611075197195226		[learning rate: 0.002483]
	Learning Rate: 0.00248299
	LOSS [training: 0.3611075197195226 | validation: 0.21418843631499113]
	TIME [epoch: 8.36 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3240397195886228		[learning rate: 0.0024771]
	Learning Rate: 0.00247713
	LOSS [training: 0.3240397195886228 | validation: 0.2954945968680548]
	TIME [epoch: 8.34 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3164589638773395		[learning rate: 0.0024713]
	Learning Rate: 0.00247129
	LOSS [training: 0.3164589638773395 | validation: 0.45416943577258245]
	TIME [epoch: 8.34 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33093233443422376		[learning rate: 0.0024655]
	Learning Rate: 0.00246546
	LOSS [training: 0.33093233443422376 | validation: 0.2703049947575977]
	TIME [epoch: 8.34 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.346039776946781		[learning rate: 0.0024596]
	Learning Rate: 0.00245964
	LOSS [training: 0.346039776946781 | validation: 0.4177324480280206]
	TIME [epoch: 8.34 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.363400079104767		[learning rate: 0.0024538]
	Learning Rate: 0.00245384
	LOSS [training: 0.363400079104767 | validation: 0.25276154935154715]
	TIME [epoch: 8.36 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48136899609439665		[learning rate: 0.0024481]
	Learning Rate: 0.00244805
	LOSS [training: 0.48136899609439665 | validation: 0.5028049954454913]
	TIME [epoch: 8.34 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3762547478538529		[learning rate: 0.0024423]
	Learning Rate: 0.00244228
	LOSS [training: 0.3762547478538529 | validation: 0.2846308453815789]
	TIME [epoch: 8.34 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3397710832091338		[learning rate: 0.0024365]
	Learning Rate: 0.00243652
	LOSS [training: 0.3397710832091338 | validation: 0.2721450105851543]
	TIME [epoch: 8.34 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4211378158029543		[learning rate: 0.0024308]
	Learning Rate: 0.00243077
	LOSS [training: 0.4211378158029543 | validation: 0.27822072458528113]
	TIME [epoch: 8.37 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2964949269810072		[learning rate: 0.002425]
	Learning Rate: 0.00242503
	LOSS [training: 0.2964949269810072 | validation: 0.35998038135853916]
	TIME [epoch: 8.34 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34718494249959		[learning rate: 0.0024193]
	Learning Rate: 0.00241931
	LOSS [training: 0.34718494249959 | validation: 0.20098525569825657]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_651.pth
	Model improved!!!
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.410844116104069		[learning rate: 0.0024136]
	Learning Rate: 0.00241361
	LOSS [training: 0.410844116104069 | validation: 0.28276398267653385]
	TIME [epoch: 8.34 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5405971223658546		[learning rate: 0.0024079]
	Learning Rate: 0.00240791
	LOSS [training: 0.5405971223658546 | validation: 0.6043274880888435]
	TIME [epoch: 8.35 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4438108184529911		[learning rate: 0.0024022]
	Learning Rate: 0.00240223
	LOSS [training: 0.4438108184529911 | validation: 0.26826619386917755]
	TIME [epoch: 8.33 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3516836215720032		[learning rate: 0.0023966]
	Learning Rate: 0.00239657
	LOSS [training: 0.3516836215720032 | validation: 0.3494723388725149]
	TIME [epoch: 8.32 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27665276362808416		[learning rate: 0.0023909]
	Learning Rate: 0.00239092
	LOSS [training: 0.27665276362808416 | validation: 0.27720999750941855]
	TIME [epoch: 8.33 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2929454878820906		[learning rate: 0.0023853]
	Learning Rate: 0.00238527
	LOSS [training: 0.2929454878820906 | validation: 0.4577602266937316]
	TIME [epoch: 8.35 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3294009469085564		[learning rate: 0.0023796]
	Learning Rate: 0.00237965
	LOSS [training: 0.3294009469085564 | validation: 0.464936280016663]
	TIME [epoch: 8.33 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3328284662418874		[learning rate: 0.002374]
	Learning Rate: 0.00237404
	LOSS [training: 0.3328284662418874 | validation: 0.8628716775581434]
	TIME [epoch: 8.33 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4938694336694328		[learning rate: 0.0023684]
	Learning Rate: 0.00236844
	LOSS [training: 0.4938694336694328 | validation: 0.4516269071640008]
	TIME [epoch: 8.33 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33644370743291496		[learning rate: 0.0023628]
	Learning Rate: 0.00236285
	LOSS [training: 0.33644370743291496 | validation: 0.3146297565453915]
	TIME [epoch: 8.33 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2634667849553923		[learning rate: 0.0023573]
	Learning Rate: 0.00235727
	LOSS [training: 0.2634667849553923 | validation: 0.20892643114121282]
	TIME [epoch: 8.35 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2936965829082759		[learning rate: 0.0023517]
	Learning Rate: 0.00235171
	LOSS [training: 0.2936965829082759 | validation: 0.2003113599271143]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_663.pth
	Model improved!!!
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3175824665750341		[learning rate: 0.0023462]
	Learning Rate: 0.00234617
	LOSS [training: 0.3175824665750341 | validation: 0.33683990163180594]
	TIME [epoch: 8.32 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7418155205047323		[learning rate: 0.0023406]
	Learning Rate: 0.00234063
	LOSS [training: 0.7418155205047323 | validation: 0.7796312837995258]
	TIME [epoch: 8.32 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3498045838271786		[learning rate: 0.0023351]
	Learning Rate: 0.00233511
	LOSS [training: 0.3498045838271786 | validation: 0.3209752363023793]
	TIME [epoch: 8.35 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25954034127676023		[learning rate: 0.0023296]
	Learning Rate: 0.0023296
	LOSS [training: 0.25954034127676023 | validation: 0.308202799333964]
	TIME [epoch: 8.33 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38089553136191007		[learning rate: 0.0023241]
	Learning Rate: 0.00232411
	LOSS [training: 0.38089553136191007 | validation: 0.532926076429703]
	TIME [epoch: 8.32 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3837727445752913		[learning rate: 0.0023186]
	Learning Rate: 0.00231863
	LOSS [training: 0.3837727445752913 | validation: 0.32897569546346994]
	TIME [epoch: 8.32 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3323797183521385		[learning rate: 0.0023132]
	Learning Rate: 0.00231316
	LOSS [training: 0.3323797183521385 | validation: 0.36470535825902817]
	TIME [epoch: 8.34 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41630986947195225		[learning rate: 0.0023077]
	Learning Rate: 0.0023077
	LOSS [training: 0.41630986947195225 | validation: 0.5152054836223904]
	TIME [epoch: 8.34 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42555434660327923		[learning rate: 0.0023023]
	Learning Rate: 0.00230226
	LOSS [training: 0.42555434660327923 | validation: 0.3158842728207027]
	TIME [epoch: 8.33 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3904464766843861		[learning rate: 0.0022968]
	Learning Rate: 0.00229683
	LOSS [training: 0.3904464766843861 | validation: 0.2604564601125655]
	TIME [epoch: 8.32 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3066311836531848		[learning rate: 0.0022914]
	Learning Rate: 0.00229141
	LOSS [training: 0.3066311836531848 | validation: 0.3628320979545311]
	TIME [epoch: 8.33 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4300470573032834		[learning rate: 0.002286]
	Learning Rate: 0.002286
	LOSS [training: 0.4300470573032834 | validation: 0.18614016559380742]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_675.pth
	Model improved!!!
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2711454915309565		[learning rate: 0.0022806]
	Learning Rate: 0.00228061
	LOSS [training: 0.2711454915309565 | validation: 0.3984968918826707]
	TIME [epoch: 8.32 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3463878306422821		[learning rate: 0.0022752]
	Learning Rate: 0.00227523
	LOSS [training: 0.3463878306422821 | validation: 0.24065933017810134]
	TIME [epoch: 8.32 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40884287524013346		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.40884287524013346 | validation: 0.33801678001813906]
	TIME [epoch: 8.32 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30099582523733315		[learning rate: 0.0022645]
	Learning Rate: 0.00226451
	LOSS [training: 0.30099582523733315 | validation: 0.44435732702388164]
	TIME [epoch: 8.35 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29729645774347874		[learning rate: 0.0022592]
	Learning Rate: 0.00225917
	LOSS [training: 0.29729645774347874 | validation: 0.4330303713592871]
	TIME [epoch: 8.32 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3193369540449673		[learning rate: 0.0022538]
	Learning Rate: 0.00225384
	LOSS [training: 0.3193369540449673 | validation: 0.3331495181985684]
	TIME [epoch: 8.33 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3214471767605316		[learning rate: 0.0022485]
	Learning Rate: 0.00224852
	LOSS [training: 0.3214471767605316 | validation: 0.22789722752314506]
	TIME [epoch: 8.32 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.334028395440425		[learning rate: 0.0022432]
	Learning Rate: 0.00224322
	LOSS [training: 0.334028395440425 | validation: 0.46105719355034314]
	TIME [epoch: 8.37 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3911483295395053		[learning rate: 0.0022379]
	Learning Rate: 0.00223793
	LOSS [training: 0.3911483295395053 | validation: 0.22435462016312002]
	TIME [epoch: 8.33 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35574039736196306		[learning rate: 0.0022326]
	Learning Rate: 0.00223265
	LOSS [training: 0.35574039736196306 | validation: 0.35097810227235665]
	TIME [epoch: 8.33 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41314440112226497		[learning rate: 0.0022274]
	Learning Rate: 0.00222738
	LOSS [training: 0.41314440112226497 | validation: 0.35917703280871127]
	TIME [epoch: 8.32 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29781455256470407		[learning rate: 0.0022221]
	Learning Rate: 0.00222213
	LOSS [training: 0.29781455256470407 | validation: 0.36232464899426736]
	TIME [epoch: 8.32 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35181271347220355		[learning rate: 0.0022169]
	Learning Rate: 0.00221689
	LOSS [training: 0.35181271347220355 | validation: 0.34875153578496126]
	TIME [epoch: 8.35 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3629008688467175		[learning rate: 0.0022117]
	Learning Rate: 0.00221166
	LOSS [training: 0.3629008688467175 | validation: 0.30235059480896953]
	TIME [epoch: 8.32 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37262460716697643		[learning rate: 0.0022064]
	Learning Rate: 0.00220644
	LOSS [training: 0.37262460716697643 | validation: 0.2922064381400924]
	TIME [epoch: 8.33 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3311603066072729		[learning rate: 0.0022012]
	Learning Rate: 0.00220124
	LOSS [training: 0.3311603066072729 | validation: 0.2156291061322994]
	TIME [epoch: 8.32 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26832707627960656		[learning rate: 0.002196]
	Learning Rate: 0.00219604
	LOSS [training: 0.26832707627960656 | validation: 0.33514365480163943]
	TIME [epoch: 8.35 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38276891878040514		[learning rate: 0.0021909]
	Learning Rate: 0.00219086
	LOSS [training: 0.38276891878040514 | validation: 0.347439667025113]
	TIME [epoch: 8.33 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3639873354223676		[learning rate: 0.0021857]
	Learning Rate: 0.0021857
	LOSS [training: 0.3639873354223676 | validation: 0.25601908021960884]
	TIME [epoch: 8.32 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29398481550849376		[learning rate: 0.0021805]
	Learning Rate: 0.00218054
	LOSS [training: 0.29398481550849376 | validation: 0.26552075348215776]
	TIME [epoch: 8.32 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25921402159787654		[learning rate: 0.0021754]
	Learning Rate: 0.0021754
	LOSS [training: 0.25921402159787654 | validation: 0.32649089429595657]
	TIME [epoch: 8.34 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30768806569271623		[learning rate: 0.0021703]
	Learning Rate: 0.00217027
	LOSS [training: 0.30768806569271623 | validation: 0.3282818664913649]
	TIME [epoch: 8.33 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4029289785843456		[learning rate: 0.0021651]
	Learning Rate: 0.00216515
	LOSS [training: 0.4029289785843456 | validation: 0.21710780645519984]
	TIME [epoch: 8.33 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2554860275918073		[learning rate: 0.00216]
	Learning Rate: 0.00216004
	LOSS [training: 0.2554860275918073 | validation: 0.2598314482273847]
	TIME [epoch: 8.33 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31947238594052096		[learning rate: 0.0021549]
	Learning Rate: 0.00215494
	LOSS [training: 0.31947238594052096 | validation: 0.2184909992119661]
	TIME [epoch: 8.32 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26826862754105785		[learning rate: 0.0021499]
	Learning Rate: 0.00214986
	LOSS [training: 0.26826862754105785 | validation: 0.3705233867197112]
	TIME [epoch: 8.35 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25658467050166184		[learning rate: 0.0021448]
	Learning Rate: 0.00214479
	LOSS [training: 0.25658467050166184 | validation: 0.33019225019297826]
	TIME [epoch: 8.33 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41785449685000886		[learning rate: 0.0021397]
	Learning Rate: 0.00213973
	LOSS [training: 0.41785449685000886 | validation: 0.39188733746801285]
	TIME [epoch: 8.32 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3136527011097131		[learning rate: 0.0021347]
	Learning Rate: 0.00213468
	LOSS [training: 0.3136527011097131 | validation: 0.4229683906642532]
	TIME [epoch: 8.32 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3097423129252654		[learning rate: 0.0021296]
	Learning Rate: 0.00212965
	LOSS [training: 0.3097423129252654 | validation: 0.2570397570863457]
	TIME [epoch: 8.34 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2582185640014619		[learning rate: 0.0021246]
	Learning Rate: 0.00212462
	LOSS [training: 0.2582185640014619 | validation: 0.3034356330931508]
	TIME [epoch: 8.33 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36562806850939644		[learning rate: 0.0021196]
	Learning Rate: 0.00211961
	LOSS [training: 0.36562806850939644 | validation: 0.22887947000740363]
	TIME [epoch: 8.32 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23764197772231288		[learning rate: 0.0021146]
	Learning Rate: 0.00211461
	LOSS [training: 0.23764197772231288 | validation: 0.39723558203853926]
	TIME [epoch: 8.32 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3058274347844402		[learning rate: 0.0021096]
	Learning Rate: 0.00210962
	LOSS [training: 0.3058274347844402 | validation: 0.2857006904156469]
	TIME [epoch: 8.34 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3123224638811155		[learning rate: 0.0021046]
	Learning Rate: 0.00210465
	LOSS [training: 0.3123224638811155 | validation: 0.26557438057232946]
	TIME [epoch: 8.33 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3150183582859561		[learning rate: 0.0020997]
	Learning Rate: 0.00209968
	LOSS [training: 0.3150183582859561 | validation: 0.351985482525402]
	TIME [epoch: 8.32 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31210208507702014		[learning rate: 0.0020947]
	Learning Rate: 0.00209473
	LOSS [training: 0.31210208507702014 | validation: 0.2135325433037834]
	TIME [epoch: 8.32 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30717645988117837		[learning rate: 0.0020898]
	Learning Rate: 0.00208979
	LOSS [training: 0.30717645988117837 | validation: 0.3531040947769817]
	TIME [epoch: 8.32 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31623470379786456		[learning rate: 0.0020849]
	Learning Rate: 0.00208486
	LOSS [training: 0.31623470379786456 | validation: 0.36572496172319174]
	TIME [epoch: 8.35 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4235765315572989		[learning rate: 0.0020799]
	Learning Rate: 0.00207994
	LOSS [training: 0.4235765315572989 | validation: 0.31976196340627405]
	TIME [epoch: 8.32 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42631241647104573		[learning rate: 0.002075]
	Learning Rate: 0.00207504
	LOSS [training: 0.42631241647104573 | validation: 0.47167817224272934]
	TIME [epoch: 8.32 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4785434327728272		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.4785434327728272 | validation: 0.29257501796475294]
	TIME [epoch: 8.32 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2969642962133269		[learning rate: 0.0020653]
	Learning Rate: 0.00206526
	LOSS [training: 0.2969642962133269 | validation: 0.27567985516070515]
	TIME [epoch: 8.35 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2665258997012755		[learning rate: 0.0020604]
	Learning Rate: 0.00206039
	LOSS [training: 0.2665258997012755 | validation: 0.407514821821939]
	TIME [epoch: 8.32 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33035058307803294		[learning rate: 0.0020555]
	Learning Rate: 0.00205553
	LOSS [training: 0.33035058307803294 | validation: 0.3988926331780302]
	TIME [epoch: 8.32 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35537305714382567		[learning rate: 0.0020507]
	Learning Rate: 0.00205068
	LOSS [training: 0.35537305714382567 | validation: 0.37853135411418937]
	TIME [epoch: 8.32 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29649587759609874		[learning rate: 0.0020458]
	Learning Rate: 0.00204584
	LOSS [training: 0.29649587759609874 | validation: 0.3311886149796386]
	TIME [epoch: 8.34 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25794680185880764		[learning rate: 0.002041]
	Learning Rate: 0.00204101
	LOSS [training: 0.25794680185880764 | validation: 0.41667590874045213]
	TIME [epoch: 8.34 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34909297387192273		[learning rate: 0.0020362]
	Learning Rate: 0.0020362
	LOSS [training: 0.34909297387192273 | validation: 0.21410887809018503]
	TIME [epoch: 8.32 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2643680249749835		[learning rate: 0.0020314]
	Learning Rate: 0.0020314
	LOSS [training: 0.2643680249749835 | validation: 0.3554288513336086]
	TIME [epoch: 8.32 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32463839845672143		[learning rate: 0.0020266]
	Learning Rate: 0.00202661
	LOSS [training: 0.32463839845672143 | validation: 0.3556792488746433]
	TIME [epoch: 8.33 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4854354073345406		[learning rate: 0.0020218]
	Learning Rate: 0.00202182
	LOSS [training: 0.4854354073345406 | validation: 0.2882514930472539]
	TIME [epoch: 8.35 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44733442887878905		[learning rate: 0.0020171]
	Learning Rate: 0.00201706
	LOSS [training: 0.44733442887878905 | validation: 0.40725443319627824]
	TIME [epoch: 8.32 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5026147422363232		[learning rate: 0.0020123]
	Learning Rate: 0.0020123
	LOSS [training: 0.5026147422363232 | validation: 0.35907835376414554]
	TIME [epoch: 8.33 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4131679186635253		[learning rate: 0.0020076]
	Learning Rate: 0.00200755
	LOSS [training: 0.4131679186635253 | validation: 0.3730070414993044]
	TIME [epoch: 8.33 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4613143919262773		[learning rate: 0.0020028]
	Learning Rate: 0.00200282
	LOSS [training: 0.4613143919262773 | validation: 0.44379518835374987]
	TIME [epoch: 8.35 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5335708805575037		[learning rate: 0.0019981]
	Learning Rate: 0.00199809
	LOSS [training: 0.5335708805575037 | validation: 0.8265970903110731]
	TIME [epoch: 8.33 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4988292455589181		[learning rate: 0.0019934]
	Learning Rate: 0.00199338
	LOSS [training: 0.4988292455589181 | validation: 0.3093961165228262]
	TIME [epoch: 8.33 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3230129541429373		[learning rate: 0.0019887]
	Learning Rate: 0.00198868
	LOSS [training: 0.3230129541429373 | validation: 0.2287413698460833]
	TIME [epoch: 8.32 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47634642301505564		[learning rate: 0.001984]
	Learning Rate: 0.00198399
	LOSS [training: 0.47634642301505564 | validation: 0.3192105842161549]
	TIME [epoch: 8.34 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30576613504394967		[learning rate: 0.0019793]
	Learning Rate: 0.00197931
	LOSS [training: 0.30576613504394967 | validation: 0.23732871223744315]
	TIME [epoch: 8.33 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.406479668385471		[learning rate: 0.0019746]
	Learning Rate: 0.00197464
	LOSS [training: 0.406479668385471 | validation: 0.291152222207185]
	TIME [epoch: 8.32 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41248044835157643		[learning rate: 0.00197]
	Learning Rate: 0.00196998
	LOSS [training: 0.41248044835157643 | validation: 0.4003851266998283]
	TIME [epoch: 8.33 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3160309527289671		[learning rate: 0.0019653]
	Learning Rate: 0.00196533
	LOSS [training: 0.3160309527289671 | validation: 0.24867957041165828]
	TIME [epoch: 8.33 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24450704112158156		[learning rate: 0.0019607]
	Learning Rate: 0.0019607
	LOSS [training: 0.24450704112158156 | validation: 0.2571129901577668]
	TIME [epoch: 8.35 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24102818142491017		[learning rate: 0.0019561]
	Learning Rate: 0.00195607
	LOSS [training: 0.24102818142491017 | validation: 0.4556948489091381]
	TIME [epoch: 8.33 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3273919771330851		[learning rate: 0.0019515]
	Learning Rate: 0.00195146
	LOSS [training: 0.3273919771330851 | validation: 0.26098796501649224]
	TIME [epoch: 8.32 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25134838169072427		[learning rate: 0.0019469]
	Learning Rate: 0.00194685
	LOSS [training: 0.25134838169072427 | validation: 0.20598826673661105]
	TIME [epoch: 8.33 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2566706489445999		[learning rate: 0.0019423]
	Learning Rate: 0.00194226
	LOSS [training: 0.2566706489445999 | validation: 0.1683241490578326]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_744.pth
	Model improved!!!
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22694391203723066		[learning rate: 0.0019377]
	Learning Rate: 0.00193768
	LOSS [training: 0.22694391203723066 | validation: 0.41459774149890505]
	TIME [epoch: 8.33 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3087840914762413		[learning rate: 0.0019331]
	Learning Rate: 0.00193311
	LOSS [training: 0.3087840914762413 | validation: 0.2883810564717871]
	TIME [epoch: 8.32 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23113369349346527		[learning rate: 0.0019285]
	Learning Rate: 0.00192855
	LOSS [training: 0.23113369349346527 | validation: 0.1653393522265057]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_747.pth
	Model improved!!!
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25990553898970237		[learning rate: 0.001924]
	Learning Rate: 0.001924
	LOSS [training: 0.25990553898970237 | validation: 0.19175698339456676]
	TIME [epoch: 8.36 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2300992456985976		[learning rate: 0.0019195]
	Learning Rate: 0.00191946
	LOSS [training: 0.2300992456985976 | validation: 0.5059764909928732]
	TIME [epoch: 8.35 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2893950173164936		[learning rate: 0.0019149]
	Learning Rate: 0.00191493
	LOSS [training: 0.2893950173164936 | validation: 0.24432882995184216]
	TIME [epoch: 8.34 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2741227162001695		[learning rate: 0.0019104]
	Learning Rate: 0.00191042
	LOSS [training: 0.2741227162001695 | validation: 0.2840719221623885]
	TIME [epoch: 8.34 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28889298796379587		[learning rate: 0.0019059]
	Learning Rate: 0.00190591
	LOSS [training: 0.28889298796379587 | validation: 0.2692754706876795]
	TIME [epoch: 8.34 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3110262876609202		[learning rate: 0.0019014]
	Learning Rate: 0.00190141
	LOSS [training: 0.3110262876609202 | validation: 0.322519233847289]
	TIME [epoch: 8.36 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32234893184835095		[learning rate: 0.0018969]
	Learning Rate: 0.00189693
	LOSS [training: 0.32234893184835095 | validation: 0.32883559295009007]
	TIME [epoch: 8.34 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2527658560393208		[learning rate: 0.0018925]
	Learning Rate: 0.00189246
	LOSS [training: 0.2527658560393208 | validation: 0.22663575004984093]
	TIME [epoch: 8.35 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32316787555913085		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.32316787555913085 | validation: 0.3979181787120727]
	TIME [epoch: 8.34 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38756443097362964		[learning rate: 0.0018835]
	Learning Rate: 0.00188354
	LOSS [training: 0.38756443097362964 | validation: 0.255251361690739]
	TIME [epoch: 8.37 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3054451202261461		[learning rate: 0.0018791]
	Learning Rate: 0.00187909
	LOSS [training: 0.3054451202261461 | validation: 0.5670467550393652]
	TIME [epoch: 8.35 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4064754628417127		[learning rate: 0.0018747]
	Learning Rate: 0.00187466
	LOSS [training: 0.4064754628417127 | validation: 0.2081098428392204]
	TIME [epoch: 8.35 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2900035405707399		[learning rate: 0.0018702]
	Learning Rate: 0.00187024
	LOSS [training: 0.2900035405707399 | validation: 0.43210393749030285]
	TIME [epoch: 8.35 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3924512136996716		[learning rate: 0.0018658]
	Learning Rate: 0.00186583
	LOSS [training: 0.3924512136996716 | validation: 0.2523770827893533]
	TIME [epoch: 8.36 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34439580389283486		[learning rate: 0.0018614]
	Learning Rate: 0.00186143
	LOSS [training: 0.34439580389283486 | validation: 0.2098845862213745]
	TIME [epoch: 8.35 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2311903893376818		[learning rate: 0.001857]
	Learning Rate: 0.00185704
	LOSS [training: 0.2311903893376818 | validation: 0.2933696128305784]
	TIME [epoch: 8.35 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2821104818878869		[learning rate: 0.0018527]
	Learning Rate: 0.00185266
	LOSS [training: 0.2821104818878869 | validation: 0.2780503460165179]
	TIME [epoch: 8.34 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3143597911812155		[learning rate: 0.0018483]
	Learning Rate: 0.00184829
	LOSS [training: 0.3143597911812155 | validation: 0.2772350003627877]
	TIME [epoch: 8.34 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28422542923623817		[learning rate: 0.0018439]
	Learning Rate: 0.00184393
	LOSS [training: 0.28422542923623817 | validation: 0.24424507768904608]
	TIME [epoch: 8.37 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29810909933522506		[learning rate: 0.0018396]
	Learning Rate: 0.00183958
	LOSS [training: 0.29810909933522506 | validation: 0.25040985817887057]
	TIME [epoch: 8.34 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3174146331461173		[learning rate: 0.0018352]
	Learning Rate: 0.00183524
	LOSS [training: 0.3174146331461173 | validation: 0.3420891630880216]
	TIME [epoch: 8.34 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2556703377972531		[learning rate: 0.0018309]
	Learning Rate: 0.00183091
	LOSS [training: 0.2556703377972531 | validation: 0.23431916083203386]
	TIME [epoch: 8.33 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24794139178933286		[learning rate: 0.0018266]
	Learning Rate: 0.00182659
	LOSS [training: 0.24794139178933286 | validation: 0.17278658468581554]
	TIME [epoch: 8.34 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21718014767270893		[learning rate: 0.0018223]
	Learning Rate: 0.00182228
	LOSS [training: 0.21718014767270893 | validation: 0.34313667765497313]
	TIME [epoch: 8.32 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23866243391063469		[learning rate: 0.001818]
	Learning Rate: 0.00181798
	LOSS [training: 0.23866243391063469 | validation: 0.21653872686887154]
	TIME [epoch: 8.31 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2822742103164283		[learning rate: 0.0018137]
	Learning Rate: 0.00181369
	LOSS [training: 0.2822742103164283 | validation: 0.31485841460792063]
	TIME [epoch: 8.31 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2943537968535607		[learning rate: 0.0018094]
	Learning Rate: 0.00180942
	LOSS [training: 0.2943537968535607 | validation: 0.45291707865915]
	TIME [epoch: 8.34 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2373360544139625		[learning rate: 0.0018051]
	Learning Rate: 0.00180515
	LOSS [training: 0.2373360544139625 | validation: 0.24045914719200673]
	TIME [epoch: 8.33 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24705375357841594		[learning rate: 0.0018009]
	Learning Rate: 0.00180089
	LOSS [training: 0.24705375357841594 | validation: 0.28847443497394115]
	TIME [epoch: 8.34 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28071257465234495		[learning rate: 0.0017966]
	Learning Rate: 0.00179664
	LOSS [training: 0.28071257465234495 | validation: 0.16294008520418476]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_777.pth
	Model improved!!!
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27224597097165354		[learning rate: 0.0017924]
	Learning Rate: 0.0017924
	LOSS [training: 0.27224597097165354 | validation: 0.2076314979025072]
	TIME [epoch: 8.32 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24645640812304576		[learning rate: 0.0017882]
	Learning Rate: 0.00178818
	LOSS [training: 0.24645640812304576 | validation: 0.2538441589509794]
	TIME [epoch: 8.34 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2387252159888878		[learning rate: 0.001784]
	Learning Rate: 0.00178396
	LOSS [training: 0.2387252159888878 | validation: 0.23010029925689643]
	TIME [epoch: 8.32 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3562129451971508		[learning rate: 0.0017797]
	Learning Rate: 0.00177975
	LOSS [training: 0.3562129451971508 | validation: 0.5475570877271261]
	TIME [epoch: 8.32 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36987406894180086		[learning rate: 0.0017756]
	Learning Rate: 0.00177555
	LOSS [training: 0.36987406894180086 | validation: 0.2988625156231444]
	TIME [epoch: 8.33 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.226191741362706		[learning rate: 0.0017714]
	Learning Rate: 0.00177136
	LOSS [training: 0.226191741362706 | validation: 0.23686619940531728]
	TIME [epoch: 8.35 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28500917658546265		[learning rate: 0.0017672]
	Learning Rate: 0.00176719
	LOSS [training: 0.28500917658546265 | validation: 0.2244877472348909]
	TIME [epoch: 8.34 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2927107311458987		[learning rate: 0.001763]
	Learning Rate: 0.00176302
	LOSS [training: 0.2927107311458987 | validation: 0.3055404499902646]
	TIME [epoch: 8.33 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2685428110355764		[learning rate: 0.0017589]
	Learning Rate: 0.00175886
	LOSS [training: 0.2685428110355764 | validation: 0.3388221941631505]
	TIME [epoch: 8.33 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38005204515270463		[learning rate: 0.0017547]
	Learning Rate: 0.00175471
	LOSS [training: 0.38005204515270463 | validation: 0.25851157530992774]
	TIME [epoch: 8.34 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3654465171576322		[learning rate: 0.0017506]
	Learning Rate: 0.00175057
	LOSS [training: 0.3654465171576322 | validation: 0.27921875156195414]
	TIME [epoch: 8.34 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29831457891314406		[learning rate: 0.0017464]
	Learning Rate: 0.00174644
	LOSS [training: 0.29831457891314406 | validation: 0.1849323427096451]
	TIME [epoch: 8.33 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29678412791980846		[learning rate: 0.0017423]
	Learning Rate: 0.00174232
	LOSS [training: 0.29678412791980846 | validation: 0.2803429801546838]
	TIME [epoch: 8.32 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3172880869873175		[learning rate: 0.0017382]
	Learning Rate: 0.00173821
	LOSS [training: 0.3172880869873175 | validation: 0.6138412271691103]
	TIME [epoch: 8.33 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4440252684889656		[learning rate: 0.0017341]
	Learning Rate: 0.00173411
	LOSS [training: 0.4440252684889656 | validation: 0.26957213720647905]
	TIME [epoch: 8.35 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23127684080991878		[learning rate: 0.00173]
	Learning Rate: 0.00173002
	LOSS [training: 0.23127684080991878 | validation: 0.2620050847163016]
	TIME [epoch: 8.33 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30397178151129695		[learning rate: 0.0017259]
	Learning Rate: 0.00172594
	LOSS [training: 0.30397178151129695 | validation: 0.2866736289830689]
	TIME [epoch: 8.33 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3112126380454898		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.3112126380454898 | validation: 0.22809323640731766]
	TIME [epoch: 8.33 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26258036770047094		[learning rate: 0.0017178]
	Learning Rate: 0.00171781
	LOSS [training: 0.26258036770047094 | validation: 0.1732431503876817]
	TIME [epoch: 8.35 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2328706052028351		[learning rate: 0.0017138]
	Learning Rate: 0.00171375
	LOSS [training: 0.2328706052028351 | validation: 0.22458234211219388]
	TIME [epoch: 8.33 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25535124875564785		[learning rate: 0.0017097]
	Learning Rate: 0.00170971
	LOSS [training: 0.25535124875564785 | validation: 0.29524746402094004]
	TIME [epoch: 8.33 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20778028220015826		[learning rate: 0.0017057]
	Learning Rate: 0.00170568
	LOSS [training: 0.20778028220015826 | validation: 0.22298062775333938]
	TIME [epoch: 8.33 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37659300076911395		[learning rate: 0.0017017]
	Learning Rate: 0.00170166
	LOSS [training: 0.37659300076911395 | validation: 0.31531323745427475]
	TIME [epoch: 8.35 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27186854573602404		[learning rate: 0.0016976]
	Learning Rate: 0.00169764
	LOSS [training: 0.27186854573602404 | validation: 0.171791216202063]
	TIME [epoch: 8.34 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2240476708485936		[learning rate: 0.0016936]
	Learning Rate: 0.00169364
	LOSS [training: 0.2240476708485936 | validation: 0.24923996233059764]
	TIME [epoch: 8.33 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2385613574186897		[learning rate: 0.0016896]
	Learning Rate: 0.00168964
	LOSS [training: 0.2385613574186897 | validation: 0.2652035050969287]
	TIME [epoch: 8.33 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20012837993862553		[learning rate: 0.0016857]
	Learning Rate: 0.00168566
	LOSS [training: 0.20012837993862553 | validation: 0.2455277746325188]
	TIME [epoch: 8.33 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3051385938749373		[learning rate: 0.0016817]
	Learning Rate: 0.00168168
	LOSS [training: 0.3051385938749373 | validation: 0.43532083194485094]
	TIME [epoch: 8.36 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2887127353496103		[learning rate: 0.0016777]
	Learning Rate: 0.00167771
	LOSS [training: 0.2887127353496103 | validation: 0.20114703845617965]
	TIME [epoch: 8.34 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2822908503846978		[learning rate: 0.0016738]
	Learning Rate: 0.00167376
	LOSS [training: 0.2822908503846978 | validation: 0.18066175434999188]
	TIME [epoch: 8.33 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23608423543904059		[learning rate: 0.0016698]
	Learning Rate: 0.00166981
	LOSS [training: 0.23608423543904059 | validation: 0.2390351279758634]
	TIME [epoch: 8.34 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24807157012254227		[learning rate: 0.0016659]
	Learning Rate: 0.00166587
	LOSS [training: 0.24807157012254227 | validation: 0.22298141302289304]
	TIME [epoch: 8.36 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2876630923375122		[learning rate: 0.0016619]
	Learning Rate: 0.00166194
	LOSS [training: 0.2876630923375122 | validation: 0.20740638704284675]
	TIME [epoch: 8.34 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1999090926797855		[learning rate: 0.001658]
	Learning Rate: 0.00165802
	LOSS [training: 0.1999090926797855 | validation: 0.19079768946655268]
	TIME [epoch: 8.34 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25435846204592216		[learning rate: 0.0016541]
	Learning Rate: 0.00165411
	LOSS [training: 0.25435846204592216 | validation: 0.3453045266722501]
	TIME [epoch: 8.33 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2334981171301697		[learning rate: 0.0016502]
	Learning Rate: 0.00165021
	LOSS [training: 0.2334981171301697 | validation: 0.2990591367171842]
	TIME [epoch: 8.35 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3507561832022935		[learning rate: 0.0016463]
	Learning Rate: 0.00164631
	LOSS [training: 0.3507561832022935 | validation: 0.14848231321993555]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_814.pth
	Model improved!!!
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2398724165423244		[learning rate: 0.0016424]
	Learning Rate: 0.00164243
	LOSS [training: 0.2398724165423244 | validation: 0.5087184044423885]
	TIME [epoch: 8.34 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2640950980838653		[learning rate: 0.0016386]
	Learning Rate: 0.00163856
	LOSS [training: 0.2640950980838653 | validation: 0.4473597013184793]
	TIME [epoch: 8.32 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24937877426083577		[learning rate: 0.0016347]
	Learning Rate: 0.00163469
	LOSS [training: 0.24937877426083577 | validation: 0.2321407609929686]
	TIME [epoch: 8.33 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25933031557384484		[learning rate: 0.0016308]
	Learning Rate: 0.00163084
	LOSS [training: 0.25933031557384484 | validation: 0.2559900851416778]
	TIME [epoch: 8.35 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23677570604017095		[learning rate: 0.001627]
	Learning Rate: 0.00162699
	LOSS [training: 0.23677570604017095 | validation: 0.16782330318514196]
	TIME [epoch: 8.33 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3156393310386275		[learning rate: 0.0016232]
	Learning Rate: 0.00162315
	LOSS [training: 0.3156393310386275 | validation: 0.3086066018477841]
	TIME [epoch: 8.33 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32210536616660507		[learning rate: 0.0016193]
	Learning Rate: 0.00161932
	LOSS [training: 0.32210536616660507 | validation: 0.4131345958975365]
	TIME [epoch: 8.33 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25470912955029035		[learning rate: 0.0016155]
	Learning Rate: 0.0016155
	LOSS [training: 0.25470912955029035 | validation: 0.16041156835552373]
	TIME [epoch: 8.35 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23937727234430667		[learning rate: 0.0016117]
	Learning Rate: 0.00161169
	LOSS [training: 0.23937727234430667 | validation: 0.23684581696284246]
	TIME [epoch: 8.33 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27224302666067995		[learning rate: 0.0016079]
	Learning Rate: 0.00160789
	LOSS [training: 0.27224302666067995 | validation: 0.2025079388795334]
	TIME [epoch: 8.33 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24857200917327638		[learning rate: 0.0016041]
	Learning Rate: 0.0016041
	LOSS [training: 0.24857200917327638 | validation: 0.31305494805378]
	TIME [epoch: 8.33 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2324646284153768		[learning rate: 0.0016003]
	Learning Rate: 0.00160031
	LOSS [training: 0.2324646284153768 | validation: 0.38287037788554207]
	TIME [epoch: 8.34 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.346576477595567		[learning rate: 0.0015965]
	Learning Rate: 0.00159654
	LOSS [training: 0.346576477595567 | validation: 0.3586761492188416]
	TIME [epoch: 8.34 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2686119881822401		[learning rate: 0.0015928]
	Learning Rate: 0.00159277
	LOSS [training: 0.2686119881822401 | validation: 0.3973820329340084]
	TIME [epoch: 8.32 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34027667700701203		[learning rate: 0.001589]
	Learning Rate: 0.00158902
	LOSS [training: 0.34027667700701203 | validation: 0.2075059218816959]
	TIME [epoch: 8.32 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3489550580290278		[learning rate: 0.0015853]
	Learning Rate: 0.00158527
	LOSS [training: 0.3489550580290278 | validation: 0.23789646973575138]
	TIME [epoch: 8.32 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2127786138131141		[learning rate: 0.0015815]
	Learning Rate: 0.00158153
	LOSS [training: 0.2127786138131141 | validation: 0.1823849183520309]
	TIME [epoch: 8.35 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2692072385412408		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.2692072385412408 | validation: 0.3541266485307479]
	TIME [epoch: 8.33 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27594375009618555		[learning rate: 0.0015741]
	Learning Rate: 0.00157408
	LOSS [training: 0.27594375009618555 | validation: 0.4330238479570373]
	TIME [epoch: 8.33 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2381740454642154		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.2381740454642154 | validation: 0.28199139426699266]
	TIME [epoch: 8.33 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22150687337424704		[learning rate: 0.0015667]
	Learning Rate: 0.00156666
	LOSS [training: 0.22150687337424704 | validation: 0.2467469284944576]
	TIME [epoch: 8.34 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20330072120297876		[learning rate: 0.001563]
	Learning Rate: 0.00156296
	LOSS [training: 0.20330072120297876 | validation: 0.2287965081917922]
	TIME [epoch: 8.33 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2415199181658887		[learning rate: 0.0015593]
	Learning Rate: 0.00155928
	LOSS [training: 0.2415199181658887 | validation: 0.1872493349641625]
	TIME [epoch: 8.33 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3193763109527231		[learning rate: 0.0015556]
	Learning Rate: 0.0015556
	LOSS [training: 0.3193763109527231 | validation: 0.2687532157634782]
	TIME [epoch: 8.33 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36367139903828727		[learning rate: 0.0015519]
	Learning Rate: 0.00155193
	LOSS [training: 0.36367139903828727 | validation: 0.26381562134796455]
	TIME [epoch: 8.34 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2967266972169317		[learning rate: 0.0015483]
	Learning Rate: 0.00154827
	LOSS [training: 0.2967266972169317 | validation: 0.21250326450770193]
	TIME [epoch: 8.34 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2640579635511051		[learning rate: 0.0015446]
	Learning Rate: 0.00154462
	LOSS [training: 0.2640579635511051 | validation: 0.25223529080363183]
	TIME [epoch: 8.33 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29803175473868676		[learning rate: 0.001541]
	Learning Rate: 0.00154097
	LOSS [training: 0.29803175473868676 | validation: 0.22926843944903968]
	TIME [epoch: 8.33 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2611583225410651		[learning rate: 0.0015373]
	Learning Rate: 0.00153734
	LOSS [training: 0.2611583225410651 | validation: 0.27869018712378707]
	TIME [epoch: 8.33 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3315041259402019		[learning rate: 0.0015337]
	Learning Rate: 0.00153371
	LOSS [training: 0.3315041259402019 | validation: 0.2282241291193161]
	TIME [epoch: 8.35 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2752974457555585		[learning rate: 0.0015301]
	Learning Rate: 0.00153009
	LOSS [training: 0.2752974457555585 | validation: 0.2740625471403362]
	TIME [epoch: 8.33 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25497261227427487		[learning rate: 0.0015265]
	Learning Rate: 0.00152648
	LOSS [training: 0.25497261227427487 | validation: 0.24696228750002305]
	TIME [epoch: 8.33 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24660505409905892		[learning rate: 0.0015229]
	Learning Rate: 0.00152288
	LOSS [training: 0.24660505409905892 | validation: 0.3592187571787759]
	TIME [epoch: 8.33 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22722206205974635		[learning rate: 0.0015193]
	Learning Rate: 0.00151929
	LOSS [training: 0.22722206205974635 | validation: 0.19905788553043097]
	TIME [epoch: 8.36 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23923412053907547		[learning rate: 0.0015157]
	Learning Rate: 0.00151571
	LOSS [training: 0.23923412053907547 | validation: 0.1966324599492954]
	TIME [epoch: 8.33 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2871519134254016		[learning rate: 0.0015121]
	Learning Rate: 0.00151213
	LOSS [training: 0.2871519134254016 | validation: 0.2605537987863271]
	TIME [epoch: 8.33 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26945653212493836		[learning rate: 0.0015086]
	Learning Rate: 0.00150857
	LOSS [training: 0.26945653212493836 | validation: 0.2005839957887206]
	TIME [epoch: 8.32 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2701242034642583		[learning rate: 0.001505]
	Learning Rate: 0.00150501
	LOSS [training: 0.2701242034642583 | validation: 0.23586992673200824]
	TIME [epoch: 8.34 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2450853161668627		[learning rate: 0.0015015]
	Learning Rate: 0.00150146
	LOSS [training: 0.2450853161668627 | validation: 0.1785602750447362]
	TIME [epoch: 8.34 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31595432935220147		[learning rate: 0.0014979]
	Learning Rate: 0.00149791
	LOSS [training: 0.31595432935220147 | validation: 0.22717784620023804]
	TIME [epoch: 8.33 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2379015714219847		[learning rate: 0.0014944]
	Learning Rate: 0.00149438
	LOSS [training: 0.2379015714219847 | validation: 0.2739195497653397]
	TIME [epoch: 8.33 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2140232556670873		[learning rate: 0.0014909]
	Learning Rate: 0.00149086
	LOSS [training: 0.2140232556670873 | validation: 0.29406145800875083]
	TIME [epoch: 8.33 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2027480477495333		[learning rate: 0.0014873]
	Learning Rate: 0.00148734
	LOSS [training: 0.2027480477495333 | validation: 0.39387036456870467]
	TIME [epoch: 8.36 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34089697688616555		[learning rate: 0.0014838]
	Learning Rate: 0.00148383
	LOSS [training: 0.34089697688616555 | validation: 0.1615195510831913]
	TIME [epoch: 8.34 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23260278365419476		[learning rate: 0.0014803]
	Learning Rate: 0.00148033
	LOSS [training: 0.23260278365419476 | validation: 1.1177209252000637]
	TIME [epoch: 8.34 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4954441746806915		[learning rate: 0.0014768]
	Learning Rate: 0.00147684
	LOSS [training: 0.4954441746806915 | validation: 0.23521228711513395]
	TIME [epoch: 8.33 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2106245890367487		[learning rate: 0.0014734]
	Learning Rate: 0.00147336
	LOSS [training: 0.2106245890367487 | validation: 0.21224409952879253]
	TIME [epoch: 8.35 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20384808530642023		[learning rate: 0.0014699]
	Learning Rate: 0.00146988
	LOSS [training: 0.20384808530642023 | validation: 0.17259512192375256]
	TIME [epoch: 8.32 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27896160158186584		[learning rate: 0.0014664]
	Learning Rate: 0.00146641
	LOSS [training: 0.27896160158186584 | validation: 0.35410542213079166]
	TIME [epoch: 8.33 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25865533841168464		[learning rate: 0.001463]
	Learning Rate: 0.00146295
	LOSS [training: 0.25865533841168464 | validation: 0.3883195857058156]
	TIME [epoch: 8.32 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26775103255422666		[learning rate: 0.0014595]
	Learning Rate: 0.0014595
	LOSS [training: 0.26775103255422666 | validation: 0.16219450638027744]
	TIME [epoch: 8.35 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3824200799457568		[learning rate: 0.0014561]
	Learning Rate: 0.00145606
	LOSS [training: 0.3824200799457568 | validation: 0.21326519366791385]
	TIME [epoch: 8.33 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24077335695820268		[learning rate: 0.0014526]
	Learning Rate: 0.00145263
	LOSS [training: 0.24077335695820268 | validation: 0.2932989242856662]
	TIME [epoch: 8.32 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2580512958976359		[learning rate: 0.0014492]
	Learning Rate: 0.0014492
	LOSS [training: 0.2580512958976359 | validation: 0.29002419729138573]
	TIME [epoch: 8.32 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3355372311833179		[learning rate: 0.0014458]
	Learning Rate: 0.00144578
	LOSS [training: 0.3355372311833179 | validation: 0.34686153980387446]
	TIME [epoch: 8.31 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1874515681944458		[learning rate: 0.0014424]
	Learning Rate: 0.00144237
	LOSS [training: 0.1874515681944458 | validation: 0.42239984022958266]
	TIME [epoch: 8.34 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20089500600083823		[learning rate: 0.001439]
	Learning Rate: 0.00143897
	LOSS [training: 0.20089500600083823 | validation: 0.22676463669630215]
	TIME [epoch: 8.32 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2855002654468674		[learning rate: 0.0014356]
	Learning Rate: 0.00143557
	LOSS [training: 0.2855002654468674 | validation: 0.29850694863488025]
	TIME [epoch: 8.32 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2559059492987563		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.2559059492987563 | validation: 0.4502806908786743]
	TIME [epoch: 8.32 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19625691071537488		[learning rate: 0.0014288]
	Learning Rate: 0.00142881
	LOSS [training: 0.19625691071537488 | validation: 0.1817521520098599]
	TIME [epoch: 8.34 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20847321344335681		[learning rate: 0.0014254]
	Learning Rate: 0.00142544
	LOSS [training: 0.20847321344335681 | validation: 0.30860572381385004]
	TIME [epoch: 8.32 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24222724352146452		[learning rate: 0.0014221]
	Learning Rate: 0.00142208
	LOSS [training: 0.24222724352146452 | validation: 0.16554924506832633]
	TIME [epoch: 8.32 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27359713139675634		[learning rate: 0.0014187]
	Learning Rate: 0.00141872
	LOSS [training: 0.27359713139675634 | validation: 0.3257653861909231]
	TIME [epoch: 8.32 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20009569037070607		[learning rate: 0.0014154]
	Learning Rate: 0.00141538
	LOSS [training: 0.20009569037070607 | validation: 0.1275373028077081]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_878.pth
	Model improved!!!
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.193724092744449		[learning rate: 0.001412]
	Learning Rate: 0.00141204
	LOSS [training: 0.193724092744449 | validation: 0.15540201689364985]
	TIME [epoch: 8.32 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2490882476101141		[learning rate: 0.0014087]
	Learning Rate: 0.00140871
	LOSS [training: 0.2490882476101141 | validation: 0.6077420430770689]
	TIME [epoch: 8.32 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28198839892401406		[learning rate: 0.0014054]
	Learning Rate: 0.00140538
	LOSS [training: 0.28198839892401406 | validation: 0.1946056425664226]
	TIME [epoch: 8.33 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21312593660555423		[learning rate: 0.0014021]
	Learning Rate: 0.00140207
	LOSS [training: 0.21312593660555423 | validation: 0.3314612321085301]
	TIME [epoch: 8.33 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2863602976418231		[learning rate: 0.0013988]
	Learning Rate: 0.00139876
	LOSS [training: 0.2863602976418231 | validation: 0.2609053000433135]
	TIME [epoch: 8.34 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2083588106121245		[learning rate: 0.0013955]
	Learning Rate: 0.00139546
	LOSS [training: 0.2083588106121245 | validation: 0.20594591969618464]
	TIME [epoch: 8.31 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17833414929117014		[learning rate: 0.0013922]
	Learning Rate: 0.00139217
	LOSS [training: 0.17833414929117014 | validation: 0.1457465062216497]
	TIME [epoch: 8.31 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2268744505318657		[learning rate: 0.0013889]
	Learning Rate: 0.00138889
	LOSS [training: 0.2268744505318657 | validation: 0.3464905965417191]
	TIME [epoch: 8.31 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3276245622601614		[learning rate: 0.0013856]
	Learning Rate: 0.00138561
	LOSS [training: 0.3276245622601614 | validation: 0.3033882916960938]
	TIME [epoch: 8.33 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2729144829697467		[learning rate: 0.0013823]
	Learning Rate: 0.00138234
	LOSS [training: 0.2729144829697467 | validation: 0.22576276634288495]
	TIME [epoch: 8.33 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22509625970168826		[learning rate: 0.0013791]
	Learning Rate: 0.00137908
	LOSS [training: 0.22509625970168826 | validation: 0.24771058266387166]
	TIME [epoch: 8.31 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25726914147067437		[learning rate: 0.0013758]
	Learning Rate: 0.00137583
	LOSS [training: 0.25726914147067437 | validation: 0.16456520930565469]
	TIME [epoch: 8.32 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22711024960719278		[learning rate: 0.0013726]
	Learning Rate: 0.00137258
	LOSS [training: 0.22711024960719278 | validation: 0.17178868246286844]
	TIME [epoch: 8.33 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20916290303682147		[learning rate: 0.0013693]
	Learning Rate: 0.00136934
	LOSS [training: 0.20916290303682147 | validation: 0.2225688993380577]
	TIME [epoch: 8.33 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.204367841086576		[learning rate: 0.0013661]
	Learning Rate: 0.00136611
	LOSS [training: 0.204367841086576 | validation: 0.14036482870874128]
	TIME [epoch: 8.32 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18830267361653288		[learning rate: 0.0013629]
	Learning Rate: 0.00136289
	LOSS [training: 0.18830267361653288 | validation: 0.17564640837403656]
	TIME [epoch: 8.33 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19501687868679166		[learning rate: 0.0013597]
	Learning Rate: 0.00135968
	LOSS [training: 0.19501687868679166 | validation: 0.1448987110296882]
	TIME [epoch: 8.32 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20991873186949267		[learning rate: 0.0013565]
	Learning Rate: 0.00135647
	LOSS [training: 0.20991873186949267 | validation: 0.2256103322545695]
	TIME [epoch: 8.35 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1990792755014739		[learning rate: 0.0013533]
	Learning Rate: 0.00135327
	LOSS [training: 0.1990792755014739 | validation: 0.18163896611049918]
	TIME [epoch: 8.31 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29226018660075853		[learning rate: 0.0013501]
	Learning Rate: 0.00135008
	LOSS [training: 0.29226018660075853 | validation: 0.2080849666892557]
	TIME [epoch: 8.31 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21629125778669223		[learning rate: 0.0013469]
	Learning Rate: 0.00134689
	LOSS [training: 0.21629125778669223 | validation: 0.25635247338681433]
	TIME [epoch: 8.32 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.230590448610261		[learning rate: 0.0013437]
	Learning Rate: 0.00134372
	LOSS [training: 0.230590448610261 | validation: 0.18601515645034603]
	TIME [epoch: 8.34 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2331289177455353		[learning rate: 0.0013405]
	Learning Rate: 0.00134055
	LOSS [training: 0.2331289177455353 | validation: 0.1173558936100671]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_901.pth
	Model improved!!!
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15323157731338388		[learning rate: 0.0013374]
	Learning Rate: 0.00133738
	LOSS [training: 0.15323157731338388 | validation: 0.12599185976797767]
	TIME [epoch: 8.33 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21348943546464003		[learning rate: 0.0013342]
	Learning Rate: 0.00133423
	LOSS [training: 0.21348943546464003 | validation: 0.24430781652091954]
	TIME [epoch: 8.31 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28049561540732326		[learning rate: 0.0013311]
	Learning Rate: 0.00133108
	LOSS [training: 0.28049561540732326 | validation: 0.22064784967124831]
	TIME [epoch: 8.33 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21069778653661064		[learning rate: 0.0013279]
	Learning Rate: 0.00132794
	LOSS [training: 0.21069778653661064 | validation: 0.13702089258310823]
	TIME [epoch: 8.33 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21964598852554432		[learning rate: 0.0013248]
	Learning Rate: 0.00132481
	LOSS [training: 0.21964598852554432 | validation: 0.1882977903507651]
	TIME [epoch: 8.32 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1796485758924812		[learning rate: 0.0013217]
	Learning Rate: 0.00132169
	LOSS [training: 0.1796485758924812 | validation: 0.13302337074373166]
	TIME [epoch: 8.31 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2068687153133682		[learning rate: 0.0013186]
	Learning Rate: 0.00131857
	LOSS [training: 0.2068687153133682 | validation: 0.2303630676495707]
	TIME [epoch: 8.32 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2660390398251183		[learning rate: 0.0013155]
	Learning Rate: 0.00131546
	LOSS [training: 0.2660390398251183 | validation: 0.31476534022958536]
	TIME [epoch: 8.34 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.356081280823907		[learning rate: 0.0013124]
	Learning Rate: 0.00131235
	LOSS [training: 0.356081280823907 | validation: 0.21922233683283204]
	TIME [epoch: 8.31 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21546103246845946		[learning rate: 0.0013093]
	Learning Rate: 0.00130926
	LOSS [training: 0.21546103246845946 | validation: 0.2553113486839738]
	TIME [epoch: 8.32 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17272916213080844		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.17272916213080844 | validation: 0.286823205741087]
	TIME [epoch: 8.33 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22395405856962297		[learning rate: 0.0013031]
	Learning Rate: 0.00130309
	LOSS [training: 0.22395405856962297 | validation: 0.16941949020147024]
	TIME [epoch: 8.35 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1784568528443909		[learning rate: 0.0013]
	Learning Rate: 0.00130002
	LOSS [training: 0.1784568528443909 | validation: 0.1577137862242719]
	TIME [epoch: 8.32 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24198463780134274		[learning rate: 0.0012969]
	Learning Rate: 0.00129695
	LOSS [training: 0.24198463780134274 | validation: 0.23411409981301795]
	TIME [epoch: 8.32 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24557058369470885		[learning rate: 0.0012939]
	Learning Rate: 0.00129389
	LOSS [training: 0.24557058369470885 | validation: 0.4477467739018901]
	TIME [epoch: 8.32 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21659700817294875		[learning rate: 0.0012908]
	Learning Rate: 0.00129084
	LOSS [training: 0.21659700817294875 | validation: 0.15453345392555837]
	TIME [epoch: 8.35 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19553183701693955		[learning rate: 0.0012878]
	Learning Rate: 0.00128779
	LOSS [training: 0.19553183701693955 | validation: 0.23642761505993887]
	TIME [epoch: 8.32 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28878703341492973		[learning rate: 0.0012848]
	Learning Rate: 0.00128476
	LOSS [training: 0.28878703341492973 | validation: 0.22811047006607255]
	TIME [epoch: 8.32 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2650093643424527		[learning rate: 0.0012817]
	Learning Rate: 0.00128173
	LOSS [training: 0.2650093643424527 | validation: 0.3944347537458826]
	TIME [epoch: 8.33 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2332675318214748		[learning rate: 0.0012787]
	Learning Rate: 0.0012787
	LOSS [training: 0.2332675318214748 | validation: 0.135102239400834]
	TIME [epoch: 8.33 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20838896948048088		[learning rate: 0.0012757]
	Learning Rate: 0.00127569
	LOSS [training: 0.20838896948048088 | validation: 0.1475477472300451]
	TIME [epoch: 8.35 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17520591687708234		[learning rate: 0.0012727]
	Learning Rate: 0.00127268
	LOSS [training: 0.17520591687708234 | validation: 0.1300397972583528]
	TIME [epoch: 8.31 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1832007273747604		[learning rate: 0.0012697]
	Learning Rate: 0.00126967
	LOSS [training: 0.1832007273747604 | validation: 0.14231297110310326]
	TIME [epoch: 8.32 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16968971332639912		[learning rate: 0.0012667]
	Learning Rate: 0.00126668
	LOSS [training: 0.16968971332639912 | validation: 0.14657871805417952]
	TIME [epoch: 8.31 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17452003794232807		[learning rate: 0.0012637]
	Learning Rate: 0.00126369
	LOSS [training: 0.17452003794232807 | validation: 0.19462596443353092]
	TIME [epoch: 8.35 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20022279744683188		[learning rate: 0.0012607]
	Learning Rate: 0.00126071
	LOSS [training: 0.20022279744683188 | validation: 0.18122171810327495]
	TIME [epoch: 8.33 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19407693272570264		[learning rate: 0.0012577]
	Learning Rate: 0.00125774
	LOSS [training: 0.19407693272570264 | validation: 0.3601475315395503]
	TIME [epoch: 8.34 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2805688774111169		[learning rate: 0.0012548]
	Learning Rate: 0.00125477
	LOSS [training: 0.2805688774111169 | validation: 0.21390125102037819]
	TIME [epoch: 8.33 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22081355901479274		[learning rate: 0.0012518]
	Learning Rate: 0.00125181
	LOSS [training: 0.22081355901479274 | validation: 0.17683006604985854]
	TIME [epoch: 8.35 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26781904591341843		[learning rate: 0.0012489]
	Learning Rate: 0.00124886
	LOSS [training: 0.26781904591341843 | validation: 0.22425790294462522]
	TIME [epoch: 8.34 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24944932990000918		[learning rate: 0.0012459]
	Learning Rate: 0.00124591
	LOSS [training: 0.24944932990000918 | validation: 0.2606549109432818]
	TIME [epoch: 8.34 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1740113614278342		[learning rate: 0.001243]
	Learning Rate: 0.00124297
	LOSS [training: 0.1740113614278342 | validation: 0.1784085874407156]
	TIME [epoch: 8.33 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19860193718367714		[learning rate: 0.00124]
	Learning Rate: 0.00124004
	LOSS [training: 0.19860193718367714 | validation: 0.20480513178227355]
	TIME [epoch: 8.32 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1798807986970144		[learning rate: 0.0012371]
	Learning Rate: 0.00123712
	LOSS [training: 0.1798807986970144 | validation: 0.1432893636945169]
	TIME [epoch: 8.35 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15525327696890726		[learning rate: 0.0012342]
	Learning Rate: 0.0012342
	LOSS [training: 0.15525327696890726 | validation: 0.40678110358573777]
	TIME [epoch: 8.33 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20236970136464935		[learning rate: 0.0012313]
	Learning Rate: 0.00123129
	LOSS [training: 0.20236970136464935 | validation: 0.1841717840589791]
	TIME [epoch: 8.33 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15783986669426192		[learning rate: 0.0012284]
	Learning Rate: 0.00122838
	LOSS [training: 0.15783986669426192 | validation: 0.21061480405622152]
	TIME [epoch: 8.32 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17634466600383458		[learning rate: 0.0012255]
	Learning Rate: 0.00122548
	LOSS [training: 0.17634466600383458 | validation: 0.1404311934034721]
	TIME [epoch: 8.35 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20349087057710827		[learning rate: 0.0012226]
	Learning Rate: 0.00122259
	LOSS [training: 0.20349087057710827 | validation: 0.17823091639117586]
	TIME [epoch: 8.33 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24951018715794165		[learning rate: 0.0012197]
	Learning Rate: 0.00121971
	LOSS [training: 0.24951018715794165 | validation: 0.2211798170883958]
	TIME [epoch: 8.33 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20233883193516258		[learning rate: 0.0012168]
	Learning Rate: 0.00121683
	LOSS [training: 0.20233883193516258 | validation: 0.1717592193410582]
	TIME [epoch: 8.33 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1832181661761834		[learning rate: 0.001214]
	Learning Rate: 0.00121396
	LOSS [training: 0.1832181661761834 | validation: 0.25582531282021737]
	TIME [epoch: 8.34 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1859296839267245		[learning rate: 0.0012111]
	Learning Rate: 0.0012111
	LOSS [training: 0.1859296839267245 | validation: 0.1426798742208403]
	TIME [epoch: 8.34 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1894196137623831		[learning rate: 0.0012082]
	Learning Rate: 0.00120824
	LOSS [training: 0.1894196137623831 | validation: 0.21146927288381145]
	TIME [epoch: 8.32 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19399765804887997		[learning rate: 0.0012054]
	Learning Rate: 0.00120539
	LOSS [training: 0.19399765804887997 | validation: 0.1868851016811759]
	TIME [epoch: 8.33 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15496141353384937		[learning rate: 0.0012025]
	Learning Rate: 0.00120255
	LOSS [training: 0.15496141353384937 | validation: 0.2214848730353002]
	TIME [epoch: 8.33 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21042809372640492		[learning rate: 0.0011997]
	Learning Rate: 0.00119971
	LOSS [training: 0.21042809372640492 | validation: 0.17282775246942472]
	TIME [epoch: 8.36 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18870764010426433		[learning rate: 0.0011969]
	Learning Rate: 0.00119688
	LOSS [training: 0.18870764010426433 | validation: 0.182723688842723]
	TIME [epoch: 8.33 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1790057402040251		[learning rate: 0.0011941]
	Learning Rate: 0.00119406
	LOSS [training: 0.1790057402040251 | validation: 0.2453993637986706]
	TIME [epoch: 8.33 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17755824001184178		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.17755824001184178 | validation: 0.17180624651208132]
	TIME [epoch: 8.33 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2179953115775289		[learning rate: 0.0011884]
	Learning Rate: 0.00118843
	LOSS [training: 0.2179953115775289 | validation: 0.175042960910282]
	TIME [epoch: 8.35 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2035641855095882		[learning rate: 0.0011856]
	Learning Rate: 0.00118563
	LOSS [training: 0.2035641855095882 | validation: 0.22046135510859804]
	TIME [epoch: 8.33 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23375862909096817		[learning rate: 0.0011828]
	Learning Rate: 0.00118283
	LOSS [training: 0.23375862909096817 | validation: 0.2483426375939921]
	TIME [epoch: 8.33 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21187163708944187		[learning rate: 0.00118]
	Learning Rate: 0.00118004
	LOSS [training: 0.21187163708944187 | validation: 0.15076137920025184]
	TIME [epoch: 8.33 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22272163822740615		[learning rate: 0.0011773]
	Learning Rate: 0.00117726
	LOSS [training: 0.22272163822740615 | validation: 0.20617938246212447]
	TIME [epoch: 8.35 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24496321855775655		[learning rate: 0.0011745]
	Learning Rate: 0.00117448
	LOSS [training: 0.24496321855775655 | validation: 0.17641151940213]
	TIME [epoch: 8.34 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2918528556733499		[learning rate: 0.0011717]
	Learning Rate: 0.00117171
	LOSS [training: 0.2918528556733499 | validation: 0.16265292845181617]
	TIME [epoch: 8.33 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19589067127166926		[learning rate: 0.0011689]
	Learning Rate: 0.00116895
	LOSS [training: 0.19589067127166926 | validation: 0.25130593964599746]
	TIME [epoch: 8.33 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21417270301491867		[learning rate: 0.0011662]
	Learning Rate: 0.00116619
	LOSS [training: 0.21417270301491867 | validation: 0.27053442369101105]
	TIME [epoch: 8.33 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18902722555786716		[learning rate: 0.0011634]
	Learning Rate: 0.00116344
	LOSS [training: 0.18902722555786716 | validation: 0.8641136720956335]
	TIME [epoch: 8.35 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3565111344068196		[learning rate: 0.0011607]
	Learning Rate: 0.00116069
	LOSS [training: 0.3565111344068196 | validation: 0.18327849699151605]
	TIME [epoch: 8.33 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19623742615264256		[learning rate: 0.001158]
	Learning Rate: 0.00115796
	LOSS [training: 0.19623742615264256 | validation: 0.15950931397383245]
	TIME [epoch: 8.33 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17427451117192388		[learning rate: 0.0011552]
	Learning Rate: 0.00115523
	LOSS [training: 0.17427451117192388 | validation: 0.14983702376715824]
	TIME [epoch: 8.33 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16742810785566056		[learning rate: 0.0011525]
	Learning Rate: 0.0011525
	LOSS [training: 0.16742810785566056 | validation: 0.15957037759275705]
	TIME [epoch: 8.35 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19242917132085474		[learning rate: 0.0011498]
	Learning Rate: 0.00114978
	LOSS [training: 0.19242917132085474 | validation: 0.22481967731246522]
	TIME [epoch: 8.33 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22004476898297837		[learning rate: 0.0011471]
	Learning Rate: 0.00114707
	LOSS [training: 0.22004476898297837 | validation: 0.27618582997047725]
	TIME [epoch: 8.33 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17720709129148435		[learning rate: 0.0011444]
	Learning Rate: 0.00114436
	LOSS [training: 0.17720709129148435 | validation: 0.1759305066126019]
	TIME [epoch: 8.33 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28388739434348675		[learning rate: 0.0011417]
	Learning Rate: 0.00114166
	LOSS [training: 0.28388739434348675 | validation: 0.2899781315078237]
	TIME [epoch: 8.34 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2966477461806629		[learning rate: 0.001139]
	Learning Rate: 0.00113897
	LOSS [training: 0.2966477461806629 | validation: 0.22909959462680723]
	TIME [epoch: 8.34 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20313247439086562		[learning rate: 0.0011363]
	Learning Rate: 0.00113628
	LOSS [training: 0.20313247439086562 | validation: 0.15617180465327063]
	TIME [epoch: 8.33 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18147527933334767		[learning rate: 0.0011336]
	Learning Rate: 0.0011336
	LOSS [training: 0.18147527933334767 | validation: 0.16649576777285502]
	TIME [epoch: 8.32 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16497776885070034		[learning rate: 0.0011309]
	Learning Rate: 0.00113093
	LOSS [training: 0.16497776885070034 | validation: 0.234920506795119]
	TIME [epoch: 8.33 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22949615242685656		[learning rate: 0.0011283]
	Learning Rate: 0.00112826
	LOSS [training: 0.22949615242685656 | validation: 0.3489139175140279]
	TIME [epoch: 8.35 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18500622245501927		[learning rate: 0.0011256]
	Learning Rate: 0.0011256
	LOSS [training: 0.18500622245501927 | validation: 0.1395532960477295]
	TIME [epoch: 8.33 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1790854051097645		[learning rate: 0.0011229]
	Learning Rate: 0.00112295
	LOSS [training: 0.1790854051097645 | validation: 0.1451789184611904]
	TIME [epoch: 8.33 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15284364391231064		[learning rate: 0.0011203]
	Learning Rate: 0.0011203
	LOSS [training: 0.15284364391231064 | validation: 0.15541496248615616]
	TIME [epoch: 8.33 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1912807025497168		[learning rate: 0.0011177]
	Learning Rate: 0.00111765
	LOSS [training: 0.1912807025497168 | validation: 0.18340672507200262]
	TIME [epoch: 8.35 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2792624870555128		[learning rate: 0.001115]
	Learning Rate: 0.00111502
	LOSS [training: 0.2792624870555128 | validation: 0.14871570701990522]
	TIME [epoch: 8.33 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18114364509609124		[learning rate: 0.0011124]
	Learning Rate: 0.00111239
	LOSS [training: 0.18114364509609124 | validation: 0.17623378907543133]
	TIME [epoch: 8.33 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16309973390374533		[learning rate: 0.0011098]
	Learning Rate: 0.00110976
	LOSS [training: 0.16309973390374533 | validation: 0.29199674773251005]
	TIME [epoch: 8.32 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18452105711414118		[learning rate: 0.0011071]
	Learning Rate: 0.00110715
	LOSS [training: 0.18452105711414118 | validation: 0.29608668083950407]
	TIME [epoch: 8.34 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18293504076851633		[learning rate: 0.0011045]
	Learning Rate: 0.00110453
	LOSS [training: 0.18293504076851633 | validation: 0.173158544394016]
	TIME [epoch: 8.33 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22912517683948397		[learning rate: 0.0011019]
	Learning Rate: 0.00110193
	LOSS [training: 0.22912517683948397 | validation: 0.2139244485204092]
	TIME [epoch: 8.33 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2632518843600061		[learning rate: 0.0010993]
	Learning Rate: 0.00109933
	LOSS [training: 0.2632518843600061 | validation: 0.19629720540655338]
	TIME [epoch: 8.33 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1943279893655889		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.1943279893655889 | validation: 0.1348718678859483]
	TIME [epoch: 8.33 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18525579951925975		[learning rate: 0.0010942]
	Learning Rate: 0.00109415
	LOSS [training: 0.18525579951925975 | validation: 0.1281182075330628]
	TIME [epoch: 8.35 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2615117576981044		[learning rate: 0.0010916]
	Learning Rate: 0.00109157
	LOSS [training: 0.2615117576981044 | validation: 0.27351428504639713]
	TIME [epoch: 8.33 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17027631456449518		[learning rate: 0.001089]
	Learning Rate: 0.00108899
	LOSS [training: 0.17027631456449518 | validation: 0.1677132309154765]
	TIME [epoch: 8.33 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18222474939831246		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.18222474939831246 | validation: 0.22347408897678422]
	TIME [epoch: 8.33 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2713393264372834		[learning rate: 0.0010839]
	Learning Rate: 0.00108386
	LOSS [training: 0.2713393264372834 | validation: 0.18717236962335537]
	TIME [epoch: 8.35 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2085671425131948		[learning rate: 0.0010813]
	Learning Rate: 0.00108131
	LOSS [training: 0.2085671425131948 | validation: 0.17836527363270527]
	TIME [epoch: 8.33 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16379566350903033		[learning rate: 0.0010788]
	Learning Rate: 0.00107876
	LOSS [training: 0.16379566350903033 | validation: 0.23838257309961255]
	TIME [epoch: 8.33 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23481706230977265		[learning rate: 0.0010762]
	Learning Rate: 0.00107621
	LOSS [training: 0.23481706230977265 | validation: 0.22998833634806903]
	TIME [epoch: 8.33 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1814076560024537		[learning rate: 0.0010737]
	Learning Rate: 0.00107367
	LOSS [training: 0.1814076560024537 | validation: 0.20395522427819526]
	TIME [epoch: 8.34 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18081588942245558		[learning rate: 0.0010711]
	Learning Rate: 0.00107114
	LOSS [training: 0.18081588942245558 | validation: 0.12921302136271134]
	TIME [epoch: 8.34 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1830987841293958		[learning rate: 0.0010686]
	Learning Rate: 0.00106861
	LOSS [training: 0.1830987841293958 | validation: 0.1346565048198267]
	TIME [epoch: 8.33 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15482187157860688		[learning rate: 0.0010661]
	Learning Rate: 0.00106609
	LOSS [training: 0.15482187157860688 | validation: 0.23380653027326243]
	TIME [epoch: 8.33 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1851880102425243		[learning rate: 0.0010636]
	Learning Rate: 0.00106358
	LOSS [training: 0.1851880102425243 | validation: 0.16392646449606224]
	TIME [epoch: 8.33 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17355304480684453		[learning rate: 0.0010611]
	Learning Rate: 0.00106107
	LOSS [training: 0.17355304480684453 | validation: 0.17067199796339655]
	TIME [epoch: 8.36 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17933437108556396		[learning rate: 0.0010586]
	Learning Rate: 0.00105857
	LOSS [training: 0.17933437108556396 | validation: 0.188040502312674]
	TIME [epoch: 8.33 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18610124000114495		[learning rate: 0.0010561]
	Learning Rate: 0.00105607
	LOSS [training: 0.18610124000114495 | validation: 0.2145273108593529]
	TIME [epoch: 8.33 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2024184813518422		[learning rate: 0.0010536]
	Learning Rate: 0.00105358
	LOSS [training: 0.2024184813518422 | validation: 0.16781105196760443]
	TIME [epoch: 8.33 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2072181513590729		[learning rate: 0.0010511]
	Learning Rate: 0.00105109
	LOSS [training: 0.2072181513590729 | validation: 0.18307349341093376]
	TIME [epoch: 8.35 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19999318455978837		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.19999318455978837 | validation: 0.14848135080775335]
	TIME [epoch: 8.32 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2132881562675261		[learning rate: 0.0010461]
	Learning Rate: 0.00104614
	LOSS [training: 0.2132881562675261 | validation: 0.3025374958162388]
	TIME [epoch: 8.32 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21064542972664527		[learning rate: 0.0010437]
	Learning Rate: 0.00104367
	LOSS [training: 0.21064542972664527 | validation: 0.13675945721276778]
	TIME [epoch: 8.32 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19438311399477765		[learning rate: 0.0010412]
	Learning Rate: 0.00104121
	LOSS [training: 0.19438311399477765 | validation: 0.16490069115731484]
	TIME [epoch: 8.35 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21588275218400937		[learning rate: 0.0010388]
	Learning Rate: 0.00103875
	LOSS [training: 0.21588275218400937 | validation: 0.20219530031427022]
	TIME [epoch: 8.34 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1612127971779162		[learning rate: 0.0010363]
	Learning Rate: 0.0010363
	LOSS [training: 0.1612127971779162 | validation: 0.1523280180342428]
	TIME [epoch: 8.32 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1982730191133911		[learning rate: 0.0010339]
	Learning Rate: 0.00103386
	LOSS [training: 0.1982730191133911 | validation: 0.17495701907266423]
	TIME [epoch: 8.32 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17950637249392334		[learning rate: 0.0010314]
	Learning Rate: 0.00103142
	LOSS [training: 0.17950637249392334 | validation: 0.1405353594482378]
	TIME [epoch: 8.33 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1444464012754112		[learning rate: 0.001029]
	Learning Rate: 0.00102899
	LOSS [training: 0.1444464012754112 | validation: 0.16959388768046008]
	TIME [epoch: 8.34 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1772727159949278		[learning rate: 0.0010266]
	Learning Rate: 0.00102656
	LOSS [training: 0.1772727159949278 | validation: 0.2726676276488571]
	TIME [epoch: 8.33 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1610708355694398		[learning rate: 0.0010241]
	Learning Rate: 0.00102414
	LOSS [training: 0.1610708355694398 | validation: 0.1470359369022311]
	TIME [epoch: 8.32 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15662726794444654		[learning rate: 0.0010217]
	Learning Rate: 0.00102172
	LOSS [training: 0.15662726794444654 | validation: 0.12749539001528354]
	TIME [epoch: 8.32 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15404681804617967		[learning rate: 0.0010193]
	Learning Rate: 0.00101931
	LOSS [training: 0.15404681804617967 | validation: 0.2229745715519802]
	TIME [epoch: 8.34 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1689725500503771		[learning rate: 0.0010169]
	Learning Rate: 0.00101691
	LOSS [training: 0.1689725500503771 | validation: 0.20957861097976221]
	TIME [epoch: 8.33 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1847097873931615		[learning rate: 0.0010145]
	Learning Rate: 0.00101451
	LOSS [training: 0.1847097873931615 | validation: 0.13525973119304752]
	TIME [epoch: 8.33 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16494151228562637		[learning rate: 0.0010121]
	Learning Rate: 0.00101212
	LOSS [training: 0.16494151228562637 | validation: 0.13023011366919113]
	TIME [epoch: 8.33 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14585741032152152		[learning rate: 0.0010097]
	Learning Rate: 0.00100973
	LOSS [training: 0.14585741032152152 | validation: 0.15242850272138397]
	TIME [epoch: 8.34 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18873497927851215		[learning rate: 0.0010073]
	Learning Rate: 0.00100735
	LOSS [training: 0.18873497927851215 | validation: 0.12790754849252922]
	TIME [epoch: 8.34 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15966242269836678		[learning rate: 0.001005]
	Learning Rate: 0.00100497
	LOSS [training: 0.15966242269836678 | validation: 0.18648174164013015]
	TIME [epoch: 8.33 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17889474276907183		[learning rate: 0.0010026]
	Learning Rate: 0.0010026
	LOSS [training: 0.17889474276907183 | validation: 0.18233185106256003]
	TIME [epoch: 8.32 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15805945743766525		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.15805945743766525 | validation: 0.15466313092936826]
	TIME [epoch: 8.33 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15768918455436365		[learning rate: 0.00099788]
	Learning Rate: 0.000997877
	LOSS [training: 0.15768918455436365 | validation: 0.2954921827511523]
	TIME [epoch: 8.35 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19266069872150982		[learning rate: 0.00099552]
	Learning Rate: 0.000995523
	LOSS [training: 0.19266069872150982 | validation: 0.2132418787644048]
	TIME [epoch: 8.33 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1727966679451113		[learning rate: 0.00099317]
	Learning Rate: 0.000993175
	LOSS [training: 0.1727966679451113 | validation: 0.2121709252421431]
	TIME [epoch: 8.32 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18942233814733786		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.18942233814733786 | validation: 0.18864489327530765]
	TIME [epoch: 8.33 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16602792960044283		[learning rate: 0.00098849]
	Learning Rate: 0.000988495
	LOSS [training: 0.16602792960044283 | validation: 0.19176460368335124]
	TIME [epoch: 8.35 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22089695860752895		[learning rate: 0.00098616]
	Learning Rate: 0.000986163
	LOSS [training: 0.22089695860752895 | validation: 0.20692334529498332]
	TIME [epoch: 8.33 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14031189859666202		[learning rate: 0.00098384]
	Learning Rate: 0.000983837
	LOSS [training: 0.14031189859666202 | validation: 0.14663297442262851]
	TIME [epoch: 8.33 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13617920783518359		[learning rate: 0.00098152]
	Learning Rate: 0.000981516
	LOSS [training: 0.13617920783518359 | validation: 0.14938200223269466]
	TIME [epoch: 8.32 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1490195516331587		[learning rate: 0.0009792]
	Learning Rate: 0.000979201
	LOSS [training: 0.1490195516331587 | validation: 0.1402438057619557]
	TIME [epoch: 8.35 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21924762214589064		[learning rate: 0.00097689]
	Learning Rate: 0.000976891
	LOSS [training: 0.21924762214589064 | validation: 0.2194351098852421]
	TIME [epoch: 8.34 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18364871545423184		[learning rate: 0.00097459]
	Learning Rate: 0.000974587
	LOSS [training: 0.18364871545423184 | validation: 0.16224240957245098]
	TIME [epoch: 8.32 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22263330859945785		[learning rate: 0.00097229]
	Learning Rate: 0.000972288
	LOSS [training: 0.22263330859945785 | validation: 0.1498056247025676]
	TIME [epoch: 8.32 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13667673494343535		[learning rate: 0.00096999]
	Learning Rate: 0.000969994
	LOSS [training: 0.13667673494343535 | validation: 0.3372108873854911]
	TIME [epoch: 8.33 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14909104151657518		[learning rate: 0.00096771]
	Learning Rate: 0.000967706
	LOSS [training: 0.14909104151657518 | validation: 0.21042612485193093]
	TIME [epoch: 8.35 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14190093821014224		[learning rate: 0.00096542]
	Learning Rate: 0.000965424
	LOSS [training: 0.14190093821014224 | validation: 0.15336446625491532]
	TIME [epoch: 8.33 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18540031745672922		[learning rate: 0.00096315]
	Learning Rate: 0.000963146
	LOSS [training: 0.18540031745672922 | validation: 0.1853640919012193]
	TIME [epoch: 8.31 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1505088340997152		[learning rate: 0.00096087]
	Learning Rate: 0.000960874
	LOSS [training: 0.1505088340997152 | validation: 0.12540471399651826]
	TIME [epoch: 8.33 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1470949316431167		[learning rate: 0.00095861]
	Learning Rate: 0.000958608
	LOSS [training: 0.1470949316431167 | validation: 0.2213780777177472]
	TIME [epoch: 8.35 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1782922803748604		[learning rate: 0.00095635]
	Learning Rate: 0.000956347
	LOSS [training: 0.1782922803748604 | validation: 0.25238352570888445]
	TIME [epoch: 8.33 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19197507037813505		[learning rate: 0.00095409]
	Learning Rate: 0.000954091
	LOSS [training: 0.19197507037813505 | validation: 0.18984553810493293]
	TIME [epoch: 8.32 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19630262508058133		[learning rate: 0.00095184]
	Learning Rate: 0.00095184
	LOSS [training: 0.19630262508058133 | validation: 0.24338477596513017]
	TIME [epoch: 8.32 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15432894452465937		[learning rate: 0.0009496]
	Learning Rate: 0.000949595
	LOSS [training: 0.15432894452465937 | validation: 0.15526068961966744]
	TIME [epoch: 8.34 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25885121291550106		[learning rate: 0.00094736]
	Learning Rate: 0.000947355
	LOSS [training: 0.25885121291550106 | validation: 0.16665068838101194]
	TIME [epoch: 8.34 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17857159811865833		[learning rate: 0.00094512]
	Learning Rate: 0.000945121
	LOSS [training: 0.17857159811865833 | validation: 0.13582614483237304]
	TIME [epoch: 8.32 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1971276588135853		[learning rate: 0.00094289]
	Learning Rate: 0.000942891
	LOSS [training: 0.1971276588135853 | validation: 0.15440143517423222]
	TIME [epoch: 8.33 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21813517739716365		[learning rate: 0.00094067]
	Learning Rate: 0.000940667
	LOSS [training: 0.21813517739716365 | validation: 0.19906790031879024]
	TIME [epoch: 8.32 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20512972252826978		[learning rate: 0.00093845]
	Learning Rate: 0.000938448
	LOSS [training: 0.20512972252826978 | validation: 0.16477031795667813]
	TIME [epoch: 8.35 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20887866405749564		[learning rate: 0.00093623]
	Learning Rate: 0.000936234
	LOSS [training: 0.20887866405749564 | validation: 0.22614525842138145]
	TIME [epoch: 8.33 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21929684209519537		[learning rate: 0.00093403]
	Learning Rate: 0.000934026
	LOSS [training: 0.21929684209519537 | validation: 0.25087051036252844]
	TIME [epoch: 8.33 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20303856970003395		[learning rate: 0.00093182]
	Learning Rate: 0.000931823
	LOSS [training: 0.20303856970003395 | validation: 0.2057217752208707]
	TIME [epoch: 8.33 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18664737985049157		[learning rate: 0.00092962]
	Learning Rate: 0.000929625
	LOSS [training: 0.18664737985049157 | validation: 0.17738872516918602]
	TIME [epoch: 8.35 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16427597645955574		[learning rate: 0.00092743]
	Learning Rate: 0.000927432
	LOSS [training: 0.16427597645955574 | validation: 0.14400950319380418]
	TIME [epoch: 8.33 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16430925651958406		[learning rate: 0.00092524]
	Learning Rate: 0.000925244
	LOSS [training: 0.16430925651958406 | validation: 0.19883187676919573]
	TIME [epoch: 8.33 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1739431915132877		[learning rate: 0.00092306]
	Learning Rate: 0.000923062
	LOSS [training: 0.1739431915132877 | validation: 0.17153158837186802]
	TIME [epoch: 8.33 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18043319617186232		[learning rate: 0.00092088]
	Learning Rate: 0.000920884
	LOSS [training: 0.18043319617186232 | validation: 0.1957816322541336]
	TIME [epoch: 8.34 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16390514879670123		[learning rate: 0.00091871]
	Learning Rate: 0.000918712
	LOSS [training: 0.16390514879670123 | validation: 0.19024256447971802]
	TIME [epoch: 8.34 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14608175262085568		[learning rate: 0.00091654]
	Learning Rate: 0.000916545
	LOSS [training: 0.14608175262085568 | validation: 0.1421804158845562]
	TIME [epoch: 8.33 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17156137083190232		[learning rate: 0.00091438]
	Learning Rate: 0.000914383
	LOSS [training: 0.17156137083190232 | validation: 0.14703918693984777]
	TIME [epoch: 8.32 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15220582696129853		[learning rate: 0.00091223]
	Learning Rate: 0.000912226
	LOSS [training: 0.15220582696129853 | validation: 0.16061754907800535]
	TIME [epoch: 8.33 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2121628148600962		[learning rate: 0.00091007]
	Learning Rate: 0.000910074
	LOSS [training: 0.2121628148600962 | validation: 0.4718330725728814]
	TIME [epoch: 8.35 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21989757495369036		[learning rate: 0.00090793]
	Learning Rate: 0.000907928
	LOSS [training: 0.21989757495369036 | validation: 0.3547999509908668]
	TIME [epoch: 8.33 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20849427514809604		[learning rate: 0.00090579]
	Learning Rate: 0.000905786
	LOSS [training: 0.20849427514809604 | validation: 0.16072034782685773]
	TIME [epoch: 8.32 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15507462976319586		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.15507462976319586 | validation: 0.447081180197826]
	TIME [epoch: 8.33 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1619470700963559		[learning rate: 0.00090152]
	Learning Rate: 0.000901518
	LOSS [training: 0.1619470700963559 | validation: 0.1186992406585597]
	TIME [epoch: 8.34 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14571907731335348		[learning rate: 0.00089939]
	Learning Rate: 0.000899391
	LOSS [training: 0.14571907731335348 | validation: 0.17704937034766718]
	TIME [epoch: 8.33 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18491630738742462		[learning rate: 0.00089727]
	Learning Rate: 0.00089727
	LOSS [training: 0.18491630738742462 | validation: 0.19982559753439771]
	TIME [epoch: 8.33 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14360877763273885		[learning rate: 0.00089515]
	Learning Rate: 0.000895153
	LOSS [training: 0.14360877763273885 | validation: 0.2556146909780251]
	TIME [epoch: 8.32 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15532217867776896		[learning rate: 0.00089304]
	Learning Rate: 0.000893042
	LOSS [training: 0.15532217867776896 | validation: 0.137376230267143]
	TIME [epoch: 8.34 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1657083597461881		[learning rate: 0.00089094]
	Learning Rate: 0.000890935
	LOSS [training: 0.1657083597461881 | validation: 0.2935342341620503]
	TIME [epoch: 8.34 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1625685229732033		[learning rate: 0.00088883]
	Learning Rate: 0.000888834
	LOSS [training: 0.1625685229732033 | validation: 0.173956453017807]
	TIME [epoch: 8.32 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13242685363675322		[learning rate: 0.00088674]
	Learning Rate: 0.000886737
	LOSS [training: 0.13242685363675322 | validation: 0.18789237134234524]
	TIME [epoch: 8.33 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16735977053643136		[learning rate: 0.00088465]
	Learning Rate: 0.000884645
	LOSS [training: 0.16735977053643136 | validation: 0.1402832799821625]
	TIME [epoch: 8.33 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16305248871293793		[learning rate: 0.00088256]
	Learning Rate: 0.000882559
	LOSS [training: 0.16305248871293793 | validation: 0.15191585161791982]
	TIME [epoch: 8.35 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19003560246096257		[learning rate: 0.00088048]
	Learning Rate: 0.000880477
	LOSS [training: 0.19003560246096257 | validation: 0.13273055389440158]
	TIME [epoch: 8.32 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18504889789004986		[learning rate: 0.0008784]
	Learning Rate: 0.0008784
	LOSS [training: 0.18504889789004986 | validation: 0.1732650181867968]
	TIME [epoch: 8.33 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1643758602550168		[learning rate: 0.00087633]
	Learning Rate: 0.000876328
	LOSS [training: 0.1643758602550168 | validation: 0.15684511803774118]
	TIME [epoch: 8.32 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1305029991485186		[learning rate: 0.00087426]
	Learning Rate: 0.000874261
	LOSS [training: 0.1305029991485186 | validation: 0.14190456883807523]
	TIME [epoch: 8.35 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1814807204961741		[learning rate: 0.0008722]
	Learning Rate: 0.000872199
	LOSS [training: 0.1814807204961741 | validation: 0.24272096574586274]
	TIME [epoch: 8.33 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1806718889327663		[learning rate: 0.00087014]
	Learning Rate: 0.000870141
	LOSS [training: 0.1806718889327663 | validation: 0.21431914494537813]
	TIME [epoch: 8.32 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14556778213307212		[learning rate: 0.00086809]
	Learning Rate: 0.000868089
	LOSS [training: 0.14556778213307212 | validation: 0.15782905962462604]
	TIME [epoch: 8.32 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1560872773364652		[learning rate: 0.00086604]
	Learning Rate: 0.000866041
	LOSS [training: 0.1560872773364652 | validation: 0.1334481120891922]
	TIME [epoch: 8.34 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13633112895850813		[learning rate: 0.000864]
	Learning Rate: 0.000863998
	LOSS [training: 0.13633112895850813 | validation: 0.12677646302030693]
	TIME [epoch: 8.34 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1282217739800601		[learning rate: 0.00086196]
	Learning Rate: 0.00086196
	LOSS [training: 0.1282217739800601 | validation: 0.13724898569164876]
	TIME [epoch: 8.32 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17052390777060253		[learning rate: 0.00085993]
	Learning Rate: 0.000859927
	LOSS [training: 0.17052390777060253 | validation: 0.2752462609547273]
	TIME [epoch: 8.32 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19203591024055208		[learning rate: 0.0008579]
	Learning Rate: 0.000857898
	LOSS [training: 0.19203591024055208 | validation: 0.13324044760734902]
	TIME [epoch: 8.33 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15834718599452322		[learning rate: 0.00085587]
	Learning Rate: 0.000855875
	LOSS [training: 0.15834718599452322 | validation: 0.14472388495583371]
	TIME [epoch: 8.35 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17716325347507667		[learning rate: 0.00085386]
	Learning Rate: 0.000853856
	LOSS [training: 0.17716325347507667 | validation: 0.20980167296093816]
	TIME [epoch: 8.33 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.144915266560587		[learning rate: 0.00085184]
	Learning Rate: 0.000851842
	LOSS [training: 0.144915266560587 | validation: 0.3212067840607937]
	TIME [epoch: 8.32 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15177331127324584		[learning rate: 0.00084983]
	Learning Rate: 0.000849832
	LOSS [training: 0.15177331127324584 | validation: 0.13702754320095428]
	TIME [epoch: 8.32 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1655278331189595		[learning rate: 0.00084783]
	Learning Rate: 0.000847828
	LOSS [training: 0.1655278331189595 | validation: 0.13956367919455637]
	TIME [epoch: 8.35 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1536440369527398		[learning rate: 0.00084583]
	Learning Rate: 0.000845828
	LOSS [training: 0.1536440369527398 | validation: 0.2559433150964803]
	TIME [epoch: 8.33 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16505275126281652		[learning rate: 0.00084383]
	Learning Rate: 0.000843833
	LOSS [training: 0.16505275126281652 | validation: 0.12404931564060022]
	TIME [epoch: 8.33 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14316174675170706		[learning rate: 0.00084184]
	Learning Rate: 0.000841842
	LOSS [training: 0.14316174675170706 | validation: 0.17637063276321313]
	TIME [epoch: 8.33 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17381503014876326		[learning rate: 0.00083986]
	Learning Rate: 0.000839856
	LOSS [training: 0.17381503014876326 | validation: 0.3561809356079202]
	TIME [epoch: 8.35 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20751511795223573		[learning rate: 0.00083788]
	Learning Rate: 0.000837876
	LOSS [training: 0.20751511795223573 | validation: 0.16150480419764018]
	TIME [epoch: 8.33 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17282565900843352		[learning rate: 0.0008359]
	Learning Rate: 0.000835899
	LOSS [training: 0.17282565900843352 | validation: 0.18231960921666493]
	TIME [epoch: 8.33 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16685418662463228		[learning rate: 0.00083393]
	Learning Rate: 0.000833927
	LOSS [training: 0.16685418662463228 | validation: 0.1865322282510325]
	TIME [epoch: 8.31 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18423551010937686		[learning rate: 0.00083196]
	Learning Rate: 0.00083196
	LOSS [training: 0.18423551010937686 | validation: 0.21132150373218883]
	TIME [epoch: 8.33 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15827584554721746		[learning rate: 0.00083]
	Learning Rate: 0.000829998
	LOSS [training: 0.15827584554721746 | validation: 0.15897453252317756]
	TIME [epoch: 8.35 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16525027033909243		[learning rate: 0.00082804]
	Learning Rate: 0.00082804
	LOSS [training: 0.16525027033909243 | validation: 0.17521754462029354]
	TIME [epoch: 8.32 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14713782274595555		[learning rate: 0.00082609]
	Learning Rate: 0.000826087
	LOSS [training: 0.14713782274595555 | validation: 0.2937823599965454]
	TIME [epoch: 8.32 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1687684560216486		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.1687684560216486 | validation: 0.2205186443226669]
	TIME [epoch: 8.32 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14009986880541578		[learning rate: 0.00082219]
	Learning Rate: 0.000822194
	LOSS [training: 0.14009986880541578 | validation: 0.2931162608341322]
	TIME [epoch: 8.35 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2072858354222463		[learning rate: 0.00082025]
	Learning Rate: 0.000820254
	LOSS [training: 0.2072858354222463 | validation: 0.1753007501390309]
	TIME [epoch: 8.33 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16014767860443702		[learning rate: 0.00081832]
	Learning Rate: 0.00081832
	LOSS [training: 0.16014767860443702 | validation: 0.14500029429165473]
	TIME [epoch: 8.33 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1377641741733025		[learning rate: 0.00081639]
	Learning Rate: 0.000816389
	LOSS [training: 0.1377641741733025 | validation: 0.11166274971087949]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_1111.pth
	Model improved!!!
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15026774468184947		[learning rate: 0.00081446]
	Learning Rate: 0.000814464
	LOSS [training: 0.15026774468184947 | validation: 0.20906681159510837]
	TIME [epoch: 8.34 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.163086481874064		[learning rate: 0.00081254]
	Learning Rate: 0.000812543
	LOSS [training: 0.163086481874064 | validation: 0.18734966509930764]
	TIME [epoch: 8.33 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14933651185973912		[learning rate: 0.00081063]
	Learning Rate: 0.000810626
	LOSS [training: 0.14933651185973912 | validation: 0.18238688818883414]
	TIME [epoch: 8.32 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17189981179082858		[learning rate: 0.00080871]
	Learning Rate: 0.000808714
	LOSS [training: 0.17189981179082858 | validation: 0.14466954853694336]
	TIME [epoch: 8.31 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14307888571276384		[learning rate: 0.00080681]
	Learning Rate: 0.000806806
	LOSS [training: 0.14307888571276384 | validation: 0.11468910360814626]
	TIME [epoch: 8.33 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12972546493389936		[learning rate: 0.0008049]
	Learning Rate: 0.000804903
	LOSS [training: 0.12972546493389936 | validation: 0.1314187269485796]
	TIME [epoch: 8.35 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1377584554505032		[learning rate: 0.000803]
	Learning Rate: 0.000803004
	LOSS [training: 0.1377584554505032 | validation: 0.14090186348771414]
	TIME [epoch: 8.33 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11665213599802268		[learning rate: 0.00080111]
	Learning Rate: 0.00080111
	LOSS [training: 0.11665213599802268 | validation: 0.13621621488602076]
	TIME [epoch: 8.32 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15251557893188125		[learning rate: 0.00079922]
	Learning Rate: 0.000799221
	LOSS [training: 0.15251557893188125 | validation: 0.13932199981827834]
	TIME [epoch: 8.33 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1495637349252261		[learning rate: 0.00079734]
	Learning Rate: 0.000797335
	LOSS [training: 0.1495637349252261 | validation: 0.18683750098047341]
	TIME [epoch: 8.34 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21030442912664307		[learning rate: 0.00079545]
	Learning Rate: 0.000795454
	LOSS [training: 0.21030442912664307 | validation: 0.3399617238811351]
	TIME [epoch: 8.33 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15670462587956385		[learning rate: 0.00079358]
	Learning Rate: 0.000793578
	LOSS [training: 0.15670462587956385 | validation: 0.11677439005242307]
	TIME [epoch: 8.33 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1348331468681636		[learning rate: 0.00079171]
	Learning Rate: 0.000791706
	LOSS [training: 0.1348331468681636 | validation: 0.12534084684448393]
	TIME [epoch: 8.32 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14608843528291052		[learning rate: 0.00078984]
	Learning Rate: 0.000789839
	LOSS [training: 0.14608843528291052 | validation: 0.2177833821945614]
	TIME [epoch: 8.34 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14117549900442672		[learning rate: 0.00078798]
	Learning Rate: 0.000787976
	LOSS [training: 0.14117549900442672 | validation: 0.1963389888751917]
	TIME [epoch: 8.33 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18304487843309752		[learning rate: 0.00078612]
	Learning Rate: 0.000786117
	LOSS [training: 0.18304487843309752 | validation: 0.1813260263538558]
	TIME [epoch: 8.33 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14934465794441812		[learning rate: 0.00078426]
	Learning Rate: 0.000784263
	LOSS [training: 0.14934465794441812 | validation: 0.1315614617257556]
	TIME [epoch: 8.32 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14226733059164437		[learning rate: 0.00078241]
	Learning Rate: 0.000782413
	LOSS [training: 0.14226733059164437 | validation: 0.16031305737875123]
	TIME [epoch: 8.32 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13753535960903257		[learning rate: 0.00078057]
	Learning Rate: 0.000780567
	LOSS [training: 0.13753535960903257 | validation: 0.14960540272978454]
	TIME [epoch: 8.36 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17905926270114536		[learning rate: 0.00077873]
	Learning Rate: 0.000778726
	LOSS [training: 0.17905926270114536 | validation: 0.1979952600619263]
	TIME [epoch: 8.32 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22652026532608266		[learning rate: 0.00077689]
	Learning Rate: 0.000776889
	LOSS [training: 0.22652026532608266 | validation: 0.16755579441266616]
	TIME [epoch: 8.31 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1767917392652635		[learning rate: 0.00077506]
	Learning Rate: 0.000775056
	LOSS [training: 0.1767917392652635 | validation: 0.12911350414846853]
	TIME [epoch: 8.33 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20743913974540312		[learning rate: 0.00077323]
	Learning Rate: 0.000773228
	LOSS [training: 0.20743913974540312 | validation: 0.13021444605706606]
	TIME [epoch: 8.34 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14049978797502027		[learning rate: 0.0007714]
	Learning Rate: 0.000771404
	LOSS [training: 0.14049978797502027 | validation: 0.1956105284887252]
	TIME [epoch: 8.32 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18657629399952302		[learning rate: 0.00076958]
	Learning Rate: 0.000769585
	LOSS [training: 0.18657629399952302 | validation: 0.11920600641655336]
	TIME [epoch: 8.32 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15973273075868752		[learning rate: 0.00076777]
	Learning Rate: 0.000767769
	LOSS [training: 0.15973273075868752 | validation: 0.19283050391061624]
	TIME [epoch: 8.33 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15595067150664585		[learning rate: 0.00076596]
	Learning Rate: 0.000765958
	LOSS [training: 0.15595067150664585 | validation: 0.12372766432361113]
	TIME [epoch: 8.35 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1365519883912591		[learning rate: 0.00076415]
	Learning Rate: 0.000764151
	LOSS [training: 0.1365519883912591 | validation: 0.13577094573643034]
	TIME [epoch: 8.33 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14976980118475144		[learning rate: 0.00076235]
	Learning Rate: 0.000762349
	LOSS [training: 0.14976980118475144 | validation: 0.1443239305302882]
	TIME [epoch: 8.33 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11381427541266013		[learning rate: 0.00076055]
	Learning Rate: 0.000760551
	LOSS [training: 0.11381427541266013 | validation: 0.18755039579870236]
	TIME [epoch: 8.32 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12780222337937105		[learning rate: 0.00075876]
	Learning Rate: 0.000758757
	LOSS [training: 0.12780222337937105 | validation: 0.14171423697077135]
	TIME [epoch: 8.33 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14517241451426136		[learning rate: 0.00075697]
	Learning Rate: 0.000756967
	LOSS [training: 0.14517241451426136 | validation: 0.13388416159346136]
	TIME [epoch: 8.35 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13692419581604764		[learning rate: 0.00075518]
	Learning Rate: 0.000755181
	LOSS [training: 0.13692419581604764 | validation: 0.2234150218398281]
	TIME [epoch: 8.33 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17091859782897162		[learning rate: 0.0007534]
	Learning Rate: 0.0007534
	LOSS [training: 0.17091859782897162 | validation: 0.13394144355270374]
	TIME [epoch: 8.32 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2056758394589176		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.2056758394589176 | validation: 0.1663280040208191]
	TIME [epoch: 8.32 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1441156617653372		[learning rate: 0.00074985]
	Learning Rate: 0.00074985
	LOSS [training: 0.1441156617653372 | validation: 0.14087809968214615]
	TIME [epoch: 8.35 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14723208226923212		[learning rate: 0.00074808]
	Learning Rate: 0.000748081
	LOSS [training: 0.14723208226923212 | validation: 0.16807588462811485]
	TIME [epoch: 8.33 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14586951608022353		[learning rate: 0.00074632]
	Learning Rate: 0.000746316
	LOSS [training: 0.14586951608022353 | validation: 0.1535276487445496]
	TIME [epoch: 8.32 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17163361208945593		[learning rate: 0.00074456]
	Learning Rate: 0.000744556
	LOSS [training: 0.17163361208945593 | validation: 0.3067011900406623]
	TIME [epoch: 8.32 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21915667004859815		[learning rate: 0.0007428]
	Learning Rate: 0.0007428
	LOSS [training: 0.21915667004859815 | validation: 0.29956771353763034]
	TIME [epoch: 8.34 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22611646649012168		[learning rate: 0.00074105]
	Learning Rate: 0.000741048
	LOSS [training: 0.22611646649012168 | validation: 0.22142200349668037]
	TIME [epoch: 8.33 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1867558282616463		[learning rate: 0.0007393]
	Learning Rate: 0.0007393
	LOSS [training: 0.1867558282616463 | validation: 0.19127967342013347]
	TIME [epoch: 8.32 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13809932036721376		[learning rate: 0.00073756]
	Learning Rate: 0.000737556
	LOSS [training: 0.13809932036721376 | validation: 0.18900245541643435]
	TIME [epoch: 8.3 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1313602771887484		[learning rate: 0.00073582]
	Learning Rate: 0.000735816
	LOSS [training: 0.1313602771887484 | validation: 0.14579245142110528]
	TIME [epoch: 8.32 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1171229902796016		[learning rate: 0.00073408]
	Learning Rate: 0.00073408
	LOSS [training: 0.1171229902796016 | validation: 0.13159122703978834]
	TIME [epoch: 8.34 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11298122631772034		[learning rate: 0.00073235]
	Learning Rate: 0.000732349
	LOSS [training: 0.11298122631772034 | validation: 0.139912833318251]
	TIME [epoch: 8.31 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1457027853936714		[learning rate: 0.00073062]
	Learning Rate: 0.000730621
	LOSS [training: 0.1457027853936714 | validation: 0.1333639521293977]
	TIME [epoch: 8.33 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1586710075471186		[learning rate: 0.0007289]
	Learning Rate: 0.000728898
	LOSS [training: 0.1586710075471186 | validation: 0.15621602240201815]
	TIME [epoch: 8.32 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22427096101674354		[learning rate: 0.00072718]
	Learning Rate: 0.000727178
	LOSS [training: 0.22427096101674354 | validation: 0.21301726703304566]
	TIME [epoch: 8.35 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21067852284110491		[learning rate: 0.00072546]
	Learning Rate: 0.000725463
	LOSS [training: 0.21067852284110491 | validation: 0.23056634504833928]
	TIME [epoch: 8.33 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21442851788534822		[learning rate: 0.00072375]
	Learning Rate: 0.000723752
	LOSS [training: 0.21442851788534822 | validation: 0.1899061051461045]
	TIME [epoch: 8.31 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2168784904931449		[learning rate: 0.00072204]
	Learning Rate: 0.000722045
	LOSS [training: 0.2168784904931449 | validation: 0.23333307913261137]
	TIME [epoch: 8.32 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22145028436325126		[learning rate: 0.00072034]
	Learning Rate: 0.000720342
	LOSS [training: 0.22145028436325126 | validation: 0.30543000829309164]
	TIME [epoch: 8.34 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33449751247352016		[learning rate: 0.00071864]
	Learning Rate: 0.000718642
	LOSS [training: 0.33449751247352016 | validation: 0.46193514750868175]
	TIME [epoch: 8.33 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3953627889663177		[learning rate: 0.00071695]
	Learning Rate: 0.000716947
	LOSS [training: 0.3953627889663177 | validation: 0.4709362868305891]
	TIME [epoch: 8.32 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49285053436624365		[learning rate: 0.00071526]
	Learning Rate: 0.000715256
	LOSS [training: 0.49285053436624365 | validation: 0.3508383103053024]
	TIME [epoch: 8.32 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23462163430401795		[learning rate: 0.00071357]
	Learning Rate: 0.000713569
	LOSS [training: 0.23462163430401795 | validation: 0.34228625715416905]
	TIME [epoch: 8.33 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16417051418431025		[learning rate: 0.00071189]
	Learning Rate: 0.000711886
	LOSS [training: 0.16417051418431025 | validation: 0.17619286533937048]
	TIME [epoch: 8.35 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1437930605210085		[learning rate: 0.00071021]
	Learning Rate: 0.000710206
	LOSS [training: 0.1437930605210085 | validation: 0.34007568456809556]
	TIME [epoch: 8.32 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1856511972535156		[learning rate: 0.00070853]
	Learning Rate: 0.000708531
	LOSS [training: 0.1856511972535156 | validation: 0.1771691372544165]
	TIME [epoch: 8.32 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12021902343664921		[learning rate: 0.00070686]
	Learning Rate: 0.00070686
	LOSS [training: 0.12021902343664921 | validation: 0.2009565490518613]
	TIME [epoch: 8.32 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17836459815507671		[learning rate: 0.00070519]
	Learning Rate: 0.000705193
	LOSS [training: 0.17836459815507671 | validation: 0.3766315120482704]
	TIME [epoch: 8.35 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40669356746652713		[learning rate: 0.00070353]
	Learning Rate: 0.000703529
	LOSS [training: 0.40669356746652713 | validation: 0.345892661959381]
	TIME [epoch: 8.33 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16723233969592205		[learning rate: 0.00070187]
	Learning Rate: 0.000701869
	LOSS [training: 0.16723233969592205 | validation: 0.3216198837417854]
	TIME [epoch: 8.32 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17546693282751552		[learning rate: 0.00070021]
	Learning Rate: 0.000700214
	LOSS [training: 0.17546693282751552 | validation: 0.1768140849418893]
	TIME [epoch: 8.31 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24789279724274094		[learning rate: 0.00069856]
	Learning Rate: 0.000698562
	LOSS [training: 0.24789279724274094 | validation: 0.2029779503737045]
	TIME [epoch: 8.33 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14546239540869665		[learning rate: 0.00069691]
	Learning Rate: 0.000696914
	LOSS [training: 0.14546239540869665 | validation: 0.10582471326110901]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_1178.pth
	Model improved!!!
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14448762469016052		[learning rate: 0.00069527]
	Learning Rate: 0.00069527
	LOSS [training: 0.14448762469016052 | validation: 0.16918985505726805]
	TIME [epoch: 8.35 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12400959688142717		[learning rate: 0.00069363]
	Learning Rate: 0.000693631
	LOSS [training: 0.12400959688142717 | validation: 0.17162909325978803]
	TIME [epoch: 8.35 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17738091711823198		[learning rate: 0.00069199]
	Learning Rate: 0.000691994
	LOSS [training: 0.17738091711823198 | validation: 0.20476453494614433]
	TIME [epoch: 8.35 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15679558535501195		[learning rate: 0.00069036]
	Learning Rate: 0.000690362
	LOSS [training: 0.15679558535501195 | validation: 0.16275548040359306]
	TIME [epoch: 8.38 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2047381667987199		[learning rate: 0.00068873]
	Learning Rate: 0.000688734
	LOSS [training: 0.2047381667987199 | validation: 0.13133772588807913]
	TIME [epoch: 8.35 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13851156845997212		[learning rate: 0.00068711]
	Learning Rate: 0.000687109
	LOSS [training: 0.13851156845997212 | validation: 0.1719914290777529]
	TIME [epoch: 8.35 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15794066617911412		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.15794066617911412 | validation: 0.3897064218751764]
	TIME [epoch: 8.35 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16732342157790128		[learning rate: 0.00068387]
	Learning Rate: 0.000683871
	LOSS [training: 0.16732342157790128 | validation: 0.28034260293809865]
	TIME [epoch: 8.37 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14778495553237367		[learning rate: 0.00068226]
	Learning Rate: 0.000682258
	LOSS [training: 0.14778495553237367 | validation: 0.22832395266844696]
	TIME [epoch: 8.35 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17991524921809035		[learning rate: 0.00068065]
	Learning Rate: 0.000680649
	LOSS [training: 0.17991524921809035 | validation: 0.12762685031094576]
	TIME [epoch: 8.35 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1373288228394341		[learning rate: 0.00067904]
	Learning Rate: 0.000679043
	LOSS [training: 0.1373288228394341 | validation: 0.15488128171800764]
	TIME [epoch: 8.35 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15938914414278255		[learning rate: 0.00067744]
	Learning Rate: 0.000677442
	LOSS [training: 0.15938914414278255 | validation: 0.1692178409231146]
	TIME [epoch: 8.37 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12582411119078696		[learning rate: 0.00067584]
	Learning Rate: 0.000675844
	LOSS [training: 0.12582411119078696 | validation: 0.14667796903539473]
	TIME [epoch: 8.36 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14522267911429873		[learning rate: 0.00067425]
	Learning Rate: 0.000674249
	LOSS [training: 0.14522267911429873 | validation: 0.16866796407488957]
	TIME [epoch: 8.36 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12290560489429174		[learning rate: 0.00067266]
	Learning Rate: 0.000672659
	LOSS [training: 0.12290560489429174 | validation: 0.13711098498065238]
	TIME [epoch: 8.35 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1573530397680168		[learning rate: 0.00067107]
	Learning Rate: 0.000671072
	LOSS [training: 0.1573530397680168 | validation: 0.5057369705905299]
	TIME [epoch: 8.35 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45554435747765004		[learning rate: 0.00066949]
	Learning Rate: 0.000669489
	LOSS [training: 0.45554435747765004 | validation: 0.4390167683596466]
	TIME [epoch: 8.38 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3512028344161926		[learning rate: 0.00066791]
	Learning Rate: 0.00066791
	LOSS [training: 0.3512028344161926 | validation: 0.3870545004223857]
	TIME [epoch: 8.35 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2329259456824396		[learning rate: 0.00066633]
	Learning Rate: 0.000666335
	LOSS [training: 0.2329259456824396 | validation: 0.2948476128074169]
	TIME [epoch: 8.35 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23067107578787951		[learning rate: 0.00066476]
	Learning Rate: 0.000664763
	LOSS [training: 0.23067107578787951 | validation: 0.18590234759573937]
	TIME [epoch: 8.35 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19145121681134702		[learning rate: 0.00066319]
	Learning Rate: 0.000663195
	LOSS [training: 0.19145121681134702 | validation: 0.197517425898156]
	TIME [epoch: 8.38 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16040512825334108		[learning rate: 0.00066163]
	Learning Rate: 0.00066163
	LOSS [training: 0.16040512825334108 | validation: 0.12771207953044136]
	TIME [epoch: 8.35 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.126184649886888		[learning rate: 0.00066007]
	Learning Rate: 0.00066007
	LOSS [training: 0.126184649886888 | validation: 0.13298420169403113]
	TIME [epoch: 8.35 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1484087446551839		[learning rate: 0.00065851]
	Learning Rate: 0.000658513
	LOSS [training: 0.1484087446551839 | validation: 0.1436035875752185]
	TIME [epoch: 8.36 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13593001206932898		[learning rate: 0.00065696]
	Learning Rate: 0.000656959
	LOSS [training: 0.13593001206932898 | validation: 0.15727662652066432]
	TIME [epoch: 8.37 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13800491666629183		[learning rate: 0.00065541]
	Learning Rate: 0.00065541
	LOSS [training: 0.13800491666629183 | validation: 0.1583672737801724]
	TIME [epoch: 8.37 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13080853106468032		[learning rate: 0.00065386]
	Learning Rate: 0.000653864
	LOSS [training: 0.13080853106468032 | validation: 0.13243092507337523]
	TIME [epoch: 8.36 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1149224718820772		[learning rate: 0.00065232]
	Learning Rate: 0.000652321
	LOSS [training: 0.1149224718820772 | validation: 0.12972747062296378]
	TIME [epoch: 8.35 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11788768180221483		[learning rate: 0.00065078]
	Learning Rate: 0.000650783
	LOSS [training: 0.11788768180221483 | validation: 0.14807294183920744]
	TIME [epoch: 8.36 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10993066181590105		[learning rate: 0.00064925]
	Learning Rate: 0.000649247
	LOSS [training: 0.10993066181590105 | validation: 0.17046174955557114]
	TIME [epoch: 8.38 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1351241675196788		[learning rate: 0.00064772]
	Learning Rate: 0.000647716
	LOSS [training: 0.1351241675196788 | validation: 0.17119056715930697]
	TIME [epoch: 8.35 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33779729569289413		[learning rate: 0.00064619]
	Learning Rate: 0.000646188
	LOSS [training: 0.33779729569289413 | validation: 0.21608493077317778]
	TIME [epoch: 8.35 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17164552436307068		[learning rate: 0.00064466]
	Learning Rate: 0.000644664
	LOSS [training: 0.17164552436307068 | validation: 0.23302516128398398]
	TIME [epoch: 8.35 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14307371441910385		[learning rate: 0.00064314]
	Learning Rate: 0.000643143
	LOSS [training: 0.14307371441910385 | validation: 0.16665518812668867]
	TIME [epoch: 8.38 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16140469840914062		[learning rate: 0.00064163]
	Learning Rate: 0.000641626
	LOSS [training: 0.16140469840914062 | validation: 0.16892310193509896]
	TIME [epoch: 8.36 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16985143710132178		[learning rate: 0.00064011]
	Learning Rate: 0.000640113
	LOSS [training: 0.16985143710132178 | validation: 0.21989601351444046]
	TIME [epoch: 8.36 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13862264272479474		[learning rate: 0.0006386]
	Learning Rate: 0.000638603
	LOSS [training: 0.13862264272479474 | validation: 0.15633728158420745]
	TIME [epoch: 8.35 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14185195094268593		[learning rate: 0.0006371]
	Learning Rate: 0.000637096
	LOSS [training: 0.14185195094268593 | validation: 0.12026982471708106]
	TIME [epoch: 8.37 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11369717924585551		[learning rate: 0.00063559]
	Learning Rate: 0.000635594
	LOSS [training: 0.11369717924585551 | validation: 0.18510650793657912]
	TIME [epoch: 8.36 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1568319739153388		[learning rate: 0.00063409]
	Learning Rate: 0.000634094
	LOSS [training: 0.1568319739153388 | validation: 0.2545746261993225]
	TIME [epoch: 8.35 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21588226800905605		[learning rate: 0.0006326]
	Learning Rate: 0.000632598
	LOSS [training: 0.21588226800905605 | validation: 0.1855170071317837]
	TIME [epoch: 8.36 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17169598279210296		[learning rate: 0.00063111]
	Learning Rate: 0.000631106
	LOSS [training: 0.17169598279210296 | validation: 0.16855492224075383]
	TIME [epoch: 8.36 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11789555651827519		[learning rate: 0.00062962]
	Learning Rate: 0.000629618
	LOSS [training: 0.11789555651827519 | validation: 0.30327342338618024]
	TIME [epoch: 8.37 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16568860688073622		[learning rate: 0.00062813]
	Learning Rate: 0.000628132
	LOSS [training: 0.16568860688073622 | validation: 0.24961133492083426]
	TIME [epoch: 8.35 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17507464144048904		[learning rate: 0.00062665]
	Learning Rate: 0.000626651
	LOSS [training: 0.17507464144048904 | validation: 0.13517480805526338]
	TIME [epoch: 8.35 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13772862848073167		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.13772862848073167 | validation: 0.20821467694563628]
	TIME [epoch: 8.35 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19926137589769638		[learning rate: 0.0006237]
	Learning Rate: 0.000623698
	LOSS [training: 0.19926137589769638 | validation: 0.21541902243397665]
	TIME [epoch: 8.37 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20427748972205703		[learning rate: 0.00062223]
	Learning Rate: 0.000622227
	LOSS [training: 0.20427748972205703 | validation: 0.2176942902937088]
	TIME [epoch: 8.35 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15398172162685642		[learning rate: 0.00062076]
	Learning Rate: 0.000620759
	LOSS [training: 0.15398172162685642 | validation: 0.13105199635241466]
	TIME [epoch: 8.35 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13999073515504662		[learning rate: 0.00061929]
	Learning Rate: 0.000619295
	LOSS [training: 0.13999073515504662 | validation: 0.14868499790028297]
	TIME [epoch: 8.35 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11314258990575596		[learning rate: 0.00061783]
	Learning Rate: 0.000617834
	LOSS [training: 0.11314258990575596 | validation: 0.17947487423632233]
	TIME [epoch: 8.37 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19185215521968182		[learning rate: 0.00061638]
	Learning Rate: 0.000616377
	LOSS [training: 0.19185215521968182 | validation: 0.2411395144549121]
	TIME [epoch: 8.35 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22820358770502872		[learning rate: 0.00061492]
	Learning Rate: 0.000614923
	LOSS [training: 0.22820358770502872 | validation: 0.2061680156337246]
	TIME [epoch: 8.35 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1703716034261718		[learning rate: 0.00061347]
	Learning Rate: 0.000613472
	LOSS [training: 0.1703716034261718 | validation: 0.17011086928274888]
	TIME [epoch: 8.35 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1556346929268281		[learning rate: 0.00061203]
	Learning Rate: 0.000612025
	LOSS [training: 0.1556346929268281 | validation: 0.1795225789449585]
	TIME [epoch: 8.36 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19661214515769843		[learning rate: 0.00061058]
	Learning Rate: 0.000610581
	LOSS [training: 0.19661214515769843 | validation: 0.225044698035137]
	TIME [epoch: 8.36 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17043837884242308		[learning rate: 0.00060914]
	Learning Rate: 0.000609141
	LOSS [training: 0.17043837884242308 | validation: 0.15676017739616446]
	TIME [epoch: 8.35 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14285230328593518		[learning rate: 0.0006077]
	Learning Rate: 0.000607704
	LOSS [training: 0.14285230328593518 | validation: 0.14827865742483443]
	TIME [epoch: 8.35 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13396361965430092		[learning rate: 0.00060627]
	Learning Rate: 0.000606271
	LOSS [training: 0.13396361965430092 | validation: 0.2580474098073214]
	TIME [epoch: 8.35 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1496144465913642		[learning rate: 0.00060484]
	Learning Rate: 0.000604841
	LOSS [training: 0.1496144465913642 | validation: 0.12924026349489437]
	TIME [epoch: 8.37 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10668654716285161		[learning rate: 0.00060341]
	Learning Rate: 0.000603414
	LOSS [training: 0.10668654716285161 | validation: 0.12234879988625252]
	TIME [epoch: 8.35 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14514549235241633		[learning rate: 0.00060199]
	Learning Rate: 0.000601991
	LOSS [training: 0.14514549235241633 | validation: 0.1659016125712296]
	TIME [epoch: 8.35 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15162538609723247		[learning rate: 0.00060057]
	Learning Rate: 0.000600571
	LOSS [training: 0.15162538609723247 | validation: 0.2726935656537133]
	TIME [epoch: 8.35 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15603834119069207		[learning rate: 0.00059915]
	Learning Rate: 0.000599154
	LOSS [training: 0.15603834119069207 | validation: 0.2392927398040666]
	TIME [epoch: 8.37 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12703414472969893		[learning rate: 0.00059774]
	Learning Rate: 0.000597741
	LOSS [training: 0.12703414472969893 | validation: 0.1481483378893358]
	TIME [epoch: 8.35 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10483918828502026		[learning rate: 0.00059633]
	Learning Rate: 0.000596331
	LOSS [training: 0.10483918828502026 | validation: 0.15613859515095538]
	TIME [epoch: 8.35 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12249163561143266		[learning rate: 0.00059492]
	Learning Rate: 0.000594924
	LOSS [training: 0.12249163561143266 | validation: 0.1308957223887596]
	TIME [epoch: 8.35 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12076197425217272		[learning rate: 0.00059352]
	Learning Rate: 0.000593521
	LOSS [training: 0.12076197425217272 | validation: 0.11792259550451858]
	TIME [epoch: 8.35 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1406370684170557		[learning rate: 0.00059212]
	Learning Rate: 0.000592121
	LOSS [training: 0.1406370684170557 | validation: 0.3067017761892885]
	TIME [epoch: 8.37 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15699663952744425		[learning rate: 0.00059072]
	Learning Rate: 0.000590724
	LOSS [training: 0.15699663952744425 | validation: 0.2112259974448169]
	TIME [epoch: 8.34 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16960448563628874		[learning rate: 0.00058933]
	Learning Rate: 0.000589331
	LOSS [training: 0.16960448563628874 | validation: 0.43984705156316295]
	TIME [epoch: 8.34 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22006859770988046		[learning rate: 0.00058794]
	Learning Rate: 0.00058794
	LOSS [training: 0.22006859770988046 | validation: 0.1854173577994433]
	TIME [epoch: 8.35 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19459595692598408		[learning rate: 0.00058655]
	Learning Rate: 0.000586554
	LOSS [training: 0.19459595692598408 | validation: 0.25870535229689967]
	TIME [epoch: 8.37 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14504421783051943		[learning rate: 0.00058517]
	Learning Rate: 0.00058517
	LOSS [training: 0.14504421783051943 | validation: 0.1876595003482535]
	TIME [epoch: 8.35 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.134613095756489		[learning rate: 0.00058379]
	Learning Rate: 0.00058379
	LOSS [training: 0.134613095756489 | validation: 0.13506625695594615]
	TIME [epoch: 8.35 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11207066721809802		[learning rate: 0.00058241]
	Learning Rate: 0.000582413
	LOSS [training: 0.11207066721809802 | validation: 0.14645345784794395]
	TIME [epoch: 8.35 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14579063886197596		[learning rate: 0.00058104]
	Learning Rate: 0.000581039
	LOSS [training: 0.14579063886197596 | validation: 0.13169608720579315]
	TIME [epoch: 8.37 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13005986095805752		[learning rate: 0.00057967]
	Learning Rate: 0.000579668
	LOSS [training: 0.13005986095805752 | validation: 0.1344425239839609]
	TIME [epoch: 8.35 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17350469881558622		[learning rate: 0.0005783]
	Learning Rate: 0.000578301
	LOSS [training: 0.17350469881558622 | validation: 0.19972155071945638]
	TIME [epoch: 8.35 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16063195206923928		[learning rate: 0.00057694]
	Learning Rate: 0.000576937
	LOSS [training: 0.16063195206923928 | validation: 0.1525961645830206]
	TIME [epoch: 8.35 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15466821837709457		[learning rate: 0.00057558]
	Learning Rate: 0.000575576
	LOSS [training: 0.15466821837709457 | validation: 0.18187139477698783]
	TIME [epoch: 8.35 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1855397377175791		[learning rate: 0.00057422]
	Learning Rate: 0.000574218
	LOSS [training: 0.1855397377175791 | validation: 0.24656341181537422]
	TIME [epoch: 8.36 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17525399335074626		[learning rate: 0.00057286]
	Learning Rate: 0.000572864
	LOSS [training: 0.17525399335074626 | validation: 0.18641040507918027]
	TIME [epoch: 8.35 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13432359972368177		[learning rate: 0.00057151]
	Learning Rate: 0.000571512
	LOSS [training: 0.13432359972368177 | validation: 0.16179342089214477]
	TIME [epoch: 8.34 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1328194401994894		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.1328194401994894 | validation: 0.19839680091320305]
	TIME [epoch: 8.34 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13331333549762275		[learning rate: 0.00056882]
	Learning Rate: 0.000568819
	LOSS [training: 0.13331333549762275 | validation: 0.11832671121187069]
	TIME [epoch: 8.37 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14756354040743497		[learning rate: 0.00056748]
	Learning Rate: 0.000567478
	LOSS [training: 0.14756354040743497 | validation: 0.1604029569757614]
	TIME [epoch: 8.35 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12570223591091795		[learning rate: 0.00056614]
	Learning Rate: 0.000566139
	LOSS [training: 0.12570223591091795 | validation: 0.14034838043792197]
	TIME [epoch: 8.34 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12729364790361425		[learning rate: 0.0005648]
	Learning Rate: 0.000564804
	LOSS [training: 0.12729364790361425 | validation: 0.1424750412041826]
	TIME [epoch: 8.35 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1279491358718226		[learning rate: 0.00056347]
	Learning Rate: 0.000563471
	LOSS [training: 0.1279491358718226 | validation: 0.1518372688499752]
	TIME [epoch: 8.37 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1356181120654269		[learning rate: 0.00056214]
	Learning Rate: 0.000562142
	LOSS [training: 0.1356181120654269 | validation: 0.1337709269162119]
	TIME [epoch: 8.36 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10509143303006148		[learning rate: 0.00056082]
	Learning Rate: 0.000560816
	LOSS [training: 0.10509143303006148 | validation: 0.21486863696546815]
	TIME [epoch: 8.35 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13216298202151122		[learning rate: 0.00055949]
	Learning Rate: 0.000559493
	LOSS [training: 0.13216298202151122 | validation: 0.13500388754569195]
	TIME [epoch: 8.35 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13160905331148348		[learning rate: 0.00055817]
	Learning Rate: 0.000558173
	LOSS [training: 0.13160905331148348 | validation: 0.19394684631329617]
	TIME [epoch: 8.36 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14825663143850845		[learning rate: 0.00055686]
	Learning Rate: 0.000556857
	LOSS [training: 0.14825663143850845 | validation: 0.1369486082604578]
	TIME [epoch: 8.37 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12863800893443608		[learning rate: 0.00055554]
	Learning Rate: 0.000555543
	LOSS [training: 0.12863800893443608 | validation: 0.10906065003118537]
	TIME [epoch: 8.35 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09992928483624927		[learning rate: 0.00055423]
	Learning Rate: 0.000554233
	LOSS [training: 0.09992928483624927 | validation: 0.1363342819628221]
	TIME [epoch: 8.35 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11254750108415837		[learning rate: 0.00055293]
	Learning Rate: 0.000552925
	LOSS [training: 0.11254750108415837 | validation: 0.14343453859413433]
	TIME [epoch: 8.35 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11602607772358309		[learning rate: 0.00055162]
	Learning Rate: 0.000551621
	LOSS [training: 0.11602607772358309 | validation: 0.11480974700388313]
	TIME [epoch: 8.37 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13412135364790861		[learning rate: 0.00055032]
	Learning Rate: 0.00055032
	LOSS [training: 0.13412135364790861 | validation: 0.21110208101032452]
	TIME [epoch: 8.35 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13716862998729237		[learning rate: 0.00054902]
	Learning Rate: 0.000549022
	LOSS [training: 0.13716862998729237 | validation: 0.20597944411581431]
	TIME [epoch: 8.35 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1516784695381729		[learning rate: 0.00054773]
	Learning Rate: 0.000547727
	LOSS [training: 0.1516784695381729 | validation: 0.1199588036695003]
	TIME [epoch: 8.35 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17597925099420292		[learning rate: 0.00054643]
	Learning Rate: 0.000546435
	LOSS [training: 0.17597925099420292 | validation: 0.13210394473678155]
	TIME [epoch: 8.37 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1201110057030278		[learning rate: 0.00054515]
	Learning Rate: 0.000545146
	LOSS [training: 0.1201110057030278 | validation: 0.1091000283744311]
	TIME [epoch: 8.35 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10274800236760265		[learning rate: 0.00054386]
	Learning Rate: 0.00054386
	LOSS [training: 0.10274800236760265 | validation: 0.12029804098178906]
	TIME [epoch: 8.35 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1287032504894767		[learning rate: 0.00054258]
	Learning Rate: 0.000542577
	LOSS [training: 0.1287032504894767 | validation: 0.13277412808324213]
	TIME [epoch: 8.35 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1288120626487531		[learning rate: 0.0005413]
	Learning Rate: 0.000541297
	LOSS [training: 0.1288120626487531 | validation: 0.20393171597166235]
	TIME [epoch: 8.36 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12806260417098608		[learning rate: 0.00054002]
	Learning Rate: 0.00054002
	LOSS [training: 0.12806260417098608 | validation: 0.17169640466045813]
	TIME [epoch: 8.35 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12572013675790977		[learning rate: 0.00053875]
	Learning Rate: 0.000538747
	LOSS [training: 0.12572013675790977 | validation: 0.1383681331225211]
	TIME [epoch: 8.35 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11513822382404226		[learning rate: 0.00053748]
	Learning Rate: 0.000537476
	LOSS [training: 0.11513822382404226 | validation: 0.19817024666797525]
	TIME [epoch: 8.35 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1493613443880307		[learning rate: 0.00053621]
	Learning Rate: 0.000536208
	LOSS [training: 0.1493613443880307 | validation: 0.16793935179840758]
	TIME [epoch: 8.35 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13262426737508967		[learning rate: 0.00053494]
	Learning Rate: 0.000534943
	LOSS [training: 0.13262426737508967 | validation: 0.1883007039741042]
	TIME [epoch: 8.37 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13283840518669296		[learning rate: 0.00053368]
	Learning Rate: 0.000533681
	LOSS [training: 0.13283840518669296 | validation: 0.1386261962274013]
	TIME [epoch: 8.35 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1327327744354811		[learning rate: 0.00053242]
	Learning Rate: 0.000532422
	LOSS [training: 0.1327327744354811 | validation: 0.22236380431034097]
	TIME [epoch: 8.35 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14062758471606285		[learning rate: 0.00053117]
	Learning Rate: 0.000531167
	LOSS [training: 0.14062758471606285 | validation: 0.14218430612902444]
	TIME [epoch: 8.34 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12310373156831451		[learning rate: 0.00052991]
	Learning Rate: 0.000529914
	LOSS [training: 0.12310373156831451 | validation: 0.11157620689849598]
	TIME [epoch: 8.37 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11940642629407945		[learning rate: 0.00052866]
	Learning Rate: 0.000528664
	LOSS [training: 0.11940642629407945 | validation: 0.12161874536059616]
	TIME [epoch: 8.35 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.135120911112736		[learning rate: 0.00052742]
	Learning Rate: 0.000527417
	LOSS [training: 0.135120911112736 | validation: 0.14327549820528931]
	TIME [epoch: 8.34 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12863816166136416		[learning rate: 0.00052617]
	Learning Rate: 0.000526173
	LOSS [training: 0.12863816166136416 | validation: 0.16857257032096584]
	TIME [epoch: 8.35 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1394751498573079		[learning rate: 0.00052493]
	Learning Rate: 0.000524931
	LOSS [training: 0.1394751498573079 | validation: 0.21067405973234898]
	TIME [epoch: 8.36 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1752489843702383		[learning rate: 0.00052369]
	Learning Rate: 0.000523693
	LOSS [training: 0.1752489843702383 | validation: 0.19507575355837048]
	TIME [epoch: 8.35 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1490799350971552		[learning rate: 0.00052246]
	Learning Rate: 0.000522458
	LOSS [training: 0.1490799350971552 | validation: 0.17919708970451959]
	TIME [epoch: 8.34 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1580977114266482		[learning rate: 0.00052123]
	Learning Rate: 0.000521225
	LOSS [training: 0.1580977114266482 | validation: 0.32744495557667375]
	TIME [epoch: 8.34 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23041284426721814		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.23041284426721814 | validation: 0.16151324759866692]
	TIME [epoch: 8.34 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15338322368916243		[learning rate: 0.00051877]
	Learning Rate: 0.000518769
	LOSS [training: 0.15338322368916243 | validation: 0.19299830349642888]
	TIME [epoch: 8.37 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1509281925078532		[learning rate: 0.00051755]
	Learning Rate: 0.000517546
	LOSS [training: 0.1509281925078532 | validation: 0.14905517113761968]
	TIME [epoch: 8.35 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11937244938876734		[learning rate: 0.00051632]
	Learning Rate: 0.000516325
	LOSS [training: 0.11937244938876734 | validation: 0.16300778736299515]
	TIME [epoch: 8.35 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11080670954451108		[learning rate: 0.00051511]
	Learning Rate: 0.000515107
	LOSS [training: 0.11080670954451108 | validation: 0.13226488342543433]
	TIME [epoch: 8.35 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11311120118757985		[learning rate: 0.00051389]
	Learning Rate: 0.000513892
	LOSS [training: 0.11311120118757985 | validation: 0.16505302570936561]
	TIME [epoch: 8.37 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13391534361671212		[learning rate: 0.00051268]
	Learning Rate: 0.00051268
	LOSS [training: 0.13391534361671212 | validation: 0.130742570008438]
	TIME [epoch: 8.35 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12495353925603572		[learning rate: 0.00051147]
	Learning Rate: 0.00051147
	LOSS [training: 0.12495353925603572 | validation: 0.15371158574057264]
	TIME [epoch: 8.34 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11427732631931131		[learning rate: 0.00051026]
	Learning Rate: 0.000510264
	LOSS [training: 0.11427732631931131 | validation: 0.11462821303147736]
	TIME [epoch: 8.34 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13357285204094418		[learning rate: 0.00050906]
	Learning Rate: 0.00050906
	LOSS [training: 0.13357285204094418 | validation: 0.12229856466117875]
	TIME [epoch: 8.36 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11851948030904189		[learning rate: 0.00050786]
	Learning Rate: 0.000507859
	LOSS [training: 0.11851948030904189 | validation: 0.13924542593231817]
	TIME [epoch: 8.35 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11285983540390429		[learning rate: 0.00050666]
	Learning Rate: 0.000506662
	LOSS [training: 0.11285983540390429 | validation: 0.1288663584029299]
	TIME [epoch: 8.34 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13850072436478097		[learning rate: 0.00050547]
	Learning Rate: 0.000505466
	LOSS [training: 0.13850072436478097 | validation: 0.14615599480846725]
	TIME [epoch: 8.34 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11083851482545018		[learning rate: 0.00050427]
	Learning Rate: 0.000504274
	LOSS [training: 0.11083851482545018 | validation: 0.12994278914976387]
	TIME [epoch: 8.34 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13185619443877183		[learning rate: 0.00050308]
	Learning Rate: 0.000503085
	LOSS [training: 0.13185619443877183 | validation: 0.17220034380355523]
	TIME [epoch: 8.36 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13337670254375955		[learning rate: 0.0005019]
	Learning Rate: 0.000501898
	LOSS [training: 0.13337670254375955 | validation: 0.21357854870251802]
	TIME [epoch: 8.34 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13529739885101227		[learning rate: 0.00050071]
	Learning Rate: 0.000500714
	LOSS [training: 0.13529739885101227 | validation: 0.11670630598015713]
	TIME [epoch: 8.34 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10962868117510163		[learning rate: 0.00049953]
	Learning Rate: 0.000499533
	LOSS [training: 0.10962868117510163 | validation: 0.12088227476555984]
	TIME [epoch: 8.34 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10857700341062178		[learning rate: 0.00049835]
	Learning Rate: 0.000498355
	LOSS [training: 0.10857700341062178 | validation: 0.12139432252056298]
	TIME [epoch: 8.36 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10961864943782876		[learning rate: 0.00049718]
	Learning Rate: 0.000497179
	LOSS [training: 0.10961864943782876 | validation: 0.18102452044929856]
	TIME [epoch: 8.34 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10578741520662811		[learning rate: 0.00049601]
	Learning Rate: 0.000496006
	LOSS [training: 0.10578741520662811 | validation: 0.1602140559477157]
	TIME [epoch: 8.34 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13540726559335392		[learning rate: 0.00049484]
	Learning Rate: 0.000494836
	LOSS [training: 0.13540726559335392 | validation: 0.19901770313158812]
	TIME [epoch: 8.34 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15517834169428096		[learning rate: 0.00049367]
	Learning Rate: 0.000493669
	LOSS [training: 0.15517834169428096 | validation: 0.1506792021125231]
	TIME [epoch: 8.36 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15228900285630434		[learning rate: 0.0004925]
	Learning Rate: 0.000492505
	LOSS [training: 0.15228900285630434 | validation: 0.22602122761354465]
	TIME [epoch: 8.35 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1332918837314527		[learning rate: 0.00049134]
	Learning Rate: 0.000491343
	LOSS [training: 0.1332918837314527 | validation: 0.14469324198027467]
	TIME [epoch: 8.34 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16986962147132129		[learning rate: 0.00049018]
	Learning Rate: 0.000490184
	LOSS [training: 0.16986962147132129 | validation: 0.18151868187409484]
	TIME [epoch: 8.34 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15330008085880478		[learning rate: 0.00048903]
	Learning Rate: 0.000489027
	LOSS [training: 0.15330008085880478 | validation: 0.16395451014520457]
	TIME [epoch: 8.34 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12159692692565272		[learning rate: 0.00048787]
	Learning Rate: 0.000487874
	LOSS [training: 0.12159692692565272 | validation: 0.1685696291960687]
	TIME [epoch: 8.36 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1889467077840746		[learning rate: 0.00048672]
	Learning Rate: 0.000486723
	LOSS [training: 0.1889467077840746 | validation: 0.14393749538748374]
	TIME [epoch: 8.33 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11316372133219946		[learning rate: 0.00048558]
	Learning Rate: 0.000485575
	LOSS [training: 0.11316372133219946 | validation: 0.13495253193218865]
	TIME [epoch: 8.33 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12067102738601987		[learning rate: 0.00048443]
	Learning Rate: 0.00048443
	LOSS [training: 0.12067102738601987 | validation: 0.15667860904655115]
	TIME [epoch: 8.33 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13194882316802092		[learning rate: 0.00048329]
	Learning Rate: 0.000483287
	LOSS [training: 0.13194882316802092 | validation: 0.13191355870685978]
	TIME [epoch: 8.35 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1355900154185663		[learning rate: 0.00048215]
	Learning Rate: 0.000482147
	LOSS [training: 0.1355900154185663 | validation: 0.14758285318704029]
	TIME [epoch: 8.34 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10842994592839186		[learning rate: 0.00048101]
	Learning Rate: 0.00048101
	LOSS [training: 0.10842994592839186 | validation: 0.12415707475597512]
	TIME [epoch: 8.33 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10580647224934128		[learning rate: 0.00047988]
	Learning Rate: 0.000479875
	LOSS [training: 0.10580647224934128 | validation: 0.1172336247792734]
	TIME [epoch: 8.33 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10384599107504675		[learning rate: 0.00047874]
	Learning Rate: 0.000478743
	LOSS [training: 0.10384599107504675 | validation: 0.09160340801794523]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_1337.pth
	Model improved!!!
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10399392092030839		[learning rate: 0.00047761]
	Learning Rate: 0.000477614
	LOSS [training: 0.10399392092030839 | validation: 0.104953364117848]
	TIME [epoch: 8.33 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10273277646434431		[learning rate: 0.00047649]
	Learning Rate: 0.000476487
	LOSS [training: 0.10273277646434431 | validation: 0.11927480359186898]
	TIME [epoch: 8.33 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0936200978390821		[learning rate: 0.00047536]
	Learning Rate: 0.000475363
	LOSS [training: 0.0936200978390821 | validation: 0.1359539230242704]
	TIME [epoch: 8.32 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11345268564073771		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.11345268564073771 | validation: 0.1497161954158273]
	TIME [epoch: 8.32 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09773165155488138		[learning rate: 0.00047312]
	Learning Rate: 0.000473123
	LOSS [training: 0.09773165155488138 | validation: 0.1718927867189755]
	TIME [epoch: 8.35 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13709560928433423		[learning rate: 0.00047201]
	Learning Rate: 0.000472007
	LOSS [training: 0.13709560928433423 | validation: 0.1397353992930557]
	TIME [epoch: 8.32 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10528556852390865		[learning rate: 0.00047089]
	Learning Rate: 0.000470894
	LOSS [training: 0.10528556852390865 | validation: 0.10291927947128487]
	TIME [epoch: 8.33 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11517645949000296		[learning rate: 0.00046978]
	Learning Rate: 0.000469783
	LOSS [training: 0.11517645949000296 | validation: 0.1403270841092929]
	TIME [epoch: 8.33 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13605896838126016		[learning rate: 0.00046867]
	Learning Rate: 0.000468675
	LOSS [training: 0.13605896838126016 | validation: 0.1490747684438719]
	TIME [epoch: 8.35 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1342750539660015		[learning rate: 0.00046757]
	Learning Rate: 0.000467569
	LOSS [training: 0.1342750539660015 | validation: 0.15572380589187812]
	TIME [epoch: 8.33 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10842561877495518		[learning rate: 0.00046647]
	Learning Rate: 0.000466467
	LOSS [training: 0.10842561877495518 | validation: 0.11177517557324693]
	TIME [epoch: 8.32 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10151233368883068		[learning rate: 0.00046537]
	Learning Rate: 0.000465366
	LOSS [training: 0.10151233368883068 | validation: 0.11199652325493989]
	TIME [epoch: 8.33 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1030019814170245		[learning rate: 0.00046427]
	Learning Rate: 0.000464269
	LOSS [training: 0.1030019814170245 | validation: 0.13084307133410533]
	TIME [epoch: 8.34 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08229741966773169		[learning rate: 0.00046317]
	Learning Rate: 0.000463173
	LOSS [training: 0.08229741966773169 | validation: 0.11636470180465376]
	TIME [epoch: 8.34 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10570300339163592		[learning rate: 0.00046208]
	Learning Rate: 0.000462081
	LOSS [training: 0.10570300339163592 | validation: 0.13892601358452542]
	TIME [epoch: 8.33 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1251456132638668		[learning rate: 0.00046099]
	Learning Rate: 0.000460991
	LOSS [training: 0.1251456132638668 | validation: 0.12057927078984368]
	TIME [epoch: 8.33 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09300223520988718		[learning rate: 0.0004599]
	Learning Rate: 0.000459903
	LOSS [training: 0.09300223520988718 | validation: 0.10847822166475055]
	TIME [epoch: 8.33 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1306240885227758		[learning rate: 0.00045882]
	Learning Rate: 0.000458819
	LOSS [training: 0.1306240885227758 | validation: 0.125939405691984]
	TIME [epoch: 8.35 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10405922928657245		[learning rate: 0.00045774]
	Learning Rate: 0.000457736
	LOSS [training: 0.10405922928657245 | validation: 0.11238882826293708]
	TIME [epoch: 8.33 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13722184675808108		[learning rate: 0.00045666]
	Learning Rate: 0.000456657
	LOSS [training: 0.13722184675808108 | validation: 0.11219656114329143]
	TIME [epoch: 8.33 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08441518359446724		[learning rate: 0.00045558]
	Learning Rate: 0.000455579
	LOSS [training: 0.08441518359446724 | validation: 0.09310288735410033]
	TIME [epoch: 8.32 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.125954452244398		[learning rate: 0.0004545]
	Learning Rate: 0.000454505
	LOSS [training: 0.125954452244398 | validation: 0.09038729549097468]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_1359.pth
	Model improved!!!
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0976507954918851		[learning rate: 0.00045343]
	Learning Rate: 0.000453433
	LOSS [training: 0.0976507954918851 | validation: 0.12032444955023341]
	TIME [epoch: 8.33 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10293871305274602		[learning rate: 0.00045236]
	Learning Rate: 0.000452363
	LOSS [training: 0.10293871305274602 | validation: 0.10466699230306961]
	TIME [epoch: 8.32 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10964021226981684		[learning rate: 0.0004513]
	Learning Rate: 0.000451296
	LOSS [training: 0.10964021226981684 | validation: 0.16575152348266248]
	TIME [epoch: 8.32 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12055129411429485		[learning rate: 0.00045023]
	Learning Rate: 0.000450232
	LOSS [training: 0.12055129411429485 | validation: 0.11098483903872512]
	TIME [epoch: 8.34 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15299980533496285		[learning rate: 0.00044917]
	Learning Rate: 0.000449169
	LOSS [training: 0.15299980533496285 | validation: 0.26900326387303347]
	TIME [epoch: 8.33 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1252586670433749		[learning rate: 0.00044811]
	Learning Rate: 0.00044811
	LOSS [training: 0.1252586670433749 | validation: 0.14040516163383118]
	TIME [epoch: 8.33 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10439037786537826		[learning rate: 0.00044705]
	Learning Rate: 0.000447053
	LOSS [training: 0.10439037786537826 | validation: 0.14627945242448592]
	TIME [epoch: 8.32 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10378828358228817		[learning rate: 0.000446]
	Learning Rate: 0.000445998
	LOSS [training: 0.10378828358228817 | validation: 0.1564508655929751]
	TIME [epoch: 8.33 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12990125200617592		[learning rate: 0.00044495]
	Learning Rate: 0.000444946
	LOSS [training: 0.12990125200617592 | validation: 0.16850166511876252]
	TIME [epoch: 8.34 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11617209078794069		[learning rate: 0.0004439]
	Learning Rate: 0.000443897
	LOSS [training: 0.11617209078794069 | validation: 0.09970259607764961]
	TIME [epoch: 8.32 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11039925259961274		[learning rate: 0.00044285]
	Learning Rate: 0.00044285
	LOSS [training: 0.11039925259961274 | validation: 0.12692955455089544]
	TIME [epoch: 8.32 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1383439064052527		[learning rate: 0.00044181]
	Learning Rate: 0.000441805
	LOSS [training: 0.1383439064052527 | validation: 0.13626050828426647]
	TIME [epoch: 8.32 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12618183487578838		[learning rate: 0.00044076]
	Learning Rate: 0.000440763
	LOSS [training: 0.12618183487578838 | validation: 0.12938650615988867]
	TIME [epoch: 8.34 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11874227477636819		[learning rate: 0.00043972]
	Learning Rate: 0.000439723
	LOSS [training: 0.11874227477636819 | validation: 0.15661739447987752]
	TIME [epoch: 8.33 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12152670194359652		[learning rate: 0.00043869]
	Learning Rate: 0.000438686
	LOSS [training: 0.12152670194359652 | validation: 0.12409699068981883]
	TIME [epoch: 8.33 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12219971464929746		[learning rate: 0.00043765]
	Learning Rate: 0.000437651
	LOSS [training: 0.12219971464929746 | validation: 0.12008665641742297]
	TIME [epoch: 8.33 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11459219457268333		[learning rate: 0.00043662]
	Learning Rate: 0.000436619
	LOSS [training: 0.11459219457268333 | validation: 0.0979433745408048]
	TIME [epoch: 8.34 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12954610817457196		[learning rate: 0.00043559]
	Learning Rate: 0.000435589
	LOSS [training: 0.12954610817457196 | validation: 0.12610824102936302]
	TIME [epoch: 8.34 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09585217733467429		[learning rate: 0.00043456]
	Learning Rate: 0.000434562
	LOSS [training: 0.09585217733467429 | validation: 0.11565433007490769]
	TIME [epoch: 8.33 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11246438578677273		[learning rate: 0.00043354]
	Learning Rate: 0.000433536
	LOSS [training: 0.11246438578677273 | validation: 0.1122173073226077]
	TIME [epoch: 8.32 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1043770905966425		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.1043770905966425 | validation: 0.11113515481514001]
	TIME [epoch: 8.34 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11095217336653529		[learning rate: 0.00043149]
	Learning Rate: 0.000431494
	LOSS [training: 0.11095217336653529 | validation: 0.120027477008364]
	TIME [epoch: 8.35 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12733342334800396		[learning rate: 0.00043048]
	Learning Rate: 0.000430476
	LOSS [training: 0.12733342334800396 | validation: 0.09569008011782053]
	TIME [epoch: 8.33 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14922172948760234		[learning rate: 0.00042946]
	Learning Rate: 0.00042946
	LOSS [training: 0.14922172948760234 | validation: 0.12696503539102133]
	TIME [epoch: 8.33 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09953459515572577		[learning rate: 0.00042845]
	Learning Rate: 0.000428447
	LOSS [training: 0.09953459515572577 | validation: 0.12464231394702358]
	TIME [epoch: 8.33 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10927139127803473		[learning rate: 0.00042744]
	Learning Rate: 0.000427437
	LOSS [training: 0.10927139127803473 | validation: 0.18371595680448727]
	TIME [epoch: 8.35 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13150489079598748		[learning rate: 0.00042643]
	Learning Rate: 0.000426428
	LOSS [training: 0.13150489079598748 | validation: 0.11984402699498486]
	TIME [epoch: 8.33 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1223489025373942		[learning rate: 0.00042542]
	Learning Rate: 0.000425423
	LOSS [training: 0.1223489025373942 | validation: 0.11521094314165442]
	TIME [epoch: 8.32 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11401460443371889		[learning rate: 0.00042442]
	Learning Rate: 0.000424419
	LOSS [training: 0.11401460443371889 | validation: 0.14371686263614902]
	TIME [epoch: 8.32 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11852057830626828		[learning rate: 0.00042342]
	Learning Rate: 0.000423418
	LOSS [training: 0.11852057830626828 | validation: 0.10886147692221193]
	TIME [epoch: 8.35 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13010042225536525		[learning rate: 0.00042242]
	Learning Rate: 0.000422419
	LOSS [training: 0.13010042225536525 | validation: 0.12288492849168167]
	TIME [epoch: 8.33 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0977684253882251		[learning rate: 0.00042142]
	Learning Rate: 0.000421423
	LOSS [training: 0.0977684253882251 | validation: 0.11827291144867018]
	TIME [epoch: 8.33 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11196015829037416		[learning rate: 0.00042043]
	Learning Rate: 0.000420429
	LOSS [training: 0.11196015829037416 | validation: 0.13231952316058174]
	TIME [epoch: 8.33 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13230916571858295		[learning rate: 0.00041944]
	Learning Rate: 0.000419437
	LOSS [training: 0.13230916571858295 | validation: 0.15354591631168696]
	TIME [epoch: 8.33 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14452688515706633		[learning rate: 0.00041845]
	Learning Rate: 0.000418448
	LOSS [training: 0.14452688515706633 | validation: 0.15286569149863766]
	TIME [epoch: 8.34 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12451741229893776		[learning rate: 0.00041746]
	Learning Rate: 0.00041746
	LOSS [training: 0.12451741229893776 | validation: 0.16011199051981737]
	TIME [epoch: 8.32 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11047602919470556		[learning rate: 0.00041648]
	Learning Rate: 0.000416476
	LOSS [training: 0.11047602919470556 | validation: 0.1314194740063156]
	TIME [epoch: 8.33 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0947180711767552		[learning rate: 0.00041549]
	Learning Rate: 0.000415493
	LOSS [training: 0.0947180711767552 | validation: 0.11692562168897008]
	TIME [epoch: 8.33 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12640478190538412		[learning rate: 0.00041451]
	Learning Rate: 0.000414513
	LOSS [training: 0.12640478190538412 | validation: 0.13043047175184846]
	TIME [epoch: 8.34 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10273502103846036		[learning rate: 0.00041354]
	Learning Rate: 0.000413535
	LOSS [training: 0.10273502103846036 | validation: 0.12794915237814317]
	TIME [epoch: 8.33 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1257725049016887		[learning rate: 0.00041256]
	Learning Rate: 0.00041256
	LOSS [training: 0.1257725049016887 | validation: 0.1391940548595869]
	TIME [epoch: 8.32 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14540596012882806		[learning rate: 0.00041159]
	Learning Rate: 0.000411587
	LOSS [training: 0.14540596012882806 | validation: 0.13233564412190074]
	TIME [epoch: 8.32 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10906655733123242		[learning rate: 0.00041062]
	Learning Rate: 0.000410616
	LOSS [training: 0.10906655733123242 | validation: 0.10813341688430486]
	TIME [epoch: 8.34 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11060766866627861		[learning rate: 0.00040965]
	Learning Rate: 0.000409647
	LOSS [training: 0.11060766866627861 | validation: 0.11368518452840096]
	TIME [epoch: 8.33 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09939610751889257		[learning rate: 0.00040868]
	Learning Rate: 0.000408681
	LOSS [training: 0.09939610751889257 | validation: 0.11292737017915365]
	TIME [epoch: 8.32 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09839074964182093		[learning rate: 0.00040772]
	Learning Rate: 0.000407717
	LOSS [training: 0.09839074964182093 | validation: 0.09798010126248163]
	TIME [epoch: 8.33 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.108517203727112		[learning rate: 0.00040676]
	Learning Rate: 0.000406755
	LOSS [training: 0.108517203727112 | validation: 0.13178846819840945]
	TIME [epoch: 8.33 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11222727533446633		[learning rate: 0.0004058]
	Learning Rate: 0.000405796
	LOSS [training: 0.11222727533446633 | validation: 0.10434053426713218]
	TIME [epoch: 8.35 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10311983007403283		[learning rate: 0.00040484]
	Learning Rate: 0.000404839
	LOSS [training: 0.10311983007403283 | validation: 0.11831282703111404]
	TIME [epoch: 8.32 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10156111591706132		[learning rate: 0.00040388]
	Learning Rate: 0.000403884
	LOSS [training: 0.10156111591706132 | validation: 0.09614094105275942]
	TIME [epoch: 8.33 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10300144936989115		[learning rate: 0.00040293]
	Learning Rate: 0.000402931
	LOSS [training: 0.10300144936989115 | validation: 0.11005390092335116]
	TIME [epoch: 8.33 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10301598794412661		[learning rate: 0.00040198]
	Learning Rate: 0.000401981
	LOSS [training: 0.10301598794412661 | validation: 0.1208640787802139]
	TIME [epoch: 8.34 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10351901188336676		[learning rate: 0.00040103]
	Learning Rate: 0.000401032
	LOSS [training: 0.10351901188336676 | validation: 0.13445504568040012]
	TIME [epoch: 8.32 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11946594083187667		[learning rate: 0.00040009]
	Learning Rate: 0.000400086
	LOSS [training: 0.11946594083187667 | validation: 0.1424721993310298]
	TIME [epoch: 8.32 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12892911068147886		[learning rate: 0.00039914]
	Learning Rate: 0.000399143
	LOSS [training: 0.12892911068147886 | validation: 0.12850243990588256]
	TIME [epoch: 8.32 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11743892525404889		[learning rate: 0.0003982]
	Learning Rate: 0.000398201
	LOSS [training: 0.11743892525404889 | validation: 0.10856449737978512]
	TIME [epoch: 8.34 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09955707031634577		[learning rate: 0.00039726]
	Learning Rate: 0.000397262
	LOSS [training: 0.09955707031634577 | validation: 0.10866342081845622]
	TIME [epoch: 8.32 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10678129962828628		[learning rate: 0.00039632]
	Learning Rate: 0.000396325
	LOSS [training: 0.10678129962828628 | validation: 0.1465558865069928]
	TIME [epoch: 8.32 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11493019621883574		[learning rate: 0.00039539]
	Learning Rate: 0.00039539
	LOSS [training: 0.11493019621883574 | validation: 0.12860052811064604]
	TIME [epoch: 8.32 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09887525616348405		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.09887525616348405 | validation: 0.1369441989679807]
	TIME [epoch: 8.33 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11856909780507267		[learning rate: 0.00039353]
	Learning Rate: 0.000393527
	LOSS [training: 0.11856909780507267 | validation: 0.13745447319428664]
	TIME [epoch: 8.34 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11087721665434754		[learning rate: 0.0003926]
	Learning Rate: 0.000392599
	LOSS [training: 0.11087721665434754 | validation: 0.1397447824853552]
	TIME [epoch: 8.32 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10062341751193793		[learning rate: 0.00039167]
	Learning Rate: 0.000391672
	LOSS [training: 0.10062341751193793 | validation: 0.10544437252225825]
	TIME [epoch: 8.32 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0950928962183906		[learning rate: 0.00039075]
	Learning Rate: 0.000390748
	LOSS [training: 0.0950928962183906 | validation: 0.09670324771140247]
	TIME [epoch: 8.32 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11445648524794076		[learning rate: 0.00038983]
	Learning Rate: 0.000389827
	LOSS [training: 0.11445648524794076 | validation: 0.15212494944472305]
	TIME [epoch: 8.33 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1161442862315524		[learning rate: 0.00038891]
	Learning Rate: 0.000388907
	LOSS [training: 0.1161442862315524 | validation: 0.08672907636468045]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_1425.pth
	Model improved!!!
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09305697973581054		[learning rate: 0.00038799]
	Learning Rate: 0.00038799
	LOSS [training: 0.09305697973581054 | validation: 0.13089105121040567]
	TIME [epoch: 8.31 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09381792027610346		[learning rate: 0.00038707]
	Learning Rate: 0.000387075
	LOSS [training: 0.09381792027610346 | validation: 0.107712848633889]
	TIME [epoch: 8.32 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0886830282761293		[learning rate: 0.00038616]
	Learning Rate: 0.000386162
	LOSS [training: 0.0886830282761293 | validation: 0.12165643200816423]
	TIME [epoch: 8.33 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08878136430977536		[learning rate: 0.00038525]
	Learning Rate: 0.000385251
	LOSS [training: 0.08878136430977536 | validation: 0.10248193790548224]
	TIME [epoch: 8.32 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09311245053368203		[learning rate: 0.00038434]
	Learning Rate: 0.000384342
	LOSS [training: 0.09311245053368203 | validation: 0.13097025571848467]
	TIME [epoch: 8.32 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1173579516202465		[learning rate: 0.00038344]
	Learning Rate: 0.000383435
	LOSS [training: 0.1173579516202465 | validation: 0.12293089996564106]
	TIME [epoch: 8.32 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10110369916568782		[learning rate: 0.00038253]
	Learning Rate: 0.000382531
	LOSS [training: 0.10110369916568782 | validation: 0.11940671450819262]
	TIME [epoch: 8.33 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10303350262426228		[learning rate: 0.00038163]
	Learning Rate: 0.000381629
	LOSS [training: 0.10303350262426228 | validation: 0.10351992662793802]
	TIME [epoch: 8.34 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09730501569204697		[learning rate: 0.00038073]
	Learning Rate: 0.000380729
	LOSS [training: 0.09730501569204697 | validation: 0.1270468088117579]
	TIME [epoch: 8.31 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09181480326236814		[learning rate: 0.00037983]
	Learning Rate: 0.00037983
	LOSS [training: 0.09181480326236814 | validation: 0.09874502780557798]
	TIME [epoch: 8.32 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10135403894357439		[learning rate: 0.00037893]
	Learning Rate: 0.000378934
	LOSS [training: 0.10135403894357439 | validation: 0.11999711947174274]
	TIME [epoch: 8.32 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10127706749516643		[learning rate: 0.00037804]
	Learning Rate: 0.000378041
	LOSS [training: 0.10127706749516643 | validation: 0.12359544988126098]
	TIME [epoch: 8.33 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0998127840708094		[learning rate: 0.00037715]
	Learning Rate: 0.000377149
	LOSS [training: 0.0998127840708094 | validation: 0.12021735783685598]
	TIME [epoch: 8.32 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09131981750399766		[learning rate: 0.00037626]
	Learning Rate: 0.000376259
	LOSS [training: 0.09131981750399766 | validation: 0.11476217044400744]
	TIME [epoch: 8.32 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10368566265035435		[learning rate: 0.00037537]
	Learning Rate: 0.000375372
	LOSS [training: 0.10368566265035435 | validation: 0.10223730262456325]
	TIME [epoch: 8.31 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09038896301095496		[learning rate: 0.00037449]
	Learning Rate: 0.000374486
	LOSS [training: 0.09038896301095496 | validation: 0.0928530188764012]
	TIME [epoch: 8.33 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10367489465732309		[learning rate: 0.0003736]
	Learning Rate: 0.000373603
	LOSS [training: 0.10367489465732309 | validation: 0.12064486077610426]
	TIME [epoch: 8.32 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09813241945505098		[learning rate: 0.00037272]
	Learning Rate: 0.000372722
	LOSS [training: 0.09813241945505098 | validation: 0.10118371347080689]
	TIME [epoch: 8.32 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09023872036236524		[learning rate: 0.00037184]
	Learning Rate: 0.000371842
	LOSS [training: 0.09023872036236524 | validation: 0.09538796439719023]
	TIME [epoch: 8.31 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11199145577326353		[learning rate: 0.00037097]
	Learning Rate: 0.000370965
	LOSS [training: 0.11199145577326353 | validation: 0.10824217860153483]
	TIME [epoch: 8.31 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10254096846923337		[learning rate: 0.00037009]
	Learning Rate: 0.00037009
	LOSS [training: 0.10254096846923337 | validation: 0.1179794451976198]
	TIME [epoch: 8.32 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09467098715253025		[learning rate: 0.00036922]
	Learning Rate: 0.000369217
	LOSS [training: 0.09467098715253025 | validation: 0.10729838118309712]
	TIME [epoch: 8.31 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09679977655906585		[learning rate: 0.00036835]
	Learning Rate: 0.000368346
	LOSS [training: 0.09679977655906585 | validation: 0.10450732385015774]
	TIME [epoch: 8.31 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10811601326629736		[learning rate: 0.00036748]
	Learning Rate: 0.000367477
	LOSS [training: 0.10811601326629736 | validation: 0.12728188833330417]
	TIME [epoch: 8.32 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10048113428359698		[learning rate: 0.00036661]
	Learning Rate: 0.000366611
	LOSS [training: 0.10048113428359698 | validation: 0.11650242654484913]
	TIME [epoch: 8.34 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09740840179796524		[learning rate: 0.00036575]
	Learning Rate: 0.000365746
	LOSS [training: 0.09740840179796524 | validation: 0.113230337574758]
	TIME [epoch: 8.31 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10535871148848353		[learning rate: 0.00036488]
	Learning Rate: 0.000364883
	LOSS [training: 0.10535871148848353 | validation: 0.1683271616430866]
	TIME [epoch: 8.32 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09853121941293747		[learning rate: 0.00036402]
	Learning Rate: 0.000364022
	LOSS [training: 0.09853121941293747 | validation: 0.11170872821937253]
	TIME [epoch: 8.31 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09273929062420903		[learning rate: 0.00036316]
	Learning Rate: 0.000363164
	LOSS [training: 0.09273929062420903 | validation: 0.11356836689305749]
	TIME [epoch: 8.33 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1013796315455896		[learning rate: 0.00036231]
	Learning Rate: 0.000362307
	LOSS [training: 0.1013796315455896 | validation: 0.11206231100441924]
	TIME [epoch: 8.32 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09997788540927902		[learning rate: 0.00036145]
	Learning Rate: 0.000361452
	LOSS [training: 0.09997788540927902 | validation: 0.13307545368227994]
	TIME [epoch: 8.31 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10104389390540158		[learning rate: 0.0003606]
	Learning Rate: 0.0003606
	LOSS [training: 0.10104389390540158 | validation: 0.1225832789732319]
	TIME [epoch: 8.32 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0888377525774478		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.0888377525774478 | validation: 0.0979726364156702]
	TIME [epoch: 8.32 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09081923504939432		[learning rate: 0.0003589]
	Learning Rate: 0.000358901
	LOSS [training: 0.09081923504939432 | validation: 0.10751860189929413]
	TIME [epoch: 8.33 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08451421070611301		[learning rate: 0.00035805]
	Learning Rate: 0.000358054
	LOSS [training: 0.08451421070611301 | validation: 0.10501889949900878]
	TIME [epoch: 8.32 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08793069434454262		[learning rate: 0.00035721]
	Learning Rate: 0.00035721
	LOSS [training: 0.08793069434454262 | validation: 0.09663949423340228]
	TIME [epoch: 8.31 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10519658749963168		[learning rate: 0.00035637]
	Learning Rate: 0.000356367
	LOSS [training: 0.10519658749963168 | validation: 0.1552248736263191]
	TIME [epoch: 8.32 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13044126378612422		[learning rate: 0.00035553]
	Learning Rate: 0.000355526
	LOSS [training: 0.13044126378612422 | validation: 0.1255000775056414]
	TIME [epoch: 8.34 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09848891634704933		[learning rate: 0.00035469]
	Learning Rate: 0.000354688
	LOSS [training: 0.09848891634704933 | validation: 0.15482818382162938]
	TIME [epoch: 8.31 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08795593945498159		[learning rate: 0.00035385]
	Learning Rate: 0.000353851
	LOSS [training: 0.08795593945498159 | validation: 0.0977971999635933]
	TIME [epoch: 8.31 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09236216516266689		[learning rate: 0.00035302]
	Learning Rate: 0.000353016
	LOSS [training: 0.09236216516266689 | validation: 0.12360240273067657]
	TIME [epoch: 8.31 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10530522306491989		[learning rate: 0.00035218]
	Learning Rate: 0.000352184
	LOSS [training: 0.10530522306491989 | validation: 0.1042246434698646]
	TIME [epoch: 8.33 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09434622133015313		[learning rate: 0.00035135]
	Learning Rate: 0.000351353
	LOSS [training: 0.09434622133015313 | validation: 0.11029896582324841]
	TIME [epoch: 8.32 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09223273947607209		[learning rate: 0.00035052]
	Learning Rate: 0.000350524
	LOSS [training: 0.09223273947607209 | validation: 0.11256158776181771]
	TIME [epoch: 8.31 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1096826413928537		[learning rate: 0.0003497]
	Learning Rate: 0.000349697
	LOSS [training: 0.1096826413928537 | validation: 0.12345358054137359]
	TIME [epoch: 8.31 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09027385955180951		[learning rate: 0.00034887]
	Learning Rate: 0.000348872
	LOSS [training: 0.09027385955180951 | validation: 0.10051748150177979]
	TIME [epoch: 8.33 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10805132706669233		[learning rate: 0.00034805]
	Learning Rate: 0.000348049
	LOSS [training: 0.10805132706669233 | validation: 0.13218323682802469]
	TIME [epoch: 8.33 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11492962174624352		[learning rate: 0.00034723]
	Learning Rate: 0.000347228
	LOSS [training: 0.11492962174624352 | validation: 0.08604991688244698]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_1473.pth
	Model improved!!!
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08277285082248882		[learning rate: 0.00034641]
	Learning Rate: 0.000346409
	LOSS [training: 0.08277285082248882 | validation: 0.0898333696499578]
	TIME [epoch: 8.32 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09083383125439323		[learning rate: 0.00034559]
	Learning Rate: 0.000345592
	LOSS [training: 0.09083383125439323 | validation: 0.10907399154029188]
	TIME [epoch: 8.32 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08034281447784677		[learning rate: 0.00034478]
	Learning Rate: 0.000344777
	LOSS [training: 0.08034281447784677 | validation: 0.09743664795088812]
	TIME [epoch: 8.34 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09863472892849787		[learning rate: 0.00034396]
	Learning Rate: 0.000343964
	LOSS [training: 0.09863472892849787 | validation: 0.11652590870688503]
	TIME [epoch: 8.31 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10995721416018585		[learning rate: 0.00034315]
	Learning Rate: 0.000343152
	LOSS [training: 0.10995721416018585 | validation: 0.13363826105403726]
	TIME [epoch: 8.31 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10932509998848039		[learning rate: 0.00034234]
	Learning Rate: 0.000342343
	LOSS [training: 0.10932509998848039 | validation: 0.13897101493190112]
	TIME [epoch: 8.32 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09539415939061711		[learning rate: 0.00034154]
	Learning Rate: 0.000341536
	LOSS [training: 0.09539415939061711 | validation: 0.08871613821237634]
	TIME [epoch: 8.34 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08594346258740032		[learning rate: 0.00034073]
	Learning Rate: 0.00034073
	LOSS [training: 0.08594346258740032 | validation: 0.10194672900630886]
	TIME [epoch: 8.32 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08216618870799455		[learning rate: 0.00033993]
	Learning Rate: 0.000339926
	LOSS [training: 0.08216618870799455 | validation: 0.10496061919777279]
	TIME [epoch: 8.31 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10160191751331002		[learning rate: 0.00033912]
	Learning Rate: 0.000339124
	LOSS [training: 0.10160191751331002 | validation: 0.14543596225226443]
	TIME [epoch: 8.32 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11209966444583697		[learning rate: 0.00033832]
	Learning Rate: 0.000338324
	LOSS [training: 0.11209966444583697 | validation: 0.11970654873358405]
	TIME [epoch: 8.31 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13309393610616987		[learning rate: 0.00033753]
	Learning Rate: 0.000337526
	LOSS [training: 0.13309393610616987 | validation: 0.172498337290438]
	TIME [epoch: 8.33 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1521777413291614		[learning rate: 0.00033673]
	Learning Rate: 0.00033673
	LOSS [training: 0.1521777413291614 | validation: 0.1540256761566882]
	TIME [epoch: 8.32 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12015157597174572		[learning rate: 0.00033594]
	Learning Rate: 0.000335936
	LOSS [training: 0.12015157597174572 | validation: 0.1274681952254791]
	TIME [epoch: 8.31 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09623106078067376		[learning rate: 0.00033514]
	Learning Rate: 0.000335143
	LOSS [training: 0.09623106078067376 | validation: 0.10513625857083686]
	TIME [epoch: 8.32 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08811040749414104		[learning rate: 0.00033435]
	Learning Rate: 0.000334353
	LOSS [training: 0.08811040749414104 | validation: 0.11032123025430599]
	TIME [epoch: 8.34 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08233845825054435		[learning rate: 0.00033356]
	Learning Rate: 0.000333564
	LOSS [training: 0.08233845825054435 | validation: 0.10390942908591373]
	TIME [epoch: 8.32 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08932741871915209		[learning rate: 0.00033278]
	Learning Rate: 0.000332777
	LOSS [training: 0.08932741871915209 | validation: 0.1132790256733901]
	TIME [epoch: 8.32 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09237715228335526		[learning rate: 0.00033199]
	Learning Rate: 0.000331992
	LOSS [training: 0.09237715228335526 | validation: 0.1052760520030388]
	TIME [epoch: 8.31 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0959407730743127		[learning rate: 0.00033121]
	Learning Rate: 0.000331209
	LOSS [training: 0.0959407730743127 | validation: 0.11730939110217349]
	TIME [epoch: 8.34 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09514440430363062		[learning rate: 0.00033043]
	Learning Rate: 0.000330428
	LOSS [training: 0.09514440430363062 | validation: 0.10071341544279452]
	TIME [epoch: 8.32 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0882383548172084		[learning rate: 0.00032965]
	Learning Rate: 0.000329649
	LOSS [training: 0.0882383548172084 | validation: 0.11239515739366365]
	TIME [epoch: 8.31 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09055946414763963		[learning rate: 0.00032887]
	Learning Rate: 0.000328871
	LOSS [training: 0.09055946414763963 | validation: 0.12046892531218753]
	TIME [epoch: 8.32 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09574709780279618		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.09574709780279618 | validation: 0.11856491603002514]
	TIME [epoch: 8.32 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10069683953518734		[learning rate: 0.00032732]
	Learning Rate: 0.000327321
	LOSS [training: 0.10069683953518734 | validation: 0.10574461756121836]
	TIME [epoch: 8.33 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09896904464248253		[learning rate: 0.00032655]
	Learning Rate: 0.000326549
	LOSS [training: 0.09896904464248253 | validation: 0.1054081178823055]
	TIME [epoch: 8.32 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0839073200087084		[learning rate: 0.00032578]
	Learning Rate: 0.000325779
	LOSS [training: 0.0839073200087084 | validation: 0.11196519091848067]
	TIME [epoch: 8.31 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11665847411148518		[learning rate: 0.00032501]
	Learning Rate: 0.000325011
	LOSS [training: 0.11665847411148518 | validation: 0.1681180130879784]
	TIME [epoch: 8.32 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10799295729871403		[learning rate: 0.00032424]
	Learning Rate: 0.000324244
	LOSS [training: 0.10799295729871403 | validation: 0.12475240390067849]
	TIME [epoch: 8.33 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12721320724835697		[learning rate: 0.00032348]
	Learning Rate: 0.000323479
	LOSS [training: 0.12721320724835697 | validation: 0.25114386948055534]
	TIME [epoch: 8.31 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1427703062202405		[learning rate: 0.00032272]
	Learning Rate: 0.000322716
	LOSS [training: 0.1427703062202405 | validation: 0.15458812469157923]
	TIME [epoch: 8.31 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1259692599980632		[learning rate: 0.00032195]
	Learning Rate: 0.000321955
	LOSS [training: 0.1259692599980632 | validation: 0.14021226527884606]
	TIME [epoch: 8.31 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12289612377267714		[learning rate: 0.0003212]
	Learning Rate: 0.000321195
	LOSS [training: 0.12289612377267714 | validation: 0.15221985622287326]
	TIME [epoch: 8.34 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13566080158830793		[learning rate: 0.00032044]
	Learning Rate: 0.000320438
	LOSS [training: 0.13566080158830793 | validation: 0.1583895259701104]
	TIME [epoch: 8.31 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12163020687781204		[learning rate: 0.00031968]
	Learning Rate: 0.000319682
	LOSS [training: 0.12163020687781204 | validation: 0.12128269629946065]
	TIME [epoch: 8.3 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09666566918234376		[learning rate: 0.00031893]
	Learning Rate: 0.000318928
	LOSS [training: 0.09666566918234376 | validation: 0.10827818193206543]
	TIME [epoch: 8.31 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10613582892482035		[learning rate: 0.00031818]
	Learning Rate: 0.000318175
	LOSS [training: 0.10613582892482035 | validation: 0.13355700020612615]
	TIME [epoch: 8.32 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11082114809128865		[learning rate: 0.00031742]
	Learning Rate: 0.000317425
	LOSS [training: 0.11082114809128865 | validation: 0.10201255132115888]
	TIME [epoch: 8.33 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10044295083361672		[learning rate: 0.00031668]
	Learning Rate: 0.000316676
	LOSS [training: 0.10044295083361672 | validation: 0.11729055338258704]
	TIME [epoch: 8.33 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11150567028773303		[learning rate: 0.00031593]
	Learning Rate: 0.000315929
	LOSS [training: 0.11150567028773303 | validation: 0.11012007629342366]
	TIME [epoch: 8.32 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1140527605967917		[learning rate: 0.00031518]
	Learning Rate: 0.000315184
	LOSS [training: 0.1140527605967917 | validation: 0.11884831264273749]
	TIME [epoch: 8.31 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09878890270210212		[learning rate: 0.00031444]
	Learning Rate: 0.00031444
	LOSS [training: 0.09878890270210212 | validation: 0.12234189869017181]
	TIME [epoch: 8.34 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09709575709803928		[learning rate: 0.0003137]
	Learning Rate: 0.000313699
	LOSS [training: 0.09709575709803928 | validation: 0.1292416305786865]
	TIME [epoch: 8.32 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09295027144751244		[learning rate: 0.00031296]
	Learning Rate: 0.000312959
	LOSS [training: 0.09295027144751244 | validation: 0.10113738640341746]
	TIME [epoch: 8.31 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09257319229272559		[learning rate: 0.00031222]
	Learning Rate: 0.000312221
	LOSS [training: 0.09257319229272559 | validation: 0.13590341285036467]
	TIME [epoch: 8.32 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08744876970466103		[learning rate: 0.00031148]
	Learning Rate: 0.000311484
	LOSS [training: 0.08744876970466103 | validation: 0.10139422586209218]
	TIME [epoch: 8.33 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09253772717765588		[learning rate: 0.00031075]
	Learning Rate: 0.000310749
	LOSS [training: 0.09253772717765588 | validation: 0.10629262411670909]
	TIME [epoch: 8.32 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0887447591732703		[learning rate: 0.00031002]
	Learning Rate: 0.000310016
	LOSS [training: 0.0887447591732703 | validation: 0.10185729254337303]
	TIME [epoch: 8.31 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09527146620853467		[learning rate: 0.00030929]
	Learning Rate: 0.000309285
	LOSS [training: 0.09527146620853467 | validation: 0.12025260958734346]
	TIME [epoch: 8.31 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10301554234669559		[learning rate: 0.00030856]
	Learning Rate: 0.000308555
	LOSS [training: 0.10301554234669559 | validation: 0.11535575393692396]
	TIME [epoch: 8.31 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09725802249520327		[learning rate: 0.00030783]
	Learning Rate: 0.000307828
	LOSS [training: 0.09725802249520327 | validation: 0.12168237642981172]
	TIME [epoch: 8.33 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09911929378650926		[learning rate: 0.0003071]
	Learning Rate: 0.000307102
	LOSS [training: 0.09911929378650926 | validation: 0.11674849499132503]
	TIME [epoch: 8.3 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12930365436221025		[learning rate: 0.00030638]
	Learning Rate: 0.000306377
	LOSS [training: 0.12930365436221025 | validation: 0.1522643606985554]
	TIME [epoch: 8.31 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11878870036159836		[learning rate: 0.00030565]
	Learning Rate: 0.000305654
	LOSS [training: 0.11878870036159836 | validation: 0.1157674938936761]
	TIME [epoch: 8.31 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1097405033786166		[learning rate: 0.00030493]
	Learning Rate: 0.000304933
	LOSS [training: 0.1097405033786166 | validation: 0.12230627396568675]
	TIME [epoch: 8.34 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09844025154945038		[learning rate: 0.00030421]
	Learning Rate: 0.000304214
	LOSS [training: 0.09844025154945038 | validation: 0.10181771507181736]
	TIME [epoch: 8.32 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08841719712837427		[learning rate: 0.0003035]
	Learning Rate: 0.000303497
	LOSS [training: 0.08841719712837427 | validation: 0.09349640664504857]
	TIME [epoch: 8.3 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08670728628255382		[learning rate: 0.00030278]
	Learning Rate: 0.000302781
	LOSS [training: 0.08670728628255382 | validation: 0.09707114309581541]
	TIME [epoch: 8.31 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11043390102044628		[learning rate: 0.00030207]
	Learning Rate: 0.000302066
	LOSS [training: 0.11043390102044628 | validation: 0.10334486224482539]
	TIME [epoch: 8.33 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09948888589275023		[learning rate: 0.00030135]
	Learning Rate: 0.000301354
	LOSS [training: 0.09948888589275023 | validation: 0.10917207156218922]
	TIME [epoch: 8.32 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08682284551785902		[learning rate: 0.00030064]
	Learning Rate: 0.000300643
	LOSS [training: 0.08682284551785902 | validation: 0.12776858076181874]
	TIME [epoch: 8.31 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08879214951464613		[learning rate: 0.00029993]
	Learning Rate: 0.000299934
	LOSS [training: 0.08879214951464613 | validation: 0.10035180133392013]
	TIME [epoch: 8.3 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10207406021223572		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.10207406021223572 | validation: 0.11339369503296653]
	TIME [epoch: 8.31 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10087144846842452		[learning rate: 0.00029852]
	Learning Rate: 0.000298521
	LOSS [training: 0.10087144846842452 | validation: 0.21249273654714393]
	TIME [epoch: 8.33 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12128914192419131		[learning rate: 0.00029782]
	Learning Rate: 0.000297816
	LOSS [training: 0.12128914192419131 | validation: 0.10426331305283552]
	TIME [epoch: 8.31 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09761916919857157		[learning rate: 0.00029711]
	Learning Rate: 0.000297114
	LOSS [training: 0.09761916919857157 | validation: 0.11440259472864811]
	TIME [epoch: 8.32 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08996718635318623		[learning rate: 0.00029641]
	Learning Rate: 0.000296413
	LOSS [training: 0.08996718635318623 | validation: 0.14935406565136988]
	TIME [epoch: 8.32 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.111493555019247		[learning rate: 0.00029571]
	Learning Rate: 0.000295714
	LOSS [training: 0.111493555019247 | validation: 0.10419734751190829]
	TIME [epoch: 8.34 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1059379114259863		[learning rate: 0.00029502]
	Learning Rate: 0.000295016
	LOSS [training: 0.1059379114259863 | validation: 0.13369288584272848]
	TIME [epoch: 8.31 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10854691513939078		[learning rate: 0.00029432]
	Learning Rate: 0.00029432
	LOSS [training: 0.10854691513939078 | validation: 0.1299238939299952]
	TIME [epoch: 8.31 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12732352112091866		[learning rate: 0.00029363]
	Learning Rate: 0.000293626
	LOSS [training: 0.12732352112091866 | validation: 0.12666353867330876]
	TIME [epoch: 8.31 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12907610636412428		[learning rate: 0.00029293]
	Learning Rate: 0.000292934
	LOSS [training: 0.12907610636412428 | validation: 0.13877297726501026]
	TIME [epoch: 8.34 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14364032285737788		[learning rate: 0.00029224]
	Learning Rate: 0.000292243
	LOSS [training: 0.14364032285737788 | validation: 0.17235939390436605]
	TIME [epoch: 8.33 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13173900011466905		[learning rate: 0.00029155]
	Learning Rate: 0.000291553
	LOSS [training: 0.13173900011466905 | validation: 0.11452995306982815]
	TIME [epoch: 8.32 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09332117514284502		[learning rate: 0.00029087]
	Learning Rate: 0.000290866
	LOSS [training: 0.09332117514284502 | validation: 0.12296540536129164]
	TIME [epoch: 8.31 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1156841728768413		[learning rate: 0.00029018]
	Learning Rate: 0.000290179
	LOSS [training: 0.1156841728768413 | validation: 0.14754505823994474]
	TIME [epoch: 8.32 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11042896651547358		[learning rate: 0.00028949]
	Learning Rate: 0.000289495
	LOSS [training: 0.11042896651547358 | validation: 0.11915884961260104]
	TIME [epoch: 8.35 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09273833093746796		[learning rate: 0.00028881]
	Learning Rate: 0.000288812
	LOSS [training: 0.09273833093746796 | validation: 0.1036503033314197]
	TIME [epoch: 8.32 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10941499357971027		[learning rate: 0.00028813]
	Learning Rate: 0.000288131
	LOSS [training: 0.10941499357971027 | validation: 0.11570017899018854]
	TIME [epoch: 8.33 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10166657665952535		[learning rate: 0.00028745]
	Learning Rate: 0.000287451
	LOSS [training: 0.10166657665952535 | validation: 0.10767188595864957]
	TIME [epoch: 8.32 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09395288856477288		[learning rate: 0.00028677]
	Learning Rate: 0.000286773
	LOSS [training: 0.09395288856477288 | validation: 0.11158372835618735]
	TIME [epoch: 8.33 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08645922511953116		[learning rate: 0.0002861]
	Learning Rate: 0.000286097
	LOSS [training: 0.08645922511953116 | validation: 0.10547116951541373]
	TIME [epoch: 8.31 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09674413872779974		[learning rate: 0.00028542]
	Learning Rate: 0.000285422
	LOSS [training: 0.09674413872779974 | validation: 0.10441536209752879]
	TIME [epoch: 8.31 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0948489216735269		[learning rate: 0.00028475]
	Learning Rate: 0.000284749
	LOSS [training: 0.0948489216735269 | validation: 0.10155201760298005]
	TIME [epoch: 8.3 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09441737076962917		[learning rate: 0.00028408]
	Learning Rate: 0.000284077
	LOSS [training: 0.09441737076962917 | validation: 0.14152391449952387]
	TIME [epoch: 8.31 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09821852970104475		[learning rate: 0.00028341]
	Learning Rate: 0.000283407
	LOSS [training: 0.09821852970104475 | validation: 0.11162260900150381]
	TIME [epoch: 8.31 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09776864386295293		[learning rate: 0.00028274]
	Learning Rate: 0.000282738
	LOSS [training: 0.09776864386295293 | validation: 0.11931928852392774]
	TIME [epoch: 8.32 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11271352022339767		[learning rate: 0.00028207]
	Learning Rate: 0.000282071
	LOSS [training: 0.11271352022339767 | validation: 0.10906669242874793]
	TIME [epoch: 8.32 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.092283087229408		[learning rate: 0.00028141]
	Learning Rate: 0.000281406
	LOSS [training: 0.092283087229408 | validation: 0.11815964043465244]
	TIME [epoch: 8.32 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08569994208753957		[learning rate: 0.00028074]
	Learning Rate: 0.000280742
	LOSS [training: 0.08569994208753957 | validation: 0.11616318663034925]
	TIME [epoch: 8.35 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09033152534205417		[learning rate: 0.00028008]
	Learning Rate: 0.00028008
	LOSS [training: 0.09033152534205417 | validation: 0.09901301110424476]
	TIME [epoch: 8.31 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08480918349128926		[learning rate: 0.00027942]
	Learning Rate: 0.000279419
	LOSS [training: 0.08480918349128926 | validation: 0.11362174571727794]
	TIME [epoch: 8.32 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10321255980252224		[learning rate: 0.00027876]
	Learning Rate: 0.00027876
	LOSS [training: 0.10321255980252224 | validation: 0.10905136557563949]
	TIME [epoch: 8.32 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0900416726061779		[learning rate: 0.0002781]
	Learning Rate: 0.000278103
	LOSS [training: 0.0900416726061779 | validation: 0.11221941567341226]
	TIME [epoch: 8.33 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09518559361649633		[learning rate: 0.00027745]
	Learning Rate: 0.000277447
	LOSS [training: 0.09518559361649633 | validation: 0.11700564651808962]
	TIME [epoch: 8.32 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08559700462944328		[learning rate: 0.00027679]
	Learning Rate: 0.000276792
	LOSS [training: 0.08559700462944328 | validation: 0.10256167965371286]
	TIME [epoch: 8.31 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09352958228949775		[learning rate: 0.00027614]
	Learning Rate: 0.000276139
	LOSS [training: 0.09352958228949775 | validation: 0.11325177476434051]
	TIME [epoch: 8.31 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09483938232568279		[learning rate: 0.00027549]
	Learning Rate: 0.000275488
	LOSS [training: 0.09483938232568279 | validation: 0.10954007959000629]
	TIME [epoch: 8.33 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10362246931458041		[learning rate: 0.00027484]
	Learning Rate: 0.000274838
	LOSS [training: 0.10362246931458041 | validation: 0.12190816208587853]
	TIME [epoch: 8.32 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09136084605197578		[learning rate: 0.00027419]
	Learning Rate: 0.00027419
	LOSS [training: 0.09136084605197578 | validation: 0.12483001202877014]
	TIME [epoch: 8.31 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11138797190867744		[learning rate: 0.00027354]
	Learning Rate: 0.000273543
	LOSS [training: 0.11138797190867744 | validation: 0.13837348496495633]
	TIME [epoch: 8.32 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11040664191299124		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.11040664191299124 | validation: 0.10373148358056224]
	TIME [epoch: 8.31 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08680094215078415		[learning rate: 0.00027225]
	Learning Rate: 0.000272254
	LOSS [training: 0.08680094215078415 | validation: 0.10909259857558246]
	TIME [epoch: 8.34 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09381961657380188		[learning rate: 0.00027161]
	Learning Rate: 0.000271612
	LOSS [training: 0.09381961657380188 | validation: 0.12641497352750397]
	TIME [epoch: 8.32 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12365573147680622		[learning rate: 0.00027097]
	Learning Rate: 0.000270971
	LOSS [training: 0.12365573147680622 | validation: 0.1344446718021806]
	TIME [epoch: 8.32 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10129847407264561		[learning rate: 0.00027033]
	Learning Rate: 0.000270332
	LOSS [training: 0.10129847407264561 | validation: 0.09427229843375703]
	TIME [epoch: 8.32 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09072225254227301		[learning rate: 0.00026969]
	Learning Rate: 0.000269694
	LOSS [training: 0.09072225254227301 | validation: 0.11311421873812068]
	TIME [epoch: 8.34 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09660803406385586		[learning rate: 0.00026906]
	Learning Rate: 0.000269058
	LOSS [training: 0.09660803406385586 | validation: 0.11979315583465067]
	TIME [epoch: 8.32 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09469177740862168		[learning rate: 0.00026842]
	Learning Rate: 0.000268423
	LOSS [training: 0.09469177740862168 | validation: 0.10942473944588071]
	TIME [epoch: 8.32 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09280122526378443		[learning rate: 0.00026779]
	Learning Rate: 0.00026779
	LOSS [training: 0.09280122526378443 | validation: 0.12414475319808271]
	TIME [epoch: 8.32 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10440495487169048		[learning rate: 0.00026716]
	Learning Rate: 0.000267159
	LOSS [training: 0.10440495487169048 | validation: 0.10319805216912298]
	TIME [epoch: 8.34 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09118067548643245		[learning rate: 0.00026653]
	Learning Rate: 0.000266528
	LOSS [training: 0.09118067548643245 | validation: 0.10377924319659407]
	TIME [epoch: 8.33 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0918397026877186		[learning rate: 0.0002659]
	Learning Rate: 0.0002659
	LOSS [training: 0.0918397026877186 | validation: 0.11962481574253453]
	TIME [epoch: 8.32 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08314580725196319		[learning rate: 0.00026527]
	Learning Rate: 0.000265273
	LOSS [training: 0.08314580725196319 | validation: 0.1152580562672065]
	TIME [epoch: 8.32 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08627948700494391		[learning rate: 0.00026465]
	Learning Rate: 0.000264647
	LOSS [training: 0.08627948700494391 | validation: 0.08829455334859479]
	TIME [epoch: 8.32 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0795661129704893		[learning rate: 0.00026402]
	Learning Rate: 0.000264022
	LOSS [training: 0.0795661129704893 | validation: 0.09817688472840887]
	TIME [epoch: 8.34 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0852043251406828		[learning rate: 0.0002634]
	Learning Rate: 0.0002634
	LOSS [training: 0.0852043251406828 | validation: 0.11997121322727793]
	TIME [epoch: 8.31 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08283922624236972		[learning rate: 0.00026278]
	Learning Rate: 0.000262778
	LOSS [training: 0.08283922624236972 | validation: 0.09718350835263895]
	TIME [epoch: 8.32 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09421542732863256		[learning rate: 0.00026216]
	Learning Rate: 0.000262159
	LOSS [training: 0.09421542732863256 | validation: 0.12027411098183793]
	TIME [epoch: 8.31 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0894296789718057		[learning rate: 0.00026154]
	Learning Rate: 0.00026154
	LOSS [training: 0.0894296789718057 | validation: 0.10083429141372746]
	TIME [epoch: 8.34 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08327572943232243		[learning rate: 0.00026092]
	Learning Rate: 0.000260923
	LOSS [training: 0.08327572943232243 | validation: 0.10829339971793306]
	TIME [epoch: 8.33 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08681101997736103		[learning rate: 0.00026031]
	Learning Rate: 0.000260308
	LOSS [training: 0.08681101997736103 | validation: 0.1095640827091085]
	TIME [epoch: 8.32 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08506207671983437		[learning rate: 0.00025969]
	Learning Rate: 0.000259694
	LOSS [training: 0.08506207671983437 | validation: 0.09535397670396523]
	TIME [epoch: 8.31 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09616523339802198		[learning rate: 0.00025908]
	Learning Rate: 0.000259081
	LOSS [training: 0.09616523339802198 | validation: 0.11185088127009697]
	TIME [epoch: 8.33 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08491599187023655		[learning rate: 0.00025847]
	Learning Rate: 0.00025847
	LOSS [training: 0.08491599187023655 | validation: 0.11377730736202071]
	TIME [epoch: 8.32 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09111287341016733		[learning rate: 0.00025786]
	Learning Rate: 0.00025786
	LOSS [training: 0.09111287341016733 | validation: 0.13566147137266207]
	TIME [epoch: 8.31 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09378603233890803		[learning rate: 0.00025725]
	Learning Rate: 0.000257252
	LOSS [training: 0.09378603233890803 | validation: 0.0949738579898565]
	TIME [epoch: 8.32 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08656484334111417		[learning rate: 0.00025665]
	Learning Rate: 0.000256645
	LOSS [training: 0.08656484334111417 | validation: 0.08856278680602761]
	TIME [epoch: 8.32 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09034642115859673		[learning rate: 0.00025604]
	Learning Rate: 0.00025604
	LOSS [training: 0.09034642115859673 | validation: 0.10011841335621621]
	TIME [epoch: 8.35 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0900281753255538		[learning rate: 0.00025544]
	Learning Rate: 0.000255436
	LOSS [training: 0.0900281753255538 | validation: 0.09246901723634707]
	TIME [epoch: 8.31 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08892172533311751		[learning rate: 0.00025483]
	Learning Rate: 0.000254833
	LOSS [training: 0.08892172533311751 | validation: 0.09520907726446548]
	TIME [epoch: 8.32 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08461110656490546		[learning rate: 0.00025423]
	Learning Rate: 0.000254232
	LOSS [training: 0.08461110656490546 | validation: 0.09767365667430022]
	TIME [epoch: 8.32 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0953499057093635		[learning rate: 0.00025363]
	Learning Rate: 0.000253633
	LOSS [training: 0.0953499057093635 | validation: 0.11336030834351177]
	TIME [epoch: 8.33 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08460183409542597		[learning rate: 0.00025303]
	Learning Rate: 0.000253034
	LOSS [training: 0.08460183409542597 | validation: 0.11211092348453056]
	TIME [epoch: 8.31 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10262956162113482		[learning rate: 0.00025244]
	Learning Rate: 0.000252437
	LOSS [training: 0.10262956162113482 | validation: 0.1356678709640685]
	TIME [epoch: 8.3 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10920848624125319		[learning rate: 0.00025184]
	Learning Rate: 0.000251842
	LOSS [training: 0.10920848624125319 | validation: 0.10445326377082302]
	TIME [epoch: 8.31 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0834409350842344		[learning rate: 0.00025125]
	Learning Rate: 0.000251248
	LOSS [training: 0.0834409350842344 | validation: 0.11211156339426856]
	TIME [epoch: 8.34 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09580514680778733		[learning rate: 0.00025066]
	Learning Rate: 0.000250655
	LOSS [training: 0.09580514680778733 | validation: 0.10122922410820948]
	TIME [epoch: 8.33 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09364670392437999		[learning rate: 0.00025006]
	Learning Rate: 0.000250064
	LOSS [training: 0.09364670392437999 | validation: 0.11668258121017559]
	TIME [epoch: 8.31 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09001348246917397		[learning rate: 0.00024947]
	Learning Rate: 0.000249474
	LOSS [training: 0.09001348246917397 | validation: 0.11349234918444123]
	TIME [epoch: 8.31 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10689774611706133		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.10689774611706133 | validation: 0.11989065758704313]
	TIME [epoch: 8.32 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10072544305786946		[learning rate: 0.0002483]
	Learning Rate: 0.000248299
	LOSS [training: 0.10072544305786946 | validation: 0.1134564969250697]
	TIME [epoch: 8.35 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0934266010017811		[learning rate: 0.00024771]
	Learning Rate: 0.000247713
	LOSS [training: 0.0934266010017811 | validation: 0.10811075130625658]
	TIME [epoch: 8.32 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09324250719333635		[learning rate: 0.00024713]
	Learning Rate: 0.000247129
	LOSS [training: 0.09324250719333635 | validation: 0.11131112383702693]
	TIME [epoch: 8.33 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.096234162420564		[learning rate: 0.00024655]
	Learning Rate: 0.000246546
	LOSS [training: 0.096234162420564 | validation: 0.11080338932796246]
	TIME [epoch: 8.31 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10430206529099402		[learning rate: 0.00024596]
	Learning Rate: 0.000245964
	LOSS [training: 0.10430206529099402 | validation: 0.1220431295433174]
	TIME [epoch: 8.33 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10858046048849272		[learning rate: 0.00024538]
	Learning Rate: 0.000245384
	LOSS [training: 0.10858046048849272 | validation: 0.11248256252626487]
	TIME [epoch: 8.32 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09791248386635536		[learning rate: 0.00024481]
	Learning Rate: 0.000244805
	LOSS [training: 0.09791248386635536 | validation: 0.153568310818036]
	TIME [epoch: 8.32 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09229127778605349		[learning rate: 0.00024423]
	Learning Rate: 0.000244228
	LOSS [training: 0.09229127778605349 | validation: 0.0922270053678251]
	TIME [epoch: 8.31 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08305341426324173		[learning rate: 0.00024365]
	Learning Rate: 0.000243652
	LOSS [training: 0.08305341426324173 | validation: 0.08568201390767448]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_1623.pth
	Model improved!!!
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08462595024377213		[learning rate: 0.00024308]
	Learning Rate: 0.000243077
	LOSS [training: 0.08462595024377213 | validation: 0.09313194506182736]
	TIME [epoch: 8.33 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09681875781791002		[learning rate: 0.0002425]
	Learning Rate: 0.000242503
	LOSS [training: 0.09681875781791002 | validation: 0.11397842533794261]
	TIME [epoch: 8.32 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09049923571002763		[learning rate: 0.00024193]
	Learning Rate: 0.000241931
	LOSS [training: 0.09049923571002763 | validation: 0.11274297889322982]
	TIME [epoch: 8.32 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10166618004225728		[learning rate: 0.00024136]
	Learning Rate: 0.000241361
	LOSS [training: 0.10166618004225728 | validation: 0.09408193893246114]
	TIME [epoch: 8.32 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08633770567031632		[learning rate: 0.00024079]
	Learning Rate: 0.000240791
	LOSS [training: 0.08633770567031632 | validation: 0.09660792226410211]
	TIME [epoch: 8.34 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08375694384347063		[learning rate: 0.00024022]
	Learning Rate: 0.000240223
	LOSS [training: 0.08375694384347063 | validation: 0.11164501027098198]
	TIME [epoch: 8.32 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11332324618912856		[learning rate: 0.00023966]
	Learning Rate: 0.000239657
	LOSS [training: 0.11332324618912856 | validation: 0.12958470819612883]
	TIME [epoch: 8.32 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10450341893115493		[learning rate: 0.00023909]
	Learning Rate: 0.000239091
	LOSS [training: 0.10450341893115493 | validation: 0.11944700867423562]
	TIME [epoch: 8.32 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10505268410097408		[learning rate: 0.00023853]
	Learning Rate: 0.000238527
	LOSS [training: 0.10505268410097408 | validation: 0.12341003369665388]
	TIME [epoch: 8.34 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09744672911052259		[learning rate: 0.00023796]
	Learning Rate: 0.000237965
	LOSS [training: 0.09744672911052259 | validation: 0.10258540082569834]
	TIME [epoch: 8.32 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08834218310485048		[learning rate: 0.0002374]
	Learning Rate: 0.000237404
	LOSS [training: 0.08834218310485048 | validation: 0.11185118633802764]
	TIME [epoch: 8.32 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09758443217874169		[learning rate: 0.00023684]
	Learning Rate: 0.000236844
	LOSS [training: 0.09758443217874169 | validation: 0.10514891102298146]
	TIME [epoch: 8.32 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09101278458849427		[learning rate: 0.00023628]
	Learning Rate: 0.000236285
	LOSS [training: 0.09101278458849427 | validation: 0.10149969266087078]
	TIME [epoch: 8.34 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09914824683675688		[learning rate: 0.00023573]
	Learning Rate: 0.000235728
	LOSS [training: 0.09914824683675688 | validation: 0.1291357085020479]
	TIME [epoch: 8.33 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11677019955992005		[learning rate: 0.00023517]
	Learning Rate: 0.000235171
	LOSS [training: 0.11677019955992005 | validation: 0.12857789486994986]
	TIME [epoch: 8.32 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12840700252069512		[learning rate: 0.00023462]
	Learning Rate: 0.000234617
	LOSS [training: 0.12840700252069512 | validation: 0.12650114825445363]
	TIME [epoch: 8.32 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09462054360632102		[learning rate: 0.00023406]
	Learning Rate: 0.000234063
	LOSS [training: 0.09462054360632102 | validation: 0.0939703935651445]
	TIME [epoch: 8.32 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08661901497787544		[learning rate: 0.00023351]
	Learning Rate: 0.000233511
	LOSS [training: 0.08661901497787544 | validation: 0.09312951717885226]
	TIME [epoch: 8.34 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07720568619452409		[learning rate: 0.00023296]
	Learning Rate: 0.00023296
	LOSS [training: 0.07720568619452409 | validation: 0.0919889342916067]
	TIME [epoch: 8.32 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08914660940142215		[learning rate: 0.00023241]
	Learning Rate: 0.000232411
	LOSS [training: 0.08914660940142215 | validation: 0.1136647014675492]
	TIME [epoch: 8.31 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09291069434872525		[learning rate: 0.00023186]
	Learning Rate: 0.000231863
	LOSS [training: 0.09291069434872525 | validation: 0.10984771443066516]
	TIME [epoch: 8.32 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0870123380488002		[learning rate: 0.00023132]
	Learning Rate: 0.000231316
	LOSS [training: 0.0870123380488002 | validation: 0.08710720922793977]
	TIME [epoch: 8.34 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08063243113815828		[learning rate: 0.00023077]
	Learning Rate: 0.00023077
	LOSS [training: 0.08063243113815828 | validation: 0.09754456625033098]
	TIME [epoch: 8.32 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08423524100675692		[learning rate: 0.00023023]
	Learning Rate: 0.000230226
	LOSS [training: 0.08423524100675692 | validation: 0.11055308907695563]
	TIME [epoch: 8.32 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08355782247959578		[learning rate: 0.00022968]
	Learning Rate: 0.000229683
	LOSS [training: 0.08355782247959578 | validation: 0.09631860847088575]
	TIME [epoch: 8.32 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09142871866410038		[learning rate: 0.00022914]
	Learning Rate: 0.000229141
	LOSS [training: 0.09142871866410038 | validation: 0.13441723214508683]
	TIME [epoch: 8.34 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10470854840240103		[learning rate: 0.0002286]
	Learning Rate: 0.0002286
	LOSS [training: 0.10470854840240103 | validation: 0.10055831776578808]
	TIME [epoch: 8.33 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1030757259925384		[learning rate: 0.00022806]
	Learning Rate: 0.000228061
	LOSS [training: 0.1030757259925384 | validation: 0.12652865330386864]
	TIME [epoch: 8.32 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08556376627946198		[learning rate: 0.00022752]
	Learning Rate: 0.000227523
	LOSS [training: 0.08556376627946198 | validation: 0.09599143499961926]
	TIME [epoch: 8.32 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08405821958753697		[learning rate: 0.00022699]
	Learning Rate: 0.000226986
	LOSS [training: 0.08405821958753697 | validation: 0.09211739275576497]
	TIME [epoch: 8.32 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07862361048254173		[learning rate: 0.00022645]
	Learning Rate: 0.000226451
	LOSS [training: 0.07862361048254173 | validation: 0.08718474817447383]
	TIME [epoch: 8.34 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08265456498847376		[learning rate: 0.00022592]
	Learning Rate: 0.000225917
	LOSS [training: 0.08265456498847376 | validation: 0.11624834037664589]
	TIME [epoch: 8.32 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08809389231954115		[learning rate: 0.00022538]
	Learning Rate: 0.000225384
	LOSS [training: 0.08809389231954115 | validation: 0.1034878123914672]
	TIME [epoch: 8.32 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10588822751444427		[learning rate: 0.00022485]
	Learning Rate: 0.000224852
	LOSS [training: 0.10588822751444427 | validation: 0.14544812259339407]
	TIME [epoch: 8.32 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10958487353840947		[learning rate: 0.00022432]
	Learning Rate: 0.000224322
	LOSS [training: 0.10958487353840947 | validation: 0.10525409092076465]
	TIME [epoch: 8.34 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08211564352370758		[learning rate: 0.00022379]
	Learning Rate: 0.000223793
	LOSS [training: 0.08211564352370758 | validation: 0.12495085296127502]
	TIME [epoch: 8.32 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08966524235793824		[learning rate: 0.00022326]
	Learning Rate: 0.000223265
	LOSS [training: 0.08966524235793824 | validation: 0.1024182619024663]
	TIME [epoch: 8.32 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08423147585655429		[learning rate: 0.00022274]
	Learning Rate: 0.000222738
	LOSS [training: 0.08423147585655429 | validation: 0.11119951442228286]
	TIME [epoch: 8.32 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08820292052535766		[learning rate: 0.00022221]
	Learning Rate: 0.000222213
	LOSS [training: 0.08820292052535766 | validation: 0.14716374461962922]
	TIME [epoch: 8.34 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10620194160539238		[learning rate: 0.00022169]
	Learning Rate: 0.000221689
	LOSS [training: 0.10620194160539238 | validation: 0.12282801564523385]
	TIME [epoch: 8.33 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11956955988967546		[learning rate: 0.00022117]
	Learning Rate: 0.000221166
	LOSS [training: 0.11956955988967546 | validation: 0.10082699749935413]
	TIME [epoch: 8.32 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09815251435839038		[learning rate: 0.00022064]
	Learning Rate: 0.000220644
	LOSS [training: 0.09815251435839038 | validation: 0.11843437973236115]
	TIME [epoch: 8.32 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10443082020993119		[learning rate: 0.00022012]
	Learning Rate: 0.000220124
	LOSS [training: 0.10443082020993119 | validation: 0.11913038106721899]
	TIME [epoch: 8.32 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10857112687697223		[learning rate: 0.0002196]
	Learning Rate: 0.000219604
	LOSS [training: 0.10857112687697223 | validation: 0.13174013423881703]
	TIME [epoch: 8.35 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11536109022766919		[learning rate: 0.00021909]
	Learning Rate: 0.000219086
	LOSS [training: 0.11536109022766919 | validation: 0.12440803923052937]
	TIME [epoch: 8.32 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1067098360617827		[learning rate: 0.00021857]
	Learning Rate: 0.00021857
	LOSS [training: 0.1067098360617827 | validation: 0.11894451664265958]
	TIME [epoch: 8.32 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09754967957848241		[learning rate: 0.00021805]
	Learning Rate: 0.000218054
	LOSS [training: 0.09754967957848241 | validation: 0.135180393343602]
	TIME [epoch: 8.32 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09932630773983894		[learning rate: 0.00021754]
	Learning Rate: 0.00021754
	LOSS [training: 0.09932630773983894 | validation: 0.09046824690336944]
	TIME [epoch: 8.34 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09743207966096665		[learning rate: 0.00021703]
	Learning Rate: 0.000217027
	LOSS [training: 0.09743207966096665 | validation: 0.11852581785890666]
	TIME [epoch: 8.32 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09673738108591891		[learning rate: 0.00021651]
	Learning Rate: 0.000216515
	LOSS [training: 0.09673738108591891 | validation: 0.12528604939305482]
	TIME [epoch: 8.32 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09739173226104934		[learning rate: 0.000216]
	Learning Rate: 0.000216004
	LOSS [training: 0.09739173226104934 | validation: 0.10910613435714057]
	TIME [epoch: 8.32 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10024234754247305		[learning rate: 0.00021549]
	Learning Rate: 0.000215494
	LOSS [training: 0.10024234754247305 | validation: 0.11813604398946456]
	TIME [epoch: 8.34 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11761065698887511		[learning rate: 0.00021499]
	Learning Rate: 0.000214986
	LOSS [training: 0.11761065698887511 | validation: 0.11389540956418195]
	TIME [epoch: 8.33 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11282841931522758		[learning rate: 0.00021448]
	Learning Rate: 0.000214479
	LOSS [training: 0.11282841931522758 | validation: 0.1088233508775935]
	TIME [epoch: 8.32 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11292784404287974		[learning rate: 0.00021397]
	Learning Rate: 0.000213973
	LOSS [training: 0.11292784404287974 | validation: 0.11187658783478302]
	TIME [epoch: 8.32 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11437586470564087		[learning rate: 0.00021347]
	Learning Rate: 0.000213468
	LOSS [training: 0.11437586470564087 | validation: 0.1449579166006128]
	TIME [epoch: 8.32 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1046604799082663		[learning rate: 0.00021296]
	Learning Rate: 0.000212965
	LOSS [training: 0.1046604799082663 | validation: 0.10811078546521154]
	TIME [epoch: 8.35 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08696870519663921		[learning rate: 0.00021246]
	Learning Rate: 0.000212462
	LOSS [training: 0.08696870519663921 | validation: 0.09808896565223438]
	TIME [epoch: 8.32 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08626732911673543		[learning rate: 0.00021196]
	Learning Rate: 0.000211961
	LOSS [training: 0.08626732911673543 | validation: 0.11183413964232258]
	TIME [epoch: 8.32 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09753891222374753		[learning rate: 0.00021146]
	Learning Rate: 0.000211461
	LOSS [training: 0.09753891222374753 | validation: 0.10940097640216538]
	TIME [epoch: 8.32 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09018770171277177		[learning rate: 0.00021096]
	Learning Rate: 0.000210962
	LOSS [training: 0.09018770171277177 | validation: 0.0875048869818631]
	TIME [epoch: 8.34 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07996079948492876		[learning rate: 0.00021046]
	Learning Rate: 0.000210465
	LOSS [training: 0.07996079948492876 | validation: 0.11123276699019147]
	TIME [epoch: 8.32 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08455113495548232		[learning rate: 0.00020997]
	Learning Rate: 0.000209968
	LOSS [training: 0.08455113495548232 | validation: 0.10303018042425835]
	TIME [epoch: 8.32 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08260103694041428		[learning rate: 0.00020947]
	Learning Rate: 0.000209473
	LOSS [training: 0.08260103694041428 | validation: 0.098888417568879]
	TIME [epoch: 8.32 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07910375259783381		[learning rate: 0.00020898]
	Learning Rate: 0.000208979
	LOSS [training: 0.07910375259783381 | validation: 0.10551510836396759]
	TIME [epoch: 8.34 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08074556914582488		[learning rate: 0.00020849]
	Learning Rate: 0.000208486
	LOSS [training: 0.08074556914582488 | validation: 0.09937575567159074]
	TIME [epoch: 8.33 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08757605140147857		[learning rate: 0.00020799]
	Learning Rate: 0.000207994
	LOSS [training: 0.08757605140147857 | validation: 0.10074784959968662]
	TIME [epoch: 8.32 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08188102479640466		[learning rate: 0.0002075]
	Learning Rate: 0.000207504
	LOSS [training: 0.08188102479640466 | validation: 0.11894089996582274]
	TIME [epoch: 8.32 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08538823107985075		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.08538823107985075 | validation: 0.10635961331693519]
	TIME [epoch: 8.32 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07578291491054975		[learning rate: 0.00020653]
	Learning Rate: 0.000206526
	LOSS [training: 0.07578291491054975 | validation: 0.09401829366829173]
	TIME [epoch: 8.35 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08307035867706772		[learning rate: 0.00020604]
	Learning Rate: 0.000206039
	LOSS [training: 0.08307035867706772 | validation: 0.10397046201788379]
	TIME [epoch: 8.32 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09180337682604985		[learning rate: 0.00020555]
	Learning Rate: 0.000205553
	LOSS [training: 0.09180337682604985 | validation: 0.09459247251749431]
	TIME [epoch: 8.32 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09683145134412538		[learning rate: 0.00020507]
	Learning Rate: 0.000205068
	LOSS [training: 0.09683145134412538 | validation: 0.1244445648097173]
	TIME [epoch: 8.32 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0898032829199082		[learning rate: 0.00020458]
	Learning Rate: 0.000204584
	LOSS [training: 0.0898032829199082 | validation: 0.09689290313555331]
	TIME [epoch: 8.34 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08700231486448903		[learning rate: 0.0002041]
	Learning Rate: 0.000204101
	LOSS [training: 0.08700231486448903 | validation: 0.13253989297384292]
	TIME [epoch: 8.33 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0863525349964932		[learning rate: 0.00020362]
	Learning Rate: 0.00020362
	LOSS [training: 0.0863525349964932 | validation: 0.09932518180358382]
	TIME [epoch: 8.33 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08133133577787817		[learning rate: 0.00020314]
	Learning Rate: 0.00020314
	LOSS [training: 0.08133133577787817 | validation: 0.10221151421250302]
	TIME [epoch: 8.32 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08058968557081375		[learning rate: 0.00020266]
	Learning Rate: 0.000202661
	LOSS [training: 0.08058968557081375 | validation: 0.08562615095707317]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_1701.pth
	Model improved!!!
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07524371137274401		[learning rate: 0.00020218]
	Learning Rate: 0.000202182
	LOSS [training: 0.07524371137274401 | validation: 0.0904117157500534]
	TIME [epoch: 8.33 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07881064352197323		[learning rate: 0.00020171]
	Learning Rate: 0.000201706
	LOSS [training: 0.07881064352197323 | validation: 0.09347414940952357]
	TIME [epoch: 8.32 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08140875574888913		[learning rate: 0.00020123]
	Learning Rate: 0.00020123
	LOSS [training: 0.08140875574888913 | validation: 0.08819849130941124]
	TIME [epoch: 8.32 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08358199591596245		[learning rate: 0.00020076]
	Learning Rate: 0.000200755
	LOSS [training: 0.08358199591596245 | validation: 0.09648647383497772]
	TIME [epoch: 8.33 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07714236603950539		[learning rate: 0.00020028]
	Learning Rate: 0.000200282
	LOSS [training: 0.07714236603950539 | validation: 0.09415836160542349]
	TIME [epoch: 8.34 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08452685560874891		[learning rate: 0.00019981]
	Learning Rate: 0.000199809
	LOSS [training: 0.08452685560874891 | validation: 0.08393583249549003]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_1707.pth
	Model improved!!!
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08176827166647059		[learning rate: 0.00019934]
	Learning Rate: 0.000199338
	LOSS [training: 0.08176827166647059 | validation: 0.09145273154737724]
	TIME [epoch: 8.33 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09054823596236286		[learning rate: 0.00019887]
	Learning Rate: 0.000198868
	LOSS [training: 0.09054823596236286 | validation: 0.1152238182147472]
	TIME [epoch: 8.32 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0893401464621291		[learning rate: 0.0001984]
	Learning Rate: 0.000198398
	LOSS [training: 0.0893401464621291 | validation: 0.09163907905341795]
	TIME [epoch: 8.34 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08548861389690293		[learning rate: 0.00019793]
	Learning Rate: 0.000197931
	LOSS [training: 0.08548861389690293 | validation: 0.08721227249022286]
	TIME [epoch: 8.32 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09860961550456926		[learning rate: 0.00019746]
	Learning Rate: 0.000197464
	LOSS [training: 0.09860961550456926 | validation: 0.10470457484245045]
	TIME [epoch: 8.33 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10175103956457407		[learning rate: 0.000197]
	Learning Rate: 0.000196998
	LOSS [training: 0.10175103956457407 | validation: 0.1208685902181226]
	TIME [epoch: 8.32 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09092885973400075		[learning rate: 0.00019653]
	Learning Rate: 0.000196533
	LOSS [training: 0.09092885973400075 | validation: 0.10837945736357908]
	TIME [epoch: 8.34 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10533332129601154		[learning rate: 0.00019607]
	Learning Rate: 0.00019607
	LOSS [training: 0.10533332129601154 | validation: 0.11722013596911712]
	TIME [epoch: 8.33 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09741962202873365		[learning rate: 0.00019561]
	Learning Rate: 0.000195607
	LOSS [training: 0.09741962202873365 | validation: 0.09855425485355057]
	TIME [epoch: 8.32 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08069704180656996		[learning rate: 0.00019515]
	Learning Rate: 0.000195146
	LOSS [training: 0.08069704180656996 | validation: 0.08730432044557854]
	TIME [epoch: 8.32 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07757861637510002		[learning rate: 0.00019469]
	Learning Rate: 0.000194685
	LOSS [training: 0.07757861637510002 | validation: 0.08443394921128045]
	TIME [epoch: 8.33 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08034573129165046		[learning rate: 0.00019423]
	Learning Rate: 0.000194226
	LOSS [training: 0.08034573129165046 | validation: 0.10885309167667248]
	TIME [epoch: 8.34 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08068384110637228		[learning rate: 0.00019377]
	Learning Rate: 0.000193768
	LOSS [training: 0.08068384110637228 | validation: 0.09595637753416357]
	TIME [epoch: 8.32 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08925053339929354		[learning rate: 0.00019331]
	Learning Rate: 0.000193311
	LOSS [training: 0.08925053339929354 | validation: 0.1123586056446178]
	TIME [epoch: 8.32 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09418528857955477		[learning rate: 0.00019285]
	Learning Rate: 0.000192855
	LOSS [training: 0.09418528857955477 | validation: 0.09549054054194878]
	TIME [epoch: 8.32 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08510301327191802		[learning rate: 0.0001924]
	Learning Rate: 0.0001924
	LOSS [training: 0.08510301327191802 | validation: 0.08462196942260086]
	TIME [epoch: 8.34 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07994414226165789		[learning rate: 0.00019195]
	Learning Rate: 0.000191946
	LOSS [training: 0.07994414226165789 | validation: 0.09882901201680461]
	TIME [epoch: 8.32 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08537812147528083		[learning rate: 0.00019149]
	Learning Rate: 0.000191493
	LOSS [training: 0.08537812147528083 | validation: 0.09744877586382536]
	TIME [epoch: 8.32 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10949218035940045		[learning rate: 0.00019104]
	Learning Rate: 0.000191042
	LOSS [training: 0.10949218035940045 | validation: 0.09839069225769598]
	TIME [epoch: 8.32 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0780223959541376		[learning rate: 0.00019059]
	Learning Rate: 0.000190591
	LOSS [training: 0.0780223959541376 | validation: 0.10512827824446415]
	TIME [epoch: 8.35 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09265810193995613		[learning rate: 0.00019014]
	Learning Rate: 0.000190141
	LOSS [training: 0.09265810193995613 | validation: 0.11010191328477223]
	TIME [epoch: 8.33 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08990743165798398		[learning rate: 0.00018969]
	Learning Rate: 0.000189693
	LOSS [training: 0.08990743165798398 | validation: 0.11366734757535468]
	TIME [epoch: 8.32 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08859539361929904		[learning rate: 0.00018925]
	Learning Rate: 0.000189245
	LOSS [training: 0.08859539361929904 | validation: 0.1223600609960897]
	TIME [epoch: 8.32 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09624047439448163		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.09624047439448163 | validation: 0.09557053889611622]
	TIME [epoch: 8.33 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08789580047260948		[learning rate: 0.00018835]
	Learning Rate: 0.000188354
	LOSS [training: 0.08789580047260948 | validation: 0.09283261439424657]
	TIME [epoch: 8.34 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08273866296004502		[learning rate: 0.00018791]
	Learning Rate: 0.000187909
	LOSS [training: 0.08273866296004502 | validation: 0.10325804488761062]
	TIME [epoch: 8.32 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07836843397552129		[learning rate: 0.00018747]
	Learning Rate: 0.000187466
	LOSS [training: 0.07836843397552129 | validation: 0.11295901748631249]
	TIME [epoch: 8.33 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09858768019748196		[learning rate: 0.00018702]
	Learning Rate: 0.000187024
	LOSS [training: 0.09858768019748196 | validation: 0.11272353703608994]
	TIME [epoch: 8.32 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10069311977366406		[learning rate: 0.00018658]
	Learning Rate: 0.000186583
	LOSS [training: 0.10069311977366406 | validation: 0.12322509568801117]
	TIME [epoch: 8.34 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09017595168164612		[learning rate: 0.00018614]
	Learning Rate: 0.000186143
	LOSS [training: 0.09017595168164612 | validation: 0.10818166320999571]
	TIME [epoch: 8.32 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11749238010307654		[learning rate: 0.0001857]
	Learning Rate: 0.000185704
	LOSS [training: 0.11749238010307654 | validation: 0.10439368693359735]
	TIME [epoch: 8.32 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09460813179528535		[learning rate: 0.00018527]
	Learning Rate: 0.000185266
	LOSS [training: 0.09460813179528535 | validation: 0.13405382090132464]
	TIME [epoch: 8.32 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1054296489944759		[learning rate: 0.00018483]
	Learning Rate: 0.000184829
	LOSS [training: 0.1054296489944759 | validation: 0.11568214549879818]
	TIME [epoch: 8.35 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10982360187157345		[learning rate: 0.00018439]
	Learning Rate: 0.000184393
	LOSS [training: 0.10982360187157345 | validation: 0.12130827817557348]
	TIME [epoch: 8.33 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1120946553134223		[learning rate: 0.00018396]
	Learning Rate: 0.000183958
	LOSS [training: 0.1120946553134223 | validation: 0.10807529142903138]
	TIME [epoch: 8.32 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10506229036999344		[learning rate: 0.00018352]
	Learning Rate: 0.000183524
	LOSS [training: 0.10506229036999344 | validation: 0.11579228981279807]
	TIME [epoch: 8.32 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10069885494350786		[learning rate: 0.00018309]
	Learning Rate: 0.000183091
	LOSS [training: 0.10069885494350786 | validation: 0.10896631114613053]
	TIME [epoch: 8.33 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09618324305826857		[learning rate: 0.00018266]
	Learning Rate: 0.000182659
	LOSS [training: 0.09618324305826857 | validation: 0.10929318537052311]
	TIME [epoch: 8.34 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0900801968933868		[learning rate: 0.00018223]
	Learning Rate: 0.000182228
	LOSS [training: 0.0900801968933868 | validation: 0.10797218888074267]
	TIME [epoch: 8.32 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0903839431846621		[learning rate: 0.0001818]
	Learning Rate: 0.000181798
	LOSS [training: 0.0903839431846621 | validation: 0.08959771948759307]
	TIME [epoch: 8.33 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07431698574524083		[learning rate: 0.00018137]
	Learning Rate: 0.000181369
	LOSS [training: 0.07431698574524083 | validation: 0.08547987037598645]
	TIME [epoch: 8.32 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08279311919362399		[learning rate: 0.00018094]
	Learning Rate: 0.000180942
	LOSS [training: 0.08279311919362399 | validation: 0.10052961568633012]
	TIME [epoch: 8.34 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07312079539058203		[learning rate: 0.00018051]
	Learning Rate: 0.000180515
	LOSS [training: 0.07312079539058203 | validation: 0.09159126550664415]
	TIME [epoch: 8.32 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0800349621610927		[learning rate: 0.00018009]
	Learning Rate: 0.000180089
	LOSS [training: 0.0800349621610927 | validation: 0.09067250795138822]
	TIME [epoch: 8.32 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08343381986630449		[learning rate: 0.00017966]
	Learning Rate: 0.000179664
	LOSS [training: 0.08343381986630449 | validation: 0.07932848774746865]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_1752.pth
	Model improved!!!
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08017019603773344		[learning rate: 0.00017924]
	Learning Rate: 0.00017924
	LOSS [training: 0.08017019603773344 | validation: 0.11421802270903818]
	TIME [epoch: 8.35 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08919176016365234		[learning rate: 0.00017882]
	Learning Rate: 0.000178818
	LOSS [training: 0.08919176016365234 | validation: 0.1058571965459496]
	TIME [epoch: 8.33 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0864559151117649		[learning rate: 0.0001784]
	Learning Rate: 0.000178396
	LOSS [training: 0.0864559151117649 | validation: 0.10412823053488648]
	TIME [epoch: 8.32 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08937402326509149		[learning rate: 0.00017797]
	Learning Rate: 0.000177975
	LOSS [training: 0.08937402326509149 | validation: 0.10339274234893216]
	TIME [epoch: 8.33 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08392660453710102		[learning rate: 0.00017756]
	Learning Rate: 0.000177555
	LOSS [training: 0.08392660453710102 | validation: 0.09410084951320838]
	TIME [epoch: 8.34 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08223990979037814		[learning rate: 0.00017714]
	Learning Rate: 0.000177136
	LOSS [training: 0.08223990979037814 | validation: 0.10495956601562748]
	TIME [epoch: 8.33 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0858107370853322		[learning rate: 0.00017672]
	Learning Rate: 0.000176718
	LOSS [training: 0.0858107370853322 | validation: 0.10555610812608379]
	TIME [epoch: 8.32 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08801848657122573		[learning rate: 0.0001763]
	Learning Rate: 0.000176302
	LOSS [training: 0.08801848657122573 | validation: 0.0949043803959915]
	TIME [epoch: 8.32 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07676876610446987		[learning rate: 0.00017589]
	Learning Rate: 0.000175886
	LOSS [training: 0.07676876610446987 | validation: 0.09431844396985085]
	TIME [epoch: 8.32 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0800274017559644		[learning rate: 0.00017547]
	Learning Rate: 0.000175471
	LOSS [training: 0.0800274017559644 | validation: 0.09332048951740121]
	TIME [epoch: 8.35 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08064656495417652		[learning rate: 0.00017506]
	Learning Rate: 0.000175057
	LOSS [training: 0.08064656495417652 | validation: 0.08973283075464648]
	TIME [epoch: 8.32 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07987375853808958		[learning rate: 0.00017464]
	Learning Rate: 0.000174644
	LOSS [training: 0.07987375853808958 | validation: 0.08684265044876244]
	TIME [epoch: 8.32 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07789961334465348		[learning rate: 0.00017423]
	Learning Rate: 0.000174232
	LOSS [training: 0.07789961334465348 | validation: 0.08380408564287783]
	TIME [epoch: 8.32 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07420851013642242		[learning rate: 0.00017382]
	Learning Rate: 0.000173821
	LOSS [training: 0.07420851013642242 | validation: 0.10505834345166863]
	TIME [epoch: 8.34 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07525609014925858		[learning rate: 0.00017341]
	Learning Rate: 0.000173411
	LOSS [training: 0.07525609014925858 | validation: 0.09138321829898927]
	TIME [epoch: 8.33 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08016199487137143		[learning rate: 0.000173]
	Learning Rate: 0.000173002
	LOSS [training: 0.08016199487137143 | validation: 0.08786916961532658]
	TIME [epoch: 8.32 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07904183214337371		[learning rate: 0.00017259]
	Learning Rate: 0.000172594
	LOSS [training: 0.07904183214337371 | validation: 0.10511294438744079]
	TIME [epoch: 8.32 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08763728876788633		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.08763728876788633 | validation: 0.09347190308562812]
	TIME [epoch: 8.34 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07753611235389901		[learning rate: 0.00017178]
	Learning Rate: 0.000171781
	LOSS [training: 0.07753611235389901 | validation: 0.1007641171685462]
	TIME [epoch: 8.33 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07414135472725215		[learning rate: 0.00017138]
	Learning Rate: 0.000171375
	LOSS [training: 0.07414135472725215 | validation: 0.1000224586725921]
	TIME [epoch: 8.33 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08671427132049915		[learning rate: 0.00017097]
	Learning Rate: 0.000170971
	LOSS [training: 0.08671427132049915 | validation: 0.10508654137867623]
	TIME [epoch: 8.33 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07408178796813844		[learning rate: 0.00017057]
	Learning Rate: 0.000170568
	LOSS [training: 0.07408178796813844 | validation: 0.09066519066356035]
	TIME [epoch: 8.33 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07059573670201819		[learning rate: 0.00017017]
	Learning Rate: 0.000170166
	LOSS [training: 0.07059573670201819 | validation: 0.09120016901139077]
	TIME [epoch: 8.35 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07671906584366771		[learning rate: 0.00016976]
	Learning Rate: 0.000169764
	LOSS [training: 0.07671906584366771 | validation: 0.09792476311914844]
	TIME [epoch: 8.33 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07459663770137812		[learning rate: 0.00016936]
	Learning Rate: 0.000169364
	LOSS [training: 0.07459663770137812 | validation: 0.08739168296356845]
	TIME [epoch: 8.33 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08279009875233967		[learning rate: 0.00016896]
	Learning Rate: 0.000168964
	LOSS [training: 0.08279009875233967 | validation: 0.10086928663309211]
	TIME [epoch: 8.33 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08172423797152514		[learning rate: 0.00016857]
	Learning Rate: 0.000168566
	LOSS [training: 0.08172423797152514 | validation: 0.09156006513079204]
	TIME [epoch: 8.35 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0731192477833387		[learning rate: 0.00016817]
	Learning Rate: 0.000168168
	LOSS [training: 0.0731192477833387 | validation: 0.08645531242841019]
	TIME [epoch: 8.33 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07289008263093569		[learning rate: 0.00016777]
	Learning Rate: 0.000167771
	LOSS [training: 0.07289008263093569 | validation: 0.08985018794371996]
	TIME [epoch: 8.33 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07813567647826888		[learning rate: 0.00016738]
	Learning Rate: 0.000167376
	LOSS [training: 0.07813567647826888 | validation: 0.09595614650102555]
	TIME [epoch: 8.32 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08507254399400735		[learning rate: 0.00016698]
	Learning Rate: 0.000166981
	LOSS [training: 0.08507254399400735 | validation: 0.09151449530775344]
	TIME [epoch: 8.34 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08763726674794069		[learning rate: 0.00016659]
	Learning Rate: 0.000166587
	LOSS [training: 0.08763726674794069 | validation: 0.1070758903216075]
	TIME [epoch: 8.34 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09709101098448372		[learning rate: 0.00016619]
	Learning Rate: 0.000166194
	LOSS [training: 0.09709101098448372 | validation: 0.1071671461534239]
	TIME [epoch: 8.33 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08448541607274414		[learning rate: 0.0001658]
	Learning Rate: 0.000165802
	LOSS [training: 0.08448541607274414 | validation: 0.09345903555806884]
	TIME [epoch: 8.32 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07687829093505275		[learning rate: 0.00016541]
	Learning Rate: 0.000165411
	LOSS [training: 0.07687829093505275 | validation: 0.11498582775185812]
	TIME [epoch: 8.32 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07671664305527243		[learning rate: 0.00016502]
	Learning Rate: 0.000165021
	LOSS [training: 0.07671664305527243 | validation: 0.0978446225274763]
	TIME [epoch: 8.35 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07501469003315303		[learning rate: 0.00016463]
	Learning Rate: 0.000164631
	LOSS [training: 0.07501469003315303 | validation: 0.09754834649506855]
	TIME [epoch: 8.32 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08062748072270405		[learning rate: 0.00016424]
	Learning Rate: 0.000164243
	LOSS [training: 0.08062748072270405 | validation: 0.10536876515125562]
	TIME [epoch: 8.32 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0761350436609832		[learning rate: 0.00016386]
	Learning Rate: 0.000163856
	LOSS [training: 0.0761350436609832 | validation: 0.08919804214593935]
	TIME [epoch: 8.32 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07730172374257968		[learning rate: 0.00016347]
	Learning Rate: 0.000163469
	LOSS [training: 0.07730172374257968 | validation: 0.08777990266237026]
	TIME [epoch: 8.35 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07943847605352512		[learning rate: 0.00016308]
	Learning Rate: 0.000163084
	LOSS [training: 0.07943847605352512 | validation: 0.09328477639908814]
	TIME [epoch: 8.33 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08904355832230712		[learning rate: 0.0001627]
	Learning Rate: 0.000162699
	LOSS [training: 0.08904355832230712 | validation: 0.09695041765556253]
	TIME [epoch: 8.32 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07660665927744778		[learning rate: 0.00016232]
	Learning Rate: 0.000162315
	LOSS [training: 0.07660665927744778 | validation: 0.08777220957764859]
	TIME [epoch: 8.32 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0762064172075222		[learning rate: 0.00016193]
	Learning Rate: 0.000161932
	LOSS [training: 0.0762064172075222 | validation: 0.09536399724961891]
	TIME [epoch: 8.34 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07813326941614913		[learning rate: 0.00016155]
	Learning Rate: 0.00016155
	LOSS [training: 0.07813326941614913 | validation: 0.08687244678980563]
	TIME [epoch: 8.33 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07809472811014281		[learning rate: 0.00016117]
	Learning Rate: 0.000161169
	LOSS [training: 0.07809472811014281 | validation: 0.09803400193053886]
	TIME [epoch: 8.33 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09666936597263953		[learning rate: 0.00016079]
	Learning Rate: 0.000160789
	LOSS [training: 0.09666936597263953 | validation: 0.11567512108782026]
	TIME [epoch: 8.32 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08923405506723632		[learning rate: 0.00016041]
	Learning Rate: 0.00016041
	LOSS [training: 0.08923405506723632 | validation: 0.10516809137451333]
	TIME [epoch: 8.32 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09316586889678073		[learning rate: 0.00016003]
	Learning Rate: 0.000160031
	LOSS [training: 0.09316586889678073 | validation: 0.10678419353982263]
	TIME [epoch: 8.35 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09837660537351624		[learning rate: 0.00015965]
	Learning Rate: 0.000159654
	LOSS [training: 0.09837660537351624 | validation: 0.11521562570690261]
	TIME [epoch: 8.32 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09538807264920379		[learning rate: 0.00015928]
	Learning Rate: 0.000159277
	LOSS [training: 0.09538807264920379 | validation: 0.10800959780658656]
	TIME [epoch: 8.32 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09143434352522832		[learning rate: 0.0001589]
	Learning Rate: 0.000158902
	LOSS [training: 0.09143434352522832 | validation: 0.11301391625613205]
	TIME [epoch: 8.33 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10585305992431251		[learning rate: 0.00015853]
	Learning Rate: 0.000158527
	LOSS [training: 0.10585305992431251 | validation: 0.13183632798184824]
	TIME [epoch: 8.35 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11862746890670947		[learning rate: 0.00015815]
	Learning Rate: 0.000158153
	LOSS [training: 0.11862746890670947 | validation: 0.12391951695112371]
	TIME [epoch: 8.33 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10618837812936086		[learning rate: 0.00015778]
	Learning Rate: 0.00015778
	LOSS [training: 0.10618837812936086 | validation: 0.11720237751849868]
	TIME [epoch: 8.32 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10233327947167896		[learning rate: 0.00015741]
	Learning Rate: 0.000157408
	LOSS [training: 0.10233327947167896 | validation: 0.09761124660386566]
	TIME [epoch: 8.32 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09090739300923548		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.09090739300923548 | validation: 0.10054557266487463]
	TIME [epoch: 8.34 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08809082309463136		[learning rate: 0.00015667]
	Learning Rate: 0.000156666
	LOSS [training: 0.08809082309463136 | validation: 0.12317031942535095]
	TIME [epoch: 8.33 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0863758977545933		[learning rate: 0.0001563]
	Learning Rate: 0.000156296
	LOSS [training: 0.0863758977545933 | validation: 0.107379618638506]
	TIME [epoch: 8.32 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08749776394187296		[learning rate: 0.00015593]
	Learning Rate: 0.000155928
	LOSS [training: 0.08749776394187296 | validation: 0.1136765690352515]
	TIME [epoch: 8.32 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08501967466814345		[learning rate: 0.00015556]
	Learning Rate: 0.00015556
	LOSS [training: 0.08501967466814345 | validation: 0.10625445622999302]
	TIME [epoch: 8.33 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08608530843382742		[learning rate: 0.00015519]
	Learning Rate: 0.000155193
	LOSS [training: 0.08608530843382742 | validation: 0.10856601941063215]
	TIME [epoch: 8.35 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08311774714238794		[learning rate: 0.00015483]
	Learning Rate: 0.000154827
	LOSS [training: 0.08311774714238794 | validation: 0.0940983494556065]
	TIME [epoch: 8.33 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07423388374523769		[learning rate: 0.00015446]
	Learning Rate: 0.000154462
	LOSS [training: 0.07423388374523769 | validation: 0.09720892953200364]
	TIME [epoch: 8.32 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07475749893954559		[learning rate: 0.0001541]
	Learning Rate: 0.000154097
	LOSS [training: 0.07475749893954559 | validation: 0.09925307399200144]
	TIME [epoch: 8.33 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08276812130407346		[learning rate: 0.00015373]
	Learning Rate: 0.000153734
	LOSS [training: 0.08276812130407346 | validation: 0.09577509408128779]
	TIME [epoch: 8.34 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07812335548051842		[learning rate: 0.00015337]
	Learning Rate: 0.000153371
	LOSS [training: 0.07812335548051842 | validation: 0.09357177969211737]
	TIME [epoch: 8.33 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08005975485545305		[learning rate: 0.00015301]
	Learning Rate: 0.000153009
	LOSS [training: 0.08005975485545305 | validation: 0.11540211293444784]
	TIME [epoch: 8.32 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07837149197277064		[learning rate: 0.00015265]
	Learning Rate: 0.000152648
	LOSS [training: 0.07837149197277064 | validation: 0.10261137296330422]
	TIME [epoch: 8.32 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0993848201571551		[learning rate: 0.00015229]
	Learning Rate: 0.000152288
	LOSS [training: 0.0993848201571551 | validation: 0.09601197437730707]
	TIME [epoch: 8.34 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08843346033361459		[learning rate: 0.00015193]
	Learning Rate: 0.000151929
	LOSS [training: 0.08843346033361459 | validation: 0.1076483519392987]
	TIME [epoch: 8.33 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08275979447933808		[learning rate: 0.00015157]
	Learning Rate: 0.000151571
	LOSS [training: 0.08275979447933808 | validation: 0.11072566870129578]
	TIME [epoch: 8.33 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09205332901443833		[learning rate: 0.00015121]
	Learning Rate: 0.000151213
	LOSS [training: 0.09205332901443833 | validation: 0.1095719916238253]
	TIME [epoch: 8.33 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08674027704747425		[learning rate: 0.00015086]
	Learning Rate: 0.000150857
	LOSS [training: 0.08674027704747425 | validation: 0.10526666842173732]
	TIME [epoch: 8.33 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08352916774727803		[learning rate: 0.0001505]
	Learning Rate: 0.000150501
	LOSS [training: 0.08352916774727803 | validation: 0.09650986583390608]
	TIME [epoch: 8.36 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07579788606936357		[learning rate: 0.00015015]
	Learning Rate: 0.000150146
	LOSS [training: 0.07579788606936357 | validation: 0.08295722539529146]
	TIME [epoch: 8.33 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07658911821804029		[learning rate: 0.00014979]
	Learning Rate: 0.000149791
	LOSS [training: 0.07658911821804029 | validation: 0.1034931165132654]
	TIME [epoch: 8.33 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08826193630639038		[learning rate: 0.00014944]
	Learning Rate: 0.000149438
	LOSS [training: 0.08826193630639038 | validation: 0.09076858648925841]
	TIME [epoch: 8.33 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08851819409030609		[learning rate: 0.00014909]
	Learning Rate: 0.000149086
	LOSS [training: 0.08851819409030609 | validation: 0.10237508273661289]
	TIME [epoch: 8.34 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08750531305656777		[learning rate: 0.00014873]
	Learning Rate: 0.000148734
	LOSS [training: 0.08750531305656777 | validation: 0.08376737050906807]
	TIME [epoch: 8.32 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07367043601461566		[learning rate: 0.00014838]
	Learning Rate: 0.000148383
	LOSS [training: 0.07367043601461566 | validation: 0.0904935866179255]
	TIME [epoch: 8.33 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08418020549742249		[learning rate: 0.00014803]
	Learning Rate: 0.000148033
	LOSS [training: 0.08418020549742249 | validation: 0.08238557135118205]
	TIME [epoch: 8.33 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07713077648532216		[learning rate: 0.00014768]
	Learning Rate: 0.000147684
	LOSS [training: 0.07713077648532216 | validation: 0.08906081705789387]
	TIME [epoch: 8.34 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08073649361411471		[learning rate: 0.00014734]
	Learning Rate: 0.000147336
	LOSS [training: 0.08073649361411471 | validation: 0.10294776957209234]
	TIME [epoch: 8.34 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08427010170401429		[learning rate: 0.00014699]
	Learning Rate: 0.000146988
	LOSS [training: 0.08427010170401429 | validation: 0.09876446325399316]
	TIME [epoch: 8.33 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08502993630643123		[learning rate: 0.00014664]
	Learning Rate: 0.000146641
	LOSS [training: 0.08502993630643123 | validation: 0.09086285749347146]
	TIME [epoch: 8.33 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0962356199568885		[learning rate: 0.0001463]
	Learning Rate: 0.000146295
	LOSS [training: 0.0962356199568885 | validation: 0.1030535111330982]
	TIME [epoch: 8.33 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09334211879772111		[learning rate: 0.00014595]
	Learning Rate: 0.00014595
	LOSS [training: 0.09334211879772111 | validation: 0.10936285923898731]
	TIME [epoch: 8.36 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09594328096850809		[learning rate: 0.00014561]
	Learning Rate: 0.000145606
	LOSS [training: 0.09594328096850809 | validation: 0.1175587827922977]
	TIME [epoch: 8.33 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08329696554810531		[learning rate: 0.00014526]
	Learning Rate: 0.000145263
	LOSS [training: 0.08329696554810531 | validation: 0.09580887569600247]
	TIME [epoch: 8.33 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09068715442429603		[learning rate: 0.00014492]
	Learning Rate: 0.00014492
	LOSS [training: 0.09068715442429603 | validation: 0.11557410744611729]
	TIME [epoch: 8.33 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09284959018316978		[learning rate: 0.00014458]
	Learning Rate: 0.000144578
	LOSS [training: 0.09284959018316978 | validation: 0.10102008280477467]
	TIME [epoch: 8.36 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08625234733498209		[learning rate: 0.00014424]
	Learning Rate: 0.000144237
	LOSS [training: 0.08625234733498209 | validation: 0.09860509551104016]
	TIME [epoch: 8.33 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08563751698167452		[learning rate: 0.0001439]
	Learning Rate: 0.000143897
	LOSS [training: 0.08563751698167452 | validation: 0.0991574667671711]
	TIME [epoch: 8.33 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07587133528156104		[learning rate: 0.00014356]
	Learning Rate: 0.000143557
	LOSS [training: 0.07587133528156104 | validation: 0.099670083366238]
	TIME [epoch: 8.33 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08450837494574799		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.08450837494574799 | validation: 0.10141903067240489]
	TIME [epoch: 8.34 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08953144994345083		[learning rate: 0.00014288]
	Learning Rate: 0.000142881
	LOSS [training: 0.08953144994345083 | validation: 0.09836413576239827]
	TIME [epoch: 8.34 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08118197483833282		[learning rate: 0.00014254]
	Learning Rate: 0.000142544
	LOSS [training: 0.08118197483833282 | validation: 0.11619694371385797]
	TIME [epoch: 8.33 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08503327045594895		[learning rate: 0.00014221]
	Learning Rate: 0.000142208
	LOSS [training: 0.08503327045594895 | validation: 0.09070303576962818]
	TIME [epoch: 8.34 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0777648932199568		[learning rate: 0.00014187]
	Learning Rate: 0.000141872
	LOSS [training: 0.0777648932199568 | validation: 0.09617338945875306]
	TIME [epoch: 8.33 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07937638039804754		[learning rate: 0.00014154]
	Learning Rate: 0.000141538
	LOSS [training: 0.07937638039804754 | validation: 0.094434924939038]
	TIME [epoch: 8.36 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07914652803910617		[learning rate: 0.0001412]
	Learning Rate: 0.000141204
	LOSS [training: 0.07914652803910617 | validation: 0.0938425855172142]
	TIME [epoch: 8.33 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07822099950225488		[learning rate: 0.00014087]
	Learning Rate: 0.000140871
	LOSS [training: 0.07822099950225488 | validation: 0.09389157068878101]
	TIME [epoch: 8.33 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.081909739536465		[learning rate: 0.00014054]
	Learning Rate: 0.000140538
	LOSS [training: 0.081909739536465 | validation: 0.11092223184420803]
	TIME [epoch: 8.33 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08091856215027388		[learning rate: 0.00014021]
	Learning Rate: 0.000140207
	LOSS [training: 0.08091856215027388 | validation: 0.11687561915784389]
	TIME [epoch: 8.36 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08223263380441219		[learning rate: 0.00013988]
	Learning Rate: 0.000139876
	LOSS [training: 0.08223263380441219 | validation: 0.11448681378057549]
	TIME [epoch: 8.34 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09169072120380051		[learning rate: 0.00013955]
	Learning Rate: 0.000139546
	LOSS [training: 0.09169072120380051 | validation: 0.1004361815617208]
	TIME [epoch: 8.33 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0764697824648578		[learning rate: 0.00013922]
	Learning Rate: 0.000139217
	LOSS [training: 0.0764697824648578 | validation: 0.10887954209780673]
	TIME [epoch: 8.33 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08348310412743572		[learning rate: 0.00013889]
	Learning Rate: 0.000138889
	LOSS [training: 0.08348310412743572 | validation: 0.09267420479769015]
	TIME [epoch: 8.35 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08996662769954737		[learning rate: 0.00013856]
	Learning Rate: 0.000138561
	LOSS [training: 0.08996662769954737 | validation: 0.10489651497919503]
	TIME [epoch: 8.34 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08398977272156727		[learning rate: 0.00013823]
	Learning Rate: 0.000138234
	LOSS [training: 0.08398977272156727 | validation: 0.10394649367314418]
	TIME [epoch: 8.33 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08295445316640712		[learning rate: 0.00013791]
	Learning Rate: 0.000137908
	LOSS [training: 0.08295445316640712 | validation: 0.10974996443666615]
	TIME [epoch: 8.33 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09473447580886414		[learning rate: 0.00013758]
	Learning Rate: 0.000137583
	LOSS [training: 0.09473447580886414 | validation: 0.10534129696278868]
	TIME [epoch: 8.34 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08013833702146965		[learning rate: 0.00013726]
	Learning Rate: 0.000137258
	LOSS [training: 0.08013833702146965 | validation: 0.10395458278641401]
	TIME [epoch: 8.35 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07020945139655597		[learning rate: 0.00013693]
	Learning Rate: 0.000136934
	LOSS [training: 0.07020945139655597 | validation: 0.09989444694456184]
	TIME [epoch: 8.33 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07442367363834243		[learning rate: 0.00013661]
	Learning Rate: 0.000136611
	LOSS [training: 0.07442367363834243 | validation: 0.08672131417451864]
	TIME [epoch: 8.33 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07069369050267213		[learning rate: 0.00013629]
	Learning Rate: 0.000136289
	LOSS [training: 0.07069369050267213 | validation: 0.08388479473444496]
	TIME [epoch: 8.33 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06951974013858932		[learning rate: 0.00013597]
	Learning Rate: 0.000135968
	LOSS [training: 0.06951974013858932 | validation: 0.09591409897600456]
	TIME [epoch: 8.35 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.078751050321718		[learning rate: 0.00013565]
	Learning Rate: 0.000135647
	LOSS [training: 0.078751050321718 | validation: 0.08712047510845666]
	TIME [epoch: 8.33 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07513178014331308		[learning rate: 0.00013533]
	Learning Rate: 0.000135327
	LOSS [training: 0.07513178014331308 | validation: 0.08956594380878305]
	TIME [epoch: 8.33 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06835064582122584		[learning rate: 0.00013501]
	Learning Rate: 0.000135008
	LOSS [training: 0.06835064582122584 | validation: 0.10242136640086769]
	TIME [epoch: 8.33 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08489483935585293		[learning rate: 0.00013469]
	Learning Rate: 0.000134689
	LOSS [training: 0.08489483935585293 | validation: 0.09106556533993446]
	TIME [epoch: 8.34 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08143537937133555		[learning rate: 0.00013437]
	Learning Rate: 0.000134372
	LOSS [training: 0.08143537937133555 | validation: 0.10223723196999399]
	TIME [epoch: 8.33 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07932519446687433		[learning rate: 0.00013405]
	Learning Rate: 0.000134055
	LOSS [training: 0.07932519446687433 | validation: 0.11577293507428087]
	TIME [epoch: 8.33 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07501738006586584		[learning rate: 0.00013374]
	Learning Rate: 0.000133738
	LOSS [training: 0.07501738006586584 | validation: 0.10080230141072274]
	TIME [epoch: 8.33 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07187304793655125		[learning rate: 0.00013342]
	Learning Rate: 0.000133423
	LOSS [training: 0.07187304793655125 | validation: 0.10402170320261328]
	TIME [epoch: 8.33 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07796809508611743		[learning rate: 0.00013311]
	Learning Rate: 0.000133108
	LOSS [training: 0.07796809508611743 | validation: 0.10817835662345243]
	TIME [epoch: 8.35 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08290015298698372		[learning rate: 0.00013279]
	Learning Rate: 0.000132794
	LOSS [training: 0.08290015298698372 | validation: 0.09665175338582985]
	TIME [epoch: 8.33 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07443477289107572		[learning rate: 0.00013248]
	Learning Rate: 0.000132481
	LOSS [training: 0.07443477289107572 | validation: 0.08444841640127856]
	TIME [epoch: 8.33 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07647192111464683		[learning rate: 0.00013217]
	Learning Rate: 0.000132169
	LOSS [training: 0.07647192111464683 | validation: 0.10628765613200739]
	TIME [epoch: 8.32 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07148566473013265		[learning rate: 0.00013186]
	Learning Rate: 0.000131857
	LOSS [training: 0.07148566473013265 | validation: 0.09476084599399959]
	TIME [epoch: 8.35 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07407178025125163		[learning rate: 0.00013155]
	Learning Rate: 0.000131546
	LOSS [training: 0.07407178025125163 | validation: 0.09139802845301288]
	TIME [epoch: 8.33 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0779163643310074		[learning rate: 0.00013124]
	Learning Rate: 0.000131235
	LOSS [training: 0.0779163643310074 | validation: 0.1049789642303641]
	TIME [epoch: 8.33 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07484956007719991		[learning rate: 0.00013093]
	Learning Rate: 0.000130926
	LOSS [training: 0.07484956007719991 | validation: 0.08981814548887918]
	TIME [epoch: 8.32 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08651677805204697		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.08651677805204697 | validation: 0.1294843844552963]
	TIME [epoch: 8.34 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11663378097709613		[learning rate: 0.00013031]
	Learning Rate: 0.000130309
	LOSS [training: 0.11663378097709613 | validation: 0.09571591363588691]
	TIME [epoch: 8.34 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0737761617235941		[learning rate: 0.00013]
	Learning Rate: 0.000130002
	LOSS [training: 0.0737761617235941 | validation: 0.09571418794774683]
	TIME [epoch: 8.32 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07185063082881085		[learning rate: 0.00012969]
	Learning Rate: 0.000129695
	LOSS [training: 0.07185063082881085 | validation: 0.09049523272100188]
	TIME [epoch: 8.33 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08096866667172713		[learning rate: 0.00012939]
	Learning Rate: 0.000129389
	LOSS [training: 0.08096866667172713 | validation: 0.09888218908686458]
	TIME [epoch: 8.33 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07994898744062776		[learning rate: 0.00012908]
	Learning Rate: 0.000129084
	LOSS [training: 0.07994898744062776 | validation: 0.10415938379572316]
	TIME [epoch: 8.35 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08956556492591772		[learning rate: 0.00012878]
	Learning Rate: 0.000128779
	LOSS [training: 0.08956556492591772 | validation: 0.10059015407458652]
	TIME [epoch: 8.33 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08314704529042055		[learning rate: 0.00012848]
	Learning Rate: 0.000128476
	LOSS [training: 0.08314704529042055 | validation: 0.10065536395157534]
	TIME [epoch: 8.33 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07131690825663525		[learning rate: 0.00012817]
	Learning Rate: 0.000128172
	LOSS [training: 0.07131690825663525 | validation: 0.09841662661206793]
	TIME [epoch: 8.32 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07289601092442692		[learning rate: 0.00012787]
	Learning Rate: 0.00012787
	LOSS [training: 0.07289601092442692 | validation: 0.09764071114746042]
	TIME [epoch: 8.34 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07747596276678466		[learning rate: 0.00012757]
	Learning Rate: 0.000127569
	LOSS [training: 0.07747596276678466 | validation: 0.08762560590928133]
	TIME [epoch: 8.33 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07344702617974239		[learning rate: 0.00012727]
	Learning Rate: 0.000127268
	LOSS [training: 0.07344702617974239 | validation: 0.09576545434109814]
	TIME [epoch: 8.33 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07798377870970355		[learning rate: 0.00012697]
	Learning Rate: 0.000126967
	LOSS [training: 0.07798377870970355 | validation: 0.09308589329448429]
	TIME [epoch: 8.33 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07057588861817954		[learning rate: 0.00012667]
	Learning Rate: 0.000126668
	LOSS [training: 0.07057588861817954 | validation: 0.13580537802104964]
	TIME [epoch: 8.35 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07664384884650585		[learning rate: 0.00012637]
	Learning Rate: 0.000126369
	LOSS [training: 0.07664384884650585 | validation: 0.09418813451928268]
	TIME [epoch: 8.33 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06877076392966022		[learning rate: 0.00012607]
	Learning Rate: 0.000126071
	LOSS [training: 0.06877076392966022 | validation: 0.09508280262013422]
	TIME [epoch: 8.33 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07518262832248973		[learning rate: 0.00012577]
	Learning Rate: 0.000125774
	LOSS [training: 0.07518262832248973 | validation: 0.10095871773261911]
	TIME [epoch: 8.33 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07228929256859849		[learning rate: 0.00012548]
	Learning Rate: 0.000125477
	LOSS [training: 0.07228929256859849 | validation: 0.10237766745212412]
	TIME [epoch: 8.33 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07565026026674866		[learning rate: 0.00012518]
	Learning Rate: 0.000125181
	LOSS [training: 0.07565026026674866 | validation: 0.10052893713974533]
	TIME [epoch: 8.34 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09223108531847089		[learning rate: 0.00012489]
	Learning Rate: 0.000124886
	LOSS [training: 0.09223108531847089 | validation: 0.10290505096168096]
	TIME [epoch: 8.33 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07361516340849222		[learning rate: 0.00012459]
	Learning Rate: 0.000124591
	LOSS [training: 0.07361516340849222 | validation: 0.10701669215421013]
	TIME [epoch: 8.33 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07574322801593027		[learning rate: 0.0001243]
	Learning Rate: 0.000124297
	LOSS [training: 0.07574322801593027 | validation: 0.0988349253871866]
	TIME [epoch: 8.33 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07387411352427016		[learning rate: 0.000124]
	Learning Rate: 0.000124004
	LOSS [training: 0.07387411352427016 | validation: 0.10660498060795526]
	TIME [epoch: 8.34 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06987383104712044		[learning rate: 0.00012371]
	Learning Rate: 0.000123712
	LOSS [training: 0.06987383104712044 | validation: 0.1107128679954584]
	TIME [epoch: 8.33 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07450759972778968		[learning rate: 0.00012342]
	Learning Rate: 0.00012342
	LOSS [training: 0.07450759972778968 | validation: 0.09651514990855667]
	TIME [epoch: 8.33 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07091851153185243		[learning rate: 0.00012313]
	Learning Rate: 0.000123129
	LOSS [training: 0.07091851153185243 | validation: 0.09020600687549582]
	TIME [epoch: 8.33 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08516328683445078		[learning rate: 0.00012284]
	Learning Rate: 0.000122838
	LOSS [training: 0.08516328683445078 | validation: 0.12007969250083417]
	TIME [epoch: 8.35 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08374694830624009		[learning rate: 0.00012255]
	Learning Rate: 0.000122548
	LOSS [training: 0.08374694830624009 | validation: 0.09706128460099556]
	TIME [epoch: 8.34 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0766658309258513		[learning rate: 0.00012226]
	Learning Rate: 0.000122259
	LOSS [training: 0.0766658309258513 | validation: 0.10225029929582993]
	TIME [epoch: 8.33 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08301278977254233		[learning rate: 0.00012197]
	Learning Rate: 0.000121971
	LOSS [training: 0.08301278977254233 | validation: 0.10129385298965754]
	TIME [epoch: 8.33 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08589501845111139		[learning rate: 0.00012168]
	Learning Rate: 0.000121683
	LOSS [training: 0.08589501845111139 | validation: 0.09206787382955905]
	TIME [epoch: 8.34 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07553760085137143		[learning rate: 0.0001214]
	Learning Rate: 0.000121396
	LOSS [training: 0.07553760085137143 | validation: 0.09927779752724597]
	TIME [epoch: 8.34 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08039751325770812		[learning rate: 0.00012111]
	Learning Rate: 0.00012111
	LOSS [training: 0.08039751325770812 | validation: 0.09605596661317121]
	TIME [epoch: 8.33 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08927167016789367		[learning rate: 0.00012082]
	Learning Rate: 0.000120824
	LOSS [training: 0.08927167016789367 | validation: 0.09846832615447973]
	TIME [epoch: 8.33 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07095888752141374		[learning rate: 0.00012054]
	Learning Rate: 0.000120539
	LOSS [training: 0.07095888752141374 | validation: 0.116062207765209]
	TIME [epoch: 8.33 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08191682384642697		[learning rate: 0.00012025]
	Learning Rate: 0.000120255
	LOSS [training: 0.08191682384642697 | validation: 0.08425277925444377]
	TIME [epoch: 8.35 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06918851539536428		[learning rate: 0.00011997]
	Learning Rate: 0.000119971
	LOSS [training: 0.06918851539536428 | validation: 0.09206963783927147]
	TIME [epoch: 8.33 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07559175400120319		[learning rate: 0.00011969]
	Learning Rate: 0.000119688
	LOSS [training: 0.07559175400120319 | validation: 0.09870031642545035]
	TIME [epoch: 8.33 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07592195523989956		[learning rate: 0.00011941]
	Learning Rate: 0.000119406
	LOSS [training: 0.07592195523989956 | validation: 0.10107545955203359]
	TIME [epoch: 8.33 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07066467978267868		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.07066467978267868 | validation: 0.0915869630113004]
	TIME [epoch: 8.35 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07059458826220817		[learning rate: 0.00011884]
	Learning Rate: 0.000118843
	LOSS [training: 0.07059458826220817 | validation: 0.09863993914213438]
	TIME [epoch: 8.33 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07421972307110328		[learning rate: 0.00011856]
	Learning Rate: 0.000118563
	LOSS [training: 0.07421972307110328 | validation: 0.08682259933892672]
	TIME [epoch: 8.33 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07631178527863154		[learning rate: 0.00011828]
	Learning Rate: 0.000118283
	LOSS [training: 0.07631178527863154 | validation: 0.10247070204870493]
	TIME [epoch: 8.33 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0848478317636524		[learning rate: 0.000118]
	Learning Rate: 0.000118004
	LOSS [training: 0.0848478317636524 | validation: 0.10331799788654211]
	TIME [epoch: 8.34 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0820299311845851		[learning rate: 0.00011773]
	Learning Rate: 0.000117726
	LOSS [training: 0.0820299311845851 | validation: 0.09409004101275]
	TIME [epoch: 8.35 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0792833771320613		[learning rate: 0.00011745]
	Learning Rate: 0.000117448
	LOSS [training: 0.0792833771320613 | validation: 0.08396740124123081]
	TIME [epoch: 8.33 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0762687648000276		[learning rate: 0.00011717]
	Learning Rate: 0.000117171
	LOSS [training: 0.0762687648000276 | validation: 0.10336728209864895]
	TIME [epoch: 8.33 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07120112494052713		[learning rate: 0.00011689]
	Learning Rate: 0.000116895
	LOSS [training: 0.07120112494052713 | validation: 0.09071756507396572]
	TIME [epoch: 8.33 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07055465677257303		[learning rate: 0.00011662]
	Learning Rate: 0.000116619
	LOSS [training: 0.07055465677257303 | validation: 0.0877812029749628]
	TIME [epoch: 8.35 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07276614738601167		[learning rate: 0.00011634]
	Learning Rate: 0.000116344
	LOSS [training: 0.07276614738601167 | validation: 0.09300347976042693]
	TIME [epoch: 8.33 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0693472215496737		[learning rate: 0.00011607]
	Learning Rate: 0.000116069
	LOSS [training: 0.0693472215496737 | validation: 0.0957900802258575]
	TIME [epoch: 8.33 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08070869240919047		[learning rate: 0.0001158]
	Learning Rate: 0.000115796
	LOSS [training: 0.08070869240919047 | validation: 0.1048506356090536]
	TIME [epoch: 8.33 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07546672482237075		[learning rate: 0.00011552]
	Learning Rate: 0.000115523
	LOSS [training: 0.07546672482237075 | validation: 0.08560601298329149]
	TIME [epoch: 8.35 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07513269295376841		[learning rate: 0.00011525]
	Learning Rate: 0.00011525
	LOSS [training: 0.07513269295376841 | validation: 0.0909273388773506]
	TIME [epoch: 8.33 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0743472881286403		[learning rate: 0.00011498]
	Learning Rate: 0.000114978
	LOSS [training: 0.0743472881286403 | validation: 0.09214955142810385]
	TIME [epoch: 8.33 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06573921517841927		[learning rate: 0.00011471]
	Learning Rate: 0.000114707
	LOSS [training: 0.06573921517841927 | validation: 0.09533218294329743]
	TIME [epoch: 8.33 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07407861387037214		[learning rate: 0.00011444]
	Learning Rate: 0.000114436
	LOSS [training: 0.07407861387037214 | validation: 0.09157066187662984]
	TIME [epoch: 8.34 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08099724338757194		[learning rate: 0.00011417]
	Learning Rate: 0.000114166
	LOSS [training: 0.08099724338757194 | validation: 0.1009060002684824]
	TIME [epoch: 8.34 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0700367109055892		[learning rate: 0.0001139]
	Learning Rate: 0.000113897
	LOSS [training: 0.0700367109055892 | validation: 0.09576580379856649]
	TIME [epoch: 8.32 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07483843157909345		[learning rate: 0.00011363]
	Learning Rate: 0.000113628
	LOSS [training: 0.07483843157909345 | validation: 0.09994979391637249]
	TIME [epoch: 8.33 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07678099602357417		[learning rate: 0.00011336]
	Learning Rate: 0.00011336
	LOSS [training: 0.07678099602357417 | validation: 0.10363433773789107]
	TIME [epoch: 8.33 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07756680184968011		[learning rate: 0.00011309]
	Learning Rate: 0.000113093
	LOSS [training: 0.07756680184968011 | validation: 0.0965022839171982]
	TIME [epoch: 8.35 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07913742826306579		[learning rate: 0.00011283]
	Learning Rate: 0.000112826
	LOSS [training: 0.07913742826306579 | validation: 0.10028199584205587]
	TIME [epoch: 8.33 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08079151818274401		[learning rate: 0.00011256]
	Learning Rate: 0.00011256
	LOSS [training: 0.08079151818274401 | validation: 0.10698677469102258]
	TIME [epoch: 8.33 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07915541878272933		[learning rate: 0.00011229]
	Learning Rate: 0.000112295
	LOSS [training: 0.07915541878272933 | validation: 0.0960995725645383]
	TIME [epoch: 8.33 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06575229950128975		[learning rate: 0.00011203]
	Learning Rate: 0.00011203
	LOSS [training: 0.06575229950128975 | validation: 0.09614068359659181]
	TIME [epoch: 8.35 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07365842077558707		[learning rate: 0.00011177]
	Learning Rate: 0.000111765
	LOSS [training: 0.07365842077558707 | validation: 0.09646933394777422]
	TIME [epoch: 8.33 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07119518345592675		[learning rate: 0.0001115]
	Learning Rate: 0.000111502
	LOSS [training: 0.07119518345592675 | validation: 0.09052520489758653]
	TIME [epoch: 8.33 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.072645475687021		[learning rate: 0.00011124]
	Learning Rate: 0.000111239
	LOSS [training: 0.072645475687021 | validation: 0.10358049028411578]
	TIME [epoch: 8.33 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08059360097931456		[learning rate: 0.00011098]
	Learning Rate: 0.000110976
	LOSS [training: 0.08059360097931456 | validation: 0.11125202410968328]
	TIME [epoch: 8.33 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08805122893762245		[learning rate: 0.00011071]
	Learning Rate: 0.000110715
	LOSS [training: 0.08805122893762245 | validation: 0.09906279857098957]
	TIME [epoch: 8.35 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07901740229678036		[learning rate: 0.00011045]
	Learning Rate: 0.000110453
	LOSS [training: 0.07901740229678036 | validation: 0.07743825364245248]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r1_20240219_184940/states/model_tr_study3_1958.pth
	Model improved!!!
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07770326232570235		[learning rate: 0.00011019]
	Learning Rate: 0.000110193
	LOSS [training: 0.07770326232570235 | validation: 0.09372552508415022]
	TIME [epoch: 8.33 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07214145033153103		[learning rate: 0.00010993]
	Learning Rate: 0.000109933
	LOSS [training: 0.07214145033153103 | validation: 0.1013822248048846]
	TIME [epoch: 8.33 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07319937626090622		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.07319937626090622 | validation: 0.10230390874331376]
	TIME [epoch: 8.35 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07997651641001575		[learning rate: 0.00010942]
	Learning Rate: 0.000109415
	LOSS [training: 0.07997651641001575 | validation: 0.0852498981214958]
	TIME [epoch: 8.33 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08506140226079952		[learning rate: 0.00010916]
	Learning Rate: 0.000109157
	LOSS [training: 0.08506140226079952 | validation: 0.093552838549155]
	TIME [epoch: 8.33 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0739116265435836		[learning rate: 0.0001089]
	Learning Rate: 0.000108899
	LOSS [training: 0.0739116265435836 | validation: 0.09384844801610726]
	TIME [epoch: 8.33 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07525834077679674		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.07525834077679674 | validation: 0.09778640418485895]
	TIME [epoch: 8.35 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07894975091100416		[learning rate: 0.00010839]
	Learning Rate: 0.000108386
	LOSS [training: 0.07894975091100416 | validation: 0.08691117688131456]
	TIME [epoch: 8.33 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07287359848698553		[learning rate: 0.00010813]
	Learning Rate: 0.000108131
	LOSS [training: 0.07287359848698553 | validation: 0.08453571918209332]
	TIME [epoch: 8.33 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07808023702026441		[learning rate: 0.00010788]
	Learning Rate: 0.000107876
	LOSS [training: 0.07808023702026441 | validation: 0.10537599600066255]
	TIME [epoch: 8.33 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07385199917098616		[learning rate: 0.00010762]
	Learning Rate: 0.000107621
	LOSS [training: 0.07385199917098616 | validation: 0.09483396870386976]
	TIME [epoch: 8.35 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07282001768271132		[learning rate: 0.00010737]
	Learning Rate: 0.000107367
	LOSS [training: 0.07282001768271132 | validation: 0.08619881474144309]
	TIME [epoch: 8.34 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07211962857105382		[learning rate: 0.00010711]
	Learning Rate: 0.000107114
	LOSS [training: 0.07211962857105382 | validation: 0.10211614605401792]
	TIME [epoch: 8.33 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07871946129290008		[learning rate: 0.00010686]
	Learning Rate: 0.000106861
	LOSS [training: 0.07871946129290008 | validation: 0.10895500040127232]
	TIME [epoch: 8.33 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08354361960862941		[learning rate: 0.00010661]
	Learning Rate: 0.000106609
	LOSS [training: 0.08354361960862941 | validation: 0.10683553434868125]
	TIME [epoch: 8.33 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0795520552060148		[learning rate: 0.00010636]
	Learning Rate: 0.000106358
	LOSS [training: 0.0795520552060148 | validation: 0.10122343584926467]
	TIME [epoch: 8.35 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08075546982627259		[learning rate: 0.00010611]
	Learning Rate: 0.000106107
	LOSS [training: 0.08075546982627259 | validation: 0.1236436792035864]
	TIME [epoch: 8.33 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09018810665832173		[learning rate: 0.00010586]
	Learning Rate: 0.000105857
	LOSS [training: 0.09018810665832173 | validation: 0.11486660030624307]
	TIME [epoch: 8.33 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09459997642244065		[learning rate: 0.00010561]
	Learning Rate: 0.000105607
	LOSS [training: 0.09459997642244065 | validation: 0.10951004740978576]
	TIME [epoch: 8.33 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08609462445423602		[learning rate: 0.00010536]
	Learning Rate: 0.000105358
	LOSS [training: 0.08609462445423602 | validation: 0.10129450535260145]
	TIME [epoch: 8.34 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07786491671078408		[learning rate: 0.00010511]
	Learning Rate: 0.000105109
	LOSS [training: 0.07786491671078408 | validation: 0.09754936728326541]
	TIME [epoch: 8.33 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07405869992347529		[learning rate: 0.00010486]
	Learning Rate: 0.000104861
	LOSS [training: 0.07405869992347529 | validation: 0.10531556291832646]
	TIME [epoch: 8.33 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07408319047997164		[learning rate: 0.00010461]
	Learning Rate: 0.000104614
	LOSS [training: 0.07408319047997164 | validation: 0.09829364137527614]
	TIME [epoch: 8.33 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07347199541996283		[learning rate: 0.00010437]
	Learning Rate: 0.000104367
	LOSS [training: 0.07347199541996283 | validation: 0.09991122803539752]
	TIME [epoch: 8.35 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07567333350894688		[learning rate: 0.00010412]
	Learning Rate: 0.000104121
	LOSS [training: 0.07567333350894688 | validation: 0.09853722706637283]
	TIME [epoch: 8.34 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08064605463734403		[learning rate: 0.00010388]
	Learning Rate: 0.000103875
	LOSS [training: 0.08064605463734403 | validation: 0.09439138215293834]
	TIME [epoch: 8.33 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07363362775508207		[learning rate: 0.00010363]
	Learning Rate: 0.00010363
	LOSS [training: 0.07363362775508207 | validation: 0.11684418054504989]
	TIME [epoch: 8.33 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08404646991283968		[learning rate: 0.00010339]
	Learning Rate: 0.000103386
	LOSS [training: 0.08404646991283968 | validation: 0.10231954321518222]
	TIME [epoch: 8.33 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07609580066612963		[learning rate: 0.00010314]
	Learning Rate: 0.000103142
	LOSS [training: 0.07609580066612963 | validation: 0.10151270055059405]
	TIME [epoch: 8.35 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08095019036798239		[learning rate: 0.0001029]
	Learning Rate: 0.000102899
	LOSS [training: 0.08095019036798239 | validation: 0.1016733199178236]
	TIME [epoch: 8.33 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08308953455617993		[learning rate: 0.00010266]
	Learning Rate: 0.000102656
	LOSS [training: 0.08308953455617993 | validation: 0.10330237587210392]
	TIME [epoch: 8.33 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07659527054263171		[learning rate: 0.00010241]
	Learning Rate: 0.000102414
	LOSS [training: 0.07659527054263171 | validation: 0.09709404384063759]
	TIME [epoch: 8.32 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07473670908993388		[learning rate: 0.00010217]
	Learning Rate: 0.000102172
	LOSS [training: 0.07473670908993388 | validation: 0.10339065254345166]
	TIME [epoch: 8.35 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07738305978766183		[learning rate: 0.00010193]
	Learning Rate: 0.000101931
	LOSS [training: 0.07738305978766183 | validation: 0.10410767457627637]
	TIME [epoch: 8.33 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06994584898677714		[learning rate: 0.00010169]
	Learning Rate: 0.000101691
	LOSS [training: 0.06994584898677714 | validation: 0.09595539607908271]
	TIME [epoch: 8.33 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07121617540737098		[learning rate: 0.00010145]
	Learning Rate: 0.000101451
	LOSS [training: 0.07121617540737098 | validation: 0.08785691515295954]
	TIME [epoch: 8.32 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07692530447115156		[learning rate: 0.00010121]
	Learning Rate: 0.000101212
	LOSS [training: 0.07692530447115156 | validation: 0.10643310051856174]
	TIME [epoch: 8.35 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07340998946369423		[learning rate: 0.00010097]
	Learning Rate: 0.000100973
	LOSS [training: 0.07340998946369423 | validation: 0.09107253038579648]
	TIME [epoch: 8.33 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07359967106653902		[learning rate: 0.00010073]
	Learning Rate: 0.000100735
	LOSS [training: 0.07359967106653902 | validation: 0.08300684443207354]
	TIME [epoch: 8.32 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06786885495564801		[learning rate: 0.0001005]
	Learning Rate: 0.000100497
	LOSS [training: 0.06786885495564801 | validation: 0.09746307766726622]
	TIME [epoch: 8.33 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07241734207901852		[learning rate: 0.00010026]
	Learning Rate: 0.00010026
	LOSS [training: 0.07241734207901852 | validation: 0.0881855893193556]
	TIME [epoch: 8.33 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07109100543659898		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.07109100543659898 | validation: 0.0852665189506999]
	TIME [epoch: 8.36 sec]
Finished training in 16828.986 seconds.
