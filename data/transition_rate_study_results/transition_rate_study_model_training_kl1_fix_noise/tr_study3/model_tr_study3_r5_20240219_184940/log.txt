Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r5', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4138833610

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.79898019791408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.79898019791408 | validation: 9.709863049241683]
	TIME [epoch: 79.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.152338794558773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.152338794558773 | validation: 9.577876679349169]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.406856383115464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.406856383115464 | validation: 8.681557307096924]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.34614090086005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.34614090086005 | validation: 8.263009712599981]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.408553551608474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.408553551608474 | validation: 8.388703250955846]
	TIME [epoch: 8.53 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.363753837431185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.363753837431185 | validation: 8.451334411180094]
	TIME [epoch: 8.53 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.413679374160118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.413679374160118 | validation: 7.870380545256162]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.576982422884443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.576982422884443 | validation: 8.26521586547572]
	TIME [epoch: 8.54 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.861805911419987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.861805911419987 | validation: 7.4239239908814865]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.858575833021308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.858575833021308 | validation: 9.237886833560099]
	TIME [epoch: 8.53 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.427942155217348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.427942155217348 | validation: 8.501106654405707]
	TIME [epoch: 8.52 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.471400736498971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.471400736498971 | validation: 7.0704604331129985]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.372298667076414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.372298667076414 | validation: 6.901541166803661]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.445788965267893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.445788965267893 | validation: 9.922609055231186]
	TIME [epoch: 8.52 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.26101483194349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.26101483194349 | validation: 7.331254059833012]
	TIME [epoch: 8.53 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.682725186333576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.682725186333576 | validation: 7.301189721982537]
	TIME [epoch: 8.54 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.178371944276551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.178371944276551 | validation: 7.082798662637956]
	TIME [epoch: 8.52 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.930092204048224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.930092204048224 | validation: 8.731889035162027]
	TIME [epoch: 8.52 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.145699674074155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.145699674074155 | validation: 10.644900466896228]
	TIME [epoch: 8.51 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.806231914584782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.806231914584782 | validation: 8.019190908559768]
	TIME [epoch: 8.53 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.487501334240195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.487501334240195 | validation: 10.148305318844931]
	TIME [epoch: 8.52 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.417802806738916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.417802806738916 | validation: 7.688330184486222]
	TIME [epoch: 8.52 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.284889935746103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.284889935746103 | validation: 11.543019957730628]
	TIME [epoch: 8.51 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.780620306638184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.780620306638184 | validation: 8.539858991522276]
	TIME [epoch: 8.52 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.985577823351802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.985577823351802 | validation: 7.909017253748207]
	TIME [epoch: 8.53 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.665741132879944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.665741132879944 | validation: 7.535050501520478]
	TIME [epoch: 8.51 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.421239634941459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.421239634941459 | validation: 8.520936844187524]
	TIME [epoch: 8.51 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.245234798996457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.245234798996457 | validation: 9.018980653418264]
	TIME [epoch: 8.52 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.877583303618957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.877583303618957 | validation: 7.775992636180354]
	TIME [epoch: 8.54 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.309691956871456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.309691956871456 | validation: 9.966772299955137]
	TIME [epoch: 8.51 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.309902480879582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.309902480879582 | validation: 7.5500627903417215]
	TIME [epoch: 8.51 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.831957218300312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.831957218300312 | validation: 7.891036074978723]
	TIME [epoch: 8.52 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.061378408291187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.061378408291187 | validation: 8.678338508216301]
	TIME [epoch: 8.54 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.081621936631942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.081621936631942 | validation: 8.02831660143938]
	TIME [epoch: 8.52 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.99021212459908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.99021212459908 | validation: 8.913768915960693]
	TIME [epoch: 8.51 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.827871691564842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.827871691564842 | validation: 8.373900816697706]
	TIME [epoch: 8.51 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.642046103561812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.642046103561812 | validation: 7.099303274852408]
	TIME [epoch: 8.53 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.746827062979949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.746827062979949 | validation: 8.14223031487587]
	TIME [epoch: 8.52 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.030136835270069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.030136835270069 | validation: 7.6011228486469715]
	TIME [epoch: 8.51 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.738476043077884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.738476043077884 | validation: 6.8452655111367395]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.338129872695025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.338129872695025 | validation: 7.077438980281633]
	TIME [epoch: 8.53 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.425693243455179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.425693243455179 | validation: 7.804733757127753]
	TIME [epoch: 8.54 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.415194010445639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.415194010445639 | validation: 7.6648795814180595]
	TIME [epoch: 8.52 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.534703560588258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.534703560588258 | validation: 7.62758999345882]
	TIME [epoch: 8.52 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.712307346734191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.712307346734191 | validation: 7.261761776674418]
	TIME [epoch: 8.52 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.506056667086085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.506056667086085 | validation: 6.952540464533442]
	TIME [epoch: 8.54 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.076407987278182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.076407987278182 | validation: 6.584631045203091]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.428334890743353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.428334890743353 | validation: 7.909849805958831]
	TIME [epoch: 8.52 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.157500939018812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.157500939018812 | validation: 7.864163181537647]
	TIME [epoch: 8.52 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.001743138112994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.001743138112994 | validation: 6.322117061092588]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.424797517215838		[learning rate: 0.0099788]
	Learning Rate: 0.00997877
	LOSS [training: 7.424797517215838 | validation: 8.814860544288539]
	TIME [epoch: 8.52 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.67598401157193		[learning rate: 0.0099552]
	Learning Rate: 0.00995523
	LOSS [training: 6.67598401157193 | validation: 6.7272170219035825]
	TIME [epoch: 8.52 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.480296863671451		[learning rate: 0.0099317]
	Learning Rate: 0.00993175
	LOSS [training: 6.480296863671451 | validation: 7.550612333679982]
	TIME [epoch: 8.52 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.118883429889538		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 7.118883429889538 | validation: 6.601017051026114]
	TIME [epoch: 8.55 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.187671162776134		[learning rate: 0.0098849]
	Learning Rate: 0.00988495
	LOSS [training: 6.187671162776134 | validation: 6.441046281906045]
	TIME [epoch: 8.52 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.9067278928242		[learning rate: 0.0098616]
	Learning Rate: 0.00986163
	LOSS [training: 8.9067278928242 | validation: 9.408104749167993]
	TIME [epoch: 8.52 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.929063099446774		[learning rate: 0.0098384]
	Learning Rate: 0.00983837
	LOSS [training: 8.929063099446774 | validation: 7.630120413800509]
	TIME [epoch: 8.52 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.59757327209566		[learning rate: 0.0098152]
	Learning Rate: 0.00981516
	LOSS [training: 6.59757327209566 | validation: 6.259932962561798]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.455664400349126		[learning rate: 0.009792]
	Learning Rate: 0.00979201
	LOSS [training: 6.455664400349126 | validation: 6.20445088868966]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.399570177308961		[learning rate: 0.0097689]
	Learning Rate: 0.00976891
	LOSS [training: 6.399570177308961 | validation: 5.256216748862684]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.155444160322164		[learning rate: 0.0097459]
	Learning Rate: 0.00974587
	LOSS [training: 6.155444160322164 | validation: 7.472231555982013]
	TIME [epoch: 8.52 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.860225977162807		[learning rate: 0.0097229]
	Learning Rate: 0.00972288
	LOSS [training: 6.860225977162807 | validation: 5.313148856074451]
	TIME [epoch: 8.53 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.280722476924648		[learning rate: 0.0096999]
	Learning Rate: 0.00969994
	LOSS [training: 8.280722476924648 | validation: 10.210520037485244]
	TIME [epoch: 8.52 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.290539293331086		[learning rate: 0.0096771]
	Learning Rate: 0.00967706
	LOSS [training: 9.290539293331086 | validation: 9.047337682488735]
	TIME [epoch: 8.51 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.581088350229255		[learning rate: 0.0096542]
	Learning Rate: 0.00965424
	LOSS [training: 8.581088350229255 | validation: 8.47313362818389]
	TIME [epoch: 8.51 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.7167486117094315		[learning rate: 0.0096315]
	Learning Rate: 0.00963146
	LOSS [training: 6.7167486117094315 | validation: 5.915907155581522]
	TIME [epoch: 8.51 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.574580462277387		[learning rate: 0.0096087]
	Learning Rate: 0.00960874
	LOSS [training: 8.574580462277387 | validation: 8.575726295824257]
	TIME [epoch: 8.54 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.821230678018397		[learning rate: 0.0095861]
	Learning Rate: 0.00958608
	LOSS [training: 8.821230678018397 | validation: 8.455293103636434]
	TIME [epoch: 8.51 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.343691987428092		[learning rate: 0.0095635]
	Learning Rate: 0.00956347
	LOSS [training: 7.343691987428092 | validation: 6.479109144267816]
	TIME [epoch: 8.51 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.355080164975336		[learning rate: 0.0095409]
	Learning Rate: 0.00954091
	LOSS [training: 7.355080164975336 | validation: 11.086199980959297]
	TIME [epoch: 8.51 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.567598835713317		[learning rate: 0.0095184]
	Learning Rate: 0.0095184
	LOSS [training: 8.567598835713317 | validation: 6.863043966175056]
	TIME [epoch: 8.54 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.326132609838325		[learning rate: 0.009496]
	Learning Rate: 0.00949595
	LOSS [training: 7.326132609838325 | validation: 6.528786073261583]
	TIME [epoch: 8.52 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.1888110810798		[learning rate: 0.0094736]
	Learning Rate: 0.00947355
	LOSS [training: 7.1888110810798 | validation: 6.302714575151279]
	TIME [epoch: 8.51 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.377939478129001		[learning rate: 0.0094512]
	Learning Rate: 0.0094512
	LOSS [training: 6.377939478129001 | validation: 5.644040685414131]
	TIME [epoch: 8.51 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.804107376799701		[learning rate: 0.0094289]
	Learning Rate: 0.00942891
	LOSS [training: 6.804107376799701 | validation: 8.810600125081645]
	TIME [epoch: 8.53 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.6714941374889065		[learning rate: 0.0094067]
	Learning Rate: 0.00940667
	LOSS [training: 6.6714941374889065 | validation: 5.770040344108855]
	TIME [epoch: 8.51 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.877190240721516		[learning rate: 0.0093845]
	Learning Rate: 0.00938448
	LOSS [training: 5.877190240721516 | validation: 6.0851879843443]
	TIME [epoch: 8.51 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.574236638519897		[learning rate: 0.0093623]
	Learning Rate: 0.00936234
	LOSS [training: 7.574236638519897 | validation: 8.645831060839036]
	TIME [epoch: 8.52 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.383777977911168		[learning rate: 0.0093403]
	Learning Rate: 0.00934026
	LOSS [training: 6.383777977911168 | validation: 5.652444609926022]
	TIME [epoch: 8.53 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.583023737697024		[learning rate: 0.0093182]
	Learning Rate: 0.00931823
	LOSS [training: 7.583023737697024 | validation: 10.286585670422696]
	TIME [epoch: 8.53 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.654467121758698		[learning rate: 0.0092962]
	Learning Rate: 0.00929625
	LOSS [training: 8.654467121758698 | validation: 6.663506785829765]
	TIME [epoch: 8.51 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.496284173551717		[learning rate: 0.0092743]
	Learning Rate: 0.00927432
	LOSS [training: 7.496284173551717 | validation: 8.881321686190207]
	TIME [epoch: 8.51 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.345239597584081		[learning rate: 0.0092524]
	Learning Rate: 0.00925244
	LOSS [training: 7.345239597584081 | validation: 5.593715491846346]
	TIME [epoch: 8.51 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.341220795203046		[learning rate: 0.0092306]
	Learning Rate: 0.00923062
	LOSS [training: 6.341220795203046 | validation: 6.876177655484558]
	TIME [epoch: 8.54 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.132349769310705		[learning rate: 0.0092088]
	Learning Rate: 0.00920884
	LOSS [training: 7.132349769310705 | validation: 5.956493540231736]
	TIME [epoch: 8.51 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.456402215451203		[learning rate: 0.0091871]
	Learning Rate: 0.00918712
	LOSS [training: 6.456402215451203 | validation: 6.854222634976601]
	TIME [epoch: 8.51 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.916792799019632		[learning rate: 0.0091655]
	Learning Rate: 0.00916545
	LOSS [training: 7.916792799019632 | validation: 8.544671580246245]
	TIME [epoch: 8.51 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.682409715230653		[learning rate: 0.0091438]
	Learning Rate: 0.00914383
	LOSS [training: 8.682409715230653 | validation: 7.221689210284775]
	TIME [epoch: 8.54 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.797063724799061		[learning rate: 0.0091223]
	Learning Rate: 0.00912226
	LOSS [training: 6.797063724799061 | validation: 6.385238801338419]
	TIME [epoch: 8.51 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.461659733525299		[learning rate: 0.0091007]
	Learning Rate: 0.00910074
	LOSS [training: 6.461659733525299 | validation: 6.086180694995962]
	TIME [epoch: 8.51 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.1445119993734085		[learning rate: 0.0090793]
	Learning Rate: 0.00907928
	LOSS [training: 6.1445119993734085 | validation: 5.816006084369327]
	TIME [epoch: 8.51 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.769811617371141		[learning rate: 0.0090579]
	Learning Rate: 0.00905786
	LOSS [training: 5.769811617371141 | validation: 6.053952657176632]
	TIME [epoch: 8.53 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.836409036674814		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 5.836409036674814 | validation: 5.917531610617528]
	TIME [epoch: 8.52 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.627495361468102		[learning rate: 0.0090152]
	Learning Rate: 0.00901518
	LOSS [training: 5.627495361468102 | validation: 5.786076702596384]
	TIME [epoch: 8.51 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.802898405309606		[learning rate: 0.0089939]
	Learning Rate: 0.00899391
	LOSS [training: 5.802898405309606 | validation: 5.705963130697739]
	TIME [epoch: 8.51 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.815522123902662		[learning rate: 0.0089727]
	Learning Rate: 0.0089727
	LOSS [training: 5.815522123902662 | validation: 6.080986183813115]
	TIME [epoch: 8.53 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.628701768627929		[learning rate: 0.0089515]
	Learning Rate: 0.00895153
	LOSS [training: 5.628701768627929 | validation: 4.9687633368110475]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.980871077765963		[learning rate: 0.0089304]
	Learning Rate: 0.00893042
	LOSS [training: 4.980871077765963 | validation: 5.804285576348882]
	TIME [epoch: 8.51 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.306962603640864		[learning rate: 0.0089094]
	Learning Rate: 0.00890935
	LOSS [training: 5.306962603640864 | validation: 4.157732396848024]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.149999119824566		[learning rate: 0.0088883]
	Learning Rate: 0.00888834
	LOSS [training: 5.149999119824566 | validation: 7.383171811479375]
	TIME [epoch: 8.52 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.1423115415426235		[learning rate: 0.0088674]
	Learning Rate: 0.00886737
	LOSS [training: 5.1423115415426235 | validation: 3.7632116211901447]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7700277222084693		[learning rate: 0.0088465]
	Learning Rate: 0.00884645
	LOSS [training: 3.7700277222084693 | validation: 3.727136782081449]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.555811919192645		[learning rate: 0.0088256]
	Learning Rate: 0.00882559
	LOSS [training: 3.555811919192645 | validation: 3.1547631843211863]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2801755085364084		[learning rate: 0.0088048]
	Learning Rate: 0.00880477
	LOSS [training: 3.2801755085364084 | validation: 4.957766815453081]
	TIME [epoch: 8.52 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.565133848275388		[learning rate: 0.008784]
	Learning Rate: 0.008784
	LOSS [training: 3.565133848275388 | validation: 4.220848781280113]
	TIME [epoch: 8.53 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2638227912918145		[learning rate: 0.0087633]
	Learning Rate: 0.00876328
	LOSS [training: 3.2638227912918145 | validation: 3.2452650659801123]
	TIME [epoch: 8.51 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.388025485704599		[learning rate: 0.0087426]
	Learning Rate: 0.00874261
	LOSS [training: 3.388025485704599 | validation: 3.658307477723733]
	TIME [epoch: 8.51 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.052721554504248		[learning rate: 0.008722]
	Learning Rate: 0.00872199
	LOSS [training: 3.052721554504248 | validation: 3.2293979640092116]
	TIME [epoch: 8.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.868525877537151		[learning rate: 0.0087014]
	Learning Rate: 0.00870141
	LOSS [training: 2.868525877537151 | validation: 3.74775972213203]
	TIME [epoch: 8.54 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0489542088213666		[learning rate: 0.0086809]
	Learning Rate: 0.00868089
	LOSS [training: 3.0489542088213666 | validation: 2.7628395557189918]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.142788480009271		[learning rate: 0.0086604]
	Learning Rate: 0.00866041
	LOSS [training: 3.142788480009271 | validation: 2.5166943564206665]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.042085687671853		[learning rate: 0.00864]
	Learning Rate: 0.00863998
	LOSS [training: 3.042085687671853 | validation: 2.5863265337085775]
	TIME [epoch: 8.51 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.054205729026511		[learning rate: 0.0086196]
	Learning Rate: 0.0086196
	LOSS [training: 3.054205729026511 | validation: 3.723790630776978]
	TIME [epoch: 8.54 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8489449870122874		[learning rate: 0.0085993]
	Learning Rate: 0.00859927
	LOSS [training: 2.8489449870122874 | validation: 2.431668156975046]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.812987457025582		[learning rate: 0.008579]
	Learning Rate: 0.00857898
	LOSS [training: 2.812987457025582 | validation: 2.537964613877892]
	TIME [epoch: 8.53 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7354351846089022		[learning rate: 0.0085587]
	Learning Rate: 0.00855875
	LOSS [training: 2.7354351846089022 | validation: 2.544263450597998]
	TIME [epoch: 8.53 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5796333094789015		[learning rate: 0.0085386]
	Learning Rate: 0.00853856
	LOSS [training: 2.5796333094789015 | validation: 2.559738897960541]
	TIME [epoch: 8.55 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0050416766226737		[learning rate: 0.0085184]
	Learning Rate: 0.00851842
	LOSS [training: 3.0050416766226737 | validation: 3.480384218337447]
	TIME [epoch: 8.54 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5434325240303624		[learning rate: 0.0084983]
	Learning Rate: 0.00849833
	LOSS [training: 2.5434325240303624 | validation: 3.0316956756763718]
	TIME [epoch: 8.54 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.363841624030548		[learning rate: 0.0084783]
	Learning Rate: 0.00847828
	LOSS [training: 2.363841624030548 | validation: 2.394429170556619]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.497229836475834		[learning rate: 0.0084583]
	Learning Rate: 0.00845828
	LOSS [training: 2.497229836475834 | validation: 2.1192229093595576]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.325647491810283		[learning rate: 0.0084383]
	Learning Rate: 0.00843833
	LOSS [training: 2.325647491810283 | validation: 2.0758752355750696]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4969203759405194		[learning rate: 0.0084184]
	Learning Rate: 0.00841842
	LOSS [training: 2.4969203759405194 | validation: 3.2411400877580565]
	TIME [epoch: 8.53 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.609826117441547		[learning rate: 0.0083986]
	Learning Rate: 0.00839857
	LOSS [training: 2.609826117441547 | validation: 2.171758445987578]
	TIME [epoch: 8.53 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0792856679095455		[learning rate: 0.0083788]
	Learning Rate: 0.00837875
	LOSS [training: 2.0792856679095455 | validation: 1.9706151241869603]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0878834838207205		[learning rate: 0.008359]
	Learning Rate: 0.00835899
	LOSS [training: 2.0878834838207205 | validation: 2.0441830467875883]
	TIME [epoch: 8.55 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.998550124021051		[learning rate: 0.0083393]
	Learning Rate: 0.00833927
	LOSS [training: 1.998550124021051 | validation: 2.4558291604885207]
	TIME [epoch: 8.53 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.010868148268153		[learning rate: 0.0083196]
	Learning Rate: 0.0083196
	LOSS [training: 2.010868148268153 | validation: 2.519680723110082]
	TIME [epoch: 8.53 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2291034242505665		[learning rate: 0.0083]
	Learning Rate: 0.00829998
	LOSS [training: 2.2291034242505665 | validation: 1.8032862887674184]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9986483170520237		[learning rate: 0.0082804]
	Learning Rate: 0.0082804
	LOSS [training: 1.9986483170520237 | validation: 1.6265632486639054]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9798893275253164		[learning rate: 0.0082609]
	Learning Rate: 0.00826087
	LOSS [training: 1.9798893275253164 | validation: 1.7652884207440838]
	TIME [epoch: 8.52 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.911532658060596		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 1.911532658060596 | validation: 2.1157972159470493]
	TIME [epoch: 8.52 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.004451721990104		[learning rate: 0.0082219]
	Learning Rate: 0.00822194
	LOSS [training: 2.004451721990104 | validation: 1.9187094359135746]
	TIME [epoch: 8.52 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7542163198303449		[learning rate: 0.0082025]
	Learning Rate: 0.00820255
	LOSS [training: 1.7542163198303449 | validation: 2.1724681620421253]
	TIME [epoch: 8.54 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7998035991946177		[learning rate: 0.0081832]
	Learning Rate: 0.0081832
	LOSS [training: 1.7998035991946177 | validation: 2.184600694367372]
	TIME [epoch: 8.52 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7475312683202504		[learning rate: 0.0081639]
	Learning Rate: 0.00816389
	LOSS [training: 1.7475312683202504 | validation: 1.8195935809778914]
	TIME [epoch: 8.52 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6858265300074176		[learning rate: 0.0081446]
	Learning Rate: 0.00814464
	LOSS [training: 1.6858265300074176 | validation: 1.9529429064291646]
	TIME [epoch: 8.52 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7527041977450826		[learning rate: 0.0081254]
	Learning Rate: 0.00812543
	LOSS [training: 1.7527041977450826 | validation: 1.501609404948344]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8910587817852167		[learning rate: 0.0081063]
	Learning Rate: 0.00810626
	LOSS [training: 1.8910587817852167 | validation: 1.4918880106686316]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6237720098980102		[learning rate: 0.0080871]
	Learning Rate: 0.00808714
	LOSS [training: 1.6237720098980102 | validation: 1.6472392037597845]
	TIME [epoch: 8.51 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5185372609289516		[learning rate: 0.0080681]
	Learning Rate: 0.00806806
	LOSS [training: 1.5185372609289516 | validation: 1.4844052545586723]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5331068239780938		[learning rate: 0.008049]
	Learning Rate: 0.00804903
	LOSS [training: 1.5331068239780938 | validation: 1.7949337732389599]
	TIME [epoch: 8.54 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6556140982878567		[learning rate: 0.00803]
	Learning Rate: 0.00803004
	LOSS [training: 1.6556140982878567 | validation: 1.3452716067131658]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.601305773841656		[learning rate: 0.0080111]
	Learning Rate: 0.0080111
	LOSS [training: 1.601305773841656 | validation: 1.3034908682930098]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8286456877051342		[learning rate: 0.0079922]
	Learning Rate: 0.00799221
	LOSS [training: 1.8286456877051342 | validation: 1.2685659083434078]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3902534771281745		[learning rate: 0.0079734]
	Learning Rate: 0.00797335
	LOSS [training: 1.3902534771281745 | validation: 1.4638213359329444]
	TIME [epoch: 8.53 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5829589981330163		[learning rate: 0.0079545]
	Learning Rate: 0.00795455
	LOSS [training: 1.5829589981330163 | validation: 1.5269176058475462]
	TIME [epoch: 8.83 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7416441807082719		[learning rate: 0.0079358]
	Learning Rate: 0.00793578
	LOSS [training: 1.7416441807082719 | validation: 1.0375020370033443]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5477589677926782		[learning rate: 0.0079171]
	Learning Rate: 0.00791706
	LOSS [training: 1.5477589677926782 | validation: 1.339056470607273]
	TIME [epoch: 8.53 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4842569384045132		[learning rate: 0.0078984]
	Learning Rate: 0.00789839
	LOSS [training: 1.4842569384045132 | validation: 2.190214632646062]
	TIME [epoch: 8.55 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6309003556498554		[learning rate: 0.0078798]
	Learning Rate: 0.00787976
	LOSS [training: 1.6309003556498554 | validation: 1.1243871958056972]
	TIME [epoch: 8.54 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2221649978466729		[learning rate: 0.0078612]
	Learning Rate: 0.00786117
	LOSS [training: 1.2221649978466729 | validation: 0.9544189213074558]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.071779033020745		[learning rate: 0.0078426]
	Learning Rate: 0.00784263
	LOSS [training: 1.071779033020745 | validation: 1.162878091184251]
	TIME [epoch: 8.53 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0978085010647867		[learning rate: 0.0078241]
	Learning Rate: 0.00782413
	LOSS [training: 1.0978085010647867 | validation: 1.1293045585283243]
	TIME [epoch: 8.53 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.21545966303107		[learning rate: 0.0078057]
	Learning Rate: 0.00780567
	LOSS [training: 1.21545966303107 | validation: 0.9337970580147299]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0711768127969752		[learning rate: 0.0077873]
	Learning Rate: 0.00778726
	LOSS [training: 1.0711768127969752 | validation: 1.058310584533714]
	TIME [epoch: 8.53 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3037928472862501		[learning rate: 0.0077689]
	Learning Rate: 0.00776889
	LOSS [training: 1.3037928472862501 | validation: 1.2621591507647265]
	TIME [epoch: 8.53 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3102753683828134		[learning rate: 0.0077506]
	Learning Rate: 0.00775056
	LOSS [training: 1.3102753683828134 | validation: 1.67890752808743]
	TIME [epoch: 8.52 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2313230648501203		[learning rate: 0.0077323]
	Learning Rate: 0.00773228
	LOSS [training: 1.2313230648501203 | validation: 1.1439105228571007]
	TIME [epoch: 8.55 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.013915514249153		[learning rate: 0.007714]
	Learning Rate: 0.00771404
	LOSS [training: 1.013915514249153 | validation: 1.2355977844756318]
	TIME [epoch: 8.53 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.226810983516907		[learning rate: 0.0076958]
	Learning Rate: 0.00769585
	LOSS [training: 1.226810983516907 | validation: 0.8453948421047741]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.721344446462009		[learning rate: 0.0076777]
	Learning Rate: 0.00767769
	LOSS [training: 1.721344446462009 | validation: 1.5963042592988834]
	TIME [epoch: 8.53 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1912051363700555		[learning rate: 0.0076596]
	Learning Rate: 0.00765958
	LOSS [training: 1.1912051363700555 | validation: 1.1666773484614585]
	TIME [epoch: 8.55 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0470120013435251		[learning rate: 0.0076415]
	Learning Rate: 0.00764151
	LOSS [training: 1.0470120013435251 | validation: 1.0672015256565355]
	TIME [epoch: 8.52 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1784375151106972		[learning rate: 0.0076235]
	Learning Rate: 0.00762349
	LOSS [training: 1.1784375151106972 | validation: 0.5893626605610771]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1708429004924277		[learning rate: 0.0076055]
	Learning Rate: 0.00760551
	LOSS [training: 1.1708429004924277 | validation: 0.9372316334281041]
	TIME [epoch: 8.52 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2188859499370508		[learning rate: 0.0075876]
	Learning Rate: 0.00758757
	LOSS [training: 1.2188859499370508 | validation: 0.9649821497489476]
	TIME [epoch: 8.55 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0940017913914668		[learning rate: 0.0075697]
	Learning Rate: 0.00756967
	LOSS [training: 1.0940017913914668 | validation: 0.8200486531828863]
	TIME [epoch: 8.52 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.110286771632322		[learning rate: 0.0075518]
	Learning Rate: 0.00755181
	LOSS [training: 1.110286771632322 | validation: 1.0005210669604017]
	TIME [epoch: 8.52 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1856646023784236		[learning rate: 0.007534]
	Learning Rate: 0.007534
	LOSS [training: 1.1856646023784236 | validation: 1.1001929314152679]
	TIME [epoch: 8.52 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1101400644828119		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 1.1101400644828119 | validation: 0.5897286403832116]
	TIME [epoch: 8.53 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8784420773514221		[learning rate: 0.0074985]
	Learning Rate: 0.0074985
	LOSS [training: 0.8784420773514221 | validation: 0.9452261520378613]
	TIME [epoch: 8.53 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.100446742972357		[learning rate: 0.0074808]
	Learning Rate: 0.00748081
	LOSS [training: 1.100446742972357 | validation: 0.8859999489494543]
	TIME [epoch: 8.52 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1296357519075049		[learning rate: 0.0074632]
	Learning Rate: 0.00746317
	LOSS [training: 1.1296357519075049 | validation: 1.1007514881033098]
	TIME [epoch: 8.52 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0351137616067787		[learning rate: 0.0074456]
	Learning Rate: 0.00744556
	LOSS [training: 1.0351137616067787 | validation: 0.7086747151137078]
	TIME [epoch: 8.53 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8470931240578776		[learning rate: 0.007428]
	Learning Rate: 0.007428
	LOSS [training: 0.8470931240578776 | validation: 1.8996049673887039]
	TIME [epoch: 8.54 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6258275828788733		[learning rate: 0.0074105]
	Learning Rate: 0.00741048
	LOSS [training: 1.6258275828788733 | validation: 1.8487807080253813]
	TIME [epoch: 8.52 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3584864314586556		[learning rate: 0.007393]
	Learning Rate: 0.007393
	LOSS [training: 1.3584864314586556 | validation: 0.9845848449390007]
	TIME [epoch: 8.52 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8005225598504054		[learning rate: 0.0073756]
	Learning Rate: 0.00737556
	LOSS [training: 0.8005225598504054 | validation: 0.853423737013604]
	TIME [epoch: 8.52 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8838813340620973		[learning rate: 0.0073582]
	Learning Rate: 0.00735816
	LOSS [training: 0.8838813340620973 | validation: 1.7056168581460696]
	TIME [epoch: 8.54 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5534650139642867		[learning rate: 0.0073408]
	Learning Rate: 0.0073408
	LOSS [training: 1.5534650139642867 | validation: 1.1177846662031063]
	TIME [epoch: 8.52 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8673189931608002		[learning rate: 0.0073235]
	Learning Rate: 0.00732349
	LOSS [training: 0.8673189931608002 | validation: 1.4241228771807322]
	TIME [epoch: 8.52 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0312595787515684		[learning rate: 0.0073062]
	Learning Rate: 0.00730621
	LOSS [training: 1.0312595787515684 | validation: 0.7263155211374207]
	TIME [epoch: 8.52 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7657699697107361		[learning rate: 0.007289]
	Learning Rate: 0.00728898
	LOSS [training: 0.7657699697107361 | validation: 0.8645618685792591]
	TIME [epoch: 8.54 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8881815921026945		[learning rate: 0.0072718]
	Learning Rate: 0.00727178
	LOSS [training: 0.8881815921026945 | validation: 0.8720393972889626]
	TIME [epoch: 8.52 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1881429705199709		[learning rate: 0.0072546]
	Learning Rate: 0.00725463
	LOSS [training: 1.1881429705199709 | validation: 1.51196891519585]
	TIME [epoch: 8.52 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2021747434505188		[learning rate: 0.0072375]
	Learning Rate: 0.00723752
	LOSS [training: 1.2021747434505188 | validation: 0.6794357547387035]
	TIME [epoch: 8.52 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.109875917855904		[learning rate: 0.0072204]
	Learning Rate: 0.00722045
	LOSS [training: 2.109875917855904 | validation: 5.957516852062578]
	TIME [epoch: 8.54 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.19383886537114		[learning rate: 0.0072034]
	Learning Rate: 0.00720342
	LOSS [training: 2.19383886537114 | validation: 1.051822882474958]
	TIME [epoch: 8.53 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9845043159161051		[learning rate: 0.0071864]
	Learning Rate: 0.00718642
	LOSS [training: 0.9845043159161051 | validation: 1.5535461605686534]
	TIME [epoch: 8.52 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.250984622022425		[learning rate: 0.0071695]
	Learning Rate: 0.00716947
	LOSS [training: 1.250984622022425 | validation: 0.8839940993691506]
	TIME [epoch: 8.52 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8346777355740501		[learning rate: 0.0071526]
	Learning Rate: 0.00715256
	LOSS [training: 0.8346777355740501 | validation: 0.8971764100807921]
	TIME [epoch: 8.54 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0234049234957565		[learning rate: 0.0071357]
	Learning Rate: 0.00713569
	LOSS [training: 1.0234049234957565 | validation: 1.2347953861701928]
	TIME [epoch: 8.54 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.132017771451907		[learning rate: 0.0071189]
	Learning Rate: 0.00711886
	LOSS [training: 1.132017771451907 | validation: 1.364747511036605]
	TIME [epoch: 8.52 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1747359349188673		[learning rate: 0.0071021]
	Learning Rate: 0.00710206
	LOSS [training: 1.1747359349188673 | validation: 0.737152541588525]
	TIME [epoch: 8.52 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8737055145272613		[learning rate: 0.0070853]
	Learning Rate: 0.00708531
	LOSS [training: 0.8737055145272613 | validation: 1.265907682039599]
	TIME [epoch: 8.53 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9849076591997058		[learning rate: 0.0070686]
	Learning Rate: 0.0070686
	LOSS [training: 0.9849076591997058 | validation: 0.6021735551808596]
	TIME [epoch: 8.55 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.746283054500719		[learning rate: 0.0070519]
	Learning Rate: 0.00705192
	LOSS [training: 0.746283054500719 | validation: 0.6443181996457188]
	TIME [epoch: 8.52 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7468211649558143		[learning rate: 0.0070353]
	Learning Rate: 0.00703529
	LOSS [training: 0.7468211649558143 | validation: 0.6143400041970261]
	TIME [epoch: 8.52 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.157211895806014		[learning rate: 0.0070187]
	Learning Rate: 0.0070187
	LOSS [training: 1.157211895806014 | validation: 2.2146610270314415]
	TIME [epoch: 8.52 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2468922346547813		[learning rate: 0.0070021]
	Learning Rate: 0.00700214
	LOSS [training: 1.2468922346547813 | validation: 1.7532683432537481]
	TIME [epoch: 8.54 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1147153441712638		[learning rate: 0.0069856]
	Learning Rate: 0.00698562
	LOSS [training: 1.1147153441712638 | validation: 0.82366834654628]
	TIME [epoch: 8.52 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8104692008334023		[learning rate: 0.0069691]
	Learning Rate: 0.00696914
	LOSS [training: 0.8104692008334023 | validation: 0.8603781693424557]
	TIME [epoch: 8.52 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9640859537358434		[learning rate: 0.0069527]
	Learning Rate: 0.00695271
	LOSS [training: 0.9640859537358434 | validation: 1.4053516650176077]
	TIME [epoch: 8.52 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8849849961357986		[learning rate: 0.0069363]
	Learning Rate: 0.00693631
	LOSS [training: 0.8849849961357986 | validation: 0.7084410318546261]
	TIME [epoch: 8.54 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9670352570485157		[learning rate: 0.0069199]
	Learning Rate: 0.00691994
	LOSS [training: 0.9670352570485157 | validation: 0.8026980398606691]
	TIME [epoch: 8.53 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8476112148918405		[learning rate: 0.0069036]
	Learning Rate: 0.00690362
	LOSS [training: 0.8476112148918405 | validation: 0.8004111750397378]
	TIME [epoch: 8.52 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8057566424379152		[learning rate: 0.0068873]
	Learning Rate: 0.00688734
	LOSS [training: 0.8057566424379152 | validation: 0.5377906375757588]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9021407306782514		[learning rate: 0.0068711]
	Learning Rate: 0.00687109
	LOSS [training: 0.9021407306782514 | validation: 0.803389306699971]
	TIME [epoch: 8.54 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9221204627713204		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.9221204627713204 | validation: 0.6317841860859451]
	TIME [epoch: 8.52 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.988363906972564		[learning rate: 0.0068387]
	Learning Rate: 0.00683871
	LOSS [training: 0.988363906972564 | validation: 0.676915415396]
	TIME [epoch: 8.52 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7917277775243876		[learning rate: 0.0068226]
	Learning Rate: 0.00682258
	LOSS [training: 0.7917277775243876 | validation: 0.8101312349290988]
	TIME [epoch: 8.51 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6738673341130215		[learning rate: 0.0068065]
	Learning Rate: 0.00680649
	LOSS [training: 0.6738673341130215 | validation: 0.9681327291800017]
	TIME [epoch: 8.52 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.022326854800108		[learning rate: 0.0067904]
	Learning Rate: 0.00679043
	LOSS [training: 1.022326854800108 | validation: 0.5881788609733636]
	TIME [epoch: 8.55 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7745338679753105		[learning rate: 0.0067744]
	Learning Rate: 0.00677441
	LOSS [training: 0.7745338679753105 | validation: 0.7550382510423825]
	TIME [epoch: 8.52 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6765938712213302		[learning rate: 0.0067584]
	Learning Rate: 0.00675843
	LOSS [training: 0.6765938712213302 | validation: 0.41946352239147033]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.898033995176647		[learning rate: 0.0067425]
	Learning Rate: 0.00674249
	LOSS [training: 0.898033995176647 | validation: 0.5146194188699443]
	TIME [epoch: 8.52 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7216149167767909		[learning rate: 0.0067266]
	Learning Rate: 0.00672659
	LOSS [training: 0.7216149167767909 | validation: 0.7000163482354471]
	TIME [epoch: 8.54 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8620414437095869		[learning rate: 0.0067107]
	Learning Rate: 0.00671072
	LOSS [training: 0.8620414437095869 | validation: 0.9045946868268617]
	TIME [epoch: 8.52 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2873797163387477		[learning rate: 0.0066949]
	Learning Rate: 0.00669489
	LOSS [training: 1.2873797163387477 | validation: 0.9703514982520494]
	TIME [epoch: 8.51 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9494429491469631		[learning rate: 0.0066791]
	Learning Rate: 0.0066791
	LOSS [training: 0.9494429491469631 | validation: 1.1654613018523703]
	TIME [epoch: 8.51 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7772486626158008		[learning rate: 0.0066633]
	Learning Rate: 0.00666334
	LOSS [training: 0.7772486626158008 | validation: 0.7181518472840444]
	TIME [epoch: 8.54 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7524049557916432		[learning rate: 0.0066476]
	Learning Rate: 0.00664763
	LOSS [training: 0.7524049557916432 | validation: 0.7070380175623293]
	TIME [epoch: 8.52 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7063714442221567		[learning rate: 0.0066319]
	Learning Rate: 0.00663195
	LOSS [training: 0.7063714442221567 | validation: 1.348346583944629]
	TIME [epoch: 8.52 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.811756676115319		[learning rate: 0.0066163]
	Learning Rate: 0.0066163
	LOSS [training: 0.811756676115319 | validation: 0.6402101813544824]
	TIME [epoch: 8.52 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7238297573146765		[learning rate: 0.0066007]
	Learning Rate: 0.0066007
	LOSS [training: 0.7238297573146765 | validation: 1.6546618126069315]
	TIME [epoch: 8.53 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9183816537930888		[learning rate: 0.0065851]
	Learning Rate: 0.00658513
	LOSS [training: 0.9183816537930888 | validation: 0.6100823493238847]
	TIME [epoch: 8.54 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7437510295530723		[learning rate: 0.0065696]
	Learning Rate: 0.00656959
	LOSS [training: 0.7437510295530723 | validation: 0.64782444561689]
	TIME [epoch: 8.52 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6063661725529377		[learning rate: 0.0065541]
	Learning Rate: 0.0065541
	LOSS [training: 0.6063661725529377 | validation: 0.46092655783758935]
	TIME [epoch: 8.51 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6964312123507244		[learning rate: 0.0065386]
	Learning Rate: 0.00653864
	LOSS [training: 0.6964312123507244 | validation: 0.916723508174857]
	TIME [epoch: 8.52 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8258438213125068		[learning rate: 0.0065232]
	Learning Rate: 0.00652321
	LOSS [training: 0.8258438213125068 | validation: 0.8926359310175016]
	TIME [epoch: 8.54 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6793644551152459		[learning rate: 0.0065078]
	Learning Rate: 0.00650783
	LOSS [training: 0.6793644551152459 | validation: 0.6451559660521045]
	TIME [epoch: 8.51 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7712425490820115		[learning rate: 0.0064925]
	Learning Rate: 0.00649247
	LOSS [training: 0.7712425490820115 | validation: 0.8683714501616087]
	TIME [epoch: 8.52 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.749010642942227		[learning rate: 0.0064772]
	Learning Rate: 0.00647716
	LOSS [training: 0.749010642942227 | validation: 0.4717326467547013]
	TIME [epoch: 8.51 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7739738335226503		[learning rate: 0.0064619]
	Learning Rate: 0.00646188
	LOSS [training: 0.7739738335226503 | validation: 0.8418647900989634]
	TIME [epoch: 8.54 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0291595107650333		[learning rate: 0.0064466]
	Learning Rate: 0.00644664
	LOSS [training: 1.0291595107650333 | validation: 0.5231980815915034]
	TIME [epoch: 8.52 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7852872544525408		[learning rate: 0.0064314]
	Learning Rate: 0.00643143
	LOSS [training: 0.7852872544525408 | validation: 0.8223104643425914]
	TIME [epoch: 8.51 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.62989100395357		[learning rate: 0.0064163]
	Learning Rate: 0.00641626
	LOSS [training: 0.62989100395357 | validation: 1.482611869338811]
	TIME [epoch: 8.51 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7869136893888875		[learning rate: 0.0064011]
	Learning Rate: 0.00640113
	LOSS [training: 0.7869136893888875 | validation: 1.0374489714453334]
	TIME [epoch: 8.54 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6153414788549225		[learning rate: 0.006386]
	Learning Rate: 0.00638603
	LOSS [training: 0.6153414788549225 | validation: 0.6612717295101214]
	TIME [epoch: 8.52 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6906282218800512		[learning rate: 0.006371]
	Learning Rate: 0.00637096
	LOSS [training: 0.6906282218800512 | validation: 0.6145690563118893]
	TIME [epoch: 8.52 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6950703884037719		[learning rate: 0.0063559]
	Learning Rate: 0.00635594
	LOSS [training: 0.6950703884037719 | validation: 1.0420028489979272]
	TIME [epoch: 8.51 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6006251826114266		[learning rate: 0.0063409]
	Learning Rate: 0.00634094
	LOSS [training: 1.6006251826114266 | validation: 0.7696160843674276]
	TIME [epoch: 8.53 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7964366477311243		[learning rate: 0.006326]
	Learning Rate: 0.00632599
	LOSS [training: 0.7964366477311243 | validation: 0.5645884287915204]
	TIME [epoch: 8.52 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6116623627561595		[learning rate: 0.0063111]
	Learning Rate: 0.00631106
	LOSS [training: 0.6116623627561595 | validation: 0.90257655782606]
	TIME [epoch: 8.52 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6561349869371369		[learning rate: 0.0062962]
	Learning Rate: 0.00629618
	LOSS [training: 0.6561349869371369 | validation: 0.760831105003961]
	TIME [epoch: 8.52 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6123772759216102		[learning rate: 0.0062813]
	Learning Rate: 0.00628133
	LOSS [training: 0.6123772759216102 | validation: 0.4215220542167877]
	TIME [epoch: 8.51 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0775255754190058		[learning rate: 0.0062665]
	Learning Rate: 0.00626651
	LOSS [training: 1.0775255754190058 | validation: 1.5640694567995597]
	TIME [epoch: 8.54 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0547576461519246		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 1.0547576461519246 | validation: 0.8973292753333388]
	TIME [epoch: 8.51 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.072159351212697		[learning rate: 0.006237]
	Learning Rate: 0.00623698
	LOSS [training: 1.072159351212697 | validation: 0.6822165650039757]
	TIME [epoch: 8.52 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.689254473662255		[learning rate: 0.0062223]
	Learning Rate: 0.00622227
	LOSS [training: 0.689254473662255 | validation: 0.8197750053609267]
	TIME [epoch: 8.51 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6762322199458651		[learning rate: 0.0062076]
	Learning Rate: 0.00620759
	LOSS [training: 0.6762322199458651 | validation: 1.3232997563065725]
	TIME [epoch: 8.54 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0453275484431441		[learning rate: 0.0061929]
	Learning Rate: 0.00619295
	LOSS [training: 1.0453275484431441 | validation: 0.6066415116910882]
	TIME [epoch: 8.51 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6847233927290264		[learning rate: 0.0061783]
	Learning Rate: 0.00617834
	LOSS [training: 0.6847233927290264 | validation: 0.3665729013494262]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_254.pth
	Model improved!!!
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7330461864039244		[learning rate: 0.0061638]
	Learning Rate: 0.00616377
	LOSS [training: 0.7330461864039244 | validation: 0.6633635485934634]
	TIME [epoch: 8.52 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1829704774612464		[learning rate: 0.0061492]
	Learning Rate: 0.00614923
	LOSS [training: 1.1829704774612464 | validation: 0.542242271552174]
	TIME [epoch: 8.54 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9712159442168111		[learning rate: 0.0061347]
	Learning Rate: 0.00613472
	LOSS [training: 0.9712159442168111 | validation: 0.7810402148822428]
	TIME [epoch: 8.51 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7687360835986456		[learning rate: 0.0061203]
	Learning Rate: 0.00612025
	LOSS [training: 0.7687360835986456 | validation: 0.5388065398988863]
	TIME [epoch: 8.51 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9371198510299379		[learning rate: 0.0061058]
	Learning Rate: 0.00610581
	LOSS [training: 0.9371198510299379 | validation: 0.8437461660710175]
	TIME [epoch: 8.51 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5709830735542557		[learning rate: 0.0060914]
	Learning Rate: 0.00609141
	LOSS [training: 0.5709830735542557 | validation: 0.5464710249779634]
	TIME [epoch: 8.52 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8823997519366037		[learning rate: 0.006077]
	Learning Rate: 0.00607704
	LOSS [training: 0.8823997519366037 | validation: 1.4953564018233685]
	TIME [epoch: 8.52 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.91957032277284		[learning rate: 0.0060627]
	Learning Rate: 0.00606271
	LOSS [training: 0.91957032277284 | validation: 0.4856303329419553]
	TIME [epoch: 8.51 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8936390994671349		[learning rate: 0.0060484]
	Learning Rate: 0.00604841
	LOSS [training: 0.8936390994671349 | validation: 1.1732575898893391]
	TIME [epoch: 8.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.981601910349022		[learning rate: 0.0060341]
	Learning Rate: 0.00603414
	LOSS [training: 0.981601910349022 | validation: 0.80638770922424]
	TIME [epoch: 8.51 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7019186451448574		[learning rate: 0.0060199]
	Learning Rate: 0.00601991
	LOSS [training: 0.7019186451448574 | validation: 0.5090729295133984]
	TIME [epoch: 8.53 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9969909252545399		[learning rate: 0.0060057]
	Learning Rate: 0.00600571
	LOSS [training: 0.9969909252545399 | validation: 0.9499798291626534]
	TIME [epoch: 8.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8106389986974838		[learning rate: 0.0059915]
	Learning Rate: 0.00599154
	LOSS [training: 0.8106389986974838 | validation: 0.4713681610710816]
	TIME [epoch: 8.51 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9571365407829383		[learning rate: 0.0059774]
	Learning Rate: 0.00597741
	LOSS [training: 0.9571365407829383 | validation: 1.090042520060602]
	TIME [epoch: 8.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8581275616167414		[learning rate: 0.0059633]
	Learning Rate: 0.00596331
	LOSS [training: 0.8581275616167414 | validation: 1.093957351656814]
	TIME [epoch: 8.53 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9481399761653803		[learning rate: 0.0059492]
	Learning Rate: 0.00594924
	LOSS [training: 0.9481399761653803 | validation: 0.8961361930095572]
	TIME [epoch: 8.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7182831659514963		[learning rate: 0.0059352]
	Learning Rate: 0.00593521
	LOSS [training: 0.7182831659514963 | validation: 0.36653641266358916]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6631094741951561		[learning rate: 0.0059212]
	Learning Rate: 0.00592121
	LOSS [training: 0.6631094741951561 | validation: 0.7096871950166288]
	TIME [epoch: 8.51 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9618580927289901		[learning rate: 0.0059072]
	Learning Rate: 0.00590724
	LOSS [training: 0.9618580927289901 | validation: 0.9533991352728459]
	TIME [epoch: 8.53 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6579256249239414		[learning rate: 0.0058933]
	Learning Rate: 0.00589331
	LOSS [training: 0.6579256249239414 | validation: 0.5975274137641176]
	TIME [epoch: 8.51 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6263317323478355		[learning rate: 0.0058794]
	Learning Rate: 0.0058794
	LOSS [training: 0.6263317323478355 | validation: 0.7666376525260432]
	TIME [epoch: 8.51 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7809445571116941		[learning rate: 0.0058655]
	Learning Rate: 0.00586554
	LOSS [training: 0.7809445571116941 | validation: 0.6195445671842073]
	TIME [epoch: 8.51 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8621990681506126		[learning rate: 0.0058517]
	Learning Rate: 0.0058517
	LOSS [training: 0.8621990681506126 | validation: 0.5908024827061011]
	TIME [epoch: 8.53 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8106708043891752		[learning rate: 0.0058379]
	Learning Rate: 0.0058379
	LOSS [training: 0.8106708043891752 | validation: 0.38540211954177006]
	TIME [epoch: 8.52 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8433087148651834		[learning rate: 0.0058241]
	Learning Rate: 0.00582413
	LOSS [training: 0.8433087148651834 | validation: 1.2696784495445619]
	TIME [epoch: 8.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7567633895697048		[learning rate: 0.0058104]
	Learning Rate: 0.00581039
	LOSS [training: 0.7567633895697048 | validation: 0.4144338807259642]
	TIME [epoch: 8.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6714523361325326		[learning rate: 0.0057967]
	Learning Rate: 0.00579668
	LOSS [training: 0.6714523361325326 | validation: 0.5981180637527863]
	TIME [epoch: 8.51 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7423551112896568		[learning rate: 0.005783]
	Learning Rate: 0.00578301
	LOSS [training: 0.7423551112896568 | validation: 1.4613166400045339]
	TIME [epoch: 8.52 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0083285903172021		[learning rate: 0.0057694]
	Learning Rate: 0.00576937
	LOSS [training: 1.0083285903172021 | validation: 1.0609156301424303]
	TIME [epoch: 8.51 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9456252610121819		[learning rate: 0.0057558]
	Learning Rate: 0.00575576
	LOSS [training: 0.9456252610121819 | validation: 0.41259251614986503]
	TIME [epoch: 8.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.08956786230092		[learning rate: 0.0057422]
	Learning Rate: 0.00574218
	LOSS [training: 1.08956786230092 | validation: 0.7242335801874069]
	TIME [epoch: 8.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6488788598867389		[learning rate: 0.0057286]
	Learning Rate: 0.00572864
	LOSS [training: 0.6488788598867389 | validation: 0.28483016982683285]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5352528207761905		[learning rate: 0.0057151]
	Learning Rate: 0.00571512
	LOSS [training: 0.5352528207761905 | validation: 0.7901404255616362]
	TIME [epoch: 8.51 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.861266929742707		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.861266929742707 | validation: 0.5572358434626997]
	TIME [epoch: 8.51 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6133189652132849		[learning rate: 0.0056882]
	Learning Rate: 0.00568819
	LOSS [training: 0.6133189652132849 | validation: 0.6578484163649689]
	TIME [epoch: 8.51 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9776159696637539		[learning rate: 0.0056748]
	Learning Rate: 0.00567478
	LOSS [training: 0.9776159696637539 | validation: 2.558869907579426]
	TIME [epoch: 8.53 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.05779452217686		[learning rate: 0.0056614]
	Learning Rate: 0.00566139
	LOSS [training: 1.05779452217686 | validation: 0.6884906579536814]
	TIME [epoch: 8.51 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0526697645129177		[learning rate: 0.005648]
	Learning Rate: 0.00564804
	LOSS [training: 1.0526697645129177 | validation: 0.6433409693358669]
	TIME [epoch: 8.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7179966834706782		[learning rate: 0.0056347]
	Learning Rate: 0.00563471
	LOSS [training: 0.7179966834706782 | validation: 1.122881604758633]
	TIME [epoch: 8.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7867953917584017		[learning rate: 0.0056214]
	Learning Rate: 0.00562142
	LOSS [training: 0.7867953917584017 | validation: 0.6550351848476421]
	TIME [epoch: 8.53 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.634348543314354		[learning rate: 0.0056082]
	Learning Rate: 0.00560816
	LOSS [training: 0.634348543314354 | validation: 0.4068517836055751]
	TIME [epoch: 8.52 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5851702635221888		[learning rate: 0.0055949]
	Learning Rate: 0.00559493
	LOSS [training: 0.5851702635221888 | validation: 0.4559590246374621]
	TIME [epoch: 8.51 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7499711712659175		[learning rate: 0.0055817]
	Learning Rate: 0.00558173
	LOSS [training: 0.7499711712659175 | validation: 0.316311350425623]
	TIME [epoch: 8.52 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6751493267228088		[learning rate: 0.0055686]
	Learning Rate: 0.00556857
	LOSS [training: 0.6751493267228088 | validation: 0.8151663632634127]
	TIME [epoch: 8.52 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7394671336671388		[learning rate: 0.0055554]
	Learning Rate: 0.00555543
	LOSS [training: 0.7394671336671388 | validation: 0.4420175309171261]
	TIME [epoch: 8.53 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.922838987297317		[learning rate: 0.0055423]
	Learning Rate: 0.00554233
	LOSS [training: 0.922838987297317 | validation: 0.6294198371067896]
	TIME [epoch: 8.51 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.025916358570773		[learning rate: 0.0055293]
	Learning Rate: 0.00552926
	LOSS [training: 1.025916358570773 | validation: 0.9769552360849445]
	TIME [epoch: 8.52 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8038549119477867		[learning rate: 0.0055162]
	Learning Rate: 0.00551621
	LOSS [training: 0.8038549119477867 | validation: 0.742670791587126]
	TIME [epoch: 8.51 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7258946048649831		[learning rate: 0.0055032]
	Learning Rate: 0.0055032
	LOSS [training: 0.7258946048649831 | validation: 0.7582860392112719]
	TIME [epoch: 8.53 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8238517661418939		[learning rate: 0.0054902]
	Learning Rate: 0.00549022
	LOSS [training: 0.8238517661418939 | validation: 0.5424529076126272]
	TIME [epoch: 8.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6790296134185762		[learning rate: 0.0054773]
	Learning Rate: 0.00547727
	LOSS [training: 0.6790296134185762 | validation: 1.3711402751368507]
	TIME [epoch: 8.51 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8513167532613432		[learning rate: 0.0054643]
	Learning Rate: 0.00546435
	LOSS [training: 0.8513167532613432 | validation: 0.6103562512422513]
	TIME [epoch: 8.49 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9128575830896832		[learning rate: 0.0054515]
	Learning Rate: 0.00545146
	LOSS [training: 0.9128575830896832 | validation: 2.86827784748915]
	TIME [epoch: 8.53 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.391407994093001		[learning rate: 0.0054386]
	Learning Rate: 0.0054386
	LOSS [training: 1.391407994093001 | validation: 0.5217017425084964]
	TIME [epoch: 8.51 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6661748585217888		[learning rate: 0.0054258]
	Learning Rate: 0.00542577
	LOSS [training: 0.6661748585217888 | validation: 1.0072845417556966]
	TIME [epoch: 8.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.153690388763716		[learning rate: 0.005413]
	Learning Rate: 0.00541297
	LOSS [training: 1.153690388763716 | validation: 0.5358349123403111]
	TIME [epoch: 8.51 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.787543705050046		[learning rate: 0.0054002]
	Learning Rate: 0.00540021
	LOSS [training: 0.787543705050046 | validation: 0.5057447772683887]
	TIME [epoch: 8.52 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7121300925414199		[learning rate: 0.0053875]
	Learning Rate: 0.00538747
	LOSS [training: 0.7121300925414199 | validation: 0.7982650680474712]
	TIME [epoch: 8.51 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7111623868837549		[learning rate: 0.0053748]
	Learning Rate: 0.00537476
	LOSS [training: 0.7111623868837549 | validation: 0.7226861529149331]
	TIME [epoch: 8.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7077042387203601		[learning rate: 0.0053621]
	Learning Rate: 0.00536208
	LOSS [training: 0.7077042387203601 | validation: 0.7115642332896007]
	TIME [epoch: 8.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9981691745216805		[learning rate: 0.0053494]
	Learning Rate: 0.00534943
	LOSS [training: 0.9981691745216805 | validation: 0.5019748355997067]
	TIME [epoch: 8.51 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.800724094473782		[learning rate: 0.0053368]
	Learning Rate: 0.00533681
	LOSS [training: 0.800724094473782 | validation: 0.5944882878805959]
	TIME [epoch: 8.52 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8103738850309978		[learning rate: 0.0053242]
	Learning Rate: 0.00532423
	LOSS [training: 0.8103738850309978 | validation: 0.7888116832299319]
	TIME [epoch: 8.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7399622520761721		[learning rate: 0.0053117]
	Learning Rate: 0.00531167
	LOSS [training: 0.7399622520761721 | validation: 0.3823796392268658]
	TIME [epoch: 8.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8143988841861367		[learning rate: 0.0052991]
	Learning Rate: 0.00529914
	LOSS [training: 0.8143988841861367 | validation: 0.865105536713701]
	TIME [epoch: 8.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7170051623599518		[learning rate: 0.0052866]
	Learning Rate: 0.00528664
	LOSS [training: 0.7170051623599518 | validation: 0.6879347123157739]
	TIME [epoch: 8.52 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5906680688135985		[learning rate: 0.0052742]
	Learning Rate: 0.00527417
	LOSS [training: 0.5906680688135985 | validation: 0.46158133712852123]
	TIME [epoch: 8.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7519671375024661		[learning rate: 0.0052617]
	Learning Rate: 0.00526173
	LOSS [training: 0.7519671375024661 | validation: 0.8426469706480089]
	TIME [epoch: 8.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6163534411473612		[learning rate: 0.0052493]
	Learning Rate: 0.00524931
	LOSS [training: 0.6163534411473612 | validation: 0.2961078724207366]
	TIME [epoch: 8.49 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1258035979672878		[learning rate: 0.0052369]
	Learning Rate: 0.00523693
	LOSS [training: 1.1258035979672878 | validation: 0.5254949734198175]
	TIME [epoch: 8.53 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5121421751650617		[learning rate: 0.0052246]
	Learning Rate: 0.00522458
	LOSS [training: 0.5121421751650617 | validation: 0.35869981724763644]
	TIME [epoch: 8.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7753263412465569		[learning rate: 0.0052123]
	Learning Rate: 0.00521225
	LOSS [training: 0.7753263412465569 | validation: 0.47908089665023623]
	TIME [epoch: 8.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9347459639450844		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.9347459639450844 | validation: 0.5403127223694407]
	TIME [epoch: 8.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7932808782116303		[learning rate: 0.0051877]
	Learning Rate: 0.00518769
	LOSS [training: 0.7932808782116303 | validation: 0.7940497650766052]
	TIME [epoch: 8.52 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0704574522811443		[learning rate: 0.0051755]
	Learning Rate: 0.00517546
	LOSS [training: 2.0704574522811443 | validation: 1.023319409868319]
	TIME [epoch: 8.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.982819892849953		[learning rate: 0.0051632]
	Learning Rate: 0.00516325
	LOSS [training: 0.982819892849953 | validation: 0.33052208590825427]
	TIME [epoch: 8.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.117395206787641		[learning rate: 0.0051511]
	Learning Rate: 0.00515107
	LOSS [training: 1.117395206787641 | validation: 0.9172529896788096]
	TIME [epoch: 8.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2594409285946424		[learning rate: 0.0051389]
	Learning Rate: 0.00513892
	LOSS [training: 1.2594409285946424 | validation: 0.7194512049099872]
	TIME [epoch: 8.51 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.987896748121084		[learning rate: 0.0051268]
	Learning Rate: 0.0051268
	LOSS [training: 0.987896748121084 | validation: 0.3773352713363633]
	TIME [epoch: 8.51 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6869786637374126		[learning rate: 0.0051147]
	Learning Rate: 0.0051147
	LOSS [training: 0.6869786637374126 | validation: 0.8265524770953128]
	TIME [epoch: 8.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9384256536894467		[learning rate: 0.0051026]
	Learning Rate: 0.00510264
	LOSS [training: 0.9384256536894467 | validation: 0.3655939417078171]
	TIME [epoch: 8.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9793833516285396		[learning rate: 0.0050906]
	Learning Rate: 0.0050906
	LOSS [training: 0.9793833516285396 | validation: 0.7137767079960176]
	TIME [epoch: 8.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7617195961270173		[learning rate: 0.0050786]
	Learning Rate: 0.00507859
	LOSS [training: 0.7617195961270173 | validation: 0.6723762015854591]
	TIME [epoch: 8.53 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.647617328301653		[learning rate: 0.0050666]
	Learning Rate: 0.00506661
	LOSS [training: 0.647617328301653 | validation: 0.8784052660809298]
	TIME [epoch: 8.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9782253722321597		[learning rate: 0.0050547]
	Learning Rate: 0.00505466
	LOSS [training: 0.9782253722321597 | validation: 0.7694675196975422]
	TIME [epoch: 8.51 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7774660032026001		[learning rate: 0.0050427]
	Learning Rate: 0.00504274
	LOSS [training: 0.7774660032026001 | validation: 0.5905425790718184]
	TIME [epoch: 8.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5837785051123887		[learning rate: 0.0050308]
	Learning Rate: 0.00503085
	LOSS [training: 0.5837785051123887 | validation: 0.471358604299445]
	TIME [epoch: 8.53 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9222899179293147		[learning rate: 0.005019]
	Learning Rate: 0.00501898
	LOSS [training: 0.9222899179293147 | validation: 0.46727432302919925]
	TIME [epoch: 8.51 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7148099333118942		[learning rate: 0.0050071]
	Learning Rate: 0.00500714
	LOSS [training: 0.7148099333118942 | validation: 0.5981165430418152]
	TIME [epoch: 8.51 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5892216622063557		[learning rate: 0.0049953]
	Learning Rate: 0.00499533
	LOSS [training: 0.5892216622063557 | validation: 0.9752651597745684]
	TIME [epoch: 8.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7927600769082754		[learning rate: 0.0049835]
	Learning Rate: 0.00498355
	LOSS [training: 0.7927600769082754 | validation: 0.4557655941863915]
	TIME [epoch: 8.51 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8239440932488353		[learning rate: 0.0049718]
	Learning Rate: 0.00497179
	LOSS [training: 0.8239440932488353 | validation: 0.7765172399928043]
	TIME [epoch: 8.51 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1128327450925855		[learning rate: 0.0049601]
	Learning Rate: 0.00496006
	LOSS [training: 1.1128327450925855 | validation: 0.5087654575946711]
	TIME [epoch: 8.51 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7788331294496402		[learning rate: 0.0049484]
	Learning Rate: 0.00494836
	LOSS [training: 0.7788331294496402 | validation: 0.44082664135282157]
	TIME [epoch: 8.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5952447577788442		[learning rate: 0.0049367]
	Learning Rate: 0.00493669
	LOSS [training: 0.5952447577788442 | validation: 0.6317773109706066]
	TIME [epoch: 8.51 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6354856046111036		[learning rate: 0.004925]
	Learning Rate: 0.00492505
	LOSS [training: 0.6354856046111036 | validation: 0.2952413929216304]
	TIME [epoch: 8.52 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5713130251179332		[learning rate: 0.0049134]
	Learning Rate: 0.00491343
	LOSS [training: 0.5713130251179332 | validation: 0.3767722437283314]
	TIME [epoch: 8.51 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7077507061726245		[learning rate: 0.0049018]
	Learning Rate: 0.00490184
	LOSS [training: 0.7077507061726245 | validation: 1.123021095833455]
	TIME [epoch: 8.51 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8712732010418011		[learning rate: 0.0048903]
	Learning Rate: 0.00489028
	LOSS [training: 0.8712732010418011 | validation: 0.8500220230199964]
	TIME [epoch: 8.51 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9684183508077882		[learning rate: 0.0048787]
	Learning Rate: 0.00487874
	LOSS [training: 0.9684183508077882 | validation: 0.39738753842452046]
	TIME [epoch: 8.52 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6101871907784175		[learning rate: 0.0048672]
	Learning Rate: 0.00486723
	LOSS [training: 0.6101871907784175 | validation: 0.5462128971742293]
	TIME [epoch: 8.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7080752897567415		[learning rate: 0.0048558]
	Learning Rate: 0.00485575
	LOSS [training: 0.7080752897567415 | validation: 0.39975908495166257]
	TIME [epoch: 8.51 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6238945233056249		[learning rate: 0.0048443]
	Learning Rate: 0.0048443
	LOSS [training: 0.6238945233056249 | validation: 0.9267453795477193]
	TIME [epoch: 8.51 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9067341199233058		[learning rate: 0.0048329]
	Learning Rate: 0.00483287
	LOSS [training: 0.9067341199233058 | validation: 0.8241775215091697]
	TIME [epoch: 8.53 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5568547738774674		[learning rate: 0.0048215]
	Learning Rate: 0.00482147
	LOSS [training: 0.5568547738774674 | validation: 0.46696504958545343]
	TIME [epoch: 8.51 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5817539076895228		[learning rate: 0.0048101]
	Learning Rate: 0.0048101
	LOSS [training: 0.5817539076895228 | validation: 0.5121280009222962]
	TIME [epoch: 8.51 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8198265428876172		[learning rate: 0.0047988]
	Learning Rate: 0.00479875
	LOSS [training: 0.8198265428876172 | validation: 0.9111605399531806]
	TIME [epoch: 8.51 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7725303626044193		[learning rate: 0.0047874]
	Learning Rate: 0.00478743
	LOSS [training: 0.7725303626044193 | validation: 0.5034616433412702]
	TIME [epoch: 8.52 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.567477673745506		[learning rate: 0.0047761]
	Learning Rate: 0.00477614
	LOSS [training: 0.567477673745506 | validation: 0.7484919812446786]
	TIME [epoch: 8.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9786241867197802		[learning rate: 0.0047649]
	Learning Rate: 0.00476487
	LOSS [training: 0.9786241867197802 | validation: 0.44517911297286855]
	TIME [epoch: 8.51 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.648144987976426		[learning rate: 0.0047536]
	Learning Rate: 0.00475363
	LOSS [training: 0.648144987976426 | validation: 1.408673241119334]
	TIME [epoch: 8.49 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9436544631054037		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.9436544631054037 | validation: 1.0068235224702105]
	TIME [epoch: 8.52 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7952971166503879		[learning rate: 0.0047312]
	Learning Rate: 0.00473123
	LOSS [training: 0.7952971166503879 | validation: 0.5106923757860499]
	TIME [epoch: 8.52 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5206817692612005		[learning rate: 0.0047201]
	Learning Rate: 0.00472007
	LOSS [training: 0.5206817692612005 | validation: 0.38726391355389095]
	TIME [epoch: 8.51 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5508797914627095		[learning rate: 0.0047089]
	Learning Rate: 0.00470894
	LOSS [training: 0.5508797914627095 | validation: 0.5827614378289945]
	TIME [epoch: 8.51 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8157500136335176		[learning rate: 0.0046978]
	Learning Rate: 0.00469783
	LOSS [training: 0.8157500136335176 | validation: 1.0298679232281471]
	TIME [epoch: 8.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7993836471221468		[learning rate: 0.0046868]
	Learning Rate: 0.00468675
	LOSS [training: 0.7993836471221468 | validation: 0.4094443305882862]
	TIME [epoch: 8.53 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5554730921521095		[learning rate: 0.0046757]
	Learning Rate: 0.00467569
	LOSS [training: 0.5554730921521095 | validation: 0.27599497371872345]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_372.pth
	Model improved!!!
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5372191912608701		[learning rate: 0.0046647]
	Learning Rate: 0.00466467
	LOSS [training: 0.5372191912608701 | validation: 0.40741671589700545]
	TIME [epoch: 8.51 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5625935543372443		[learning rate: 0.0046537]
	Learning Rate: 0.00465366
	LOSS [training: 0.5625935543372443 | validation: 0.4353047103122292]
	TIME [epoch: 8.51 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8563827895930128		[learning rate: 0.0046427]
	Learning Rate: 0.00464268
	LOSS [training: 0.8563827895930128 | validation: 0.35622139618620674]
	TIME [epoch: 8.53 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4768999173104487		[learning rate: 0.0046317]
	Learning Rate: 0.00463173
	LOSS [training: 1.4768999173104487 | validation: 5.710055379609737]
	TIME [epoch: 8.51 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.672436206126445		[learning rate: 0.0046208]
	Learning Rate: 0.00462081
	LOSS [training: 2.672436206126445 | validation: 0.4680316794681093]
	TIME [epoch: 8.51 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7361247133049861		[learning rate: 0.0046099]
	Learning Rate: 0.00460991
	LOSS [training: 0.7361247133049861 | validation: 1.281951257843019]
	TIME [epoch: 8.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6392823393550519		[learning rate: 0.004599]
	Learning Rate: 0.00459903
	LOSS [training: 0.6392823393550519 | validation: 0.7136246093613496]
	TIME [epoch: 8.53 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9569204003232938		[learning rate: 0.0045882]
	Learning Rate: 0.00458819
	LOSS [training: 0.9569204003232938 | validation: 0.42514531445120485]
	TIME [epoch: 8.51 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.533084525292787		[learning rate: 0.0045774]
	Learning Rate: 0.00457736
	LOSS [training: 0.533084525292787 | validation: 0.6632836000674229]
	TIME [epoch: 8.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9664782871690984		[learning rate: 0.0045666]
	Learning Rate: 0.00456657
	LOSS [training: 0.9664782871690984 | validation: 1.5945950666013586]
	TIME [epoch: 8.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0656349002163885		[learning rate: 0.0045558]
	Learning Rate: 0.00455579
	LOSS [training: 1.0656349002163885 | validation: 0.6246671845577267]
	TIME [epoch: 8.53 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.587547768011628		[learning rate: 0.004545]
	Learning Rate: 0.00454505
	LOSS [training: 0.587547768011628 | validation: 0.48215731925437333]
	TIME [epoch: 8.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5582926842822473		[learning rate: 0.0045343]
	Learning Rate: 0.00453433
	LOSS [training: 0.5582926842822473 | validation: 0.4757455224012763]
	TIME [epoch: 8.52 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.69130883877167		[learning rate: 0.0045236]
	Learning Rate: 0.00452363
	LOSS [training: 0.69130883877167 | validation: 0.6019383167173686]
	TIME [epoch: 8.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48341950865537775		[learning rate: 0.004513]
	Learning Rate: 0.00451296
	LOSS [training: 0.48341950865537775 | validation: 1.3158583484201434]
	TIME [epoch: 8.52 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8263287948808312		[learning rate: 0.0045023]
	Learning Rate: 0.00450232
	LOSS [training: 0.8263287948808312 | validation: 0.6063105089944121]
	TIME [epoch: 8.53 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6272276113894424		[learning rate: 0.0044917]
	Learning Rate: 0.00449169
	LOSS [training: 0.6272276113894424 | validation: 0.7491195067430572]
	TIME [epoch: 8.52 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5455303153986465		[learning rate: 0.0044811]
	Learning Rate: 0.0044811
	LOSS [training: 0.5455303153986465 | validation: 0.6135269393229552]
	TIME [epoch: 8.51 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7592961616731941		[learning rate: 0.0044705]
	Learning Rate: 0.00447053
	LOSS [training: 0.7592961616731941 | validation: 0.4175222377501958]
	TIME [epoch: 8.51 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5662083240766776		[learning rate: 0.00446]
	Learning Rate: 0.00445998
	LOSS [training: 0.5662083240766776 | validation: 0.496276840533041]
	TIME [epoch: 8.53 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.593916064653225		[learning rate: 0.0044495]
	Learning Rate: 0.00444946
	LOSS [training: 0.593916064653225 | validation: 0.3438275897943432]
	TIME [epoch: 8.51 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5467984017182765		[learning rate: 0.004439]
	Learning Rate: 0.00443897
	LOSS [training: 0.5467984017182765 | validation: 0.6639887334098111]
	TIME [epoch: 8.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8607059501498574		[learning rate: 0.0044285]
	Learning Rate: 0.0044285
	LOSS [training: 0.8607059501498574 | validation: 1.0788457508043492]
	TIME [epoch: 8.51 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0519477753981312		[learning rate: 0.0044181]
	Learning Rate: 0.00441805
	LOSS [training: 1.0519477753981312 | validation: 0.8538956818862229]
	TIME [epoch: 8.53 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7045104305336026		[learning rate: 0.0044076]
	Learning Rate: 0.00440763
	LOSS [training: 0.7045104305336026 | validation: 0.4440257423875288]
	TIME [epoch: 8.51 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5487675055524643		[learning rate: 0.0043972]
	Learning Rate: 0.00439723
	LOSS [training: 0.5487675055524643 | validation: 0.30951443318236327]
	TIME [epoch: 8.51 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6345351480342807		[learning rate: 0.0043869]
	Learning Rate: 0.00438686
	LOSS [training: 0.6345351480342807 | validation: 0.5093823511063922]
	TIME [epoch: 8.51 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6403100990751669		[learning rate: 0.0043765]
	Learning Rate: 0.00437651
	LOSS [training: 0.6403100990751669 | validation: 1.1381554120744832]
	TIME [epoch: 8.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6260000369962896		[learning rate: 0.0043662]
	Learning Rate: 0.00436619
	LOSS [training: 0.6260000369962896 | validation: 0.3912011648282939]
	TIME [epoch: 8.52 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6494610595944627		[learning rate: 0.0043559]
	Learning Rate: 0.00435589
	LOSS [training: 0.6494610595944627 | validation: 0.3981944860059131]
	TIME [epoch: 8.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7032652872667139		[learning rate: 0.0043456]
	Learning Rate: 0.00434561
	LOSS [training: 0.7032652872667139 | validation: 0.2818116921060077]
	TIME [epoch: 8.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47084703321585886		[learning rate: 0.0043354]
	Learning Rate: 0.00433536
	LOSS [training: 0.47084703321585886 | validation: 0.3999202859393638]
	TIME [epoch: 8.51 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4165376117762449		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.4165376117762449 | validation: 0.42760526302007984]
	TIME [epoch: 8.52 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6311537777683689		[learning rate: 0.0043149]
	Learning Rate: 0.00431494
	LOSS [training: 0.6311537777683689 | validation: 0.5757600827232612]
	TIME [epoch: 8.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5764474790936107		[learning rate: 0.0043048]
	Learning Rate: 0.00430476
	LOSS [training: 0.5764474790936107 | validation: 0.7003396402659452]
	TIME [epoch: 8.49 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7326343528669239		[learning rate: 0.0042946]
	Learning Rate: 0.0042946
	LOSS [training: 0.7326343528669239 | validation: 0.5090677474679947]
	TIME [epoch: 8.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.729058451891304		[learning rate: 0.0042845]
	Learning Rate: 0.00428447
	LOSS [training: 0.729058451891304 | validation: 0.4098659400270799]
	TIME [epoch: 8.52 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4790266221237395		[learning rate: 0.0042744]
	Learning Rate: 0.00427437
	LOSS [training: 0.4790266221237395 | validation: 0.6512291132559045]
	TIME [epoch: 8.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7889964618041558		[learning rate: 0.0042643]
	Learning Rate: 0.00426428
	LOSS [training: 0.7889964618041558 | validation: 0.7860855176858391]
	TIME [epoch: 8.49 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5676883981854698		[learning rate: 0.0042542]
	Learning Rate: 0.00425423
	LOSS [training: 0.5676883981854698 | validation: 0.8615719655821172]
	TIME [epoch: 8.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8255093416479349		[learning rate: 0.0042442]
	Learning Rate: 0.00424419
	LOSS [training: 0.8255093416479349 | validation: 0.8430837960857519]
	TIME [epoch: 8.51 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6198917930250374		[learning rate: 0.0042342]
	Learning Rate: 0.00423418
	LOSS [training: 0.6198917930250374 | validation: 0.5123235404969779]
	TIME [epoch: 8.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6649781841192178		[learning rate: 0.0042242]
	Learning Rate: 0.00422419
	LOSS [training: 0.6649781841192178 | validation: 0.5487078258464566]
	TIME [epoch: 8.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5854539738961881		[learning rate: 0.0042142]
	Learning Rate: 0.00421423
	LOSS [training: 0.5854539738961881 | validation: 0.727565660656425]
	TIME [epoch: 8.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7088983236561986		[learning rate: 0.0042043]
	Learning Rate: 0.00420429
	LOSS [training: 0.7088983236561986 | validation: 0.6967867705524804]
	TIME [epoch: 8.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7797122504680223		[learning rate: 0.0041944]
	Learning Rate: 0.00419437
	LOSS [training: 0.7797122504680223 | validation: 0.759088071143051]
	TIME [epoch: 8.51 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7297078022522258		[learning rate: 0.0041845]
	Learning Rate: 0.00418448
	LOSS [training: 0.7297078022522258 | validation: 0.5684924484613478]
	TIME [epoch: 8.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6050636044558709		[learning rate: 0.0041746]
	Learning Rate: 0.0041746
	LOSS [training: 0.6050636044558709 | validation: 1.075167843578694]
	TIME [epoch: 8.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6132446557829971		[learning rate: 0.0041648]
	Learning Rate: 0.00416476
	LOSS [training: 0.6132446557829971 | validation: 0.7619286949139654]
	TIME [epoch: 8.51 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0870901124739807		[learning rate: 0.0041549]
	Learning Rate: 0.00415493
	LOSS [training: 1.0870901124739807 | validation: 0.3976340536429981]
	TIME [epoch: 8.52 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6755855630726693		[learning rate: 0.0041451]
	Learning Rate: 0.00414513
	LOSS [training: 0.6755855630726693 | validation: 0.32087122401562024]
	TIME [epoch: 8.51 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5365504387052564		[learning rate: 0.0041354]
	Learning Rate: 0.00413535
	LOSS [training: 0.5365504387052564 | validation: 0.3244654946776095]
	TIME [epoch: 8.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9416470666537581		[learning rate: 0.0041256]
	Learning Rate: 0.0041256
	LOSS [training: 0.9416470666537581 | validation: 0.44397511974207754]
	TIME [epoch: 8.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5544927511348277		[learning rate: 0.0041159]
	Learning Rate: 0.00411587
	LOSS [training: 0.5544927511348277 | validation: 0.4772559441614995]
	TIME [epoch: 8.53 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7274973156962796		[learning rate: 0.0041062]
	Learning Rate: 0.00410616
	LOSS [training: 0.7274973156962796 | validation: 0.7319487910590856]
	TIME [epoch: 8.51 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6436433096925411		[learning rate: 0.0040965]
	Learning Rate: 0.00409647
	LOSS [training: 0.6436433096925411 | validation: 0.5031444952787063]
	TIME [epoch: 8.5 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5987462235116844		[learning rate: 0.0040868]
	Learning Rate: 0.00408681
	LOSS [training: 0.5987462235116844 | validation: 1.086453314043014]
	TIME [epoch: 8.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8105909202388103		[learning rate: 0.0040772]
	Learning Rate: 0.00407717
	LOSS [training: 0.8105909202388103 | validation: 0.6958501290160539]
	TIME [epoch: 8.53 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6622025474650004		[learning rate: 0.0040676]
	Learning Rate: 0.00406755
	LOSS [training: 0.6622025474650004 | validation: 0.4954928746696915]
	TIME [epoch: 8.51 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5707365954423298		[learning rate: 0.004058]
	Learning Rate: 0.00405796
	LOSS [training: 0.5707365954423298 | validation: 0.2811554517404089]
	TIME [epoch: 8.51 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.573640104804978		[learning rate: 0.0040484]
	Learning Rate: 0.00404839
	LOSS [training: 0.573640104804978 | validation: 0.5582931488477276]
	TIME [epoch: 8.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7775786442044381		[learning rate: 0.0040388]
	Learning Rate: 0.00403884
	LOSS [training: 0.7775786442044381 | validation: 0.4486669167360345]
	TIME [epoch: 8.51 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5768643156311123		[learning rate: 0.0040293]
	Learning Rate: 0.00402931
	LOSS [training: 0.5768643156311123 | validation: 0.812490984252494]
	TIME [epoch: 8.52 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7602198196964917		[learning rate: 0.0040198]
	Learning Rate: 0.00401981
	LOSS [training: 0.7602198196964917 | validation: 0.6456219907002827]
	TIME [epoch: 8.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6094672420609258		[learning rate: 0.0040103]
	Learning Rate: 0.00401032
	LOSS [training: 0.6094672420609258 | validation: 0.4058024497292315]
	TIME [epoch: 8.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4764408448138826		[learning rate: 0.0040009]
	Learning Rate: 0.00400086
	LOSS [training: 0.4764408448138826 | validation: 0.5604381306553584]
	TIME [epoch: 8.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8712154246116469		[learning rate: 0.0039914]
	Learning Rate: 0.00399143
	LOSS [training: 0.8712154246116469 | validation: 0.6740589462338082]
	TIME [epoch: 8.53 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7217643563363552		[learning rate: 0.003982]
	Learning Rate: 0.00398201
	LOSS [training: 0.7217643563363552 | validation: 0.6146535268203757]
	TIME [epoch: 8.51 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5234498751781409		[learning rate: 0.0039726]
	Learning Rate: 0.00397262
	LOSS [training: 0.5234498751781409 | validation: 0.4531955190613204]
	TIME [epoch: 8.51 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7531763419823758		[learning rate: 0.0039632]
	Learning Rate: 0.00396325
	LOSS [training: 0.7531763419823758 | validation: 0.8318443073533095]
	TIME [epoch: 8.51 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5658078826957141		[learning rate: 0.0039539]
	Learning Rate: 0.0039539
	LOSS [training: 0.5658078826957141 | validation: 0.574563665504755]
	TIME [epoch: 8.53 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.559804637072033		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.559804637072033 | validation: 0.5339824507018861]
	TIME [epoch: 8.51 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0251564030752252		[learning rate: 0.0039353]
	Learning Rate: 0.00393527
	LOSS [training: 1.0251564030752252 | validation: 0.4290873420931653]
	TIME [epoch: 8.51 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.55249962368657		[learning rate: 0.003926]
	Learning Rate: 0.00392599
	LOSS [training: 0.55249962368657 | validation: 0.35487070512966945]
	TIME [epoch: 8.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5366446898374078		[learning rate: 0.0039167]
	Learning Rate: 0.00391672
	LOSS [training: 0.5366446898374078 | validation: 0.47244513363762897]
	TIME [epoch: 8.52 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5556186332889596		[learning rate: 0.0039075]
	Learning Rate: 0.00390749
	LOSS [training: 0.5556186332889596 | validation: 0.38445396017103484]
	TIME [epoch: 8.51 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5114074011334147		[learning rate: 0.0038983]
	Learning Rate: 0.00389827
	LOSS [training: 0.5114074011334147 | validation: 0.5982452771778202]
	TIME [epoch: 8.52 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5833094232259011		[learning rate: 0.0038891]
	Learning Rate: 0.00388907
	LOSS [training: 0.5833094232259011 | validation: 0.39690661654893855]
	TIME [epoch: 8.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46749528972810134		[learning rate: 0.0038799]
	Learning Rate: 0.0038799
	LOSS [training: 0.46749528972810134 | validation: 0.4056877229006291]
	TIME [epoch: 8.52 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46456930498105564		[learning rate: 0.0038707]
	Learning Rate: 0.00387075
	LOSS [training: 0.46456930498105564 | validation: 0.6447253181215267]
	TIME [epoch: 8.53 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42233536408378763		[learning rate: 0.0038616]
	Learning Rate: 0.00386162
	LOSS [training: 0.42233536408378763 | validation: 0.8403713036554734]
	TIME [epoch: 8.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6784041992372764		[learning rate: 0.0038525]
	Learning Rate: 0.00385251
	LOSS [training: 0.6784041992372764 | validation: 0.4006165425867333]
	TIME [epoch: 8.51 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5980890888686725		[learning rate: 0.0038434]
	Learning Rate: 0.00384342
	LOSS [training: 0.5980890888686725 | validation: 0.3594974109320794]
	TIME [epoch: 8.51 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4908079646528393		[learning rate: 0.0038344]
	Learning Rate: 0.00383435
	LOSS [training: 0.4908079646528393 | validation: 0.7268857987083466]
	TIME [epoch: 8.54 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7574816924535185		[learning rate: 0.0038253]
	Learning Rate: 0.00382531
	LOSS [training: 0.7574816924535185 | validation: 0.9676066664567544]
	TIME [epoch: 8.51 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7504375341006944		[learning rate: 0.0038163]
	Learning Rate: 0.00381629
	LOSS [training: 0.7504375341006944 | validation: 0.3411390565971577]
	TIME [epoch: 8.51 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.502493223632902		[learning rate: 0.0038073]
	Learning Rate: 0.00380728
	LOSS [training: 0.502493223632902 | validation: 0.4312519017150939]
	TIME [epoch: 8.51 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48663148223433456		[learning rate: 0.0037983]
	Learning Rate: 0.0037983
	LOSS [training: 0.48663148223433456 | validation: 0.7880617061862921]
	TIME [epoch: 8.53 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.759052187702285		[learning rate: 0.0037893]
	Learning Rate: 0.00378934
	LOSS [training: 0.759052187702285 | validation: 0.380982826523453]
	TIME [epoch: 8.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4510058671218566		[learning rate: 0.0037804]
	Learning Rate: 0.00378041
	LOSS [training: 1.4510058671218566 | validation: 0.5839439874160969]
	TIME [epoch: 8.5 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6109516115726901		[learning rate: 0.0037715]
	Learning Rate: 0.00377149
	LOSS [training: 0.6109516115726901 | validation: 0.42636099712714953]
	TIME [epoch: 8.49 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7561312716464599		[learning rate: 0.0037626]
	Learning Rate: 0.00376259
	LOSS [training: 0.7561312716464599 | validation: 0.5695550610237985]
	TIME [epoch: 8.52 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6034664753570003		[learning rate: 0.0037537]
	Learning Rate: 0.00375372
	LOSS [training: 0.6034664753570003 | validation: 0.34578792233776223]
	TIME [epoch: 8.51 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5887132042873033		[learning rate: 0.0037449]
	Learning Rate: 0.00374486
	LOSS [training: 0.5887132042873033 | validation: 0.5571255474156572]
	TIME [epoch: 8.51 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4900917434762733		[learning rate: 0.003736]
	Learning Rate: 0.00373603
	LOSS [training: 0.4900917434762733 | validation: 0.36585732850236563]
	TIME [epoch: 8.51 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6358946545294091		[learning rate: 0.0037272]
	Learning Rate: 0.00372722
	LOSS [training: 0.6358946545294091 | validation: 0.44019705501384593]
	TIME [epoch: 8.52 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4837846919743464		[learning rate: 0.0037184]
	Learning Rate: 0.00371842
	LOSS [training: 0.4837846919743464 | validation: 0.4601343005449404]
	TIME [epoch: 8.52 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5848408883371605		[learning rate: 0.0037097]
	Learning Rate: 0.00370965
	LOSS [training: 0.5848408883371605 | validation: 0.40644947878264953]
	TIME [epoch: 8.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46391544106007754		[learning rate: 0.0037009]
	Learning Rate: 0.0037009
	LOSS [training: 0.46391544106007754 | validation: 0.3138188021392332]
	TIME [epoch: 8.51 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6019384671308409		[learning rate: 0.0036922]
	Learning Rate: 0.00369217
	LOSS [training: 0.6019384671308409 | validation: 0.6004695678284486]
	TIME [epoch: 8.51 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.568857361153462		[learning rate: 0.0036835]
	Learning Rate: 0.00368346
	LOSS [training: 0.568857361153462 | validation: 2.389571784853185]
	TIME [epoch: 8.54 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9059795598310452		[learning rate: 0.0036748]
	Learning Rate: 0.00367478
	LOSS [training: 0.9059795598310452 | validation: 0.3614574724734807]
	TIME [epoch: 8.51 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5376358599552475		[learning rate: 0.0036661]
	Learning Rate: 0.00366611
	LOSS [training: 0.5376358599552475 | validation: 0.6929306280562975]
	TIME [epoch: 8.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5463393734192552		[learning rate: 0.0036575]
	Learning Rate: 0.00365746
	LOSS [training: 0.5463393734192552 | validation: 0.3567090847681258]
	TIME [epoch: 8.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7854345214631667		[learning rate: 0.0036488]
	Learning Rate: 0.00364883
	LOSS [training: 0.7854345214631667 | validation: 0.6629665675812499]
	TIME [epoch: 8.53 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5369171137135184		[learning rate: 0.0036402]
	Learning Rate: 0.00364022
	LOSS [training: 0.5369171137135184 | validation: 0.2645252783382954]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_478.pth
	Model improved!!!
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8251373310761771		[learning rate: 0.0036316]
	Learning Rate: 0.00363164
	LOSS [training: 0.8251373310761771 | validation: 0.3415718309823253]
	TIME [epoch: 8.51 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4333274182743322		[learning rate: 0.0036231]
	Learning Rate: 0.00362307
	LOSS [training: 0.4333274182743322 | validation: 0.40113671319450617]
	TIME [epoch: 8.52 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46878271932375126		[learning rate: 0.0036145]
	Learning Rate: 0.00361453
	LOSS [training: 0.46878271932375126 | validation: 0.32032076304581747]
	TIME [epoch: 8.54 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46404717570877735		[learning rate: 0.003606]
	Learning Rate: 0.003606
	LOSS [training: 0.46404717570877735 | validation: 0.44686691943716444]
	TIME [epoch: 8.52 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5786338374449198		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.5786338374449198 | validation: 0.4289127079701692]
	TIME [epoch: 8.51 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7235402783395186		[learning rate: 0.003589]
	Learning Rate: 0.00358901
	LOSS [training: 0.7235402783395186 | validation: 0.5537926059267444]
	TIME [epoch: 8.52 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4722065307962605		[learning rate: 0.0035805]
	Learning Rate: 0.00358054
	LOSS [training: 0.4722065307962605 | validation: 0.3041922139440851]
	TIME [epoch: 8.53 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48539183734410807		[learning rate: 0.0035721]
	Learning Rate: 0.0035721
	LOSS [training: 0.48539183734410807 | validation: 0.44855711032057455]
	TIME [epoch: 8.52 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41927122367216746		[learning rate: 0.0035637]
	Learning Rate: 0.00356367
	LOSS [training: 0.41927122367216746 | validation: 0.5302418685189267]
	TIME [epoch: 8.52 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5291125490225206		[learning rate: 0.0035553]
	Learning Rate: 0.00355526
	LOSS [training: 0.5291125490225206 | validation: 0.6690593648558023]
	TIME [epoch: 8.51 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.448220764143192		[learning rate: 0.0035469]
	Learning Rate: 0.00354688
	LOSS [training: 0.448220764143192 | validation: 0.3379505029483145]
	TIME [epoch: 8.52 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5302084055211322		[learning rate: 0.0035385]
	Learning Rate: 0.00353851
	LOSS [training: 0.5302084055211322 | validation: 0.4021074728771902]
	TIME [epoch: 8.55 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4522155887388524		[learning rate: 0.0035302]
	Learning Rate: 0.00353016
	LOSS [training: 0.4522155887388524 | validation: 0.41563865671238953]
	TIME [epoch: 8.52 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8427779178020689		[learning rate: 0.0035218]
	Learning Rate: 0.00352184
	LOSS [training: 0.8427779178020689 | validation: 0.6667177050474495]
	TIME [epoch: 8.52 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7168374967754432		[learning rate: 0.0035135]
	Learning Rate: 0.00351353
	LOSS [training: 0.7168374967754432 | validation: 0.5838946550041995]
	TIME [epoch: 8.52 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4626908604816487		[learning rate: 0.0035052]
	Learning Rate: 0.00350524
	LOSS [training: 0.4626908604816487 | validation: 0.2523343692213756]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_494.pth
	Model improved!!!
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46896080028405207		[learning rate: 0.003497]
	Learning Rate: 0.00349697
	LOSS [training: 0.46896080028405207 | validation: 0.7308987812193446]
	TIME [epoch: 8.53 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5295382080569391		[learning rate: 0.0034887]
	Learning Rate: 0.00348872
	LOSS [training: 0.5295382080569391 | validation: 0.4207189260554689]
	TIME [epoch: 8.52 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45804984180727326		[learning rate: 0.0034805]
	Learning Rate: 0.00348049
	LOSS [training: 0.45804984180727326 | validation: 0.37326108424581506]
	TIME [epoch: 8.52 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6005142965737023		[learning rate: 0.0034723]
	Learning Rate: 0.00347228
	LOSS [training: 0.6005142965737023 | validation: 0.376008221995031]
	TIME [epoch: 8.54 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5525781733667874		[learning rate: 0.0034641]
	Learning Rate: 0.00346409
	LOSS [training: 0.5525781733667874 | validation: 0.7085790772214642]
	TIME [epoch: 8.52 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46843340066188704		[learning rate: 0.0034559]
	Learning Rate: 0.00345592
	LOSS [training: 0.46843340066188704 | validation: 0.26062984226043884]
	TIME [epoch: 8.52 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5041568118397345		[learning rate: 0.0034478]
	Learning Rate: 0.00344777
	LOSS [training: 0.5041568118397345 | validation: 0.3304711107866764]
	TIME [epoch: 8.52 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49662161402142474		[learning rate: 0.0034396]
	Learning Rate: 0.00343964
	LOSS [training: 0.49662161402142474 | validation: 0.4745422197779313]
	TIME [epoch: 8.54 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43812088986768927		[learning rate: 0.0034315]
	Learning Rate: 0.00343152
	LOSS [training: 0.43812088986768927 | validation: 0.3130424462363921]
	TIME [epoch: 8.53 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6365443770750796		[learning rate: 0.0034234]
	Learning Rate: 0.00342343
	LOSS [training: 0.6365443770750796 | validation: 0.51936902911264]
	TIME [epoch: 8.52 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47697475017157664		[learning rate: 0.0034154]
	Learning Rate: 0.00341535
	LOSS [training: 0.47697475017157664 | validation: 0.8261321862472788]
	TIME [epoch: 8.52 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3903297952463827		[learning rate: 0.0034073]
	Learning Rate: 0.0034073
	LOSS [training: 1.3903297952463827 | validation: 0.7729434298931658]
	TIME [epoch: 8.53 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.530453472496706		[learning rate: 0.0033993]
	Learning Rate: 0.00339926
	LOSS [training: 0.530453472496706 | validation: 0.2966416448331221]
	TIME [epoch: 8.54 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5068026113545445		[learning rate: 0.0033912]
	Learning Rate: 0.00339124
	LOSS [training: 0.5068026113545445 | validation: 0.9499409619606636]
	TIME [epoch: 8.52 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6312504272925705		[learning rate: 0.0033832]
	Learning Rate: 0.00338324
	LOSS [training: 0.6312504272925705 | validation: 0.4772552852545776]
	TIME [epoch: 8.52 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5705945737832491		[learning rate: 0.0033753]
	Learning Rate: 0.00337526
	LOSS [training: 0.5705945737832491 | validation: 0.261314155011648]
	TIME [epoch: 8.52 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45902361770302325		[learning rate: 0.0033673]
	Learning Rate: 0.0033673
	LOSS [training: 0.45902361770302325 | validation: 0.4619325841017043]
	TIME [epoch: 8.54 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3928915570041046		[learning rate: 0.0033594]
	Learning Rate: 0.00335936
	LOSS [training: 0.3928915570041046 | validation: 0.637936914825689]
	TIME [epoch: 8.52 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6225617735332251		[learning rate: 0.0033514]
	Learning Rate: 0.00335143
	LOSS [training: 0.6225617735332251 | validation: 0.5790199275247271]
	TIME [epoch: 8.52 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4839836705008403		[learning rate: 0.0033435]
	Learning Rate: 0.00334353
	LOSS [training: 0.4839836705008403 | validation: 0.36079464706632125]
	TIME [epoch: 8.52 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4435090731221645		[learning rate: 0.0033356]
	Learning Rate: 0.00333564
	LOSS [training: 0.4435090731221645 | validation: 0.5169663764484822]
	TIME [epoch: 8.54 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7096920737874106		[learning rate: 0.0033278]
	Learning Rate: 0.00332777
	LOSS [training: 0.7096920737874106 | validation: 0.5515211482046499]
	TIME [epoch: 8.52 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47529725183764615		[learning rate: 0.0033199]
	Learning Rate: 0.00331992
	LOSS [training: 0.47529725183764615 | validation: 0.6666128620386687]
	TIME [epoch: 8.52 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.550899690839717		[learning rate: 0.0033121]
	Learning Rate: 0.00331209
	LOSS [training: 0.550899690839717 | validation: 0.41121199171339107]
	TIME [epoch: 8.51 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4273118644684857		[learning rate: 0.0033043]
	Learning Rate: 0.00330428
	LOSS [training: 0.4273118644684857 | validation: 0.4148111487178249]
	TIME [epoch: 8.54 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46140462319359515		[learning rate: 0.0032965]
	Learning Rate: 0.00329649
	LOSS [training: 0.46140462319359515 | validation: 0.2575882397703143]
	TIME [epoch: 8.52 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45538411525166395		[learning rate: 0.0032887]
	Learning Rate: 0.00328871
	LOSS [training: 0.45538411525166395 | validation: 0.374921633144576]
	TIME [epoch: 8.51 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5385699426386583		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.5385699426386583 | validation: 0.39634066000854223]
	TIME [epoch: 8.51 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5300485514520005		[learning rate: 0.0032732]
	Learning Rate: 0.00327321
	LOSS [training: 0.5300485514520005 | validation: 0.4560067461577327]
	TIME [epoch: 8.52 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7247938048874782		[learning rate: 0.0032655]
	Learning Rate: 0.00326549
	LOSS [training: 0.7247938048874782 | validation: 0.5309002739728927]
	TIME [epoch: 8.53 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4473721572528763		[learning rate: 0.0032578]
	Learning Rate: 0.00325779
	LOSS [training: 0.4473721572528763 | validation: 0.8453144509887773]
	TIME [epoch: 8.52 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6632792474117088		[learning rate: 0.0032501]
	Learning Rate: 0.00325011
	LOSS [training: 0.6632792474117088 | validation: 0.2852052183149467]
	TIME [epoch: 8.51 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3554626972463202		[learning rate: 0.0032424]
	Learning Rate: 0.00324244
	LOSS [training: 0.3554626972463202 | validation: 0.48159820016606236]
	TIME [epoch: 8.51 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5103489310251916		[learning rate: 0.0032348]
	Learning Rate: 0.00323479
	LOSS [training: 0.5103489310251916 | validation: 0.47954994262181366]
	TIME [epoch: 8.54 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.546095181232704		[learning rate: 0.0032272]
	Learning Rate: 0.00322716
	LOSS [training: 0.546095181232704 | validation: 0.4379306623297597]
	TIME [epoch: 8.51 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9687779779604604		[learning rate: 0.0032195]
	Learning Rate: 0.00321955
	LOSS [training: 0.9687779779604604 | validation: 0.3350265694904651]
	TIME [epoch: 8.52 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.362353185171994		[learning rate: 0.003212]
	Learning Rate: 0.00321195
	LOSS [training: 0.362353185171994 | validation: 0.30014450034413087]
	TIME [epoch: 8.51 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38312815885851925		[learning rate: 0.0032044]
	Learning Rate: 0.00320438
	LOSS [training: 0.38312815885851925 | validation: 0.22806302774899379]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_532.pth
	Model improved!!!
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5036463840324434		[learning rate: 0.0031968]
	Learning Rate: 0.00319682
	LOSS [training: 0.5036463840324434 | validation: 0.3005166855689533]
	TIME [epoch: 8.51 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5113259457816585		[learning rate: 0.0031893]
	Learning Rate: 0.00318928
	LOSS [training: 0.5113259457816585 | validation: 0.35073829059765904]
	TIME [epoch: 8.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40726513714796597		[learning rate: 0.0031818]
	Learning Rate: 0.00318175
	LOSS [training: 0.40726513714796597 | validation: 0.43962599626953186]
	TIME [epoch: 8.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44526360826641803		[learning rate: 0.0031742]
	Learning Rate: 0.00317425
	LOSS [training: 0.44526360826641803 | validation: 0.49344555468500517]
	TIME [epoch: 8.52 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5856037640475742		[learning rate: 0.0031668]
	Learning Rate: 0.00316676
	LOSS [training: 0.5856037640475742 | validation: 0.2802668709809875]
	TIME [epoch: 8.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4880729778866117		[learning rate: 0.0031593]
	Learning Rate: 0.00315929
	LOSS [training: 0.4880729778866117 | validation: 0.49329620837478594]
	TIME [epoch: 8.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4127633032548004		[learning rate: 0.0031518]
	Learning Rate: 0.00315184
	LOSS [training: 0.4127633032548004 | validation: 0.41331383612115175]
	TIME [epoch: 8.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4246876205408026		[learning rate: 0.0031444]
	Learning Rate: 0.0031444
	LOSS [training: 0.4246876205408026 | validation: 0.478128575147172]
	TIME [epoch: 8.52 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4420504320962907		[learning rate: 0.003137]
	Learning Rate: 0.00313699
	LOSS [training: 0.4420504320962907 | validation: 0.3525233121179921]
	TIME [epoch: 8.51 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40215111148581945		[learning rate: 0.0031296]
	Learning Rate: 0.00312959
	LOSS [training: 0.40215111148581945 | validation: 0.4876784802949001]
	TIME [epoch: 8.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5400924813452352		[learning rate: 0.0031222]
	Learning Rate: 0.00312221
	LOSS [training: 0.5400924813452352 | validation: 1.0122940021033031]
	TIME [epoch: 8.51 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5499257965691008		[learning rate: 0.0031148]
	Learning Rate: 0.00311484
	LOSS [training: 0.5499257965691008 | validation: 0.34370158208383783]
	TIME [epoch: 8.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4823763591579766		[learning rate: 0.0031075]
	Learning Rate: 0.00310749
	LOSS [training: 0.4823763591579766 | validation: 0.28740420721912346]
	TIME [epoch: 8.53 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5241314556447831		[learning rate: 0.0031002]
	Learning Rate: 0.00310016
	LOSS [training: 0.5241314556447831 | validation: 0.4447843118094698]
	TIME [epoch: 8.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44776787720344136		[learning rate: 0.0030929]
	Learning Rate: 0.00309285
	LOSS [training: 0.44776787720344136 | validation: 0.39953187382678357]
	TIME [epoch: 8.51 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4983021176560472		[learning rate: 0.0030856]
	Learning Rate: 0.00308556
	LOSS [training: 0.4983021176560472 | validation: 0.27850329483785924]
	TIME [epoch: 8.51 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44795661001236137		[learning rate: 0.0030783]
	Learning Rate: 0.00307828
	LOSS [training: 0.44795661001236137 | validation: 0.35008841837843996]
	TIME [epoch: 8.53 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36453041025592425		[learning rate: 0.003071]
	Learning Rate: 0.00307102
	LOSS [training: 0.36453041025592425 | validation: 0.30628433471458827]
	TIME [epoch: 8.51 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3413422189264095		[learning rate: 0.0030638]
	Learning Rate: 0.00306377
	LOSS [training: 0.3413422189264095 | validation: 0.2437513681304147]
	TIME [epoch: 8.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5591113844905488		[learning rate: 0.0030565]
	Learning Rate: 0.00305654
	LOSS [training: 0.5591113844905488 | validation: 0.33380719819667004]
	TIME [epoch: 8.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45601818107506276		[learning rate: 0.0030493]
	Learning Rate: 0.00304933
	LOSS [training: 0.45601818107506276 | validation: 0.3330468093456457]
	TIME [epoch: 8.52 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3934136065157243		[learning rate: 0.0030421]
	Learning Rate: 0.00304214
	LOSS [training: 0.3934136065157243 | validation: 0.3891583658727533]
	TIME [epoch: 8.51 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43916041875400785		[learning rate: 0.003035]
	Learning Rate: 0.00303497
	LOSS [training: 0.43916041875400785 | validation: 0.6145963498519227]
	TIME [epoch: 8.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5257103304860898		[learning rate: 0.0030278]
	Learning Rate: 0.00302781
	LOSS [training: 0.5257103304860898 | validation: 0.49922507864126353]
	TIME [epoch: 8.51 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4547179076435618		[learning rate: 0.0030207]
	Learning Rate: 0.00302066
	LOSS [training: 0.4547179076435618 | validation: 0.2612121673033154]
	TIME [epoch: 8.52 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4431096549016142		[learning rate: 0.0030135]
	Learning Rate: 0.00301354
	LOSS [training: 0.4431096549016142 | validation: 0.542038289596843]
	TIME [epoch: 8.51 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4382176959657804		[learning rate: 0.0030064]
	Learning Rate: 0.00300643
	LOSS [training: 0.4382176959657804 | validation: 0.274249627027448]
	TIME [epoch: 8.51 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4815791034605005		[learning rate: 0.0029993]
	Learning Rate: 0.00299934
	LOSS [training: 0.4815791034605005 | validation: 0.3997355640803858]
	TIME [epoch: 8.51 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3965441731249882		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.3965441731249882 | validation: 0.37680719277301533]
	TIME [epoch: 8.51 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36584326056888783		[learning rate: 0.0029852]
	Learning Rate: 0.00298521
	LOSS [training: 0.36584326056888783 | validation: 0.40165954373445534]
	TIME [epoch: 8.53 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4437897767853884		[learning rate: 0.0029782]
	Learning Rate: 0.00297816
	LOSS [training: 0.4437897767853884 | validation: 0.4287462457502474]
	TIME [epoch: 8.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4062269118201659		[learning rate: 0.0029711]
	Learning Rate: 0.00297114
	LOSS [training: 0.4062269118201659 | validation: 0.7345969903932718]
	TIME [epoch: 8.51 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40662220854725845		[learning rate: 0.0029641]
	Learning Rate: 0.00296413
	LOSS [training: 0.40662220854725845 | validation: 0.49517326269969997]
	TIME [epoch: 8.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5293147391999703		[learning rate: 0.0029571]
	Learning Rate: 0.00295714
	LOSS [training: 0.5293147391999703 | validation: 0.4174044933936143]
	TIME [epoch: 8.53 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3754691436442103		[learning rate: 0.0029502]
	Learning Rate: 0.00295016
	LOSS [training: 0.3754691436442103 | validation: 0.6837322171980147]
	TIME [epoch: 8.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5042060984578145		[learning rate: 0.0029432]
	Learning Rate: 0.0029432
	LOSS [training: 0.5042060984578145 | validation: 0.7266130563507414]
	TIME [epoch: 8.51 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44272151501163837		[learning rate: 0.0029363]
	Learning Rate: 0.00293626
	LOSS [training: 0.44272151501163837 | validation: 0.5248127526704011]
	TIME [epoch: 8.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4145016823124986		[learning rate: 0.0029293]
	Learning Rate: 0.00292934
	LOSS [training: 0.4145016823124986 | validation: 0.42901751941949423]
	TIME [epoch: 8.53 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5138148600161989		[learning rate: 0.0029224]
	Learning Rate: 0.00292243
	LOSS [training: 0.5138148600161989 | validation: 0.2310972409624097]
	TIME [epoch: 8.51 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4409153621964624		[learning rate: 0.0029155]
	Learning Rate: 0.00291553
	LOSS [training: 0.4409153621964624 | validation: 0.3988010213379376]
	TIME [epoch: 8.51 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36710619924278937		[learning rate: 0.0029087]
	Learning Rate: 0.00290866
	LOSS [training: 0.36710619924278937 | validation: 0.3909258133600726]
	TIME [epoch: 8.51 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6440552417158112		[learning rate: 0.0029018]
	Learning Rate: 0.00290179
	LOSS [training: 0.6440552417158112 | validation: 0.35713492719635365]
	TIME [epoch: 8.52 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37554712539234447		[learning rate: 0.0028949]
	Learning Rate: 0.00289495
	LOSS [training: 0.37554712539234447 | validation: 0.4414945362314502]
	TIME [epoch: 8.51 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46561234772616517		[learning rate: 0.0028881]
	Learning Rate: 0.00288812
	LOSS [training: 0.46561234772616517 | validation: 0.3381287906536026]
	TIME [epoch: 8.51 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4201060648091208		[learning rate: 0.0028813]
	Learning Rate: 0.00288131
	LOSS [training: 0.4201060648091208 | validation: 0.29804279823065327]
	TIME [epoch: 8.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4022708839907182		[learning rate: 0.0028745]
	Learning Rate: 0.00287451
	LOSS [training: 0.4022708839907182 | validation: 0.7802979078220385]
	TIME [epoch: 8.51 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45331578401682826		[learning rate: 0.0028677]
	Learning Rate: 0.00286773
	LOSS [training: 0.45331578401682826 | validation: 0.3085803096920402]
	TIME [epoch: 8.53 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.392139904756678		[learning rate: 0.002861]
	Learning Rate: 0.00286097
	LOSS [training: 0.392139904756678 | validation: 0.27928035237702487]
	TIME [epoch: 8.51 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.844594263044474		[learning rate: 0.0028542]
	Learning Rate: 0.00285422
	LOSS [training: 0.844594263044474 | validation: 0.8014870304277684]
	TIME [epoch: 8.51 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5482388079052076		[learning rate: 0.0028475]
	Learning Rate: 0.00284749
	LOSS [training: 0.5482388079052076 | validation: 0.6010954403803627]
	TIME [epoch: 8.51 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5626258359608289		[learning rate: 0.0028408]
	Learning Rate: 0.00284077
	LOSS [training: 0.5626258359608289 | validation: 0.2708207814804615]
	TIME [epoch: 8.53 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48367341166450767		[learning rate: 0.0028341]
	Learning Rate: 0.00283407
	LOSS [training: 0.48367341166450767 | validation: 0.5352156903769736]
	TIME [epoch: 8.51 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5995806484871646		[learning rate: 0.0028274]
	Learning Rate: 0.00282738
	LOSS [training: 0.5995806484871646 | validation: 0.4236651313923069]
	TIME [epoch: 8.51 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45511210101729527		[learning rate: 0.0028207]
	Learning Rate: 0.00282071
	LOSS [training: 0.45511210101729527 | validation: 0.3830192836627507]
	TIME [epoch: 8.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4153113484129469		[learning rate: 0.0028141]
	Learning Rate: 0.00281406
	LOSS [training: 0.4153113484129469 | validation: 0.30771797054138195]
	TIME [epoch: 8.53 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3575861347555865		[learning rate: 0.0028074]
	Learning Rate: 0.00280742
	LOSS [training: 0.3575861347555865 | validation: 0.27097702279446123]
	TIME [epoch: 8.51 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4200481851875352		[learning rate: 0.0028008]
	Learning Rate: 0.0028008
	LOSS [training: 0.4200481851875352 | validation: 0.23042969106232078]
	TIME [epoch: 8.51 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4803690208690095		[learning rate: 0.0027942]
	Learning Rate: 0.00279419
	LOSS [training: 0.4803690208690095 | validation: 0.29282572073968616]
	TIME [epoch: 8.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4539608872937106		[learning rate: 0.0027876]
	Learning Rate: 0.0027876
	LOSS [training: 0.4539608872937106 | validation: 0.31433538657995885]
	TIME [epoch: 8.52 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4170556675172542		[learning rate: 0.002781]
	Learning Rate: 0.00278103
	LOSS [training: 0.4170556675172542 | validation: 0.6800979187425638]
	TIME [epoch: 8.51 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6679659443502979		[learning rate: 0.0027745]
	Learning Rate: 0.00277447
	LOSS [training: 0.6679659443502979 | validation: 0.4599974075281208]
	TIME [epoch: 8.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4672339385935024		[learning rate: 0.0027679]
	Learning Rate: 0.00276792
	LOSS [training: 0.4672339385935024 | validation: 0.4681596806386553]
	TIME [epoch: 8.51 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41412297617630395		[learning rate: 0.0027614]
	Learning Rate: 0.00276139
	LOSS [training: 0.41412297617630395 | validation: 0.3605349112827312]
	TIME [epoch: 8.51 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41564182348343753		[learning rate: 0.0027549]
	Learning Rate: 0.00275488
	LOSS [training: 0.41564182348343753 | validation: 0.5113171105697365]
	TIME [epoch: 8.54 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48930355742604253		[learning rate: 0.0027484]
	Learning Rate: 0.00274838
	LOSS [training: 0.48930355742604253 | validation: 0.49040364002143083]
	TIME [epoch: 8.51 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44225428601307115		[learning rate: 0.0027419]
	Learning Rate: 0.0027419
	LOSS [training: 0.44225428601307115 | validation: 0.41754035456036975]
	TIME [epoch: 8.51 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3739235907668		[learning rate: 0.0027354]
	Learning Rate: 0.00273543
	LOSS [training: 0.3739235907668 | validation: 0.30665320065235946]
	TIME [epoch: 8.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39697896099539837		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.39697896099539837 | validation: 0.6499862836166753]
	TIME [epoch: 8.53 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5391837575717671		[learning rate: 0.0027225]
	Learning Rate: 0.00272254
	LOSS [training: 0.5391837575717671 | validation: 0.3241274613970519]
	TIME [epoch: 8.51 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45997055164676165		[learning rate: 0.0027161]
	Learning Rate: 0.00271612
	LOSS [training: 0.45997055164676165 | validation: 0.4231219750242156]
	TIME [epoch: 8.51 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4549552678608646		[learning rate: 0.0027097]
	Learning Rate: 0.00270971
	LOSS [training: 0.4549552678608646 | validation: 0.4573131871410472]
	TIME [epoch: 8.51 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3913831081767843		[learning rate: 0.0027033]
	Learning Rate: 0.00270332
	LOSS [training: 0.3913831081767843 | validation: 0.3703995215749345]
	TIME [epoch: 8.53 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3223197577011543		[learning rate: 0.0026969]
	Learning Rate: 0.00269694
	LOSS [training: 0.3223197577011543 | validation: 0.31396894635091094]
	TIME [epoch: 8.51 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5546681908890995		[learning rate: 0.0026906]
	Learning Rate: 0.00269058
	LOSS [training: 0.5546681908890995 | validation: 0.4275600509055678]
	TIME [epoch: 8.51 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4684534149145342		[learning rate: 0.0026842]
	Learning Rate: 0.00268423
	LOSS [training: 0.4684534149145342 | validation: 0.24177333185775893]
	TIME [epoch: 8.51 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37608608689744255		[learning rate: 0.0026779]
	Learning Rate: 0.0026779
	LOSS [training: 0.37608608689744255 | validation: 0.8014297390354177]
	TIME [epoch: 8.53 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39221253267640965		[learning rate: 0.0026716]
	Learning Rate: 0.00267159
	LOSS [training: 0.39221253267640965 | validation: 0.4221826457522561]
	TIME [epoch: 8.51 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4966380608837171		[learning rate: 0.0026653]
	Learning Rate: 0.00266528
	LOSS [training: 0.4966380608837171 | validation: 0.2577782049280091]
	TIME [epoch: 8.51 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4346390985993042		[learning rate: 0.002659]
	Learning Rate: 0.002659
	LOSS [training: 0.4346390985993042 | validation: 0.5874918669795604]
	TIME [epoch: 8.51 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4512533440192293		[learning rate: 0.0026527]
	Learning Rate: 0.00265273
	LOSS [training: 0.4512533440192293 | validation: 0.27380588379048865]
	TIME [epoch: 8.51 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35748961243325017		[learning rate: 0.0026465]
	Learning Rate: 0.00264647
	LOSS [training: 0.35748961243325017 | validation: 0.33126563099424966]
	TIME [epoch: 8.53 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40879980040710084		[learning rate: 0.0026402]
	Learning Rate: 0.00264023
	LOSS [training: 0.40879980040710084 | validation: 0.25143121821632824]
	TIME [epoch: 8.51 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41270561408093237		[learning rate: 0.002634]
	Learning Rate: 0.002634
	LOSS [training: 0.41270561408093237 | validation: 0.6332991472833331]
	TIME [epoch: 8.51 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4457512449807113		[learning rate: 0.0026278]
	Learning Rate: 0.00262778
	LOSS [training: 0.4457512449807113 | validation: 0.3799516565696754]
	TIME [epoch: 8.51 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4806854824523543		[learning rate: 0.0026216]
	Learning Rate: 0.00262159
	LOSS [training: 0.4806854824523543 | validation: 0.34805607143894707]
	TIME [epoch: 8.52 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.362574898966714		[learning rate: 0.0026154]
	Learning Rate: 0.0026154
	LOSS [training: 0.362574898966714 | validation: 0.3223729418474198]
	TIME [epoch: 8.51 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5556148583909976		[learning rate: 0.0026092]
	Learning Rate: 0.00260923
	LOSS [training: 0.5556148583909976 | validation: 0.5503801836339016]
	TIME [epoch: 8.51 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4347547217887711		[learning rate: 0.0026031]
	Learning Rate: 0.00260308
	LOSS [training: 0.4347547217887711 | validation: 0.32609258716173695]
	TIME [epoch: 8.51 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3993722143268564		[learning rate: 0.0025969]
	Learning Rate: 0.00259694
	LOSS [training: 0.3993722143268564 | validation: 0.5882844652792732]
	TIME [epoch: 8.53 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4744363703877387		[learning rate: 0.0025908]
	Learning Rate: 0.00259081
	LOSS [training: 0.4744363703877387 | validation: 0.2776137412129964]
	TIME [epoch: 8.51 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3104028184849673		[learning rate: 0.0025847]
	Learning Rate: 0.0025847
	LOSS [training: 0.3104028184849673 | validation: 0.5491493951512343]
	TIME [epoch: 8.51 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5436802534140628		[learning rate: 0.0025786]
	Learning Rate: 0.0025786
	LOSS [training: 0.5436802534140628 | validation: 0.44309975301070764]
	TIME [epoch: 8.51 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5455015193736162		[learning rate: 0.0025725]
	Learning Rate: 0.00257252
	LOSS [training: 0.5455015193736162 | validation: 0.3115530293299438]
	TIME [epoch: 8.53 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44882433366724994		[learning rate: 0.0025665]
	Learning Rate: 0.00256645
	LOSS [training: 0.44882433366724994 | validation: 0.8552447869521148]
	TIME [epoch: 8.52 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4677314018801729		[learning rate: 0.0025604]
	Learning Rate: 0.0025604
	LOSS [training: 0.4677314018801729 | validation: 0.30202621992821355]
	TIME [epoch: 8.51 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37173170242375897		[learning rate: 0.0025544]
	Learning Rate: 0.00255436
	LOSS [training: 0.37173170242375897 | validation: 0.39425432345534583]
	TIME [epoch: 8.51 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3998863237018454		[learning rate: 0.0025483]
	Learning Rate: 0.00254833
	LOSS [training: 0.3998863237018454 | validation: 0.24073616613216509]
	TIME [epoch: 8.51 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40091636926235896		[learning rate: 0.0025423]
	Learning Rate: 0.00254232
	LOSS [training: 0.40091636926235896 | validation: 0.27401271368931657]
	TIME [epoch: 8.53 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5376950768073954		[learning rate: 0.0025363]
	Learning Rate: 0.00253633
	LOSS [training: 0.5376950768073954 | validation: 0.35033793059851925]
	TIME [epoch: 8.51 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34373510007888697		[learning rate: 0.0025303]
	Learning Rate: 0.00253034
	LOSS [training: 0.34373510007888697 | validation: 0.2619454268542488]
	TIME [epoch: 8.51 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41771785558877045		[learning rate: 0.0025244]
	Learning Rate: 0.00252437
	LOSS [training: 0.41771785558877045 | validation: 0.4148860475646716]
	TIME [epoch: 8.51 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4020445904811072		[learning rate: 0.0025184]
	Learning Rate: 0.00251842
	LOSS [training: 0.4020445904811072 | validation: 0.380159462192903]
	TIME [epoch: 8.53 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33396592308683004		[learning rate: 0.0025125]
	Learning Rate: 0.00251248
	LOSS [training: 0.33396592308683004 | validation: 0.38344565325932767]
	TIME [epoch: 8.51 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35196933244818057		[learning rate: 0.0025066]
	Learning Rate: 0.00250655
	LOSS [training: 0.35196933244818057 | validation: 0.2535224431739169]
	TIME [epoch: 8.51 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5800624187220617		[learning rate: 0.0025006]
	Learning Rate: 0.00250064
	LOSS [training: 0.5800624187220617 | validation: 0.8470598491112773]
	TIME [epoch: 8.51 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6096597303451571		[learning rate: 0.0024947]
	Learning Rate: 0.00249474
	LOSS [training: 0.6096597303451571 | validation: 0.4403139129298749]
	TIME [epoch: 8.53 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6803974060929334		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.6803974060929334 | validation: 0.5143248486986328]
	TIME [epoch: 8.53 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6220085126554138		[learning rate: 0.002483]
	Learning Rate: 0.00248299
	LOSS [training: 0.6220085126554138 | validation: 0.5058504673680304]
	TIME [epoch: 8.51 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3967252754716054		[learning rate: 0.0024771]
	Learning Rate: 0.00247713
	LOSS [training: 0.3967252754716054 | validation: 0.39388835982009673]
	TIME [epoch: 8.51 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43052905265649066		[learning rate: 0.0024713]
	Learning Rate: 0.00247129
	LOSS [training: 0.43052905265649066 | validation: 0.5768525339768014]
	TIME [epoch: 8.52 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37952909068699936		[learning rate: 0.0024655]
	Learning Rate: 0.00246546
	LOSS [training: 0.37952909068699936 | validation: 0.3940279213275143]
	TIME [epoch: 8.51 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35187549137938895		[learning rate: 0.0024596]
	Learning Rate: 0.00245964
	LOSS [training: 0.35187549137938895 | validation: 0.2396704181230822]
	TIME [epoch: 8.51 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3699077343023108		[learning rate: 0.0024538]
	Learning Rate: 0.00245384
	LOSS [training: 0.3699077343023108 | validation: 0.30519204019306057]
	TIME [epoch: 8.51 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34628623684119997		[learning rate: 0.0024481]
	Learning Rate: 0.00244805
	LOSS [training: 0.34628623684119997 | validation: 0.34974402471430466]
	TIME [epoch: 8.51 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4016872638441318		[learning rate: 0.0024423]
	Learning Rate: 0.00244228
	LOSS [training: 0.4016872638441318 | validation: 0.3468581315482008]
	TIME [epoch: 8.53 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3363760659510998		[learning rate: 0.0024365]
	Learning Rate: 0.00243652
	LOSS [training: 0.3363760659510998 | validation: 0.33200215004782396]
	TIME [epoch: 8.51 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4332848316918267		[learning rate: 0.0024308]
	Learning Rate: 0.00243077
	LOSS [training: 0.4332848316918267 | validation: 0.31534839119546587]
	TIME [epoch: 8.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3211968043643813		[learning rate: 0.002425]
	Learning Rate: 0.00242503
	LOSS [training: 0.3211968043643813 | validation: 0.2618876554701257]
	TIME [epoch: 8.51 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4100506377006089		[learning rate: 0.0024193]
	Learning Rate: 0.00241931
	LOSS [training: 0.4100506377006089 | validation: 0.29977430435660746]
	TIME [epoch: 8.53 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36301381386407555		[learning rate: 0.0024136]
	Learning Rate: 0.00241361
	LOSS [training: 0.36301381386407555 | validation: 0.44470359303998974]
	TIME [epoch: 8.51 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5177689021160694		[learning rate: 0.0024079]
	Learning Rate: 0.00240791
	LOSS [training: 0.5177689021160694 | validation: 0.6048019451484656]
	TIME [epoch: 8.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4191961413966635		[learning rate: 0.0024022]
	Learning Rate: 0.00240223
	LOSS [training: 0.4191961413966635 | validation: 0.43807710992877585]
	TIME [epoch: 8.51 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36489741770405015		[learning rate: 0.0023966]
	Learning Rate: 0.00239657
	LOSS [training: 0.36489741770405015 | validation: 0.37586582024808923]
	TIME [epoch: 8.53 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41797095219456637		[learning rate: 0.0023909]
	Learning Rate: 0.00239092
	LOSS [training: 0.41797095219456637 | validation: 0.2459855964640109]
	TIME [epoch: 8.51 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3953470446119702		[learning rate: 0.0023853]
	Learning Rate: 0.00238527
	LOSS [training: 0.3953470446119702 | validation: 0.31861285191868227]
	TIME [epoch: 8.51 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40503874454970595		[learning rate: 0.0023796]
	Learning Rate: 0.00237965
	LOSS [training: 0.40503874454970595 | validation: 0.33715983631715524]
	TIME [epoch: 8.51 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3182866257737649		[learning rate: 0.002374]
	Learning Rate: 0.00237404
	LOSS [training: 0.3182866257737649 | validation: 0.2918818323031678]
	TIME [epoch: 8.52 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3573235537611725		[learning rate: 0.0023684]
	Learning Rate: 0.00236844
	LOSS [training: 0.3573235537611725 | validation: 0.3436740235710929]
	TIME [epoch: 8.51 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.313806768003403		[learning rate: 0.0023628]
	Learning Rate: 0.00236285
	LOSS [training: 0.313806768003403 | validation: 0.3401903942981152]
	TIME [epoch: 8.51 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33072144968735817		[learning rate: 0.0023573]
	Learning Rate: 0.00235727
	LOSS [training: 0.33072144968735817 | validation: 0.2774908638169174]
	TIME [epoch: 8.51 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34372083676922616		[learning rate: 0.0023517]
	Learning Rate: 0.00235171
	LOSS [training: 0.34372083676922616 | validation: 0.41766762617450154]
	TIME [epoch: 8.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.318475914096651		[learning rate: 0.0023462]
	Learning Rate: 0.00234617
	LOSS [training: 0.318475914096651 | validation: 0.23639548887008993]
	TIME [epoch: 8.53 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4156510822893103		[learning rate: 0.0023406]
	Learning Rate: 0.00234063
	LOSS [training: 0.4156510822893103 | validation: 0.449573579221203]
	TIME [epoch: 8.51 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3224327642695167		[learning rate: 0.0023351]
	Learning Rate: 0.00233511
	LOSS [training: 0.3224327642695167 | validation: 0.39630467394145275]
	TIME [epoch: 8.51 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.302958545318016		[learning rate: 0.0023296]
	Learning Rate: 0.0023296
	LOSS [training: 0.302958545318016 | validation: 0.5060326993917558]
	TIME [epoch: 8.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4104176138124215		[learning rate: 0.0023241]
	Learning Rate: 0.00232411
	LOSS [training: 0.4104176138124215 | validation: 0.2266474117197117]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_668.pth
	Model improved!!!
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30692454751200693		[learning rate: 0.0023186]
	Learning Rate: 0.00231863
	LOSS [training: 0.30692454751200693 | validation: 0.31142945341296313]
	TIME [epoch: 8.51 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3436013972627946		[learning rate: 0.0023132]
	Learning Rate: 0.00231316
	LOSS [training: 0.3436013972627946 | validation: 0.32874816034781507]
	TIME [epoch: 8.51 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36840936518395806		[learning rate: 0.0023077]
	Learning Rate: 0.0023077
	LOSS [training: 0.36840936518395806 | validation: 0.407383279321368]
	TIME [epoch: 8.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38091707446779577		[learning rate: 0.0023023]
	Learning Rate: 0.00230226
	LOSS [training: 0.38091707446779577 | validation: 0.1918563893859174]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_672.pth
	Model improved!!!
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31549969334522643		[learning rate: 0.0022968]
	Learning Rate: 0.00229683
	LOSS [training: 0.31549969334522643 | validation: 0.29267074018205497]
	TIME [epoch: 8.51 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43295971901326114		[learning rate: 0.0022914]
	Learning Rate: 0.00229141
	LOSS [training: 0.43295971901326114 | validation: 0.44814117179464785]
	TIME [epoch: 8.51 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5463866036070312		[learning rate: 0.002286]
	Learning Rate: 0.002286
	LOSS [training: 0.5463866036070312 | validation: 0.47048711399533605]
	TIME [epoch: 8.51 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4653834259392526		[learning rate: 0.0022806]
	Learning Rate: 0.00228061
	LOSS [training: 0.4653834259392526 | validation: 0.3027262176412244]
	TIME [epoch: 8.52 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37820357928661624		[learning rate: 0.0022752]
	Learning Rate: 0.00227523
	LOSS [training: 0.37820357928661624 | validation: 0.2510569365597135]
	TIME [epoch: 8.51 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29635564199077835		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.29635564199077835 | validation: 0.19899242049163732]
	TIME [epoch: 8.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33451995593047157		[learning rate: 0.0022645]
	Learning Rate: 0.00226451
	LOSS [training: 0.33451995593047157 | validation: 0.3759398304356141]
	TIME [epoch: 8.51 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35548536368630684		[learning rate: 0.0022592]
	Learning Rate: 0.00225917
	LOSS [training: 0.35548536368630684 | validation: 0.40084940853538165]
	TIME [epoch: 8.51 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3249716486255609		[learning rate: 0.0022538]
	Learning Rate: 0.00225384
	LOSS [training: 0.3249716486255609 | validation: 0.2843391941885554]
	TIME [epoch: 8.52 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48281266711655035		[learning rate: 0.0022485]
	Learning Rate: 0.00224852
	LOSS [training: 0.48281266711655035 | validation: 0.40475664394197164]
	TIME [epoch: 8.51 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35663253552594465		[learning rate: 0.0022432]
	Learning Rate: 0.00224322
	LOSS [training: 0.35663253552594465 | validation: 0.5716866597536516]
	TIME [epoch: 8.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4098884778533053		[learning rate: 0.0022379]
	Learning Rate: 0.00223793
	LOSS [training: 0.4098884778533053 | validation: 0.2676954421327906]
	TIME [epoch: 8.51 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3604049454260189		[learning rate: 0.0022326]
	Learning Rate: 0.00223265
	LOSS [training: 0.3604049454260189 | validation: 0.3313847650496228]
	TIME [epoch: 8.53 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2927899571236385		[learning rate: 0.0022274]
	Learning Rate: 0.00222738
	LOSS [training: 0.2927899571236385 | validation: 0.32025684142714306]
	TIME [epoch: 8.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2933879243212128		[learning rate: 0.0022221]
	Learning Rate: 0.00222213
	LOSS [training: 0.2933879243212128 | validation: 0.2901505586306202]
	TIME [epoch: 8.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2780787035911564		[learning rate: 0.0022169]
	Learning Rate: 0.00221689
	LOSS [training: 0.2780787035911564 | validation: 0.5491049566621483]
	TIME [epoch: 8.51 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42361009695041363		[learning rate: 0.0022117]
	Learning Rate: 0.00221166
	LOSS [training: 0.42361009695041363 | validation: 0.23483865908573062]
	TIME [epoch: 8.53 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3407376397943538		[learning rate: 0.0022064]
	Learning Rate: 0.00220644
	LOSS [training: 0.3407376397943538 | validation: 0.31974502672601307]
	TIME [epoch: 8.51 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30389137115943643		[learning rate: 0.0022012]
	Learning Rate: 0.00220124
	LOSS [training: 0.30389137115943643 | validation: 0.2759105084021689]
	TIME [epoch: 8.51 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2730186863240445		[learning rate: 0.002196]
	Learning Rate: 0.00219604
	LOSS [training: 0.2730186863240445 | validation: 0.24396180905760154]
	TIME [epoch: 8.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2827841321190197		[learning rate: 0.0021909]
	Learning Rate: 0.00219086
	LOSS [training: 0.2827841321190197 | validation: 0.21058189095118252]
	TIME [epoch: 8.52 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3303387801224063		[learning rate: 0.0021857]
	Learning Rate: 0.0021857
	LOSS [training: 0.3303387801224063 | validation: 0.2389796317922715]
	TIME [epoch: 8.51 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38672932707266383		[learning rate: 0.0021805]
	Learning Rate: 0.00218054
	LOSS [training: 0.38672932707266383 | validation: 0.40257949404479176]
	TIME [epoch: 8.51 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42710102197520794		[learning rate: 0.0021754]
	Learning Rate: 0.0021754
	LOSS [training: 0.42710102197520794 | validation: 0.3151346865213779]
	TIME [epoch: 8.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3969494140077552		[learning rate: 0.0021703]
	Learning Rate: 0.00217027
	LOSS [training: 0.3969494140077552 | validation: 0.28539069396131106]
	TIME [epoch: 8.51 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44143275402548465		[learning rate: 0.0021651]
	Learning Rate: 0.00216515
	LOSS [training: 0.44143275402548465 | validation: 0.32493985987540874]
	TIME [epoch: 8.52 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27431245379408964		[learning rate: 0.00216]
	Learning Rate: 0.00216004
	LOSS [training: 0.27431245379408964 | validation: 0.29092003248788123]
	TIME [epoch: 8.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36704597657574345		[learning rate: 0.0021549]
	Learning Rate: 0.00215494
	LOSS [training: 0.36704597657574345 | validation: 0.38540799552742644]
	TIME [epoch: 8.51 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32511791905603227		[learning rate: 0.0021499]
	Learning Rate: 0.00214986
	LOSS [training: 0.32511791905603227 | validation: 0.3834772398438574]
	TIME [epoch: 8.51 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3261328010694432		[learning rate: 0.0021448]
	Learning Rate: 0.00214479
	LOSS [training: 0.3261328010694432 | validation: 0.8727540136923655]
	TIME [epoch: 8.53 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5036345480759852		[learning rate: 0.0021397]
	Learning Rate: 0.00213973
	LOSS [training: 0.5036345480759852 | validation: 0.39196646200537444]
	TIME [epoch: 8.51 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40776403879293044		[learning rate: 0.0021347]
	Learning Rate: 0.00213468
	LOSS [training: 0.40776403879293044 | validation: 0.30079684590542033]
	TIME [epoch: 8.51 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33573614443709593		[learning rate: 0.0021296]
	Learning Rate: 0.00212965
	LOSS [training: 0.33573614443709593 | validation: 0.20394214452901782]
	TIME [epoch: 8.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34655335776283014		[learning rate: 0.0021246]
	Learning Rate: 0.00212462
	LOSS [training: 0.34655335776283014 | validation: 0.29799377216580214]
	TIME [epoch: 8.53 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30454592505953676		[learning rate: 0.0021196]
	Learning Rate: 0.00211961
	LOSS [training: 0.30454592505953676 | validation: 0.23732220569636012]
	TIME [epoch: 8.51 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3914328445910269		[learning rate: 0.0021146]
	Learning Rate: 0.00211461
	LOSS [training: 0.3914328445910269 | validation: 0.3757370819832064]
	TIME [epoch: 8.49 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3664474051269423		[learning rate: 0.0021096]
	Learning Rate: 0.00210962
	LOSS [training: 0.3664474051269423 | validation: 0.2755710122296773]
	TIME [epoch: 8.51 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30449700796287144		[learning rate: 0.0021046]
	Learning Rate: 0.00210465
	LOSS [training: 0.30449700796287144 | validation: 0.2766279773629358]
	TIME [epoch: 8.52 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35424567617265257		[learning rate: 0.0020997]
	Learning Rate: 0.00209968
	LOSS [training: 0.35424567617265257 | validation: 0.20792916379026652]
	TIME [epoch: 8.51 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3576260544687202		[learning rate: 0.0020947]
	Learning Rate: 0.00209473
	LOSS [training: 0.3576260544687202 | validation: 0.44964949332876747]
	TIME [epoch: 8.51 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3341977424850696		[learning rate: 0.0020898]
	Learning Rate: 0.00208979
	LOSS [training: 0.3341977424850696 | validation: 0.3245711730962769]
	TIME [epoch: 8.5 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40036157104978515		[learning rate: 0.0020849]
	Learning Rate: 0.00208486
	LOSS [training: 0.40036157104978515 | validation: 0.26597623086552136]
	TIME [epoch: 8.52 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3016415593861263		[learning rate: 0.0020799]
	Learning Rate: 0.00207994
	LOSS [training: 0.3016415593861263 | validation: 0.379864170512766]
	TIME [epoch: 8.52 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3422835769425249		[learning rate: 0.002075]
	Learning Rate: 0.00207504
	LOSS [training: 0.3422835769425249 | validation: 0.20922501464709348]
	TIME [epoch: 8.51 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34235012833488165		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.34235012833488165 | validation: 0.2510964588446897]
	TIME [epoch: 8.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28598380983645055		[learning rate: 0.0020653]
	Learning Rate: 0.00206526
	LOSS [training: 0.28598380983645055 | validation: 0.24450492902548002]
	TIME [epoch: 8.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3429658587408591		[learning rate: 0.0020604]
	Learning Rate: 0.00206039
	LOSS [training: 0.3429658587408591 | validation: 0.5281816055160786]
	TIME [epoch: 8.53 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3732585287906415		[learning rate: 0.0020555]
	Learning Rate: 0.00205553
	LOSS [training: 0.3732585287906415 | validation: 0.30282958375553204]
	TIME [epoch: 8.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3167795431035061		[learning rate: 0.0020507]
	Learning Rate: 0.00205068
	LOSS [training: 0.3167795431035061 | validation: 0.5354081974435236]
	TIME [epoch: 8.51 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3484345921918931		[learning rate: 0.0020458]
	Learning Rate: 0.00204584
	LOSS [training: 0.3484345921918931 | validation: 0.2998278431687904]
	TIME [epoch: 8.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32300268412816335		[learning rate: 0.002041]
	Learning Rate: 0.00204101
	LOSS [training: 0.32300268412816335 | validation: 0.4525057384197714]
	TIME [epoch: 8.53 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43731390647699264		[learning rate: 0.0020362]
	Learning Rate: 0.0020362
	LOSS [training: 0.43731390647699264 | validation: 0.3268575649367833]
	TIME [epoch: 8.51 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39155094326193335		[learning rate: 0.0020314]
	Learning Rate: 0.0020314
	LOSS [training: 0.39155094326193335 | validation: 0.27571136276989233]
	TIME [epoch: 8.51 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31100036607681114		[learning rate: 0.0020266]
	Learning Rate: 0.00202661
	LOSS [training: 0.31100036607681114 | validation: 0.2899183715989049]
	TIME [epoch: 8.51 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3070050491157102		[learning rate: 0.0020218]
	Learning Rate: 0.00202182
	LOSS [training: 0.3070050491157102 | validation: 0.36460842669310123]
	TIME [epoch: 8.52 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31210358877814237		[learning rate: 0.0020171]
	Learning Rate: 0.00201706
	LOSS [training: 0.31210358877814237 | validation: 0.29455822336744175]
	TIME [epoch: 8.51 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3115242627878125		[learning rate: 0.0020123]
	Learning Rate: 0.0020123
	LOSS [training: 0.3115242627878125 | validation: 0.2587554790723103]
	TIME [epoch: 8.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3736423869683312		[learning rate: 0.0020076]
	Learning Rate: 0.00200755
	LOSS [training: 0.3736423869683312 | validation: 0.255913022951334]
	TIME [epoch: 8.51 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29632330817405356		[learning rate: 0.0020028]
	Learning Rate: 0.00200282
	LOSS [training: 0.29632330817405356 | validation: 0.5384271993022339]
	TIME [epoch: 8.51 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42715683656728043		[learning rate: 0.0019981]
	Learning Rate: 0.00199809
	LOSS [training: 0.42715683656728043 | validation: 0.24820730748683367]
	TIME [epoch: 8.52 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35564276701432196		[learning rate: 0.0019934]
	Learning Rate: 0.00199338
	LOSS [training: 0.35564276701432196 | validation: 0.36964649280192946]
	TIME [epoch: 8.51 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3243689894653322		[learning rate: 0.0019887]
	Learning Rate: 0.00198868
	LOSS [training: 0.3243689894653322 | validation: 0.1913139889941496]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_734.pth
	Model improved!!!
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31511925362407733		[learning rate: 0.001984]
	Learning Rate: 0.00198399
	LOSS [training: 0.31511925362407733 | validation: 0.2126780233345812]
	TIME [epoch: 8.51 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3269264128532969		[learning rate: 0.0019793]
	Learning Rate: 0.00197931
	LOSS [training: 0.3269264128532969 | validation: 0.3095099265452128]
	TIME [epoch: 8.52 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3183779238814847		[learning rate: 0.0019746]
	Learning Rate: 0.00197464
	LOSS [training: 0.3183779238814847 | validation: 0.3047967806224745]
	TIME [epoch: 8.51 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3139028192916541		[learning rate: 0.00197]
	Learning Rate: 0.00196998
	LOSS [training: 0.3139028192916541 | validation: 0.30984633310951826]
	TIME [epoch: 8.51 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3509421577262789		[learning rate: 0.0019653]
	Learning Rate: 0.00196533
	LOSS [training: 0.3509421577262789 | validation: 0.2796683093022245]
	TIME [epoch: 8.51 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2856712545402543		[learning rate: 0.0019607]
	Learning Rate: 0.0019607
	LOSS [training: 0.2856712545402543 | validation: 0.5198052942713608]
	TIME [epoch: 8.52 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33229664584982727		[learning rate: 0.0019561]
	Learning Rate: 0.00195607
	LOSS [training: 0.33229664584982727 | validation: 0.20805909931068617]
	TIME [epoch: 8.51 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2632513611044488		[learning rate: 0.0019515]
	Learning Rate: 0.00195146
	LOSS [training: 0.2632513611044488 | validation: 0.16845161832234057]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_742.pth
	Model improved!!!
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2576019951816441		[learning rate: 0.0019469]
	Learning Rate: 0.00194685
	LOSS [training: 0.2576019951816441 | validation: 0.3527660033833069]
	TIME [epoch: 8.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2894214700855414		[learning rate: 0.0019423]
	Learning Rate: 0.00194226
	LOSS [training: 0.2894214700855414 | validation: 0.3766866979645803]
	TIME [epoch: 8.53 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33367629274421706		[learning rate: 0.0019377]
	Learning Rate: 0.00193768
	LOSS [training: 0.33367629274421706 | validation: 0.2361420227685764]
	TIME [epoch: 8.51 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23720962293878153		[learning rate: 0.0019331]
	Learning Rate: 0.00193311
	LOSS [training: 0.23720962293878153 | validation: 0.294275459985772]
	TIME [epoch: 8.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26359353969172283		[learning rate: 0.0019285]
	Learning Rate: 0.00192855
	LOSS [training: 0.26359353969172283 | validation: 0.3100972774381888]
	TIME [epoch: 8.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4121367898629624		[learning rate: 0.001924]
	Learning Rate: 0.001924
	LOSS [training: 0.4121367898629624 | validation: 0.2767365107243018]
	TIME [epoch: 8.52 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2611854660050994		[learning rate: 0.0019195]
	Learning Rate: 0.00191946
	LOSS [training: 0.2611854660050994 | validation: 0.24029404775557958]
	TIME [epoch: 8.51 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2556122386952132		[learning rate: 0.0019149]
	Learning Rate: 0.00191493
	LOSS [training: 0.2556122386952132 | validation: 0.26424286083439386]
	TIME [epoch: 8.51 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29170552771692043		[learning rate: 0.0019104]
	Learning Rate: 0.00191042
	LOSS [training: 0.29170552771692043 | validation: 0.35368118512370184]
	TIME [epoch: 8.51 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4079036294798968		[learning rate: 0.0019059]
	Learning Rate: 0.00190591
	LOSS [training: 0.4079036294798968 | validation: 0.45049218818542475]
	TIME [epoch: 8.51 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3188087379491909		[learning rate: 0.0019014]
	Learning Rate: 0.00190141
	LOSS [training: 0.3188087379491909 | validation: 0.25386790088199085]
	TIME [epoch: 8.52 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3072823316111352		[learning rate: 0.0018969]
	Learning Rate: 0.00189693
	LOSS [training: 0.3072823316111352 | validation: 0.1950093623400449]
	TIME [epoch: 8.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31257418252055447		[learning rate: 0.0018925]
	Learning Rate: 0.00189246
	LOSS [training: 0.31257418252055447 | validation: 0.3039156745600873]
	TIME [epoch: 8.51 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32126199084195206		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.32126199084195206 | validation: 0.444937869217661]
	TIME [epoch: 8.51 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38309434145551224		[learning rate: 0.0018835]
	Learning Rate: 0.00188354
	LOSS [training: 0.38309434145551224 | validation: 0.2778393190721339]
	TIME [epoch: 8.52 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29304682767262746		[learning rate: 0.0018791]
	Learning Rate: 0.00187909
	LOSS [training: 0.29304682767262746 | validation: 0.2214951672202975]
	TIME [epoch: 8.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2520624851500264		[learning rate: 0.0018747]
	Learning Rate: 0.00187466
	LOSS [training: 0.2520624851500264 | validation: 0.20278727470370805]
	TIME [epoch: 8.51 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25308146381583835		[learning rate: 0.0018702]
	Learning Rate: 0.00187024
	LOSS [training: 0.25308146381583835 | validation: 0.2007066394108212]
	TIME [epoch: 8.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32455805436411483		[learning rate: 0.0018658]
	Learning Rate: 0.00186583
	LOSS [training: 0.32455805436411483 | validation: 0.22707489486112692]
	TIME [epoch: 8.52 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3202496357163132		[learning rate: 0.0018614]
	Learning Rate: 0.00186143
	LOSS [training: 0.3202496357163132 | validation: 0.2333615340684476]
	TIME [epoch: 8.51 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34074001903159823		[learning rate: 0.001857]
	Learning Rate: 0.00185704
	LOSS [training: 0.34074001903159823 | validation: 0.2150008967335487]
	TIME [epoch: 8.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3078460722706756		[learning rate: 0.0018527]
	Learning Rate: 0.00185266
	LOSS [training: 0.3078460722706756 | validation: 0.30400782253717096]
	TIME [epoch: 8.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3120059315749974		[learning rate: 0.0018483]
	Learning Rate: 0.00184829
	LOSS [training: 0.3120059315749974 | validation: 0.20466307190560326]
	TIME [epoch: 8.52 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3621700121966298		[learning rate: 0.0018439]
	Learning Rate: 0.00184393
	LOSS [training: 0.3621700121966298 | validation: 0.24205917941396649]
	TIME [epoch: 8.51 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2853728075417717		[learning rate: 0.0018396]
	Learning Rate: 0.00183958
	LOSS [training: 0.2853728075417717 | validation: 0.2361599195999206]
	TIME [epoch: 8.51 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.288098911659888		[learning rate: 0.0018352]
	Learning Rate: 0.00183524
	LOSS [training: 0.288098911659888 | validation: 0.19291017193208104]
	TIME [epoch: 8.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2490216157692596		[learning rate: 0.0018309]
	Learning Rate: 0.00183091
	LOSS [training: 0.2490216157692596 | validation: 0.3927331332406767]
	TIME [epoch: 8.51 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3014307922547822		[learning rate: 0.0018266]
	Learning Rate: 0.00182659
	LOSS [training: 0.3014307922547822 | validation: 0.22689907992594546]
	TIME [epoch: 8.54 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29225778230880345		[learning rate: 0.0018223]
	Learning Rate: 0.00182228
	LOSS [training: 0.29225778230880345 | validation: 0.19648947873597594]
	TIME [epoch: 8.51 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3033027223302847		[learning rate: 0.001818]
	Learning Rate: 0.00181798
	LOSS [training: 0.3033027223302847 | validation: 0.23445618001033927]
	TIME [epoch: 8.51 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33965564140131194		[learning rate: 0.0018137]
	Learning Rate: 0.00181369
	LOSS [training: 0.33965564140131194 | validation: 0.26991687579998525]
	TIME [epoch: 8.51 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25642091800955935		[learning rate: 0.0018094]
	Learning Rate: 0.00180942
	LOSS [training: 0.25642091800955935 | validation: 0.3071621154240443]
	TIME [epoch: 8.53 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25495251456318174		[learning rate: 0.0018051]
	Learning Rate: 0.00180515
	LOSS [training: 0.25495251456318174 | validation: 0.2354099835438367]
	TIME [epoch: 8.52 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26922763605241		[learning rate: 0.0018009]
	Learning Rate: 0.00180089
	LOSS [training: 0.26922763605241 | validation: 0.33424705181325953]
	TIME [epoch: 8.51 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3159987561763218		[learning rate: 0.0017966]
	Learning Rate: 0.00179664
	LOSS [training: 0.3159987561763218 | validation: 0.2854939890716533]
	TIME [epoch: 8.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34946070376791305		[learning rate: 0.0017924]
	Learning Rate: 0.0017924
	LOSS [training: 0.34946070376791305 | validation: 0.3277723593714804]
	TIME [epoch: 8.52 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.304059910183173		[learning rate: 0.0017882]
	Learning Rate: 0.00178818
	LOSS [training: 0.304059910183173 | validation: 0.20703874007426712]
	TIME [epoch: 8.51 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31049820957088226		[learning rate: 0.001784]
	Learning Rate: 0.00178396
	LOSS [training: 0.31049820957088226 | validation: 0.23966100058196668]
	TIME [epoch: 8.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23401533944802524		[learning rate: 0.0017797]
	Learning Rate: 0.00177975
	LOSS [training: 0.23401533944802524 | validation: 0.3211589718422771]
	TIME [epoch: 8.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3271365293628262		[learning rate: 0.0017756]
	Learning Rate: 0.00177555
	LOSS [training: 0.3271365293628262 | validation: 0.34306448155090397]
	TIME [epoch: 8.53 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28785355190262435		[learning rate: 0.0017714]
	Learning Rate: 0.00177136
	LOSS [training: 0.28785355190262435 | validation: 0.32007226555548784]
	TIME [epoch: 8.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26953682305442317		[learning rate: 0.0017672]
	Learning Rate: 0.00176719
	LOSS [training: 0.26953682305442317 | validation: 0.23061772952102083]
	TIME [epoch: 8.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28529640746242074		[learning rate: 0.001763]
	Learning Rate: 0.00176302
	LOSS [training: 0.28529640746242074 | validation: 0.19842055302560446]
	TIME [epoch: 8.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27710552479213824		[learning rate: 0.0017589]
	Learning Rate: 0.00175886
	LOSS [training: 0.27710552479213824 | validation: 0.2922151499806208]
	TIME [epoch: 8.52 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4299186297769865		[learning rate: 0.0017547]
	Learning Rate: 0.00175471
	LOSS [training: 0.4299186297769865 | validation: 0.5608767558683545]
	TIME [epoch: 8.52 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3178449088791034		[learning rate: 0.0017506]
	Learning Rate: 0.00175057
	LOSS [training: 0.3178449088791034 | validation: 0.20710208649119727]
	TIME [epoch: 8.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2658763421600606		[learning rate: 0.0017464]
	Learning Rate: 0.00174644
	LOSS [training: 0.2658763421600606 | validation: 0.20266061728610155]
	TIME [epoch: 8.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.267099491886829		[learning rate: 0.0017423]
	Learning Rate: 0.00174232
	LOSS [training: 0.267099491886829 | validation: 0.21077842032310762]
	TIME [epoch: 8.51 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3072743460240758		[learning rate: 0.0017382]
	Learning Rate: 0.00173821
	LOSS [training: 0.3072743460240758 | validation: 0.2461843782903399]
	TIME [epoch: 8.52 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27945191426428995		[learning rate: 0.0017341]
	Learning Rate: 0.00173411
	LOSS [training: 0.27945191426428995 | validation: 0.22971616549222545]
	TIME [epoch: 8.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3121085758603561		[learning rate: 0.00173]
	Learning Rate: 0.00173002
	LOSS [training: 0.3121085758603561 | validation: 0.283815975609115]
	TIME [epoch: 8.51 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3103169243333859		[learning rate: 0.0017259]
	Learning Rate: 0.00172594
	LOSS [training: 0.3103169243333859 | validation: 0.19482140957750724]
	TIME [epoch: 8.51 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26186478969267984		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.26186478969267984 | validation: 0.2763662987392479]
	TIME [epoch: 8.54 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27258111022452325		[learning rate: 0.0017178]
	Learning Rate: 0.00171781
	LOSS [training: 0.27258111022452325 | validation: 0.3898097657823387]
	TIME [epoch: 8.52 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2589855031803837		[learning rate: 0.0017138]
	Learning Rate: 0.00171375
	LOSS [training: 0.2589855031803837 | validation: 0.18787783180733036]
	TIME [epoch: 8.51 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4555043530469668		[learning rate: 0.0017097]
	Learning Rate: 0.00170971
	LOSS [training: 0.4555043530469668 | validation: 0.26814599562485847]
	TIME [epoch: 8.51 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25718780263269725		[learning rate: 0.0017057]
	Learning Rate: 0.00170568
	LOSS [training: 0.25718780263269725 | validation: 0.37037560565549404]
	TIME [epoch: 8.53 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34319426958364363		[learning rate: 0.0017017]
	Learning Rate: 0.00170166
	LOSS [training: 0.34319426958364363 | validation: 0.36332369478132953]
	TIME [epoch: 8.51 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3020937966807321		[learning rate: 0.0016976]
	Learning Rate: 0.00169764
	LOSS [training: 0.3020937966807321 | validation: 0.24346753355686923]
	TIME [epoch: 8.51 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24284373556384078		[learning rate: 0.0016936]
	Learning Rate: 0.00169364
	LOSS [training: 0.24284373556384078 | validation: 0.3682531230621243]
	TIME [epoch: 8.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35433928028352857		[learning rate: 0.0016896]
	Learning Rate: 0.00168964
	LOSS [training: 0.35433928028352857 | validation: 0.2346569896940041]
	TIME [epoch: 8.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31107699634876745		[learning rate: 0.0016857]
	Learning Rate: 0.00168566
	LOSS [training: 0.31107699634876745 | validation: 0.3626129832547941]
	TIME [epoch: 8.52 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3302921500860723		[learning rate: 0.0016817]
	Learning Rate: 0.00168168
	LOSS [training: 0.3302921500860723 | validation: 0.23267132489596376]
	TIME [epoch: 8.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23930774000866833		[learning rate: 0.0016777]
	Learning Rate: 0.00167771
	LOSS [training: 0.23930774000866833 | validation: 0.24642488944451346]
	TIME [epoch: 8.51 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29859204283616253		[learning rate: 0.0016738]
	Learning Rate: 0.00167376
	LOSS [training: 0.29859204283616253 | validation: 0.2526379199075818]
	TIME [epoch: 8.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25070962350097603		[learning rate: 0.0016698]
	Learning Rate: 0.00166981
	LOSS [training: 0.25070962350097603 | validation: 0.3139645796146489]
	TIME [epoch: 8.54 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30246838037385454		[learning rate: 0.0016659]
	Learning Rate: 0.00166587
	LOSS [training: 0.30246838037385454 | validation: 0.22796268022284855]
	TIME [epoch: 8.52 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2698277331589191		[learning rate: 0.0016619]
	Learning Rate: 0.00166194
	LOSS [training: 0.2698277331589191 | validation: 0.3601733222049397]
	TIME [epoch: 8.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28839201788261104		[learning rate: 0.001658]
	Learning Rate: 0.00165802
	LOSS [training: 0.28839201788261104 | validation: 0.2976279272115892]
	TIME [epoch: 8.51 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3524068462046757		[learning rate: 0.0016541]
	Learning Rate: 0.00165411
	LOSS [training: 0.3524068462046757 | validation: 0.20849601229098824]
	TIME [epoch: 8.53 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28230173716717155		[learning rate: 0.0016502]
	Learning Rate: 0.00165021
	LOSS [training: 0.28230173716717155 | validation: 0.19981398467426403]
	TIME [epoch: 8.51 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28048911892408324		[learning rate: 0.0016463]
	Learning Rate: 0.00164631
	LOSS [training: 0.28048911892408324 | validation: 0.2789419659324089]
	TIME [epoch: 8.52 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28283727103575473		[learning rate: 0.0016424]
	Learning Rate: 0.00164243
	LOSS [training: 0.28283727103575473 | validation: 0.367621593770854]
	TIME [epoch: 8.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3215431846854066		[learning rate: 0.0016386]
	Learning Rate: 0.00163856
	LOSS [training: 0.3215431846854066 | validation: 0.24768995855244513]
	TIME [epoch: 8.53 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2869965967897584		[learning rate: 0.0016347]
	Learning Rate: 0.00163469
	LOSS [training: 0.2869965967897584 | validation: 0.23371491185352533]
	TIME [epoch: 8.52 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3055005267791437		[learning rate: 0.0016308]
	Learning Rate: 0.00163084
	LOSS [training: 0.3055005267791437 | validation: 0.3281134896142691]
	TIME [epoch: 8.51 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31323613033129344		[learning rate: 0.001627]
	Learning Rate: 0.00162699
	LOSS [training: 0.31323613033129344 | validation: 0.46369639770228144]
	TIME [epoch: 8.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35634062948462875		[learning rate: 0.0016232]
	Learning Rate: 0.00162315
	LOSS [training: 0.35634062948462875 | validation: 0.3541890109773459]
	TIME [epoch: 8.51 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3156284088308892		[learning rate: 0.0016193]
	Learning Rate: 0.00161932
	LOSS [training: 0.3156284088308892 | validation: 0.25781721487887554]
	TIME [epoch: 8.52 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2985537063886257		[learning rate: 0.0016155]
	Learning Rate: 0.0016155
	LOSS [training: 0.2985537063886257 | validation: 0.4922084405617766]
	TIME [epoch: 8.51 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3369970831309882		[learning rate: 0.0016117]
	Learning Rate: 0.00161169
	LOSS [training: 0.3369970831309882 | validation: 0.3122774126261878]
	TIME [epoch: 8.51 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35155309725481626		[learning rate: 0.0016079]
	Learning Rate: 0.00160789
	LOSS [training: 0.35155309725481626 | validation: 0.20652154181883553]
	TIME [epoch: 8.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27006162978128784		[learning rate: 0.0016041]
	Learning Rate: 0.0016041
	LOSS [training: 0.27006162978128784 | validation: 0.28560348660845947]
	TIME [epoch: 8.53 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25955031270821277		[learning rate: 0.0016003]
	Learning Rate: 0.00160031
	LOSS [training: 0.25955031270821277 | validation: 0.22037527637866258]
	TIME [epoch: 8.51 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2627521436070948		[learning rate: 0.0015965]
	Learning Rate: 0.00159654
	LOSS [training: 0.2627521436070948 | validation: 0.19755556090808266]
	TIME [epoch: 8.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33100942927754795		[learning rate: 0.0015928]
	Learning Rate: 0.00159277
	LOSS [training: 0.33100942927754795 | validation: 0.3230019937467318]
	TIME [epoch: 8.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35334953866541785		[learning rate: 0.001589]
	Learning Rate: 0.00158902
	LOSS [training: 0.35334953866541785 | validation: 0.4674941170861353]
	TIME [epoch: 8.53 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31419277945907503		[learning rate: 0.0015853]
	Learning Rate: 0.00158527
	LOSS [training: 0.31419277945907503 | validation: 0.44108826347949615]
	TIME [epoch: 8.51 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2793169923003033		[learning rate: 0.0015815]
	Learning Rate: 0.00158153
	LOSS [training: 0.2793169923003033 | validation: 0.23338231964224992]
	TIME [epoch: 8.51 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.283581557708596		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.283581557708596 | validation: 0.23095482488554575]
	TIME [epoch: 8.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3109171091642168		[learning rate: 0.0015741]
	Learning Rate: 0.00157408
	LOSS [training: 0.3109171091642168 | validation: 0.2743209779028977]
	TIME [epoch: 8.52 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2567037871669764		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.2567037871669764 | validation: 0.25692747630999246]
	TIME [epoch: 8.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2667891416505374		[learning rate: 0.0015667]
	Learning Rate: 0.00156666
	LOSS [training: 0.2667891416505374 | validation: 0.34363109614838816]
	TIME [epoch: 8.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31951104499685373		[learning rate: 0.001563]
	Learning Rate: 0.00156296
	LOSS [training: 0.31951104499685373 | validation: 0.2222828464493002]
	TIME [epoch: 8.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22148487543180734		[learning rate: 0.0015593]
	Learning Rate: 0.00155928
	LOSS [training: 0.22148487543180734 | validation: 0.18569921952655508]
	TIME [epoch: 8.51 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2742626656331858		[learning rate: 0.0015556]
	Learning Rate: 0.0015556
	LOSS [training: 0.2742626656331858 | validation: 0.3144261265954964]
	TIME [epoch: 8.52 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28994785882168805		[learning rate: 0.0015519]
	Learning Rate: 0.00155193
	LOSS [training: 0.28994785882168805 | validation: 0.23827817028082726]
	TIME [epoch: 8.51 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23525150752519805		[learning rate: 0.0015483]
	Learning Rate: 0.00154827
	LOSS [training: 0.23525150752519805 | validation: 0.3867012362610127]
	TIME [epoch: 8.51 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3110224715000814		[learning rate: 0.0015446]
	Learning Rate: 0.00154462
	LOSS [training: 0.3110224715000814 | validation: 0.2681293006262172]
	TIME [epoch: 8.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2538459210458499		[learning rate: 0.001541]
	Learning Rate: 0.00154097
	LOSS [training: 0.2538459210458499 | validation: 0.23665065545613134]
	TIME [epoch: 8.53 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2612183663911739		[learning rate: 0.0015373]
	Learning Rate: 0.00153734
	LOSS [training: 0.2612183663911739 | validation: 0.2194532216365358]
	TIME [epoch: 8.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27020134454019684		[learning rate: 0.0015337]
	Learning Rate: 0.00153371
	LOSS [training: 0.27020134454019684 | validation: 0.3006947741253255]
	TIME [epoch: 8.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3050192980295797		[learning rate: 0.0015301]
	Learning Rate: 0.00153009
	LOSS [training: 0.3050192980295797 | validation: 0.26019196533317707]
	TIME [epoch: 8.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3035033948981912		[learning rate: 0.0015265]
	Learning Rate: 0.00152648
	LOSS [training: 0.3035033948981912 | validation: 0.2052134148739817]
	TIME [epoch: 8.52 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21610252826078385		[learning rate: 0.0015229]
	Learning Rate: 0.00152288
	LOSS [training: 0.21610252826078385 | validation: 0.3269518522615304]
	TIME [epoch: 8.51 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2997759574881842		[learning rate: 0.0015193]
	Learning Rate: 0.00151929
	LOSS [training: 0.2997759574881842 | validation: 0.21361235996867642]
	TIME [epoch: 8.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23000924379815652		[learning rate: 0.0015157]
	Learning Rate: 0.00151571
	LOSS [training: 0.23000924379815652 | validation: 0.21434573003723464]
	TIME [epoch: 8.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2658205245780926		[learning rate: 0.0015121]
	Learning Rate: 0.00151213
	LOSS [training: 0.2658205245780926 | validation: 0.3659378826323184]
	TIME [epoch: 8.52 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3424243958327581		[learning rate: 0.0015086]
	Learning Rate: 0.00150857
	LOSS [training: 0.3424243958327581 | validation: 0.19118819223556974]
	TIME [epoch: 8.52 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25877828278419185		[learning rate: 0.001505]
	Learning Rate: 0.00150501
	LOSS [training: 0.25877828278419185 | validation: 0.18649672401293854]
	TIME [epoch: 8.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2582590010927008		[learning rate: 0.0015015]
	Learning Rate: 0.00150146
	LOSS [training: 0.2582590010927008 | validation: 0.19368617481979422]
	TIME [epoch: 8.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2608619423187734		[learning rate: 0.0014979]
	Learning Rate: 0.00149791
	LOSS [training: 0.2608619423187734 | validation: 0.20292207038177676]
	TIME [epoch: 8.51 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22091378504588938		[learning rate: 0.0014944]
	Learning Rate: 0.00149438
	LOSS [training: 0.22091378504588938 | validation: 0.1970621890120434]
	TIME [epoch: 8.52 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35650682390264693		[learning rate: 0.0014909]
	Learning Rate: 0.00149086
	LOSS [training: 0.35650682390264693 | validation: 0.3545600450587977]
	TIME [epoch: 8.51 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3224085781165229		[learning rate: 0.0014873]
	Learning Rate: 0.00148734
	LOSS [training: 0.3224085781165229 | validation: 0.3094995330648639]
	TIME [epoch: 8.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24829928884165525		[learning rate: 0.0014838]
	Learning Rate: 0.00148383
	LOSS [training: 0.24829928884165525 | validation: 0.23541917053340516]
	TIME [epoch: 8.51 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33865904457348667		[learning rate: 0.0014803]
	Learning Rate: 0.00148033
	LOSS [training: 0.33865904457348667 | validation: 0.24814681244474024]
	TIME [epoch: 8.52 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26998791629603963		[learning rate: 0.0014768]
	Learning Rate: 0.00147684
	LOSS [training: 0.26998791629603963 | validation: 0.3027334556101501]
	TIME [epoch: 8.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.250407339695642		[learning rate: 0.0014734]
	Learning Rate: 0.00147336
	LOSS [training: 0.250407339695642 | validation: 0.2682057258299487]
	TIME [epoch: 8.5 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2678062133254778		[learning rate: 0.0014699]
	Learning Rate: 0.00146988
	LOSS [training: 0.2678062133254778 | validation: 0.20336915904511155]
	TIME [epoch: 8.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.256709888610439		[learning rate: 0.0014664]
	Learning Rate: 0.00146641
	LOSS [training: 0.256709888610439 | validation: 0.3859033086136454]
	TIME [epoch: 8.52 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30472161000343667		[learning rate: 0.001463]
	Learning Rate: 0.00146295
	LOSS [training: 0.30472161000343667 | validation: 0.4135719764445539]
	TIME [epoch: 8.5 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30766678809954473		[learning rate: 0.0014595]
	Learning Rate: 0.0014595
	LOSS [training: 0.30766678809954473 | validation: 0.20955384487866757]
	TIME [epoch: 8.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24141359827390096		[learning rate: 0.0014561]
	Learning Rate: 0.00145606
	LOSS [training: 0.24141359827390096 | validation: 0.24546906543615982]
	TIME [epoch: 8.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24371404665205826		[learning rate: 0.0014526]
	Learning Rate: 0.00145263
	LOSS [training: 0.24371404665205826 | validation: 0.36833599122936644]
	TIME [epoch: 8.52 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3097996957286893		[learning rate: 0.0014492]
	Learning Rate: 0.0014492
	LOSS [training: 0.3097996957286893 | validation: 0.25657054850169936]
	TIME [epoch: 8.51 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21904672427243305		[learning rate: 0.0014458]
	Learning Rate: 0.00144578
	LOSS [training: 0.21904672427243305 | validation: 0.19494366417732717]
	TIME [epoch: 8.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2588192073172694		[learning rate: 0.0014424]
	Learning Rate: 0.00144237
	LOSS [training: 0.2588192073172694 | validation: 0.24626359319206423]
	TIME [epoch: 8.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23800295840792499		[learning rate: 0.001439]
	Learning Rate: 0.00143897
	LOSS [training: 0.23800295840792499 | validation: 0.18065564885785015]
	TIME [epoch: 8.51 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28468718193013337		[learning rate: 0.0014356]
	Learning Rate: 0.00143557
	LOSS [training: 0.28468718193013337 | validation: 0.2792357585729205]
	TIME [epoch: 8.52 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24214226432773667		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.24214226432773667 | validation: 0.1992165870956668]
	TIME [epoch: 8.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24585966241006885		[learning rate: 0.0014288]
	Learning Rate: 0.00142881
	LOSS [training: 0.24585966241006885 | validation: 0.27730881062760926]
	TIME [epoch: 8.49 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2815269554480509		[learning rate: 0.0014254]
	Learning Rate: 0.00142544
	LOSS [training: 0.2815269554480509 | validation: 0.3919744741031732]
	TIME [epoch: 8.49 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29850143800570206		[learning rate: 0.0014221]
	Learning Rate: 0.00142208
	LOSS [training: 0.29850143800570206 | validation: 0.2579138100332696]
	TIME [epoch: 8.52 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29626896447931483		[learning rate: 0.0014187]
	Learning Rate: 0.00141872
	LOSS [training: 0.29626896447931483 | validation: 0.23859653535152336]
	TIME [epoch: 8.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2669045098776137		[learning rate: 0.0014154]
	Learning Rate: 0.00141538
	LOSS [training: 0.2669045098776137 | validation: 0.21668111295013337]
	TIME [epoch: 8.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22508902653554577		[learning rate: 0.001412]
	Learning Rate: 0.00141204
	LOSS [training: 0.22508902653554577 | validation: 0.22355988862805265]
	TIME [epoch: 8.49 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25657935820950595		[learning rate: 0.0014087]
	Learning Rate: 0.00140871
	LOSS [training: 0.25657935820950595 | validation: 0.2315378662439047]
	TIME [epoch: 8.52 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.250302796408789		[learning rate: 0.0014054]
	Learning Rate: 0.00140538
	LOSS [training: 0.250302796408789 | validation: 0.3037905258935565]
	TIME [epoch: 8.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33656024464902		[learning rate: 0.0014021]
	Learning Rate: 0.00140207
	LOSS [training: 0.33656024464902 | validation: 0.1998251091688131]
	TIME [epoch: 8.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21500743424163918		[learning rate: 0.0013988]
	Learning Rate: 0.00139876
	LOSS [training: 0.21500743424163918 | validation: 0.18400217328981522]
	TIME [epoch: 8.49 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2567813847420794		[learning rate: 0.0013955]
	Learning Rate: 0.00139546
	LOSS [training: 0.2567813847420794 | validation: 0.3234997591591746]
	TIME [epoch: 8.51 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31318384964712803		[learning rate: 0.0013922]
	Learning Rate: 0.00139217
	LOSS [training: 0.31318384964712803 | validation: 0.23267389648832018]
	TIME [epoch: 8.49 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26582653973522496		[learning rate: 0.0013889]
	Learning Rate: 0.00138889
	LOSS [training: 0.26582653973522496 | validation: 0.5465894630147144]
	TIME [epoch: 8.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4114818909690833		[learning rate: 0.0013856]
	Learning Rate: 0.00138561
	LOSS [training: 0.4114818909690833 | validation: 0.2253144231139924]
	TIME [epoch: 8.49 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33103353667137453		[learning rate: 0.0013823]
	Learning Rate: 0.00138234
	LOSS [training: 0.33103353667137453 | validation: 0.2189098735706872]
	TIME [epoch: 8.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29009525318763174		[learning rate: 0.0013791]
	Learning Rate: 0.00137908
	LOSS [training: 0.29009525318763174 | validation: 0.22516191096954793]
	TIME [epoch: 8.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22155939271550612		[learning rate: 0.0013758]
	Learning Rate: 0.00137583
	LOSS [training: 0.22155939271550612 | validation: 0.16794859553066196]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_890.pth
	Model improved!!!
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3477022250199271		[learning rate: 0.0013726]
	Learning Rate: 0.00137258
	LOSS [training: 0.3477022250199271 | validation: 0.29237355550510047]
	TIME [epoch: 8.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24132808721446564		[learning rate: 0.0013693]
	Learning Rate: 0.00136934
	LOSS [training: 0.24132808721446564 | validation: 0.22032172254857885]
	TIME [epoch: 8.49 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28665213620290086		[learning rate: 0.0013661]
	Learning Rate: 0.00136611
	LOSS [training: 0.28665213620290086 | validation: 0.27240996515425847]
	TIME [epoch: 8.52 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2734533544239673		[learning rate: 0.0013629]
	Learning Rate: 0.00136289
	LOSS [training: 0.2734533544239673 | validation: 0.27620806814130794]
	TIME [epoch: 8.49 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30797318602165047		[learning rate: 0.0013597]
	Learning Rate: 0.00135968
	LOSS [training: 0.30797318602165047 | validation: 0.3142599388995802]
	TIME [epoch: 8.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.242949835946835		[learning rate: 0.0013565]
	Learning Rate: 0.00135647
	LOSS [training: 0.242949835946835 | validation: 0.2231464513655254]
	TIME [epoch: 8.49 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24379077448541064		[learning rate: 0.0013533]
	Learning Rate: 0.00135327
	LOSS [training: 0.24379077448541064 | validation: 0.20692810402078982]
	TIME [epoch: 8.52 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24016843284161396		[learning rate: 0.0013501]
	Learning Rate: 0.00135008
	LOSS [training: 0.24016843284161396 | validation: 0.18413164233477364]
	TIME [epoch: 8.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22483413534203703		[learning rate: 0.0013469]
	Learning Rate: 0.00134689
	LOSS [training: 0.22483413534203703 | validation: 0.4038526533214152]
	TIME [epoch: 8.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25608866057069235		[learning rate: 0.0013437]
	Learning Rate: 0.00134372
	LOSS [training: 0.25608866057069235 | validation: 0.18992223579517825]
	TIME [epoch: 8.49 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22012538177520574		[learning rate: 0.0013405]
	Learning Rate: 0.00134055
	LOSS [training: 0.22012538177520574 | validation: 0.20899349993545868]
	TIME [epoch: 8.51 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23366377716764758		[learning rate: 0.0013374]
	Learning Rate: 0.00133738
	LOSS [training: 0.23366377716764758 | validation: 0.3775883912715682]
	TIME [epoch: 8.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2658775873517987		[learning rate: 0.0013342]
	Learning Rate: 0.00133423
	LOSS [training: 0.2658775873517987 | validation: 0.411971780610609]
	TIME [epoch: 8.49 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3202587525779901		[learning rate: 0.0013311]
	Learning Rate: 0.00133108
	LOSS [training: 0.3202587525779901 | validation: 0.1737609977221428]
	TIME [epoch: 8.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2220471548816715		[learning rate: 0.0013279]
	Learning Rate: 0.00132794
	LOSS [training: 0.2220471548816715 | validation: 0.20202274908558832]
	TIME [epoch: 8.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27353209651856625		[learning rate: 0.0013248]
	Learning Rate: 0.00132481
	LOSS [training: 0.27353209651856625 | validation: 0.27571025687396944]
	TIME [epoch: 8.51 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29414748823123676		[learning rate: 0.0013217]
	Learning Rate: 0.00132169
	LOSS [training: 0.29414748823123676 | validation: 0.26385216025466063]
	TIME [epoch: 8.49 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21099830540539255		[learning rate: 0.0013186]
	Learning Rate: 0.00131857
	LOSS [training: 0.21099830540539255 | validation: 0.25108466259493023]
	TIME [epoch: 8.48 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22499752608908946		[learning rate: 0.0013155]
	Learning Rate: 0.00131546
	LOSS [training: 0.22499752608908946 | validation: 0.424081986360325]
	TIME [epoch: 8.48 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2889060923686416		[learning rate: 0.0013124]
	Learning Rate: 0.00131235
	LOSS [training: 0.2889060923686416 | validation: 0.1974729041552044]
	TIME [epoch: 8.51 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26206798315875873		[learning rate: 0.0013093]
	Learning Rate: 0.00130926
	LOSS [training: 0.26206798315875873 | validation: 0.20457771425077034]
	TIME [epoch: 8.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2651924118804458		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.2651924118804458 | validation: 0.26640045938018364]
	TIME [epoch: 8.51 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2614336843704864		[learning rate: 0.0013031]
	Learning Rate: 0.00130309
	LOSS [training: 0.2614336843704864 | validation: 0.20737356937180979]
	TIME [epoch: 8.49 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2765932212880265		[learning rate: 0.0013]
	Learning Rate: 0.00130002
	LOSS [training: 0.2765932212880265 | validation: 0.1907165925134584]
	TIME [epoch: 8.52 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23700284283646642		[learning rate: 0.0012969]
	Learning Rate: 0.00129695
	LOSS [training: 0.23700284283646642 | validation: 0.2605239185303132]
	TIME [epoch: 8.49 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2643283660715277		[learning rate: 0.0012939]
	Learning Rate: 0.00129389
	LOSS [training: 0.2643283660715277 | validation: 0.2302868270077299]
	TIME [epoch: 8.49 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21335577818801404		[learning rate: 0.0012908]
	Learning Rate: 0.00129084
	LOSS [training: 0.21335577818801404 | validation: 0.25523553663033577]
	TIME [epoch: 8.49 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2719373590919248		[learning rate: 0.0012878]
	Learning Rate: 0.00128779
	LOSS [training: 0.2719373590919248 | validation: 0.1996459005851196]
	TIME [epoch: 8.51 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22365438576827573		[learning rate: 0.0012848]
	Learning Rate: 0.00128476
	LOSS [training: 0.22365438576827573 | validation: 0.2468769092402279]
	TIME [epoch: 8.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2654834616782714		[learning rate: 0.0012817]
	Learning Rate: 0.00128173
	LOSS [training: 0.2654834616782714 | validation: 0.25582808940675106]
	TIME [epoch: 8.49 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24960686264796378		[learning rate: 0.0012787]
	Learning Rate: 0.0012787
	LOSS [training: 0.24960686264796378 | validation: 0.305068523017647]
	TIME [epoch: 8.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25300480301278083		[learning rate: 0.0012757]
	Learning Rate: 0.00127569
	LOSS [training: 0.25300480301278083 | validation: 0.22071595172416514]
	TIME [epoch: 8.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3071864068822716		[learning rate: 0.0012727]
	Learning Rate: 0.00127268
	LOSS [training: 0.3071864068822716 | validation: 0.18548878032094623]
	TIME [epoch: 8.51 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23556538140803865		[learning rate: 0.0012697]
	Learning Rate: 0.00126967
	LOSS [training: 0.23556538140803865 | validation: 0.23686907161787413]
	TIME [epoch: 8.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23314306072545735		[learning rate: 0.0012667]
	Learning Rate: 0.00126668
	LOSS [training: 0.23314306072545735 | validation: 0.27940716552171685]
	TIME [epoch: 8.49 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24282230614111744		[learning rate: 0.0012637]
	Learning Rate: 0.00126369
	LOSS [training: 0.24282230614111744 | validation: 0.20859670456960985]
	TIME [epoch: 8.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22095487616183118		[learning rate: 0.0012607]
	Learning Rate: 0.00126071
	LOSS [training: 0.22095487616183118 | validation: 0.179276743263322]
	TIME [epoch: 8.52 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21398103228491752		[learning rate: 0.0012577]
	Learning Rate: 0.00125774
	LOSS [training: 0.21398103228491752 | validation: 0.19184664338255575]
	TIME [epoch: 8.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20845546658640374		[learning rate: 0.0012548]
	Learning Rate: 0.00125477
	LOSS [training: 0.20845546658640374 | validation: 0.1541955417216124]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_929.pth
	Model improved!!!
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24797072134604203		[learning rate: 0.0012518]
	Learning Rate: 0.00125181
	LOSS [training: 0.24797072134604203 | validation: 0.18251237769584777]
	TIME [epoch: 8.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23745961275044616		[learning rate: 0.0012489]
	Learning Rate: 0.00124886
	LOSS [training: 0.23745961275044616 | validation: 0.1720655466063765]
	TIME [epoch: 8.52 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2540715268500803		[learning rate: 0.0012459]
	Learning Rate: 0.00124591
	LOSS [training: 0.2540715268500803 | validation: 0.25603195638486953]
	TIME [epoch: 8.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30117865033361585		[learning rate: 0.001243]
	Learning Rate: 0.00124297
	LOSS [training: 0.30117865033361585 | validation: 0.22434230987414588]
	TIME [epoch: 8.49 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26483726881142455		[learning rate: 0.00124]
	Learning Rate: 0.00124004
	LOSS [training: 0.26483726881142455 | validation: 0.2902098314993761]
	TIME [epoch: 8.49 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2404727178884491		[learning rate: 0.0012371]
	Learning Rate: 0.00123712
	LOSS [training: 0.2404727178884491 | validation: 0.17866196800044834]
	TIME [epoch: 8.51 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26151738143955905		[learning rate: 0.0012342]
	Learning Rate: 0.0012342
	LOSS [training: 0.26151738143955905 | validation: 0.20333656742408476]
	TIME [epoch: 8.5 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3240369257497603		[learning rate: 0.0012313]
	Learning Rate: 0.00123129
	LOSS [training: 0.3240369257497603 | validation: 0.24673183074906527]
	TIME [epoch: 8.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28478035491651765		[learning rate: 0.0012284]
	Learning Rate: 0.00122838
	LOSS [training: 0.28478035491651765 | validation: 0.3306935430478999]
	TIME [epoch: 8.49 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2296675152984436		[learning rate: 0.0012255]
	Learning Rate: 0.00122548
	LOSS [training: 0.2296675152984436 | validation: 0.2685110280679841]
	TIME [epoch: 8.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2592777247083097		[learning rate: 0.0012226]
	Learning Rate: 0.00122259
	LOSS [training: 0.2592777247083097 | validation: 0.23477233609621764]
	TIME [epoch: 8.51 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2782646884443606		[learning rate: 0.0012197]
	Learning Rate: 0.00121971
	LOSS [training: 0.2782646884443606 | validation: 0.33759515647869653]
	TIME [epoch: 8.49 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32777289888629213		[learning rate: 0.0012168]
	Learning Rate: 0.00121683
	LOSS [training: 0.32777289888629213 | validation: 0.23115296101531624]
	TIME [epoch: 8.49 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22721086870121043		[learning rate: 0.001214]
	Learning Rate: 0.00121396
	LOSS [training: 0.22721086870121043 | validation: 0.32442961904786327]
	TIME [epoch: 8.49 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2709301791689643		[learning rate: 0.0012111]
	Learning Rate: 0.0012111
	LOSS [training: 0.2709301791689643 | validation: 0.3360228321227904]
	TIME [epoch: 8.51 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24376147501162246		[learning rate: 0.0012082]
	Learning Rate: 0.00120824
	LOSS [training: 0.24376147501162246 | validation: 0.20409879739791148]
	TIME [epoch: 8.49 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2941129945985936		[learning rate: 0.0012054]
	Learning Rate: 0.00120539
	LOSS [training: 0.2941129945985936 | validation: 0.2727687734178452]
	TIME [epoch: 8.49 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24514739486507692		[learning rate: 0.0012025]
	Learning Rate: 0.00120255
	LOSS [training: 0.24514739486507692 | validation: 0.3340810202556078]
	TIME [epoch: 8.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2836256631398134		[learning rate: 0.0011997]
	Learning Rate: 0.00119971
	LOSS [training: 0.2836256631398134 | validation: 0.18972725131330992]
	TIME [epoch: 8.51 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34154527876366586		[learning rate: 0.0011969]
	Learning Rate: 0.00119688
	LOSS [training: 0.34154527876366586 | validation: 0.37764391755995963]
	TIME [epoch: 8.49 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2820261867895722		[learning rate: 0.0011941]
	Learning Rate: 0.00119406
	LOSS [training: 0.2820261867895722 | validation: 0.23758234012306767]
	TIME [epoch: 8.49 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2528505586215173		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.2528505586215173 | validation: 0.2432469413817922]
	TIME [epoch: 8.49 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2395637841507484		[learning rate: 0.0011884]
	Learning Rate: 0.00118843
	LOSS [training: 0.2395637841507484 | validation: 0.2088429122080312]
	TIME [epoch: 8.51 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29630297419550833		[learning rate: 0.0011856]
	Learning Rate: 0.00118563
	LOSS [training: 0.29630297419550833 | validation: 0.20368641045932478]
	TIME [epoch: 8.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2277264356156214		[learning rate: 0.0011828]
	Learning Rate: 0.00118283
	LOSS [training: 0.2277264356156214 | validation: 0.3235600071654245]
	TIME [epoch: 8.49 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2705700139821035		[learning rate: 0.00118]
	Learning Rate: 0.00118004
	LOSS [training: 0.2705700139821035 | validation: 0.2929367028979234]
	TIME [epoch: 8.49 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2606031716055796		[learning rate: 0.0011773]
	Learning Rate: 0.00117726
	LOSS [training: 0.2606031716055796 | validation: 0.2548967458753346]
	TIME [epoch: 8.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2446789470792193		[learning rate: 0.0011745]
	Learning Rate: 0.00117448
	LOSS [training: 0.2446789470792193 | validation: 0.19768968136218282]
	TIME [epoch: 8.51 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.256699226762855		[learning rate: 0.0011717]
	Learning Rate: 0.00117171
	LOSS [training: 0.256699226762855 | validation: 0.21691468645039166]
	TIME [epoch: 8.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1899448973951824		[learning rate: 0.0011689]
	Learning Rate: 0.00116895
	LOSS [training: 0.1899448973951824 | validation: 0.17065966541626182]
	TIME [epoch: 8.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2478111279019731		[learning rate: 0.0011662]
	Learning Rate: 0.00116619
	LOSS [training: 0.2478111279019731 | validation: 0.24964506533060582]
	TIME [epoch: 8.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23108829789819246		[learning rate: 0.0011634]
	Learning Rate: 0.00116344
	LOSS [training: 0.23108829789819246 | validation: 0.34122907722028084]
	TIME [epoch: 8.52 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24721466049921817		[learning rate: 0.0011607]
	Learning Rate: 0.00116069
	LOSS [training: 0.24721466049921817 | validation: 0.2523251059070769]
	TIME [epoch: 8.49 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25116313330189566		[learning rate: 0.001158]
	Learning Rate: 0.00115796
	LOSS [training: 0.25116313330189566 | validation: 0.19558329731951532]
	TIME [epoch: 8.49 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28325207121434637		[learning rate: 0.0011552]
	Learning Rate: 0.00115523
	LOSS [training: 0.28325207121434637 | validation: 0.2732514648941133]
	TIME [epoch: 8.49 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2260537471143939		[learning rate: 0.0011525]
	Learning Rate: 0.0011525
	LOSS [training: 0.2260537471143939 | validation: 0.2062076005204987]
	TIME [epoch: 8.52 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24044449473465387		[learning rate: 0.0011498]
	Learning Rate: 0.00114978
	LOSS [training: 0.24044449473465387 | validation: 0.2128488748301661]
	TIME [epoch: 8.51 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2768434718638057		[learning rate: 0.0011471]
	Learning Rate: 0.00114707
	LOSS [training: 0.2768434718638057 | validation: 0.24607889054689558]
	TIME [epoch: 8.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23635328839264624		[learning rate: 0.0011444]
	Learning Rate: 0.00114436
	LOSS [training: 0.23635328839264624 | validation: 0.23678094060914995]
	TIME [epoch: 8.5 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19879017827664544		[learning rate: 0.0011417]
	Learning Rate: 0.00114166
	LOSS [training: 0.19879017827664544 | validation: 0.17758028180565252]
	TIME [epoch: 8.51 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21775059415701592		[learning rate: 0.001139]
	Learning Rate: 0.00113897
	LOSS [training: 0.21775059415701592 | validation: 0.24310265556633576]
	TIME [epoch: 8.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24176857994766482		[learning rate: 0.0011363]
	Learning Rate: 0.00113628
	LOSS [training: 0.24176857994766482 | validation: 0.23678272407209977]
	TIME [epoch: 8.5 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26601330420353164		[learning rate: 0.0011336]
	Learning Rate: 0.0011336
	LOSS [training: 0.26601330420353164 | validation: 0.2333576427243064]
	TIME [epoch: 8.49 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2534340550324544		[learning rate: 0.0011309]
	Learning Rate: 0.00113093
	LOSS [training: 0.2534340550324544 | validation: 0.28516638600385735]
	TIME [epoch: 8.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24598629022303972		[learning rate: 0.0011283]
	Learning Rate: 0.00112826
	LOSS [training: 0.24598629022303972 | validation: 0.2505758942160451]
	TIME [epoch: 8.51 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32077353336627257		[learning rate: 0.0011256]
	Learning Rate: 0.0011256
	LOSS [training: 0.32077353336627257 | validation: 0.33573417188666965]
	TIME [epoch: 8.5 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26372597578476054		[learning rate: 0.0011229]
	Learning Rate: 0.00112295
	LOSS [training: 0.26372597578476054 | validation: 0.14764098990396238]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_976.pth
	Model improved!!!
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24496232122534164		[learning rate: 0.0011203]
	Learning Rate: 0.0011203
	LOSS [training: 0.24496232122534164 | validation: 0.23065413184233582]
	TIME [epoch: 8.51 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25048103422286927		[learning rate: 0.0011177]
	Learning Rate: 0.00111765
	LOSS [training: 0.25048103422286927 | validation: 0.22421077393792277]
	TIME [epoch: 8.52 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22036528427772056		[learning rate: 0.001115]
	Learning Rate: 0.00111502
	LOSS [training: 0.22036528427772056 | validation: 0.26042549825593636]
	TIME [epoch: 8.49 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24328866426980275		[learning rate: 0.0011124]
	Learning Rate: 0.00111239
	LOSS [training: 0.24328866426980275 | validation: 0.17659998114352413]
	TIME [epoch: 8.49 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24454096406911052		[learning rate: 0.0011098]
	Learning Rate: 0.00110976
	LOSS [training: 0.24454096406911052 | validation: 0.22181732728449938]
	TIME [epoch: 8.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2085744299422064		[learning rate: 0.0011071]
	Learning Rate: 0.00110715
	LOSS [training: 0.2085744299422064 | validation: 0.17649538064951323]
	TIME [epoch: 8.51 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2110867692918749		[learning rate: 0.0011045]
	Learning Rate: 0.00110453
	LOSS [training: 0.2110867692918749 | validation: 0.21277635401626063]
	TIME [epoch: 8.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30550800905421327		[learning rate: 0.0011019]
	Learning Rate: 0.00110193
	LOSS [training: 0.30550800905421327 | validation: 0.2178651128305679]
	TIME [epoch: 8.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20847236036276443		[learning rate: 0.0010993]
	Learning Rate: 0.00109933
	LOSS [training: 0.20847236036276443 | validation: 0.19838761166997432]
	TIME [epoch: 8.49 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28229530993547886		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.28229530993547886 | validation: 0.22560129813540183]
	TIME [epoch: 8.53 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25711273779346283		[learning rate: 0.0010942]
	Learning Rate: 0.00109415
	LOSS [training: 0.25711273779346283 | validation: 0.2586992503048159]
	TIME [epoch: 8.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2529168909924566		[learning rate: 0.0010916]
	Learning Rate: 0.00109157
	LOSS [training: 0.2529168909924566 | validation: 0.1650858525057044]
	TIME [epoch: 8.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26959156364485287		[learning rate: 0.001089]
	Learning Rate: 0.00108899
	LOSS [training: 0.26959156364485287 | validation: 0.17578518912272023]
	TIME [epoch: 8.49 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21545609085724746		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.21545609085724746 | validation: 0.17861222438705482]
	TIME [epoch: 8.52 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22545121002259152		[learning rate: 0.0010839]
	Learning Rate: 0.00108386
	LOSS [training: 0.22545121002259152 | validation: 0.24290072978472318]
	TIME [epoch: 8.51 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21691408110298865		[learning rate: 0.0010813]
	Learning Rate: 0.00108131
	LOSS [training: 0.21691408110298865 | validation: 0.19644122280119555]
	TIME [epoch: 8.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2199409832449875		[learning rate: 0.0010788]
	Learning Rate: 0.00107876
	LOSS [training: 0.2199409832449875 | validation: 0.19519843622055544]
	TIME [epoch: 8.49 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7230551181135894		[learning rate: 0.0010762]
	Learning Rate: 0.00107621
	LOSS [training: 0.7230551181135894 | validation: 0.25321537611284084]
	TIME [epoch: 8.51 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2555497798589118		[learning rate: 0.0010737]
	Learning Rate: 0.00107367
	LOSS [training: 0.2555497798589118 | validation: 0.21571996870602825]
	TIME [epoch: 8.52 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21480509422116906		[learning rate: 0.0010711]
	Learning Rate: 0.00107114
	LOSS [training: 0.21480509422116906 | validation: 0.19806562772972036]
	TIME [epoch: 8.49 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24645692850848605		[learning rate: 0.0010686]
	Learning Rate: 0.00106861
	LOSS [training: 0.24645692850848605 | validation: 0.26258159626150923]
	TIME [epoch: 8.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24066490491462952		[learning rate: 0.0010661]
	Learning Rate: 0.00106609
	LOSS [training: 0.24066490491462952 | validation: 0.2103419824018545]
	TIME [epoch: 8.49 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2640783453006987		[learning rate: 0.0010636]
	Learning Rate: 0.00106358
	LOSS [training: 0.2640783453006987 | validation: 0.2348302195410336]
	TIME [epoch: 8.51 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27999014210454387		[learning rate: 0.0010611]
	Learning Rate: 0.00106107
	LOSS [training: 0.27999014210454387 | validation: 0.21353606914921122]
	TIME [epoch: 8.49 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2410466648850063		[learning rate: 0.0010586]
	Learning Rate: 0.00105857
	LOSS [training: 0.2410466648850063 | validation: 0.2972015833475238]
	TIME [epoch: 8.49 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23952577841135017		[learning rate: 0.0010561]
	Learning Rate: 0.00105607
	LOSS [training: 0.23952577841135017 | validation: 0.3482353329269928]
	TIME [epoch: 8.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25671160410509597		[learning rate: 0.0010536]
	Learning Rate: 0.00105358
	LOSS [training: 0.25671160410509597 | validation: 0.27783185446829073]
	TIME [epoch: 8.52 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28246060042615184		[learning rate: 0.0010511]
	Learning Rate: 0.00105109
	LOSS [training: 0.28246060042615184 | validation: 0.19517591775501975]
	TIME [epoch: 8.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25689933317882285		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.25689933317882285 | validation: 0.21920949102515494]
	TIME [epoch: 8.49 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25025002161659543		[learning rate: 0.0010461]
	Learning Rate: 0.00104614
	LOSS [training: 0.25025002161659543 | validation: 0.2814010815005673]
	TIME [epoch: 8.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30630724341563004		[learning rate: 0.0010437]
	Learning Rate: 0.00104367
	LOSS [training: 0.30630724341563004 | validation: 0.2450735131075081]
	TIME [epoch: 8.51 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30661357613696605		[learning rate: 0.0010412]
	Learning Rate: 0.00104121
	LOSS [training: 0.30661357613696605 | validation: 0.26928570580162536]
	TIME [epoch: 8.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2630723056839632		[learning rate: 0.0010388]
	Learning Rate: 0.00103875
	LOSS [training: 0.2630723056839632 | validation: 0.2312057705648773]
	TIME [epoch: 8.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25982025433476236		[learning rate: 0.0010363]
	Learning Rate: 0.0010363
	LOSS [training: 0.25982025433476236 | validation: 0.1731548649490281]
	TIME [epoch: 8.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2593187247598931		[learning rate: 0.0010339]
	Learning Rate: 0.00103386
	LOSS [training: 0.2593187247598931 | validation: 0.16154210128046007]
	TIME [epoch: 8.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20744948250396042		[learning rate: 0.0010314]
	Learning Rate: 0.00103142
	LOSS [training: 0.20744948250396042 | validation: 0.17965528066815378]
	TIME [epoch: 8.52 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2563313360254071		[learning rate: 0.001029]
	Learning Rate: 0.00102899
	LOSS [training: 0.2563313360254071 | validation: 0.23266301828496677]
	TIME [epoch: 8.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21380648820166237		[learning rate: 0.0010266]
	Learning Rate: 0.00102656
	LOSS [training: 0.21380648820166237 | validation: 0.19021704959225352]
	TIME [epoch: 8.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2031417774255405		[learning rate: 0.0010241]
	Learning Rate: 0.00102414
	LOSS [training: 0.2031417774255405 | validation: 0.17712137263171218]
	TIME [epoch: 8.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21884990137697452		[learning rate: 0.0010217]
	Learning Rate: 0.00102172
	LOSS [training: 0.21884990137697452 | validation: 0.19533674948327726]
	TIME [epoch: 8.51 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2042963126723067		[learning rate: 0.0010193]
	Learning Rate: 0.00101931
	LOSS [training: 0.2042963126723067 | validation: 0.19604386525028644]
	TIME [epoch: 8.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22899688782278563		[learning rate: 0.0010169]
	Learning Rate: 0.00101691
	LOSS [training: 0.22899688782278563 | validation: 0.2566229977719835]
	TIME [epoch: 8.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2206654438758367		[learning rate: 0.0010145]
	Learning Rate: 0.00101451
	LOSS [training: 0.2206654438758367 | validation: 0.17189521457616957]
	TIME [epoch: 8.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2202849377854718		[learning rate: 0.0010121]
	Learning Rate: 0.00101212
	LOSS [training: 0.2202849377854718 | validation: 0.18361145263927695]
	TIME [epoch: 8.51 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21582586406814813		[learning rate: 0.0010097]
	Learning Rate: 0.00100973
	LOSS [training: 0.21582586406814813 | validation: 0.15845951532896335]
	TIME [epoch: 8.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19170136051102288		[learning rate: 0.0010073]
	Learning Rate: 0.00100735
	LOSS [training: 0.19170136051102288 | validation: 0.15639831767316928]
	TIME [epoch: 8.49 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21990384503733754		[learning rate: 0.001005]
	Learning Rate: 0.00100497
	LOSS [training: 0.21990384503733754 | validation: 0.21012477763533366]
	TIME [epoch: 8.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24732452825083978		[learning rate: 0.0010026]
	Learning Rate: 0.0010026
	LOSS [training: 0.24732452825083978 | validation: 0.18759802512522017]
	TIME [epoch: 8.51 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22057987668847967		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.22057987668847967 | validation: 0.1716791638795535]
	TIME [epoch: 8.51 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28308265466673543		[learning rate: 0.00099788]
	Learning Rate: 0.000997877
	LOSS [training: 0.28308265466673543 | validation: 0.17711437012632272]
	TIME [epoch: 8.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20367596402192642		[learning rate: 0.00099552]
	Learning Rate: 0.000995523
	LOSS [training: 0.20367596402192642 | validation: 0.17120205352486828]
	TIME [epoch: 8.49 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25333427774238737		[learning rate: 0.00099317]
	Learning Rate: 0.000993175
	LOSS [training: 0.25333427774238737 | validation: 0.22649599079491523]
	TIME [epoch: 8.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21984719652138404		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.21984719652138404 | validation: 0.1858767629231996]
	TIME [epoch: 8.52 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19170675129063602		[learning rate: 0.00098849]
	Learning Rate: 0.000988495
	LOSS [training: 0.19170675129063602 | validation: 0.17890187635305044]
	TIME [epoch: 8.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28542922246125313		[learning rate: 0.00098616]
	Learning Rate: 0.000986163
	LOSS [training: 0.28542922246125313 | validation: 0.4751322231001515]
	TIME [epoch: 8.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3244415506005655		[learning rate: 0.00098384]
	Learning Rate: 0.000983837
	LOSS [training: 0.3244415506005655 | validation: 0.29029183671197645]
	TIME [epoch: 8.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20872383625373453		[learning rate: 0.00098152]
	Learning Rate: 0.000981516
	LOSS [training: 0.20872383625373453 | validation: 0.19664052520026176]
	TIME [epoch: 8.52 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22590843468166116		[learning rate: 0.0009792]
	Learning Rate: 0.000979201
	LOSS [training: 0.22590843468166116 | validation: 0.2843279477789247]
	TIME [epoch: 8.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24235555089694497		[learning rate: 0.00097689]
	Learning Rate: 0.000976891
	LOSS [training: 0.24235555089694497 | validation: 0.21478346042114693]
	TIME [epoch: 8.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22272897909351969		[learning rate: 0.00097459]
	Learning Rate: 0.000974587
	LOSS [training: 0.22272897909351969 | validation: 0.21217238868776972]
	TIME [epoch: 8.49 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21202705025934718		[learning rate: 0.00097229]
	Learning Rate: 0.000972288
	LOSS [training: 0.21202705025934718 | validation: 0.2750684528430699]
	TIME [epoch: 8.51 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21183073194513566		[learning rate: 0.00096999]
	Learning Rate: 0.000969994
	LOSS [training: 0.21183073194513566 | validation: 0.2938921409036886]
	TIME [epoch: 8.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28254576121332153		[learning rate: 0.00096771]
	Learning Rate: 0.000967706
	LOSS [training: 0.28254576121332153 | validation: 0.35059331650183534]
	TIME [epoch: 8.49 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3204927790873138		[learning rate: 0.00096542]
	Learning Rate: 0.000965424
	LOSS [training: 0.3204927790873138 | validation: 0.2552473328772916]
	TIME [epoch: 8.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2378633695897435		[learning rate: 0.00096315]
	Learning Rate: 0.000963146
	LOSS [training: 0.2378633695897435 | validation: 0.1837118299556999]
	TIME [epoch: 8.51 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24322771228674106		[learning rate: 0.00096087]
	Learning Rate: 0.000960874
	LOSS [training: 0.24322771228674106 | validation: 0.19632310664518382]
	TIME [epoch: 8.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21456176020092949		[learning rate: 0.00095861]
	Learning Rate: 0.000958608
	LOSS [training: 0.21456176020092949 | validation: 0.22710290702173216]
	TIME [epoch: 8.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2680117922135264		[learning rate: 0.00095635]
	Learning Rate: 0.000956347
	LOSS [training: 0.2680117922135264 | validation: 0.1898394604053754]
	TIME [epoch: 8.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20688738899448053		[learning rate: 0.00095409]
	Learning Rate: 0.000954091
	LOSS [training: 0.20688738899448053 | validation: 0.17626251989412045]
	TIME [epoch: 8.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19485827255229476		[learning rate: 0.00095184]
	Learning Rate: 0.00095184
	LOSS [training: 0.19485827255229476 | validation: 0.233074081346478]
	TIME [epoch: 8.53 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24387416669992962		[learning rate: 0.0009496]
	Learning Rate: 0.000949595
	LOSS [training: 0.24387416669992962 | validation: 0.334970148893286]
	TIME [epoch: 8.49 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.273041361808842		[learning rate: 0.00094736]
	Learning Rate: 0.000947355
	LOSS [training: 0.273041361808842 | validation: 0.19650599015986087]
	TIME [epoch: 8.51 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2701751058467883		[learning rate: 0.00094512]
	Learning Rate: 0.000945121
	LOSS [training: 0.2701751058467883 | validation: 0.18925507097440394]
	TIME [epoch: 8.53 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23892248318839043		[learning rate: 0.00094289]
	Learning Rate: 0.000942891
	LOSS [training: 0.23892248318839043 | validation: 0.1723500017280173]
	TIME [epoch: 8.51 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2014440931392083		[learning rate: 0.00094067]
	Learning Rate: 0.000940667
	LOSS [training: 0.2014440931392083 | validation: 0.21867312077604562]
	TIME [epoch: 8.51 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.204322111643695		[learning rate: 0.00093845]
	Learning Rate: 0.000938448
	LOSS [training: 0.204322111643695 | validation: 0.1807630356455472]
	TIME [epoch: 8.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21695033392167207		[learning rate: 0.00093623]
	Learning Rate: 0.000936234
	LOSS [training: 0.21695033392167207 | validation: 0.14057371814033937]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_1053.pth
	Model improved!!!
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1976705444257757		[learning rate: 0.00093403]
	Learning Rate: 0.000934026
	LOSS [training: 0.1976705444257757 | validation: 0.19213254467265267]
	TIME [epoch: 8.52 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18448611437054793		[learning rate: 0.00093182]
	Learning Rate: 0.000931823
	LOSS [training: 0.18448611437054793 | validation: 0.21557755437001436]
	TIME [epoch: 8.51 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27000648774155855		[learning rate: 0.00092962]
	Learning Rate: 0.000929625
	LOSS [training: 0.27000648774155855 | validation: 0.1553606062795374]
	TIME [epoch: 8.51 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21433967866177123		[learning rate: 0.00092743]
	Learning Rate: 0.000927432
	LOSS [training: 0.21433967866177123 | validation: 0.20436700493934373]
	TIME [epoch: 8.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2060070116613375		[learning rate: 0.00092524]
	Learning Rate: 0.000925244
	LOSS [training: 0.2060070116613375 | validation: 0.1493171384458586]
	TIME [epoch: 8.52 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18151847127260443		[learning rate: 0.00092306]
	Learning Rate: 0.000923062
	LOSS [training: 0.18151847127260443 | validation: 0.17554127896121247]
	TIME [epoch: 8.51 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2406905442113127		[learning rate: 0.00092088]
	Learning Rate: 0.000920884
	LOSS [training: 0.2406905442113127 | validation: 0.18549197046798122]
	TIME [epoch: 8.51 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23099392402020014		[learning rate: 0.00091871]
	Learning Rate: 0.000918712
	LOSS [training: 0.23099392402020014 | validation: 0.25033518164401397]
	TIME [epoch: 8.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24471396926365757		[learning rate: 0.00091654]
	Learning Rate: 0.000916545
	LOSS [training: 0.24471396926365757 | validation: 0.22093415167752514]
	TIME [epoch: 8.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2352103311859969		[learning rate: 0.00091438]
	Learning Rate: 0.000914383
	LOSS [training: 0.2352103311859969 | validation: 0.17699079439857895]
	TIME [epoch: 8.52 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21559189928056943		[learning rate: 0.00091223]
	Learning Rate: 0.000912226
	LOSS [training: 0.21559189928056943 | validation: 0.24449643506264612]
	TIME [epoch: 8.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2568180948883364		[learning rate: 0.00091007]
	Learning Rate: 0.000910074
	LOSS [training: 0.2568180948883364 | validation: 0.16862377803465245]
	TIME [epoch: 8.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34730025470234765		[learning rate: 0.00090793]
	Learning Rate: 0.000907928
	LOSS [training: 0.34730025470234765 | validation: 0.2813140659449802]
	TIME [epoch: 8.51 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3621267490432888		[learning rate: 0.00090579]
	Learning Rate: 0.000905786
	LOSS [training: 0.3621267490432888 | validation: 0.246400248674561]
	TIME [epoch: 8.53 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29825085720687794		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.29825085720687794 | validation: 0.3219320109475009]
	TIME [epoch: 8.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2466122038018328		[learning rate: 0.00090152]
	Learning Rate: 0.000901518
	LOSS [training: 0.2466122038018328 | validation: 0.18471930170275153]
	TIME [epoch: 8.51 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20170536781907394		[learning rate: 0.00089939]
	Learning Rate: 0.000899391
	LOSS [training: 0.20170536781907394 | validation: 0.175635685666675]
	TIME [epoch: 8.51 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23841382687422877		[learning rate: 0.00089727]
	Learning Rate: 0.00089727
	LOSS [training: 0.23841382687422877 | validation: 0.17012302826747153]
	TIME [epoch: 8.53 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28542351136764094		[learning rate: 0.00089515]
	Learning Rate: 0.000895153
	LOSS [training: 0.28542351136764094 | validation: 0.2870240941838943]
	TIME [epoch: 8.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24765550009757664		[learning rate: 0.00089304]
	Learning Rate: 0.000893042
	LOSS [training: 0.24765550009757664 | validation: 0.2393636649305578]
	TIME [epoch: 8.51 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27606922021812863		[learning rate: 0.00089094]
	Learning Rate: 0.000890935
	LOSS [training: 0.27606922021812863 | validation: 0.2200199091163785]
	TIME [epoch: 8.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2716763855524311		[learning rate: 0.00088883]
	Learning Rate: 0.000888834
	LOSS [training: 0.2716763855524311 | validation: 0.21568768836464708]
	TIME [epoch: 8.52 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22950888400606329		[learning rate: 0.00088674]
	Learning Rate: 0.000886737
	LOSS [training: 0.22950888400606329 | validation: 0.21386223712151703]
	TIME [epoch: 8.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19592927510944436		[learning rate: 0.00088465]
	Learning Rate: 0.000884645
	LOSS [training: 0.19592927510944436 | validation: 0.1802776218784598]
	TIME [epoch: 8.51 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21150521022561114		[learning rate: 0.00088256]
	Learning Rate: 0.000882559
	LOSS [training: 0.21150521022561114 | validation: 0.17479244719693793]
	TIME [epoch: 8.51 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19708737869117215		[learning rate: 0.00088048]
	Learning Rate: 0.000880477
	LOSS [training: 0.19708737869117215 | validation: 0.16151938185145365]
	TIME [epoch: 8.52 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21279585191910777		[learning rate: 0.0008784]
	Learning Rate: 0.0008784
	LOSS [training: 0.21279585191910777 | validation: 0.17122016602199833]
	TIME [epoch: 8.53 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1923433207663408		[learning rate: 0.00087633]
	Learning Rate: 0.000876328
	LOSS [training: 0.1923433207663408 | validation: 0.188343557624426]
	TIME [epoch: 8.51 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18394120870427252		[learning rate: 0.00087426]
	Learning Rate: 0.000874261
	LOSS [training: 0.18394120870427252 | validation: 0.21053907693177887]
	TIME [epoch: 8.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19058647866486927		[learning rate: 0.0008722]
	Learning Rate: 0.000872199
	LOSS [training: 0.19058647866486927 | validation: 0.19905054817015885]
	TIME [epoch: 8.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24079640787063067		[learning rate: 0.00087014]
	Learning Rate: 0.000870141
	LOSS [training: 0.24079640787063067 | validation: 0.5054816166489096]
	TIME [epoch: 8.52 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31642671614471113		[learning rate: 0.00086809]
	Learning Rate: 0.000868089
	LOSS [training: 0.31642671614471113 | validation: 0.20139793242229992]
	TIME [epoch: 8.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2318341863555055		[learning rate: 0.00086604]
	Learning Rate: 0.000866041
	LOSS [training: 0.2318341863555055 | validation: 0.26158783300771604]
	TIME [epoch: 8.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19451529629914477		[learning rate: 0.000864]
	Learning Rate: 0.000863998
	LOSS [training: 0.19451529629914477 | validation: 0.22611954651839913]
	TIME [epoch: 8.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18175669125681526		[learning rate: 0.00086196]
	Learning Rate: 0.00086196
	LOSS [training: 0.18175669125681526 | validation: 0.16402272662761352]
	TIME [epoch: 8.52 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19855505832663464		[learning rate: 0.00085993]
	Learning Rate: 0.000859927
	LOSS [training: 0.19855505832663464 | validation: 0.1817305327921156]
	TIME [epoch: 8.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1818896022147985		[learning rate: 0.0008579]
	Learning Rate: 0.000857898
	LOSS [training: 0.1818896022147985 | validation: 0.14331718695245504]
	TIME [epoch: 8.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.176262771738255		[learning rate: 0.00085587]
	Learning Rate: 0.000855875
	LOSS [training: 0.176262771738255 | validation: 0.17720884321411312]
	TIME [epoch: 8.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16682034074094682		[learning rate: 0.00085386]
	Learning Rate: 0.000853856
	LOSS [training: 0.16682034074094682 | validation: 0.15275920605937282]
	TIME [epoch: 8.52 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1961414696391362		[learning rate: 0.00085184]
	Learning Rate: 0.000851842
	LOSS [training: 0.1961414696391362 | validation: 0.22473738942548746]
	TIME [epoch: 8.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1788903438613054		[learning rate: 0.00084983]
	Learning Rate: 0.000849832
	LOSS [training: 0.1788903438613054 | validation: 0.19583523660844585]
	TIME [epoch: 8.5 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2460434620813922		[learning rate: 0.00084783]
	Learning Rate: 0.000847828
	LOSS [training: 0.2460434620813922 | validation: 0.13731867385286597]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_1095.pth
	Model improved!!!
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14399173867149925		[learning rate: 0.00084583]
	Learning Rate: 0.000845828
	LOSS [training: 0.14399173867149925 | validation: 0.1597808220875762]
	TIME [epoch: 8.53 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18515163384206262		[learning rate: 0.00084383]
	Learning Rate: 0.000843833
	LOSS [training: 0.18515163384206262 | validation: 0.1903006225737114]
	TIME [epoch: 8.54 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20592577849595378		[learning rate: 0.00084184]
	Learning Rate: 0.000841842
	LOSS [training: 0.20592577849595378 | validation: 0.14176633211282624]
	TIME [epoch: 8.52 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19295660053452884		[learning rate: 0.00083986]
	Learning Rate: 0.000839856
	LOSS [training: 0.19295660053452884 | validation: 0.17919422126226364]
	TIME [epoch: 8.52 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20333500671073695		[learning rate: 0.00083788]
	Learning Rate: 0.000837876
	LOSS [training: 0.20333500671073695 | validation: 0.2680049555380393]
	TIME [epoch: 8.52 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2133373585631558		[learning rate: 0.0008359]
	Learning Rate: 0.000835899
	LOSS [training: 0.2133373585631558 | validation: 0.18724367880679132]
	TIME [epoch: 8.55 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20804234859379145		[learning rate: 0.00083393]
	Learning Rate: 0.000833927
	LOSS [training: 0.20804234859379145 | validation: 0.22248098395909655]
	TIME [epoch: 8.53 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21017991331996844		[learning rate: 0.00083196]
	Learning Rate: 0.00083196
	LOSS [training: 0.21017991331996844 | validation: 0.12685870272294125]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_1103.pth
	Model improved!!!
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2369900701796362		[learning rate: 0.00083]
	Learning Rate: 0.000829998
	LOSS [training: 0.2369900701796362 | validation: 0.20800374367093402]
	TIME [epoch: 8.53 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21955729856292225		[learning rate: 0.00082804]
	Learning Rate: 0.00082804
	LOSS [training: 0.21955729856292225 | validation: 0.2238882429420815]
	TIME [epoch: 8.55 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23967659341739092		[learning rate: 0.00082609]
	Learning Rate: 0.000826087
	LOSS [training: 0.23967659341739092 | validation: 0.294454531428817]
	TIME [epoch: 8.53 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35567951958732896		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.35567951958732896 | validation: 0.2648480825124267]
	TIME [epoch: 8.52 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26787509183510594		[learning rate: 0.00082219]
	Learning Rate: 0.000822194
	LOSS [training: 0.26787509183510594 | validation: 0.25462892192886666]
	TIME [epoch: 8.52 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29191984152171796		[learning rate: 0.00082025]
	Learning Rate: 0.000820254
	LOSS [training: 0.29191984152171796 | validation: 0.3353001028807039]
	TIME [epoch: 8.54 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27738185418142336		[learning rate: 0.00081832]
	Learning Rate: 0.00081832
	LOSS [training: 0.27738185418142336 | validation: 0.27060583100246205]
	TIME [epoch: 8.53 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2344051465687437		[learning rate: 0.00081639]
	Learning Rate: 0.000816389
	LOSS [training: 0.2344051465687437 | validation: 0.22735276415241024]
	TIME [epoch: 8.53 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24202233362072317		[learning rate: 0.00081446]
	Learning Rate: 0.000814464
	LOSS [training: 0.24202233362072317 | validation: 0.24472034066535572]
	TIME [epoch: 8.53 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25794561990258835		[learning rate: 0.00081254]
	Learning Rate: 0.000812543
	LOSS [training: 0.25794561990258835 | validation: 0.2060690031894563]
	TIME [epoch: 8.54 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19961329550511916		[learning rate: 0.00081063]
	Learning Rate: 0.000810626
	LOSS [training: 0.19961329550511916 | validation: 0.29870273647347395]
	TIME [epoch: 8.53 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2665794269133228		[learning rate: 0.00080871]
	Learning Rate: 0.000808714
	LOSS [training: 0.2665794269133228 | validation: 0.23036406769294315]
	TIME [epoch: 8.54 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2824799401750389		[learning rate: 0.00080681]
	Learning Rate: 0.000806806
	LOSS [training: 0.2824799401750389 | validation: 0.19078762952626]
	TIME [epoch: 8.53 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30245728808772415		[learning rate: 0.0008049]
	Learning Rate: 0.000804903
	LOSS [training: 0.30245728808772415 | validation: 0.23590987264530927]
	TIME [epoch: 8.53 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26842730962592143		[learning rate: 0.000803]
	Learning Rate: 0.000803004
	LOSS [training: 0.26842730962592143 | validation: 0.21242456617088804]
	TIME [epoch: 8.55 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2622049175950256		[learning rate: 0.00080111]
	Learning Rate: 0.00080111
	LOSS [training: 0.2622049175950256 | validation: 0.23349487431326327]
	TIME [epoch: 8.52 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24455234772060294		[learning rate: 0.00079922]
	Learning Rate: 0.000799221
	LOSS [training: 0.24455234772060294 | validation: 0.20748918969737895]
	TIME [epoch: 8.53 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24287282558100293		[learning rate: 0.00079734]
	Learning Rate: 0.000797335
	LOSS [training: 0.24287282558100293 | validation: 0.2863494405042293]
	TIME [epoch: 8.52 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2527648204956336		[learning rate: 0.00079545]
	Learning Rate: 0.000795454
	LOSS [training: 0.2527648204956336 | validation: 0.22735320412426685]
	TIME [epoch: 8.55 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20435742109132926		[learning rate: 0.00079358]
	Learning Rate: 0.000793578
	LOSS [training: 0.20435742109132926 | validation: 0.17193728866702798]
	TIME [epoch: 8.52 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22482424260096234		[learning rate: 0.00079171]
	Learning Rate: 0.000791706
	LOSS [training: 0.22482424260096234 | validation: 0.24315946546623385]
	TIME [epoch: 8.52 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19698633243276306		[learning rate: 0.00078984]
	Learning Rate: 0.000789839
	LOSS [training: 0.19698633243276306 | validation: 0.1672993057833054]
	TIME [epoch: 8.53 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19039179719925445		[learning rate: 0.00078798]
	Learning Rate: 0.000787976
	LOSS [training: 0.19039179719925445 | validation: 0.17155230044099895]
	TIME [epoch: 8.55 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18891876631920276		[learning rate: 0.00078612]
	Learning Rate: 0.000786117
	LOSS [training: 0.18891876631920276 | validation: 0.2650624734822997]
	TIME [epoch: 8.53 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23102529044222128		[learning rate: 0.00078426]
	Learning Rate: 0.000784263
	LOSS [training: 0.23102529044222128 | validation: 0.17297869650495507]
	TIME [epoch: 8.52 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19408571218836884		[learning rate: 0.00078241]
	Learning Rate: 0.000782413
	LOSS [training: 0.19408571218836884 | validation: 0.1592028270996923]
	TIME [epoch: 8.52 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17433629950503388		[learning rate: 0.00078057]
	Learning Rate: 0.000780567
	LOSS [training: 0.17433629950503388 | validation: 0.1856686054592382]
	TIME [epoch: 8.53 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23031783421751673		[learning rate: 0.00077873]
	Learning Rate: 0.000778726
	LOSS [training: 0.23031783421751673 | validation: 0.23463314650138817]
	TIME [epoch: 8.52 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2133633674073428		[learning rate: 0.00077689]
	Learning Rate: 0.000776889
	LOSS [training: 0.2133633674073428 | validation: 0.16782239459109033]
	TIME [epoch: 8.52 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19436945630829303		[learning rate: 0.00077506]
	Learning Rate: 0.000775056
	LOSS [training: 0.19436945630829303 | validation: 0.15069826447076035]
	TIME [epoch: 8.52 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20726936889382		[learning rate: 0.00077323]
	Learning Rate: 0.000773228
	LOSS [training: 0.20726936889382 | validation: 0.2115975383932479]
	TIME [epoch: 8.53 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25706908136011497		[learning rate: 0.0007714]
	Learning Rate: 0.000771404
	LOSS [training: 0.25706908136011497 | validation: 0.20658899833769093]
	TIME [epoch: 8.53 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24158286628398917		[learning rate: 0.00076958]
	Learning Rate: 0.000769585
	LOSS [training: 0.24158286628398917 | validation: 0.23659211284958392]
	TIME [epoch: 8.52 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22257287420756974		[learning rate: 0.00076777]
	Learning Rate: 0.000767769
	LOSS [training: 0.22257287420756974 | validation: 0.16572971130925485]
	TIME [epoch: 8.52 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23885295412382704		[learning rate: 0.00076596]
	Learning Rate: 0.000765958
	LOSS [training: 0.23885295412382704 | validation: 0.23616120312415795]
	TIME [epoch: 8.52 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2354773465699739		[learning rate: 0.00076415]
	Learning Rate: 0.000764151
	LOSS [training: 0.2354773465699739 | validation: 0.17910412074513216]
	TIME [epoch: 8.54 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18129313188563018		[learning rate: 0.00076235]
	Learning Rate: 0.000762349
	LOSS [training: 0.18129313188563018 | validation: 0.16221546502696904]
	TIME [epoch: 8.52 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22139889004595653		[learning rate: 0.00076055]
	Learning Rate: 0.000760551
	LOSS [training: 0.22139889004595653 | validation: 0.2087674708519192]
	TIME [epoch: 8.52 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2381166299083836		[learning rate: 0.00075876]
	Learning Rate: 0.000758757
	LOSS [training: 0.2381166299083836 | validation: 0.192202405985213]
	TIME [epoch: 8.52 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22970927352222809		[learning rate: 0.00075697]
	Learning Rate: 0.000756967
	LOSS [training: 0.22970927352222809 | validation: 0.20900474778481623]
	TIME [epoch: 8.54 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22408047075349527		[learning rate: 0.00075518]
	Learning Rate: 0.000755181
	LOSS [training: 0.22408047075349527 | validation: 0.20513313651954518]
	TIME [epoch: 8.52 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19898944812322017		[learning rate: 0.0007534]
	Learning Rate: 0.0007534
	LOSS [training: 0.19898944812322017 | validation: 0.15024822995008474]
	TIME [epoch: 8.52 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18360002019842753		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.18360002019842753 | validation: 0.19215866942042348]
	TIME [epoch: 8.52 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23290170671998647		[learning rate: 0.00074985]
	Learning Rate: 0.00074985
	LOSS [training: 0.23290170671998647 | validation: 0.19964761901084271]
	TIME [epoch: 8.53 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22064677924635046		[learning rate: 0.00074808]
	Learning Rate: 0.000748081
	LOSS [training: 0.22064677924635046 | validation: 0.22870126751295225]
	TIME [epoch: 8.52 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18318144195894187		[learning rate: 0.00074632]
	Learning Rate: 0.000746316
	LOSS [training: 0.18318144195894187 | validation: 0.16460705519314595]
	TIME [epoch: 8.51 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18612748377774113		[learning rate: 0.00074456]
	Learning Rate: 0.000744556
	LOSS [training: 0.18612748377774113 | validation: 0.2069438651914821]
	TIME [epoch: 8.51 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2266695052385757		[learning rate: 0.0007428]
	Learning Rate: 0.0007428
	LOSS [training: 0.2266695052385757 | validation: 0.18666050956489896]
	TIME [epoch: 8.52 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22679644615232664		[learning rate: 0.00074105]
	Learning Rate: 0.000741048
	LOSS [training: 0.22679644615232664 | validation: 0.16624099035045556]
	TIME [epoch: 8.53 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22663231080010346		[learning rate: 0.0007393]
	Learning Rate: 0.0007393
	LOSS [training: 0.22663231080010346 | validation: 0.20296361196010781]
	TIME [epoch: 8.51 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21617852393956327		[learning rate: 0.00073756]
	Learning Rate: 0.000737556
	LOSS [training: 0.21617852393956327 | validation: 0.2100412128069623]
	TIME [epoch: 8.51 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1925145174790859		[learning rate: 0.00073582]
	Learning Rate: 0.000735816
	LOSS [training: 0.1925145174790859 | validation: 0.18361011759039642]
	TIME [epoch: 8.52 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2044998348888453		[learning rate: 0.00073408]
	Learning Rate: 0.00073408
	LOSS [training: 0.2044998348888453 | validation: 0.2000742754254724]
	TIME [epoch: 8.54 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32884018083033834		[learning rate: 0.00073235]
	Learning Rate: 0.000732349
	LOSS [training: 0.32884018083033834 | validation: 0.2908845511428365]
	TIME [epoch: 8.52 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28848806100476654		[learning rate: 0.00073062]
	Learning Rate: 0.000730621
	LOSS [training: 0.28848806100476654 | validation: 0.3030743121821945]
	TIME [epoch: 8.52 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2797029715690555		[learning rate: 0.0007289]
	Learning Rate: 0.000728898
	LOSS [training: 0.2797029715690555 | validation: 0.3025917079463014]
	TIME [epoch: 8.51 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2832408938901156		[learning rate: 0.00072718]
	Learning Rate: 0.000727178
	LOSS [training: 0.2832408938901156 | validation: 0.21366675744966418]
	TIME [epoch: 8.54 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23602482446942083		[learning rate: 0.00072546]
	Learning Rate: 0.000725463
	LOSS [training: 0.23602482446942083 | validation: 0.26931875947470274]
	TIME [epoch: 8.52 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20502846399127864		[learning rate: 0.00072375]
	Learning Rate: 0.000723752
	LOSS [training: 0.20502846399127864 | validation: 0.18954101588077077]
	TIME [epoch: 8.52 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19804032519928855		[learning rate: 0.00072204]
	Learning Rate: 0.000722045
	LOSS [training: 0.19804032519928855 | validation: 0.24557859197791865]
	TIME [epoch: 8.51 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21381562519865005		[learning rate: 0.00072034]
	Learning Rate: 0.000720342
	LOSS [training: 0.21381562519865005 | validation: 0.19713967978167019]
	TIME [epoch: 8.54 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21199898830784414		[learning rate: 0.00071864]
	Learning Rate: 0.000718642
	LOSS [training: 0.21199898830784414 | validation: 0.2860397200352862]
	TIME [epoch: 8.51 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2240299856841948		[learning rate: 0.00071695]
	Learning Rate: 0.000716947
	LOSS [training: 0.2240299856841948 | validation: 0.1410363609831675]
	TIME [epoch: 8.52 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.170111449713347		[learning rate: 0.00071526]
	Learning Rate: 0.000715256
	LOSS [training: 0.170111449713347 | validation: 0.18977308212459043]
	TIME [epoch: 8.52 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17863477670864353		[learning rate: 0.00071357]
	Learning Rate: 0.000713569
	LOSS [training: 0.17863477670864353 | validation: 0.21303690089983626]
	TIME [epoch: 8.53 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1957416851185123		[learning rate: 0.00071189]
	Learning Rate: 0.000711886
	LOSS [training: 0.1957416851185123 | validation: 0.13612467443723958]
	TIME [epoch: 8.52 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16708631227125573		[learning rate: 0.00071021]
	Learning Rate: 0.000710206
	LOSS [training: 0.16708631227125573 | validation: 0.17094807575729143]
	TIME [epoch: 8.52 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24135698283409904		[learning rate: 0.00070853]
	Learning Rate: 0.000708531
	LOSS [training: 0.24135698283409904 | validation: 0.3764623470150829]
	TIME [epoch: 8.52 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24432346401930025		[learning rate: 0.00070686]
	Learning Rate: 0.00070686
	LOSS [training: 0.24432346401930025 | validation: 0.14892819957748987]
	TIME [epoch: 8.51 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22483445448151218		[learning rate: 0.00070519]
	Learning Rate: 0.000705193
	LOSS [training: 0.22483445448151218 | validation: 0.18970698996805954]
	TIME [epoch: 8.54 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1972047872108287		[learning rate: 0.00070353]
	Learning Rate: 0.000703529
	LOSS [training: 0.1972047872108287 | validation: 0.24045393271446638]
	TIME [epoch: 8.52 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23771521212964583		[learning rate: 0.00070187]
	Learning Rate: 0.000701869
	LOSS [training: 0.23771521212964583 | validation: 0.20385198727008927]
	TIME [epoch: 8.51 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20720608878161925		[learning rate: 0.00070021]
	Learning Rate: 0.000700214
	LOSS [training: 0.20720608878161925 | validation: 0.15358619910737803]
	TIME [epoch: 8.52 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16337345866583408		[learning rate: 0.00069856]
	Learning Rate: 0.000698562
	LOSS [training: 0.16337345866583408 | validation: 0.19344729035364172]
	TIME [epoch: 8.54 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18111652709819098		[learning rate: 0.00069691]
	Learning Rate: 0.000696914
	LOSS [training: 0.18111652709819098 | validation: 0.1798881262098508]
	TIME [epoch: 8.52 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18830577478837524		[learning rate: 0.00069527]
	Learning Rate: 0.00069527
	LOSS [training: 0.18830577478837524 | validation: 0.17228470757804806]
	TIME [epoch: 8.52 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1753811254515488		[learning rate: 0.00069363]
	Learning Rate: 0.000693631
	LOSS [training: 0.1753811254515488 | validation: 0.17560583073679858]
	TIME [epoch: 8.52 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17416619272844922		[learning rate: 0.00069199]
	Learning Rate: 0.000691994
	LOSS [training: 0.17416619272844922 | validation: 0.17142417894606393]
	TIME [epoch: 8.54 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.176718483471105		[learning rate: 0.00069036]
	Learning Rate: 0.000690362
	LOSS [training: 0.176718483471105 | validation: 0.17962597025706706]
	TIME [epoch: 8.52 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21091533705639529		[learning rate: 0.00068873]
	Learning Rate: 0.000688734
	LOSS [training: 0.21091533705639529 | validation: 0.16671047223933577]
	TIME [epoch: 8.53 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18123943304634976		[learning rate: 0.00068711]
	Learning Rate: 0.000687109
	LOSS [training: 0.18123943304634976 | validation: 0.15334358374189255]
	TIME [epoch: 8.52 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19132952785576773		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.19132952785576773 | validation: 0.16173245964048202]
	TIME [epoch: 8.54 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17637013489007247		[learning rate: 0.00068387]
	Learning Rate: 0.000683871
	LOSS [training: 0.17637013489007247 | validation: 0.15694934087307177]
	TIME [epoch: 8.52 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1941863390632372		[learning rate: 0.00068226]
	Learning Rate: 0.000682258
	LOSS [training: 0.1941863390632372 | validation: 0.16476111364299448]
	TIME [epoch: 8.51 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21135196985689006		[learning rate: 0.00068065]
	Learning Rate: 0.000680649
	LOSS [training: 0.21135196985689006 | validation: 0.14295191961267983]
	TIME [epoch: 8.52 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.187703732944917		[learning rate: 0.00067904]
	Learning Rate: 0.000679043
	LOSS [training: 0.187703732944917 | validation: 0.2239559293538363]
	TIME [epoch: 8.52 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18922751473137048		[learning rate: 0.00067744]
	Learning Rate: 0.000677442
	LOSS [training: 0.18922751473137048 | validation: 0.17842959870801467]
	TIME [epoch: 8.54 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18668187277145631		[learning rate: 0.00067584]
	Learning Rate: 0.000675844
	LOSS [training: 0.18668187277145631 | validation: 0.15561617166959527]
	TIME [epoch: 8.52 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21146921020552503		[learning rate: 0.00067425]
	Learning Rate: 0.000674249
	LOSS [training: 0.21146921020552503 | validation: 0.20039696672779206]
	TIME [epoch: 8.52 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26209262141685735		[learning rate: 0.00067266]
	Learning Rate: 0.000672659
	LOSS [training: 0.26209262141685735 | validation: 0.1974751761766983]
	TIME [epoch: 8.52 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.227889761468495		[learning rate: 0.00067107]
	Learning Rate: 0.000671072
	LOSS [training: 0.227889761468495 | validation: 0.2158439132382995]
	TIME [epoch: 8.54 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19513127388667023		[learning rate: 0.00066949]
	Learning Rate: 0.000669489
	LOSS [training: 0.19513127388667023 | validation: 0.19129437008353223]
	TIME [epoch: 8.51 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2066886797741895		[learning rate: 0.00066791]
	Learning Rate: 0.00066791
	LOSS [training: 0.2066886797741895 | validation: 0.2566542416290325]
	TIME [epoch: 8.52 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22940052158692986		[learning rate: 0.00066633]
	Learning Rate: 0.000666335
	LOSS [training: 0.22940052158692986 | validation: 0.17025293063059072]
	TIME [epoch: 8.51 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20833443687184974		[learning rate: 0.00066476]
	Learning Rate: 0.000664763
	LOSS [training: 0.20833443687184974 | validation: 0.2171177699346079]
	TIME [epoch: 8.54 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23278078495056623		[learning rate: 0.00066319]
	Learning Rate: 0.000663195
	LOSS [training: 0.23278078495056623 | validation: 0.17516640403388556]
	TIME [epoch: 8.52 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16619978897333043		[learning rate: 0.00066163]
	Learning Rate: 0.00066163
	LOSS [training: 0.16619978897333043 | validation: 0.2168972527670503]
	TIME [epoch: 8.52 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2072089445008895		[learning rate: 0.00066007]
	Learning Rate: 0.00066007
	LOSS [training: 0.2072089445008895 | validation: 0.2299713692701818]
	TIME [epoch: 8.52 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20467484656140206		[learning rate: 0.00065851]
	Learning Rate: 0.000658513
	LOSS [training: 0.20467484656140206 | validation: 0.1779673388841668]
	TIME [epoch: 8.54 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18413330713584952		[learning rate: 0.00065696]
	Learning Rate: 0.000656959
	LOSS [training: 0.18413330713584952 | validation: 0.21158580840153612]
	TIME [epoch: 8.53 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20913952800446517		[learning rate: 0.00065541]
	Learning Rate: 0.00065541
	LOSS [training: 0.20913952800446517 | validation: 0.17976132997159192]
	TIME [epoch: 8.52 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18003772250496108		[learning rate: 0.00065386]
	Learning Rate: 0.000653864
	LOSS [training: 0.18003772250496108 | validation: 0.2012402735428384]
	TIME [epoch: 8.52 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19072671297579075		[learning rate: 0.00065232]
	Learning Rate: 0.000652321
	LOSS [training: 0.19072671297579075 | validation: 0.30448865324018526]
	TIME [epoch: 8.53 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24710549351681843		[learning rate: 0.00065078]
	Learning Rate: 0.000650783
	LOSS [training: 0.24710549351681843 | validation: 0.2149807794621913]
	TIME [epoch: 8.53 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21012870170442105		[learning rate: 0.00064925]
	Learning Rate: 0.000649247
	LOSS [training: 0.21012870170442105 | validation: 0.1606887509643687]
	TIME [epoch: 8.52 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17168467482862962		[learning rate: 0.00064772]
	Learning Rate: 0.000647716
	LOSS [training: 0.17168467482862962 | validation: 0.1761096930628776]
	TIME [epoch: 8.52 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18276462359499787		[learning rate: 0.00064619]
	Learning Rate: 0.000646188
	LOSS [training: 0.18276462359499787 | validation: 0.14807739620075083]
	TIME [epoch: 8.52 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1971083383535232		[learning rate: 0.00064466]
	Learning Rate: 0.000644664
	LOSS [training: 0.1971083383535232 | validation: 0.17132738872692788]
	TIME [epoch: 8.54 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1908966978864611		[learning rate: 0.00064314]
	Learning Rate: 0.000643143
	LOSS [training: 0.1908966978864611 | validation: 0.1901793310157034]
	TIME [epoch: 8.51 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22555146267522064		[learning rate: 0.00064163]
	Learning Rate: 0.000641626
	LOSS [training: 0.22555146267522064 | validation: 0.23117661830447278]
	TIME [epoch: 8.52 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27248578674959234		[learning rate: 0.00064011]
	Learning Rate: 0.000640113
	LOSS [training: 0.27248578674959234 | validation: 0.3243852481621649]
	TIME [epoch: 8.52 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22322801016332136		[learning rate: 0.0006386]
	Learning Rate: 0.000638603
	LOSS [training: 0.22322801016332136 | validation: 0.21227753843875768]
	TIME [epoch: 8.54 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19373669245504382		[learning rate: 0.0006371]
	Learning Rate: 0.000637096
	LOSS [training: 0.19373669245504382 | validation: 0.18204749983915441]
	TIME [epoch: 8.52 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16406993906881295		[learning rate: 0.00063559]
	Learning Rate: 0.000635594
	LOSS [training: 0.16406993906881295 | validation: 0.15020570339883502]
	TIME [epoch: 8.51 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20032329435739632		[learning rate: 0.00063409]
	Learning Rate: 0.000634094
	LOSS [training: 0.20032329435739632 | validation: 0.21058216171488497]
	TIME [epoch: 8.52 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18607533817243577		[learning rate: 0.0006326]
	Learning Rate: 0.000632598
	LOSS [training: 0.18607533817243577 | validation: 0.14428703302672352]
	TIME [epoch: 8.53 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16043662162130357		[learning rate: 0.00063111]
	Learning Rate: 0.000631106
	LOSS [training: 0.16043662162130357 | validation: 0.14285982869181846]
	TIME [epoch: 8.53 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16742613801082573		[learning rate: 0.00062962]
	Learning Rate: 0.000629618
	LOSS [training: 0.16742613801082573 | validation: 0.18232221646850938]
	TIME [epoch: 8.52 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1625906229542904		[learning rate: 0.00062813]
	Learning Rate: 0.000628132
	LOSS [training: 0.1625906229542904 | validation: 0.17779303228631888]
	TIME [epoch: 8.52 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1477644003455442		[learning rate: 0.00062665]
	Learning Rate: 0.000626651
	LOSS [training: 0.1477644003455442 | validation: 0.13800221564071619]
	TIME [epoch: 8.53 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15351413978895606		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.15351413978895606 | validation: 0.14007517092556693]
	TIME [epoch: 8.53 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18113671988221786		[learning rate: 0.0006237]
	Learning Rate: 0.000623698
	LOSS [training: 0.18113671988221786 | validation: 0.13783066403549965]
	TIME [epoch: 8.52 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18332401203232865		[learning rate: 0.00062223]
	Learning Rate: 0.000622227
	LOSS [training: 0.18332401203232865 | validation: 0.17915526138448626]
	TIME [epoch: 8.52 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1741472901645576		[learning rate: 0.00062076]
	Learning Rate: 0.000620759
	LOSS [training: 0.1741472901645576 | validation: 0.16122715932019255]
	TIME [epoch: 8.52 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1909238581524871		[learning rate: 0.00061929]
	Learning Rate: 0.000619295
	LOSS [training: 0.1909238581524871 | validation: 0.16107842133707537]
	TIME [epoch: 8.54 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16459225451350087		[learning rate: 0.00061783]
	Learning Rate: 0.000617834
	LOSS [training: 0.16459225451350087 | validation: 0.16025227056255942]
	TIME [epoch: 8.52 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1644206201183106		[learning rate: 0.00061638]
	Learning Rate: 0.000616377
	LOSS [training: 0.1644206201183106 | validation: 0.20486804310316414]
	TIME [epoch: 8.52 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1677900894142227		[learning rate: 0.00061492]
	Learning Rate: 0.000614923
	LOSS [training: 0.1677900894142227 | validation: 0.135531957135223]
	TIME [epoch: 8.52 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15282242895745105		[learning rate: 0.00061347]
	Learning Rate: 0.000613472
	LOSS [training: 0.15282242895745105 | validation: 0.16977973784250833]
	TIME [epoch: 8.54 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19246929082352718		[learning rate: 0.00061203]
	Learning Rate: 0.000612025
	LOSS [training: 0.19246929082352718 | validation: 0.11786757292605995]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_1233.pth
	Model improved!!!
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18232539380293689		[learning rate: 0.00061058]
	Learning Rate: 0.000610581
	LOSS [training: 0.18232539380293689 | validation: 0.16293416610410483]
	TIME [epoch: 8.51 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18558868057173675		[learning rate: 0.00060914]
	Learning Rate: 0.000609141
	LOSS [training: 0.18558868057173675 | validation: 0.13129299724113794]
	TIME [epoch: 8.51 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14917527465589323		[learning rate: 0.0006077]
	Learning Rate: 0.000607704
	LOSS [training: 0.14917527465589323 | validation: 0.12840989973620315]
	TIME [epoch: 8.53 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16450389858639017		[learning rate: 0.00060627]
	Learning Rate: 0.000606271
	LOSS [training: 0.16450389858639017 | validation: 0.1894730554397123]
	TIME [epoch: 8.52 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19710240330109557		[learning rate: 0.00060484]
	Learning Rate: 0.000604841
	LOSS [training: 0.19710240330109557 | validation: 0.18345260824432227]
	TIME [epoch: 8.52 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16751026000588892		[learning rate: 0.00060341]
	Learning Rate: 0.000603414
	LOSS [training: 0.16751026000588892 | validation: 0.1454041805013887]
	TIME [epoch: 8.52 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1707063979543794		[learning rate: 0.00060199]
	Learning Rate: 0.000601991
	LOSS [training: 0.1707063979543794 | validation: 0.19321111088606163]
	TIME [epoch: 8.53 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17991475502186538		[learning rate: 0.00060057]
	Learning Rate: 0.000600571
	LOSS [training: 0.17991475502186538 | validation: 0.145008712299808]
	TIME [epoch: 8.53 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1858654002979736		[learning rate: 0.00059915]
	Learning Rate: 0.000599154
	LOSS [training: 0.1858654002979736 | validation: 0.1345085377627751]
	TIME [epoch: 8.52 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1518067976252367		[learning rate: 0.00059774]
	Learning Rate: 0.000597741
	LOSS [training: 0.1518067976252367 | validation: 0.18264073180283036]
	TIME [epoch: 8.51 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.215859301328266		[learning rate: 0.00059633]
	Learning Rate: 0.000596331
	LOSS [training: 0.215859301328266 | validation: 0.2259391740834979]
	TIME [epoch: 8.51 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20746539071986336		[learning rate: 0.00059492]
	Learning Rate: 0.000594924
	LOSS [training: 0.20746539071986336 | validation: 0.16338488139632704]
	TIME [epoch: 8.54 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17967756316510855		[learning rate: 0.00059352]
	Learning Rate: 0.000593521
	LOSS [training: 0.17967756316510855 | validation: 0.19969653984028812]
	TIME [epoch: 8.51 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.178318147652012		[learning rate: 0.00059212]
	Learning Rate: 0.000592121
	LOSS [training: 0.178318147652012 | validation: 0.14664053568234542]
	TIME [epoch: 8.51 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15655705872115144		[learning rate: 0.00059072]
	Learning Rate: 0.000590724
	LOSS [training: 0.15655705872115144 | validation: 0.13670870833049567]
	TIME [epoch: 8.51 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18194304337261386		[learning rate: 0.00058933]
	Learning Rate: 0.000589331
	LOSS [training: 0.18194304337261386 | validation: 0.14032374323493466]
	TIME [epoch: 8.54 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1697460735983521		[learning rate: 0.00058794]
	Learning Rate: 0.00058794
	LOSS [training: 0.1697460735983521 | validation: 0.12504621760859325]
	TIME [epoch: 8.51 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17319200588618158		[learning rate: 0.00058655]
	Learning Rate: 0.000586554
	LOSS [training: 0.17319200588618158 | validation: 0.14799852025801544]
	TIME [epoch: 8.51 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1548379342014875		[learning rate: 0.00058517]
	Learning Rate: 0.00058517
	LOSS [training: 0.1548379342014875 | validation: 0.12668828268605958]
	TIME [epoch: 8.51 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16521280227378288		[learning rate: 0.00058379]
	Learning Rate: 0.00058379
	LOSS [training: 0.16521280227378288 | validation: 0.1736641072417201]
	TIME [epoch: 8.53 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16106629082629237		[learning rate: 0.00058241]
	Learning Rate: 0.000582413
	LOSS [training: 0.16106629082629237 | validation: 0.1694812712496328]
	TIME [epoch: 8.51 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.173018477177304		[learning rate: 0.00058104]
	Learning Rate: 0.000581039
	LOSS [training: 0.173018477177304 | validation: 0.15778557062243914]
	TIME [epoch: 8.51 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.156650633779372		[learning rate: 0.00057967]
	Learning Rate: 0.000579668
	LOSS [training: 0.156650633779372 | validation: 0.16049596685774878]
	TIME [epoch: 8.52 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14861230160170366		[learning rate: 0.0005783]
	Learning Rate: 0.000578301
	LOSS [training: 0.14861230160170366 | validation: 0.12898987573017928]
	TIME [epoch: 8.53 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1613972489003423		[learning rate: 0.00057694]
	Learning Rate: 0.000576937
	LOSS [training: 0.1613972489003423 | validation: 0.13883436630511287]
	TIME [epoch: 8.52 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1667408488374557		[learning rate: 0.00057558]
	Learning Rate: 0.000575576
	LOSS [training: 0.1667408488374557 | validation: 0.13658493215430395]
	TIME [epoch: 8.52 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17331628080921863		[learning rate: 0.00057422]
	Learning Rate: 0.000574218
	LOSS [training: 0.17331628080921863 | validation: 0.1490495927539891]
	TIME [epoch: 8.51 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16133327176720014		[learning rate: 0.00057286]
	Learning Rate: 0.000572864
	LOSS [training: 0.16133327176720014 | validation: 0.14103093108546283]
	TIME [epoch: 8.51 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1711909871185473		[learning rate: 0.00057151]
	Learning Rate: 0.000571512
	LOSS [training: 0.1711909871185473 | validation: 0.17949102151705215]
	TIME [epoch: 8.53 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16513285945400785		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.16513285945400785 | validation: 0.1629474805385268]
	TIME [epoch: 8.51 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17893968321234457		[learning rate: 0.00056882]
	Learning Rate: 0.000568819
	LOSS [training: 0.17893968321234457 | validation: 0.16140134356413097]
	TIME [epoch: 8.51 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15298953232214665		[learning rate: 0.00056748]
	Learning Rate: 0.000567478
	LOSS [training: 0.15298953232214665 | validation: 0.1380751695039751]
	TIME [epoch: 8.51 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18476506793326425		[learning rate: 0.00056614]
	Learning Rate: 0.000566139
	LOSS [training: 0.18476506793326425 | validation: 0.19598296099138568]
	TIME [epoch: 8.53 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21349934710494806		[learning rate: 0.0005648]
	Learning Rate: 0.000564804
	LOSS [training: 0.21349934710494806 | validation: 0.15589272649254832]
	TIME [epoch: 8.51 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2197346903173555		[learning rate: 0.00056347]
	Learning Rate: 0.000563471
	LOSS [training: 0.2197346903173555 | validation: 0.1667167124943173]
	TIME [epoch: 8.51 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19058642167473824		[learning rate: 0.00056214]
	Learning Rate: 0.000562142
	LOSS [training: 0.19058642167473824 | validation: 0.19491865198914377]
	TIME [epoch: 8.51 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20401171022637365		[learning rate: 0.00056082]
	Learning Rate: 0.000560816
	LOSS [training: 0.20401171022637365 | validation: 0.1522980479486834]
	TIME [epoch: 8.54 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16135001938712262		[learning rate: 0.00055949]
	Learning Rate: 0.000559493
	LOSS [training: 0.16135001938712262 | validation: 0.12439817192641703]
	TIME [epoch: 8.51 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16797461323412366		[learning rate: 0.00055817]
	Learning Rate: 0.000558173
	LOSS [training: 0.16797461323412366 | validation: 0.16022205782440205]
	TIME [epoch: 8.51 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2205086974842137		[learning rate: 0.00055686]
	Learning Rate: 0.000556857
	LOSS [training: 0.2205086974842137 | validation: 0.22542501726143116]
	TIME [epoch: 8.51 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18344603325648987		[learning rate: 0.00055554]
	Learning Rate: 0.000555543
	LOSS [training: 0.18344603325648987 | validation: 0.16393904122265676]
	TIME [epoch: 8.53 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19297286582329912		[learning rate: 0.00055423]
	Learning Rate: 0.000554233
	LOSS [training: 0.19297286582329912 | validation: 0.18203972423909304]
	TIME [epoch: 8.52 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19718988130745052		[learning rate: 0.00055293]
	Learning Rate: 0.000552925
	LOSS [training: 0.19718988130745052 | validation: 0.1982983089573638]
	TIME [epoch: 8.51 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18559738725084302		[learning rate: 0.00055162]
	Learning Rate: 0.000551621
	LOSS [training: 0.18559738725084302 | validation: 0.1493277202626623]
	TIME [epoch: 8.51 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16593883875796053		[learning rate: 0.00055032]
	Learning Rate: 0.00055032
	LOSS [training: 0.16593883875796053 | validation: 0.1513736293686967]
	TIME [epoch: 8.52 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15908412790503204		[learning rate: 0.00054902]
	Learning Rate: 0.000549022
	LOSS [training: 0.15908412790503204 | validation: 0.14758995041602124]
	TIME [epoch: 8.52 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16673246253440888		[learning rate: 0.00054773]
	Learning Rate: 0.000547727
	LOSS [training: 0.16673246253440888 | validation: 0.19043422070501242]
	TIME [epoch: 8.51 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17179794554664274		[learning rate: 0.00054643]
	Learning Rate: 0.000546435
	LOSS [training: 0.17179794554664274 | validation: 0.15867612673052367]
	TIME [epoch: 8.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17241022859032584		[learning rate: 0.00054515]
	Learning Rate: 0.000545146
	LOSS [training: 0.17241022859032584 | validation: 0.1431945243994207]
	TIME [epoch: 8.51 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1547077154628098		[learning rate: 0.00054386]
	Learning Rate: 0.00054386
	LOSS [training: 0.1547077154628098 | validation: 0.16940967713937194]
	TIME [epoch: 8.54 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17190300117775323		[learning rate: 0.00054258]
	Learning Rate: 0.000542577
	LOSS [training: 0.17190300117775323 | validation: 0.16628075325450672]
	TIME [epoch: 8.51 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14615151344988367		[learning rate: 0.0005413]
	Learning Rate: 0.000541297
	LOSS [training: 0.14615151344988367 | validation: 0.13840401042449474]
	TIME [epoch: 8.51 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16940316557518625		[learning rate: 0.00054002]
	Learning Rate: 0.00054002
	LOSS [training: 0.16940316557518625 | validation: 0.14701045758070985]
	TIME [epoch: 8.51 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14606308134761659		[learning rate: 0.00053875]
	Learning Rate: 0.000538747
	LOSS [training: 0.14606308134761659 | validation: 0.16452694978901505]
	TIME [epoch: 8.53 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17817068613883827		[learning rate: 0.00053748]
	Learning Rate: 0.000537476
	LOSS [training: 0.17817068613883827 | validation: 0.2003812156413446]
	TIME [epoch: 8.51 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24342193503562565		[learning rate: 0.00053621]
	Learning Rate: 0.000536208
	LOSS [training: 0.24342193503562565 | validation: 0.1999815730709565]
	TIME [epoch: 8.51 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19655032944639506		[learning rate: 0.00053494]
	Learning Rate: 0.000534943
	LOSS [training: 0.19655032944639506 | validation: 0.15504354745110618]
	TIME [epoch: 8.51 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1647282348776134		[learning rate: 0.00053368]
	Learning Rate: 0.000533681
	LOSS [training: 0.1647282348776134 | validation: 0.167212238871566]
	TIME [epoch: 8.52 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.169854649090801		[learning rate: 0.00053242]
	Learning Rate: 0.000532422
	LOSS [training: 0.169854649090801 | validation: 0.15419628868875707]
	TIME [epoch: 8.51 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1705640501622826		[learning rate: 0.00053117]
	Learning Rate: 0.000531167
	LOSS [training: 0.1705640501622826 | validation: 0.1732698880556769]
	TIME [epoch: 8.51 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1606460307239137		[learning rate: 0.00052991]
	Learning Rate: 0.000529914
	LOSS [training: 0.1606460307239137 | validation: 0.13896155313559022]
	TIME [epoch: 8.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16179100705195665		[learning rate: 0.00052866]
	Learning Rate: 0.000528664
	LOSS [training: 0.16179100705195665 | validation: 0.12358788714444985]
	TIME [epoch: 8.52 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15916498214514024		[learning rate: 0.00052742]
	Learning Rate: 0.000527417
	LOSS [training: 0.15916498214514024 | validation: 0.1287762669952719]
	TIME [epoch: 8.53 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1872437814768018		[learning rate: 0.00052617]
	Learning Rate: 0.000526173
	LOSS [training: 0.1872437814768018 | validation: 0.21709852343632247]
	TIME [epoch: 8.52 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2002758812616739		[learning rate: 0.00052493]
	Learning Rate: 0.000524931
	LOSS [training: 0.2002758812616739 | validation: 0.180276469959958]
	TIME [epoch: 8.51 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1806025737623717		[learning rate: 0.00052369]
	Learning Rate: 0.000523693
	LOSS [training: 0.1806025737623717 | validation: 0.17841966691884997]
	TIME [epoch: 8.51 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16744973877705027		[learning rate: 0.00052246]
	Learning Rate: 0.000522458
	LOSS [training: 0.16744973877705027 | validation: 0.15025162972046008]
	TIME [epoch: 8.53 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17864096608786373		[learning rate: 0.00052123]
	Learning Rate: 0.000521225
	LOSS [training: 0.17864096608786373 | validation: 0.22450235071259406]
	TIME [epoch: 8.52 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18021184028627268		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.18021184028627268 | validation: 0.13630463589718406]
	TIME [epoch: 8.51 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14344103070357023		[learning rate: 0.00051877]
	Learning Rate: 0.000518769
	LOSS [training: 0.14344103070357023 | validation: 0.13947004269657395]
	TIME [epoch: 8.51 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1659691822708455		[learning rate: 0.00051755]
	Learning Rate: 0.000517546
	LOSS [training: 0.1659691822708455 | validation: 0.13433181245491532]
	TIME [epoch: 8.53 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14571374362096112		[learning rate: 0.00051632]
	Learning Rate: 0.000516325
	LOSS [training: 0.14571374362096112 | validation: 0.14516525944354464]
	TIME [epoch: 8.51 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17232119231068727		[learning rate: 0.00051511]
	Learning Rate: 0.000515107
	LOSS [training: 0.17232119231068727 | validation: 0.19908607018930663]
	TIME [epoch: 8.51 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16748066401230585		[learning rate: 0.00051389]
	Learning Rate: 0.000513892
	LOSS [training: 0.16748066401230585 | validation: 0.14434276844694094]
	TIME [epoch: 8.51 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18551791394496056		[learning rate: 0.00051268]
	Learning Rate: 0.00051268
	LOSS [training: 0.18551791394496056 | validation: 0.15552284378389508]
	TIME [epoch: 8.53 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15306830545365574		[learning rate: 0.00051147]
	Learning Rate: 0.00051147
	LOSS [training: 0.15306830545365574 | validation: 0.13856235896825003]
	TIME [epoch: 8.52 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19491850521597914		[learning rate: 0.00051026]
	Learning Rate: 0.000510264
	LOSS [training: 0.19491850521597914 | validation: 0.19386479834497178]
	TIME [epoch: 8.51 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22076220575744432		[learning rate: 0.00050906]
	Learning Rate: 0.00050906
	LOSS [training: 0.22076220575744432 | validation: 0.13495532153315068]
	TIME [epoch: 8.51 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16789493218429927		[learning rate: 0.00050786]
	Learning Rate: 0.000507859
	LOSS [training: 0.16789493218429927 | validation: 0.15303888913957087]
	TIME [epoch: 8.52 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17994883824907884		[learning rate: 0.00050666]
	Learning Rate: 0.000506662
	LOSS [training: 0.17994883824907884 | validation: 0.18197594989458102]
	TIME [epoch: 8.52 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19245385181639826		[learning rate: 0.00050547]
	Learning Rate: 0.000505466
	LOSS [training: 0.19245385181639826 | validation: 0.13766220166843615]
	TIME [epoch: 8.51 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17047208924439067		[learning rate: 0.00050427]
	Learning Rate: 0.000504274
	LOSS [training: 0.17047208924439067 | validation: 0.2177331092957591]
	TIME [epoch: 8.51 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2166780907898332		[learning rate: 0.00050308]
	Learning Rate: 0.000503085
	LOSS [training: 0.2166780907898332 | validation: 0.16819760567187653]
	TIME [epoch: 8.51 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1967265829207792		[learning rate: 0.0005019]
	Learning Rate: 0.000501898
	LOSS [training: 0.1967265829207792 | validation: 0.1746523682026368]
	TIME [epoch: 8.54 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1847858146712727		[learning rate: 0.00050071]
	Learning Rate: 0.000500714
	LOSS [training: 0.1847858146712727 | validation: 0.1490443322514864]
	TIME [epoch: 8.53 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1790831563095336		[learning rate: 0.00049953]
	Learning Rate: 0.000499533
	LOSS [training: 0.1790831563095336 | validation: 0.16066763894512964]
	TIME [epoch: 8.51 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15634114960414458		[learning rate: 0.00049835]
	Learning Rate: 0.000498355
	LOSS [training: 0.15634114960414458 | validation: 0.13936468449160855]
	TIME [epoch: 8.51 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14986083582565096		[learning rate: 0.00049718]
	Learning Rate: 0.000497179
	LOSS [training: 0.14986083582565096 | validation: 0.1305368616748317]
	TIME [epoch: 8.53 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15213910214712456		[learning rate: 0.00049601]
	Learning Rate: 0.000496006
	LOSS [training: 0.15213910214712456 | validation: 0.15060133476479207]
	TIME [epoch: 8.51 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1666332793317944		[learning rate: 0.00049484]
	Learning Rate: 0.000494836
	LOSS [training: 0.1666332793317944 | validation: 0.14231841205057813]
	TIME [epoch: 8.51 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1554033811871061		[learning rate: 0.00049367]
	Learning Rate: 0.000493669
	LOSS [training: 0.1554033811871061 | validation: 0.14531053558805962]
	TIME [epoch: 8.51 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15300145150159933		[learning rate: 0.0004925]
	Learning Rate: 0.000492505
	LOSS [training: 0.15300145150159933 | validation: 0.12828215140003235]
	TIME [epoch: 8.54 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15873540254291654		[learning rate: 0.00049134]
	Learning Rate: 0.000491343
	LOSS [training: 0.15873540254291654 | validation: 0.14191123844623474]
	TIME [epoch: 8.52 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1489404670466274		[learning rate: 0.00049018]
	Learning Rate: 0.000490184
	LOSS [training: 0.1489404670466274 | validation: 0.18813834956829129]
	TIME [epoch: 8.51 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19609810943583322		[learning rate: 0.00048903]
	Learning Rate: 0.000489027
	LOSS [training: 0.19609810943583322 | validation: 0.15780668389868696]
	TIME [epoch: 8.51 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16571915401370568		[learning rate: 0.00048787]
	Learning Rate: 0.000487874
	LOSS [training: 0.16571915401370568 | validation: 0.17288181545224612]
	TIME [epoch: 8.53 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.165306273456339		[learning rate: 0.00048672]
	Learning Rate: 0.000486723
	LOSS [training: 0.165306273456339 | validation: 0.20629749821343651]
	TIME [epoch: 8.51 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17094110539987561		[learning rate: 0.00048558]
	Learning Rate: 0.000485575
	LOSS [training: 0.17094110539987561 | validation: 0.12514662376249633]
	TIME [epoch: 8.51 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16062319462007799		[learning rate: 0.00048443]
	Learning Rate: 0.00048443
	LOSS [training: 0.16062319462007799 | validation: 0.17713992774229942]
	TIME [epoch: 8.51 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20704029573926125		[learning rate: 0.00048329]
	Learning Rate: 0.000483287
	LOSS [training: 0.20704029573926125 | validation: 0.15607719088575117]
	TIME [epoch: 8.51 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16347976256143187		[learning rate: 0.00048215]
	Learning Rate: 0.000482147
	LOSS [training: 0.16347976256143187 | validation: 0.17178598046092283]
	TIME [epoch: 8.53 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16362853732657692		[learning rate: 0.00048101]
	Learning Rate: 0.00048101
	LOSS [training: 0.16362853732657692 | validation: 0.13838815067151966]
	TIME [epoch: 8.51 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16434480057413886		[learning rate: 0.00047988]
	Learning Rate: 0.000479875
	LOSS [training: 0.16434480057413886 | validation: 0.13654980648644993]
	TIME [epoch: 8.51 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1492113275720564		[learning rate: 0.00047874]
	Learning Rate: 0.000478743
	LOSS [training: 0.1492113275720564 | validation: 0.16543810192559233]
	TIME [epoch: 8.51 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16882645774674643		[learning rate: 0.00047761]
	Learning Rate: 0.000477614
	LOSS [training: 0.16882645774674643 | validation: 0.12855699125530812]
	TIME [epoch: 8.53 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19257518631694567		[learning rate: 0.00047649]
	Learning Rate: 0.000476487
	LOSS [training: 0.19257518631694567 | validation: 0.25633614936760385]
	TIME [epoch: 8.51 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27032039423965204		[learning rate: 0.00047536]
	Learning Rate: 0.000475363
	LOSS [training: 0.27032039423965204 | validation: 0.2016408402337354]
	TIME [epoch: 8.51 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19334515511559214		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.19334515511559214 | validation: 0.12586847631579356]
	TIME [epoch: 8.51 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14483320398343466		[learning rate: 0.00047312]
	Learning Rate: 0.000473123
	LOSS [training: 0.14483320398343466 | validation: 0.12168019706529845]
	TIME [epoch: 8.53 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1448674409646867		[learning rate: 0.00047201]
	Learning Rate: 0.000472007
	LOSS [training: 0.1448674409646867 | validation: 0.14351897802325275]
	TIME [epoch: 8.51 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16049489686935642		[learning rate: 0.00047089]
	Learning Rate: 0.000470894
	LOSS [training: 0.16049489686935642 | validation: 0.13286493723334986]
	TIME [epoch: 8.51 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15338812229365095		[learning rate: 0.00046978]
	Learning Rate: 0.000469783
	LOSS [training: 0.15338812229365095 | validation: 0.12477767214679339]
	TIME [epoch: 8.51 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15062394274153582		[learning rate: 0.00046867]
	Learning Rate: 0.000468675
	LOSS [training: 0.15062394274153582 | validation: 0.1442468411670591]
	TIME [epoch: 8.52 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15473005553416883		[learning rate: 0.00046757]
	Learning Rate: 0.000467569
	LOSS [training: 0.15473005553416883 | validation: 0.1677600642910939]
	TIME [epoch: 8.51 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16997130638454666		[learning rate: 0.00046647]
	Learning Rate: 0.000466467
	LOSS [training: 0.16997130638454666 | validation: 0.153875861174537]
	TIME [epoch: 8.51 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15113730804501468		[learning rate: 0.00046537]
	Learning Rate: 0.000465366
	LOSS [training: 0.15113730804501468 | validation: 0.14086622497422224]
	TIME [epoch: 8.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1532471257126932		[learning rate: 0.00046427]
	Learning Rate: 0.000464269
	LOSS [training: 0.1532471257126932 | validation: 0.15819850802733854]
	TIME [epoch: 8.51 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17248419624135033		[learning rate: 0.00046317]
	Learning Rate: 0.000463173
	LOSS [training: 0.17248419624135033 | validation: 0.1345424528094686]
	TIME [epoch: 8.53 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16064756394568142		[learning rate: 0.00046208]
	Learning Rate: 0.000462081
	LOSS [training: 0.16064756394568142 | validation: 0.13678570468375176]
	TIME [epoch: 8.51 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15672888513093206		[learning rate: 0.00046099]
	Learning Rate: 0.000460991
	LOSS [training: 0.15672888513093206 | validation: 0.1391919381245852]
	TIME [epoch: 8.52 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16291332164692787		[learning rate: 0.0004599]
	Learning Rate: 0.000459903
	LOSS [training: 0.16291332164692787 | validation: 0.1165123617358036]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_1354.pth
	Model improved!!!
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15580322813318176		[learning rate: 0.00045882]
	Learning Rate: 0.000458819
	LOSS [training: 0.15580322813318176 | validation: 0.16713980137075551]
	TIME [epoch: 8.53 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16721951510399496		[learning rate: 0.00045774]
	Learning Rate: 0.000457736
	LOSS [training: 0.16721951510399496 | validation: 0.14254240329095166]
	TIME [epoch: 8.51 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15461313384005532		[learning rate: 0.00045666]
	Learning Rate: 0.000456657
	LOSS [training: 0.15461313384005532 | validation: 0.15882526122375645]
	TIME [epoch: 8.51 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17132400724533706		[learning rate: 0.00045558]
	Learning Rate: 0.000455579
	LOSS [training: 0.17132400724533706 | validation: 0.13745549209623475]
	TIME [epoch: 8.51 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15739787049026038		[learning rate: 0.0004545]
	Learning Rate: 0.000454505
	LOSS [training: 0.15739787049026038 | validation: 0.17008456206606334]
	TIME [epoch: 8.53 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1639396794375403		[learning rate: 0.00045343]
	Learning Rate: 0.000453433
	LOSS [training: 0.1639396794375403 | validation: 0.12766650339143562]
	TIME [epoch: 8.51 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15615894533964164		[learning rate: 0.00045236]
	Learning Rate: 0.000452363
	LOSS [training: 0.15615894533964164 | validation: 0.16191441484415398]
	TIME [epoch: 8.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1891576147554071		[learning rate: 0.0004513]
	Learning Rate: 0.000451296
	LOSS [training: 0.1891576147554071 | validation: 0.16609578120920657]
	TIME [epoch: 8.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1701600080403215		[learning rate: 0.00045023]
	Learning Rate: 0.000450232
	LOSS [training: 0.1701600080403215 | validation: 0.1457842344597432]
	TIME [epoch: 8.52 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14581840414246802		[learning rate: 0.00044917]
	Learning Rate: 0.000449169
	LOSS [training: 0.14581840414246802 | validation: 0.1309199952332985]
	TIME [epoch: 8.52 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16945319916963691		[learning rate: 0.00044811]
	Learning Rate: 0.00044811
	LOSS [training: 0.16945319916963691 | validation: 0.1475874165565659]
	TIME [epoch: 8.51 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16689943522961836		[learning rate: 0.00044705]
	Learning Rate: 0.000447053
	LOSS [training: 0.16689943522961836 | validation: 0.17606231368655467]
	TIME [epoch: 8.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18242965301011443		[learning rate: 0.000446]
	Learning Rate: 0.000445998
	LOSS [training: 0.18242965301011443 | validation: 0.15172970890320947]
	TIME [epoch: 8.51 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1541893443967996		[learning rate: 0.00044495]
	Learning Rate: 0.000444946
	LOSS [training: 0.1541893443967996 | validation: 0.14186320563298072]
	TIME [epoch: 8.52 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15886023321941567		[learning rate: 0.0004439]
	Learning Rate: 0.000443897
	LOSS [training: 0.15886023321941567 | validation: 0.16795708276455593]
	TIME [epoch: 8.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18224839192508296		[learning rate: 0.00044285]
	Learning Rate: 0.00044285
	LOSS [training: 0.18224839192508296 | validation: 0.1854190288854022]
	TIME [epoch: 8.51 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17189400339700903		[learning rate: 0.00044181]
	Learning Rate: 0.000441805
	LOSS [training: 0.17189400339700903 | validation: 0.14463484548792999]
	TIME [epoch: 8.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18346576423259206		[learning rate: 0.00044076]
	Learning Rate: 0.000440763
	LOSS [training: 0.18346576423259206 | validation: 0.17417507425443998]
	TIME [epoch: 8.53 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22672193550519512		[learning rate: 0.00043972]
	Learning Rate: 0.000439723
	LOSS [training: 0.22672193550519512 | validation: 0.1759737506010834]
	TIME [epoch: 8.51 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17248317014865558		[learning rate: 0.00043869]
	Learning Rate: 0.000438686
	LOSS [training: 0.17248317014865558 | validation: 0.15490202257875632]
	TIME [epoch: 8.51 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18936524063280466		[learning rate: 0.00043765]
	Learning Rate: 0.000437651
	LOSS [training: 0.18936524063280466 | validation: 0.1577252181442388]
	TIME [epoch: 8.51 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16618185869316232		[learning rate: 0.00043662]
	Learning Rate: 0.000436619
	LOSS [training: 0.16618185869316232 | validation: 0.1838996823837467]
	TIME [epoch: 8.53 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1672906957558248		[learning rate: 0.00043559]
	Learning Rate: 0.000435589
	LOSS [training: 0.1672906957558248 | validation: 0.16880900869570853]
	TIME [epoch: 8.51 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1846125469098334		[learning rate: 0.00043456]
	Learning Rate: 0.000434562
	LOSS [training: 0.1846125469098334 | validation: 0.139733966206541]
	TIME [epoch: 8.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14742181745250843		[learning rate: 0.00043354]
	Learning Rate: 0.000433536
	LOSS [training: 0.14742181745250843 | validation: 0.16046462257050312]
	TIME [epoch: 8.51 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16141354115777917		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.16141354115777917 | validation: 0.13001427453984]
	TIME [epoch: 8.52 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15710133886751607		[learning rate: 0.00043149]
	Learning Rate: 0.000431494
	LOSS [training: 0.15710133886751607 | validation: 0.14208241305893476]
	TIME [epoch: 8.52 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15634783403909197		[learning rate: 0.00043048]
	Learning Rate: 0.000430476
	LOSS [training: 0.15634783403909197 | validation: 0.16255379332944864]
	TIME [epoch: 8.51 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15857688659923821		[learning rate: 0.00042946]
	Learning Rate: 0.00042946
	LOSS [training: 0.15857688659923821 | validation: 0.1347492435120015]
	TIME [epoch: 8.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17304931710699		[learning rate: 0.00042845]
	Learning Rate: 0.000428447
	LOSS [training: 0.17304931710699 | validation: 0.1378622974116026]
	TIME [epoch: 8.51 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15541017182128594		[learning rate: 0.00042744]
	Learning Rate: 0.000427437
	LOSS [training: 0.15541017182128594 | validation: 0.154247761495232]
	TIME [epoch: 8.52 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15152445131288408		[learning rate: 0.00042643]
	Learning Rate: 0.000426428
	LOSS [training: 0.15152445131288408 | validation: 0.11884886303141502]
	TIME [epoch: 8.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14227320009870142		[learning rate: 0.00042542]
	Learning Rate: 0.000425423
	LOSS [training: 0.14227320009870142 | validation: 0.11791794140114642]
	TIME [epoch: 8.5 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13842931490174562		[learning rate: 0.00042442]
	Learning Rate: 0.000424419
	LOSS [training: 0.13842931490174562 | validation: 0.1257585939723355]
	TIME [epoch: 8.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1428784545853986		[learning rate: 0.00042342]
	Learning Rate: 0.000423418
	LOSS [training: 0.1428784545853986 | validation: 0.15021821157241097]
	TIME [epoch: 8.53 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1631574228688632		[learning rate: 0.00042242]
	Learning Rate: 0.000422419
	LOSS [training: 0.1631574228688632 | validation: 0.16188564021283383]
	TIME [epoch: 8.51 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15181452880586488		[learning rate: 0.00042142]
	Learning Rate: 0.000421423
	LOSS [training: 0.15181452880586488 | validation: 0.1438377759775465]
	TIME [epoch: 8.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16044090117646867		[learning rate: 0.00042043]
	Learning Rate: 0.000420429
	LOSS [training: 0.16044090117646867 | validation: 0.1338566013652246]
	TIME [epoch: 8.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15220528495977018		[learning rate: 0.00041944]
	Learning Rate: 0.000419437
	LOSS [training: 0.15220528495977018 | validation: 0.13418898596926132]
	TIME [epoch: 8.52 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1485264032532187		[learning rate: 0.00041845]
	Learning Rate: 0.000418448
	LOSS [training: 0.1485264032532187 | validation: 0.1358532594415146]
	TIME [epoch: 8.5 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1674974117651659		[learning rate: 0.00041746]
	Learning Rate: 0.00041746
	LOSS [training: 0.1674974117651659 | validation: 0.13693805103980672]
	TIME [epoch: 8.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14528165821889882		[learning rate: 0.00041648]
	Learning Rate: 0.000416476
	LOSS [training: 0.14528165821889882 | validation: 0.12775281576504877]
	TIME [epoch: 8.5 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15346375597992906		[learning rate: 0.00041549]
	Learning Rate: 0.000415493
	LOSS [training: 0.15346375597992906 | validation: 0.14293876050182125]
	TIME [epoch: 8.52 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15656150379415554		[learning rate: 0.00041451]
	Learning Rate: 0.000414513
	LOSS [training: 0.15656150379415554 | validation: 0.19557167301083556]
	TIME [epoch: 8.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17550376949306787		[learning rate: 0.00041354]
	Learning Rate: 0.000413535
	LOSS [training: 0.17550376949306787 | validation: 0.16242080890301425]
	TIME [epoch: 8.51 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1686082704242767		[learning rate: 0.00041256]
	Learning Rate: 0.00041256
	LOSS [training: 0.1686082704242767 | validation: 0.16102462341803314]
	TIME [epoch: 8.51 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20780403236555262		[learning rate: 0.00041159]
	Learning Rate: 0.000411587
	LOSS [training: 0.20780403236555262 | validation: 0.17446688083906292]
	TIME [epoch: 8.51 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16651885749800563		[learning rate: 0.00041062]
	Learning Rate: 0.000410616
	LOSS [training: 0.16651885749800563 | validation: 0.13222604041417368]
	TIME [epoch: 8.52 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14470951907199522		[learning rate: 0.00040965]
	Learning Rate: 0.000409647
	LOSS [training: 0.14470951907199522 | validation: 0.13444910031735613]
	TIME [epoch: 8.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1689919975186556		[learning rate: 0.00040868]
	Learning Rate: 0.000408681
	LOSS [training: 0.1689919975186556 | validation: 0.16845988387578903]
	TIME [epoch: 8.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19496012615976888		[learning rate: 0.00040772]
	Learning Rate: 0.000407717
	LOSS [training: 0.19496012615976888 | validation: 0.13674084303129075]
	TIME [epoch: 8.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14064104009037312		[learning rate: 0.00040676]
	Learning Rate: 0.000406755
	LOSS [training: 0.14064104009037312 | validation: 0.12307529755949667]
	TIME [epoch: 8.52 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13981542944660152		[learning rate: 0.0004058]
	Learning Rate: 0.000405796
	LOSS [training: 0.13981542944660152 | validation: 0.12367704759779216]
	TIME [epoch: 8.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13886145487641424		[learning rate: 0.00040484]
	Learning Rate: 0.000404839
	LOSS [training: 0.13886145487641424 | validation: 0.13065791669052657]
	TIME [epoch: 8.49 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1489094488632742		[learning rate: 0.00040388]
	Learning Rate: 0.000403884
	LOSS [training: 0.1489094488632742 | validation: 0.1657238024746645]
	TIME [epoch: 8.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15519404456237737		[learning rate: 0.00040293]
	Learning Rate: 0.000402931
	LOSS [training: 0.15519404456237737 | validation: 0.13099618500553117]
	TIME [epoch: 8.52 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14616841534578873		[learning rate: 0.00040198]
	Learning Rate: 0.000401981
	LOSS [training: 0.14616841534578873 | validation: 0.14486167182940882]
	TIME [epoch: 8.51 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16111492321571091		[learning rate: 0.00040103]
	Learning Rate: 0.000401032
	LOSS [training: 0.16111492321571091 | validation: 0.151405342632759]
	TIME [epoch: 8.5 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1576917525675064		[learning rate: 0.00040009]
	Learning Rate: 0.000400086
	LOSS [training: 0.1576917525675064 | validation: 0.15498587153170817]
	TIME [epoch: 8.51 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1452522073006181		[learning rate: 0.00039914]
	Learning Rate: 0.000399143
	LOSS [training: 0.1452522073006181 | validation: 0.11942640741409018]
	TIME [epoch: 8.52 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14646739218316276		[learning rate: 0.0003982]
	Learning Rate: 0.000398201
	LOSS [training: 0.14646739218316276 | validation: 0.16190077431664518]
	TIME [epoch: 8.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1584108932511161		[learning rate: 0.00039726]
	Learning Rate: 0.000397262
	LOSS [training: 0.1584108932511161 | validation: 0.17296673889249348]
	TIME [epoch: 8.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16021781237635266		[learning rate: 0.00039632]
	Learning Rate: 0.000396325
	LOSS [training: 0.16021781237635266 | validation: 0.1334663885098038]
	TIME [epoch: 8.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24690365046846816		[learning rate: 0.00039539]
	Learning Rate: 0.00039539
	LOSS [training: 0.24690365046846816 | validation: 0.242921897418576]
	TIME [epoch: 8.52 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21205601906401955		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.21205601906401955 | validation: 0.1794661642478133]
	TIME [epoch: 8.52 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20727527217421407		[learning rate: 0.00039353]
	Learning Rate: 0.000393527
	LOSS [training: 0.20727527217421407 | validation: 0.1593263979606518]
	TIME [epoch: 8.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16669552850950792		[learning rate: 0.0003926]
	Learning Rate: 0.000392599
	LOSS [training: 0.16669552850950792 | validation: 0.18493453684849911]
	TIME [epoch: 8.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19546886934155852		[learning rate: 0.00039167]
	Learning Rate: 0.000391672
	LOSS [training: 0.19546886934155852 | validation: 0.14547561126861275]
	TIME [epoch: 8.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1574965683921414		[learning rate: 0.00039075]
	Learning Rate: 0.000390748
	LOSS [training: 0.1574965683921414 | validation: 0.14803809398771475]
	TIME [epoch: 8.53 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15598506314112956		[learning rate: 0.00038983]
	Learning Rate: 0.000389827
	LOSS [training: 0.15598506314112956 | validation: 0.1697133044906192]
	TIME [epoch: 8.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14809312755123832		[learning rate: 0.00038891]
	Learning Rate: 0.000388907
	LOSS [training: 0.14809312755123832 | validation: 0.13583163393167502]
	TIME [epoch: 8.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1461969071489815		[learning rate: 0.00038799]
	Learning Rate: 0.00038799
	LOSS [training: 0.1461969071489815 | validation: 0.1622126690311914]
	TIME [epoch: 8.51 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.159573910750903		[learning rate: 0.00038707]
	Learning Rate: 0.000387075
	LOSS [training: 0.159573910750903 | validation: 0.1910955117755372]
	TIME [epoch: 8.53 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14585419396217922		[learning rate: 0.00038616]
	Learning Rate: 0.000386162
	LOSS [training: 0.14585419396217922 | validation: 0.14643130561159923]
	TIME [epoch: 8.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15205878914469448		[learning rate: 0.00038525]
	Learning Rate: 0.000385251
	LOSS [training: 0.15205878914469448 | validation: 0.25161008661299855]
	TIME [epoch: 8.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21189229671360632		[learning rate: 0.00038434]
	Learning Rate: 0.000384342
	LOSS [training: 0.21189229671360632 | validation: 0.20393045358141398]
	TIME [epoch: 8.51 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19209932697832657		[learning rate: 0.00038344]
	Learning Rate: 0.000383435
	LOSS [training: 0.19209932697832657 | validation: 0.20171030796231265]
	TIME [epoch: 8.51 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2050884551797873		[learning rate: 0.00038253]
	Learning Rate: 0.000382531
	LOSS [training: 0.2050884551797873 | validation: 0.23174273850784174]
	TIME [epoch: 8.51 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18480238982410985		[learning rate: 0.00038163]
	Learning Rate: 0.000381629
	LOSS [training: 0.18480238982410985 | validation: 0.16927632729824915]
	TIME [epoch: 8.49 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17990407402458392		[learning rate: 0.00038073]
	Learning Rate: 0.000380729
	LOSS [training: 0.17990407402458392 | validation: 0.16446116077968648]
	TIME [epoch: 8.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15607909490179653		[learning rate: 0.00037983]
	Learning Rate: 0.00037983
	LOSS [training: 0.15607909490179653 | validation: 0.1387937291071381]
	TIME [epoch: 8.52 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15859486018262814		[learning rate: 0.00037893]
	Learning Rate: 0.000378934
	LOSS [training: 0.15859486018262814 | validation: 0.14816356558154137]
	TIME [epoch: 8.51 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14723493776818505		[learning rate: 0.00037804]
	Learning Rate: 0.000378041
	LOSS [training: 0.14723493776818505 | validation: 0.1468547704973936]
	TIME [epoch: 8.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14680577363085806		[learning rate: 0.00037715]
	Learning Rate: 0.000377149
	LOSS [training: 0.14680577363085806 | validation: 0.13390366758443006]
	TIME [epoch: 8.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15281343176868395		[learning rate: 0.00037626]
	Learning Rate: 0.000376259
	LOSS [training: 0.15281343176868395 | validation: 0.14702769101148866]
	TIME [epoch: 8.5 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15194414683232324		[learning rate: 0.00037537]
	Learning Rate: 0.000375372
	LOSS [training: 0.15194414683232324 | validation: 0.14539819521852426]
	TIME [epoch: 8.53 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16467750314193308		[learning rate: 0.00037449]
	Learning Rate: 0.000374486
	LOSS [training: 0.16467750314193308 | validation: 0.12195504711402058]
	TIME [epoch: 8.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13961694871123992		[learning rate: 0.0003736]
	Learning Rate: 0.000373603
	LOSS [training: 0.13961694871123992 | validation: 0.19871133123938928]
	TIME [epoch: 8.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16007589439961623		[learning rate: 0.00037272]
	Learning Rate: 0.000372722
	LOSS [training: 0.16007589439961623 | validation: 0.16363520377807017]
	TIME [epoch: 8.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15577957048298202		[learning rate: 0.00037184]
	Learning Rate: 0.000371842
	LOSS [training: 0.15577957048298202 | validation: 0.12872244292964888]
	TIME [epoch: 8.52 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14575770481306027		[learning rate: 0.00037097]
	Learning Rate: 0.000370965
	LOSS [training: 0.14575770481306027 | validation: 0.15742087658339682]
	TIME [epoch: 8.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1523620239225256		[learning rate: 0.00037009]
	Learning Rate: 0.00037009
	LOSS [training: 0.1523620239225256 | validation: 0.13162261703188283]
	TIME [epoch: 8.49 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19974449440488673		[learning rate: 0.00036922]
	Learning Rate: 0.000369217
	LOSS [training: 0.19974449440488673 | validation: 0.14584774758760466]
	TIME [epoch: 8.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18676520157591572		[learning rate: 0.00036835]
	Learning Rate: 0.000368346
	LOSS [training: 0.18676520157591572 | validation: 0.14416199338409172]
	TIME [epoch: 8.52 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1541633616929524		[learning rate: 0.00036748]
	Learning Rate: 0.000367477
	LOSS [training: 0.1541633616929524 | validation: 0.12350251406004877]
	TIME [epoch: 8.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15124642394654014		[learning rate: 0.00036661]
	Learning Rate: 0.000366611
	LOSS [training: 0.15124642394654014 | validation: 0.1187316065554396]
	TIME [epoch: 8.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1566600663088449		[learning rate: 0.00036575]
	Learning Rate: 0.000365746
	LOSS [training: 0.1566600663088449 | validation: 0.14913109534123997]
	TIME [epoch: 8.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1534577542478064		[learning rate: 0.00036488]
	Learning Rate: 0.000364883
	LOSS [training: 0.1534577542478064 | validation: 0.11746836685195974]
	TIME [epoch: 8.51 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15155843153769327		[learning rate: 0.00036402]
	Learning Rate: 0.000364022
	LOSS [training: 0.15155843153769327 | validation: 0.12723222976435256]
	TIME [epoch: 8.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15453713546521838		[learning rate: 0.00036316]
	Learning Rate: 0.000363164
	LOSS [training: 0.15453713546521838 | validation: 0.1253941955203741]
	TIME [epoch: 8.52 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14050752391049456		[learning rate: 0.00036231]
	Learning Rate: 0.000362307
	LOSS [training: 0.14050752391049456 | validation: 0.13300096104320194]
	TIME [epoch: 8.49 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1558149845471103		[learning rate: 0.00036145]
	Learning Rate: 0.000361452
	LOSS [training: 0.1558149845471103 | validation: 0.1502017504464436]
	TIME [epoch: 8.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15661313681020833		[learning rate: 0.0003606]
	Learning Rate: 0.0003606
	LOSS [training: 0.15661313681020833 | validation: 0.11208734944359214]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_1457.pth
	Model improved!!!
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12451231487831815		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.12451231487831815 | validation: 0.1175689712707465]
	TIME [epoch: 8.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14322602851667593		[learning rate: 0.0003589]
	Learning Rate: 0.000358901
	LOSS [training: 0.14322602851667593 | validation: 0.14328275074374494]
	TIME [epoch: 8.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1395387154454962		[learning rate: 0.00035805]
	Learning Rate: 0.000358054
	LOSS [training: 0.1395387154454962 | validation: 0.12465711608574316]
	TIME [epoch: 8.51 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1399680927512803		[learning rate: 0.00035721]
	Learning Rate: 0.00035721
	LOSS [training: 0.1399680927512803 | validation: 0.14198730304679452]
	TIME [epoch: 8.52 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13716886832612457		[learning rate: 0.00035637]
	Learning Rate: 0.000356367
	LOSS [training: 0.13716886832612457 | validation: 0.1259676598410639]
	TIME [epoch: 8.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15128050619041908		[learning rate: 0.00035553]
	Learning Rate: 0.000355526
	LOSS [training: 0.15128050619041908 | validation: 0.1409429236595452]
	TIME [epoch: 8.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15059270747443848		[learning rate: 0.00035469]
	Learning Rate: 0.000354688
	LOSS [training: 0.15059270747443848 | validation: 0.12334697673364317]
	TIME [epoch: 8.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15064194759692986		[learning rate: 0.00035385]
	Learning Rate: 0.000353851
	LOSS [training: 0.15064194759692986 | validation: 0.14150999752279383]
	TIME [epoch: 8.52 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15382594867859142		[learning rate: 0.00035302]
	Learning Rate: 0.000353016
	LOSS [training: 0.15382594867859142 | validation: 0.16453971009243745]
	TIME [epoch: 8.5 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16376658243120037		[learning rate: 0.00035218]
	Learning Rate: 0.000352184
	LOSS [training: 0.16376658243120037 | validation: 0.16855312362634178]
	TIME [epoch: 8.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17164316087702897		[learning rate: 0.00035135]
	Learning Rate: 0.000351353
	LOSS [training: 0.17164316087702897 | validation: 0.17977318291348832]
	TIME [epoch: 8.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17666671364885664		[learning rate: 0.00035052]
	Learning Rate: 0.000350524
	LOSS [training: 0.17666671364885664 | validation: 0.16152462265004208]
	TIME [epoch: 8.52 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13684568859769014		[learning rate: 0.0003497]
	Learning Rate: 0.000349697
	LOSS [training: 0.13684568859769014 | validation: 0.12723372484951145]
	TIME [epoch: 8.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13746877966386456		[learning rate: 0.00034887]
	Learning Rate: 0.000348872
	LOSS [training: 0.13746877966386456 | validation: 0.1263179459586489]
	TIME [epoch: 8.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13694302445201112		[learning rate: 0.00034805]
	Learning Rate: 0.000348049
	LOSS [training: 0.13694302445201112 | validation: 0.12636980118758445]
	TIME [epoch: 8.49 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14169389278416117		[learning rate: 0.00034723]
	Learning Rate: 0.000347228
	LOSS [training: 0.14169389278416117 | validation: 0.1274255944285098]
	TIME [epoch: 8.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14851052126004216		[learning rate: 0.00034641]
	Learning Rate: 0.000346409
	LOSS [training: 0.14851052126004216 | validation: 0.13901862944716958]
	TIME [epoch: 8.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16216807458497384		[learning rate: 0.00034559]
	Learning Rate: 0.000345592
	LOSS [training: 0.16216807458497384 | validation: 0.1290376559116423]
	TIME [epoch: 8.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14771781481523028		[learning rate: 0.00034478]
	Learning Rate: 0.000344777
	LOSS [training: 0.14771781481523028 | validation: 0.1357922349310206]
	TIME [epoch: 8.49 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14951585419994995		[learning rate: 0.00034396]
	Learning Rate: 0.000343964
	LOSS [training: 0.14951585419994995 | validation: 0.12333494435477865]
	TIME [epoch: 8.49 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13781421968725677		[learning rate: 0.00034315]
	Learning Rate: 0.000343152
	LOSS [training: 0.13781421968725677 | validation: 0.12835191757005796]
	TIME [epoch: 8.52 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15026770743281231		[learning rate: 0.00034234]
	Learning Rate: 0.000342343
	LOSS [training: 0.15026770743281231 | validation: 0.1377224239050566]
	TIME [epoch: 8.49 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14945599451802322		[learning rate: 0.00034154]
	Learning Rate: 0.000341536
	LOSS [training: 0.14945599451802322 | validation: 0.14989906296076086]
	TIME [epoch: 8.49 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15112528387837504		[learning rate: 0.00034073]
	Learning Rate: 0.00034073
	LOSS [training: 0.15112528387837504 | validation: 0.15023362087603742]
	TIME [epoch: 8.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14496891461760436		[learning rate: 0.00033993]
	Learning Rate: 0.000339926
	LOSS [training: 0.14496891461760436 | validation: 0.12864953699221413]
	TIME [epoch: 8.51 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14312103075553562		[learning rate: 0.00033912]
	Learning Rate: 0.000339124
	LOSS [training: 0.14312103075553562 | validation: 0.14804004811876917]
	TIME [epoch: 8.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16151104279818387		[learning rate: 0.00033832]
	Learning Rate: 0.000338324
	LOSS [training: 0.16151104279818387 | validation: 0.1257970350719524]
	TIME [epoch: 8.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1399128105126185		[learning rate: 0.00033753]
	Learning Rate: 0.000337526
	LOSS [training: 0.1399128105126185 | validation: 0.12418764271555932]
	TIME [epoch: 8.49 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13645711369466768		[learning rate: 0.00033673]
	Learning Rate: 0.00033673
	LOSS [training: 0.13645711369466768 | validation: 0.1415851746910603]
	TIME [epoch: 8.51 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15064871391296192		[learning rate: 0.00033594]
	Learning Rate: 0.000335936
	LOSS [training: 0.15064871391296192 | validation: 0.1263237650388235]
	TIME [epoch: 8.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14291136376448724		[learning rate: 0.00033514]
	Learning Rate: 0.000335143
	LOSS [training: 0.14291136376448724 | validation: 0.16246939018130507]
	TIME [epoch: 8.49 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1421610581182024		[learning rate: 0.00033435]
	Learning Rate: 0.000334353
	LOSS [training: 0.1421610581182024 | validation: 0.13673466733795026]
	TIME [epoch: 8.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14842176065866047		[learning rate: 0.00033356]
	Learning Rate: 0.000333564
	LOSS [training: 0.14842176065866047 | validation: 0.15078223839860272]
	TIME [epoch: 8.49 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1343100486117152		[learning rate: 0.00033278]
	Learning Rate: 0.000332777
	LOSS [training: 0.1343100486117152 | validation: 0.13182732905864777]
	TIME [epoch: 8.52 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12825565809559716		[learning rate: 0.00033199]
	Learning Rate: 0.000331992
	LOSS [training: 0.12825565809559716 | validation: 0.1259016726412763]
	TIME [epoch: 8.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13580647510878013		[learning rate: 0.00033121]
	Learning Rate: 0.000331209
	LOSS [training: 0.13580647510878013 | validation: 0.1300823194599712]
	TIME [epoch: 8.49 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13129971478410457		[learning rate: 0.00033043]
	Learning Rate: 0.000330428
	LOSS [training: 0.13129971478410457 | validation: 0.13885972424494558]
	TIME [epoch: 8.49 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.149327601068542		[learning rate: 0.00032965]
	Learning Rate: 0.000329649
	LOSS [training: 0.149327601068542 | validation: 0.135769764593658]
	TIME [epoch: 8.53 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13572747938477636		[learning rate: 0.00032887]
	Learning Rate: 0.000328871
	LOSS [training: 0.13572747938477636 | validation: 0.14167307997447345]
	TIME [epoch: 8.49 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15539318104908606		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.15539318104908606 | validation: 0.15143762746328335]
	TIME [epoch: 8.49 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21059480493756064		[learning rate: 0.00032732]
	Learning Rate: 0.000327321
	LOSS [training: 0.21059480493756064 | validation: 0.17550333810803298]
	TIME [epoch: 8.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1654295649164758		[learning rate: 0.00032655]
	Learning Rate: 0.000326549
	LOSS [training: 0.1654295649164758 | validation: 0.1169480330938392]
	TIME [epoch: 8.52 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1332741919608324		[learning rate: 0.00032578]
	Learning Rate: 0.000325779
	LOSS [training: 0.1332741919608324 | validation: 0.11591207345740301]
	TIME [epoch: 8.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15897315327193887		[learning rate: 0.00032501]
	Learning Rate: 0.000325011
	LOSS [training: 0.15897315327193887 | validation: 0.1505761729203659]
	TIME [epoch: 8.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16335641431679007		[learning rate: 0.00032424]
	Learning Rate: 0.000324244
	LOSS [training: 0.16335641431679007 | validation: 0.1341307635787635]
	TIME [epoch: 8.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13845649992757558		[learning rate: 0.00032348]
	Learning Rate: 0.000323479
	LOSS [training: 0.13845649992757558 | validation: 0.12878413906108535]
	TIME [epoch: 8.52 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13896928063729352		[learning rate: 0.00032272]
	Learning Rate: 0.000322716
	LOSS [training: 0.13896928063729352 | validation: 0.12899640665013862]
	TIME [epoch: 8.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15170522582258078		[learning rate: 0.00032195]
	Learning Rate: 0.000321955
	LOSS [training: 0.15170522582258078 | validation: 0.12919985679471618]
	TIME [epoch: 8.51 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12933446040478744		[learning rate: 0.0003212]
	Learning Rate: 0.000321195
	LOSS [training: 0.12933446040478744 | validation: 0.13433169141054818]
	TIME [epoch: 8.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14140096430429308		[learning rate: 0.00032044]
	Learning Rate: 0.000320438
	LOSS [training: 0.14140096430429308 | validation: 0.15383919834072016]
	TIME [epoch: 8.51 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14484579488695562		[learning rate: 0.00031968]
	Learning Rate: 0.000319682
	LOSS [training: 0.14484579488695562 | validation: 0.14565819826426457]
	TIME [epoch: 8.52 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14334022944848304		[learning rate: 0.00031893]
	Learning Rate: 0.000318928
	LOSS [training: 0.14334022944848304 | validation: 0.11434382306934121]
	TIME [epoch: 8.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13258987923218074		[learning rate: 0.00031818]
	Learning Rate: 0.000318175
	LOSS [training: 0.13258987923218074 | validation: 0.1219149745251541]
	TIME [epoch: 8.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1406401345173354		[learning rate: 0.00031742]
	Learning Rate: 0.000317425
	LOSS [training: 0.1406401345173354 | validation: 0.12095927022145853]
	TIME [epoch: 8.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1465886691335382		[learning rate: 0.00031668]
	Learning Rate: 0.000316676
	LOSS [training: 0.1465886691335382 | validation: 0.14625344151715977]
	TIME [epoch: 8.52 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16763567624238895		[learning rate: 0.00031593]
	Learning Rate: 0.000315929
	LOSS [training: 0.16763567624238895 | validation: 0.1480633568026712]
	TIME [epoch: 8.49 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16955194084058361		[learning rate: 0.00031518]
	Learning Rate: 0.000315184
	LOSS [training: 0.16955194084058361 | validation: 0.14900327536195562]
	TIME [epoch: 8.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1488750346111253		[learning rate: 0.00031444]
	Learning Rate: 0.00031444
	LOSS [training: 0.1488750346111253 | validation: 0.14085719036975192]
	TIME [epoch: 8.49 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14290113204027768		[learning rate: 0.0003137]
	Learning Rate: 0.000313699
	LOSS [training: 0.14290113204027768 | validation: 0.12259331505566079]
	TIME [epoch: 8.52 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14395984380631943		[learning rate: 0.00031296]
	Learning Rate: 0.000312959
	LOSS [training: 0.14395984380631943 | validation: 0.13747581284683968]
	TIME [epoch: 8.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13884109053718713		[learning rate: 0.00031222]
	Learning Rate: 0.000312221
	LOSS [training: 0.13884109053718713 | validation: 0.14276976709534744]
	TIME [epoch: 8.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15915064086774		[learning rate: 0.00031148]
	Learning Rate: 0.000311484
	LOSS [training: 0.15915064086774 | validation: 0.1442930323063009]
	TIME [epoch: 8.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1385848176984197		[learning rate: 0.00031075]
	Learning Rate: 0.000310749
	LOSS [training: 0.1385848176984197 | validation: 0.12342712345532343]
	TIME [epoch: 8.51 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14137112648030548		[learning rate: 0.00031002]
	Learning Rate: 0.000310016
	LOSS [training: 0.14137112648030548 | validation: 0.13973216264495397]
	TIME [epoch: 8.51 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14178344960605163		[learning rate: 0.00030929]
	Learning Rate: 0.000309285
	LOSS [training: 0.14178344960605163 | validation: 0.1329646186146923]
	TIME [epoch: 8.5 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1396207639258266		[learning rate: 0.00030856]
	Learning Rate: 0.000308555
	LOSS [training: 0.1396207639258266 | validation: 0.12681293016823353]
	TIME [epoch: 8.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14128690217399298		[learning rate: 0.00030783]
	Learning Rate: 0.000307828
	LOSS [training: 0.14128690217399298 | validation: 0.13494893980301598]
	TIME [epoch: 8.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15633343017272244		[learning rate: 0.0003071]
	Learning Rate: 0.000307102
	LOSS [training: 0.15633343017272244 | validation: 0.16030646914917235]
	TIME [epoch: 8.51 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15124658695188553		[learning rate: 0.00030638]
	Learning Rate: 0.000306377
	LOSS [training: 0.15124658695188553 | validation: 0.13042435367773883]
	TIME [epoch: 8.51 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13856821112019946		[learning rate: 0.00030565]
	Learning Rate: 0.000305654
	LOSS [training: 0.13856821112019946 | validation: 0.12744513764780252]
	TIME [epoch: 8.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1339621673149122		[learning rate: 0.00030493]
	Learning Rate: 0.000304933
	LOSS [training: 0.1339621673149122 | validation: 0.1301709989169425]
	TIME [epoch: 8.51 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13668507219838175		[learning rate: 0.00030421]
	Learning Rate: 0.000304214
	LOSS [training: 0.13668507219838175 | validation: 0.14028330174052478]
	TIME [epoch: 8.52 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13795331326020735		[learning rate: 0.0003035]
	Learning Rate: 0.000303497
	LOSS [training: 0.13795331326020735 | validation: 0.11888787502186116]
	TIME [epoch: 8.51 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13091300900164987		[learning rate: 0.00030278]
	Learning Rate: 0.000302781
	LOSS [training: 0.13091300900164987 | validation: 0.12367322871943302]
	TIME [epoch: 8.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12896317328772358		[learning rate: 0.00030207]
	Learning Rate: 0.000302066
	LOSS [training: 0.12896317328772358 | validation: 0.1260343052733308]
	TIME [epoch: 8.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1378102539894803		[learning rate: 0.00030135]
	Learning Rate: 0.000301354
	LOSS [training: 0.1378102539894803 | validation: 0.12811976869128539]
	TIME [epoch: 8.51 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.126354676693266		[learning rate: 0.00030064]
	Learning Rate: 0.000300643
	LOSS [training: 0.126354676693266 | validation: 0.11983958862082392]
	TIME [epoch: 8.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13215311534764163		[learning rate: 0.00029993]
	Learning Rate: 0.000299934
	LOSS [training: 0.13215311534764163 | validation: 0.1495109590877372]
	TIME [epoch: 8.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18780655134919275		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.18780655134919275 | validation: 0.18318434198047867]
	TIME [epoch: 8.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18519523536444976		[learning rate: 0.00029852]
	Learning Rate: 0.000298521
	LOSS [training: 0.18519523536444976 | validation: 0.14052623198172826]
	TIME [epoch: 8.52 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15161941935326978		[learning rate: 0.00029782]
	Learning Rate: 0.000297816
	LOSS [training: 0.15161941935326978 | validation: 0.12268094344667971]
	TIME [epoch: 8.51 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1516993692870385		[learning rate: 0.00029711]
	Learning Rate: 0.000297114
	LOSS [training: 0.1516993692870385 | validation: 0.14185543624554037]
	TIME [epoch: 8.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1779659525113203		[learning rate: 0.00029641]
	Learning Rate: 0.000296413
	LOSS [training: 0.1779659525113203 | validation: 0.16559146915998196]
	TIME [epoch: 8.51 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17054476903192126		[learning rate: 0.00029571]
	Learning Rate: 0.000295714
	LOSS [training: 0.17054476903192126 | validation: 0.1374993091993023]
	TIME [epoch: 8.51 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14784678697391365		[learning rate: 0.00029502]
	Learning Rate: 0.000295016
	LOSS [training: 0.14784678697391365 | validation: 0.1191472686603108]
	TIME [epoch: 8.53 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1353995146653793		[learning rate: 0.00029432]
	Learning Rate: 0.00029432
	LOSS [training: 0.1353995146653793 | validation: 0.13477572738092736]
	TIME [epoch: 8.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14553112635340554		[learning rate: 0.00029363]
	Learning Rate: 0.000293626
	LOSS [training: 0.14553112635340554 | validation: 0.10966089913244681]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_1544.pth
	Model improved!!!
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14517186662552498		[learning rate: 0.00029293]
	Learning Rate: 0.000292934
	LOSS [training: 0.14517186662552498 | validation: 0.12467162650268149]
	TIME [epoch: 8.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14678256012633412		[learning rate: 0.00029224]
	Learning Rate: 0.000292243
	LOSS [training: 0.14678256012633412 | validation: 0.13282240808390888]
	TIME [epoch: 8.52 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1488298226979127		[learning rate: 0.00029155]
	Learning Rate: 0.000291553
	LOSS [training: 0.1488298226979127 | validation: 0.11539291625584913]
	TIME [epoch: 8.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1350761021016022		[learning rate: 0.00029087]
	Learning Rate: 0.000290866
	LOSS [training: 0.1350761021016022 | validation: 0.1137711091404669]
	TIME [epoch: 8.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12956966237911696		[learning rate: 0.00029018]
	Learning Rate: 0.000290179
	LOSS [training: 0.12956966237911696 | validation: 0.15011860726907605]
	TIME [epoch: 8.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15327365452780387		[learning rate: 0.00028949]
	Learning Rate: 0.000289495
	LOSS [training: 0.15327365452780387 | validation: 0.13006473437682314]
	TIME [epoch: 8.52 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14939944271123154		[learning rate: 0.00028881]
	Learning Rate: 0.000288812
	LOSS [training: 0.14939944271123154 | validation: 0.12380212118570627]
	TIME [epoch: 8.51 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1472522880559267		[learning rate: 0.00028813]
	Learning Rate: 0.000288131
	LOSS [training: 0.1472522880559267 | validation: 0.1370471795226148]
	TIME [epoch: 8.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1513560764977803		[learning rate: 0.00028745]
	Learning Rate: 0.000287451
	LOSS [training: 0.1513560764977803 | validation: 0.11967303594218014]
	TIME [epoch: 8.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14750265314987776		[learning rate: 0.00028677]
	Learning Rate: 0.000286773
	LOSS [training: 0.14750265314987776 | validation: 0.12319233782633296]
	TIME [epoch: 8.52 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1824203989548348		[learning rate: 0.0002861]
	Learning Rate: 0.000286097
	LOSS [training: 0.1824203989548348 | validation: 0.14986964659135293]
	TIME [epoch: 8.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16995171641825757		[learning rate: 0.00028542]
	Learning Rate: 0.000285422
	LOSS [training: 0.16995171641825757 | validation: 0.1267758562580178]
	TIME [epoch: 8.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14789444718489014		[learning rate: 0.00028475]
	Learning Rate: 0.000284749
	LOSS [training: 0.14789444718489014 | validation: 0.12683017276755776]
	TIME [epoch: 8.49 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14334143942173952		[learning rate: 0.00028408]
	Learning Rate: 0.000284077
	LOSS [training: 0.14334143942173952 | validation: 0.12483148487376233]
	TIME [epoch: 8.52 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13251987263835296		[learning rate: 0.00028341]
	Learning Rate: 0.000283407
	LOSS [training: 0.13251987263835296 | validation: 0.11293002234616309]
	TIME [epoch: 8.51 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13397489311403982		[learning rate: 0.00028274]
	Learning Rate: 0.000282738
	LOSS [training: 0.13397489311403982 | validation: 0.1119885049682584]
	TIME [epoch: 8.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12886504002166546		[learning rate: 0.00028207]
	Learning Rate: 0.000282071
	LOSS [training: 0.12886504002166546 | validation: 0.12575549726954605]
	TIME [epoch: 8.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14016761586305618		[learning rate: 0.00028141]
	Learning Rate: 0.000281406
	LOSS [training: 0.14016761586305618 | validation: 0.12974711519101173]
	TIME [epoch: 8.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1523653438047728		[learning rate: 0.00028074]
	Learning Rate: 0.000280742
	LOSS [training: 0.1523653438047728 | validation: 0.14702704073542291]
	TIME [epoch: 8.52 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14360659671258177		[learning rate: 0.00028008]
	Learning Rate: 0.00028008
	LOSS [training: 0.14360659671258177 | validation: 0.1492790006901967]
	TIME [epoch: 8.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14237642155332883		[learning rate: 0.00027942]
	Learning Rate: 0.000279419
	LOSS [training: 0.14237642155332883 | validation: 0.13358355150131468]
	TIME [epoch: 8.49 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18783264660541701		[learning rate: 0.00027876]
	Learning Rate: 0.00027876
	LOSS [training: 0.18783264660541701 | validation: 0.15829275474466878]
	TIME [epoch: 8.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16381005967235296		[learning rate: 0.0002781]
	Learning Rate: 0.000278103
	LOSS [training: 0.16381005967235296 | validation: 0.12670961873655595]
	TIME [epoch: 8.53 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13739103676618375		[learning rate: 0.00027745]
	Learning Rate: 0.000277447
	LOSS [training: 0.13739103676618375 | validation: 0.10644840000647221]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_1568.pth
	Model improved!!!
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13453955499674836		[learning rate: 0.00027679]
	Learning Rate: 0.000276792
	LOSS [training: 0.13453955499674836 | validation: 0.13502162284285063]
	TIME [epoch: 8.51 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13872254225493846		[learning rate: 0.00027614]
	Learning Rate: 0.000276139
	LOSS [training: 0.13872254225493846 | validation: 0.1312552702232615]
	TIME [epoch: 8.51 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14435838057214528		[learning rate: 0.00027549]
	Learning Rate: 0.000275488
	LOSS [training: 0.14435838057214528 | validation: 0.13600118853977855]
	TIME [epoch: 8.52 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14841398812288106		[learning rate: 0.00027484]
	Learning Rate: 0.000274838
	LOSS [training: 0.14841398812288106 | validation: 0.11322448089920945]
	TIME [epoch: 8.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1289633249195729		[learning rate: 0.00027419]
	Learning Rate: 0.00027419
	LOSS [training: 0.1289633249195729 | validation: 0.10670183025523465]
	TIME [epoch: 8.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13588836807776095		[learning rate: 0.00027354]
	Learning Rate: 0.000273543
	LOSS [training: 0.13588836807776095 | validation: 0.13707915382018]
	TIME [epoch: 8.49 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13905825148543272		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.13905825148543272 | validation: 0.15238806989349024]
	TIME [epoch: 8.52 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15407650744031096		[learning rate: 0.00027225]
	Learning Rate: 0.000272254
	LOSS [training: 0.15407650744031096 | validation: 0.1255654186026855]
	TIME [epoch: 8.51 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1633874425969722		[learning rate: 0.00027161]
	Learning Rate: 0.000271612
	LOSS [training: 0.1633874425969722 | validation: 0.14422482507041928]
	TIME [epoch: 8.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1663545420883185		[learning rate: 0.00027097]
	Learning Rate: 0.000270971
	LOSS [training: 0.1663545420883185 | validation: 0.11974250565726294]
	TIME [epoch: 8.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13667724956237434		[learning rate: 0.00027033]
	Learning Rate: 0.000270332
	LOSS [training: 0.13667724956237434 | validation: 0.13242368391259782]
	TIME [epoch: 8.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1398970553740908		[learning rate: 0.00026969]
	Learning Rate: 0.000269694
	LOSS [training: 0.1398970553740908 | validation: 0.12669609349503902]
	TIME [epoch: 8.51 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14912996272374013		[learning rate: 0.00026906]
	Learning Rate: 0.000269058
	LOSS [training: 0.14912996272374013 | validation: 0.1219627577182309]
	TIME [epoch: 8.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14202421386050107		[learning rate: 0.00026842]
	Learning Rate: 0.000268423
	LOSS [training: 0.14202421386050107 | validation: 0.13314149633602912]
	TIME [epoch: 8.49 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12797430935930887		[learning rate: 0.00026779]
	Learning Rate: 0.00026779
	LOSS [training: 0.12797430935930887 | validation: 0.11496318274556236]
	TIME [epoch: 8.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13367579220590148		[learning rate: 0.00026716]
	Learning Rate: 0.000267159
	LOSS [training: 0.13367579220590148 | validation: 0.13314532651827388]
	TIME [epoch: 8.53 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13763492838103503		[learning rate: 0.00026653]
	Learning Rate: 0.000266528
	LOSS [training: 0.13763492838103503 | validation: 0.12998684931351767]
	TIME [epoch: 8.49 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13970203964619227		[learning rate: 0.0002659]
	Learning Rate: 0.0002659
	LOSS [training: 0.13970203964619227 | validation: 0.12898716634887109]
	TIME [epoch: 8.49 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14828841631351306		[learning rate: 0.00026527]
	Learning Rate: 0.000265273
	LOSS [training: 0.14828841631351306 | validation: 0.12931537848092142]
	TIME [epoch: 8.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1382898503116193		[learning rate: 0.00026465]
	Learning Rate: 0.000264647
	LOSS [training: 0.1382898503116193 | validation: 0.1113085495265212]
	TIME [epoch: 8.53 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14168164965309551		[learning rate: 0.00026402]
	Learning Rate: 0.000264022
	LOSS [training: 0.14168164965309551 | validation: 0.16908812247667243]
	TIME [epoch: 8.51 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1539860820338879		[learning rate: 0.0002634]
	Learning Rate: 0.0002634
	LOSS [training: 0.1539860820338879 | validation: 0.1539435646426408]
	TIME [epoch: 8.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13460824057422224		[learning rate: 0.00026278]
	Learning Rate: 0.000262778
	LOSS [training: 0.13460824057422224 | validation: 0.1250872840596443]
	TIME [epoch: 8.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1380622176311381		[learning rate: 0.00026216]
	Learning Rate: 0.000262159
	LOSS [training: 0.1380622176311381 | validation: 0.12648685398399853]
	TIME [epoch: 8.52 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1255214106757433		[learning rate: 0.00026154]
	Learning Rate: 0.00026154
	LOSS [training: 0.1255214106757433 | validation: 0.11760355963684586]
	TIME [epoch: 8.52 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12652117674266322		[learning rate: 0.00026092]
	Learning Rate: 0.000260923
	LOSS [training: 0.12652117674266322 | validation: 0.13149524527522063]
	TIME [epoch: 8.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16317166281737283		[learning rate: 0.00026031]
	Learning Rate: 0.000260308
	LOSS [training: 0.16317166281737283 | validation: 0.11804995399568664]
	TIME [epoch: 8.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14375008577221154		[learning rate: 0.00025969]
	Learning Rate: 0.000259694
	LOSS [training: 0.14375008577221154 | validation: 0.1245049266965878]
	TIME [epoch: 8.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13733295215734823		[learning rate: 0.00025908]
	Learning Rate: 0.000259081
	LOSS [training: 0.13733295215734823 | validation: 0.1140907360026572]
	TIME [epoch: 8.51 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13770064866687232		[learning rate: 0.00025847]
	Learning Rate: 0.00025847
	LOSS [training: 0.13770064866687232 | validation: 0.14325268270722136]
	TIME [epoch: 8.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14128200551351372		[learning rate: 0.00025786]
	Learning Rate: 0.00025786
	LOSS [training: 0.14128200551351372 | validation: 0.139570224334281]
	TIME [epoch: 8.49 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1461017791279877		[learning rate: 0.00025725]
	Learning Rate: 0.000257252
	LOSS [training: 0.1461017791279877 | validation: 0.1373355541263115]
	TIME [epoch: 8.49 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1532835733602381		[learning rate: 0.00025665]
	Learning Rate: 0.000256645
	LOSS [training: 0.1532835733602381 | validation: 0.166796337681286]
	TIME [epoch: 8.52 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16028502782662918		[learning rate: 0.00025604]
	Learning Rate: 0.00025604
	LOSS [training: 0.16028502782662918 | validation: 0.14298024494061223]
	TIME [epoch: 8.49 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13490186451130437		[learning rate: 0.00025544]
	Learning Rate: 0.000255436
	LOSS [training: 0.13490186451130437 | validation: 0.11351570517713921]
	TIME [epoch: 8.49 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1204519084290649		[learning rate: 0.00025483]
	Learning Rate: 0.000254833
	LOSS [training: 0.1204519084290649 | validation: 0.11837476112464687]
	TIME [epoch: 8.49 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1394295070194531		[learning rate: 0.00025423]
	Learning Rate: 0.000254232
	LOSS [training: 0.1394295070194531 | validation: 0.13193465372324198]
	TIME [epoch: 8.52 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1222321718238982		[learning rate: 0.00025363]
	Learning Rate: 0.000253633
	LOSS [training: 0.1222321718238982 | validation: 0.1071042987114674]
	TIME [epoch: 8.49 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13206071469218988		[learning rate: 0.00025303]
	Learning Rate: 0.000253034
	LOSS [training: 0.13206071469218988 | validation: 0.10956325949328485]
	TIME [epoch: 8.49 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13017887449230944		[learning rate: 0.00025244]
	Learning Rate: 0.000252437
	LOSS [training: 0.13017887449230944 | validation: 0.11739925180136719]
	TIME [epoch: 8.49 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13178366256680582		[learning rate: 0.00025184]
	Learning Rate: 0.000251842
	LOSS [training: 0.13178366256680582 | validation: 0.11704091891935445]
	TIME [epoch: 8.51 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12471984229772307		[learning rate: 0.00025125]
	Learning Rate: 0.000251248
	LOSS [training: 0.12471984229772307 | validation: 0.11341638937489906]
	TIME [epoch: 8.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13461453742552462		[learning rate: 0.00025066]
	Learning Rate: 0.000250655
	LOSS [training: 0.13461453742552462 | validation: 0.1343654187593321]
	TIME [epoch: 8.49 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14585153252165112		[learning rate: 0.00025006]
	Learning Rate: 0.000250064
	LOSS [training: 0.14585153252165112 | validation: 0.1199602747637192]
	TIME [epoch: 8.49 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15173678615590183		[learning rate: 0.00024947]
	Learning Rate: 0.000249474
	LOSS [training: 0.15173678615590183 | validation: 0.12936317710428338]
	TIME [epoch: 8.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13716674224063818		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.13716674224063818 | validation: 0.12278319340917693]
	TIME [epoch: 8.51 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12268530064525154		[learning rate: 0.0002483]
	Learning Rate: 0.000248299
	LOSS [training: 0.12268530064525154 | validation: 0.12628714067262065]
	TIME [epoch: 8.49 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12653377558811046		[learning rate: 0.00024771]
	Learning Rate: 0.000247713
	LOSS [training: 0.12653377558811046 | validation: 0.13316336133281292]
	TIME [epoch: 8.49 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13255326468496142		[learning rate: 0.00024713]
	Learning Rate: 0.000247129
	LOSS [training: 0.13255326468496142 | validation: 0.11230902209447957]
	TIME [epoch: 8.49 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11862995112183297		[learning rate: 0.00024655]
	Learning Rate: 0.000246546
	LOSS [training: 0.11862995112183297 | validation: 0.11420761451389733]
	TIME [epoch: 8.52 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1238422738848803		[learning rate: 0.00024596]
	Learning Rate: 0.000245964
	LOSS [training: 0.1238422738848803 | validation: 0.11624838397553539]
	TIME [epoch: 8.49 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12141936211773816		[learning rate: 0.00024538]
	Learning Rate: 0.000245384
	LOSS [training: 0.12141936211773816 | validation: 0.11917647908854131]
	TIME [epoch: 8.49 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12020368072832258		[learning rate: 0.00024481]
	Learning Rate: 0.000244805
	LOSS [training: 0.12020368072832258 | validation: 0.12076880062841194]
	TIME [epoch: 8.49 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1338800141945753		[learning rate: 0.00024423]
	Learning Rate: 0.000244228
	LOSS [training: 0.1338800141945753 | validation: 0.12074432113645703]
	TIME [epoch: 8.52 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1254441277224722		[learning rate: 0.00024365]
	Learning Rate: 0.000243652
	LOSS [training: 0.1254441277224722 | validation: 0.11880151908924397]
	TIME [epoch: 8.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12743480240619617		[learning rate: 0.00024308]
	Learning Rate: 0.000243077
	LOSS [training: 0.12743480240619617 | validation: 0.12677195837580363]
	TIME [epoch: 8.49 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12174458687196346		[learning rate: 0.0002425]
	Learning Rate: 0.000242503
	LOSS [training: 0.12174458687196346 | validation: 0.12466540581911156]
	TIME [epoch: 8.49 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13193867874423057		[learning rate: 0.00024193]
	Learning Rate: 0.000241931
	LOSS [training: 0.13193867874423057 | validation: 0.11826138802261278]
	TIME [epoch: 8.51 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12942914726352048		[learning rate: 0.00024136]
	Learning Rate: 0.000241361
	LOSS [training: 0.12942914726352048 | validation: 0.12860415088648255]
	TIME [epoch: 8.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12710103876374032		[learning rate: 0.00024079]
	Learning Rate: 0.000240791
	LOSS [training: 0.12710103876374032 | validation: 0.12915180639489315]
	TIME [epoch: 8.49 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12648458014014152		[learning rate: 0.00024022]
	Learning Rate: 0.000240223
	LOSS [training: 0.12648458014014152 | validation: 0.12870157559760448]
	TIME [epoch: 8.49 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12554453630345677		[learning rate: 0.00023966]
	Learning Rate: 0.000239657
	LOSS [training: 0.12554453630345677 | validation: 0.11061304906296004]
	TIME [epoch: 8.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14172821459480245		[learning rate: 0.00023909]
	Learning Rate: 0.000239091
	LOSS [training: 0.14172821459480245 | validation: 0.11802010700608123]
	TIME [epoch: 8.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1420497484667397		[learning rate: 0.00023853]
	Learning Rate: 0.000238527
	LOSS [training: 0.1420497484667397 | validation: 0.14357693743401936]
	TIME [epoch: 8.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1562567948757823		[learning rate: 0.00023796]
	Learning Rate: 0.000237965
	LOSS [training: 0.1562567948757823 | validation: 0.13210041288959928]
	TIME [epoch: 8.49 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13368208697988943		[learning rate: 0.0002374]
	Learning Rate: 0.000237404
	LOSS [training: 0.13368208697988943 | validation: 0.1465010613548588]
	TIME [epoch: 8.49 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.134451324856166		[learning rate: 0.00023684]
	Learning Rate: 0.000236844
	LOSS [training: 0.134451324856166 | validation: 0.14208166197073285]
	TIME [epoch: 8.51 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1324124566539801		[learning rate: 0.00023628]
	Learning Rate: 0.000236285
	LOSS [training: 0.1324124566539801 | validation: 0.11786917521026002]
	TIME [epoch: 8.49 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13631589139835368		[learning rate: 0.00023573]
	Learning Rate: 0.000235728
	LOSS [training: 0.13631589139835368 | validation: 0.13768924077728317]
	TIME [epoch: 8.49 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1516499758455096		[learning rate: 0.00023517]
	Learning Rate: 0.000235171
	LOSS [training: 0.1516499758455096 | validation: 0.11083717622160104]
	TIME [epoch: 8.49 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13169411792488833		[learning rate: 0.00023462]
	Learning Rate: 0.000234617
	LOSS [training: 0.13169411792488833 | validation: 0.12319649844566938]
	TIME [epoch: 8.52 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14147665770683154		[learning rate: 0.00023406]
	Learning Rate: 0.000234063
	LOSS [training: 0.14147665770683154 | validation: 0.10681405913221659]
	TIME [epoch: 8.49 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13243370846003527		[learning rate: 0.00023351]
	Learning Rate: 0.000233511
	LOSS [training: 0.13243370846003527 | validation: 0.12963441840789108]
	TIME [epoch: 8.49 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14097722285207087		[learning rate: 0.00023296]
	Learning Rate: 0.00023296
	LOSS [training: 0.14097722285207087 | validation: 0.13090853129785446]
	TIME [epoch: 8.49 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1714906874400544		[learning rate: 0.00023241]
	Learning Rate: 0.000232411
	LOSS [training: 0.1714906874400544 | validation: 0.12596897122491094]
	TIME [epoch: 8.51 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14256413337497692		[learning rate: 0.00023186]
	Learning Rate: 0.000231863
	LOSS [training: 0.14256413337497692 | validation: 0.11308140836535141]
	TIME [epoch: 8.49 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1264711390292714		[learning rate: 0.00023132]
	Learning Rate: 0.000231316
	LOSS [training: 0.1264711390292714 | validation: 0.10855232650806274]
	TIME [epoch: 8.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1271669998833159		[learning rate: 0.00023077]
	Learning Rate: 0.00023077
	LOSS [training: 0.1271669998833159 | validation: 0.10818601262285361]
	TIME [epoch: 8.49 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1370675571219037		[learning rate: 0.00023023]
	Learning Rate: 0.000230226
	LOSS [training: 0.1370675571219037 | validation: 0.12750308204735636]
	TIME [epoch: 8.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18112627288572647		[learning rate: 0.00022968]
	Learning Rate: 0.000229683
	LOSS [training: 0.18112627288572647 | validation: 0.1494341974976852]
	TIME [epoch: 8.51 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1471431206251916		[learning rate: 0.00022914]
	Learning Rate: 0.000229141
	LOSS [training: 0.1471431206251916 | validation: 0.10497896682575601]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_1649.pth
	Model improved!!!
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1375014926750766		[learning rate: 0.0002286]
	Learning Rate: 0.0002286
	LOSS [training: 0.1375014926750766 | validation: 0.10727439778357437]
	TIME [epoch: 8.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14444113692332167		[learning rate: 0.00022806]
	Learning Rate: 0.000228061
	LOSS [training: 0.14444113692332167 | validation: 0.11597016184265699]
	TIME [epoch: 8.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12599316287562728		[learning rate: 0.00022752]
	Learning Rate: 0.000227523
	LOSS [training: 0.12599316287562728 | validation: 0.1176267417240136]
	TIME [epoch: 8.53 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13847288285740336		[learning rate: 0.00022699]
	Learning Rate: 0.000226986
	LOSS [training: 0.13847288285740336 | validation: 0.10885679190290234]
	TIME [epoch: 8.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12702579184571944		[learning rate: 0.00022645]
	Learning Rate: 0.000226451
	LOSS [training: 0.12702579184571944 | validation: 0.1324425167704693]
	TIME [epoch: 8.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1334992432092106		[learning rate: 0.00022592]
	Learning Rate: 0.000225917
	LOSS [training: 0.1334992432092106 | validation: 0.12434376436173701]
	TIME [epoch: 8.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12683177774341653		[learning rate: 0.00022538]
	Learning Rate: 0.000225384
	LOSS [training: 0.12683177774341653 | validation: 0.10622795487143986]
	TIME [epoch: 8.52 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12259204540794177		[learning rate: 0.00022485]
	Learning Rate: 0.000224852
	LOSS [training: 0.12259204540794177 | validation: 0.11574234823167329]
	TIME [epoch: 8.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12746310104147957		[learning rate: 0.00022432]
	Learning Rate: 0.000224322
	LOSS [training: 0.12746310104147957 | validation: 0.11642244133544526]
	TIME [epoch: 8.49 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13366866986945133		[learning rate: 0.00022379]
	Learning Rate: 0.000223793
	LOSS [training: 0.13366866986945133 | validation: 0.12531102703581465]
	TIME [epoch: 8.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13356038014037433		[learning rate: 0.00022326]
	Learning Rate: 0.000223265
	LOSS [training: 0.13356038014037433 | validation: 0.13531491268770438]
	TIME [epoch: 8.52 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1477812407674411		[learning rate: 0.00022274]
	Learning Rate: 0.000222738
	LOSS [training: 0.1477812407674411 | validation: 0.1398572251448016]
	TIME [epoch: 8.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12826405358398663		[learning rate: 0.00022221]
	Learning Rate: 0.000222213
	LOSS [training: 0.12826405358398663 | validation: 0.1269015851454084]
	TIME [epoch: 8.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12944472069514085		[learning rate: 0.00022169]
	Learning Rate: 0.000221689
	LOSS [training: 0.12944472069514085 | validation: 0.11791647512238027]
	TIME [epoch: 8.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1265810778475432		[learning rate: 0.00022117]
	Learning Rate: 0.000221166
	LOSS [training: 0.1265810778475432 | validation: 0.12180717973687402]
	TIME [epoch: 8.52 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1272316561838106		[learning rate: 0.00022064]
	Learning Rate: 0.000220644
	LOSS [training: 0.1272316561838106 | validation: 0.1339944695704004]
	TIME [epoch: 8.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1389313038790992		[learning rate: 0.00022012]
	Learning Rate: 0.000220124
	LOSS [training: 0.1389313038790992 | validation: 0.13958163501082588]
	TIME [epoch: 8.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12672483399904688		[learning rate: 0.0002196]
	Learning Rate: 0.000219604
	LOSS [training: 0.12672483399904688 | validation: 0.1102208986832007]
	TIME [epoch: 8.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1317834502960155		[learning rate: 0.00021909]
	Learning Rate: 0.000219086
	LOSS [training: 0.1317834502960155 | validation: 0.1244422846636819]
	TIME [epoch: 8.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12518994251512452		[learning rate: 0.00021857]
	Learning Rate: 0.00021857
	LOSS [training: 0.12518994251512452 | validation: 0.11908874339650188]
	TIME [epoch: 8.52 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12771270776463456		[learning rate: 0.00021805]
	Learning Rate: 0.000218054
	LOSS [training: 0.12771270776463456 | validation: 0.10989718938818369]
	TIME [epoch: 8.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12183971134776166		[learning rate: 0.00021754]
	Learning Rate: 0.00021754
	LOSS [training: 0.12183971134776166 | validation: 0.12045264825536678]
	TIME [epoch: 8.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13055663539519782		[learning rate: 0.00021703]
	Learning Rate: 0.000217027
	LOSS [training: 0.13055663539519782 | validation: 0.12108091114259227]
	TIME [epoch: 8.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13535121659029817		[learning rate: 0.00021651]
	Learning Rate: 0.000216515
	LOSS [training: 0.13535121659029817 | validation: 0.11832671111139133]
	TIME [epoch: 8.52 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1417380462094055		[learning rate: 0.000216]
	Learning Rate: 0.000216004
	LOSS [training: 0.1417380462094055 | validation: 0.12302384177120394]
	TIME [epoch: 8.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14354518022723844		[learning rate: 0.00021549]
	Learning Rate: 0.000215494
	LOSS [training: 0.14354518022723844 | validation: 0.13531832429012114]
	TIME [epoch: 8.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1477797873840557		[learning rate: 0.00021499]
	Learning Rate: 0.000214986
	LOSS [training: 0.1477797873840557 | validation: 0.11047662289477825]
	TIME [epoch: 8.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13833398922657564		[learning rate: 0.00021448]
	Learning Rate: 0.000214479
	LOSS [training: 0.13833398922657564 | validation: 0.1105126266587326]
	TIME [epoch: 8.52 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.134431247602388		[learning rate: 0.00021397]
	Learning Rate: 0.000213973
	LOSS [training: 0.134431247602388 | validation: 0.11683013064508527]
	TIME [epoch: 8.51 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14800560857954398		[learning rate: 0.00021347]
	Learning Rate: 0.000213468
	LOSS [training: 0.14800560857954398 | validation: 0.15533740575991486]
	TIME [epoch: 8.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1392758360806301		[learning rate: 0.00021296]
	Learning Rate: 0.000212965
	LOSS [training: 0.1392758360806301 | validation: 0.11614954530639013]
	TIME [epoch: 8.48 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13617612295860215		[learning rate: 0.00021246]
	Learning Rate: 0.000212462
	LOSS [training: 0.13617612295860215 | validation: 0.13615167553076707]
	TIME [epoch: 8.51 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16185781831602386		[learning rate: 0.00021196]
	Learning Rate: 0.000211961
	LOSS [training: 0.16185781831602386 | validation: 0.14259481287440934]
	TIME [epoch: 8.51 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13648240383587282		[learning rate: 0.00021146]
	Learning Rate: 0.000211461
	LOSS [training: 0.13648240383587282 | validation: 0.1157348053124641]
	TIME [epoch: 8.49 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13545250382912571		[learning rate: 0.00021096]
	Learning Rate: 0.000210962
	LOSS [training: 0.13545250382912571 | validation: 0.10547428599655695]
	TIME [epoch: 8.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12388160576073562		[learning rate: 0.00021046]
	Learning Rate: 0.000210465
	LOSS [training: 0.12388160576073562 | validation: 0.13063865029909627]
	TIME [epoch: 8.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1412264524705938		[learning rate: 0.00020997]
	Learning Rate: 0.000209968
	LOSS [training: 0.1412264524705938 | validation: 0.11192925627851583]
	TIME [epoch: 8.53 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12254711088024287		[learning rate: 0.00020947]
	Learning Rate: 0.000209473
	LOSS [training: 0.12254711088024287 | validation: 0.11523034412996838]
	TIME [epoch: 8.49 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.126037785989028		[learning rate: 0.00020898]
	Learning Rate: 0.000208979
	LOSS [training: 0.126037785989028 | validation: 0.1235561038284114]
	TIME [epoch: 8.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13474959795697772		[learning rate: 0.00020849]
	Learning Rate: 0.000208486
	LOSS [training: 0.13474959795697772 | validation: 0.11072114685083803]
	TIME [epoch: 8.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12731855211509768		[learning rate: 0.00020799]
	Learning Rate: 0.000207994
	LOSS [training: 0.12731855211509768 | validation: 0.11449979762857915]
	TIME [epoch: 8.52 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1279189972196287		[learning rate: 0.0002075]
	Learning Rate: 0.000207504
	LOSS [training: 0.1279189972196287 | validation: 0.12919939255920665]
	TIME [epoch: 8.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12383094152030254		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.12383094152030254 | validation: 0.11027827709762146]
	TIME [epoch: 8.49 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1389740637589793		[learning rate: 0.00020653]
	Learning Rate: 0.000206526
	LOSS [training: 0.1389740637589793 | validation: 0.10911817912745952]
	TIME [epoch: 8.49 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12490395598305223		[learning rate: 0.00020604]
	Learning Rate: 0.000206039
	LOSS [training: 0.12490395598305223 | validation: 0.11356138793874361]
	TIME [epoch: 8.52 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1309284300314594		[learning rate: 0.00020555]
	Learning Rate: 0.000205553
	LOSS [training: 0.1309284300314594 | validation: 0.13588939672009792]
	TIME [epoch: 8.51 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13054819228054673		[learning rate: 0.00020507]
	Learning Rate: 0.000205068
	LOSS [training: 0.13054819228054673 | validation: 0.1244695346831288]
	TIME [epoch: 8.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13068292737067322		[learning rate: 0.00020458]
	Learning Rate: 0.000204584
	LOSS [training: 0.13068292737067322 | validation: 0.1109687539878293]
	TIME [epoch: 8.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13440265828413445		[learning rate: 0.0002041]
	Learning Rate: 0.000204101
	LOSS [training: 0.13440265828413445 | validation: 0.12328484829859257]
	TIME [epoch: 8.52 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13991879883542332		[learning rate: 0.00020362]
	Learning Rate: 0.00020362
	LOSS [training: 0.13991879883542332 | validation: 0.1431053062141131]
	TIME [epoch: 8.51 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12340127703856567		[learning rate: 0.00020314]
	Learning Rate: 0.00020314
	LOSS [training: 0.12340127703856567 | validation: 0.11795526564311387]
	TIME [epoch: 8.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12349330186407967		[learning rate: 0.00020266]
	Learning Rate: 0.000202661
	LOSS [training: 0.12349330186407967 | validation: 0.12101308555606946]
	TIME [epoch: 8.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12376080491831945		[learning rate: 0.00020218]
	Learning Rate: 0.000202182
	LOSS [training: 0.12376080491831945 | validation: 0.11522635629115932]
	TIME [epoch: 8.51 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12800976819749582		[learning rate: 0.00020171]
	Learning Rate: 0.000201706
	LOSS [training: 0.12800976819749582 | validation: 0.12118527901329751]
	TIME [epoch: 8.51 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12653798009660813		[learning rate: 0.00020123]
	Learning Rate: 0.00020123
	LOSS [training: 0.12653798009660813 | validation: 0.11620995392930655]
	TIME [epoch: 8.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11805700774196612		[learning rate: 0.00020076]
	Learning Rate: 0.000200755
	LOSS [training: 0.11805700774196612 | validation: 0.10983183018881856]
	TIME [epoch: 8.49 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1394793994019346		[learning rate: 0.00020028]
	Learning Rate: 0.000200282
	LOSS [training: 0.1394793994019346 | validation: 0.11860844272319507]
	TIME [epoch: 8.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12600641419589453		[learning rate: 0.00019981]
	Learning Rate: 0.000199809
	LOSS [training: 0.12600641419589453 | validation: 0.1287700464021051]
	TIME [epoch: 8.52 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1271122644997476		[learning rate: 0.00019934]
	Learning Rate: 0.000199338
	LOSS [training: 0.1271122644997476 | validation: 0.10994180115883638]
	TIME [epoch: 8.49 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12504719310625373		[learning rate: 0.00019887]
	Learning Rate: 0.000198868
	LOSS [training: 0.12504719310625373 | validation: 0.12093171458360708]
	TIME [epoch: 8.49 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14151304323589767		[learning rate: 0.0001984]
	Learning Rate: 0.000198398
	LOSS [training: 0.14151304323589767 | validation: 0.13573883458167849]
	TIME [epoch: 8.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1308096867997999		[learning rate: 0.00019793]
	Learning Rate: 0.000197931
	LOSS [training: 0.1308096867997999 | validation: 0.10397820392157425]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_1711.pth
	Model improved!!!
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11834714859975337		[learning rate: 0.00019746]
	Learning Rate: 0.000197464
	LOSS [training: 0.11834714859975337 | validation: 0.12902361917072994]
	TIME [epoch: 8.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12923736335603997		[learning rate: 0.000197]
	Learning Rate: 0.000196998
	LOSS [training: 0.12923736335603997 | validation: 0.11555217219382319]
	TIME [epoch: 8.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1392241383046003		[learning rate: 0.00019653]
	Learning Rate: 0.000196533
	LOSS [training: 0.1392241383046003 | validation: 0.14203943687894327]
	TIME [epoch: 8.49 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1640395439850157		[learning rate: 0.00019607]
	Learning Rate: 0.00019607
	LOSS [training: 0.1640395439850157 | validation: 0.15242073844509907]
	TIME [epoch: 8.51 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.165237324301618		[learning rate: 0.00019561]
	Learning Rate: 0.000195607
	LOSS [training: 0.165237324301618 | validation: 0.14049757595322587]
	TIME [epoch: 8.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16867134132648698		[learning rate: 0.00019515]
	Learning Rate: 0.000195146
	LOSS [training: 0.16867134132648698 | validation: 0.13268477555382355]
	TIME [epoch: 8.49 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13349262948777535		[learning rate: 0.00019469]
	Learning Rate: 0.000194685
	LOSS [training: 0.13349262948777535 | validation: 0.11398233188304932]
	TIME [epoch: 8.49 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13325338687846916		[learning rate: 0.00019423]
	Learning Rate: 0.000194226
	LOSS [training: 0.13325338687846916 | validation: 0.11742129323240802]
	TIME [epoch: 8.51 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1302001627279345		[learning rate: 0.00019377]
	Learning Rate: 0.000193768
	LOSS [training: 0.1302001627279345 | validation: 0.13411517804916068]
	TIME [epoch: 8.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13247409965546333		[learning rate: 0.00019331]
	Learning Rate: 0.000193311
	LOSS [training: 0.13247409965546333 | validation: 0.12037234767090292]
	TIME [epoch: 8.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12417182311251466		[learning rate: 0.00019285]
	Learning Rate: 0.000192855
	LOSS [training: 0.12417182311251466 | validation: 0.11395227057908816]
	TIME [epoch: 8.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12357743767487046		[learning rate: 0.0001924]
	Learning Rate: 0.0001924
	LOSS [training: 0.12357743767487046 | validation: 0.13690726945309822]
	TIME [epoch: 8.51 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12998180614087568		[learning rate: 0.00019195]
	Learning Rate: 0.000191946
	LOSS [training: 0.12998180614087568 | validation: 0.10566380981334603]
	TIME [epoch: 8.53 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12448307620287932		[learning rate: 0.00019149]
	Learning Rate: 0.000191493
	LOSS [training: 0.12448307620287932 | validation: 0.13474659912048342]
	TIME [epoch: 8.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12796278253012577		[learning rate: 0.00019104]
	Learning Rate: 0.000191042
	LOSS [training: 0.12796278253012577 | validation: 0.1215216944185745]
	TIME [epoch: 8.49 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12073993205714209		[learning rate: 0.00019059]
	Learning Rate: 0.000190591
	LOSS [training: 0.12073993205714209 | validation: 0.13487705701202352]
	TIME [epoch: 8.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14094449517843882		[learning rate: 0.00019014]
	Learning Rate: 0.000190141
	LOSS [training: 0.14094449517843882 | validation: 0.14719917696312768]
	TIME [epoch: 8.52 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15994735193388715		[learning rate: 0.00018969]
	Learning Rate: 0.000189693
	LOSS [training: 0.15994735193388715 | validation: 0.15445285815136073]
	TIME [epoch: 8.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13459726282393714		[learning rate: 0.00018925]
	Learning Rate: 0.000189245
	LOSS [training: 0.13459726282393714 | validation: 0.12212140654496874]
	TIME [epoch: 8.51 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12837842513800937		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.12837842513800937 | validation: 0.1354352310405874]
	TIME [epoch: 8.49 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12383439006482662		[learning rate: 0.00018835]
	Learning Rate: 0.000188354
	LOSS [training: 0.12383439006482662 | validation: 0.10868612047287453]
	TIME [epoch: 8.52 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11504382483070663		[learning rate: 0.00018791]
	Learning Rate: 0.000187909
	LOSS [training: 0.11504382483070663 | validation: 0.11860955661103453]
	TIME [epoch: 8.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11778053885871383		[learning rate: 0.00018747]
	Learning Rate: 0.000187466
	LOSS [training: 0.11778053885871383 | validation: 0.11529020610228469]
	TIME [epoch: 8.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12434506992249032		[learning rate: 0.00018702]
	Learning Rate: 0.000187024
	LOSS [training: 0.12434506992249032 | validation: 0.12346914449622476]
	TIME [epoch: 8.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12110740862424636		[learning rate: 0.00018658]
	Learning Rate: 0.000186583
	LOSS [training: 0.12110740862424636 | validation: 0.11646052970496448]
	TIME [epoch: 8.51 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12266987027958584		[learning rate: 0.00018614]
	Learning Rate: 0.000186143
	LOSS [training: 0.12266987027958584 | validation: 0.12734583630641452]
	TIME [epoch: 8.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.130115839286559		[learning rate: 0.0001857]
	Learning Rate: 0.000185704
	LOSS [training: 0.130115839286559 | validation: 0.11941568803104388]
	TIME [epoch: 8.49 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13255815801100762		[learning rate: 0.00018527]
	Learning Rate: 0.000185266
	LOSS [training: 0.13255815801100762 | validation: 0.10107610179216264]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_1739.pth
	Model improved!!!
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13344329929961424		[learning rate: 0.00018483]
	Learning Rate: 0.000184829
	LOSS [training: 0.13344329929961424 | validation: 0.1115930766565402]
	TIME [epoch: 8.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1211129878293632		[learning rate: 0.00018439]
	Learning Rate: 0.000184393
	LOSS [training: 0.1211129878293632 | validation: 0.10262723242221117]
	TIME [epoch: 8.52 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12266848908286869		[learning rate: 0.00018396]
	Learning Rate: 0.000183958
	LOSS [training: 0.12266848908286869 | validation: 0.10476576309128456]
	TIME [epoch: 8.49 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1200090001005116		[learning rate: 0.00018352]
	Learning Rate: 0.000183524
	LOSS [training: 0.1200090001005116 | validation: 0.11364930175898455]
	TIME [epoch: 8.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1337648498732706		[learning rate: 0.00018309]
	Learning Rate: 0.000183091
	LOSS [training: 0.1337648498732706 | validation: 0.123303737610996]
	TIME [epoch: 8.49 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13072129434642135		[learning rate: 0.00018266]
	Learning Rate: 0.000182659
	LOSS [training: 0.13072129434642135 | validation: 0.12487231920866455]
	TIME [epoch: 8.52 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13867812070627336		[learning rate: 0.00018223]
	Learning Rate: 0.000182228
	LOSS [training: 0.13867812070627336 | validation: 0.1156994173306127]
	TIME [epoch: 8.49 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1346846534274604		[learning rate: 0.0001818]
	Learning Rate: 0.000181798
	LOSS [training: 0.1346846534274604 | validation: 0.13253245487018145]
	TIME [epoch: 8.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1261984085332471		[learning rate: 0.00018137]
	Learning Rate: 0.000181369
	LOSS [training: 0.1261984085332471 | validation: 0.11061480786136238]
	TIME [epoch: 8.49 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12067511345332124		[learning rate: 0.00018094]
	Learning Rate: 0.000180942
	LOSS [training: 0.12067511345332124 | validation: 0.11269194704415866]
	TIME [epoch: 8.52 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.126947376444626		[learning rate: 0.00018051]
	Learning Rate: 0.000180515
	LOSS [training: 0.126947376444626 | validation: 0.11636914719474299]
	TIME [epoch: 8.49 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12672374102712988		[learning rate: 0.00018009]
	Learning Rate: 0.000180089
	LOSS [training: 0.12672374102712988 | validation: 0.10906084323219395]
	TIME [epoch: 8.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12735026655154552		[learning rate: 0.00017966]
	Learning Rate: 0.000179664
	LOSS [training: 0.12735026655154552 | validation: 0.12316434476752687]
	TIME [epoch: 8.49 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13132217210510147		[learning rate: 0.00017924]
	Learning Rate: 0.00017924
	LOSS [training: 0.13132217210510147 | validation: 0.12411373922396667]
	TIME [epoch: 8.51 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1320910597703198		[learning rate: 0.00017882]
	Learning Rate: 0.000178818
	LOSS [training: 0.1320910597703198 | validation: 0.13194407547236411]
	TIME [epoch: 8.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1308056515204294		[learning rate: 0.0001784]
	Learning Rate: 0.000178396
	LOSS [training: 0.1308056515204294 | validation: 0.12065911223176035]
	TIME [epoch: 8.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12602701607400132		[learning rate: 0.00017797]
	Learning Rate: 0.000177975
	LOSS [training: 0.12602701607400132 | validation: 0.10757912519328389]
	TIME [epoch: 8.49 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12200545129031597		[learning rate: 0.00017756]
	Learning Rate: 0.000177555
	LOSS [training: 0.12200545129031597 | validation: 0.1180199458044128]
	TIME [epoch: 8.5 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12136646826302502		[learning rate: 0.00017714]
	Learning Rate: 0.000177136
	LOSS [training: 0.12136646826302502 | validation: 0.12066582826721195]
	TIME [epoch: 8.51 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13433947867983947		[learning rate: 0.00017672]
	Learning Rate: 0.000176718
	LOSS [training: 0.13433947867983947 | validation: 0.12416210476837691]
	TIME [epoch: 8.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14228117768625484		[learning rate: 0.0001763]
	Learning Rate: 0.000176302
	LOSS [training: 0.14228117768625484 | validation: 0.11725227709058753]
	TIME [epoch: 8.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12767334222996193		[learning rate: 0.00017589]
	Learning Rate: 0.000175886
	LOSS [training: 0.12767334222996193 | validation: 0.12900935718792456]
	TIME [epoch: 8.49 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13439400420603279		[learning rate: 0.00017547]
	Learning Rate: 0.000175471
	LOSS [training: 0.13439400420603279 | validation: 0.12520088053522632]
	TIME [epoch: 8.53 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1241940074879111		[learning rate: 0.00017506]
	Learning Rate: 0.000175057
	LOSS [training: 0.1241940074879111 | validation: 0.12260792858459141]
	TIME [epoch: 8.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12565663243765052		[learning rate: 0.00017464]
	Learning Rate: 0.000174644
	LOSS [training: 0.12565663243765052 | validation: 0.11720680779864141]
	TIME [epoch: 8.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12112425196629631		[learning rate: 0.00017423]
	Learning Rate: 0.000174232
	LOSS [training: 0.12112425196629631 | validation: 0.11078218423318917]
	TIME [epoch: 8.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11616762165992796		[learning rate: 0.00017382]
	Learning Rate: 0.000173821
	LOSS [training: 0.11616762165992796 | validation: 0.11447255343063521]
	TIME [epoch: 8.52 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12391268994702562		[learning rate: 0.00017341]
	Learning Rate: 0.000173411
	LOSS [training: 0.12391268994702562 | validation: 0.12002435827113667]
	TIME [epoch: 8.5 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13245140403486722		[learning rate: 0.000173]
	Learning Rate: 0.000173002
	LOSS [training: 0.13245140403486722 | validation: 0.1379570498359179]
	TIME [epoch: 8.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.150932943038768		[learning rate: 0.00017259]
	Learning Rate: 0.000172594
	LOSS [training: 0.150932943038768 | validation: 0.12289314174420285]
	TIME [epoch: 8.49 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13085342837058817		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.13085342837058817 | validation: 0.13436524341019437]
	TIME [epoch: 8.52 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12864789714515318		[learning rate: 0.00017178]
	Learning Rate: 0.000171781
	LOSS [training: 0.12864789714515318 | validation: 0.11673499595832641]
	TIME [epoch: 8.51 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1274899317794856		[learning rate: 0.00017138]
	Learning Rate: 0.000171375
	LOSS [training: 0.1274899317794856 | validation: 0.10627413633518956]
	TIME [epoch: 8.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13721810170186527		[learning rate: 0.00017097]
	Learning Rate: 0.000170971
	LOSS [training: 0.13721810170186527 | validation: 0.13505382547710965]
	TIME [epoch: 8.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13497473761375425		[learning rate: 0.00017057]
	Learning Rate: 0.000170568
	LOSS [training: 0.13497473761375425 | validation: 0.11389934263315236]
	TIME [epoch: 8.52 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13066450445703873		[learning rate: 0.00017017]
	Learning Rate: 0.000170166
	LOSS [training: 0.13066450445703873 | validation: 0.13300054096734554]
	TIME [epoch: 8.51 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13210991500694974		[learning rate: 0.00016976]
	Learning Rate: 0.000169764
	LOSS [training: 0.13210991500694974 | validation: 0.12588142057768228]
	TIME [epoch: 8.49 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12035871076233329		[learning rate: 0.00016936]
	Learning Rate: 0.000169364
	LOSS [training: 0.12035871076233329 | validation: 0.12690516015181993]
	TIME [epoch: 8.49 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12362758380027225		[learning rate: 0.00016896]
	Learning Rate: 0.000168964
	LOSS [training: 0.12362758380027225 | validation: 0.1262017068026625]
	TIME [epoch: 8.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12836211188318253		[learning rate: 0.00016857]
	Learning Rate: 0.000168566
	LOSS [training: 0.12836211188318253 | validation: 0.13322770084861457]
	TIME [epoch: 8.52 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14004296937454758		[learning rate: 0.00016817]
	Learning Rate: 0.000168168
	LOSS [training: 0.14004296937454758 | validation: 0.1176764136418535]
	TIME [epoch: 8.5 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13110699958406324		[learning rate: 0.00016777]
	Learning Rate: 0.000167771
	LOSS [training: 0.13110699958406324 | validation: 0.13873519478976215]
	TIME [epoch: 8.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13359425443476708		[learning rate: 0.00016738]
	Learning Rate: 0.000167376
	LOSS [training: 0.13359425443476708 | validation: 0.13855877293116753]
	TIME [epoch: 8.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12914419904979849		[learning rate: 0.00016698]
	Learning Rate: 0.000166981
	LOSS [training: 0.12914419904979849 | validation: 0.12487367362884111]
	TIME [epoch: 8.53 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12979401001169172		[learning rate: 0.00016659]
	Learning Rate: 0.000166587
	LOSS [training: 0.12979401001169172 | validation: 0.13635732347614082]
	TIME [epoch: 8.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1383653413252532		[learning rate: 0.00016619]
	Learning Rate: 0.000166194
	LOSS [training: 0.1383653413252532 | validation: 0.13530933664021827]
	TIME [epoch: 8.51 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13859208180927582		[learning rate: 0.0001658]
	Learning Rate: 0.000165802
	LOSS [training: 0.13859208180927582 | validation: 0.13150791967732245]
	TIME [epoch: 8.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12325737915588283		[learning rate: 0.00016541]
	Learning Rate: 0.000165411
	LOSS [training: 0.12325737915588283 | validation: 0.121369474682471]
	TIME [epoch: 8.52 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13123480917372582		[learning rate: 0.00016502]
	Learning Rate: 0.000165021
	LOSS [training: 0.13123480917372582 | validation: 0.1304724589785452]
	TIME [epoch: 8.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13408408390107765		[learning rate: 0.00016463]
	Learning Rate: 0.000164631
	LOSS [training: 0.13408408390107765 | validation: 0.13595843433935792]
	TIME [epoch: 8.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.130915114245819		[learning rate: 0.00016424]
	Learning Rate: 0.000164243
	LOSS [training: 0.130915114245819 | validation: 0.11538260002487771]
	TIME [epoch: 8.49 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1305187495590141		[learning rate: 0.00016386]
	Learning Rate: 0.000163856
	LOSS [training: 0.1305187495590141 | validation: 0.12945488791538054]
	TIME [epoch: 8.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13093923640460423		[learning rate: 0.00016347]
	Learning Rate: 0.000163469
	LOSS [training: 0.13093923640460423 | validation: 0.12553011931359737]
	TIME [epoch: 8.52 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12883187175993951		[learning rate: 0.00016308]
	Learning Rate: 0.000163084
	LOSS [training: 0.12883187175993951 | validation: 0.12320945831226546]
	TIME [epoch: 8.49 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12515310581661518		[learning rate: 0.0001627]
	Learning Rate: 0.000162699
	LOSS [training: 0.12515310581661518 | validation: 0.11531631758259181]
	TIME [epoch: 8.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12308978763357437		[learning rate: 0.00016232]
	Learning Rate: 0.000162315
	LOSS [training: 0.12308978763357437 | validation: 0.11194582880265103]
	TIME [epoch: 8.49 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12605437489552884		[learning rate: 0.00016193]
	Learning Rate: 0.000161932
	LOSS [training: 0.12605437489552884 | validation: 0.13120035371852087]
	TIME [epoch: 8.52 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13210298325950448		[learning rate: 0.00016155]
	Learning Rate: 0.00016155
	LOSS [training: 0.13210298325950448 | validation: 0.11324186464296154]
	TIME [epoch: 8.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12420456751813336		[learning rate: 0.00016117]
	Learning Rate: 0.000161169
	LOSS [training: 0.12420456751813336 | validation: 0.10832281335034655]
	TIME [epoch: 8.49 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12205260743116741		[learning rate: 0.00016079]
	Learning Rate: 0.000160789
	LOSS [training: 0.12205260743116741 | validation: 0.10351482538560905]
	TIME [epoch: 8.49 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12471022101608684		[learning rate: 0.00016041]
	Learning Rate: 0.00016041
	LOSS [training: 0.12471022101608684 | validation: 0.11531302729141477]
	TIME [epoch: 8.52 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12190053316547107		[learning rate: 0.00016003]
	Learning Rate: 0.000160031
	LOSS [training: 0.12190053316547107 | validation: 0.12976185030922366]
	TIME [epoch: 8.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13075934251797725		[learning rate: 0.00015965]
	Learning Rate: 0.000159654
	LOSS [training: 0.13075934251797725 | validation: 0.11633288598643388]
	TIME [epoch: 8.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12817875227398604		[learning rate: 0.00015928]
	Learning Rate: 0.000159277
	LOSS [training: 0.12817875227398604 | validation: 0.12118924826159397]
	TIME [epoch: 8.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12188758988869164		[learning rate: 0.0001589]
	Learning Rate: 0.000158902
	LOSS [training: 0.12188758988869164 | validation: 0.12419437944702048]
	TIME [epoch: 8.52 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13336375458396235		[learning rate: 0.00015853]
	Learning Rate: 0.000158527
	LOSS [training: 0.13336375458396235 | validation: 0.10787358035101585]
	TIME [epoch: 8.51 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.116302617924718		[learning rate: 0.00015815]
	Learning Rate: 0.000158153
	LOSS [training: 0.116302617924718 | validation: 0.10670111746351299]
	TIME [epoch: 8.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.120867402856246		[learning rate: 0.00015778]
	Learning Rate: 0.00015778
	LOSS [training: 0.120867402856246 | validation: 0.10871866520796813]
	TIME [epoch: 8.51 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12009535201831778		[learning rate: 0.00015741]
	Learning Rate: 0.000157408
	LOSS [training: 0.12009535201831778 | validation: 0.13181364785846078]
	TIME [epoch: 8.51 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13657175952534337		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.13657175952534337 | validation: 0.11737267355662115]
	TIME [epoch: 8.53 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11924042350977923		[learning rate: 0.00015667]
	Learning Rate: 0.000156666
	LOSS [training: 0.11924042350977923 | validation: 0.11342829771189536]
	TIME [epoch: 8.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12657885409020408		[learning rate: 0.0001563]
	Learning Rate: 0.000156296
	LOSS [training: 0.12657885409020408 | validation: 0.1287748472158567]
	TIME [epoch: 8.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12665073438905897		[learning rate: 0.00015593]
	Learning Rate: 0.000155928
	LOSS [training: 0.12665073438905897 | validation: 0.10598314324223257]
	TIME [epoch: 8.5 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12233365006557431		[learning rate: 0.00015556]
	Learning Rate: 0.00015556
	LOSS [training: 0.12233365006557431 | validation: 0.11411364167613852]
	TIME [epoch: 8.53 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12534840879895093		[learning rate: 0.00015519]
	Learning Rate: 0.000155193
	LOSS [training: 0.12534840879895093 | validation: 0.11172363358323498]
	TIME [epoch: 8.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12059095970269215		[learning rate: 0.00015483]
	Learning Rate: 0.000154827
	LOSS [training: 0.12059095970269215 | validation: 0.11613047371871577]
	TIME [epoch: 8.51 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12584584717360253		[learning rate: 0.00015446]
	Learning Rate: 0.000154462
	LOSS [training: 0.12584584717360253 | validation: 0.11545954945339926]
	TIME [epoch: 8.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13239359867648842		[learning rate: 0.0001541]
	Learning Rate: 0.000154097
	LOSS [training: 0.13239359867648842 | validation: 0.12705170767506585]
	TIME [epoch: 8.53 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13808321637870483		[learning rate: 0.00015373]
	Learning Rate: 0.000153734
	LOSS [training: 0.13808321637870483 | validation: 0.11501214471265121]
	TIME [epoch: 8.51 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12097170227100022		[learning rate: 0.00015337]
	Learning Rate: 0.000153371
	LOSS [training: 0.12097170227100022 | validation: 0.10061756276612965]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_1819.pth
	Model improved!!!
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12141568311879677		[learning rate: 0.00015301]
	Learning Rate: 0.000153009
	LOSS [training: 0.12141568311879677 | validation: 0.11367247058643111]
	TIME [epoch: 8.51 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1177503927900552		[learning rate: 0.00015265]
	Learning Rate: 0.000152648
	LOSS [training: 0.1177503927900552 | validation: 0.10734412966182144]
	TIME [epoch: 8.52 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12237848325754508		[learning rate: 0.00015229]
	Learning Rate: 0.000152288
	LOSS [training: 0.12237848325754508 | validation: 0.11803632457798352]
	TIME [epoch: 8.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12736447703486403		[learning rate: 0.00015193]
	Learning Rate: 0.000151929
	LOSS [training: 0.12736447703486403 | validation: 0.11918407398371306]
	TIME [epoch: 8.49 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12930947087402384		[learning rate: 0.00015157]
	Learning Rate: 0.000151571
	LOSS [training: 0.12930947087402384 | validation: 0.11305570449383677]
	TIME [epoch: 8.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11826964416124161		[learning rate: 0.00015121]
	Learning Rate: 0.000151213
	LOSS [training: 0.11826964416124161 | validation: 0.1193514814241652]
	TIME [epoch: 8.51 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12638748002934957		[learning rate: 0.00015086]
	Learning Rate: 0.000150857
	LOSS [training: 0.12638748002934957 | validation: 0.1100006753402133]
	TIME [epoch: 8.51 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13342241721034984		[learning rate: 0.0001505]
	Learning Rate: 0.000150501
	LOSS [training: 0.13342241721034984 | validation: 0.1268580746582778]
	TIME [epoch: 8.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12739020022611913		[learning rate: 0.00015015]
	Learning Rate: 0.000150146
	LOSS [training: 0.12739020022611913 | validation: 0.11880263239834007]
	TIME [epoch: 8.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12993636943284198		[learning rate: 0.00014979]
	Learning Rate: 0.000149791
	LOSS [training: 0.12993636943284198 | validation: 0.11962819311954254]
	TIME [epoch: 8.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12191622357583905		[learning rate: 0.00014944]
	Learning Rate: 0.000149438
	LOSS [training: 0.12191622357583905 | validation: 0.11680070569786442]
	TIME [epoch: 8.53 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12609031115016064		[learning rate: 0.00014909]
	Learning Rate: 0.000149086
	LOSS [training: 0.12609031115016064 | validation: 0.10586351863883336]
	TIME [epoch: 8.51 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12321591448882444		[learning rate: 0.00014873]
	Learning Rate: 0.000148734
	LOSS [training: 0.12321591448882444 | validation: 0.1139439302594075]
	TIME [epoch: 8.51 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1123866671947769		[learning rate: 0.00014838]
	Learning Rate: 0.000148383
	LOSS [training: 0.1123866671947769 | validation: 0.1021412516026374]
	TIME [epoch: 8.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12137494234496678		[learning rate: 0.00014803]
	Learning Rate: 0.000148033
	LOSS [training: 0.12137494234496678 | validation: 0.11305139559810655]
	TIME [epoch: 8.52 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12685214549689844		[learning rate: 0.00014768]
	Learning Rate: 0.000147684
	LOSS [training: 0.12685214549689844 | validation: 0.10497539086028686]
	TIME [epoch: 8.5 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1204574190909489		[learning rate: 0.00014734]
	Learning Rate: 0.000147336
	LOSS [training: 0.1204574190909489 | validation: 0.11872038463851871]
	TIME [epoch: 8.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12096294229637113		[learning rate: 0.00014699]
	Learning Rate: 0.000146988
	LOSS [training: 0.12096294229637113 | validation: 0.11586335098274801]
	TIME [epoch: 8.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11591961191570248		[learning rate: 0.00014664]
	Learning Rate: 0.000146641
	LOSS [training: 0.11591961191570248 | validation: 0.1173047654973639]
	TIME [epoch: 8.53 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11886644504091157		[learning rate: 0.0001463]
	Learning Rate: 0.000146295
	LOSS [training: 0.11886644504091157 | validation: 0.10736714162378899]
	TIME [epoch: 8.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11735961477718104		[learning rate: 0.00014595]
	Learning Rate: 0.00014595
	LOSS [training: 0.11735961477718104 | validation: 0.11731653705343761]
	TIME [epoch: 8.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12743579650789244		[learning rate: 0.00014561]
	Learning Rate: 0.000145606
	LOSS [training: 0.12743579650789244 | validation: 0.12092756030736655]
	TIME [epoch: 8.51 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13287437183081097		[learning rate: 0.00014526]
	Learning Rate: 0.000145263
	LOSS [training: 0.13287437183081097 | validation: 0.11237297827593735]
	TIME [epoch: 8.52 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12419393268373688		[learning rate: 0.00014492]
	Learning Rate: 0.00014492
	LOSS [training: 0.12419393268373688 | validation: 0.10874082617139899]
	TIME [epoch: 8.51 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11835633655136027		[learning rate: 0.00014458]
	Learning Rate: 0.000144578
	LOSS [training: 0.11835633655136027 | validation: 0.11617211541947713]
	TIME [epoch: 8.51 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12071752973672671		[learning rate: 0.00014424]
	Learning Rate: 0.000144237
	LOSS [training: 0.12071752973672671 | validation: 0.12092423036877326]
	TIME [epoch: 8.49 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12127348413120824		[learning rate: 0.0001439]
	Learning Rate: 0.000143897
	LOSS [training: 0.12127348413120824 | validation: 0.12137339022197946]
	TIME [epoch: 8.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1228486200538407		[learning rate: 0.00014356]
	Learning Rate: 0.000143557
	LOSS [training: 0.1228486200538407 | validation: 0.11118853374525442]
	TIME [epoch: 8.52 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11959087736946646		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.11959087736946646 | validation: 0.11563944788985366]
	TIME [epoch: 8.52 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11968721235057526		[learning rate: 0.00014288]
	Learning Rate: 0.000142881
	LOSS [training: 0.11968721235057526 | validation: 0.12836849596698252]
	TIME [epoch: 8.51 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12139835035763176		[learning rate: 0.00014254]
	Learning Rate: 0.000142544
	LOSS [training: 0.12139835035763176 | validation: 0.1219683360985478]
	TIME [epoch: 8.52 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11897715226304242		[learning rate: 0.00014221]
	Learning Rate: 0.000142208
	LOSS [training: 0.11897715226304242 | validation: 0.11275526345096286]
	TIME [epoch: 8.54 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11815800793491307		[learning rate: 0.00014187]
	Learning Rate: 0.000141872
	LOSS [training: 0.11815800793491307 | validation: 0.11626967020028592]
	TIME [epoch: 8.51 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12177581977202986		[learning rate: 0.00014154]
	Learning Rate: 0.000141538
	LOSS [training: 0.12177581977202986 | validation: 0.12238569400792143]
	TIME [epoch: 8.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12104840241248187		[learning rate: 0.0001412]
	Learning Rate: 0.000141204
	LOSS [training: 0.12104840241248187 | validation: 0.09857566148201391]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_1854.pth
	Model improved!!!
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12655195431881172		[learning rate: 0.00014087]
	Learning Rate: 0.000140871
	LOSS [training: 0.12655195431881172 | validation: 0.10662013768288822]
	TIME [epoch: 8.56 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12471693426768586		[learning rate: 0.00014054]
	Learning Rate: 0.000140538
	LOSS [training: 0.12471693426768586 | validation: 0.11816196890717219]
	TIME [epoch: 8.54 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1271218998370957		[learning rate: 0.00014021]
	Learning Rate: 0.000140207
	LOSS [training: 0.1271218998370957 | validation: 0.12203146318821974]
	TIME [epoch: 8.57 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1262406464989248		[learning rate: 0.00013988]
	Learning Rate: 0.000139876
	LOSS [training: 0.1262406464989248 | validation: 0.12840305315159325]
	TIME [epoch: 8.53 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11988169220001132		[learning rate: 0.00013955]
	Learning Rate: 0.000139546
	LOSS [training: 0.11988169220001132 | validation: 0.1179843351113038]
	TIME [epoch: 8.55 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1251270001967175		[learning rate: 0.00013922]
	Learning Rate: 0.000139217
	LOSS [training: 0.1251270001967175 | validation: 0.11934688432522061]
	TIME [epoch: 8.53 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12385474085159245		[learning rate: 0.00013889]
	Learning Rate: 0.000138889
	LOSS [training: 0.12385474085159245 | validation: 0.13622686283925328]
	TIME [epoch: 8.53 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12659472512411882		[learning rate: 0.00013856]
	Learning Rate: 0.000138561
	LOSS [training: 0.12659472512411882 | validation: 0.12797818727477267]
	TIME [epoch: 8.53 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1370536728280076		[learning rate: 0.00013823]
	Learning Rate: 0.000138234
	LOSS [training: 0.1370536728280076 | validation: 0.14201306764276514]
	TIME [epoch: 8.54 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13957838477024867		[learning rate: 0.00013791]
	Learning Rate: 0.000137908
	LOSS [training: 0.13957838477024867 | validation: 0.13108349820077306]
	TIME [epoch: 8.54 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1306609740811951		[learning rate: 0.00013758]
	Learning Rate: 0.000137583
	LOSS [training: 0.1306609740811951 | validation: 0.11780255492110153]
	TIME [epoch: 8.53 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12039830278996902		[learning rate: 0.00013726]
	Learning Rate: 0.000137258
	LOSS [training: 0.12039830278996902 | validation: 0.11641752611182923]
	TIME [epoch: 8.53 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12326602787731913		[learning rate: 0.00013693]
	Learning Rate: 0.000136934
	LOSS [training: 0.12326602787731913 | validation: 0.12482766342451374]
	TIME [epoch: 8.53 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12770179078125285		[learning rate: 0.00013661]
	Learning Rate: 0.000136611
	LOSS [training: 0.12770179078125285 | validation: 0.12392421615842018]
	TIME [epoch: 8.55 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14574619226953223		[learning rate: 0.00013629]
	Learning Rate: 0.000136289
	LOSS [training: 0.14574619226953223 | validation: 0.14355200713005317]
	TIME [epoch: 8.52 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1448201515971261		[learning rate: 0.00013597]
	Learning Rate: 0.000135968
	LOSS [training: 0.1448201515971261 | validation: 0.13086222180456386]
	TIME [epoch: 8.52 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13252545276170985		[learning rate: 0.00013565]
	Learning Rate: 0.000135647
	LOSS [training: 0.13252545276170985 | validation: 0.11637490889652863]
	TIME [epoch: 8.52 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14183503772061687		[learning rate: 0.00013533]
	Learning Rate: 0.000135327
	LOSS [training: 0.14183503772061687 | validation: 0.14912156190606118]
	TIME [epoch: 8.55 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1452880122683388		[learning rate: 0.00013501]
	Learning Rate: 0.000135008
	LOSS [training: 0.1452880122683388 | validation: 0.12138804405259651]
	TIME [epoch: 8.52 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13797238828652988		[learning rate: 0.00013469]
	Learning Rate: 0.000134689
	LOSS [training: 0.13797238828652988 | validation: 0.1168092428778413]
	TIME [epoch: 8.52 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12394154442484454		[learning rate: 0.00013437]
	Learning Rate: 0.000134372
	LOSS [training: 0.12394154442484454 | validation: 0.11882707867672916]
	TIME [epoch: 8.52 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13265146950862633		[learning rate: 0.00013405]
	Learning Rate: 0.000134055
	LOSS [training: 0.13265146950862633 | validation: 0.11385172317887318]
	TIME [epoch: 8.54 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13969762889266715		[learning rate: 0.00013374]
	Learning Rate: 0.000133738
	LOSS [training: 0.13969762889266715 | validation: 0.11647450826026613]
	TIME [epoch: 8.52 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13042546488009818		[learning rate: 0.00013342]
	Learning Rate: 0.000133423
	LOSS [training: 0.13042546488009818 | validation: 0.12204301865802226]
	TIME [epoch: 8.52 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1383329006946584		[learning rate: 0.00013311]
	Learning Rate: 0.000133108
	LOSS [training: 0.1383329006946584 | validation: 0.11949748310093722]
	TIME [epoch: 8.52 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13429020050716403		[learning rate: 0.00013279]
	Learning Rate: 0.000132794
	LOSS [training: 0.13429020050716403 | validation: 0.14506909796171719]
	TIME [epoch: 8.54 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1451469982987901		[learning rate: 0.00013248]
	Learning Rate: 0.000132481
	LOSS [training: 0.1451469982987901 | validation: 0.12797865033456707]
	TIME [epoch: 8.53 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14166563923900022		[learning rate: 0.00013217]
	Learning Rate: 0.000132169
	LOSS [training: 0.14166563923900022 | validation: 0.12885985805226197]
	TIME [epoch: 8.52 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13168387713350577		[learning rate: 0.00013186]
	Learning Rate: 0.000131857
	LOSS [training: 0.13168387713350577 | validation: 0.11737991465446705]
	TIME [epoch: 8.52 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12748787958447558		[learning rate: 0.00013155]
	Learning Rate: 0.000131546
	LOSS [training: 0.12748787958447558 | validation: 0.12456223494230505]
	TIME [epoch: 8.53 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12564871896921112		[learning rate: 0.00013124]
	Learning Rate: 0.000131235
	LOSS [training: 0.12564871896921112 | validation: 0.10625352760336568]
	TIME [epoch: 8.53 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13216939856682602		[learning rate: 0.00013093]
	Learning Rate: 0.000130926
	LOSS [training: 0.13216939856682602 | validation: 0.12990072667475144]
	TIME [epoch: 8.52 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13386036082983904		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.13386036082983904 | validation: 0.10993789150158875]
	TIME [epoch: 8.52 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12127924664203352		[learning rate: 0.00013031]
	Learning Rate: 0.000130309
	LOSS [training: 0.12127924664203352 | validation: 0.12010732407109098]
	TIME [epoch: 8.52 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11708935046554422		[learning rate: 0.00013]
	Learning Rate: 0.000130002
	LOSS [training: 0.11708935046554422 | validation: 0.1198361416419958]
	TIME [epoch: 8.55 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12005074704881327		[learning rate: 0.00012969]
	Learning Rate: 0.000129695
	LOSS [training: 0.12005074704881327 | validation: 0.1021662938795326]
	TIME [epoch: 8.52 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11680906745268822		[learning rate: 0.00012939]
	Learning Rate: 0.000129389
	LOSS [training: 0.11680906745268822 | validation: 0.1291582122927871]
	TIME [epoch: 8.53 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11683375919229885		[learning rate: 0.00012908]
	Learning Rate: 0.000129084
	LOSS [training: 0.11683375919229885 | validation: 0.10949224726998605]
	TIME [epoch: 8.52 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12183296059569237		[learning rate: 0.00012878]
	Learning Rate: 0.000128779
	LOSS [training: 0.12183296059569237 | validation: 0.11467784206365575]
	TIME [epoch: 8.54 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11797729781098198		[learning rate: 0.00012848]
	Learning Rate: 0.000128476
	LOSS [training: 0.11797729781098198 | validation: 0.10887021265472697]
	TIME [epoch: 8.52 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12018363019992209		[learning rate: 0.00012817]
	Learning Rate: 0.000128172
	LOSS [training: 0.12018363019992209 | validation: 0.12465870563971798]
	TIME [epoch: 8.52 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11824288656390633		[learning rate: 0.00012787]
	Learning Rate: 0.00012787
	LOSS [training: 0.11824288656390633 | validation: 0.1140912821411485]
	TIME [epoch: 8.52 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1226517955115571		[learning rate: 0.00012757]
	Learning Rate: 0.000127569
	LOSS [training: 0.1226517955115571 | validation: 0.11554968089488366]
	TIME [epoch: 8.54 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12465311471396412		[learning rate: 0.00012727]
	Learning Rate: 0.000127268
	LOSS [training: 0.12465311471396412 | validation: 0.12126639598518482]
	TIME [epoch: 8.52 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12188359049552071		[learning rate: 0.00012697]
	Learning Rate: 0.000126967
	LOSS [training: 0.12188359049552071 | validation: 0.10791889164851157]
	TIME [epoch: 8.52 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12317149419694355		[learning rate: 0.00012667]
	Learning Rate: 0.000126668
	LOSS [training: 0.12317149419694355 | validation: 0.1269299734047586]
	TIME [epoch: 8.52 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12115772494769401		[learning rate: 0.00012637]
	Learning Rate: 0.000126369
	LOSS [training: 0.12115772494769401 | validation: 0.11564720021255029]
	TIME [epoch: 8.54 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12821783267306952		[learning rate: 0.00012607]
	Learning Rate: 0.000126071
	LOSS [training: 0.12821783267306952 | validation: 0.12523583988834555]
	TIME [epoch: 8.53 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12289124068897046		[learning rate: 0.00012577]
	Learning Rate: 0.000125774
	LOSS [training: 0.12289124068897046 | validation: 0.1332039220702087]
	TIME [epoch: 8.52 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13622128833789432		[learning rate: 0.00012548]
	Learning Rate: 0.000125477
	LOSS [training: 0.13622128833789432 | validation: 0.13649949353152474]
	TIME [epoch: 8.52 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14290698046558725		[learning rate: 0.00012518]
	Learning Rate: 0.000125181
	LOSS [training: 0.14290698046558725 | validation: 0.1453095887462248]
	TIME [epoch: 8.52 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1386104417092647		[learning rate: 0.00012489]
	Learning Rate: 0.000124886
	LOSS [training: 0.1386104417092647 | validation: 0.13246626486243385]
	TIME [epoch: 8.54 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12270163318208338		[learning rate: 0.00012459]
	Learning Rate: 0.000124591
	LOSS [training: 0.12270163318208338 | validation: 0.11312703933276708]
	TIME [epoch: 8.52 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12158055604841729		[learning rate: 0.0001243]
	Learning Rate: 0.000124297
	LOSS [training: 0.12158055604841729 | validation: 0.11041213674448375]
	TIME [epoch: 8.52 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11707923228045776		[learning rate: 0.000124]
	Learning Rate: 0.000124004
	LOSS [training: 0.11707923228045776 | validation: 0.11719416012698175]
	TIME [epoch: 8.52 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1227612166505371		[learning rate: 0.00012371]
	Learning Rate: 0.000123712
	LOSS [training: 0.1227612166505371 | validation: 0.12412457550466957]
	TIME [epoch: 8.54 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11530165592386754		[learning rate: 0.00012342]
	Learning Rate: 0.00012342
	LOSS [training: 0.11530165592386754 | validation: 0.12237019868813478]
	TIME [epoch: 8.52 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11953718864761324		[learning rate: 0.00012313]
	Learning Rate: 0.000123129
	LOSS [training: 0.11953718864761324 | validation: 0.1286638724648962]
	TIME [epoch: 8.52 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1265012520486585		[learning rate: 0.00012284]
	Learning Rate: 0.000122838
	LOSS [training: 0.1265012520486585 | validation: 0.12569234029259352]
	TIME [epoch: 8.51 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12568348146464675		[learning rate: 0.00012255]
	Learning Rate: 0.000122548
	LOSS [training: 0.12568348146464675 | validation: 0.11298716349223456]
	TIME [epoch: 8.54 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12712029948540832		[learning rate: 0.00012226]
	Learning Rate: 0.000122259
	LOSS [training: 0.12712029948540832 | validation: 0.1201354843218156]
	TIME [epoch: 8.52 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12591503315596617		[learning rate: 0.00012197]
	Learning Rate: 0.000121971
	LOSS [training: 0.12591503315596617 | validation: 0.11587883775373366]
	TIME [epoch: 8.52 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12315804818107172		[learning rate: 0.00012168]
	Learning Rate: 0.000121683
	LOSS [training: 0.12315804818107172 | validation: 0.11537114487498192]
	TIME [epoch: 8.52 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1295776389164285		[learning rate: 0.0001214]
	Learning Rate: 0.000121396
	LOSS [training: 0.1295776389164285 | validation: 0.12583206303359956]
	TIME [epoch: 8.54 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1306404168308494		[learning rate: 0.00012111]
	Learning Rate: 0.00012111
	LOSS [training: 0.1306404168308494 | validation: 0.12417811381122115]
	TIME [epoch: 8.52 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1236953173328355		[learning rate: 0.00012082]
	Learning Rate: 0.000120824
	LOSS [training: 0.1236953173328355 | validation: 0.12641830534349796]
	TIME [epoch: 8.52 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12009835822201147		[learning rate: 0.00012054]
	Learning Rate: 0.000120539
	LOSS [training: 0.12009835822201147 | validation: 0.1180401599284803]
	TIME [epoch: 8.52 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12112240729811256		[learning rate: 0.00012025]
	Learning Rate: 0.000120255
	LOSS [training: 0.12112240729811256 | validation: 0.12249056355624208]
	TIME [epoch: 8.52 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12623603238397893		[learning rate: 0.00011997]
	Learning Rate: 0.000119971
	LOSS [training: 0.12623603238397893 | validation: 0.11610399180020387]
	TIME [epoch: 8.54 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12245190294465196		[learning rate: 0.00011969]
	Learning Rate: 0.000119688
	LOSS [training: 0.12245190294465196 | validation: 0.12302292322861319]
	TIME [epoch: 8.52 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13006202890635365		[learning rate: 0.00011941]
	Learning Rate: 0.000119406
	LOSS [training: 0.13006202890635365 | validation: 0.11613522083520793]
	TIME [epoch: 8.52 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11880275418954016		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.11880275418954016 | validation: 0.1169759563373332]
	TIME [epoch: 8.52 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12033383422479083		[learning rate: 0.00011884]
	Learning Rate: 0.000118843
	LOSS [training: 0.12033383422479083 | validation: 0.1304420041065122]
	TIME [epoch: 8.54 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13223447560038812		[learning rate: 0.00011856]
	Learning Rate: 0.000118563
	LOSS [training: 0.13223447560038812 | validation: 0.10821433143166773]
	TIME [epoch: 8.52 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12249441787557495		[learning rate: 0.00011828]
	Learning Rate: 0.000118283
	LOSS [training: 0.12249441787557495 | validation: 0.11546092624021001]
	TIME [epoch: 8.52 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12522637545022247		[learning rate: 0.000118]
	Learning Rate: 0.000118004
	LOSS [training: 0.12522637545022247 | validation: 0.12514167554648387]
	TIME [epoch: 8.52 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1158418415093555		[learning rate: 0.00011773]
	Learning Rate: 0.000117726
	LOSS [training: 0.1158418415093555 | validation: 0.1287776181897272]
	TIME [epoch: 8.54 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11925821656201822		[learning rate: 0.00011745]
	Learning Rate: 0.000117448
	LOSS [training: 0.11925821656201822 | validation: 0.11739993938926582]
	TIME [epoch: 8.52 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12030777899957704		[learning rate: 0.00011717]
	Learning Rate: 0.000117171
	LOSS [training: 0.12030777899957704 | validation: 0.11212319873779107]
	TIME [epoch: 8.52 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11803300564690866		[learning rate: 0.00011689]
	Learning Rate: 0.000116895
	LOSS [training: 0.11803300564690866 | validation: 0.10643418890401254]
	TIME [epoch: 8.51 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1183277603947622		[learning rate: 0.00011662]
	Learning Rate: 0.000116619
	LOSS [training: 0.1183277603947622 | validation: 0.10251074518255568]
	TIME [epoch: 8.54 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11830964374560766		[learning rate: 0.00011634]
	Learning Rate: 0.000116344
	LOSS [training: 0.11830964374560766 | validation: 0.1150033885288081]
	TIME [epoch: 8.52 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11938844987100575		[learning rate: 0.00011607]
	Learning Rate: 0.000116069
	LOSS [training: 0.11938844987100575 | validation: 0.10528385158773182]
	TIME [epoch: 8.51 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11779969078477881		[learning rate: 0.0001158]
	Learning Rate: 0.000115796
	LOSS [training: 0.11779969078477881 | validation: 0.12475575717980561]
	TIME [epoch: 8.51 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12114668070776542		[learning rate: 0.00011552]
	Learning Rate: 0.000115523
	LOSS [training: 0.12114668070776542 | validation: 0.10906164393029928]
	TIME [epoch: 8.53 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12225567607470944		[learning rate: 0.00011525]
	Learning Rate: 0.00011525
	LOSS [training: 0.12225567607470944 | validation: 0.12604760883922317]
	TIME [epoch: 8.53 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12478093434715569		[learning rate: 0.00011498]
	Learning Rate: 0.000114978
	LOSS [training: 0.12478093434715569 | validation: 0.11291115230570928]
	TIME [epoch: 8.52 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11544223020650465		[learning rate: 0.00011471]
	Learning Rate: 0.000114707
	LOSS [training: 0.11544223020650465 | validation: 0.09858738412550969]
	TIME [epoch: 8.52 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12058772821184646		[learning rate: 0.00011444]
	Learning Rate: 0.000114436
	LOSS [training: 0.12058772821184646 | validation: 0.13106143167413664]
	TIME [epoch: 8.52 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1335095341318491		[learning rate: 0.00011417]
	Learning Rate: 0.000114166
	LOSS [training: 0.1335095341318491 | validation: 0.11974608849768079]
	TIME [epoch: 8.54 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1293121927363805		[learning rate: 0.0001139]
	Learning Rate: 0.000113897
	LOSS [training: 0.1293121927363805 | validation: 0.10447807085616212]
	TIME [epoch: 8.52 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12149921843024933		[learning rate: 0.00011363]
	Learning Rate: 0.000113628
	LOSS [training: 0.12149921843024933 | validation: 0.10974271635140655]
	TIME [epoch: 8.52 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1173902964214791		[learning rate: 0.00011336]
	Learning Rate: 0.00011336
	LOSS [training: 0.1173902964214791 | validation: 0.11080129260912205]
	TIME [epoch: 8.52 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12208836866270892		[learning rate: 0.00011309]
	Learning Rate: 0.000113093
	LOSS [training: 0.12208836866270892 | validation: 0.0984569567956844]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study3/model_tr_study3_r5_20240219_184940/states/model_tr_study3_1948.pth
	Model improved!!!
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11967919536539937		[learning rate: 0.00011283]
	Learning Rate: 0.000112826
	LOSS [training: 0.11967919536539937 | validation: 0.1261784467738744]
	TIME [epoch: 8.52 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12055646432648133		[learning rate: 0.00011256]
	Learning Rate: 0.00011256
	LOSS [training: 0.12055646432648133 | validation: 0.12068048197431126]
	TIME [epoch: 8.51 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11731585047415043		[learning rate: 0.00011229]
	Learning Rate: 0.000112295
	LOSS [training: 0.11731585047415043 | validation: 0.10074976886406761]
	TIME [epoch: 8.51 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11877700945218597		[learning rate: 0.00011203]
	Learning Rate: 0.00011203
	LOSS [training: 0.11877700945218597 | validation: 0.10993094662009034]
	TIME [epoch: 8.53 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11385506682452207		[learning rate: 0.00011177]
	Learning Rate: 0.000111765
	LOSS [training: 0.11385506682452207 | validation: 0.10972571312198923]
	TIME [epoch: 8.51 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11751229108461074		[learning rate: 0.0001115]
	Learning Rate: 0.000111502
	LOSS [training: 0.11751229108461074 | validation: 0.11362974428009284]
	TIME [epoch: 8.52 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11787019033795083		[learning rate: 0.00011124]
	Learning Rate: 0.000111239
	LOSS [training: 0.11787019033795083 | validation: 0.125408001069979]
	TIME [epoch: 8.51 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12651629464861736		[learning rate: 0.00011098]
	Learning Rate: 0.000110976
	LOSS [training: 0.12651629464861736 | validation: 0.11558253138247274]
	TIME [epoch: 8.53 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1171503683857171		[learning rate: 0.00011071]
	Learning Rate: 0.000110715
	LOSS [training: 0.1171503683857171 | validation: 0.11485020850142318]
	TIME [epoch: 8.52 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11550366713868039		[learning rate: 0.00011045]
	Learning Rate: 0.000110453
	LOSS [training: 0.11550366713868039 | validation: 0.11440601202854467]
	TIME [epoch: 8.51 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1213325209337203		[learning rate: 0.00011019]
	Learning Rate: 0.000110193
	LOSS [training: 0.1213325209337203 | validation: 0.11011536702025554]
	TIME [epoch: 8.51 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12247794353012256		[learning rate: 0.00010993]
	Learning Rate: 0.000109933
	LOSS [training: 0.12247794353012256 | validation: 0.11675150715875963]
	TIME [epoch: 8.51 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1266543136767791		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.1266543136767791 | validation: 0.1290645047753154]
	TIME [epoch: 8.55 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12470903701873107		[learning rate: 0.00010942]
	Learning Rate: 0.000109415
	LOSS [training: 0.12470903701873107 | validation: 0.10725308037177969]
	TIME [epoch: 8.55 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12113384362222557		[learning rate: 0.00010916]
	Learning Rate: 0.000109157
	LOSS [training: 0.12113384362222557 | validation: 0.1415754188086718]
	TIME [epoch: 8.53 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13889117719319716		[learning rate: 0.0001089]
	Learning Rate: 0.000108899
	LOSS [training: 0.13889117719319716 | validation: 0.12076567413387396]
	TIME [epoch: 8.53 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1315660727852005		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.1315660727852005 | validation: 0.1307780270887372]
	TIME [epoch: 8.56 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1335765674854154		[learning rate: 0.00010839]
	Learning Rate: 0.000108386
	LOSS [training: 0.1335765674854154 | validation: 0.12142972422873219]
	TIME [epoch: 8.53 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.129920810664719		[learning rate: 0.00010813]
	Learning Rate: 0.000108131
	LOSS [training: 0.129920810664719 | validation: 0.1177434482467122]
	TIME [epoch: 8.53 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14383806175499098		[learning rate: 0.00010788]
	Learning Rate: 0.000107876
	LOSS [training: 0.14383806175499098 | validation: 0.12990346383138274]
	TIME [epoch: 8.53 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13416237380245244		[learning rate: 0.00010762]
	Learning Rate: 0.000107621
	LOSS [training: 0.13416237380245244 | validation: 0.12076944784369263]
	TIME [epoch: 8.57 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11710894345865677		[learning rate: 0.00010737]
	Learning Rate: 0.000107367
	LOSS [training: 0.11710894345865677 | validation: 0.11278670207614482]
	TIME [epoch: 8.54 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12067419499305923		[learning rate: 0.00010711]
	Learning Rate: 0.000107114
	LOSS [training: 0.12067419499305923 | validation: 0.11727009925970906]
	TIME [epoch: 8.54 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13782560931706625		[learning rate: 0.00010686]
	Learning Rate: 0.000106861
	LOSS [training: 0.13782560931706625 | validation: 0.14270806611517112]
	TIME [epoch: 8.54 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15819836592564215		[learning rate: 0.00010661]
	Learning Rate: 0.000106609
	LOSS [training: 0.15819836592564215 | validation: 0.156722830819068]
	TIME [epoch: 8.56 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16834015987597967		[learning rate: 0.00010636]
	Learning Rate: 0.000106358
	LOSS [training: 0.16834015987597967 | validation: 0.14636084768571478]
	TIME [epoch: 8.55 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14730706305903116		[learning rate: 0.00010611]
	Learning Rate: 0.000106107
	LOSS [training: 0.14730706305903116 | validation: 0.12484124430778529]
	TIME [epoch: 8.54 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13309705456524704		[learning rate: 0.00010586]
	Learning Rate: 0.000105857
	LOSS [training: 0.13309705456524704 | validation: 0.12545853803957685]
	TIME [epoch: 8.54 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1361533849815143		[learning rate: 0.00010561]
	Learning Rate: 0.000105607
	LOSS [training: 0.1361533849815143 | validation: 0.127483452095344]
	TIME [epoch: 8.55 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13267561382702137		[learning rate: 0.00010536]
	Learning Rate: 0.000105358
	LOSS [training: 0.13267561382702137 | validation: 0.12246548435149363]
	TIME [epoch: 8.56 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13075957958626327		[learning rate: 0.00010511]
	Learning Rate: 0.000105109
	LOSS [training: 0.13075957958626327 | validation: 0.10390620517640137]
	TIME [epoch: 8.54 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12377181738149923		[learning rate: 0.00010486]
	Learning Rate: 0.000104861
	LOSS [training: 0.12377181738149923 | validation: 0.11658789133812056]
	TIME [epoch: 8.54 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12227274678466638		[learning rate: 0.00010461]
	Learning Rate: 0.000104614
	LOSS [training: 0.12227274678466638 | validation: 0.11273200112796275]
	TIME [epoch: 8.54 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12496612225296522		[learning rate: 0.00010437]
	Learning Rate: 0.000104367
	LOSS [training: 0.12496612225296522 | validation: 0.1168551602908042]
	TIME [epoch: 8.56 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12759593036751976		[learning rate: 0.00010412]
	Learning Rate: 0.000104121
	LOSS [training: 0.12759593036751976 | validation: 0.11789441796287216]
	TIME [epoch: 8.53 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12706313426485352		[learning rate: 0.00010388]
	Learning Rate: 0.000103875
	LOSS [training: 0.12706313426485352 | validation: 0.12352516460782961]
	TIME [epoch: 8.54 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13148830733515823		[learning rate: 0.00010363]
	Learning Rate: 0.00010363
	LOSS [training: 0.13148830733515823 | validation: 0.1244393587774115]
	TIME [epoch: 8.54 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12688136546314016		[learning rate: 0.00010339]
	Learning Rate: 0.000103386
	LOSS [training: 0.12688136546314016 | validation: 0.12202692869331178]
	TIME [epoch: 8.56 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1268924798588993		[learning rate: 0.00010314]
	Learning Rate: 0.000103142
	LOSS [training: 0.1268924798588993 | validation: 0.11583646354658225]
	TIME [epoch: 8.54 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12852510096794362		[learning rate: 0.0001029]
	Learning Rate: 0.000102899
	LOSS [training: 0.12852510096794362 | validation: 0.12690047835491514]
	TIME [epoch: 8.54 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14086807130361612		[learning rate: 0.00010266]
	Learning Rate: 0.000102656
	LOSS [training: 0.14086807130361612 | validation: 0.14097432701185308]
	TIME [epoch: 8.54 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13842492739847784		[learning rate: 0.00010241]
	Learning Rate: 0.000102414
	LOSS [training: 0.13842492739847784 | validation: 0.11903588410210096]
	TIME [epoch: 8.57 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12998327688873954		[learning rate: 0.00010217]
	Learning Rate: 0.000102172
	LOSS [training: 0.12998327688873954 | validation: 0.1165642662672835]
	TIME [epoch: 8.55 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12781969167155863		[learning rate: 0.00010193]
	Learning Rate: 0.000101931
	LOSS [training: 0.12781969167155863 | validation: 0.11128261435847972]
	TIME [epoch: 8.55 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.124234095180492		[learning rate: 0.00010169]
	Learning Rate: 0.000101691
	LOSS [training: 0.124234095180492 | validation: 0.11148898217477335]
	TIME [epoch: 8.54 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12115964575061985		[learning rate: 0.00010145]
	Learning Rate: 0.000101451
	LOSS [training: 0.12115964575061985 | validation: 0.11311516701851035]
	TIME [epoch: 8.56 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12192839579254404		[learning rate: 0.00010121]
	Learning Rate: 0.000101212
	LOSS [training: 0.12192839579254404 | validation: 0.12429622435720183]
	TIME [epoch: 8.55 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12877791412168813		[learning rate: 0.00010097]
	Learning Rate: 0.000100973
	LOSS [training: 0.12877791412168813 | validation: 0.12275729813023376]
	TIME [epoch: 8.54 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13579870064823085		[learning rate: 0.00010073]
	Learning Rate: 0.000100735
	LOSS [training: 0.13579870064823085 | validation: 0.1167247928086582]
	TIME [epoch: 8.53 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12766612381431963		[learning rate: 0.0001005]
	Learning Rate: 0.000100497
	LOSS [training: 0.12766612381431963 | validation: 0.11134321159457314]
	TIME [epoch: 8.54 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13369583836526341		[learning rate: 0.00010026]
	Learning Rate: 0.00010026
	LOSS [training: 0.13369583836526341 | validation: 0.1251449857906261]
	TIME [epoch: 8.56 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13223970245173777		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.13223970245173777 | validation: 0.1187753049505168]
	TIME [epoch: 8.54 sec]
Finished training in 17186.038 seconds.
