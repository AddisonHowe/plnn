Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r1', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3278332428

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.598843489909052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.598843489909052 | validation: 9.69180991038058]
	TIME [epoch: 80.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.766474061212943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.766474061212943 | validation: 9.146431611874517]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.619049158057038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.619049158057038 | validation: 8.823553026352393]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.352170986612665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.352170986612665 | validation: 8.41982596665419]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.035543658769257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.035543658769257 | validation: 8.570253618893549]
	TIME [epoch: 9.49 sec]
EPOCH 6/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.260580948207998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.260580948207998 | validation: 8.57257066215024]
	TIME [epoch: 9.49 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.90169928463867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.90169928463867 | validation: 8.195188971014723]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.890795026174725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.890795026174725 | validation: 8.343743308216883]
	TIME [epoch: 9.49 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.67911530581055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.67911530581055 | validation: 9.053081056675612]
	TIME [epoch: 9.48 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.834785465266984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.834785465266984 | validation: 8.063012772654721]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.644802043590078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.644802043590078 | validation: 8.023493887269339]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.554378952399686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.554378952399686 | validation: 8.145330649161622]
	TIME [epoch: 9.5 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.686116494694435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.686116494694435 | validation: 8.445568170466306]
	TIME [epoch: 9.49 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.629617705178164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.629617705178164 | validation: 8.003853037167499]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.529496395378855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.529496395378855 | validation: 7.98328026665899]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.504593758285646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.504593758285646 | validation: 8.140493038781178]
	TIME [epoch: 9.49 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.47110059398617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.47110059398617 | validation: 8.221687501225528]
	TIME [epoch: 9.49 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.289525230550918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.289525230550918 | validation: 8.371570730672131]
	TIME [epoch: 9.49 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.58703110852396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.58703110852396 | validation: 7.809370629302845]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.158617246091932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.158617246091932 | validation: 7.42965501539702]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.037303058989538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.037303058989538 | validation: 7.38000932681974]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.897514354080144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.897514354080144 | validation: 7.364567453896416]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.970238061280033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.970238061280033 | validation: 7.537227696662244]
	TIME [epoch: 9.49 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.83095441027046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.83095441027046 | validation: 7.719912050268545]
	TIME [epoch: 9.5 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.944101779136136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.944101779136136 | validation: 7.639248981002061]
	TIME [epoch: 9.49 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.659053439234761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.659053439234761 | validation: 7.426290447152028]
	TIME [epoch: 9.48 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.791660941337784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.791660941337784 | validation: 7.60243476758503]
	TIME [epoch: 9.48 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.353008979155587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.353008979155587 | validation: 7.405228664708143]
	TIME [epoch: 9.51 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.084725805861305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.084725805861305 | validation: 7.055965604445443]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_29.pth
	Model improved!!!
EPOCH 30/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.542809292531115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.542809292531115 | validation: 9.469097510509657]
	TIME [epoch: 9.47 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.51165096245271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.51165096245271 | validation: 7.924526214928486]
	TIME [epoch: 9.49 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.557734576855935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.557734576855935 | validation: 6.840178129975014]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.772051198763886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.772051198763886 | validation: 6.141044399338901]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_33.pth
	Model improved!!!
EPOCH 34/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.1846382548293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1846382548293 | validation: 6.633830551969756]
	TIME [epoch: 9.48 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.411890329057262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.411890329057262 | validation: 5.521566335200827]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_35.pth
	Model improved!!!
EPOCH 36/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.608534013941119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.608534013941119 | validation: 5.1300492884628754]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.916199092807203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.916199092807203 | validation: 4.394438868978231]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_37.pth
	Model improved!!!
EPOCH 38/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.679763444565611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.679763444565611 | validation: 6.810644715205117]
	TIME [epoch: 9.5 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.415197941515334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.415197941515334 | validation: 8.307842666601797]
	TIME [epoch: 9.48 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.3893129568931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.3893129568931 | validation: 6.842874753315312]
	TIME [epoch: 9.48 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.076241731414332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.076241731414332 | validation: 6.586122717912978]
	TIME [epoch: 9.48 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.657489601705611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.657489601705611 | validation: 3.540555501881014]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_42.pth
	Model improved!!!
EPOCH 43/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9921544747624758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9921544747624758 | validation: 2.940863774978426]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_43.pth
	Model improved!!!
EPOCH 44/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.429609997445135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.429609997445135 | validation: 3.521985983322535]
	TIME [epoch: 9.48 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0582530291404053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0582530291404053 | validation: 2.8025838913418455]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4070837873015054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4070837873015054 | validation: 2.996165227939017]
	TIME [epoch: 9.48 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2970593944912645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2970593944912645 | validation: 3.021226657009759]
	TIME [epoch: 9.47 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.994836709851896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.994836709851896 | validation: 2.7316386761647107]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5161535790454703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5161535790454703 | validation: 1.928228372740403]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_49.pth
	Model improved!!!
EPOCH 50/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9278670320243267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9278670320243267 | validation: 2.118999383836335]
	TIME [epoch: 9.47 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8616345636297758		[learning rate: 0.0099613]
	Learning Rate: 0.00996129
	LOSS [training: 2.8616345636297758 | validation: 2.0786633584720846]
	TIME [epoch: 9.47 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9664814710780463		[learning rate: 0.0099131]
	Learning Rate: 0.00991312
	LOSS [training: 2.9664814710780463 | validation: 4.1258456361760185]
	TIME [epoch: 9.5 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.084568176794572		[learning rate: 0.0098652]
	Learning Rate: 0.00986519
	LOSS [training: 3.084568176794572 | validation: 2.603669053218135]
	TIME [epoch: 9.47 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.223323212607885		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 3.223323212607885 | validation: 4.262988457116341]
	TIME [epoch: 9.47 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7128072130452283		[learning rate: 0.00977]
	Learning Rate: 0.00977
	LOSS [training: 3.7128072130452283 | validation: 2.0239908753756604]
	TIME [epoch: 9.49 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.451219389279549		[learning rate: 0.0097228]
	Learning Rate: 0.00972276
	LOSS [training: 2.451219389279549 | validation: 2.579154135544572]
	TIME [epoch: 9.49 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.489946062875067		[learning rate: 0.0096757]
	Learning Rate: 0.00967574
	LOSS [training: 2.489946062875067 | validation: 2.205687330498548]
	TIME [epoch: 9.48 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.187846844264403		[learning rate: 0.009629]
	Learning Rate: 0.00962895
	LOSS [training: 3.187846844264403 | validation: 1.9754957443964474]
	TIME [epoch: 9.47 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.529253613983248		[learning rate: 0.0095824]
	Learning Rate: 0.00958239
	LOSS [training: 2.529253613983248 | validation: 2.9871352859904836]
	TIME [epoch: 9.51 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.501664677178295		[learning rate: 0.009536]
	Learning Rate: 0.00953605
	LOSS [training: 2.501664677178295 | validation: 2.2656946272557326]
	TIME [epoch: 9.48 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7896639846988243		[learning rate: 0.0094899]
	Learning Rate: 0.00948993
	LOSS [training: 2.7896639846988243 | validation: 2.841180928475476]
	TIME [epoch: 9.46 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4732621283036162		[learning rate: 0.009444]
	Learning Rate: 0.00944404
	LOSS [training: 2.4732621283036162 | validation: 1.9357840947492166]
	TIME [epoch: 9.5 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.294576797718416		[learning rate: 0.0093984]
	Learning Rate: 0.00939837
	LOSS [training: 2.294576797718416 | validation: 1.8863358081650947]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_63.pth
	Model improved!!!
EPOCH 64/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6121873404015075		[learning rate: 0.0093529]
	Learning Rate: 0.00935292
	LOSS [training: 2.6121873404015075 | validation: 2.3855788050465443]
	TIME [epoch: 9.49 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.241284640485337		[learning rate: 0.0093077]
	Learning Rate: 0.00930769
	LOSS [training: 2.241284640485337 | validation: 2.197981684279659]
	TIME [epoch: 9.48 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4379591836520476		[learning rate: 0.0092627]
	Learning Rate: 0.00926268
	LOSS [training: 3.4379591836520476 | validation: 2.4267684013473962]
	TIME [epoch: 9.51 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.833313639577624		[learning rate: 0.0092179]
	Learning Rate: 0.00921789
	LOSS [training: 2.833313639577624 | validation: 1.9363447384158854]
	TIME [epoch: 9.49 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9525168178076497		[learning rate: 0.0091733]
	Learning Rate: 0.00917332
	LOSS [training: 1.9525168178076497 | validation: 1.9587264866506136]
	TIME [epoch: 9.48 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1074899390304047		[learning rate: 0.009129]
	Learning Rate: 0.00912895
	LOSS [training: 2.1074899390304047 | validation: 2.352219017445256]
	TIME [epoch: 9.5 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.148904670447321		[learning rate: 0.0090848]
	Learning Rate: 0.00908481
	LOSS [training: 2.148904670447321 | validation: 2.2988130165939955]
	TIME [epoch: 9.5 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7248990266824464		[learning rate: 0.0090409]
	Learning Rate: 0.00904088
	LOSS [training: 1.7248990266824464 | validation: 1.666838336045383]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_71.pth
	Model improved!!!
EPOCH 72/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9470927271093026		[learning rate: 0.0089972]
	Learning Rate: 0.00899716
	LOSS [training: 2.9470927271093026 | validation: 5.325385586634066]
	TIME [epoch: 9.48 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1803640570859133		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 3.1803640570859133 | validation: 1.8779896639340012]
	TIME [epoch: 9.51 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.790889204212138		[learning rate: 0.0089103]
	Learning Rate: 0.00891035
	LOSS [training: 1.790889204212138 | validation: 2.0247127409516694]
	TIME [epoch: 9.48 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.758607531519452		[learning rate: 0.0088673]
	Learning Rate: 0.00886726
	LOSS [training: 1.758607531519452 | validation: 2.7608724205446213]
	TIME [epoch: 9.48 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2761596630549663		[learning rate: 0.0088244]
	Learning Rate: 0.00882438
	LOSS [training: 2.2761596630549663 | validation: 2.1878176907511557]
	TIME [epoch: 9.48 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1567009109377624		[learning rate: 0.0087817]
	Learning Rate: 0.00878171
	LOSS [training: 2.1567009109377624 | validation: 3.6088348636341814]
	TIME [epoch: 9.48 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.785815640247905		[learning rate: 0.0087392]
	Learning Rate: 0.00873924
	LOSS [training: 2.785815640247905 | validation: 4.158894696551503]
	TIME [epoch: 9.47 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.336143983499396		[learning rate: 0.008697]
	Learning Rate: 0.00869698
	LOSS [training: 6.336143983499396 | validation: 6.554620203168679]
	TIME [epoch: 9.49 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.8037433127499325		[learning rate: 0.0086549]
	Learning Rate: 0.00865492
	LOSS [training: 5.8037433127499325 | validation: 2.175788361145684]
	TIME [epoch: 9.51 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.66469558360757		[learning rate: 0.0086131]
	Learning Rate: 0.00861307
	LOSS [training: 2.66469558360757 | validation: 3.067455357730306]
	TIME [epoch: 9.49 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.804095518095818		[learning rate: 0.0085714]
	Learning Rate: 0.00857142
	LOSS [training: 2.804095518095818 | validation: 2.4665725184073333]
	TIME [epoch: 9.48 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1525165481920494		[learning rate: 0.00853]
	Learning Rate: 0.00852997
	LOSS [training: 2.1525165481920494 | validation: 3.238152976526559]
	TIME [epoch: 9.48 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2927678197732235		[learning rate: 0.0084887]
	Learning Rate: 0.00848872
	LOSS [training: 2.2927678197732235 | validation: 2.0181159710694896]
	TIME [epoch: 9.48 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.116690987286477		[learning rate: 0.0084477]
	Learning Rate: 0.00844767
	LOSS [training: 3.116690987286477 | validation: 2.480141914147726]
	TIME [epoch: 9.47 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9856796262465553		[learning rate: 0.0084068]
	Learning Rate: 0.00840682
	LOSS [training: 2.9856796262465553 | validation: 2.9697644082804446]
	TIME [epoch: 9.46 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9885787254938103		[learning rate: 0.0083662]
	Learning Rate: 0.00836616
	LOSS [training: 2.9885787254938103 | validation: 2.514053122775862]
	TIME [epoch: 9.49 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9146945869937566		[learning rate: 0.0083257]
	Learning Rate: 0.00832571
	LOSS [training: 2.9146945869937566 | validation: 3.453136760818044]
	TIME [epoch: 9.46 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6303790925902675		[learning rate: 0.0082854]
	Learning Rate: 0.00828544
	LOSS [training: 2.6303790925902675 | validation: 4.2847517880925485]
	TIME [epoch: 9.47 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.371054581369617		[learning rate: 0.0082454]
	Learning Rate: 0.00824538
	LOSS [training: 2.371054581369617 | validation: 1.823764153190619]
	TIME [epoch: 9.48 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5398219717663375		[learning rate: 0.0082055]
	Learning Rate: 0.0082055
	LOSS [training: 1.5398219717663375 | validation: 5.402317070272641]
	TIME [epoch: 9.49 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.162410145494893		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 3.162410145494893 | validation: 5.232750897825928]
	TIME [epoch: 9.47 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8446815244010453		[learning rate: 0.0081263]
	Learning Rate: 0.00812634
	LOSS [training: 3.8446815244010453 | validation: 2.020804317976893]
	TIME [epoch: 9.47 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7718347908040346		[learning rate: 0.008087]
	Learning Rate: 0.00808704
	LOSS [training: 1.7718347908040346 | validation: 1.718415974107882]
	TIME [epoch: 9.49 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.030857320143313		[learning rate: 0.0080479]
	Learning Rate: 0.00804793
	LOSS [training: 2.030857320143313 | validation: 1.595510949729105]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_95.pth
	Model improved!!!
EPOCH 96/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3775989721736788		[learning rate: 0.008009]
	Learning Rate: 0.00800901
	LOSS [training: 1.3775989721736788 | validation: 1.8769432857327666]
	TIME [epoch: 9.49 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6353589008808016		[learning rate: 0.0079703]
	Learning Rate: 0.00797028
	LOSS [training: 1.6353589008808016 | validation: 1.7684999216663277]
	TIME [epoch: 9.49 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5068502960431842		[learning rate: 0.0079317]
	Learning Rate: 0.00793174
	LOSS [training: 1.5068502960431842 | validation: 2.073160358685809]
	TIME [epoch: 9.49 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9970202517204616		[learning rate: 0.0078934]
	Learning Rate: 0.00789338
	LOSS [training: 1.9970202517204616 | validation: 1.2326321294741407]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_99.pth
	Model improved!!!
EPOCH 100/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.325128614621062		[learning rate: 0.0078552]
	Learning Rate: 0.00785521
	LOSS [training: 1.325128614621062 | validation: 2.3782953369173145]
	TIME [epoch: 9.46 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7241225649762444		[learning rate: 0.0078172]
	Learning Rate: 0.00781722
	LOSS [training: 1.7241225649762444 | validation: 1.108326598905603]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_101.pth
	Model improved!!!
EPOCH 102/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.568497765932243		[learning rate: 0.0077794]
	Learning Rate: 0.00777942
	LOSS [training: 1.568497765932243 | validation: 1.6598176380874266]
	TIME [epoch: 9.47 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2812937522596308		[learning rate: 0.0077418]
	Learning Rate: 0.0077418
	LOSS [training: 1.2812937522596308 | validation: 1.4534620488535785]
	TIME [epoch: 9.47 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9986057810051914		[learning rate: 0.0077044]
	Learning Rate: 0.00770437
	LOSS [training: 1.9986057810051914 | validation: 4.032295049184439]
	TIME [epoch: 9.49 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.034358690427766		[learning rate: 0.0076671]
	Learning Rate: 0.00766711
	LOSS [training: 3.034358690427766 | validation: 1.6395513858978297]
	TIME [epoch: 9.47 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7047995683973352		[learning rate: 0.00763]
	Learning Rate: 0.00763003
	LOSS [training: 1.7047995683973352 | validation: 3.3946423959377388]
	TIME [epoch: 9.47 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9296109535901693		[learning rate: 0.0075931]
	Learning Rate: 0.00759313
	LOSS [training: 1.9296109535901693 | validation: 1.5220315775799989]
	TIME [epoch: 9.48 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7999058705047908		[learning rate: 0.0075564]
	Learning Rate: 0.00755642
	LOSS [training: 1.7999058705047908 | validation: 1.2817452715229036]
	TIME [epoch: 9.51 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.496041728621237		[learning rate: 0.0075199]
	Learning Rate: 0.00751987
	LOSS [training: 1.496041728621237 | validation: 1.4550979527692138]
	TIME [epoch: 9.47 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3818360858321892		[learning rate: 0.0074835]
	Learning Rate: 0.00748351
	LOSS [training: 1.3818360858321892 | validation: 1.5887158126311858]
	TIME [epoch: 9.47 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.433290413112495		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 1.433290413112495 | validation: 2.79979340411682]
	TIME [epoch: 9.5 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5267006113803645		[learning rate: 0.0074113]
	Learning Rate: 0.00741131
	LOSS [training: 1.5267006113803645 | validation: 1.3394961690005622]
	TIME [epoch: 9.48 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.136561699942292		[learning rate: 0.0073755]
	Learning Rate: 0.00737547
	LOSS [training: 2.136561699942292 | validation: 1.9397008927870278]
	TIME [epoch: 9.47 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5041350520379462		[learning rate: 0.0073398]
	Learning Rate: 0.0073398
	LOSS [training: 1.5041350520379462 | validation: 1.0324616953379393]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_114.pth
	Model improved!!!
EPOCH 115/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1298231302936825		[learning rate: 0.0073043]
	Learning Rate: 0.00730431
	LOSS [training: 1.1298231302936825 | validation: 1.7328875897875031]
	TIME [epoch: 9.49 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0072689779677186		[learning rate: 0.007269]
	Learning Rate: 0.00726898
	LOSS [training: 2.0072689779677186 | validation: 0.9356978241279151]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_116.pth
	Model improved!!!
EPOCH 117/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.952561629774366		[learning rate: 0.0072338]
	Learning Rate: 0.00723383
	LOSS [training: 1.952561629774366 | validation: 2.1972386853415236]
	TIME [epoch: 9.47 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8555089373021185		[learning rate: 0.0071989]
	Learning Rate: 0.00719885
	LOSS [training: 1.8555089373021185 | validation: 4.176852497734353]
	TIME [epoch: 9.48 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.941469774785844		[learning rate: 0.007164]
	Learning Rate: 0.00716404
	LOSS [training: 1.941469774785844 | validation: 2.324922405850086]
	TIME [epoch: 9.48 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5117995115170237		[learning rate: 0.0071294]
	Learning Rate: 0.00712939
	LOSS [training: 1.5117995115170237 | validation: 1.1862886793881264]
	TIME [epoch: 9.47 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1881803491924148		[learning rate: 0.0070949]
	Learning Rate: 0.00709492
	LOSS [training: 1.1881803491924148 | validation: 1.4857091063340588]
	TIME [epoch: 9.48 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5361469927135303		[learning rate: 0.0070606]
	Learning Rate: 0.00706061
	LOSS [training: 1.5361469927135303 | validation: 2.46631962629709]
	TIME [epoch: 9.51 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2111860526120695		[learning rate: 0.0070265]
	Learning Rate: 0.00702646
	LOSS [training: 2.2111860526120695 | validation: 2.941564152390544]
	TIME [epoch: 9.48 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1042753137886065		[learning rate: 0.0069925]
	Learning Rate: 0.00699248
	LOSS [training: 2.1042753137886065 | validation: 1.5628201661642789]
	TIME [epoch: 9.46 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.932066994164611		[learning rate: 0.0069587]
	Learning Rate: 0.00695867
	LOSS [training: 1.932066994164611 | validation: 1.8405907211584878]
	TIME [epoch: 9.48 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.10998536888533		[learning rate: 0.006925]
	Learning Rate: 0.00692502
	LOSS [training: 2.10998536888533 | validation: 2.2366862772843024]
	TIME [epoch: 9.47 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.55810076020556		[learning rate: 0.0068915]
	Learning Rate: 0.00689153
	LOSS [training: 2.55810076020556 | validation: 1.9752932794122606]
	TIME [epoch: 9.48 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6478699963236239		[learning rate: 0.0068582]
	Learning Rate: 0.00685821
	LOSS [training: 1.6478699963236239 | validation: 1.4676989906330744]
	TIME [epoch: 9.47 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1727452209592213		[learning rate: 0.006825]
	Learning Rate: 0.00682504
	LOSS [training: 1.1727452209592213 | validation: 1.8032933992504336]
	TIME [epoch: 9.49 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7945944558561178		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 1.7945944558561178 | validation: 3.4579558762782563]
	TIME [epoch: 9.48 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2930195481660567		[learning rate: 0.0067592]
	Learning Rate: 0.00675919
	LOSS [training: 2.2930195481660567 | validation: 1.2028130324350104]
	TIME [epoch: 9.48 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4921285290513104		[learning rate: 0.0067265]
	Learning Rate: 0.00672651
	LOSS [training: 2.4921285290513104 | validation: 1.3501443404015248]
	TIME [epoch: 9.5 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.625114027737963		[learning rate: 0.006694]
	Learning Rate: 0.00669398
	LOSS [training: 1.625114027737963 | validation: 1.0458432532415267]
	TIME [epoch: 9.48 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9184130811505009		[learning rate: 0.0066616]
	Learning Rate: 0.00666161
	LOSS [training: 0.9184130811505009 | validation: 0.869077582055085]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_134.pth
	Model improved!!!
EPOCH 135/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0190073139467466		[learning rate: 0.0066294]
	Learning Rate: 0.00662939
	LOSS [training: 1.0190073139467466 | validation: 0.8217483486589015]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_135.pth
	Model improved!!!
EPOCH 136/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0991711265908712		[learning rate: 0.0065973]
	Learning Rate: 0.00659733
	LOSS [training: 2.0991711265908712 | validation: 2.7167989225633358]
	TIME [epoch: 9.48 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.688953053918882		[learning rate: 0.0065654]
	Learning Rate: 0.00656543
	LOSS [training: 1.688953053918882 | validation: 1.4998444882303759]
	TIME [epoch: 9.46 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3073469972319107		[learning rate: 0.0065337]
	Learning Rate: 0.00653368
	LOSS [training: 1.3073469972319107 | validation: 0.9530680831623112]
	TIME [epoch: 9.46 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0034267793233265		[learning rate: 0.0065021]
	Learning Rate: 0.00650208
	LOSS [training: 1.0034267793233265 | validation: 1.6044208479349948]
	TIME [epoch: 9.48 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4935233280979783		[learning rate: 0.0064706]
	Learning Rate: 0.00647064
	LOSS [training: 1.4935233280979783 | validation: 1.5851931858494677]
	TIME [epoch: 9.47 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7053743499513971		[learning rate: 0.0064394]
	Learning Rate: 0.00643935
	LOSS [training: 1.7053743499513971 | validation: 2.471498069496865]
	TIME [epoch: 9.46 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.06455654415052		[learning rate: 0.0064082]
	Learning Rate: 0.00640821
	LOSS [training: 2.06455654415052 | validation: 1.8583152974081403]
	TIME [epoch: 9.46 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1865198126989376		[learning rate: 0.0063772]
	Learning Rate: 0.00637722
	LOSS [training: 1.1865198126989376 | validation: 1.0211781128360697]
	TIME [epoch: 9.49 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1051353497716312		[learning rate: 0.0063464]
	Learning Rate: 0.00634638
	LOSS [training: 1.1051353497716312 | validation: 1.4656264293173535]
	TIME [epoch: 9.46 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.930086243138558		[learning rate: 0.0063157]
	Learning Rate: 0.00631569
	LOSS [training: 1.930086243138558 | validation: 2.4450636953384173]
	TIME [epoch: 9.46 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9211272616814086		[learning rate: 0.0062852]
	Learning Rate: 0.00628515
	LOSS [training: 1.9211272616814086 | validation: 3.353582059658163]
	TIME [epoch: 9.49 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6690577303258478		[learning rate: 0.0062548]
	Learning Rate: 0.00625476
	LOSS [training: 1.6690577303258478 | validation: 1.519533155987044]
	TIME [epoch: 9.47 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1140001111091808		[learning rate: 0.0062245]
	Learning Rate: 0.00622451
	LOSS [training: 1.1140001111091808 | validation: 1.3627347875182465]
	TIME [epoch: 9.46 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2334679300081626		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 2.2334679300081626 | validation: 1.3720852465982574]
	TIME [epoch: 9.46 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4632331659964037		[learning rate: 0.0061645]
	Learning Rate: 0.00616446
	LOSS [training: 1.4632331659964037 | validation: 1.894475731323427]
	TIME [epoch: 9.49 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6439066839312144		[learning rate: 0.0061346]
	Learning Rate: 0.00613465
	LOSS [training: 1.6439066839312144 | validation: 1.698310032205882]
	TIME [epoch: 9.46 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2455720336797644		[learning rate: 0.006105]
	Learning Rate: 0.00610498
	LOSS [training: 1.2455720336797644 | validation: 1.2755797112597356]
	TIME [epoch: 9.47 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.452397702532377		[learning rate: 0.0060755]
	Learning Rate: 0.00607546
	LOSS [training: 1.452397702532377 | validation: 1.7677070731990239]
	TIME [epoch: 9.48 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3241406917606464		[learning rate: 0.0060461]
	Learning Rate: 0.00604608
	LOSS [training: 1.3241406917606464 | validation: 1.4698458055805552]
	TIME [epoch: 9.47 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1699297753587485		[learning rate: 0.0060168]
	Learning Rate: 0.00601684
	LOSS [training: 1.1699297753587485 | validation: 0.9483998688969245]
	TIME [epoch: 9.46 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0665870305416365		[learning rate: 0.0059877]
	Learning Rate: 0.00598774
	LOSS [training: 1.0665870305416365 | validation: 1.70545035222539]
	TIME [epoch: 9.46 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3223157691588054		[learning rate: 0.0059588]
	Learning Rate: 0.00595879
	LOSS [training: 1.3223157691588054 | validation: 1.2501899695394085]
	TIME [epoch: 9.48 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9376465358168293		[learning rate: 0.00593]
	Learning Rate: 0.00592997
	LOSS [training: 0.9376465358168293 | validation: 1.725998040433232]
	TIME [epoch: 9.45 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9353392439994679		[learning rate: 0.0059013]
	Learning Rate: 0.0059013
	LOSS [training: 1.9353392439994679 | validation: 1.3495724792313586]
	TIME [epoch: 9.45 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2596329866039417		[learning rate: 0.0058728]
	Learning Rate: 0.00587276
	LOSS [training: 1.2596329866039417 | validation: 0.9821908032432378]
	TIME [epoch: 9.48 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9004497576722494		[learning rate: 0.0058444]
	Learning Rate: 0.00584436
	LOSS [training: 0.9004497576722494 | validation: 0.952675515861039]
	TIME [epoch: 9.46 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0725546989902348		[learning rate: 0.0058161]
	Learning Rate: 0.0058161
	LOSS [training: 1.0725546989902348 | validation: 1.6462414133534737]
	TIME [epoch: 9.46 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4649176883816486		[learning rate: 0.005788]
	Learning Rate: 0.00578797
	LOSS [training: 1.4649176883816486 | validation: 1.250977654592117]
	TIME [epoch: 9.45 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6264953235624753		[learning rate: 0.00576]
	Learning Rate: 0.00575998
	LOSS [training: 1.6264953235624753 | validation: 1.2170531533571778]
	TIME [epoch: 9.47 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1556877842291464		[learning rate: 0.0057321]
	Learning Rate: 0.00573213
	LOSS [training: 1.1556877842291464 | validation: 1.3417287720478128]
	TIME [epoch: 9.45 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8049463810995338		[learning rate: 0.0057044]
	Learning Rate: 0.00570441
	LOSS [training: 0.8049463810995338 | validation: 0.8155326137918113]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_166.pth
	Model improved!!!
EPOCH 167/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8863202386072843		[learning rate: 0.0056768]
	Learning Rate: 0.00567682
	LOSS [training: 0.8863202386072843 | validation: 0.8321882773377014]
	TIME [epoch: 9.48 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.212742398838289		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 1.212742398838289 | validation: 1.9286476392834546]
	TIME [epoch: 9.46 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2119434983621353		[learning rate: 0.0056221]
	Learning Rate: 0.00562205
	LOSS [training: 2.2119434983621353 | validation: 3.232632731833478]
	TIME [epoch: 9.45 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9737645630500296		[learning rate: 0.0055949]
	Learning Rate: 0.00559486
	LOSS [training: 1.9737645630500296 | validation: 0.9974866078414308]
	TIME [epoch: 9.46 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5341062242058414		[learning rate: 0.0055678]
	Learning Rate: 0.00556781
	LOSS [training: 1.5341062242058414 | validation: 5.134208084705872]
	TIME [epoch: 9.48 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.782223498321621		[learning rate: 0.0055409]
	Learning Rate: 0.00554088
	LOSS [training: 2.782223498321621 | validation: 1.1158031069657222]
	TIME [epoch: 9.45 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9757722156149089		[learning rate: 0.0055141]
	Learning Rate: 0.00551409
	LOSS [training: 0.9757722156149089 | validation: 1.2232982135692216]
	TIME [epoch: 9.45 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8489213973792958		[learning rate: 0.0054874]
	Learning Rate: 0.00548742
	LOSS [training: 0.8489213973792958 | validation: 1.6655496437761246]
	TIME [epoch: 9.47 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9783280870203279		[learning rate: 0.0054609]
	Learning Rate: 0.00546089
	LOSS [training: 0.9783280870203279 | validation: 0.7796864693283192]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_175.pth
	Model improved!!!
EPOCH 176/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8135790808817112		[learning rate: 0.0054345]
	Learning Rate: 0.00543448
	LOSS [training: 0.8135790808817112 | validation: 0.654057420710124]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_176.pth
	Model improved!!!
EPOCH 177/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.808923474524469		[learning rate: 0.0054082]
	Learning Rate: 0.0054082
	LOSS [training: 0.808923474524469 | validation: 0.8063177240902698]
	TIME [epoch: 9.46 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3221173610601666		[learning rate: 0.005382]
	Learning Rate: 0.00538205
	LOSS [training: 1.3221173610601666 | validation: 1.0974192526050564]
	TIME [epoch: 9.47 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0593127315004527		[learning rate: 0.005356]
	Learning Rate: 0.00535602
	LOSS [training: 1.0593127315004527 | validation: 1.7913544613506873]
	TIME [epoch: 9.45 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3505477435397446		[learning rate: 0.0053301]
	Learning Rate: 0.00533012
	LOSS [training: 1.3505477435397446 | validation: 1.5576302303849792]
	TIME [epoch: 9.45 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5170917542946116		[learning rate: 0.0053043]
	Learning Rate: 0.00530434
	LOSS [training: 1.5170917542946116 | validation: 1.131182162625245]
	TIME [epoch: 9.46 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.074730396734179		[learning rate: 0.0052787]
	Learning Rate: 0.00527869
	LOSS [training: 1.074730396734179 | validation: 0.9487552650816895]
	TIME [epoch: 9.44 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8043006504701931		[learning rate: 0.0052532]
	Learning Rate: 0.00525316
	LOSS [training: 0.8043006504701931 | validation: 0.9384816726067027]
	TIME [epoch: 9.44 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7814569107943071		[learning rate: 0.0052278]
	Learning Rate: 0.00522776
	LOSS [training: 0.7814569107943071 | validation: 0.7755399804177614]
	TIME [epoch: 9.44 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8102783388104676		[learning rate: 0.0052025]
	Learning Rate: 0.00520248
	LOSS [training: 0.8102783388104676 | validation: 0.8073919655326088]
	TIME [epoch: 9.46 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0664142747650065		[learning rate: 0.0051773]
	Learning Rate: 0.00517732
	LOSS [training: 1.0664142747650065 | validation: 0.8345278822869453]
	TIME [epoch: 9.45 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8074796161852331		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 0.8074796161852331 | validation: 0.8155343676183359]
	TIME [epoch: 9.44 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9035270653994496		[learning rate: 0.0051274]
	Learning Rate: 0.00512737
	LOSS [training: 0.9035270653994496 | validation: 0.6607902775018554]
	TIME [epoch: 9.47 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.067867973805998		[learning rate: 0.0051026]
	Learning Rate: 0.00510258
	LOSS [training: 1.067867973805998 | validation: 1.364786274343743]
	TIME [epoch: 9.45 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6038204476205085		[learning rate: 0.0050779]
	Learning Rate: 0.0050779
	LOSS [training: 1.6038204476205085 | validation: 1.3180347439198548]
	TIME [epoch: 9.44 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0059819054185704		[learning rate: 0.0050533]
	Learning Rate: 0.00505334
	LOSS [training: 1.0059819054185704 | validation: 0.8181344659710189]
	TIME [epoch: 9.45 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.708533226060917		[learning rate: 0.0050289]
	Learning Rate: 0.00502891
	LOSS [training: 0.708533226060917 | validation: 0.8738412534027746]
	TIME [epoch: 9.46 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.722858038078261		[learning rate: 0.0050046]
	Learning Rate: 0.00500459
	LOSS [training: 0.722858038078261 | validation: 0.6521336827486703]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_193.pth
	Model improved!!!
EPOCH 194/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8941656618270271		[learning rate: 0.0049804]
	Learning Rate: 0.00498039
	LOSS [training: 0.8941656618270271 | validation: 0.9265092524791502]
	TIME [epoch: 9.46 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6162825415129306		[learning rate: 0.0049563]
	Learning Rate: 0.0049563
	LOSS [training: 0.6162825415129306 | validation: 1.0949800441958197]
	TIME [epoch: 9.47 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0115681608260751		[learning rate: 0.0049323]
	Learning Rate: 0.00493234
	LOSS [training: 1.0115681608260751 | validation: 1.120648124953535]
	TIME [epoch: 9.46 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9885909800327569		[learning rate: 0.0049085]
	Learning Rate: 0.00490848
	LOSS [training: 0.9885909800327569 | validation: 0.843467259696373]
	TIME [epoch: 9.46 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8035894855321576		[learning rate: 0.0048847]
	Learning Rate: 0.00488475
	LOSS [training: 0.8035894855321576 | validation: 1.025868319816087]
	TIME [epoch: 9.47 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9565986813983747		[learning rate: 0.0048611]
	Learning Rate: 0.00486113
	LOSS [training: 0.9565986813983747 | validation: 1.774424384199666]
	TIME [epoch: 9.47 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0578147783447174		[learning rate: 0.0048376]
	Learning Rate: 0.00483762
	LOSS [training: 1.0578147783447174 | validation: 1.112438754009657]
	TIME [epoch: 9.45 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9765402542884836		[learning rate: 0.0048142]
	Learning Rate: 0.00481422
	LOSS [training: 0.9765402542884836 | validation: 1.019600945188998]
	TIME [epoch: 9.44 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2919292552588222		[learning rate: 0.0047909]
	Learning Rate: 0.00479094
	LOSS [training: 1.2919292552588222 | validation: 1.1149588105512218]
	TIME [epoch: 9.47 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9541817601408276		[learning rate: 0.0047678]
	Learning Rate: 0.00476778
	LOSS [training: 0.9541817601408276 | validation: 0.7398636493920782]
	TIME [epoch: 9.45 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8308648114056378		[learning rate: 0.0047447]
	Learning Rate: 0.00474472
	LOSS [training: 0.8308648114056378 | validation: 2.7803941628945172]
	TIME [epoch: 9.45 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7938277859332015		[learning rate: 0.0047218]
	Learning Rate: 0.00472177
	LOSS [training: 1.7938277859332015 | validation: 1.450071716760931]
	TIME [epoch: 9.45 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0030172102841672		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 1.0030172102841672 | validation: 1.2087883048258978]
	TIME [epoch: 9.46 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.996343786410334		[learning rate: 0.0046762]
	Learning Rate: 0.00467622
	LOSS [training: 0.996343786410334 | validation: 1.1147263941489949]
	TIME [epoch: 9.44 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0216784391332108		[learning rate: 0.0046536]
	Learning Rate: 0.0046536
	LOSS [training: 1.0216784391332108 | validation: 1.1283706946073555]
	TIME [epoch: 9.44 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.015117639126193		[learning rate: 0.0046311]
	Learning Rate: 0.0046311
	LOSS [training: 1.015117639126193 | validation: 0.9722550649648863]
	TIME [epoch: 9.46 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0056383671764646		[learning rate: 0.0046087]
	Learning Rate: 0.00460871
	LOSS [training: 1.0056383671764646 | validation: 0.9474467368715123]
	TIME [epoch: 9.45 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9243204310540412		[learning rate: 0.0045864]
	Learning Rate: 0.00458642
	LOSS [training: 0.9243204310540412 | validation: 0.7885579175681179]
	TIME [epoch: 9.45 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8763770654992928		[learning rate: 0.0045642]
	Learning Rate: 0.00456424
	LOSS [training: 0.8763770654992928 | validation: 0.9484524953080962]
	TIME [epoch: 9.45 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8356295701168831		[learning rate: 0.0045422]
	Learning Rate: 0.00454217
	LOSS [training: 0.8356295701168831 | validation: 0.8772244837839034]
	TIME [epoch: 9.46 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0462429162636024		[learning rate: 0.0045202]
	Learning Rate: 0.0045202
	LOSS [training: 1.0462429162636024 | validation: 1.1341827003266258]
	TIME [epoch: 9.45 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.496725093247988		[learning rate: 0.0044983]
	Learning Rate: 0.00449834
	LOSS [training: 1.496725093247988 | validation: 0.9828533674090957]
	TIME [epoch: 9.44 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.809273160671118		[learning rate: 0.0044766]
	Learning Rate: 0.00447659
	LOSS [training: 0.809273160671118 | validation: 0.5663261945099354]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_216.pth
	Model improved!!!
EPOCH 217/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7031801559983744		[learning rate: 0.0044549]
	Learning Rate: 0.00445494
	LOSS [training: 0.7031801559983744 | validation: 0.7940836654690935]
	TIME [epoch: 9.46 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7731728656620775		[learning rate: 0.0044334]
	Learning Rate: 0.0044334
	LOSS [training: 0.7731728656620775 | validation: 1.031476497534141]
	TIME [epoch: 9.46 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7758856848491487		[learning rate: 0.004412]
	Learning Rate: 0.00441196
	LOSS [training: 0.7758856848491487 | validation: 0.6261419626130496]
	TIME [epoch: 9.47 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6436686103830085		[learning rate: 0.0043906]
	Learning Rate: 0.00439062
	LOSS [training: 0.6436686103830085 | validation: 0.8142551459139077]
	TIME [epoch: 9.48 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7529263701192718		[learning rate: 0.0043694]
	Learning Rate: 0.00436939
	LOSS [training: 0.7529263701192718 | validation: 1.8518212932228841]
	TIME [epoch: 9.47 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.256209426978177		[learning rate: 0.0043483]
	Learning Rate: 0.00434826
	LOSS [training: 1.256209426978177 | validation: 1.6602133072228213]
	TIME [epoch: 9.46 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.881188831911755		[learning rate: 0.0043272]
	Learning Rate: 0.00432724
	LOSS [training: 0.881188831911755 | validation: 0.6227471853911511]
	TIME [epoch: 9.49 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6287157321169303		[learning rate: 0.0043063]
	Learning Rate: 0.00430631
	LOSS [training: 0.6287157321169303 | validation: 0.7600911098659617]
	TIME [epoch: 9.47 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5865190463604459		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 0.5865190463604459 | validation: 1.0433986196084997]
	TIME [epoch: 9.47 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.700277531941368		[learning rate: 0.0042648]
	Learning Rate: 0.00426476
	LOSS [training: 0.700277531941368 | validation: 0.8576088101671977]
	TIME [epoch: 9.47 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2076668431561137		[learning rate: 0.0042441]
	Learning Rate: 0.00424414
	LOSS [training: 1.2076668431561137 | validation: 0.8555082949241813]
	TIME [epoch: 9.48 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.651501087793559		[learning rate: 0.0042236]
	Learning Rate: 0.00422361
	LOSS [training: 0.651501087793559 | validation: 0.5790123429925755]
	TIME [epoch: 9.46 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0641421558329145		[learning rate: 0.0042032]
	Learning Rate: 0.00420319
	LOSS [training: 1.0641421558329145 | validation: 1.1920135499710822]
	TIME [epoch: 9.47 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1585661900201498		[learning rate: 0.0041829]
	Learning Rate: 0.00418286
	LOSS [training: 1.1585661900201498 | validation: 1.0585225777412708]
	TIME [epoch: 9.49 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.119216921939455		[learning rate: 0.0041626]
	Learning Rate: 0.00416264
	LOSS [training: 1.119216921939455 | validation: 0.8691097381814344]
	TIME [epoch: 9.47 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0387252266531688		[learning rate: 0.0041425]
	Learning Rate: 0.00414251
	LOSS [training: 1.0387252266531688 | validation: 1.7603555815897876]
	TIME [epoch: 9.47 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8070413655867256		[learning rate: 0.0041225]
	Learning Rate: 0.00412247
	LOSS [training: 0.8070413655867256 | validation: 1.2913429637895961]
	TIME [epoch: 9.47 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.130510474506313		[learning rate: 0.0041025]
	Learning Rate: 0.00410254
	LOSS [training: 1.130510474506313 | validation: 0.8101590415206785]
	TIME [epoch: 9.48 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0839313004203128		[learning rate: 0.0040827]
	Learning Rate: 0.0040827
	LOSS [training: 1.0839313004203128 | validation: 1.8786053105114338]
	TIME [epoch: 9.46 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1077867160354866		[learning rate: 0.004063]
	Learning Rate: 0.00406296
	LOSS [training: 1.1077867160354866 | validation: 0.7334837392780051]
	TIME [epoch: 9.46 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7976878260720464		[learning rate: 0.0040433]
	Learning Rate: 0.00404331
	LOSS [training: 0.7976878260720464 | validation: 0.8721525216449879]
	TIME [epoch: 9.48 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7393946970740963		[learning rate: 0.0040238]
	Learning Rate: 0.00402375
	LOSS [training: 0.7393946970740963 | validation: 1.0531687974462627]
	TIME [epoch: 9.47 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6120146929461651		[learning rate: 0.0040043]
	Learning Rate: 0.0040043
	LOSS [training: 0.6120146929461651 | validation: 1.0716308862687505]
	TIME [epoch: 9.46 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.798537603355926		[learning rate: 0.0039849]
	Learning Rate: 0.00398493
	LOSS [training: 0.798537603355926 | validation: 0.6730388906272549]
	TIME [epoch: 9.47 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8431272678973467		[learning rate: 0.0039657]
	Learning Rate: 0.00396566
	LOSS [training: 0.8431272678973467 | validation: 0.5867225365108741]
	TIME [epoch: 9.48 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7505693491290598		[learning rate: 0.0039465]
	Learning Rate: 0.00394649
	LOSS [training: 0.7505693491290598 | validation: 0.6845194406829846]
	TIME [epoch: 9.47 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7516800733132737		[learning rate: 0.0039274]
	Learning Rate: 0.0039274
	LOSS [training: 0.7516800733132737 | validation: 0.4982442308978594]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_243.pth
	Model improved!!!
EPOCH 244/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.485992404061317		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 0.485992404061317 | validation: 0.6165122343282939]
	TIME [epoch: 9.49 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7215658048224547		[learning rate: 0.0038895]
	Learning Rate: 0.00388951
	LOSS [training: 0.7215658048224547 | validation: 1.516674628840118]
	TIME [epoch: 9.47 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.016619414828221		[learning rate: 0.0038707]
	Learning Rate: 0.0038707
	LOSS [training: 1.016619414828221 | validation: 1.1592204486975035]
	TIME [epoch: 9.47 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7318693227071942		[learning rate: 0.003852]
	Learning Rate: 0.00385198
	LOSS [training: 0.7318693227071942 | validation: 1.0949185588906845]
	TIME [epoch: 9.47 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8700469613546749		[learning rate: 0.0038334]
	Learning Rate: 0.00383335
	LOSS [training: 1.8700469613546749 | validation: 1.1940145210972164]
	TIME [epoch: 9.48 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3425579664568463		[learning rate: 0.0038148]
	Learning Rate: 0.00381482
	LOSS [training: 1.3425579664568463 | validation: 1.5548488780964242]
	TIME [epoch: 9.47 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2875459993040157		[learning rate: 0.0037964]
	Learning Rate: 0.00379637
	LOSS [training: 1.2875459993040157 | validation: 0.6849740209730081]
	TIME [epoch: 9.46 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7461208137113031		[learning rate: 0.003778]
	Learning Rate: 0.00377801
	LOSS [training: 0.7461208137113031 | validation: 1.2799177033940377]
	TIME [epoch: 9.49 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.070862035254036		[learning rate: 0.0037597]
	Learning Rate: 0.00375974
	LOSS [training: 1.070862035254036 | validation: 2.5316649476963495]
	TIME [epoch: 9.47 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1270969935158246		[learning rate: 0.0037416]
	Learning Rate: 0.00374156
	LOSS [training: 1.1270969935158246 | validation: 0.8469446031679178]
	TIME [epoch: 9.47 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6428700208627693		[learning rate: 0.0037235]
	Learning Rate: 0.00372347
	LOSS [training: 0.6428700208627693 | validation: 0.8314480738303499]
	TIME [epoch: 9.48 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9780054341454173		[learning rate: 0.0037055]
	Learning Rate: 0.00370546
	LOSS [training: 0.9780054341454173 | validation: 0.6797208623022424]
	TIME [epoch: 9.48 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.599110254585912		[learning rate: 0.0036875]
	Learning Rate: 0.00368754
	LOSS [training: 0.599110254585912 | validation: 0.4626158479456372]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_256.pth
	Model improved!!!
EPOCH 257/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5795360920063611		[learning rate: 0.0036697]
	Learning Rate: 0.00366971
	LOSS [training: 0.5795360920063611 | validation: 0.6739000810068844]
	TIME [epoch: 9.46 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9082435003389691		[learning rate: 0.003652]
	Learning Rate: 0.00365196
	LOSS [training: 0.9082435003389691 | validation: 0.8130955990237524]
	TIME [epoch: 9.49 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6790275104082728		[learning rate: 0.0036343]
	Learning Rate: 0.0036343
	LOSS [training: 0.6790275104082728 | validation: 1.3302178330784233]
	TIME [epoch: 9.47 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6893856725922863		[learning rate: 0.0036167]
	Learning Rate: 0.00361673
	LOSS [training: 0.6893856725922863 | validation: 0.4380054848950224]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_260.pth
	Model improved!!!
EPOCH 261/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.513345949205595		[learning rate: 0.0035992]
	Learning Rate: 0.00359924
	LOSS [training: 0.513345949205595 | validation: 0.7226004754935377]
	TIME [epoch: 9.47 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7860931340587332		[learning rate: 0.0035818]
	Learning Rate: 0.00358183
	LOSS [training: 0.7860931340587332 | validation: 0.4118585019310173]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_262.pth
	Model improved!!!
EPOCH 263/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0843499599299629		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 1.0843499599299629 | validation: 1.8368816300647766]
	TIME [epoch: 9.46 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2519789360413702		[learning rate: 0.0035473]
	Learning Rate: 0.00354727
	LOSS [training: 1.2519789360413702 | validation: 1.3271364654155533]
	TIME [epoch: 9.46 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7334554041349736		[learning rate: 0.0035301]
	Learning Rate: 0.00353012
	LOSS [training: 0.7334554041349736 | validation: 1.0576849149692418]
	TIME [epoch: 9.48 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7360921473696145		[learning rate: 0.003513]
	Learning Rate: 0.00351305
	LOSS [training: 0.7360921473696145 | validation: 1.8565699663017996]
	TIME [epoch: 9.45 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0198013212636368		[learning rate: 0.0034961]
	Learning Rate: 0.00349606
	LOSS [training: 1.0198013212636368 | validation: 0.9289771865127497]
	TIME [epoch: 9.45 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8710136431422043		[learning rate: 0.0034792]
	Learning Rate: 0.00347915
	LOSS [training: 0.8710136431422043 | validation: 2.9687172746746353]
	TIME [epoch: 9.47 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7703310421677982		[learning rate: 0.0034623]
	Learning Rate: 0.00346233
	LOSS [training: 1.7703310421677982 | validation: 0.6742564333067336]
	TIME [epoch: 9.46 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6239636446855943		[learning rate: 0.0034456]
	Learning Rate: 0.00344559
	LOSS [training: 0.6239636446855943 | validation: 0.46157947888824746]
	TIME [epoch: 9.46 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1043225043872433		[learning rate: 0.0034289]
	Learning Rate: 0.00342892
	LOSS [training: 1.1043225043872433 | validation: 1.572520010933032]
	TIME [epoch: 9.45 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.968388422357733		[learning rate: 0.0034123]
	Learning Rate: 0.00341234
	LOSS [training: 0.968388422357733 | validation: 0.9975818506899571]
	TIME [epoch: 9.48 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9973528994282248		[learning rate: 0.0033958]
	Learning Rate: 0.00339584
	LOSS [training: 0.9973528994282248 | validation: 0.91681450429825]
	TIME [epoch: 9.45 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8449130190564624		[learning rate: 0.0033794]
	Learning Rate: 0.00337942
	LOSS [training: 0.8449130190564624 | validation: 0.9949763316798486]
	TIME [epoch: 9.45 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.691216045428712		[learning rate: 0.0033631]
	Learning Rate: 0.00336308
	LOSS [training: 0.691216045428712 | validation: 0.8485644182211931]
	TIME [epoch: 9.47 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6993244414421993		[learning rate: 0.0033468]
	Learning Rate: 0.00334681
	LOSS [training: 0.6993244414421993 | validation: 1.2092268268874171]
	TIME [epoch: 9.47 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7768063932581899		[learning rate: 0.0033306]
	Learning Rate: 0.00333063
	LOSS [training: 0.7768063932581899 | validation: 0.8950903222395621]
	TIME [epoch: 9.45 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9333785040892216		[learning rate: 0.0033145]
	Learning Rate: 0.00331452
	LOSS [training: 0.9333785040892216 | validation: 0.793054372764432]
	TIME [epoch: 9.46 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8529211826552519		[learning rate: 0.0032985]
	Learning Rate: 0.00329849
	LOSS [training: 0.8529211826552519 | validation: 0.6312757749181932]
	TIME [epoch: 9.47 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0434091037551743		[learning rate: 0.0032825]
	Learning Rate: 0.00328254
	LOSS [training: 1.0434091037551743 | validation: 0.8202740445351188]
	TIME [epoch: 9.45 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5647099231024694		[learning rate: 0.0032667]
	Learning Rate: 0.00326667
	LOSS [training: 0.5647099231024694 | validation: 0.9544993160506371]
	TIME [epoch: 9.45 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.684708016088384		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 0.684708016088384 | validation: 0.48364578333869745]
	TIME [epoch: 9.47 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43690646412388967		[learning rate: 0.0032352]
	Learning Rate: 0.00323515
	LOSS [training: 0.43690646412388967 | validation: 1.5035352839628546]
	TIME [epoch: 9.46 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9906662195879032		[learning rate: 0.0032195]
	Learning Rate: 0.00321951
	LOSS [training: 0.9906662195879032 | validation: 1.2333999783815104]
	TIME [epoch: 9.46 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7496864202009441		[learning rate: 0.0032039]
	Learning Rate: 0.00320394
	LOSS [training: 0.7496864202009441 | validation: 0.5378294705564675]
	TIME [epoch: 9.45 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7442323034159677		[learning rate: 0.0031884]
	Learning Rate: 0.00318845
	LOSS [training: 0.7442323034159677 | validation: 0.6276903634686815]
	TIME [epoch: 9.48 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9286033006089756		[learning rate: 0.003173]
	Learning Rate: 0.00317303
	LOSS [training: 0.9286033006089756 | validation: 1.0344701079953342]
	TIME [epoch: 9.45 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6559047993487861		[learning rate: 0.0031577]
	Learning Rate: 0.00315768
	LOSS [training: 0.6559047993487861 | validation: 0.5557880358857716]
	TIME [epoch: 9.45 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6194269184041709		[learning rate: 0.0031424]
	Learning Rate: 0.00314241
	LOSS [training: 0.6194269184041709 | validation: 0.5202408009813495]
	TIME [epoch: 9.47 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6018919059413322		[learning rate: 0.0031272]
	Learning Rate: 0.00312722
	LOSS [training: 0.6018919059413322 | validation: 0.5280983018778386]
	TIME [epoch: 9.48 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9923690042505589		[learning rate: 0.0031121]
	Learning Rate: 0.00311209
	LOSS [training: 0.9923690042505589 | validation: 1.3457685366586716]
	TIME [epoch: 9.45 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9469109689030425		[learning rate: 0.003097]
	Learning Rate: 0.00309704
	LOSS [training: 0.9469109689030425 | validation: 1.2785197593727222]
	TIME [epoch: 9.46 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2726987837628365		[learning rate: 0.0030821]
	Learning Rate: 0.00308207
	LOSS [training: 1.2726987837628365 | validation: 0.6939901140941171]
	TIME [epoch: 9.47 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6490519673077743		[learning rate: 0.0030672]
	Learning Rate: 0.00306716
	LOSS [training: 0.6490519673077743 | validation: 0.7640072957537334]
	TIME [epoch: 9.46 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6279290045161243		[learning rate: 0.0030523]
	Learning Rate: 0.00305233
	LOSS [training: 0.6279290045161243 | validation: 0.5953671676021104]
	TIME [epoch: 9.45 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6079306229514758		[learning rate: 0.0030376]
	Learning Rate: 0.00303757
	LOSS [training: 0.6079306229514758 | validation: 1.1312183639685705]
	TIME [epoch: 9.46 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7498885152912643		[learning rate: 0.0030229]
	Learning Rate: 0.00302288
	LOSS [training: 0.7498885152912643 | validation: 1.0774697953128862]
	TIME [epoch: 9.47 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7707762389213466		[learning rate: 0.0030083]
	Learning Rate: 0.00300826
	LOSS [training: 0.7707762389213466 | validation: 0.7209757551416778]
	TIME [epoch: 9.46 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8099890586065059		[learning rate: 0.0029937]
	Learning Rate: 0.00299372
	LOSS [training: 0.8099890586065059 | validation: 2.004863168891025]
	TIME [epoch: 9.45 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.847689325584741		[learning rate: 0.0029792]
	Learning Rate: 0.00297924
	LOSS [training: 0.847689325584741 | validation: 0.5739129354795967]
	TIME [epoch: 9.48 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8091267054257891		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 0.8091267054257891 | validation: 1.6062564716094534]
	TIME [epoch: 9.45 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7855427410195539		[learning rate: 0.0029505]
	Learning Rate: 0.00295049
	LOSS [training: 0.7855427410195539 | validation: 1.1271253919111357]
	TIME [epoch: 9.45 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6052122723150879		[learning rate: 0.0029362]
	Learning Rate: 0.00293623
	LOSS [training: 0.6052122723150879 | validation: 0.49912712283277594]
	TIME [epoch: 9.46 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.533672138562686		[learning rate: 0.002922]
	Learning Rate: 0.00292203
	LOSS [training: 0.533672138562686 | validation: 0.8474839979359544]
	TIME [epoch: 9.47 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.824748060281303		[learning rate: 0.0029079]
	Learning Rate: 0.0029079
	LOSS [training: 1.824748060281303 | validation: 1.0068898794467147]
	TIME [epoch: 9.45 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1130429056906554		[learning rate: 0.0028938]
	Learning Rate: 0.00289383
	LOSS [training: 1.1130429056906554 | validation: 1.717614129448354]
	TIME [epoch: 9.46 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.690613247790491		[learning rate: 0.0028798]
	Learning Rate: 0.00287984
	LOSS [training: 0.690613247790491 | validation: 0.5630473425444292]
	TIME [epoch: 9.47 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5223748317687993		[learning rate: 0.0028659]
	Learning Rate: 0.00286591
	LOSS [training: 0.5223748317687993 | validation: 0.7642127700787507]
	TIME [epoch: 9.46 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5586966958242129		[learning rate: 0.0028521]
	Learning Rate: 0.00285205
	LOSS [training: 0.5586966958242129 | validation: 0.533335897595488]
	TIME [epoch: 9.45 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4418857746797902		[learning rate: 0.0028383]
	Learning Rate: 0.00283826
	LOSS [training: 0.4418857746797902 | validation: 0.45504910746352734]
	TIME [epoch: 9.46 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49231050137087473		[learning rate: 0.0028245]
	Learning Rate: 0.00282454
	LOSS [training: 0.49231050137087473 | validation: 0.45836279192124935]
	TIME [epoch: 9.47 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5139871758082777		[learning rate: 0.0028109]
	Learning Rate: 0.00281088
	LOSS [training: 0.5139871758082777 | validation: 0.4791097511282071]
	TIME [epoch: 9.45 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5549265915627514		[learning rate: 0.0027973]
	Learning Rate: 0.00279729
	LOSS [training: 0.5549265915627514 | validation: 0.7319436954392654]
	TIME [epoch: 9.45 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48507499420951883		[learning rate: 0.0027838]
	Learning Rate: 0.00278376
	LOSS [training: 0.48507499420951883 | validation: 0.5063500900778751]
	TIME [epoch: 9.48 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6286674542899584		[learning rate: 0.0027703]
	Learning Rate: 0.0027703
	LOSS [training: 0.6286674542899584 | validation: 1.1456411576964862]
	TIME [epoch: 9.46 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9081593638301714		[learning rate: 0.0027569]
	Learning Rate: 0.0027569
	LOSS [training: 0.9081593638301714 | validation: 0.48937860862079674]
	TIME [epoch: 9.46 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5124761396482544		[learning rate: 0.0027436]
	Learning Rate: 0.00274357
	LOSS [training: 0.5124761396482544 | validation: 0.6137880285637745]
	TIME [epoch: 9.46 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8251828900441456		[learning rate: 0.0027303]
	Learning Rate: 0.0027303
	LOSS [training: 0.8251828900441456 | validation: 0.8214441673665541]
	TIME [epoch: 9.47 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8263947558406581		[learning rate: 0.0027171]
	Learning Rate: 0.0027171
	LOSS [training: 0.8263947558406581 | validation: 0.5828814773703065]
	TIME [epoch: 9.45 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6504181008893626		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 0.6504181008893626 | validation: 0.9766575466917077]
	TIME [epoch: 9.45 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.643527113174431		[learning rate: 0.0026909]
	Learning Rate: 0.00269088
	LOSS [training: 0.643527113174431 | validation: 0.5226411501955537]
	TIME [epoch: 9.48 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5429608278076137		[learning rate: 0.0026779]
	Learning Rate: 0.00267787
	LOSS [training: 0.5429608278076137 | validation: 0.4040090368789156]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_322.pth
	Model improved!!!
EPOCH 323/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5129084828286679		[learning rate: 0.0026649]
	Learning Rate: 0.00266492
	LOSS [training: 0.5129084828286679 | validation: 0.4232551145236376]
	TIME [epoch: 9.45 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4207415585937386		[learning rate: 0.002652]
	Learning Rate: 0.00265203
	LOSS [training: 0.4207415585937386 | validation: 0.46883817548279266]
	TIME [epoch: 9.47 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5211882963059445		[learning rate: 0.0026392]
	Learning Rate: 0.00263921
	LOSS [training: 0.5211882963059445 | validation: 0.43139594834876177]
	TIME [epoch: 9.47 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6739208783231639		[learning rate: 0.0026264]
	Learning Rate: 0.00262645
	LOSS [training: 0.6739208783231639 | validation: 0.5253141304900746]
	TIME [epoch: 9.45 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46053468687491667		[learning rate: 0.0026137]
	Learning Rate: 0.00261374
	LOSS [training: 0.46053468687491667 | validation: 0.5589063478651026]
	TIME [epoch: 9.46 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49591618773611135		[learning rate: 0.0026011]
	Learning Rate: 0.00260111
	LOSS [training: 0.49591618773611135 | validation: 0.5052513426830407]
	TIME [epoch: 9.48 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.903834743862593		[learning rate: 0.0025885]
	Learning Rate: 0.00258853
	LOSS [training: 0.903834743862593 | validation: 1.3245913107018754]
	TIME [epoch: 9.46 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0992895389049868		[learning rate: 0.002576]
	Learning Rate: 0.00257601
	LOSS [training: 1.0992895389049868 | validation: 1.0222909229745012]
	TIME [epoch: 9.46 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7910421470938431		[learning rate: 0.0025636]
	Learning Rate: 0.00256355
	LOSS [training: 0.7910421470938431 | validation: 0.9567406283310271]
	TIME [epoch: 9.46 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0386693608778423		[learning rate: 0.0025512]
	Learning Rate: 0.00255115
	LOSS [training: 1.0386693608778423 | validation: 1.3893911341557992]
	TIME [epoch: 9.47 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9957833667637199		[learning rate: 0.0025388]
	Learning Rate: 0.00253882
	LOSS [training: 0.9957833667637199 | validation: 0.7833978331736046]
	TIME [epoch: 9.45 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6858722815779117		[learning rate: 0.0025265]
	Learning Rate: 0.00252654
	LOSS [training: 0.6858722815779117 | validation: 0.8409104808950711]
	TIME [epoch: 9.46 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.49179732304396		[learning rate: 0.0025143]
	Learning Rate: 0.00251432
	LOSS [training: 1.49179732304396 | validation: 1.1084770578925118]
	TIME [epoch: 9.48 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7081668703288482		[learning rate: 0.0025022]
	Learning Rate: 0.00250216
	LOSS [training: 0.7081668703288482 | validation: 1.264841794906905]
	TIME [epoch: 9.46 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7777547077396918		[learning rate: 0.0024901]
	Learning Rate: 0.00249006
	LOSS [training: 0.7777547077396918 | validation: 0.6718607170523806]
	TIME [epoch: 9.45 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5645031902248902		[learning rate: 0.002478]
	Learning Rate: 0.00247802
	LOSS [training: 0.5645031902248902 | validation: 0.48529846576262503]
	TIME [epoch: 9.47 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4930692249803382		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 0.4930692249803382 | validation: 0.5260741934623817]
	TIME [epoch: 9.47 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4099128884911156		[learning rate: 0.0024541]
	Learning Rate: 0.00245411
	LOSS [training: 0.4099128884911156 | validation: 0.5150610152880848]
	TIME [epoch: 9.46 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43557885557069387		[learning rate: 0.0024422]
	Learning Rate: 0.00244225
	LOSS [training: 0.43557885557069387 | validation: 0.4584213497020771]
	TIME [epoch: 9.45 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7072192502227809		[learning rate: 0.0024304]
	Learning Rate: 0.00243044
	LOSS [training: 0.7072192502227809 | validation: 0.8830795246907337]
	TIME [epoch: 9.48 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6539518374393976		[learning rate: 0.0024187]
	Learning Rate: 0.00241868
	LOSS [training: 0.6539518374393976 | validation: 0.6583858682347009]
	TIME [epoch: 9.45 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5078977697622002		[learning rate: 0.002407]
	Learning Rate: 0.00240699
	LOSS [training: 0.5078977697622002 | validation: 0.43933927410664925]
	TIME [epoch: 9.45 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39373393515785693		[learning rate: 0.0023953]
	Learning Rate: 0.00239535
	LOSS [training: 0.39373393515785693 | validation: 0.4745019609526298]
	TIME [epoch: 9.45 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44819290900658126		[learning rate: 0.0023838]
	Learning Rate: 0.00238376
	LOSS [training: 0.44819290900658126 | validation: 0.6295337646435878]
	TIME [epoch: 9.48 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5113230922461589		[learning rate: 0.0023722]
	Learning Rate: 0.00237224
	LOSS [training: 0.5113230922461589 | validation: 0.5641570638004411]
	TIME [epoch: 9.45 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6038662814462904		[learning rate: 0.0023608]
	Learning Rate: 0.00236076
	LOSS [training: 0.6038662814462904 | validation: 0.8858187664364396]
	TIME [epoch: 9.45 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0846450530405858		[learning rate: 0.0023493]
	Learning Rate: 0.00234935
	LOSS [training: 1.0846450530405858 | validation: 0.8876182460163947]
	TIME [epoch: 9.48 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6117676442348542		[learning rate: 0.002338]
	Learning Rate: 0.00233799
	LOSS [training: 0.6117676442348542 | validation: 0.513430427772971]
	TIME [epoch: 9.46 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4166552056918422		[learning rate: 0.0023267]
	Learning Rate: 0.00232668
	LOSS [training: 0.4166552056918422 | validation: 0.6195027609820523]
	TIME [epoch: 9.46 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4642174736322657		[learning rate: 0.0023154]
	Learning Rate: 0.00231543
	LOSS [training: 0.4642174736322657 | validation: 0.5742515830437799]
	TIME [epoch: 9.47 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0064863177535393		[learning rate: 0.0023042]
	Learning Rate: 0.00230423
	LOSS [training: 1.0064863177535393 | validation: 1.0955930362469437]
	TIME [epoch: 9.47 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6656835615706412		[learning rate: 0.0022931]
	Learning Rate: 0.00229309
	LOSS [training: 0.6656835615706412 | validation: 0.6842335800555642]
	TIME [epoch: 9.45 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6926916540598933		[learning rate: 0.002282]
	Learning Rate: 0.002282
	LOSS [training: 0.6926916540598933 | validation: 0.9388036986997017]
	TIME [epoch: 9.46 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5755930760759831		[learning rate: 0.002271]
	Learning Rate: 0.00227097
	LOSS [training: 0.5755930760759831 | validation: 0.6855680524740484]
	TIME [epoch: 9.48 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3469891177645044		[learning rate: 0.00226]
	Learning Rate: 0.00225998
	LOSS [training: 1.3469891177645044 | validation: 1.2417232627554229]
	TIME [epoch: 9.45 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7206286182863365		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 0.7206286182863365 | validation: 0.47894970963026795]
	TIME [epoch: 9.45 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4766804011162168		[learning rate: 0.0022382]
	Learning Rate: 0.00223818
	LOSS [training: 0.4766804011162168 | validation: 0.6239053260832514]
	TIME [epoch: 9.46 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5052405332650352		[learning rate: 0.0022274]
	Learning Rate: 0.00222736
	LOSS [training: 0.5052405332650352 | validation: 0.6226973796743976]
	TIME [epoch: 9.47 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5999624917481322		[learning rate: 0.0022166]
	Learning Rate: 0.00221658
	LOSS [training: 0.5999624917481322 | validation: 0.9446285454018755]
	TIME [epoch: 9.45 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6556064166804703		[learning rate: 0.0022059]
	Learning Rate: 0.00220586
	LOSS [training: 0.6556064166804703 | validation: 1.0555608155025473]
	TIME [epoch: 9.45 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9594353935352758		[learning rate: 0.0021952]
	Learning Rate: 0.0021952
	LOSS [training: 0.9594353935352758 | validation: 0.6968458188818147]
	TIME [epoch: 9.47 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6910348614784988		[learning rate: 0.0021846]
	Learning Rate: 0.00218458
	LOSS [training: 0.6910348614784988 | validation: 1.006080599091996]
	TIME [epoch: 9.45 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6923123282824734		[learning rate: 0.002174]
	Learning Rate: 0.00217402
	LOSS [training: 0.6923123282824734 | validation: 0.5396744459932731]
	TIME [epoch: 9.47 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49506277198029647		[learning rate: 0.0021635]
	Learning Rate: 0.0021635
	LOSS [training: 0.49506277198029647 | validation: 0.5004605464563207]
	TIME [epoch: 9.46 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5034419853239946		[learning rate: 0.002153]
	Learning Rate: 0.00215304
	LOSS [training: 0.5034419853239946 | validation: 0.7430391500341377]
	TIME [epoch: 9.47 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6306659172198001		[learning rate: 0.0021426]
	Learning Rate: 0.00214263
	LOSS [training: 0.6306659172198001 | validation: 0.5286740240584727]
	TIME [epoch: 9.46 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5588534123543798		[learning rate: 0.0021323]
	Learning Rate: 0.00213227
	LOSS [training: 0.5588534123543798 | validation: 0.5401470108855467]
	TIME [epoch: 9.45 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6053194854457489		[learning rate: 0.002122]
	Learning Rate: 0.00212196
	LOSS [training: 0.6053194854457489 | validation: 0.5662311940269452]
	TIME [epoch: 9.47 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6093085122408952		[learning rate: 0.0021117]
	Learning Rate: 0.0021117
	LOSS [training: 0.6093085122408952 | validation: 1.1396278897281973]
	TIME [epoch: 9.45 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6312846493172481		[learning rate: 0.0021015]
	Learning Rate: 0.00210149
	LOSS [training: 0.6312846493172481 | validation: 0.6730229801397237]
	TIME [epoch: 9.45 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5174344011141635		[learning rate: 0.0020913]
	Learning Rate: 0.00209132
	LOSS [training: 0.5174344011141635 | validation: 0.8282708608996299]
	TIME [epoch: 9.46 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6507002731051472		[learning rate: 0.0020812]
	Learning Rate: 0.00208121
	LOSS [training: 0.6507002731051472 | validation: 1.2552314706900563]
	TIME [epoch: 9.47 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4984422336014191		[learning rate: 0.0020711]
	Learning Rate: 0.00207115
	LOSS [training: 0.4984422336014191 | validation: 0.5785683173873465]
	TIME [epoch: 9.46 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6708730481570638		[learning rate: 0.0020611]
	Learning Rate: 0.00206113
	LOSS [training: 0.6708730481570638 | validation: 0.7159621955243608]
	TIME [epoch: 9.45 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4465865301256115		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 0.4465865301256115 | validation: 0.4293871007654934]
	TIME [epoch: 9.47 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44578981855847166		[learning rate: 0.0020412]
	Learning Rate: 0.00204124
	LOSS [training: 0.44578981855847166 | validation: 0.9173243929051182]
	TIME [epoch: 9.46 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.551656366434476		[learning rate: 0.0020314]
	Learning Rate: 0.00203137
	LOSS [training: 0.551656366434476 | validation: 0.9735373157594337]
	TIME [epoch: 9.46 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6180052269828914		[learning rate: 0.0020215]
	Learning Rate: 0.00202155
	LOSS [training: 0.6180052269828914 | validation: 0.6282795120721911]
	TIME [epoch: 9.46 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44595099480708156		[learning rate: 0.0020118]
	Learning Rate: 0.00201177
	LOSS [training: 0.44595099480708156 | validation: 0.44911563891793066]
	TIME [epoch: 9.49 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5473139277433561		[learning rate: 0.002002]
	Learning Rate: 0.00200204
	LOSS [training: 0.5473139277433561 | validation: 0.5291436257781023]
	TIME [epoch: 9.46 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42994473496658114		[learning rate: 0.0019924]
	Learning Rate: 0.00199236
	LOSS [training: 0.42994473496658114 | validation: 0.4242726342461518]
	TIME [epoch: 9.46 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5464194626969121		[learning rate: 0.0019827]
	Learning Rate: 0.00198273
	LOSS [training: 0.5464194626969121 | validation: 0.6405556992526467]
	TIME [epoch: 9.48 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5108497349520881		[learning rate: 0.0019731]
	Learning Rate: 0.00197314
	LOSS [training: 0.5108497349520881 | validation: 0.4218253965490933]
	TIME [epoch: 9.46 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3812111219829669		[learning rate: 0.0019636]
	Learning Rate: 0.0019636
	LOSS [training: 0.3812111219829669 | validation: 0.7324415333936182]
	TIME [epoch: 9.47 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5023058090278629		[learning rate: 0.0019541]
	Learning Rate: 0.0019541
	LOSS [training: 0.5023058090278629 | validation: 1.2294811209719156]
	TIME [epoch: 9.46 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2949994287316895		[learning rate: 0.0019447]
	Learning Rate: 0.00194465
	LOSS [training: 1.2949994287316895 | validation: 1.1404382766493384]
	TIME [epoch: 9.48 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8089381732455605		[learning rate: 0.0019352]
	Learning Rate: 0.00193525
	LOSS [training: 0.8089381732455605 | validation: 0.7463090452672977]
	TIME [epoch: 9.46 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5578349936072309		[learning rate: 0.0019259]
	Learning Rate: 0.00192589
	LOSS [training: 0.5578349936072309 | validation: 0.491483733811809]
	TIME [epoch: 9.46 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5768264760920253		[learning rate: 0.0019166]
	Learning Rate: 0.00191658
	LOSS [training: 0.5768264760920253 | validation: 0.49643264906409496]
	TIME [epoch: 9.48 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40742175012171417		[learning rate: 0.0019073]
	Learning Rate: 0.00190731
	LOSS [training: 0.40742175012171417 | validation: 0.37957327941446467]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_392.pth
	Model improved!!!
EPOCH 393/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3766147242419528		[learning rate: 0.0018981]
	Learning Rate: 0.00189809
	LOSS [training: 0.3766147242419528 | validation: 0.6206032586809361]
	TIME [epoch: 9.45 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4224709172856091		[learning rate: 0.0018889]
	Learning Rate: 0.00188891
	LOSS [training: 0.4224709172856091 | validation: 0.4477700602532561]
	TIME [epoch: 9.47 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4427860725132361		[learning rate: 0.0018798]
	Learning Rate: 0.00187977
	LOSS [training: 0.4427860725132361 | validation: 0.5327515075376134]
	TIME [epoch: 9.47 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4484046983920117		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 0.4484046983920117 | validation: 0.5567311412689335]
	TIME [epoch: 9.44 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4991582302499557		[learning rate: 0.0018616]
	Learning Rate: 0.00186164
	LOSS [training: 0.4991582302499557 | validation: 0.3866199918518883]
	TIME [epoch: 9.45 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3765878180726684		[learning rate: 0.0018526]
	Learning Rate: 0.00185263
	LOSS [training: 0.3765878180726684 | validation: 0.4516012856088553]
	TIME [epoch: 9.47 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39191248912988824		[learning rate: 0.0018437]
	Learning Rate: 0.00184367
	LOSS [training: 0.39191248912988824 | validation: 1.261575026615356]
	TIME [epoch: 9.44 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5529430931411645		[learning rate: 0.0018348]
	Learning Rate: 0.00183476
	LOSS [training: 0.5529430931411645 | validation: 0.4364496149235379]
	TIME [epoch: 9.45 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4439033767685281		[learning rate: 0.0018259]
	Learning Rate: 0.00182589
	LOSS [training: 0.4439033767685281 | validation: 0.38570527354442447]
	TIME [epoch: 9.46 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4966096286037425		[learning rate: 0.0018171]
	Learning Rate: 0.00181706
	LOSS [training: 0.4966096286037425 | validation: 0.728281609719517]
	TIME [epoch: 9.47 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5010696569943712		[learning rate: 0.0018083]
	Learning Rate: 0.00180827
	LOSS [training: 0.5010696569943712 | validation: 0.5372244412290115]
	TIME [epoch: 9.45 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40359888757903584		[learning rate: 0.0017995]
	Learning Rate: 0.00179952
	LOSS [training: 0.40359888757903584 | validation: 0.4571273166947302]
	TIME [epoch: 9.45 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4312302707362531		[learning rate: 0.0017908]
	Learning Rate: 0.00179082
	LOSS [training: 0.4312302707362531 | validation: 0.5077930871763902]
	TIME [epoch: 9.47 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5137253761817419		[learning rate: 0.0017822]
	Learning Rate: 0.00178216
	LOSS [training: 0.5137253761817419 | validation: 0.39470112010941194]
	TIME [epoch: 9.45 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4234833468597416		[learning rate: 0.0017735]
	Learning Rate: 0.00177354
	LOSS [training: 0.4234833468597416 | validation: 0.5836567598076146]
	TIME [epoch: 9.45 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37115153320094996		[learning rate: 0.001765]
	Learning Rate: 0.00176497
	LOSS [training: 0.37115153320094996 | validation: 0.48150434327534003]
	TIME [epoch: 9.45 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4308133615272802		[learning rate: 0.0017564]
	Learning Rate: 0.00175643
	LOSS [training: 0.4308133615272802 | validation: 0.5260968892547008]
	TIME [epoch: 9.46 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.367675851927672		[learning rate: 0.0017479]
	Learning Rate: 0.00174794
	LOSS [training: 0.367675851927672 | validation: 0.8294161244568641]
	TIME [epoch: 9.45 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5204017336973743		[learning rate: 0.0017395]
	Learning Rate: 0.00173949
	LOSS [training: 0.5204017336973743 | validation: 0.4370287762986139]
	TIME [epoch: 9.44 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6330985509070175		[learning rate: 0.0017311]
	Learning Rate: 0.00173107
	LOSS [training: 0.6330985509070175 | validation: 1.4034677031862877]
	TIME [epoch: 9.47 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.583993786765444		[learning rate: 0.0017227]
	Learning Rate: 0.0017227
	LOSS [training: 0.583993786765444 | validation: 0.6007699270080568]
	TIME [epoch: 9.45 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4855216062831361		[learning rate: 0.0017144]
	Learning Rate: 0.00171437
	LOSS [training: 0.4855216062831361 | validation: 0.46961609150038763]
	TIME [epoch: 9.45 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48523810018167224		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 0.48523810018167224 | validation: 0.4018066598951376]
	TIME [epoch: 9.45 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44029571158366193		[learning rate: 0.0016978]
	Learning Rate: 0.00169783
	LOSS [training: 0.44029571158366193 | validation: 0.7015008666309563]
	TIME [epoch: 9.46 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48094697123038366		[learning rate: 0.0016896]
	Learning Rate: 0.00168962
	LOSS [training: 0.48094697123038366 | validation: 0.5145355312639327]
	TIME [epoch: 9.44 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36817902523729423		[learning rate: 0.0016815]
	Learning Rate: 0.00168145
	LOSS [training: 0.36817902523729423 | validation: 0.3625431632054672]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_418.pth
	Model improved!!!
EPOCH 419/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33750355648998437		[learning rate: 0.0016733]
	Learning Rate: 0.00167332
	LOSS [training: 0.33750355648998437 | validation: 0.41125977292993116]
	TIME [epoch: 9.47 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3736119164093397		[learning rate: 0.0016652]
	Learning Rate: 0.00166523
	LOSS [training: 0.3736119164093397 | validation: 0.5121821111525441]
	TIME [epoch: 9.45 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42546607043150936		[learning rate: 0.0016572]
	Learning Rate: 0.00165718
	LOSS [training: 0.42546607043150936 | validation: 0.6065815284076052]
	TIME [epoch: 9.44 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7035484803069516		[learning rate: 0.0016492]
	Learning Rate: 0.00164916
	LOSS [training: 0.7035484803069516 | validation: 1.251941821689964]
	TIME [epoch: 9.46 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6421786001394162		[learning rate: 0.0016412]
	Learning Rate: 0.00164119
	LOSS [training: 0.6421786001394162 | validation: 0.8210399160377887]
	TIME [epoch: 9.46 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7675371931825671		[learning rate: 0.0016332]
	Learning Rate: 0.00163325
	LOSS [training: 0.7675371931825671 | validation: 0.7200744013695897]
	TIME [epoch: 9.45 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6432710421528195		[learning rate: 0.0016254]
	Learning Rate: 0.00162535
	LOSS [training: 0.6432710421528195 | validation: 0.5714747984174009]
	TIME [epoch: 9.45 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46735228483452085		[learning rate: 0.0016175]
	Learning Rate: 0.00161749
	LOSS [training: 0.46735228483452085 | validation: 0.4837518930570422]
	TIME [epoch: 9.48 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4863130686563437		[learning rate: 0.0016097]
	Learning Rate: 0.00160967
	LOSS [training: 0.4863130686563437 | validation: 0.5102448973319522]
	TIME [epoch: 9.45 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.517765905629505		[learning rate: 0.0016019]
	Learning Rate: 0.00160189
	LOSS [training: 0.517765905629505 | validation: 0.49505171065798953]
	TIME [epoch: 9.44 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6766977898535387		[learning rate: 0.0015941]
	Learning Rate: 0.00159414
	LOSS [training: 0.6766977898535387 | validation: 0.7452023830041021]
	TIME [epoch: 9.46 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6351874235236148		[learning rate: 0.0015864]
	Learning Rate: 0.00158643
	LOSS [training: 0.6351874235236148 | validation: 0.810072334534884]
	TIME [epoch: 9.47 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6737107236219663		[learning rate: 0.0015788]
	Learning Rate: 0.00157876
	LOSS [training: 0.6737107236219663 | validation: 0.5815406344758788]
	TIME [epoch: 9.45 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41366834315050116		[learning rate: 0.0015711]
	Learning Rate: 0.00157112
	LOSS [training: 0.41366834315050116 | validation: 0.49841183226482616]
	TIME [epoch: 9.45 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37024690764179624		[learning rate: 0.0015635]
	Learning Rate: 0.00156353
	LOSS [training: 0.37024690764179624 | validation: 0.3849801268658209]
	TIME [epoch: 9.47 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3502793883662977		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 0.3502793883662977 | validation: 0.5521065206820548]
	TIME [epoch: 9.45 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6355332878347412		[learning rate: 0.0015484]
	Learning Rate: 0.00154844
	LOSS [training: 0.6355332878347412 | validation: 0.5621672754846314]
	TIME [epoch: 9.45 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4395730177289061		[learning rate: 0.001541]
	Learning Rate: 0.00154095
	LOSS [training: 0.4395730177289061 | validation: 1.265860196496957]
	TIME [epoch: 9.46 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5577883742273307		[learning rate: 0.0015335]
	Learning Rate: 0.0015335
	LOSS [training: 0.5577883742273307 | validation: 0.43003328052730994]
	TIME [epoch: 9.47 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42180741000395894		[learning rate: 0.0015261]
	Learning Rate: 0.00152609
	LOSS [training: 0.42180741000395894 | validation: 0.5182846210326575]
	TIME [epoch: 9.45 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40267527461692587		[learning rate: 0.0015187]
	Learning Rate: 0.00151871
	LOSS [training: 0.40267527461692587 | validation: 0.47869629734795427]
	TIME [epoch: 9.45 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3562437033155749		[learning rate: 0.0015114]
	Learning Rate: 0.00151136
	LOSS [training: 0.3562437033155749 | validation: 0.42421223237509154]
	TIME [epoch: 9.48 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33109176424315445		[learning rate: 0.0015041]
	Learning Rate: 0.00150405
	LOSS [training: 0.33109176424315445 | validation: 0.40304189256284584]
	TIME [epoch: 9.46 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43692267216926506		[learning rate: 0.0014968]
	Learning Rate: 0.00149678
	LOSS [training: 0.43692267216926506 | validation: 0.4429666698827619]
	TIME [epoch: 9.44 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3405287730850953		[learning rate: 0.0014895]
	Learning Rate: 0.00148954
	LOSS [training: 0.3405287730850953 | validation: 0.4630935185808607]
	TIME [epoch: 9.46 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3588361186676388		[learning rate: 0.0014823]
	Learning Rate: 0.00148234
	LOSS [training: 0.3588361186676388 | validation: 0.46529378347634553]
	TIME [epoch: 9.47 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42007586487779125		[learning rate: 0.0014752]
	Learning Rate: 0.00147517
	LOSS [training: 0.42007586487779125 | validation: 0.6239801226511706]
	TIME [epoch: 9.45 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6532811808146625		[learning rate: 0.001468]
	Learning Rate: 0.00146804
	LOSS [training: 0.6532811808146625 | validation: 0.9073322912616445]
	TIME [epoch: 9.45 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5919046651303872		[learning rate: 0.0014609]
	Learning Rate: 0.00146094
	LOSS [training: 0.5919046651303872 | validation: 0.5917602593840409]
	TIME [epoch: 9.47 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39686744105143945		[learning rate: 0.0014539]
	Learning Rate: 0.00145387
	LOSS [training: 0.39686744105143945 | validation: 0.8346839466937584]
	TIME [epoch: 9.45 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8147995279146076		[learning rate: 0.0014468]
	Learning Rate: 0.00144684
	LOSS [training: 0.8147995279146076 | validation: 0.34495696782909635]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_449.pth
	Model improved!!!
EPOCH 450/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49828277048976233		[learning rate: 0.0014398]
	Learning Rate: 0.00143985
	LOSS [training: 0.49828277048976233 | validation: 0.5464514771124879]
	TIME [epoch: 9.46 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4529280575068547		[learning rate: 0.0014329]
	Learning Rate: 0.00143288
	LOSS [training: 0.4529280575068547 | validation: 0.5208788080979533]
	TIME [epoch: 9.47 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35072637542443275		[learning rate: 0.001426]
	Learning Rate: 0.00142595
	LOSS [training: 0.35072637542443275 | validation: 0.5551497109258591]
	TIME [epoch: 9.44 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3320953773059216		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.3320953773059216 | validation: 0.4244628147731918]
	TIME [epoch: 9.45 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3846545990873068		[learning rate: 0.0014122]
	Learning Rate: 0.0014122
	LOSS [training: 0.3846545990873068 | validation: 0.49162040161952975]
	TIME [epoch: 9.47 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43609648301499593		[learning rate: 0.0014054]
	Learning Rate: 0.00140537
	LOSS [training: 0.43609648301499593 | validation: 0.5724681367948572]
	TIME [epoch: 9.46 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4082623872650089		[learning rate: 0.0013986]
	Learning Rate: 0.00139857
	LOSS [training: 0.4082623872650089 | validation: 0.4023312780027303]
	TIME [epoch: 9.44 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3030088509663714		[learning rate: 0.0013918]
	Learning Rate: 0.00139181
	LOSS [training: 0.3030088509663714 | validation: 0.3670370763102564]
	TIME [epoch: 9.46 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31035263535232355		[learning rate: 0.0013851]
	Learning Rate: 0.00138508
	LOSS [training: 0.31035263535232355 | validation: 0.4370182391665387]
	TIME [epoch: 9.47 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3523106116892135		[learning rate: 0.0013784]
	Learning Rate: 0.00137838
	LOSS [training: 0.3523106116892135 | validation: 0.3647628343667357]
	TIME [epoch: 9.44 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.727804455634681		[learning rate: 0.0013717]
	Learning Rate: 0.00137171
	LOSS [training: 0.727804455634681 | validation: 2.087924873510865]
	TIME [epoch: 9.44 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2296582795968816		[learning rate: 0.0013651]
	Learning Rate: 0.00136508
	LOSS [training: 1.2296582795968816 | validation: 0.7831751972729291]
	TIME [epoch: 9.47 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5553861077761674		[learning rate: 0.0013585]
	Learning Rate: 0.00135848
	LOSS [training: 0.5553861077761674 | validation: 0.47088189399665]
	TIME [epoch: 9.44 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41604652342262993		[learning rate: 0.0013519]
	Learning Rate: 0.00135191
	LOSS [training: 0.41604652342262993 | validation: 0.5709022167317701]
	TIME [epoch: 9.45 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6205633882336244		[learning rate: 0.0013454]
	Learning Rate: 0.00134537
	LOSS [training: 0.6205633882336244 | validation: 0.5219942640957322]
	TIME [epoch: 9.45 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37916613462141574		[learning rate: 0.0013389]
	Learning Rate: 0.00133887
	LOSS [training: 0.37916613462141574 | validation: 0.3768167507000182]
	TIME [epoch: 9.46 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4002685595430119		[learning rate: 0.0013324]
	Learning Rate: 0.00133239
	LOSS [training: 0.4002685595430119 | validation: 0.4921024529776506]
	TIME [epoch: 9.45 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3347012820598934		[learning rate: 0.0013259]
	Learning Rate: 0.00132595
	LOSS [training: 0.3347012820598934 | validation: 0.5475548046448911]
	TIME [epoch: 9.44 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3774195004202912		[learning rate: 0.0013195]
	Learning Rate: 0.00131954
	LOSS [training: 0.3774195004202912 | validation: 0.5078819740250752]
	TIME [epoch: 9.47 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43647480905864305		[learning rate: 0.0013132]
	Learning Rate: 0.00131315
	LOSS [training: 0.43647480905864305 | validation: 0.4786436389625166]
	TIME [epoch: 9.45 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4007660626428155		[learning rate: 0.0013068]
	Learning Rate: 0.0013068
	LOSS [training: 0.4007660626428155 | validation: 0.40749998165769924]
	TIME [epoch: 9.45 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3369614770481958		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.3369614770481958 | validation: 0.5180654502665056]
	TIME [epoch: 9.46 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.463508458118305		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 0.463508458118305 | validation: 0.4556224649433662]
	TIME [epoch: 9.46 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3167975708763414		[learning rate: 0.0012879]
	Learning Rate: 0.00128794
	LOSS [training: 0.3167975708763414 | validation: 0.40931537797947515]
	TIME [epoch: 9.44 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39822597021654216		[learning rate: 0.0012817]
	Learning Rate: 0.00128171
	LOSS [training: 0.39822597021654216 | validation: 0.6176271106848445]
	TIME [epoch: 9.44 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38269588991045217		[learning rate: 0.0012755]
	Learning Rate: 0.00127551
	LOSS [training: 0.38269588991045217 | validation: 0.46974122778538907]
	TIME [epoch: 9.47 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34688608662445725		[learning rate: 0.0012693]
	Learning Rate: 0.00126934
	LOSS [training: 0.34688608662445725 | validation: 0.45743061683414915]
	TIME [epoch: 9.45 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4598678643830347		[learning rate: 0.0012632]
	Learning Rate: 0.0012632
	LOSS [training: 0.4598678643830347 | validation: 0.7139460307730738]
	TIME [epoch: 9.45 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5647404675804032		[learning rate: 0.0012571]
	Learning Rate: 0.0012571
	LOSS [training: 0.5647404675804032 | validation: 0.5540053374291835]
	TIME [epoch: 9.46 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3503550453756529		[learning rate: 0.001251]
	Learning Rate: 0.00125102
	LOSS [training: 0.3503550453756529 | validation: 0.4270243313116726]
	TIME [epoch: 9.47 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33905540879902424		[learning rate: 0.001245]
	Learning Rate: 0.00124497
	LOSS [training: 0.33905540879902424 | validation: 0.38323580194256257]
	TIME [epoch: 9.44 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3109325310065821		[learning rate: 0.0012389]
	Learning Rate: 0.00123895
	LOSS [training: 0.3109325310065821 | validation: 0.45870748482224555]
	TIME [epoch: 9.45 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3697985005771491		[learning rate: 0.001233]
	Learning Rate: 0.00123296
	LOSS [training: 0.3697985005771491 | validation: 0.3413723403203735]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_482.pth
	Model improved!!!
EPOCH 483/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3076991158153014		[learning rate: 0.001227]
	Learning Rate: 0.00122699
	LOSS [training: 0.3076991158153014 | validation: 0.28779476696205203]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_483.pth
	Model improved!!!
EPOCH 484/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3609717569740868		[learning rate: 0.0012211]
	Learning Rate: 0.00122106
	LOSS [training: 0.3609717569740868 | validation: 0.7740591998387933]
	TIME [epoch: 9.45 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7063386530886224		[learning rate: 0.0012152]
	Learning Rate: 0.00121515
	LOSS [training: 0.7063386530886224 | validation: 0.7413637298861504]
	TIME [epoch: 9.45 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5629418343983216		[learning rate: 0.0012093]
	Learning Rate: 0.00120928
	LOSS [training: 0.5629418343983216 | validation: 0.3968242091463013]
	TIME [epoch: 9.47 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3188079002193984		[learning rate: 0.0012034]
	Learning Rate: 0.00120343
	LOSS [training: 0.3188079002193984 | validation: 0.47333269986229903]
	TIME [epoch: 9.45 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6273363690144335		[learning rate: 0.0011976]
	Learning Rate: 0.00119761
	LOSS [training: 0.6273363690144335 | validation: 0.5374545069075564]
	TIME [epoch: 9.45 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5378282120976903		[learning rate: 0.0011918]
	Learning Rate: 0.00119182
	LOSS [training: 0.5378282120976903 | validation: 0.5703348559117629]
	TIME [epoch: 9.48 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4646734003318043		[learning rate: 0.0011861]
	Learning Rate: 0.00118606
	LOSS [training: 0.4646734003318043 | validation: 0.5848084298350974]
	TIME [epoch: 9.45 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5028611544495238		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.5028611544495238 | validation: 0.5810675866886815]
	TIME [epoch: 9.45 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3878487352870619		[learning rate: 0.0011746]
	Learning Rate: 0.00117461
	LOSS [training: 0.3878487352870619 | validation: 0.5307562918043253]
	TIME [epoch: 9.46 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4194228442939171		[learning rate: 0.0011689]
	Learning Rate: 0.00116893
	LOSS [training: 0.4194228442939171 | validation: 0.8928672529448435]
	TIME [epoch: 9.47 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38601115448451273		[learning rate: 0.0011633]
	Learning Rate: 0.00116328
	LOSS [training: 0.38601115448451273 | validation: 0.37082876257149167]
	TIME [epoch: 9.46 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48079186601200624		[learning rate: 0.0011577]
	Learning Rate: 0.00115765
	LOSS [training: 0.48079186601200624 | validation: 0.7911882887496324]
	TIME [epoch: 9.45 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4201751093036975		[learning rate: 0.0011521]
	Learning Rate: 0.00115206
	LOSS [training: 0.4201751093036975 | validation: 0.4851256423549051]
	TIME [epoch: 9.47 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4134388864975954		[learning rate: 0.0011465]
	Learning Rate: 0.00114648
	LOSS [training: 0.4134388864975954 | validation: 0.36518461459956664]
	TIME [epoch: 9.45 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31126537045608715		[learning rate: 0.0011409]
	Learning Rate: 0.00114094
	LOSS [training: 0.31126537045608715 | validation: 0.4659918386969665]
	TIME [epoch: 9.45 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33885266919921053		[learning rate: 0.0011354]
	Learning Rate: 0.00113542
	LOSS [training: 0.33885266919921053 | validation: 0.3138083761927329]
	TIME [epoch: 9.45 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37498533449417504		[learning rate: 0.0011299]
	Learning Rate: 0.00112993
	LOSS [training: 0.37498533449417504 | validation: 0.3102595741028779]
	TIME [epoch: 9.47 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44171165504374016		[learning rate: 0.0011245]
	Learning Rate: 0.00112447
	LOSS [training: 0.44171165504374016 | validation: 0.5049955907302087]
	TIME [epoch: 9.45 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4077611684227639		[learning rate: 0.001119]
	Learning Rate: 0.00111903
	LOSS [training: 0.4077611684227639 | validation: 0.4064395012276779]
	TIME [epoch: 9.46 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43727258051891854		[learning rate: 0.0011136]
	Learning Rate: 0.00111362
	LOSS [training: 0.43727258051891854 | validation: 1.0529327851940449]
	TIME [epoch: 9.47 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4251072341469578		[learning rate: 0.0011082]
	Learning Rate: 0.00110823
	LOSS [training: 0.4251072341469578 | validation: 0.4330099334800956]
	TIME [epoch: 9.45 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37270574661539646		[learning rate: 0.0011029]
	Learning Rate: 0.00110287
	LOSS [training: 0.37270574661539646 | validation: 0.5236818445509821]
	TIME [epoch: 9.46 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37215606106543564		[learning rate: 0.0010975]
	Learning Rate: 0.00109754
	LOSS [training: 0.37215606106543564 | validation: 0.3749898176916159]
	TIME [epoch: 9.46 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31689324294470056		[learning rate: 0.0010922]
	Learning Rate: 0.00109223
	LOSS [training: 0.31689324294470056 | validation: 0.43091332216325856]
	TIME [epoch: 9.47 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2922940236557342		[learning rate: 0.001087]
	Learning Rate: 0.00108695
	LOSS [training: 0.2922940236557342 | validation: 0.3965307234655328]
	TIME [epoch: 9.46 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4058310191438603		[learning rate: 0.0010817]
	Learning Rate: 0.0010817
	LOSS [training: 0.4058310191438603 | validation: 0.4239435021247141]
	TIME [epoch: 9.45 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.341995441019018		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.341995441019018 | validation: 0.3318955328435568]
	TIME [epoch: 9.47 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37868577458026587		[learning rate: 0.0010713]
	Learning Rate: 0.00107126
	LOSS [training: 0.37868577458026587 | validation: 0.5762235292481876]
	TIME [epoch: 9.46 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4647578588169085		[learning rate: 0.0010661]
	Learning Rate: 0.00106608
	LOSS [training: 0.4647578588169085 | validation: 0.5032706068873811]
	TIME [epoch: 9.45 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39912779688204125		[learning rate: 0.0010609]
	Learning Rate: 0.00106092
	LOSS [training: 0.39912779688204125 | validation: 0.5386925824828238]
	TIME [epoch: 9.46 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42389355745972096		[learning rate: 0.0010558]
	Learning Rate: 0.00105579
	LOSS [training: 0.42389355745972096 | validation: 0.4483518258828117]
	TIME [epoch: 9.47 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.364642642052044		[learning rate: 0.0010507]
	Learning Rate: 0.00105069
	LOSS [training: 0.364642642052044 | validation: 0.4470939050525826]
	TIME [epoch: 9.45 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3689720842135957		[learning rate: 0.0010456]
	Learning Rate: 0.00104561
	LOSS [training: 0.3689720842135957 | validation: 0.4525013851385401]
	TIME [epoch: 9.46 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3593532357104726		[learning rate: 0.0010406]
	Learning Rate: 0.00104055
	LOSS [training: 0.3593532357104726 | validation: 0.5887683068171867]
	TIME [epoch: 9.48 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7044780839096045		[learning rate: 0.0010355]
	Learning Rate: 0.00103552
	LOSS [training: 0.7044780839096045 | validation: 0.9246428185287997]
	TIME [epoch: 9.46 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4754686649821055		[learning rate: 0.0010305]
	Learning Rate: 0.00103051
	LOSS [training: 0.4754686649821055 | validation: 0.5125686750143182]
	TIME [epoch: 9.45 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3714170631059382		[learning rate: 0.0010255]
	Learning Rate: 0.00102553
	LOSS [training: 0.3714170631059382 | validation: 0.7916166061825564]
	TIME [epoch: 9.46 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43662363251483144		[learning rate: 0.0010206]
	Learning Rate: 0.00102057
	LOSS [training: 0.43662363251483144 | validation: 0.5440042883879046]
	TIME [epoch: 9.48 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4510117984485092		[learning rate: 0.0010156]
	Learning Rate: 0.00101563
	LOSS [training: 0.4510117984485092 | validation: 0.647283771375166]
	TIME [epoch: 9.45 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39145153552948814		[learning rate: 0.0010107]
	Learning Rate: 0.00101072
	LOSS [training: 0.39145153552948814 | validation: 0.6333578854863451]
	TIME [epoch: 9.45 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32708525978150976		[learning rate: 0.0010058]
	Learning Rate: 0.00100583
	LOSS [training: 0.32708525978150976 | validation: 0.4598045916843268]
	TIME [epoch: 9.48 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43033699359429634		[learning rate: 0.001001]
	Learning Rate: 0.00100097
	LOSS [training: 0.43033699359429634 | validation: 0.7521691256226406]
	TIME [epoch: 9.45 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44509930598544506		[learning rate: 0.00099613]
	Learning Rate: 0.000996129
	LOSS [training: 0.44509930598544506 | validation: 0.36871000925253]
	TIME [epoch: 9.45 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3147803106575774		[learning rate: 0.00099131]
	Learning Rate: 0.000991312
	LOSS [training: 0.3147803106575774 | validation: 0.3830864140258571]
	TIME [epoch: 9.46 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27000256137992423		[learning rate: 0.00098652]
	Learning Rate: 0.000986519
	LOSS [training: 0.27000256137992423 | validation: 0.3639475950807602]
	TIME [epoch: 9.47 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3059340970937702		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 0.3059340970937702 | validation: 0.4442740999119494]
	TIME [epoch: 9.45 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4529263030121866		[learning rate: 0.000977]
	Learning Rate: 0.000977
	LOSS [training: 0.4529263030121866 | validation: 0.3775532537451714]
	TIME [epoch: 9.45 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29677636608597135		[learning rate: 0.00097228]
	Learning Rate: 0.000972276
	LOSS [training: 0.29677636608597135 | validation: 0.38440210676521985]
	TIME [epoch: 9.47 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32947002926036906		[learning rate: 0.00096757]
	Learning Rate: 0.000967574
	LOSS [training: 0.32947002926036906 | validation: 0.6661294264055404]
	TIME [epoch: 9.45 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5812171392068791		[learning rate: 0.00096289]
	Learning Rate: 0.000962895
	LOSS [training: 0.5812171392068791 | validation: 0.4134656458824128]
	TIME [epoch: 9.46 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36651472196680057		[learning rate: 0.00095824]
	Learning Rate: 0.000958239
	LOSS [training: 0.36651472196680057 | validation: 0.5386518316215502]
	TIME [epoch: 9.46 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35196238535474006		[learning rate: 0.0009536]
	Learning Rate: 0.000953605
	LOSS [training: 0.35196238535474006 | validation: 0.5422889416034363]
	TIME [epoch: 9.48 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4703842939892092		[learning rate: 0.00094899]
	Learning Rate: 0.000948993
	LOSS [training: 0.4703842939892092 | validation: 0.917424137872103]
	TIME [epoch: 9.45 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38592719398873027		[learning rate: 0.0009444]
	Learning Rate: 0.000944404
	LOSS [training: 0.38592719398873027 | validation: 0.4768236262855605]
	TIME [epoch: 9.45 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34814224279554973		[learning rate: 0.00093984]
	Learning Rate: 0.000939837
	LOSS [training: 0.34814224279554973 | validation: 0.40869823520194715]
	TIME [epoch: 9.47 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3022032551193575		[learning rate: 0.00093529]
	Learning Rate: 0.000935292
	LOSS [training: 0.3022032551193575 | validation: 0.3189380801396769]
	TIME [epoch: 9.45 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30419489461406035		[learning rate: 0.00093077]
	Learning Rate: 0.000930769
	LOSS [training: 0.30419489461406035 | validation: 0.32728575583302993]
	TIME [epoch: 9.45 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40676987998294595		[learning rate: 0.00092627]
	Learning Rate: 0.000926268
	LOSS [training: 0.40676987998294595 | validation: 0.36472769145461753]
	TIME [epoch: 9.45 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2903940317486714		[learning rate: 0.00092179]
	Learning Rate: 0.000921789
	LOSS [training: 0.2903940317486714 | validation: 0.38270454840792467]
	TIME [epoch: 9.46 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2765825425119369		[learning rate: 0.00091733]
	Learning Rate: 0.000917331
	LOSS [training: 0.2765825425119369 | validation: 0.3279189795573978]
	TIME [epoch: 9.45 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30698501031169406		[learning rate: 0.0009129]
	Learning Rate: 0.000912895
	LOSS [training: 0.30698501031169406 | validation: 0.45546616504987947]
	TIME [epoch: 9.45 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3779465167806598		[learning rate: 0.00090848]
	Learning Rate: 0.000908481
	LOSS [training: 0.3779465167806598 | validation: 0.36414251352560584]
	TIME [epoch: 9.47 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31191021644857025		[learning rate: 0.00090409]
	Learning Rate: 0.000904088
	LOSS [training: 0.31191021644857025 | validation: 0.33236434127940956]
	TIME [epoch: 9.45 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30638045299685457		[learning rate: 0.00089972]
	Learning Rate: 0.000899716
	LOSS [training: 0.30638045299685457 | validation: 0.3105928307647931]
	TIME [epoch: 9.45 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2975377798637363		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.2975377798637363 | validation: 0.3122075187879361]
	TIME [epoch: 9.45 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4027203289950293		[learning rate: 0.00089104]
	Learning Rate: 0.000891035
	LOSS [training: 0.4027203289950293 | validation: 0.6507925500421612]
	TIME [epoch: 9.47 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44301171973151304		[learning rate: 0.00088673]
	Learning Rate: 0.000886726
	LOSS [training: 0.44301171973151304 | validation: 0.35175115358590575]
	TIME [epoch: 9.45 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3507985006738806		[learning rate: 0.00088244]
	Learning Rate: 0.000882438
	LOSS [training: 0.3507985006738806 | validation: 0.2931616882726448]
	TIME [epoch: 9.45 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2630537914216274		[learning rate: 0.00087817]
	Learning Rate: 0.000878171
	LOSS [training: 0.2630537914216274 | validation: 0.3142685095334107]
	TIME [epoch: 9.48 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2634772163724953		[learning rate: 0.00087392]
	Learning Rate: 0.000873924
	LOSS [training: 0.2634772163724953 | validation: 0.32479433402812113]
	TIME [epoch: 9.44 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25035183025671126		[learning rate: 0.0008697]
	Learning Rate: 0.000869698
	LOSS [training: 0.25035183025671126 | validation: 0.34899223526952455]
	TIME [epoch: 9.44 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3625915815594626		[learning rate: 0.00086549]
	Learning Rate: 0.000865492
	LOSS [training: 0.3625915815594626 | validation: 0.5742839060745905]
	TIME [epoch: 9.45 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4214528498573701		[learning rate: 0.00086131]
	Learning Rate: 0.000861307
	LOSS [training: 0.4214528498573701 | validation: 0.5079478366630277]
	TIME [epoch: 9.5 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45958820505518244		[learning rate: 0.00085714]
	Learning Rate: 0.000857142
	LOSS [training: 0.45958820505518244 | validation: 0.668335413960619]
	TIME [epoch: 9.45 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4582666200840369		[learning rate: 0.000853]
	Learning Rate: 0.000852997
	LOSS [training: 0.4582666200840369 | validation: 0.571693051328975]
	TIME [epoch: 9.45 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5153640729666166		[learning rate: 0.00084887]
	Learning Rate: 0.000848872
	LOSS [training: 0.5153640729666166 | validation: 0.5046400558326677]
	TIME [epoch: 9.48 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34267012901246596		[learning rate: 0.00084477]
	Learning Rate: 0.000844767
	LOSS [training: 0.34267012901246596 | validation: 0.39738603284512586]
	TIME [epoch: 9.45 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4010558350043435		[learning rate: 0.00084068]
	Learning Rate: 0.000840682
	LOSS [training: 0.4010558350043435 | validation: 0.5853767897825721]
	TIME [epoch: 9.45 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39492650593011047		[learning rate: 0.00083662]
	Learning Rate: 0.000836616
	LOSS [training: 0.39492650593011047 | validation: 0.3193598808780617]
	TIME [epoch: 9.46 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.302775510973731		[learning rate: 0.00083257]
	Learning Rate: 0.000832571
	LOSS [training: 0.302775510973731 | validation: 0.37713455919579597]
	TIME [epoch: 9.47 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4214764285082488		[learning rate: 0.00082854]
	Learning Rate: 0.000828544
	LOSS [training: 0.4214764285082488 | validation: 0.49217625635004186]
	TIME [epoch: 9.45 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39731170371735763		[learning rate: 0.00082454]
	Learning Rate: 0.000824538
	LOSS [training: 0.39731170371735763 | validation: 0.3531325660365004]
	TIME [epoch: 9.45 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30332114931986004		[learning rate: 0.00082055]
	Learning Rate: 0.00082055
	LOSS [training: 0.30332114931986004 | validation: 0.492642598763026]
	TIME [epoch: 9.47 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5235383206748349		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.5235383206748349 | validation: 0.40271509673422856]
	TIME [epoch: 9.45 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39049526530701145		[learning rate: 0.00081263]
	Learning Rate: 0.000812633
	LOSS [training: 0.39049526530701145 | validation: 0.40257515093212926]
	TIME [epoch: 9.45 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3437212236227274		[learning rate: 0.0008087]
	Learning Rate: 0.000808704
	LOSS [training: 0.3437212236227274 | validation: 0.41639041475668165]
	TIME [epoch: 9.46 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41911805252544854		[learning rate: 0.00080479]
	Learning Rate: 0.000804793
	LOSS [training: 0.41911805252544854 | validation: 0.40636465727926097]
	TIME [epoch: 9.47 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4147105642596028		[learning rate: 0.0008009]
	Learning Rate: 0.000800901
	LOSS [training: 0.4147105642596028 | validation: 0.6992076749439875]
	TIME [epoch: 9.46 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6128747384282403		[learning rate: 0.00079703]
	Learning Rate: 0.000797028
	LOSS [training: 0.6128747384282403 | validation: 0.4468907182430425]
	TIME [epoch: 9.45 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41622513921944326		[learning rate: 0.00079317]
	Learning Rate: 0.000793174
	LOSS [training: 0.41622513921944326 | validation: 0.38088497731233445]
	TIME [epoch: 9.48 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4070090260100253		[learning rate: 0.00078934]
	Learning Rate: 0.000789338
	LOSS [training: 0.4070090260100253 | validation: 0.48903799130906633]
	TIME [epoch: 9.45 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37329611211268005		[learning rate: 0.00078552]
	Learning Rate: 0.000785521
	LOSS [training: 0.37329611211268005 | validation: 0.409249299873394]
	TIME [epoch: 9.45 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33508316861551785		[learning rate: 0.00078172]
	Learning Rate: 0.000781723
	LOSS [training: 0.33508316861551785 | validation: 0.3254995043257848]
	TIME [epoch: 9.46 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30315411403687137		[learning rate: 0.00077794]
	Learning Rate: 0.000777942
	LOSS [training: 0.30315411403687137 | validation: 0.3481185150890839]
	TIME [epoch: 9.47 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2753199149571838		[learning rate: 0.00077418]
	Learning Rate: 0.00077418
	LOSS [training: 0.2753199149571838 | validation: 0.34044734046205405]
	TIME [epoch: 9.45 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27994393259398936		[learning rate: 0.00077044]
	Learning Rate: 0.000770436
	LOSS [training: 0.27994393259398936 | validation: 0.32064908141726917]
	TIME [epoch: 9.45 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3113143700287049		[learning rate: 0.00076671]
	Learning Rate: 0.000766711
	LOSS [training: 0.3113143700287049 | validation: 0.3380927425963111]
	TIME [epoch: 9.47 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2756180179523852		[learning rate: 0.000763]
	Learning Rate: 0.000763003
	LOSS [training: 0.2756180179523852 | validation: 0.41328505380220576]
	TIME [epoch: 9.45 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27158123731958084		[learning rate: 0.00075931]
	Learning Rate: 0.000759313
	LOSS [training: 0.27158123731958084 | validation: 0.32968248172132814]
	TIME [epoch: 9.45 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2591409055419322		[learning rate: 0.00075564]
	Learning Rate: 0.000755641
	LOSS [training: 0.2591409055419322 | validation: 0.31089795734202147]
	TIME [epoch: 9.45 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25886110197206535		[learning rate: 0.00075199]
	Learning Rate: 0.000751987
	LOSS [training: 0.25886110197206535 | validation: 0.4778255928689131]
	TIME [epoch: 9.47 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3210084921471957		[learning rate: 0.00074835]
	Learning Rate: 0.000748351
	LOSS [training: 0.3210084921471957 | validation: 0.32940552344407453]
	TIME [epoch: 9.45 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2591375759698197		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.2591375759698197 | validation: 0.370333224883351]
	TIME [epoch: 9.45 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2528249801648902		[learning rate: 0.00074113]
	Learning Rate: 0.000741131
	LOSS [training: 0.2528249801648902 | validation: 0.30880440595199093]
	TIME [epoch: 9.47 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26647588319532234		[learning rate: 0.00073755]
	Learning Rate: 0.000737547
	LOSS [training: 0.26647588319532234 | validation: 0.3413156885684771]
	TIME [epoch: 9.45 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27282477869988414		[learning rate: 0.00073398]
	Learning Rate: 0.00073398
	LOSS [training: 0.27282477869988414 | validation: 0.3611728890503471]
	TIME [epoch: 9.45 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2871502944628484		[learning rate: 0.00073043]
	Learning Rate: 0.00073043
	LOSS [training: 0.2871502944628484 | validation: 0.33475076827992195]
	TIME [epoch: 9.46 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2680040553359015		[learning rate: 0.0007269]
	Learning Rate: 0.000726898
	LOSS [training: 0.2680040553359015 | validation: 0.3133876419054046]
	TIME [epoch: 9.47 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29133747872944254		[learning rate: 0.00072338]
	Learning Rate: 0.000723383
	LOSS [training: 0.29133747872944254 | validation: 0.3430175820917741]
	TIME [epoch: 9.45 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3003190582225025		[learning rate: 0.00071989]
	Learning Rate: 0.000719885
	LOSS [training: 0.3003190582225025 | validation: 0.3024864897138107]
	TIME [epoch: 9.45 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31826682660187017		[learning rate: 0.0007164]
	Learning Rate: 0.000716404
	LOSS [training: 0.31826682660187017 | validation: 0.42569775416612315]
	TIME [epoch: 9.47 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4236745733021241		[learning rate: 0.00071294]
	Learning Rate: 0.000712939
	LOSS [training: 0.4236745733021241 | validation: 0.5688040683098948]
	TIME [epoch: 9.46 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4421337715103112		[learning rate: 0.00070949]
	Learning Rate: 0.000709492
	LOSS [training: 0.4421337715103112 | validation: 0.4025912291579215]
	TIME [epoch: 9.45 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32979064104946		[learning rate: 0.00070606]
	Learning Rate: 0.000706061
	LOSS [training: 0.32979064104946 | validation: 0.40356364438970477]
	TIME [epoch: 9.46 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34862693328197936		[learning rate: 0.00070265]
	Learning Rate: 0.000702647
	LOSS [training: 0.34862693328197936 | validation: 0.4134545676835674]
	TIME [epoch: 9.47 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3543361177731288		[learning rate: 0.00069925]
	Learning Rate: 0.000699248
	LOSS [training: 0.3543361177731288 | validation: 0.31763438771784885]
	TIME [epoch: 9.45 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2850313136627721		[learning rate: 0.00069587]
	Learning Rate: 0.000695867
	LOSS [training: 0.2850313136627721 | validation: 0.35983603338256537]
	TIME [epoch: 9.45 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28636549246695975		[learning rate: 0.0006925]
	Learning Rate: 0.000692502
	LOSS [training: 0.28636549246695975 | validation: 0.3924321548739541]
	TIME [epoch: 9.48 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29538458831600867		[learning rate: 0.00068915]
	Learning Rate: 0.000689153
	LOSS [training: 0.29538458831600867 | validation: 0.3627714122631981]
	TIME [epoch: 9.46 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3429961161715954		[learning rate: 0.00068582]
	Learning Rate: 0.000685821
	LOSS [training: 0.3429961161715954 | validation: 0.5313821416387167]
	TIME [epoch: 9.45 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46748012166477054		[learning rate: 0.0006825]
	Learning Rate: 0.000682504
	LOSS [training: 0.46748012166477054 | validation: 0.3281419979449612]
	TIME [epoch: 9.46 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27911979993495356		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.27911979993495356 | validation: 0.3210613822284373]
	TIME [epoch: 9.48 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2810742699320925		[learning rate: 0.00067592]
	Learning Rate: 0.000675919
	LOSS [training: 0.2810742699320925 | validation: 0.2988826140789599]
	TIME [epoch: 9.46 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2960730995448933		[learning rate: 0.00067265]
	Learning Rate: 0.000672651
	LOSS [training: 0.2960730995448933 | validation: 0.44436525651550085]
	TIME [epoch: 9.45 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2870112710693981		[learning rate: 0.0006694]
	Learning Rate: 0.000669398
	LOSS [training: 0.2870112710693981 | validation: 0.39643155495300036]
	TIME [epoch: 9.47 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2985878403700275		[learning rate: 0.00066616]
	Learning Rate: 0.000666161
	LOSS [training: 0.2985878403700275 | validation: 0.44068038108495033]
	TIME [epoch: 9.46 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.287794377710084		[learning rate: 0.00066294]
	Learning Rate: 0.000662939
	LOSS [training: 0.287794377710084 | validation: 0.3184171185786676]
	TIME [epoch: 9.45 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27483087924047733		[learning rate: 0.00065973]
	Learning Rate: 0.000659733
	LOSS [training: 0.27483087924047733 | validation: 0.29529962646741115]
	TIME [epoch: 9.46 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3079670245998287		[learning rate: 0.00065654]
	Learning Rate: 0.000656543
	LOSS [training: 0.3079670245998287 | validation: 0.37657388552414633]
	TIME [epoch: 9.48 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37961410916142035		[learning rate: 0.00065337]
	Learning Rate: 0.000653368
	LOSS [training: 0.37961410916142035 | validation: 0.43848123025795915]
	TIME [epoch: 9.45 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4097928762218709		[learning rate: 0.00065021]
	Learning Rate: 0.000650209
	LOSS [training: 0.4097928762218709 | validation: 0.48090802523853554]
	TIME [epoch: 9.46 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3515103432514827		[learning rate: 0.00064706]
	Learning Rate: 0.000647064
	LOSS [training: 0.3515103432514827 | validation: 0.3743450057532225]
	TIME [epoch: 9.47 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3890825993993289		[learning rate: 0.00064394]
	Learning Rate: 0.000643935
	LOSS [training: 0.3890825993993289 | validation: 0.4729036898788618]
	TIME [epoch: 9.45 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3398489113777792		[learning rate: 0.00064082]
	Learning Rate: 0.000640821
	LOSS [training: 0.3398489113777792 | validation: 0.3614427814825666]
	TIME [epoch: 9.45 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31631884954215594		[learning rate: 0.00063772]
	Learning Rate: 0.000637722
	LOSS [training: 0.31631884954215594 | validation: 0.372264676723464]
	TIME [epoch: 9.46 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31181825184514944		[learning rate: 0.00063464]
	Learning Rate: 0.000634638
	LOSS [training: 0.31181825184514944 | validation: 0.329379604850983]
	TIME [epoch: 9.47 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3042797580225056		[learning rate: 0.00063157]
	Learning Rate: 0.000631569
	LOSS [training: 0.3042797580225056 | validation: 0.3821983458009524]
	TIME [epoch: 9.45 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29818221935434563		[learning rate: 0.00062852]
	Learning Rate: 0.000628515
	LOSS [training: 0.29818221935434563 | validation: 0.3473536342936264]
	TIME [epoch: 9.45 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2899455413865276		[learning rate: 0.00062548]
	Learning Rate: 0.000625476
	LOSS [training: 0.2899455413865276 | validation: 0.33942038502118105]
	TIME [epoch: 9.48 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2675458503177092		[learning rate: 0.00062245]
	Learning Rate: 0.000622451
	LOSS [training: 0.2675458503177092 | validation: 0.38427945762959115]
	TIME [epoch: 9.45 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30380780821193004		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.30380780821193004 | validation: 0.3655925110973925]
	TIME [epoch: 9.45 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2593444014809208		[learning rate: 0.00061645]
	Learning Rate: 0.000616445
	LOSS [training: 0.2593444014809208 | validation: 0.346232147586471]
	TIME [epoch: 9.46 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27475048355325526		[learning rate: 0.00061346]
	Learning Rate: 0.000613465
	LOSS [training: 0.27475048355325526 | validation: 0.2923790640554604]
	TIME [epoch: 9.47 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25548610372798225		[learning rate: 0.0006105]
	Learning Rate: 0.000610498
	LOSS [training: 0.25548610372798225 | validation: 0.28426370736229917]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_627.pth
	Model improved!!!
EPOCH 628/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27197883333371997		[learning rate: 0.00060755]
	Learning Rate: 0.000607546
	LOSS [training: 0.27197883333371997 | validation: 0.3091061377650865]
	TIME [epoch: 9.44 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31141126649405254		[learning rate: 0.00060461]
	Learning Rate: 0.000604608
	LOSS [training: 0.31141126649405254 | validation: 0.3068350686370777]
	TIME [epoch: 9.48 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24389359306270264		[learning rate: 0.00060168]
	Learning Rate: 0.000601684
	LOSS [training: 0.24389359306270264 | validation: 0.26761072817435333]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_630.pth
	Model improved!!!
EPOCH 631/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2584152181741781		[learning rate: 0.00059877]
	Learning Rate: 0.000598774
	LOSS [training: 0.2584152181741781 | validation: 0.37635153098947116]
	TIME [epoch: 9.46 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29520430060608277		[learning rate: 0.00059588]
	Learning Rate: 0.000595879
	LOSS [training: 0.29520430060608277 | validation: 0.33485834321979663]
	TIME [epoch: 9.45 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.262697725313877		[learning rate: 0.000593]
	Learning Rate: 0.000592997
	LOSS [training: 0.262697725313877 | validation: 0.38267505806359936]
	TIME [epoch: 9.46 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4103343669711979		[learning rate: 0.00059013]
	Learning Rate: 0.000590129
	LOSS [training: 0.4103343669711979 | validation: 0.5220631623489052]
	TIME [epoch: 9.46 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38414454053987823		[learning rate: 0.00058728]
	Learning Rate: 0.000587276
	LOSS [training: 0.38414454053987823 | validation: 0.37678641233623567]
	TIME [epoch: 9.45 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30448570943184283		[learning rate: 0.00058444]
	Learning Rate: 0.000584436
	LOSS [training: 0.30448570943184283 | validation: 0.3297342797655387]
	TIME [epoch: 9.47 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28275945739464653		[learning rate: 0.00058161]
	Learning Rate: 0.00058161
	LOSS [training: 0.28275945739464653 | validation: 0.3604380308139726]
	TIME [epoch: 9.45 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2709938836527065		[learning rate: 0.0005788]
	Learning Rate: 0.000578797
	LOSS [training: 0.2709938836527065 | validation: 0.2870869142847804]
	TIME [epoch: 9.44 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2434777146662564		[learning rate: 0.000576]
	Learning Rate: 0.000575998
	LOSS [training: 0.2434777146662564 | validation: 0.42090362731310055]
	TIME [epoch: 9.45 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3446919314172636		[learning rate: 0.00057321]
	Learning Rate: 0.000573213
	LOSS [training: 0.3446919314172636 | validation: 0.42321941343574504]
	TIME [epoch: 9.47 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29254587436616153		[learning rate: 0.00057044]
	Learning Rate: 0.000570441
	LOSS [training: 0.29254587436616153 | validation: 0.3427957163991534]
	TIME [epoch: 9.45 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3217830090894235		[learning rate: 0.00056768]
	Learning Rate: 0.000567682
	LOSS [training: 0.3217830090894235 | validation: 0.3602179415243791]
	TIME [epoch: 9.45 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2821745155292247		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.2821745155292247 | validation: 0.391540860052005]
	TIME [epoch: 9.47 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3153119786122941		[learning rate: 0.0005622]
	Learning Rate: 0.000562205
	LOSS [training: 0.3153119786122941 | validation: 0.3321008012233625]
	TIME [epoch: 9.45 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2798217827282965		[learning rate: 0.00055949]
	Learning Rate: 0.000559486
	LOSS [training: 0.2798217827282965 | validation: 0.31720591292231753]
	TIME [epoch: 9.45 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30047512999517706		[learning rate: 0.00055678]
	Learning Rate: 0.000556781
	LOSS [training: 0.30047512999517706 | validation: 0.4135239213934142]
	TIME [epoch: 9.46 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27244725100359346		[learning rate: 0.00055409]
	Learning Rate: 0.000554088
	LOSS [training: 0.27244725100359346 | validation: 0.417406130164584]
	TIME [epoch: 9.47 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3329303718886967		[learning rate: 0.00055141]
	Learning Rate: 0.000551409
	LOSS [training: 0.3329303718886967 | validation: 0.36902009921226764]
	TIME [epoch: 9.44 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3018612815229493		[learning rate: 0.00054874]
	Learning Rate: 0.000548742
	LOSS [training: 0.3018612815229493 | validation: 0.3427918622187158]
	TIME [epoch: 9.45 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.325874577981416		[learning rate: 0.00054609]
	Learning Rate: 0.000546089
	LOSS [training: 0.325874577981416 | validation: 0.3514072684384489]
	TIME [epoch: 9.47 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.278878752010468		[learning rate: 0.00054345]
	Learning Rate: 0.000543448
	LOSS [training: 0.278878752010468 | validation: 0.391715759268716]
	TIME [epoch: 9.44 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2768549602146807		[learning rate: 0.00054082]
	Learning Rate: 0.00054082
	LOSS [training: 0.2768549602146807 | validation: 0.3456677858562236]
	TIME [epoch: 9.44 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2478572245980967		[learning rate: 0.0005382]
	Learning Rate: 0.000538205
	LOSS [training: 0.2478572245980967 | validation: 0.42273366763062004]
	TIME [epoch: 9.45 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27687170445989173		[learning rate: 0.0005356]
	Learning Rate: 0.000535602
	LOSS [training: 0.27687170445989173 | validation: 0.4017453644883726]
	TIME [epoch: 9.47 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2852692472759998		[learning rate: 0.00053301]
	Learning Rate: 0.000533012
	LOSS [training: 0.2852692472759998 | validation: 0.3530136040028933]
	TIME [epoch: 9.45 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25274807399369503		[learning rate: 0.00053043]
	Learning Rate: 0.000530434
	LOSS [training: 0.25274807399369503 | validation: 0.294154711279923]
	TIME [epoch: 9.45 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23314435843027512		[learning rate: 0.00052787]
	Learning Rate: 0.000527869
	LOSS [training: 0.23314435843027512 | validation: 0.3343365022955762]
	TIME [epoch: 9.47 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2631603350089622		[learning rate: 0.00052532]
	Learning Rate: 0.000525317
	LOSS [training: 0.2631603350089622 | validation: 0.41931068692399187]
	TIME [epoch: 9.45 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25805350499232005		[learning rate: 0.00052278]
	Learning Rate: 0.000522776
	LOSS [training: 0.25805350499232005 | validation: 0.39928405884707685]
	TIME [epoch: 9.44 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2702955148640491		[learning rate: 0.00052025]
	Learning Rate: 0.000520248
	LOSS [training: 0.2702955148640491 | validation: 0.32310943587830926]
	TIME [epoch: 9.45 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2681349691779716		[learning rate: 0.00051773]
	Learning Rate: 0.000517732
	LOSS [training: 0.2681349691779716 | validation: 0.3990390574338488]
	TIME [epoch: 9.46 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2847584977439429		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.2847584977439429 | validation: 0.49134061382205335]
	TIME [epoch: 9.45 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2764199023964137		[learning rate: 0.00051274]
	Learning Rate: 0.000512737
	LOSS [training: 0.2764199023964137 | validation: 0.4862123183954343]
	TIME [epoch: 9.45 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32866822508388494		[learning rate: 0.00051026]
	Learning Rate: 0.000510258
	LOSS [training: 0.32866822508388494 | validation: 0.46467437362115704]
	TIME [epoch: 9.48 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31141175259008536		[learning rate: 0.00050779]
	Learning Rate: 0.00050779
	LOSS [training: 0.31141175259008536 | validation: 0.5004003743226096]
	TIME [epoch: 9.46 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37355743561845517		[learning rate: 0.00050533]
	Learning Rate: 0.000505334
	LOSS [training: 0.37355743561845517 | validation: 0.5218810576629358]
	TIME [epoch: 9.45 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3641963104907228		[learning rate: 0.00050289]
	Learning Rate: 0.000502891
	LOSS [training: 0.3641963104907228 | validation: 0.4814211650988085]
	TIME [epoch: 9.45 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35218026164006677		[learning rate: 0.00050046]
	Learning Rate: 0.000500459
	LOSS [training: 0.35218026164006677 | validation: 0.4502455461693903]
	TIME [epoch: 9.47 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3240602958321447		[learning rate: 0.00049804]
	Learning Rate: 0.000498039
	LOSS [training: 0.3240602958321447 | validation: 0.38696532070135903]
	TIME [epoch: 9.45 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.301427238203032		[learning rate: 0.00049563]
	Learning Rate: 0.00049563
	LOSS [training: 0.301427238203032 | validation: 0.4210890442075625]
	TIME [epoch: 9.45 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.363869280116563		[learning rate: 0.00049323]
	Learning Rate: 0.000493234
	LOSS [training: 0.363869280116563 | validation: 0.3876351945792875]
	TIME [epoch: 9.48 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.318662221163582		[learning rate: 0.00049085]
	Learning Rate: 0.000490848
	LOSS [training: 0.318662221163582 | validation: 0.4775949909412938]
	TIME [epoch: 9.45 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33980943955991744		[learning rate: 0.00048847]
	Learning Rate: 0.000488475
	LOSS [training: 0.33980943955991744 | validation: 0.39436745140313434]
	TIME [epoch: 9.46 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30939076533565135		[learning rate: 0.00048611]
	Learning Rate: 0.000486113
	LOSS [training: 0.30939076533565135 | validation: 0.4188575585755035]
	TIME [epoch: 9.46 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3133879570077551		[learning rate: 0.00048376]
	Learning Rate: 0.000483762
	LOSS [training: 0.3133879570077551 | validation: 0.4208477802925765]
	TIME [epoch: 9.47 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26617544810872623		[learning rate: 0.00048142]
	Learning Rate: 0.000481422
	LOSS [training: 0.26617544810872623 | validation: 0.3980589299697272]
	TIME [epoch: 9.45 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3126808403722457		[learning rate: 0.00047909]
	Learning Rate: 0.000479094
	LOSS [training: 0.3126808403722457 | validation: 0.32226040066374134]
	TIME [epoch: 9.45 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2506738581885679		[learning rate: 0.00047678]
	Learning Rate: 0.000476777
	LOSS [training: 0.2506738581885679 | validation: 0.30590156799370555]
	TIME [epoch: 9.48 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23110081619018552		[learning rate: 0.00047447]
	Learning Rate: 0.000474472
	LOSS [training: 0.23110081619018552 | validation: 0.34356285334923514]
	TIME [epoch: 9.45 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24651385139918397		[learning rate: 0.00047218]
	Learning Rate: 0.000472177
	LOSS [training: 0.24651385139918397 | validation: 0.32670689633000394]
	TIME [epoch: 9.46 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22065773385823792		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.22065773385823792 | validation: 0.3678523355419476]
	TIME [epoch: 9.46 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3142420597980118		[learning rate: 0.00046762]
	Learning Rate: 0.000467622
	LOSS [training: 0.3142420597980118 | validation: 0.4669071951871976]
	TIME [epoch: 9.47 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28660666598212325		[learning rate: 0.00046536]
	Learning Rate: 0.00046536
	LOSS [training: 0.28660666598212325 | validation: 0.4352597097172158]
	TIME [epoch: 9.45 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2570686772777915		[learning rate: 0.00046311]
	Learning Rate: 0.00046311
	LOSS [training: 0.2570686772777915 | validation: 0.3609957560817722]
	TIME [epoch: 9.46 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24996841657315017		[learning rate: 0.00046087]
	Learning Rate: 0.000460871
	LOSS [training: 0.24996841657315017 | validation: 0.3795206309609132]
	TIME [epoch: 9.47 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2664097132131827		[learning rate: 0.00045864]
	Learning Rate: 0.000458642
	LOSS [training: 0.2664097132131827 | validation: 0.49848329831686927]
	TIME [epoch: 9.45 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3305783666378326		[learning rate: 0.00045642]
	Learning Rate: 0.000456424
	LOSS [training: 0.3305783666378326 | validation: 0.46631448009278564]
	TIME [epoch: 9.46 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3720073870351264		[learning rate: 0.00045422]
	Learning Rate: 0.000454217
	LOSS [training: 0.3720073870351264 | validation: 0.6650181141296388]
	TIME [epoch: 9.45 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.410493570173042		[learning rate: 0.00045202]
	Learning Rate: 0.00045202
	LOSS [training: 0.410493570173042 | validation: 0.52292778251025]
	TIME [epoch: 9.47 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2914622218544887		[learning rate: 0.00044983]
	Learning Rate: 0.000449834
	LOSS [training: 0.2914622218544887 | validation: 0.4182210396492836]
	TIME [epoch: 9.45 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2700470118495123		[learning rate: 0.00044766]
	Learning Rate: 0.000447659
	LOSS [training: 0.2700470118495123 | validation: 0.423046541081978]
	TIME [epoch: 9.45 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32422558535607177		[learning rate: 0.00044549]
	Learning Rate: 0.000445494
	LOSS [training: 0.32422558535607177 | validation: 0.6112381872001614]
	TIME [epoch: 9.47 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3261624511515243		[learning rate: 0.00044334]
	Learning Rate: 0.00044334
	LOSS [training: 0.3261624511515243 | validation: 0.500905345165483]
	TIME [epoch: 9.46 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3296082579196714		[learning rate: 0.0004412]
	Learning Rate: 0.000441196
	LOSS [training: 0.3296082579196714 | validation: 0.48530050108727424]
	TIME [epoch: 9.45 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29381352192046306		[learning rate: 0.00043906]
	Learning Rate: 0.000439063
	LOSS [training: 0.29381352192046306 | validation: 0.4114404620056311]
	TIME [epoch: 9.45 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27124994645800343		[learning rate: 0.00043694]
	Learning Rate: 0.000436939
	LOSS [training: 0.27124994645800343 | validation: 0.4026464695068266]
	TIME [epoch: 9.47 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.277417311505051		[learning rate: 0.00043483]
	Learning Rate: 0.000434826
	LOSS [training: 0.277417311505051 | validation: 0.42634692420655596]
	TIME [epoch: 9.45 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2953603037732412		[learning rate: 0.00043272]
	Learning Rate: 0.000432724
	LOSS [training: 0.2953603037732412 | validation: 0.6374729299131778]
	TIME [epoch: 9.45 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38050748761150366		[learning rate: 0.00043063]
	Learning Rate: 0.000430631
	LOSS [training: 0.38050748761150366 | validation: 0.5269818454893347]
	TIME [epoch: 9.47 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.279733870124126		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.279733870124126 | validation: 0.4176743126396248]
	TIME [epoch: 9.45 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3073573007336324		[learning rate: 0.00042648]
	Learning Rate: 0.000426476
	LOSS [training: 0.3073573007336324 | validation: 0.451024107432103]
	TIME [epoch: 9.44 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3416714344667308		[learning rate: 0.00042441]
	Learning Rate: 0.000424414
	LOSS [training: 0.3416714344667308 | validation: 0.40540996681278774]
	TIME [epoch: 9.45 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3919031333909738		[learning rate: 0.00042236]
	Learning Rate: 0.000422361
	LOSS [training: 0.3919031333909738 | validation: 0.33620477736903126]
	TIME [epoch: 9.47 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27595138445819356		[learning rate: 0.00042032]
	Learning Rate: 0.000420319
	LOSS [training: 0.27595138445819356 | validation: 0.3205692726047999]
	TIME [epoch: 9.45 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2524717840806706		[learning rate: 0.00041829]
	Learning Rate: 0.000418286
	LOSS [training: 0.2524717840806706 | validation: 0.33934744540211853]
	TIME [epoch: 9.45 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3156153235674156		[learning rate: 0.00041626]
	Learning Rate: 0.000416264
	LOSS [training: 0.3156153235674156 | validation: 0.3140107369810132]
	TIME [epoch: 9.47 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22989799212431428		[learning rate: 0.00041425]
	Learning Rate: 0.000414251
	LOSS [training: 0.22989799212431428 | validation: 0.31116991655321974]
	TIME [epoch: 9.45 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2349162166987334		[learning rate: 0.00041225]
	Learning Rate: 0.000412247
	LOSS [training: 0.2349162166987334 | validation: 0.3228631176020614]
	TIME [epoch: 9.45 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2435098639498261		[learning rate: 0.00041025]
	Learning Rate: 0.000410254
	LOSS [training: 0.2435098639498261 | validation: 0.2937569630785441]
	TIME [epoch: 9.45 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23299929687997478		[learning rate: 0.00040827]
	Learning Rate: 0.00040827
	LOSS [training: 0.23299929687997478 | validation: 0.33257993134896047]
	TIME [epoch: 9.46 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2449749821778368		[learning rate: 0.0004063]
	Learning Rate: 0.000406296
	LOSS [training: 0.2449749821778368 | validation: 0.29841661097057054]
	TIME [epoch: 9.44 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25645639215134736		[learning rate: 0.00040433]
	Learning Rate: 0.000404331
	LOSS [training: 0.25645639215134736 | validation: 0.32402223002821096]
	TIME [epoch: 9.45 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2440317385935074		[learning rate: 0.00040238]
	Learning Rate: 0.000402376
	LOSS [training: 0.2440317385935074 | validation: 0.274365852923556]
	TIME [epoch: 9.46 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21909275979067627		[learning rate: 0.00040043]
	Learning Rate: 0.00040043
	LOSS [training: 0.21909275979067627 | validation: 0.4024787776447984]
	TIME [epoch: 9.45 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2638970725611271		[learning rate: 0.00039849]
	Learning Rate: 0.000398493
	LOSS [training: 0.2638970725611271 | validation: 0.37717096060181404]
	TIME [epoch: 9.46 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23798321703035025		[learning rate: 0.00039657]
	Learning Rate: 0.000396566
	LOSS [training: 0.23798321703035025 | validation: 0.3536444378929956]
	TIME [epoch: 9.47 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24524301150259786		[learning rate: 0.00039465]
	Learning Rate: 0.000394649
	LOSS [training: 0.24524301150259786 | validation: 0.4129105130127425]
	TIME [epoch: 9.47 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2469570126383284		[learning rate: 0.00039274]
	Learning Rate: 0.00039274
	LOSS [training: 0.2469570126383284 | validation: 0.37091161806867434]
	TIME [epoch: 9.45 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2757868109452316		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.2757868109452316 | validation: 0.47232452119070273]
	TIME [epoch: 9.45 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2725740442653897		[learning rate: 0.00038895]
	Learning Rate: 0.000388951
	LOSS [training: 0.2725740442653897 | validation: 0.3503722171452454]
	TIME [epoch: 9.48 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24051036808694795		[learning rate: 0.00038707]
	Learning Rate: 0.00038707
	LOSS [training: 0.24051036808694795 | validation: 0.320261981217566]
	TIME [epoch: 9.45 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23017060223307687		[learning rate: 0.0003852]
	Learning Rate: 0.000385198
	LOSS [training: 0.23017060223307687 | validation: 0.3485433335768262]
	TIME [epoch: 9.45 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22409324286864923		[learning rate: 0.00038334]
	Learning Rate: 0.000383335
	LOSS [training: 0.22409324286864923 | validation: 0.2826618495614293]
	TIME [epoch: 9.46 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20741940838360434		[learning rate: 0.00038148]
	Learning Rate: 0.000381482
	LOSS [training: 0.20741940838360434 | validation: 0.29376832635480193]
	TIME [epoch: 9.47 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23473176239169677		[learning rate: 0.00037964]
	Learning Rate: 0.000379637
	LOSS [training: 0.23473176239169677 | validation: 0.35733501294977216]
	TIME [epoch: 9.46 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.255919020864284		[learning rate: 0.0003778]
	Learning Rate: 0.000377801
	LOSS [training: 0.255919020864284 | validation: 0.37296720566689623]
	TIME [epoch: 9.46 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27601371739187286		[learning rate: 0.00037597]
	Learning Rate: 0.000375974
	LOSS [training: 0.27601371739187286 | validation: 0.4611729612526531]
	TIME [epoch: 9.47 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.310601943248081		[learning rate: 0.00037416]
	Learning Rate: 0.000374156
	LOSS [training: 0.310601943248081 | validation: 0.45357849132022315]
	TIME [epoch: 9.45 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2992234128157746		[learning rate: 0.00037235]
	Learning Rate: 0.000372347
	LOSS [training: 0.2992234128157746 | validation: 0.45268171674007307]
	TIME [epoch: 9.45 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2649756057650972		[learning rate: 0.00037055]
	Learning Rate: 0.000370546
	LOSS [training: 0.2649756057650972 | validation: 0.4027401231555619]
	TIME [epoch: 9.45 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.243771302457603		[learning rate: 0.00036875]
	Learning Rate: 0.000368754
	LOSS [training: 0.243771302457603 | validation: 0.3559823828010425]
	TIME [epoch: 9.47 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2585267538926419		[learning rate: 0.00036697]
	Learning Rate: 0.000366971
	LOSS [training: 0.2585267538926419 | validation: 0.30889297162842044]
	TIME [epoch: 9.44 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2279846578524519		[learning rate: 0.0003652]
	Learning Rate: 0.000365196
	LOSS [training: 0.2279846578524519 | validation: 0.3467316391620037]
	TIME [epoch: 9.45 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23274792760869464		[learning rate: 0.00036343]
	Learning Rate: 0.00036343
	LOSS [training: 0.23274792760869464 | validation: 0.3855098318541006]
	TIME [epoch: 9.47 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2409300912406221		[learning rate: 0.00036167]
	Learning Rate: 0.000361673
	LOSS [training: 0.2409300912406221 | validation: 0.31647770061639774]
	TIME [epoch: 9.46 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23942902562349846		[learning rate: 0.00035992]
	Learning Rate: 0.000359924
	LOSS [training: 0.23942902562349846 | validation: 0.33904800310491384]
	TIME [epoch: 9.45 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2508837631581418		[learning rate: 0.00035818]
	Learning Rate: 0.000358183
	LOSS [training: 0.2508837631581418 | validation: 0.32019670765911434]
	TIME [epoch: 9.46 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25429552538700617		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.25429552538700617 | validation: 0.34913008601313666]
	TIME [epoch: 9.47 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28392175548284443		[learning rate: 0.00035473]
	Learning Rate: 0.000354727
	LOSS [training: 0.28392175548284443 | validation: 0.4395999491453984]
	TIME [epoch: 9.45 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32457084461938357		[learning rate: 0.00035301]
	Learning Rate: 0.000353012
	LOSS [training: 0.32457084461938357 | validation: 0.3581785752708147]
	TIME [epoch: 9.44 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3078927617580835		[learning rate: 0.0003513]
	Learning Rate: 0.000351305
	LOSS [training: 0.3078927617580835 | validation: 0.2949744220761318]
	TIME [epoch: 9.47 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26130085119960267		[learning rate: 0.00034961]
	Learning Rate: 0.000349606
	LOSS [training: 0.26130085119960267 | validation: 0.3373563000518142]
	TIME [epoch: 9.45 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2573465451278631		[learning rate: 0.00034792]
	Learning Rate: 0.000347915
	LOSS [training: 0.2573465451278631 | validation: 0.3406688515420395]
	TIME [epoch: 9.45 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23392760165693485		[learning rate: 0.00034623]
	Learning Rate: 0.000346233
	LOSS [training: 0.23392760165693485 | validation: 0.30284942463182263]
	TIME [epoch: 9.46 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26395392533828754		[learning rate: 0.00034456]
	Learning Rate: 0.000344559
	LOSS [training: 0.26395392533828754 | validation: 0.35665695235284306]
	TIME [epoch: 9.47 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27436673586620053		[learning rate: 0.00034289]
	Learning Rate: 0.000342892
	LOSS [training: 0.27436673586620053 | validation: 0.3769384199373573]
	TIME [epoch: 9.45 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28399418301703566		[learning rate: 0.00034123]
	Learning Rate: 0.000341234
	LOSS [training: 0.28399418301703566 | validation: 0.3395386451494883]
	TIME [epoch: 9.45 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27666849589230746		[learning rate: 0.00033958]
	Learning Rate: 0.000339584
	LOSS [training: 0.27666849589230746 | validation: 0.34825048259689134]
	TIME [epoch: 9.47 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26522884508431466		[learning rate: 0.00033794]
	Learning Rate: 0.000337942
	LOSS [training: 0.26522884508431466 | validation: 0.3629969321113866]
	TIME [epoch: 9.45 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2456175514026948		[learning rate: 0.00033631]
	Learning Rate: 0.000336308
	LOSS [training: 0.2456175514026948 | validation: 0.3029025639841849]
	TIME [epoch: 9.46 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26212047359736146		[learning rate: 0.00033468]
	Learning Rate: 0.000334681
	LOSS [training: 0.26212047359736146 | validation: 0.28046550154683464]
	TIME [epoch: 9.46 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22796846334927215		[learning rate: 0.00033306]
	Learning Rate: 0.000333063
	LOSS [training: 0.22796846334927215 | validation: 0.2701819255122138]
	TIME [epoch: 9.46 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2493644606010405		[learning rate: 0.00033145]
	Learning Rate: 0.000331452
	LOSS [training: 0.2493644606010405 | validation: 0.28278667807801056]
	TIME [epoch: 9.45 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23889213509832916		[learning rate: 0.00032985]
	Learning Rate: 0.000329849
	LOSS [training: 0.23889213509832916 | validation: 0.27558337734127625]
	TIME [epoch: 9.45 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2149249534150659		[learning rate: 0.00032825]
	Learning Rate: 0.000328254
	LOSS [training: 0.2149249534150659 | validation: 0.2509611441963481]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_755.pth
	Model improved!!!
EPOCH 756/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20752812373109655		[learning rate: 0.00032667]
	Learning Rate: 0.000326667
	LOSS [training: 0.20752812373109655 | validation: 0.24240297282944973]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_756.pth
	Model improved!!!
EPOCH 757/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20644996979860922		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.20644996979860922 | validation: 0.28580674907142045]
	TIME [epoch: 9.46 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21854003027315888		[learning rate: 0.00032352]
	Learning Rate: 0.000323515
	LOSS [training: 0.21854003027315888 | validation: 0.3492382719488284]
	TIME [epoch: 9.46 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22426482363243588		[learning rate: 0.00032195]
	Learning Rate: 0.000321951
	LOSS [training: 0.22426482363243588 | validation: 0.3148265561964627]
	TIME [epoch: 9.47 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21256536943137538		[learning rate: 0.00032039]
	Learning Rate: 0.000320394
	LOSS [training: 0.21256536943137538 | validation: 0.2780830833214952]
	TIME [epoch: 9.46 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24274974691400836		[learning rate: 0.00031884]
	Learning Rate: 0.000318845
	LOSS [training: 0.24274974691400836 | validation: 0.2763963162653503]
	TIME [epoch: 9.46 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25094726537612333		[learning rate: 0.0003173]
	Learning Rate: 0.000317303
	LOSS [training: 0.25094726537612333 | validation: 0.26989880701565905]
	TIME [epoch: 9.47 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25845037954378813		[learning rate: 0.00031577]
	Learning Rate: 0.000315768
	LOSS [training: 0.25845037954378813 | validation: 0.3089251004643879]
	TIME [epoch: 9.45 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28612138598694925		[learning rate: 0.00031424]
	Learning Rate: 0.000314241
	LOSS [training: 0.28612138598694925 | validation: 0.3024119386516384]
	TIME [epoch: 9.44 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2628696184997415		[learning rate: 0.00031272]
	Learning Rate: 0.000312722
	LOSS [training: 0.2628696184997415 | validation: 0.2845965682452716]
	TIME [epoch: 9.45 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27488963722792314		[learning rate: 0.00031121]
	Learning Rate: 0.000311209
	LOSS [training: 0.27488963722792314 | validation: 0.3233151588957589]
	TIME [epoch: 9.46 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27633275446651967		[learning rate: 0.0003097]
	Learning Rate: 0.000309704
	LOSS [training: 0.27633275446651967 | validation: 0.274994764460282]
	TIME [epoch: 9.45 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22430381978728864		[learning rate: 0.00030821]
	Learning Rate: 0.000308207
	LOSS [training: 0.22430381978728864 | validation: 0.29340569033357083]
	TIME [epoch: 9.44 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23351329870121712		[learning rate: 0.00030672]
	Learning Rate: 0.000306716
	LOSS [training: 0.23351329870121712 | validation: 0.3820804552546454]
	TIME [epoch: 9.47 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2967924474095937		[learning rate: 0.00030523]
	Learning Rate: 0.000305233
	LOSS [training: 0.2967924474095937 | validation: 0.36291204544132283]
	TIME [epoch: 9.44 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28911183813056807		[learning rate: 0.00030376]
	Learning Rate: 0.000303757
	LOSS [training: 0.28911183813056807 | validation: 0.3426204126220844]
	TIME [epoch: 9.45 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2698278791708641		[learning rate: 0.00030229]
	Learning Rate: 0.000302288
	LOSS [training: 0.2698278791708641 | validation: 0.2915316712387434]
	TIME [epoch: 9.45 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2805288319439112		[learning rate: 0.00030083]
	Learning Rate: 0.000300826
	LOSS [training: 0.2805288319439112 | validation: 0.3317298996404849]
	TIME [epoch: 9.46 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2681724460827163		[learning rate: 0.00029937]
	Learning Rate: 0.000299372
	LOSS [training: 0.2681724460827163 | validation: 0.29898500387201205]
	TIME [epoch: 9.44 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25231500451786915		[learning rate: 0.00029792]
	Learning Rate: 0.000297924
	LOSS [training: 0.25231500451786915 | validation: 0.2704931600704788]
	TIME [epoch: 9.44 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24857129165438266		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.24857129165438266 | validation: 0.2949058353288748]
	TIME [epoch: 9.47 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2692214919717778		[learning rate: 0.00029505]
	Learning Rate: 0.000295049
	LOSS [training: 0.2692214919717778 | validation: 0.2879687939868586]
	TIME [epoch: 9.46 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22093771127971235		[learning rate: 0.00029362]
	Learning Rate: 0.000293623
	LOSS [training: 0.22093771127971235 | validation: 0.28308823412273065]
	TIME [epoch: 9.45 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21144996066950217		[learning rate: 0.0002922]
	Learning Rate: 0.000292203
	LOSS [training: 0.21144996066950217 | validation: 0.2798017224464768]
	TIME [epoch: 9.46 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23062730668027545		[learning rate: 0.00029079]
	Learning Rate: 0.00029079
	LOSS [training: 0.23062730668027545 | validation: 0.3145567727560875]
	TIME [epoch: 9.47 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2837866315564647		[learning rate: 0.00028938]
	Learning Rate: 0.000289383
	LOSS [training: 0.2837866315564647 | validation: 0.2956069764143635]
	TIME [epoch: 9.46 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2528578156786268		[learning rate: 0.00028798]
	Learning Rate: 0.000287984
	LOSS [training: 0.2528578156786268 | validation: 0.2637093138081822]
	TIME [epoch: 9.46 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22686585207476262		[learning rate: 0.00028659]
	Learning Rate: 0.000286591
	LOSS [training: 0.22686585207476262 | validation: 0.2381434220300347]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_783.pth
	Model improved!!!
EPOCH 784/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2193111113135425		[learning rate: 0.00028521]
	Learning Rate: 0.000285205
	LOSS [training: 0.2193111113135425 | validation: 0.25436788569647134]
	TIME [epoch: 9.45 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20853112772368224		[learning rate: 0.00028383]
	Learning Rate: 0.000283826
	LOSS [training: 0.20853112772368224 | validation: 0.24547562890713728]
	TIME [epoch: 9.45 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23851250751161		[learning rate: 0.00028245]
	Learning Rate: 0.000282454
	LOSS [training: 0.23851250751161 | validation: 0.30001289565679623]
	TIME [epoch: 9.45 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25667624145346474		[learning rate: 0.00028109]
	Learning Rate: 0.000281088
	LOSS [training: 0.25667624145346474 | validation: 0.29240911126789215]
	TIME [epoch: 9.46 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25651318220636615		[learning rate: 0.00027973]
	Learning Rate: 0.000279729
	LOSS [training: 0.25651318220636615 | validation: 0.3611541914434617]
	TIME [epoch: 9.44 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35801025050796953		[learning rate: 0.00027838]
	Learning Rate: 0.000278376
	LOSS [training: 0.35801025050796953 | validation: 0.3602398904660888]
	TIME [epoch: 9.44 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3304478124663112		[learning rate: 0.00027703]
	Learning Rate: 0.00027703
	LOSS [training: 0.3304478124663112 | validation: 0.423360989558438]
	TIME [epoch: 9.47 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40480806700335403		[learning rate: 0.00027569]
	Learning Rate: 0.00027569
	LOSS [training: 0.40480806700335403 | validation: 0.37713273843005796]
	TIME [epoch: 9.44 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3090107273061052		[learning rate: 0.00027436]
	Learning Rate: 0.000274357
	LOSS [training: 0.3090107273061052 | validation: 0.32380754255446015]
	TIME [epoch: 9.44 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29970676825756454		[learning rate: 0.00027303]
	Learning Rate: 0.00027303
	LOSS [training: 0.29970676825756454 | validation: 0.3495049815960141]
	TIME [epoch: 9.45 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34001252339728966		[learning rate: 0.00027171]
	Learning Rate: 0.00027171
	LOSS [training: 0.34001252339728966 | validation: 0.3284462984411248]
	TIME [epoch: 9.46 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31115830203142913		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.31115830203142913 | validation: 0.3419293310128031]
	TIME [epoch: 9.45 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2774497561085072		[learning rate: 0.00026909]
	Learning Rate: 0.000269088
	LOSS [training: 0.2774497561085072 | validation: 0.29734048606142277]
	TIME [epoch: 9.45 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.280462363834704		[learning rate: 0.00026779]
	Learning Rate: 0.000267787
	LOSS [training: 0.280462363834704 | validation: 0.33044570052185734]
	TIME [epoch: 9.47 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28047570445321796		[learning rate: 0.00026649]
	Learning Rate: 0.000266492
	LOSS [training: 0.28047570445321796 | validation: 0.3100237691864095]
	TIME [epoch: 9.45 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2674179421885786		[learning rate: 0.0002652]
	Learning Rate: 0.000265203
	LOSS [training: 0.2674179421885786 | validation: 0.2915614843487249]
	TIME [epoch: 9.45 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24700281622616282		[learning rate: 0.00026392]
	Learning Rate: 0.000263921
	LOSS [training: 0.24700281622616282 | validation: 0.2869991853958623]
	TIME [epoch: 9.45 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2584930518845938		[learning rate: 0.00026264]
	Learning Rate: 0.000262645
	LOSS [training: 0.2584930518845938 | validation: 0.28378221863428127]
	TIME [epoch: 9.46 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23258941200552194		[learning rate: 0.00026137]
	Learning Rate: 0.000261374
	LOSS [training: 0.23258941200552194 | validation: 0.27913225225383964]
	TIME [epoch: 9.45 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24541189223471394		[learning rate: 0.00026011]
	Learning Rate: 0.00026011
	LOSS [training: 0.24541189223471394 | validation: 0.2592788345473073]
	TIME [epoch: 9.44 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21731448580876966		[learning rate: 0.00025885]
	Learning Rate: 0.000258853
	LOSS [training: 0.21731448580876966 | validation: 0.2704799426711462]
	TIME [epoch: 9.47 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22713752262408762		[learning rate: 0.0002576]
	Learning Rate: 0.000257601
	LOSS [training: 0.22713752262408762 | validation: 0.27012465724719564]
	TIME [epoch: 9.45 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2479597390228654		[learning rate: 0.00025636]
	Learning Rate: 0.000256355
	LOSS [training: 0.2479597390228654 | validation: 0.2845447851326813]
	TIME [epoch: 9.44 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24673979034947133		[learning rate: 0.00025512]
	Learning Rate: 0.000255115
	LOSS [training: 0.24673979034947133 | validation: 0.27357646468049224]
	TIME [epoch: 9.46 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24246287914881676		[learning rate: 0.00025388]
	Learning Rate: 0.000253882
	LOSS [training: 0.24246287914881676 | validation: 0.25916189999577255]
	TIME [epoch: 9.46 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24315122861803232		[learning rate: 0.00025265]
	Learning Rate: 0.000252654
	LOSS [training: 0.24315122861803232 | validation: 0.2641358651347123]
	TIME [epoch: 9.45 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22996257612125928		[learning rate: 0.00025143]
	Learning Rate: 0.000251432
	LOSS [training: 0.22996257612125928 | validation: 0.26710210887453506]
	TIME [epoch: 9.45 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24065741943446134		[learning rate: 0.00025022]
	Learning Rate: 0.000250216
	LOSS [training: 0.24065741943446134 | validation: 0.2705658676092986]
	TIME [epoch: 9.47 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21980451108555826		[learning rate: 0.00024901]
	Learning Rate: 0.000249006
	LOSS [training: 0.21980451108555826 | validation: 0.26424763243870647]
	TIME [epoch: 9.45 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23188914786343878		[learning rate: 0.0002478]
	Learning Rate: 0.000247802
	LOSS [training: 0.23188914786343878 | validation: 0.26702081079394374]
	TIME [epoch: 9.44 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22261204468919052		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.22261204468919052 | validation: 0.24495809338323304]
	TIME [epoch: 9.46 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2180420341476025		[learning rate: 0.00024541]
	Learning Rate: 0.000245411
	LOSS [training: 0.2180420341476025 | validation: 0.2465218925765308]
	TIME [epoch: 9.47 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21917819546501177		[learning rate: 0.00024422]
	Learning Rate: 0.000244225
	LOSS [training: 0.21917819546501177 | validation: 0.2344529320606082]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_816.pth
	Model improved!!!
EPOCH 817/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2093570563160882		[learning rate: 0.00024304]
	Learning Rate: 0.000243044
	LOSS [training: 0.2093570563160882 | validation: 0.25361405430982575]
	TIME [epoch: 9.45 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22201127586993752		[learning rate: 0.00024187]
	Learning Rate: 0.000241868
	LOSS [training: 0.22201127586993752 | validation: 0.24128813606822108]
	TIME [epoch: 9.46 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23779735633871485		[learning rate: 0.0002407]
	Learning Rate: 0.000240699
	LOSS [training: 0.23779735633871485 | validation: 0.28366420124044295]
	TIME [epoch: 9.44 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23552972127484847		[learning rate: 0.00023953]
	Learning Rate: 0.000239535
	LOSS [training: 0.23552972127484847 | validation: 0.23877073739091864]
	TIME [epoch: 9.44 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21336454260384125		[learning rate: 0.00023838]
	Learning Rate: 0.000238376
	LOSS [training: 0.21336454260384125 | validation: 0.24472755901879914]
	TIME [epoch: 9.45 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22042202731481825		[learning rate: 0.00023722]
	Learning Rate: 0.000237224
	LOSS [training: 0.22042202731481825 | validation: 0.24825603659155504]
	TIME [epoch: 9.47 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23173810158213914		[learning rate: 0.00023608]
	Learning Rate: 0.000236076
	LOSS [training: 0.23173810158213914 | validation: 0.2977464478997905]
	TIME [epoch: 9.44 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24594235015021196		[learning rate: 0.00023493]
	Learning Rate: 0.000234935
	LOSS [training: 0.24594235015021196 | validation: 0.24632820201165215]
	TIME [epoch: 9.44 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2102073071285735		[learning rate: 0.0002338]
	Learning Rate: 0.000233799
	LOSS [training: 0.2102073071285735 | validation: 0.23587576764954332]
	TIME [epoch: 9.46 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21713988669150855		[learning rate: 0.00023267]
	Learning Rate: 0.000232668
	LOSS [training: 0.21713988669150855 | validation: 0.26348379367607955]
	TIME [epoch: 9.44 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22184050206388833		[learning rate: 0.00023154]
	Learning Rate: 0.000231543
	LOSS [training: 0.22184050206388833 | validation: 0.2854732154272857]
	TIME [epoch: 9.44 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24297432966286228		[learning rate: 0.00023042]
	Learning Rate: 0.000230423
	LOSS [training: 0.24297432966286228 | validation: 0.28727995250524674]
	TIME [epoch: 9.44 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23329333844073924		[learning rate: 0.00022931]
	Learning Rate: 0.000229309
	LOSS [training: 0.23329333844073924 | validation: 0.2499033174243464]
	TIME [epoch: 9.46 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20858511128355794		[learning rate: 0.0002282]
	Learning Rate: 0.0002282
	LOSS [training: 0.20858511128355794 | validation: 0.26884309188329936]
	TIME [epoch: 9.43 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.215303717581322		[learning rate: 0.0002271]
	Learning Rate: 0.000227097
	LOSS [training: 0.215303717581322 | validation: 0.2700041358722615]
	TIME [epoch: 9.44 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24553622324318364		[learning rate: 0.000226]
	Learning Rate: 0.000225998
	LOSS [training: 0.24553622324318364 | validation: 0.3115040837249204]
	TIME [epoch: 9.46 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23558814144118362		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.23558814144118362 | validation: 0.26406953409662737]
	TIME [epoch: 9.45 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21499923805613924		[learning rate: 0.00022382]
	Learning Rate: 0.000223818
	LOSS [training: 0.21499923805613924 | validation: 0.26134093976941003]
	TIME [epoch: 9.44 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22702618374904757		[learning rate: 0.00022274]
	Learning Rate: 0.000222736
	LOSS [training: 0.22702618374904757 | validation: 0.2945983632543815]
	TIME [epoch: 9.45 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2401564830631903		[learning rate: 0.00022166]
	Learning Rate: 0.000221658
	LOSS [training: 0.2401564830631903 | validation: 0.25786045419871256]
	TIME [epoch: 9.46 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20811315056655108		[learning rate: 0.00022059]
	Learning Rate: 0.000220587
	LOSS [training: 0.20811315056655108 | validation: 0.2482239119992562]
	TIME [epoch: 9.44 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20731194602023226		[learning rate: 0.00021952]
	Learning Rate: 0.00021952
	LOSS [training: 0.20731194602023226 | validation: 0.25780328636609307]
	TIME [epoch: 9.44 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23173896048071635		[learning rate: 0.00021846]
	Learning Rate: 0.000218458
	LOSS [training: 0.23173896048071635 | validation: 0.2698299555791992]
	TIME [epoch: 9.46 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2259611437629739		[learning rate: 0.0002174]
	Learning Rate: 0.000217402
	LOSS [training: 0.2259611437629739 | validation: 0.2615143192805142]
	TIME [epoch: 9.44 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22622470039273343		[learning rate: 0.00021635]
	Learning Rate: 0.00021635
	LOSS [training: 0.22622470039273343 | validation: 0.29300421048990144]
	TIME [epoch: 9.44 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2753508996591999		[learning rate: 0.0002153]
	Learning Rate: 0.000215304
	LOSS [training: 0.2753508996591999 | validation: 0.27569254300863116]
	TIME [epoch: 9.45 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2571925677021392		[learning rate: 0.00021426]
	Learning Rate: 0.000214263
	LOSS [training: 0.2571925677021392 | validation: 0.27275239011042135]
	TIME [epoch: 9.46 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24411527508139047		[learning rate: 0.00021323]
	Learning Rate: 0.000213227
	LOSS [training: 0.24411527508139047 | validation: 0.2581021849374085]
	TIME [epoch: 9.45 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23413050133649121		[learning rate: 0.0002122]
	Learning Rate: 0.000212196
	LOSS [training: 0.23413050133649121 | validation: 0.28377418741768806]
	TIME [epoch: 9.45 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24447132982705497		[learning rate: 0.00021117]
	Learning Rate: 0.00021117
	LOSS [training: 0.24447132982705497 | validation: 0.26798490352107424]
	TIME [epoch: 9.47 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2488913304251393		[learning rate: 0.00021015]
	Learning Rate: 0.000210149
	LOSS [training: 0.2488913304251393 | validation: 0.2787618018474673]
	TIME [epoch: 9.45 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24883414034637888		[learning rate: 0.00020913]
	Learning Rate: 0.000209132
	LOSS [training: 0.24883414034637888 | validation: 0.28010659609852534]
	TIME [epoch: 9.44 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2233868458504323		[learning rate: 0.00020812]
	Learning Rate: 0.000208121
	LOSS [training: 0.2233868458504323 | validation: 0.25561525842796023]
	TIME [epoch: 9.45 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22478311290671898		[learning rate: 0.00020711]
	Learning Rate: 0.000207114
	LOSS [training: 0.22478311290671898 | validation: 0.24714320603931306]
	TIME [epoch: 9.47 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22856551705584177		[learning rate: 0.00020611]
	Learning Rate: 0.000206113
	LOSS [training: 0.22856551705584177 | validation: 0.2661777313015436]
	TIME [epoch: 9.45 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21844157931880487		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.21844157931880487 | validation: 0.24328982842996777]
	TIME [epoch: 9.45 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21345284936267417		[learning rate: 0.00020412]
	Learning Rate: 0.000204124
	LOSS [training: 0.21345284936267417 | validation: 0.24669260731451592]
	TIME [epoch: 9.47 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20231188501227382		[learning rate: 0.00020314]
	Learning Rate: 0.000203137
	LOSS [training: 0.20231188501227382 | validation: 0.23710872143693862]
	TIME [epoch: 9.45 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2016175109830068		[learning rate: 0.00020215]
	Learning Rate: 0.000202155
	LOSS [training: 0.2016175109830068 | validation: 0.260621002143808]
	TIME [epoch: 9.44 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21286382614452276		[learning rate: 0.00020118]
	Learning Rate: 0.000201177
	LOSS [training: 0.21286382614452276 | validation: 0.2497697399494458]
	TIME [epoch: 9.45 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20509583360864117		[learning rate: 0.0002002]
	Learning Rate: 0.000200204
	LOSS [training: 0.20509583360864117 | validation: 0.242069272346914]
	TIME [epoch: 9.46 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20568450602033733		[learning rate: 0.00019924]
	Learning Rate: 0.000199236
	LOSS [training: 0.20568450602033733 | validation: 0.25141854962487004]
	TIME [epoch: 9.44 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2084091832520576		[learning rate: 0.00019827]
	Learning Rate: 0.000198273
	LOSS [training: 0.2084091832520576 | validation: 0.25179002623114705]
	TIME [epoch: 9.45 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20561267879466566		[learning rate: 0.00019731]
	Learning Rate: 0.000197314
	LOSS [training: 0.20561267879466566 | validation: 0.2351997811043757]
	TIME [epoch: 9.47 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20239809302919826		[learning rate: 0.00019636]
	Learning Rate: 0.00019636
	LOSS [training: 0.20239809302919826 | validation: 0.2539907942091578]
	TIME [epoch: 9.44 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2039786080571048		[learning rate: 0.00019541]
	Learning Rate: 0.00019541
	LOSS [training: 0.2039786080571048 | validation: 0.2591777263035609]
	TIME [epoch: 9.44 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19828627450618236		[learning rate: 0.00019447]
	Learning Rate: 0.000194465
	LOSS [training: 0.19828627450618236 | validation: 0.2590911791594841]
	TIME [epoch: 9.45 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2076802144316814		[learning rate: 0.00019352]
	Learning Rate: 0.000193525
	LOSS [training: 0.2076802144316814 | validation: 0.2984943451823407]
	TIME [epoch: 9.47 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21956216458881345		[learning rate: 0.00019259]
	Learning Rate: 0.000192589
	LOSS [training: 0.21956216458881345 | validation: 0.2797584232594541]
	TIME [epoch: 9.44 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22313063850718		[learning rate: 0.00019166]
	Learning Rate: 0.000191658
	LOSS [training: 0.22313063850718 | validation: 0.302006868843709]
	TIME [epoch: 9.44 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22498574532885907		[learning rate: 0.00019073]
	Learning Rate: 0.000190731
	LOSS [training: 0.22498574532885907 | validation: 0.3178523160501935]
	TIME [epoch: 9.47 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20345622522361437		[learning rate: 0.00018981]
	Learning Rate: 0.000189809
	LOSS [training: 0.20345622522361437 | validation: 0.292062915909273]
	TIME [epoch: 9.45 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21273257539901347		[learning rate: 0.00018889]
	Learning Rate: 0.000188891
	LOSS [training: 0.21273257539901347 | validation: 0.3070801049795004]
	TIME [epoch: 9.45 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.208366008377214		[learning rate: 0.00018798]
	Learning Rate: 0.000187977
	LOSS [training: 0.208366008377214 | validation: 0.3246178998405755]
	TIME [epoch: 9.45 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2128615033808301		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.2128615033808301 | validation: 0.3199035626901308]
	TIME [epoch: 9.46 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21760498876423853		[learning rate: 0.00018616]
	Learning Rate: 0.000186164
	LOSS [training: 0.21760498876423853 | validation: 0.3317934679920012]
	TIME [epoch: 9.44 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22541665239938058		[learning rate: 0.00018526]
	Learning Rate: 0.000185263
	LOSS [training: 0.22541665239938058 | validation: 0.358305139881241]
	TIME [epoch: 9.45 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2341792770483741		[learning rate: 0.00018437]
	Learning Rate: 0.000184367
	LOSS [training: 0.2341792770483741 | validation: 0.35945172774184897]
	TIME [epoch: 9.46 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23083367457446266		[learning rate: 0.00018348]
	Learning Rate: 0.000183476
	LOSS [training: 0.23083367457446266 | validation: 0.36776128544048403]
	TIME [epoch: 9.45 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2622260364416575		[learning rate: 0.00018259]
	Learning Rate: 0.000182589
	LOSS [training: 0.2622260364416575 | validation: 0.4271929248641947]
	TIME [epoch: 9.45 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25777213551146455		[learning rate: 0.00018171]
	Learning Rate: 0.000181706
	LOSS [training: 0.25777213551146455 | validation: 0.4128842255689071]
	TIME [epoch: 9.45 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2409509752868199		[learning rate: 0.00018083]
	Learning Rate: 0.000180827
	LOSS [training: 0.2409509752868199 | validation: 0.3920393779525486]
	TIME [epoch: 9.46 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2474237750066827		[learning rate: 0.00017995]
	Learning Rate: 0.000179953
	LOSS [training: 0.2474237750066827 | validation: 0.4094654975609017]
	TIME [epoch: 9.45 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24684151106843594		[learning rate: 0.00017908]
	Learning Rate: 0.000179082
	LOSS [training: 0.24684151106843594 | validation: 0.39603204933090447]
	TIME [epoch: 9.45 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24131724912826108		[learning rate: 0.00017822]
	Learning Rate: 0.000178216
	LOSS [training: 0.24131724912826108 | validation: 0.44186077784129363]
	TIME [epoch: 9.47 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2525435105416416		[learning rate: 0.00017735]
	Learning Rate: 0.000177354
	LOSS [training: 0.2525435105416416 | validation: 0.37736720902113363]
	TIME [epoch: 9.45 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23432518532545626		[learning rate: 0.0001765]
	Learning Rate: 0.000176497
	LOSS [training: 0.23432518532545626 | validation: 0.3634514864605603]
	TIME [epoch: 9.45 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22116817885904866		[learning rate: 0.00017564]
	Learning Rate: 0.000175643
	LOSS [training: 0.22116817885904866 | validation: 0.3915425619598612]
	TIME [epoch: 9.45 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26197465659136193		[learning rate: 0.00017479]
	Learning Rate: 0.000174794
	LOSS [training: 0.26197465659136193 | validation: 0.449340193105254]
	TIME [epoch: 9.47 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28918682444471344		[learning rate: 0.00017395]
	Learning Rate: 0.000173949
	LOSS [training: 0.28918682444471344 | validation: 0.4771889609326533]
	TIME [epoch: 9.45 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.286649978147124		[learning rate: 0.00017311]
	Learning Rate: 0.000173107
	LOSS [training: 0.286649978147124 | validation: 0.42163592843968395]
	TIME [epoch: 9.44 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2717972326860272		[learning rate: 0.00017227]
	Learning Rate: 0.00017227
	LOSS [training: 0.2717972326860272 | validation: 0.45495913783877784]
	TIME [epoch: 9.47 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29822034381144863		[learning rate: 0.00017144]
	Learning Rate: 0.000171437
	LOSS [training: 0.29822034381144863 | validation: 0.44327927225517016]
	TIME [epoch: 9.45 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26094222853923577		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.26094222853923577 | validation: 0.40131588438669014]
	TIME [epoch: 9.45 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2414682700395434		[learning rate: 0.00016978]
	Learning Rate: 0.000169783
	LOSS [training: 0.2414682700395434 | validation: 0.36706255964619905]
	TIME [epoch: 9.45 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23462022997758986		[learning rate: 0.00016896]
	Learning Rate: 0.000168962
	LOSS [training: 0.23462022997758986 | validation: 0.42596177203144103]
	TIME [epoch: 9.47 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26020117591154335		[learning rate: 0.00016815]
	Learning Rate: 0.000168145
	LOSS [training: 0.26020117591154335 | validation: 0.39453558473539124]
	TIME [epoch: 9.45 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2599408856150435		[learning rate: 0.00016733]
	Learning Rate: 0.000167332
	LOSS [training: 0.2599408856150435 | validation: 0.393116253263257]
	TIME [epoch: 9.45 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24292242834718922		[learning rate: 0.00016652]
	Learning Rate: 0.000166523
	LOSS [training: 0.24292242834718922 | validation: 0.3508214708081124]
	TIME [epoch: 9.47 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2302080923406724		[learning rate: 0.00016572]
	Learning Rate: 0.000165718
	LOSS [training: 0.2302080923406724 | validation: 0.3573157376920838]
	TIME [epoch: 9.45 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23890832904756382		[learning rate: 0.00016492]
	Learning Rate: 0.000164916
	LOSS [training: 0.23890832904756382 | validation: 0.34578078681482427]
	TIME [epoch: 9.45 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2244176944768741		[learning rate: 0.00016412]
	Learning Rate: 0.000164119
	LOSS [training: 0.2244176944768741 | validation: 0.29211096881517273]
	TIME [epoch: 9.45 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21656607013078594		[learning rate: 0.00016332]
	Learning Rate: 0.000163325
	LOSS [training: 0.21656607013078594 | validation: 0.2967828259436021]
	TIME [epoch: 9.46 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21071385033561268		[learning rate: 0.00016254]
	Learning Rate: 0.000162535
	LOSS [training: 0.21071385033561268 | validation: 0.28389704258328946]
	TIME [epoch: 9.45 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22875754461609973		[learning rate: 0.00016175]
	Learning Rate: 0.000161749
	LOSS [training: 0.22875754461609973 | validation: 0.29284271908160775]
	TIME [epoch: 9.45 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2331553056472641		[learning rate: 0.00016097]
	Learning Rate: 0.000160967
	LOSS [training: 0.2331553056472641 | validation: 0.2868116888211713]
	TIME [epoch: 9.47 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27582989671578934		[learning rate: 0.00016019]
	Learning Rate: 0.000160189
	LOSS [training: 0.27582989671578934 | validation: 0.3554657138597913]
	TIME [epoch: 9.45 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2515341295339158		[learning rate: 0.00015941]
	Learning Rate: 0.000159414
	LOSS [training: 0.2515341295339158 | validation: 0.3138092870688529]
	TIME [epoch: 9.45 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23434880133072894		[learning rate: 0.00015864]
	Learning Rate: 0.000158643
	LOSS [training: 0.23434880133072894 | validation: 0.2932375277539485]
	TIME [epoch: 9.45 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21829690200141744		[learning rate: 0.00015788]
	Learning Rate: 0.000157876
	LOSS [training: 0.21829690200141744 | validation: 0.2896556406492368]
	TIME [epoch: 9.47 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2469828266664326		[learning rate: 0.00015711]
	Learning Rate: 0.000157112
	LOSS [training: 0.2469828266664326 | validation: 0.31548913719081034]
	TIME [epoch: 9.45 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2645348776772737		[learning rate: 0.00015635]
	Learning Rate: 0.000156353
	LOSS [training: 0.2645348776772737 | validation: 0.32121124461856454]
	TIME [epoch: 9.45 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25896752696499015		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.25896752696499015 | validation: 0.29330450802640645]
	TIME [epoch: 9.47 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24264309646638935		[learning rate: 0.00015484]
	Learning Rate: 0.000154844
	LOSS [training: 0.24264309646638935 | validation: 0.2811106665113691]
	TIME [epoch: 9.45 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22874712311258466		[learning rate: 0.0001541]
	Learning Rate: 0.000154095
	LOSS [training: 0.22874712311258466 | validation: 0.27572343397474725]
	TIME [epoch: 9.45 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24325231453536106		[learning rate: 0.00015335]
	Learning Rate: 0.00015335
	LOSS [training: 0.24325231453536106 | validation: 0.3192227842918262]
	TIME [epoch: 9.45 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2531422595408274		[learning rate: 0.00015261]
	Learning Rate: 0.000152609
	LOSS [training: 0.2531422595408274 | validation: 0.3216658518235518]
	TIME [epoch: 9.46 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2377999692201686		[learning rate: 0.00015187]
	Learning Rate: 0.000151871
	LOSS [training: 0.2377999692201686 | validation: 0.3051767697292456]
	TIME [epoch: 9.44 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22593924573336105		[learning rate: 0.00015114]
	Learning Rate: 0.000151136
	LOSS [training: 0.22593924573336105 | validation: 0.3256980525659249]
	TIME [epoch: 9.45 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24553708433765475		[learning rate: 0.00015041]
	Learning Rate: 0.000150405
	LOSS [training: 0.24553708433765475 | validation: 0.3247632634959761]
	TIME [epoch: 9.47 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25332308569485057		[learning rate: 0.00014968]
	Learning Rate: 0.000149678
	LOSS [training: 0.25332308569485057 | validation: 0.35296616700619415]
	TIME [epoch: 9.45 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26355800247145267		[learning rate: 0.00014895]
	Learning Rate: 0.000148954
	LOSS [training: 0.26355800247145267 | validation: 0.34691848806039877]
	TIME [epoch: 9.45 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2617548413962438		[learning rate: 0.00014823]
	Learning Rate: 0.000148234
	LOSS [training: 0.2617548413962438 | validation: 0.2995020937789723]
	TIME [epoch: 9.45 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22878985548072608		[learning rate: 0.00014752]
	Learning Rate: 0.000147517
	LOSS [training: 0.22878985548072608 | validation: 0.29582089787242466]
	TIME [epoch: 9.46 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23107905270293383		[learning rate: 0.0001468]
	Learning Rate: 0.000146804
	LOSS [training: 0.23107905270293383 | validation: 0.3192842029578199]
	TIME [epoch: 9.45 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22586995631455925		[learning rate: 0.00014609]
	Learning Rate: 0.000146094
	LOSS [training: 0.22586995631455925 | validation: 0.36089384399145913]
	TIME [epoch: 9.45 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24188048912547533		[learning rate: 0.00014539]
	Learning Rate: 0.000145387
	LOSS [training: 0.24188048912547533 | validation: 0.3068531580257831]
	TIME [epoch: 9.47 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23401631544657545		[learning rate: 0.00014468]
	Learning Rate: 0.000144684
	LOSS [training: 0.23401631544657545 | validation: 0.2768445323837228]
	TIME [epoch: 9.45 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2439709297112523		[learning rate: 0.00014398]
	Learning Rate: 0.000143985
	LOSS [training: 0.2439709297112523 | validation: 0.29953326479674625]
	TIME [epoch: 9.45 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2475534591054102		[learning rate: 0.00014329]
	Learning Rate: 0.000143288
	LOSS [training: 0.2475534591054102 | validation: 0.3050660374622574]
	TIME [epoch: 9.45 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2593069974387102		[learning rate: 0.0001426]
	Learning Rate: 0.000142595
	LOSS [training: 0.2593069974387102 | validation: 0.3085152533946495]
	TIME [epoch: 9.46 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2526003961968125		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.2526003961968125 | validation: 0.30043334886959966]
	TIME [epoch: 9.44 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25185553996108356		[learning rate: 0.00014122]
	Learning Rate: 0.000141219
	LOSS [training: 0.25185553996108356 | validation: 0.2993200108767523]
	TIME [epoch: 9.44 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24517109745563173		[learning rate: 0.00014054]
	Learning Rate: 0.000140537
	LOSS [training: 0.24517109745563173 | validation: 0.28894902522226695]
	TIME [epoch: 9.47 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21654409126158755		[learning rate: 0.00013986]
	Learning Rate: 0.000139857
	LOSS [training: 0.21654409126158755 | validation: 0.277795753927819]
	TIME [epoch: 9.44 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2127178939906907		[learning rate: 0.00013918]
	Learning Rate: 0.000139181
	LOSS [training: 0.2127178939906907 | validation: 0.2710787187321274]
	TIME [epoch: 9.45 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21799212365701476		[learning rate: 0.00013851]
	Learning Rate: 0.000138508
	LOSS [training: 0.21799212365701476 | validation: 0.260877643185471]
	TIME [epoch: 9.45 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21929734998426453		[learning rate: 0.00013784]
	Learning Rate: 0.000137838
	LOSS [training: 0.21929734998426453 | validation: 0.26102333894018626]
	TIME [epoch: 9.47 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22225678493433962		[learning rate: 0.00013717]
	Learning Rate: 0.000137171
	LOSS [training: 0.22225678493433962 | validation: 0.2949062900164266]
	TIME [epoch: 9.45 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2515345216294044		[learning rate: 0.00013651]
	Learning Rate: 0.000136508
	LOSS [training: 0.2515345216294044 | validation: 0.30630560509340954]
	TIME [epoch: 9.45 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24698712662348243		[learning rate: 0.00013585]
	Learning Rate: 0.000135848
	LOSS [training: 0.24698712662348243 | validation: 0.29306773877445663]
	TIME [epoch: 9.46 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25269340504874105		[learning rate: 0.00013519]
	Learning Rate: 0.000135191
	LOSS [training: 0.25269340504874105 | validation: 0.28430335492204867]
	TIME [epoch: 9.45 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2519222657019623		[learning rate: 0.00013454]
	Learning Rate: 0.000134537
	LOSS [training: 0.2519222657019623 | validation: 0.3063026317408341]
	TIME [epoch: 9.44 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2541224549465362		[learning rate: 0.00013389]
	Learning Rate: 0.000133887
	LOSS [training: 0.2541224549465362 | validation: 0.27500349596089785]
	TIME [epoch: 9.45 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2596866001475413		[learning rate: 0.00013324]
	Learning Rate: 0.000133239
	LOSS [training: 0.2596866001475413 | validation: 0.28483608418605794]
	TIME [epoch: 9.46 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24311948581458803		[learning rate: 0.00013259]
	Learning Rate: 0.000132595
	LOSS [training: 0.24311948581458803 | validation: 0.29572709868096647]
	TIME [epoch: 9.45 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24996810754220466		[learning rate: 0.00013195]
	Learning Rate: 0.000131954
	LOSS [training: 0.24996810754220466 | validation: 0.26944791575790616]
	TIME [epoch: 9.45 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2424330789263441		[learning rate: 0.00013132]
	Learning Rate: 0.000131315
	LOSS [training: 0.2424330789263441 | validation: 0.2966650756455514]
	TIME [epoch: 9.47 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2440433743876139		[learning rate: 0.00013068]
	Learning Rate: 0.00013068
	LOSS [training: 0.2440433743876139 | validation: 0.2873982055701901]
	TIME [epoch: 9.45 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23524274048061095		[learning rate: 0.00013005]
	Learning Rate: 0.000130048
	LOSS [training: 0.23524274048061095 | validation: 0.26196419017270633]
	TIME [epoch: 9.45 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22415164978049723		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.22415164978049723 | validation: 0.27879859515685756]
	TIME [epoch: 9.45 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20655906763983753		[learning rate: 0.00012879]
	Learning Rate: 0.000128794
	LOSS [training: 0.20655906763983753 | validation: 0.28235406178984035]
	TIME [epoch: 9.46 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21363991181570086		[learning rate: 0.00012817]
	Learning Rate: 0.000128171
	LOSS [training: 0.21363991181570086 | validation: 0.26627392079995155]
	TIME [epoch: 9.45 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2149515343254152		[learning rate: 0.00012755]
	Learning Rate: 0.000127551
	LOSS [training: 0.2149515343254152 | validation: 0.2531016953261368]
	TIME [epoch: 9.45 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22486542918964228		[learning rate: 0.00012693]
	Learning Rate: 0.000126934
	LOSS [training: 0.22486542918964228 | validation: 0.2667951676605513]
	TIME [epoch: 9.47 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22513151011858795		[learning rate: 0.00012632]
	Learning Rate: 0.00012632
	LOSS [training: 0.22513151011858795 | validation: 0.28517845468283237]
	TIME [epoch: 9.45 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2352781130812663		[learning rate: 0.00012571]
	Learning Rate: 0.00012571
	LOSS [training: 0.2352781130812663 | validation: 0.2679005469124605]
	TIME [epoch: 9.44 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22570747752499712		[learning rate: 0.0001251]
	Learning Rate: 0.000125102
	LOSS [training: 0.22570747752499712 | validation: 0.2691630774903577]
	TIME [epoch: 9.46 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22958009608196		[learning rate: 0.0001245]
	Learning Rate: 0.000124497
	LOSS [training: 0.22958009608196 | validation: 0.29569966442573614]
	TIME [epoch: 9.46 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2567338295234257		[learning rate: 0.00012389]
	Learning Rate: 0.000123895
	LOSS [training: 0.2567338295234257 | validation: 0.3064210072855403]
	TIME [epoch: 9.45 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23800451581167725		[learning rate: 0.0001233]
	Learning Rate: 0.000123296
	LOSS [training: 0.23800451581167725 | validation: 0.25939900964666535]
	TIME [epoch: 9.45 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2156970743573002		[learning rate: 0.0001227]
	Learning Rate: 0.000122699
	LOSS [training: 0.2156970743573002 | validation: 0.2518145823692101]
	TIME [epoch: 9.46 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21864256482629849		[learning rate: 0.00012211]
	Learning Rate: 0.000122106
	LOSS [training: 0.21864256482629849 | validation: 0.2628487160450264]
	TIME [epoch: 9.45 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22358821895207984		[learning rate: 0.00012152]
	Learning Rate: 0.000121515
	LOSS [training: 0.22358821895207984 | validation: 0.2726203631466636]
	TIME [epoch: 9.44 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23998912857094196		[learning rate: 0.00012093]
	Learning Rate: 0.000120928
	LOSS [training: 0.23998912857094196 | validation: 0.27629464677592735]
	TIME [epoch: 9.45 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23163650548660725		[learning rate: 0.00012034]
	Learning Rate: 0.000120343
	LOSS [training: 0.23163650548660725 | validation: 0.2800559255239136]
	TIME [epoch: 9.47 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22932834314160555		[learning rate: 0.00011976]
	Learning Rate: 0.000119761
	LOSS [training: 0.22932834314160555 | validation: 0.26341661895969715]
	TIME [epoch: 9.45 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22843054913708105		[learning rate: 0.00011918]
	Learning Rate: 0.000119182
	LOSS [training: 0.22843054913708105 | validation: 0.25900769983024513]
	TIME [epoch: 9.45 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21297248456404852		[learning rate: 0.00011861]
	Learning Rate: 0.000118606
	LOSS [training: 0.21297248456404852 | validation: 0.23232007989242864]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_965.pth
	Model improved!!!
EPOCH 966/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21636270842923647		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.21636270842923647 | validation: 0.24435352859191525]
	TIME [epoch: 9.45 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21337788893704115		[learning rate: 0.00011746]
	Learning Rate: 0.000117461
	LOSS [training: 0.21337788893704115 | validation: 0.23985147921487548]
	TIME [epoch: 9.44 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2172552583823233		[learning rate: 0.00011689]
	Learning Rate: 0.000116893
	LOSS [training: 0.2172552583823233 | validation: 0.23678111902082538]
	TIME [epoch: 9.45 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21815642479959707		[learning rate: 0.00011633]
	Learning Rate: 0.000116328
	LOSS [training: 0.21815642479959707 | validation: 0.22228444462885372]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240218_115020/states/model_tr_study5_969.pth
	Model improved!!!
EPOCH 970/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20031223756905278		[learning rate: 0.00011577]
	Learning Rate: 0.000115765
	LOSS [training: 0.20031223756905278 | validation: 0.2574655449663354]
	TIME [epoch: 9.45 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20700692556279782		[learning rate: 0.00011521]
	Learning Rate: 0.000115206
	LOSS [training: 0.20700692556279782 | validation: 0.2436104958482505]
	TIME [epoch: 9.44 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2094717695727375		[learning rate: 0.00011465]
	Learning Rate: 0.000114649
	LOSS [training: 0.2094717695727375 | validation: 0.2603612658171949]
	TIME [epoch: 9.46 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20917770430512048		[learning rate: 0.00011409]
	Learning Rate: 0.000114094
	LOSS [training: 0.20917770430512048 | validation: 0.24179584577415944]
	TIME [epoch: 9.44 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21055876137668336		[learning rate: 0.00011354]
	Learning Rate: 0.000113542
	LOSS [training: 0.21055876137668336 | validation: 0.24733361690342745]
	TIME [epoch: 9.44 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19782160128515558		[learning rate: 0.00011299]
	Learning Rate: 0.000112993
	LOSS [training: 0.19782160128515558 | validation: 0.25867435576812875]
	TIME [epoch: 9.45 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21393002380477438		[learning rate: 0.00011245]
	Learning Rate: 0.000112447
	LOSS [training: 0.21393002380477438 | validation: 0.23128113333335443]
	TIME [epoch: 9.46 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20542498388028946		[learning rate: 0.0001119]
	Learning Rate: 0.000111903
	LOSS [training: 0.20542498388028946 | validation: 0.2478456393690674]
	TIME [epoch: 9.44 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19656513781716606		[learning rate: 0.00011136]
	Learning Rate: 0.000111362
	LOSS [training: 0.19656513781716606 | validation: 0.24492996746206566]
	TIME [epoch: 9.44 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.203229326736795		[learning rate: 0.00011082]
	Learning Rate: 0.000110823
	LOSS [training: 0.203229326736795 | validation: 0.23679197925216217]
	TIME [epoch: 9.46 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20359421119481155		[learning rate: 0.00011029]
	Learning Rate: 0.000110288
	LOSS [training: 0.20359421119481155 | validation: 0.24423867190946966]
	TIME [epoch: 9.44 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20021687166602153		[learning rate: 0.00010975]
	Learning Rate: 0.000109754
	LOSS [training: 0.20021687166602153 | validation: 0.23908996745397598]
	TIME [epoch: 9.44 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2004528218531727		[learning rate: 0.00010922]
	Learning Rate: 0.000109223
	LOSS [training: 0.2004528218531727 | validation: 0.2713253510854009]
	TIME [epoch: 9.45 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20171447272165324		[learning rate: 0.0001087]
	Learning Rate: 0.000108695
	LOSS [training: 0.20171447272165324 | validation: 0.2532801723467551]
	TIME [epoch: 9.46 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1986593458425321		[learning rate: 0.00010817]
	Learning Rate: 0.00010817
	LOSS [training: 0.1986593458425321 | validation: 0.25093361551009946]
	TIME [epoch: 9.44 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2016350084736342		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.2016350084736342 | validation: 0.2559553776241815]
	TIME [epoch: 9.44 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20903712074817973		[learning rate: 0.00010713]
	Learning Rate: 0.000107126
	LOSS [training: 0.20903712074817973 | validation: 0.2773751872295959]
	TIME [epoch: 9.47 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20704719890128187		[learning rate: 0.00010661]
	Learning Rate: 0.000106608
	LOSS [training: 0.20704719890128187 | validation: 0.2533761394122674]
	TIME [epoch: 9.44 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20730316332184834		[learning rate: 0.00010609]
	Learning Rate: 0.000106092
	LOSS [training: 0.20730316332184834 | validation: 0.26680215615371317]
	TIME [epoch: 9.44 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21375094683305096		[learning rate: 0.00010558]
	Learning Rate: 0.000105579
	LOSS [training: 0.21375094683305096 | validation: 0.23860627610379348]
	TIME [epoch: 9.45 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21135142603176033		[learning rate: 0.00010507]
	Learning Rate: 0.000105069
	LOSS [training: 0.21135142603176033 | validation: 0.2741809986845183]
	TIME [epoch: 9.46 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21337818362761288		[learning rate: 0.00010456]
	Learning Rate: 0.000104561
	LOSS [training: 0.21337818362761288 | validation: 0.24558517655580572]
	TIME [epoch: 9.44 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20540174615668905		[learning rate: 0.00010406]
	Learning Rate: 0.000104055
	LOSS [training: 0.20540174615668905 | validation: 0.2547058563276292]
	TIME [epoch: 9.45 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2047004730285836		[learning rate: 0.00010355]
	Learning Rate: 0.000103552
	LOSS [training: 0.2047004730285836 | validation: 0.2502026294681586]
	TIME [epoch: 9.46 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20232894451650663		[learning rate: 0.00010305]
	Learning Rate: 0.000103051
	LOSS [training: 0.20232894451650663 | validation: 0.2691915105886149]
	TIME [epoch: 9.45 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20394842223990634		[learning rate: 0.00010255]
	Learning Rate: 0.000102553
	LOSS [training: 0.20394842223990634 | validation: 0.23381098467143444]
	TIME [epoch: 9.44 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2018906333541472		[learning rate: 0.00010206]
	Learning Rate: 0.000102057
	LOSS [training: 0.2018906333541472 | validation: 0.26052113533680094]
	TIME [epoch: 9.45 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20803629847228794		[learning rate: 0.00010156]
	Learning Rate: 0.000101563
	LOSS [training: 0.20803629847228794 | validation: 0.259808475821634]
	TIME [epoch: 9.46 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1945045798872535		[learning rate: 0.00010107]
	Learning Rate: 0.000101072
	LOSS [training: 0.1945045798872535 | validation: 0.24500245025817247]
	TIME [epoch: 9.44 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19753707578717633		[learning rate: 0.00010058]
	Learning Rate: 0.000100583
	LOSS [training: 0.19753707578717633 | validation: 0.25073408892245713]
	TIME [epoch: 9.44 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18851693123572427		[learning rate: 0.0001001]
	Learning Rate: 0.000100097
	LOSS [training: 0.18851693123572427 | validation: 0.25742617110381555]
	TIME [epoch: 9.46 sec]
Finished training in 9576.347 seconds.
