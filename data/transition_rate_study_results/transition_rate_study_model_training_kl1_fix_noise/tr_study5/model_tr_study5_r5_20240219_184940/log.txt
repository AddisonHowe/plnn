Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r5', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4009595251

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.747526866343268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.747526866343268 | validation: 11.39403865201999]
	TIME [epoch: 80.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.246284056492135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.246284056492135 | validation: 11.161104900192582]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.540547814713813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.540547814713813 | validation: 11.301784595627506]
	TIME [epoch: 9.62 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.392037883549099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.392037883549099 | validation: 11.357131849702347]
	TIME [epoch: 9.6 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.21299507547454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.21299507547454 | validation: 10.804837195290316]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.958673732105458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.958673732105458 | validation: 10.878070942918772]
	TIME [epoch: 9.58 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.920079607350766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.920079607350766 | validation: 11.118698718949986]
	TIME [epoch: 9.61 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.105868924909494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.105868924909494 | validation: 10.535823149400882]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.791206588527197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.791206588527197 | validation: 10.318095989751951]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.193432099240699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.193432099240699 | validation: 10.747402590922025]
	TIME [epoch: 9.58 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.799038162562528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.799038162562528 | validation: 10.227586841033279]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.224353635584777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.224353635584777 | validation: 10.07474608548966]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.98530667393852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.98530667393852 | validation: 9.820675978897027]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.542715075591307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.542715075591307 | validation: 9.484037928708629]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.629525929335664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.629525929335664 | validation: 9.699639500324084]
	TIME [epoch: 9.61 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.699907457697535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.699907457697535 | validation: 9.737359440301171]
	TIME [epoch: 9.59 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.043761886129171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.043761886129171 | validation: 9.615147534400661]
	TIME [epoch: 9.57 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.592846093597927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.592846093597927 | validation: 10.279500340780343]
	TIME [epoch: 9.62 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.487590902789982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.487590902789982 | validation: 8.531893438779473]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.216552627417975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.216552627417975 | validation: 7.823050056388922]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.085985581395031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.085985581395031 | validation: 7.7324839190680335]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.200971204320052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.200971204320052 | validation: 7.939390465722887]
	TIME [epoch: 9.61 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.467805196966543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.467805196966543 | validation: 9.391972176243508]
	TIME [epoch: 9.58 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.448858526657372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.448858526657372 | validation: 7.650635520451626]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.697092561529997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.697092561529997 | validation: 7.832507834276416]
	TIME [epoch: 9.6 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.677685901711433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.677685901711433 | validation: 8.94033795362282]
	TIME [epoch: 9.58 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.474911908674845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.474911908674845 | validation: 7.401245390996003]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.636578857579737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.636578857579737 | validation: 8.015050170917915]
	TIME [epoch: 9.59 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.11092504717891		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.11092504717891 | validation: 7.820638172280821]
	TIME [epoch: 9.6 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.449530384121819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.449530384121819 | validation: 9.118036843624676]
	TIME [epoch: 9.58 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.271370367071978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.271370367071978 | validation: 8.52572215805166]
	TIME [epoch: 9.59 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.325696855223317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.325696855223317 | validation: 9.00870081215737]
	TIME [epoch: 9.58 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.852528927554923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.852528927554923 | validation: 8.922842893851726]
	TIME [epoch: 9.59 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.814480446410111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.814480446410111 | validation: 7.249882516469793]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.768103592002873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.768103592002873 | validation: 7.397224803600716]
	TIME [epoch: 9.59 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.2833624569196616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.2833624569196616 | validation: 8.31069270644618]
	TIME [epoch: 9.58 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.610194510040546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.610194510040546 | validation: 7.2307792938225806]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.282414603408247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.282414603408247 | validation: 7.499784926212473]
	TIME [epoch: 9.59 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.161887433884232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.161887433884232 | validation: 7.3945385052954]
	TIME [epoch: 9.6 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.60408839777642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.60408839777642 | validation: 7.496508504991316]
	TIME [epoch: 9.63 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.4304352715517314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4304352715517314 | validation: 7.010518925312356]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.5017745431622584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.5017745431622584 | validation: 7.851505706794774]
	TIME [epoch: 9.59 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.27028749485496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.27028749485496 | validation: 7.2198609162352545]
	TIME [epoch: 9.57 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.807835388028641		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.807835388028641 | validation: 8.526676278674758]
	TIME [epoch: 9.62 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.7968122136884315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7968122136884315 | validation: 7.169347421880043]
	TIME [epoch: 9.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.386797217289064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.386797217289064 | validation: 7.04233043056842]
	TIME [epoch: 9.58 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.8007846072474525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8007846072474525 | validation: 7.98986194814712]
	TIME [epoch: 9.59 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.149980431951781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.149980431951781 | validation: 7.432447926427302]
	TIME [epoch: 9.63 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.992688172897624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.992688172897624 | validation: 7.040981410755838]
	TIME [epoch: 9.6 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.349723925783772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.349723925783772 | validation: 7.902859550634013]
	TIME [epoch: 9.6 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.384245016213284		[learning rate: 0.0099811]
	Learning Rate: 0.00998112
	LOSS [training: 6.384245016213284 | validation: 7.0418385645154755]
	TIME [epoch: 9.61 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.964507807370884		[learning rate: 0.0099576]
	Learning Rate: 0.00995758
	LOSS [training: 5.964507807370884 | validation: 6.933353161346154]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.752929325591872		[learning rate: 0.0099341]
	Learning Rate: 0.00993409
	LOSS [training: 5.752929325591872 | validation: 7.021679315470192]
	TIME [epoch: 9.57 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.862708293719804		[learning rate: 0.0099107]
	Learning Rate: 0.00991066
	LOSS [training: 5.862708293719804 | validation: 7.354980828324399]
	TIME [epoch: 9.58 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.885866474926407		[learning rate: 0.0098873]
	Learning Rate: 0.00988728
	LOSS [training: 5.885866474926407 | validation: 7.071446314802754]
	TIME [epoch: 9.62 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.944140719690766		[learning rate: 0.009864]
	Learning Rate: 0.00986396
	LOSS [training: 5.944140719690766 | validation: 7.021965124571281]
	TIME [epoch: 9.59 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.621849274256941		[learning rate: 0.0098407]
	Learning Rate: 0.00984069
	LOSS [training: 5.621849274256941 | validation: 7.059740164962993]
	TIME [epoch: 9.59 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.764687864279362		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 5.764687864279362 | validation: 7.012382347611574]
	TIME [epoch: 9.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.667030349736522		[learning rate: 0.0097943]
	Learning Rate: 0.00979432
	LOSS [training: 5.667030349736522 | validation: 6.83591812964645]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.669816785148021		[learning rate: 0.0097712]
	Learning Rate: 0.00977122
	LOSS [training: 5.669816785148021 | validation: 6.883568147785884]
	TIME [epoch: 9.57 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.578424471368658		[learning rate: 0.0097482]
	Learning Rate: 0.00974817
	LOSS [training: 5.578424471368658 | validation: 6.825482266371469]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.561196980899551		[learning rate: 0.0097252]
	Learning Rate: 0.00972517
	LOSS [training: 5.561196980899551 | validation: 6.991098086796322]
	TIME [epoch: 9.59 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.804379274778878		[learning rate: 0.0097022]
	Learning Rate: 0.00970223
	LOSS [training: 5.804379274778878 | validation: 7.5336708303507525]
	TIME [epoch: 9.92 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.894553623129113		[learning rate: 0.0096793]
	Learning Rate: 0.00967935
	LOSS [training: 5.894553623129113 | validation: 6.623950568177088]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.380090993593024		[learning rate: 0.0096565]
	Learning Rate: 0.00965652
	LOSS [training: 5.380090993593024 | validation: 7.280505121788276]
	TIME [epoch: 9.58 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.529231223845221		[learning rate: 0.0096337]
	Learning Rate: 0.00963374
	LOSS [training: 5.529231223845221 | validation: 6.934868919238811]
	TIME [epoch: 9.61 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.465224171379333		[learning rate: 0.009611]
	Learning Rate: 0.00961101
	LOSS [training: 5.465224171379333 | validation: 6.518323895570932]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.430212162256212		[learning rate: 0.0095883]
	Learning Rate: 0.00958834
	LOSS [training: 5.430212162256212 | validation: 6.353165125841311]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.251716419403396		[learning rate: 0.0095657]
	Learning Rate: 0.00956573
	LOSS [training: 5.251716419403396 | validation: 6.392890147597759]
	TIME [epoch: 9.59 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.630899071162192		[learning rate: 0.0095432]
	Learning Rate: 0.00954316
	LOSS [training: 5.630899071162192 | validation: 6.403534995144469]
	TIME [epoch: 9.61 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.523312152697938		[learning rate: 0.0095207]
	Learning Rate: 0.00952065
	LOSS [training: 5.523312152697938 | validation: 6.5068631838119675]
	TIME [epoch: 9.59 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.366040993527003		[learning rate: 0.0094982]
	Learning Rate: 0.00949819
	LOSS [training: 5.366040993527003 | validation: 6.246253956373637]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.053782920167168		[learning rate: 0.0094758]
	Learning Rate: 0.00947579
	LOSS [training: 5.053782920167168 | validation: 6.400590970330365]
	TIME [epoch: 9.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.182150945189621		[learning rate: 0.0094534]
	Learning Rate: 0.00945344
	LOSS [training: 5.182150945189621 | validation: 6.543471483014027]
	TIME [epoch: 9.62 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.644072816522627		[learning rate: 0.0094311]
	Learning Rate: 0.00943114
	LOSS [training: 5.644072816522627 | validation: 7.392884548192458]
	TIME [epoch: 9.58 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.548528293650288		[learning rate: 0.0094089]
	Learning Rate: 0.00940889
	LOSS [training: 6.548528293650288 | validation: 6.782079117994895]
	TIME [epoch: 9.58 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.297903548875345		[learning rate: 0.0093867]
	Learning Rate: 0.0093867
	LOSS [training: 5.297903548875345 | validation: 6.851137419868264]
	TIME [epoch: 9.6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.045380890930167		[learning rate: 0.0093646]
	Learning Rate: 0.00936456
	LOSS [training: 5.045380890930167 | validation: 6.128473030017779]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.903749036041992		[learning rate: 0.0093425]
	Learning Rate: 0.00934247
	LOSS [training: 4.903749036041992 | validation: 5.866365187017309]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.8947301434722785		[learning rate: 0.0093204]
	Learning Rate: 0.00932043
	LOSS [training: 4.8947301434722785 | validation: 6.051526600890554]
	TIME [epoch: 9.59 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.8868378953257885		[learning rate: 0.0092984]
	Learning Rate: 0.00929844
	LOSS [training: 4.8868378953257885 | validation: 5.926302808899786]
	TIME [epoch: 9.62 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.910596004473069		[learning rate: 0.0092765]
	Learning Rate: 0.00927651
	LOSS [training: 4.910596004473069 | validation: 5.976814185785806]
	TIME [epoch: 9.59 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.72097193975044		[learning rate: 0.0092546]
	Learning Rate: 0.00925463
	LOSS [training: 4.72097193975044 | validation: 6.445296753423186]
	TIME [epoch: 9.59 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.590590224328727		[learning rate: 0.0092328]
	Learning Rate: 0.0092328
	LOSS [training: 5.590590224328727 | validation: 6.347846643448409]
	TIME [epoch: 9.59 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.934149479316322		[learning rate: 0.009211]
	Learning Rate: 0.00921102
	LOSS [training: 4.934149479316322 | validation: 6.271340796411705]
	TIME [epoch: 9.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.972327018885915		[learning rate: 0.0091893]
	Learning Rate: 0.00918929
	LOSS [training: 4.972327018885915 | validation: 5.868615306073893]
	TIME [epoch: 9.58 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.756988314246148		[learning rate: 0.0091676]
	Learning Rate: 0.00916762
	LOSS [training: 4.756988314246148 | validation: 5.8131634162831185]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.7288723653748095		[learning rate: 0.009146]
	Learning Rate: 0.00914599
	LOSS [training: 4.7288723653748095 | validation: 6.051387869766101]
	TIME [epoch: 9.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.643223334872214		[learning rate: 0.0091244]
	Learning Rate: 0.00912442
	LOSS [training: 4.643223334872214 | validation: 5.863025195010232]
	TIME [epoch: 9.62 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.7954255775208825		[learning rate: 0.0091029]
	Learning Rate: 0.00910289
	LOSS [training: 4.7954255775208825 | validation: 5.970009685107551]
	TIME [epoch: 9.6 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.992088020130317		[learning rate: 0.0090814]
	Learning Rate: 0.00908142
	LOSS [training: 4.992088020130317 | validation: 5.8557696983098895]
	TIME [epoch: 9.59 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.613841222068716		[learning rate: 0.00906]
	Learning Rate: 0.00906
	LOSS [training: 4.613841222068716 | validation: 5.700226506075317]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.134478602844382		[learning rate: 0.0090386]
	Learning Rate: 0.00903863
	LOSS [training: 5.134478602844382 | validation: 5.896911616110911]
	TIME [epoch: 9.61 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.7739503056388255		[learning rate: 0.0090173]
	Learning Rate: 0.00901731
	LOSS [training: 4.7739503056388255 | validation: 9.497626510674147]
	TIME [epoch: 9.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.317142625698808		[learning rate: 0.008996]
	Learning Rate: 0.00899604
	LOSS [training: 6.317142625698808 | validation: 5.71698901598624]
	TIME [epoch: 9.59 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.480542083622541		[learning rate: 0.0089748]
	Learning Rate: 0.00897482
	LOSS [training: 4.480542083622541 | validation: 5.493712994168089]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.441743929985916		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 4.441743929985916 | validation: 5.491954801456954]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.639214224913372		[learning rate: 0.0089325]
	Learning Rate: 0.00893253
	LOSS [training: 4.639214224913372 | validation: 6.116524599473346]
	TIME [epoch: 9.59 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.2514808469155145		[learning rate: 0.0089115]
	Learning Rate: 0.00891146
	LOSS [training: 5.2514808469155145 | validation: 5.7534985184801535]
	TIME [epoch: 9.58 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.099128190502009		[learning rate: 0.0088904]
	Learning Rate: 0.00889044
	LOSS [training: 5.099128190502009 | validation: 6.493881936004918]
	TIME [epoch: 9.61 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.3417615254907655		[learning rate: 0.0088695]
	Learning Rate: 0.00886946
	LOSS [training: 5.3417615254907655 | validation: 5.998551889762946]
	TIME [epoch: 9.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.7052890446639495		[learning rate: 0.0088485]
	Learning Rate: 0.00884854
	LOSS [training: 4.7052890446639495 | validation: 5.732562295976244]
	TIME [epoch: 9.59 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.611545158546045		[learning rate: 0.0088277]
	Learning Rate: 0.00882767
	LOSS [training: 4.611545158546045 | validation: 5.636035695145649]
	TIME [epoch: 9.59 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.554242182076696		[learning rate: 0.0088068]
	Learning Rate: 0.00880685
	LOSS [training: 4.554242182076696 | validation: 5.788908062509548]
	TIME [epoch: 9.61 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.6643144528022855		[learning rate: 0.0087861]
	Learning Rate: 0.00878607
	LOSS [training: 4.6643144528022855 | validation: 5.569039453353392]
	TIME [epoch: 9.59 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.395257921838279		[learning rate: 0.0087653]
	Learning Rate: 0.00876535
	LOSS [training: 4.395257921838279 | validation: 5.45551132791123]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.475686363244481		[learning rate: 0.0087447]
	Learning Rate: 0.00874467
	LOSS [training: 5.475686363244481 | validation: 6.188497532956752]
	TIME [epoch: 9.61 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.009428089115317		[learning rate: 0.008724]
	Learning Rate: 0.00872405
	LOSS [training: 5.009428089115317 | validation: 5.549734794587861]
	TIME [epoch: 9.59 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.647646304515137		[learning rate: 0.0087035]
	Learning Rate: 0.00870347
	LOSS [training: 4.647646304515137 | validation: 6.349280551598797]
	TIME [epoch: 9.59 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.542776889619569		[learning rate: 0.0086829]
	Learning Rate: 0.00868294
	LOSS [training: 5.542776889619569 | validation: 5.938576742964747]
	TIME [epoch: 9.59 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.81889760668893		[learning rate: 0.0086625]
	Learning Rate: 0.00866246
	LOSS [training: 4.81889760668893 | validation: 5.734819933473837]
	TIME [epoch: 9.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.45896029779299		[learning rate: 0.008642]
	Learning Rate: 0.00864202
	LOSS [training: 4.45896029779299 | validation: 5.436843030939104]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.370384343560444		[learning rate: 0.0086216]
	Learning Rate: 0.00862164
	LOSS [training: 4.370384343560444 | validation: 5.515720385881141]
	TIME [epoch: 9.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.4434967616729875		[learning rate: 0.0086013]
	Learning Rate: 0.0086013
	LOSS [training: 4.4434967616729875 | validation: 5.778556836842947]
	TIME [epoch: 9.59 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.581032207299905		[learning rate: 0.008581]
	Learning Rate: 0.00858101
	LOSS [training: 4.581032207299905 | validation: 5.372883331501706]
	TIME [epoch: 9.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.321129860299847		[learning rate: 0.0085608]
	Learning Rate: 0.00856077
	LOSS [training: 4.321129860299847 | validation: 5.299295153823837]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.3375821018858165		[learning rate: 0.0085406]
	Learning Rate: 0.00854058
	LOSS [training: 4.3375821018858165 | validation: 5.193267449104399]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.029018771816242		[learning rate: 0.0085204]
	Learning Rate: 0.00852043
	LOSS [training: 5.029018771816242 | validation: 5.550019067734439]
	TIME [epoch: 9.61 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.439402828136505		[learning rate: 0.0085003]
	Learning Rate: 0.00850033
	LOSS [training: 4.439402828136505 | validation: 5.3950586862441785]
	TIME [epoch: 9.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.353156138021303		[learning rate: 0.0084803]
	Learning Rate: 0.00848028
	LOSS [training: 4.353156138021303 | validation: 5.743199534251237]
	TIME [epoch: 9.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.666954880969647		[learning rate: 0.0084603]
	Learning Rate: 0.00846028
	LOSS [training: 4.666954880969647 | validation: 5.398051771148845]
	TIME [epoch: 9.59 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.556703500645695		[learning rate: 0.0084403]
	Learning Rate: 0.00844032
	LOSS [training: 4.556703500645695 | validation: 5.924125057183011]
	TIME [epoch: 9.62 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.759515143942959		[learning rate: 0.0084204]
	Learning Rate: 0.00842041
	LOSS [training: 4.759515143942959 | validation: 5.313617349279239]
	TIME [epoch: 9.59 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.781878797941265		[learning rate: 0.0084005]
	Learning Rate: 0.00840055
	LOSS [training: 4.781878797941265 | validation: 5.579888837195035]
	TIME [epoch: 9.59 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.5467928448044415		[learning rate: 0.0083807]
	Learning Rate: 0.00838073
	LOSS [training: 4.5467928448044415 | validation: 5.621850167807909]
	TIME [epoch: 9.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.4397562810849855		[learning rate: 0.008361]
	Learning Rate: 0.00836096
	LOSS [training: 4.4397562810849855 | validation: 5.300394210567661]
	TIME [epoch: 9.62 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.316120038269296		[learning rate: 0.0083412]
	Learning Rate: 0.00834124
	LOSS [training: 4.316120038269296 | validation: 5.11092707806931]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.874697633516552		[learning rate: 0.0083216]
	Learning Rate: 0.00832157
	LOSS [training: 4.874697633516552 | validation: 5.251135359582873]
	TIME [epoch: 9.59 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.8372934214593375		[learning rate: 0.0083019]
	Learning Rate: 0.00830194
	LOSS [training: 4.8372934214593375 | validation: 5.231269487842185]
	TIME [epoch: 9.58 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.36203315092276		[learning rate: 0.0082824]
	Learning Rate: 0.00828236
	LOSS [training: 4.36203315092276 | validation: 5.224596156440125]
	TIME [epoch: 9.61 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.280074534412903		[learning rate: 0.0082628]
	Learning Rate: 0.00826282
	LOSS [training: 4.280074534412903 | validation: 4.906800078022797]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.307005084734187		[learning rate: 0.0082433]
	Learning Rate: 0.00824333
	LOSS [training: 5.307005084734187 | validation: 6.747054461534154]
	TIME [epoch: 9.58 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.698647526415925		[learning rate: 0.0082239]
	Learning Rate: 0.00822388
	LOSS [training: 4.698647526415925 | validation: 5.057762024668916]
	TIME [epoch: 9.61 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.3020315735571995		[learning rate: 0.0082045]
	Learning Rate: 0.00820448
	LOSS [training: 4.3020315735571995 | validation: 5.010447385638543]
	TIME [epoch: 9.59 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.811521298505227		[learning rate: 0.0081851]
	Learning Rate: 0.00818513
	LOSS [training: 4.811521298505227 | validation: 5.5310126304107925]
	TIME [epoch: 9.59 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.431222786481997		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 4.431222786481997 | validation: 6.079846038953299]
	TIME [epoch: 9.58 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.294991927485285		[learning rate: 0.0081466]
	Learning Rate: 0.00814656
	LOSS [training: 4.294991927485285 | validation: 4.90771609985064]
	TIME [epoch: 9.62 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.358546200980124		[learning rate: 0.0081273]
	Learning Rate: 0.00812735
	LOSS [training: 4.358546200980124 | validation: 5.116048909423985]
	TIME [epoch: 9.59 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.1518271959527695		[learning rate: 0.0081082]
	Learning Rate: 0.00810817
	LOSS [training: 4.1518271959527695 | validation: 4.7932117609172655]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.0087465260259485		[learning rate: 0.008089]
	Learning Rate: 0.00808905
	LOSS [training: 4.0087465260259485 | validation: 4.976984507223286]
	TIME [epoch: 9.59 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9593943775731923		[learning rate: 0.00807]
	Learning Rate: 0.00806997
	LOSS [training: 3.9593943775731923 | validation: 4.726995411479562]
	TIME [epoch: 9.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.4357666707023835		[learning rate: 0.0080509]
	Learning Rate: 0.00805093
	LOSS [training: 4.4357666707023835 | validation: 7.07360261066404]
	TIME [epoch: 9.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.873920335049132		[learning rate: 0.0080319]
	Learning Rate: 0.00803194
	LOSS [training: 4.873920335049132 | validation: 4.701413129802989]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.436916541772613		[learning rate: 0.008013]
	Learning Rate: 0.00801299
	LOSS [training: 4.436916541772613 | validation: 4.986905580337839]
	TIME [epoch: 9.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.401051978064883		[learning rate: 0.0079941]
	Learning Rate: 0.00799409
	LOSS [training: 4.401051978064883 | validation: 4.749285043788271]
	TIME [epoch: 9.62 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.570859663043186		[learning rate: 0.0079752]
	Learning Rate: 0.00797524
	LOSS [training: 4.570859663043186 | validation: 5.067282942020421]
	TIME [epoch: 9.58 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.7977326701893634		[learning rate: 0.0079564]
	Learning Rate: 0.00795642
	LOSS [training: 4.7977326701893634 | validation: 4.726000900674491]
	TIME [epoch: 9.59 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.1457388198030145		[learning rate: 0.0079377]
	Learning Rate: 0.00793766
	LOSS [training: 4.1457388198030145 | validation: 4.691338246016029]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7562328620795484		[learning rate: 0.0079189]
	Learning Rate: 0.00791893
	LOSS [training: 3.7562328620795484 | validation: 3.866014299205186]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.465509142522604		[learning rate: 0.0079003]
	Learning Rate: 0.00790025
	LOSS [training: 3.465509142522604 | validation: 3.0105249073725204]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.374194701767575		[learning rate: 0.0078816]
	Learning Rate: 0.00788162
	LOSS [training: 2.374194701767575 | validation: 2.0508959659856365]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.419328653345716		[learning rate: 0.007863]
	Learning Rate: 0.00786303
	LOSS [training: 2.419328653345716 | validation: 2.1886466584596294]
	TIME [epoch: 9.62 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4409634572035115		[learning rate: 0.0078445]
	Learning Rate: 0.00784448
	LOSS [training: 2.4409634572035115 | validation: 2.42278235030252]
	TIME [epoch: 9.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5775464082319623		[learning rate: 0.007826]
	Learning Rate: 0.00782597
	LOSS [training: 2.5775464082319623 | validation: 1.9482687696937768]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.315212821406582		[learning rate: 0.0078075]
	Learning Rate: 0.00780751
	LOSS [training: 2.315212821406582 | validation: 4.605264796698302]
	TIME [epoch: 9.61 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3427001623225614		[learning rate: 0.0077891]
	Learning Rate: 0.0077891
	LOSS [training: 3.3427001623225614 | validation: 2.933670555278444]
	TIME [epoch: 9.63 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9139383181325345		[learning rate: 0.0077707]
	Learning Rate: 0.00777072
	LOSS [training: 3.9139383181325345 | validation: 2.8857203213183937]
	TIME [epoch: 9.6 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8058231689615036		[learning rate: 0.0077524]
	Learning Rate: 0.00775239
	LOSS [training: 2.8058231689615036 | validation: 3.1857466215847787]
	TIME [epoch: 9.61 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9691909355137405		[learning rate: 0.0077341]
	Learning Rate: 0.00773411
	LOSS [training: 2.9691909355137405 | validation: 4.169441783395724]
	TIME [epoch: 9.64 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.643215139661227		[learning rate: 0.0077159]
	Learning Rate: 0.00771586
	LOSS [training: 2.643215139661227 | validation: 1.8839432096072422]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4223685910891333		[learning rate: 0.0076977]
	Learning Rate: 0.00769766
	LOSS [training: 2.4223685910891333 | validation: 1.9656179971303869]
	TIME [epoch: 9.58 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2932193988894243		[learning rate: 0.0076795]
	Learning Rate: 0.00767951
	LOSS [training: 2.2932193988894243 | validation: 2.333620510952278]
	TIME [epoch: 9.59 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3968841630155415		[learning rate: 0.0076614]
	Learning Rate: 0.00766139
	LOSS [training: 2.3968841630155415 | validation: 1.7726395474102925]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4975161799657424		[learning rate: 0.0076433]
	Learning Rate: 0.00764332
	LOSS [training: 2.4975161799657424 | validation: 2.365655797593414]
	TIME [epoch: 9.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.844284062832338		[learning rate: 0.0076253]
	Learning Rate: 0.00762529
	LOSS [training: 2.844284062832338 | validation: 2.2100636480145277]
	TIME [epoch: 9.59 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7071069831366623		[learning rate: 0.0076073]
	Learning Rate: 0.0076073
	LOSS [training: 2.7071069831366623 | validation: 3.063517699356868]
	TIME [epoch: 9.59 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.829105331337835		[learning rate: 0.0075894]
	Learning Rate: 0.00758936
	LOSS [training: 2.829105331337835 | validation: 2.285806531592603]
	TIME [epoch: 9.63 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1938580715108946		[learning rate: 0.0075715]
	Learning Rate: 0.00757146
	LOSS [training: 3.1938580715108946 | validation: 2.3221271547082747]
	TIME [epoch: 9.59 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.004134475871173		[learning rate: 0.0075536]
	Learning Rate: 0.0075536
	LOSS [training: 2.004134475871173 | validation: 2.370866794326073]
	TIME [epoch: 9.59 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8283372126995614		[learning rate: 0.0075358]
	Learning Rate: 0.00753578
	LOSS [training: 2.8283372126995614 | validation: 4.446350707781457]
	TIME [epoch: 9.61 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.761215611151275		[learning rate: 0.007518]
	Learning Rate: 0.007518
	LOSS [training: 2.761215611151275 | validation: 2.525959597451146]
	TIME [epoch: 9.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8808452893758343		[learning rate: 0.0075003]
	Learning Rate: 0.00750027
	LOSS [training: 1.8808452893758343 | validation: 2.2565430447018646]
	TIME [epoch: 9.59 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.098437377373987		[learning rate: 0.0074826]
	Learning Rate: 0.00748258
	LOSS [training: 2.098437377373987 | validation: 2.5053077432767457]
	TIME [epoch: 9.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.095577944371785		[learning rate: 0.0074649]
	Learning Rate: 0.00746493
	LOSS [training: 2.095577944371785 | validation: 2.0047474535500216]
	TIME [epoch: 9.62 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0927658096491624		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 2.0927658096491624 | validation: 2.0626540674318075]
	TIME [epoch: 9.61 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.143207579522988		[learning rate: 0.0074298]
	Learning Rate: 0.00742975
	LOSS [training: 2.143207579522988 | validation: 2.146341894856821]
	TIME [epoch: 9.59 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.092560136633076		[learning rate: 0.0074122]
	Learning Rate: 0.00741223
	LOSS [training: 2.092560136633076 | validation: 2.5283343043483977]
	TIME [epoch: 9.61 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.048379693823611		[learning rate: 0.0073947]
	Learning Rate: 0.00739474
	LOSS [training: 3.048379693823611 | validation: 2.060595199051597]
	TIME [epoch: 9.62 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8168518159027311		[learning rate: 0.0073773]
	Learning Rate: 0.0073773
	LOSS [training: 1.8168518159027311 | validation: 1.5287756849499257]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0677452678437667		[learning rate: 0.0073599]
	Learning Rate: 0.0073599
	LOSS [training: 2.0677452678437667 | validation: 1.7497580745755597]
	TIME [epoch: 9.59 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8257592734449575		[learning rate: 0.0073425]
	Learning Rate: 0.00734254
	LOSS [training: 1.8257592734449575 | validation: 2.0303572742751648]
	TIME [epoch: 9.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7757856240614032		[learning rate: 0.0073252]
	Learning Rate: 0.00732522
	LOSS [training: 1.7757856240614032 | validation: 2.0534428511689065]
	TIME [epoch: 9.62 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6221179380812831		[learning rate: 0.0073079]
	Learning Rate: 0.00730794
	LOSS [training: 1.6221179380812831 | validation: 1.489117910919521]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8649840670113433		[learning rate: 0.0072907]
	Learning Rate: 0.0072907
	LOSS [training: 1.8649840670113433 | validation: 2.3265621515856734]
	TIME [epoch: 9.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0851127828134937		[learning rate: 0.0072735]
	Learning Rate: 0.0072735
	LOSS [training: 2.0851127828134937 | validation: 3.1571777290028593]
	TIME [epoch: 9.62 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.634040277929386		[learning rate: 0.0072563]
	Learning Rate: 0.00725635
	LOSS [training: 2.634040277929386 | validation: 2.0843781993611503]
	TIME [epoch: 9.61 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0012431926033467		[learning rate: 0.0072392]
	Learning Rate: 0.00723923
	LOSS [training: 2.0012431926033467 | validation: 1.9146349656041577]
	TIME [epoch: 9.62 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3956833866796603		[learning rate: 0.0072222]
	Learning Rate: 0.00722215
	LOSS [training: 2.3956833866796603 | validation: 2.5908660585926873]
	TIME [epoch: 9.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0109787122694307		[learning rate: 0.0072051]
	Learning Rate: 0.00720512
	LOSS [training: 2.0109787122694307 | validation: 2.0947483872053816]
	TIME [epoch: 9.62 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0373660160476565		[learning rate: 0.0071881]
	Learning Rate: 0.00718812
	LOSS [training: 2.0373660160476565 | validation: 1.804865819140693]
	TIME [epoch: 9.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6799754015092383		[learning rate: 0.0071712]
	Learning Rate: 0.00717117
	LOSS [training: 1.6799754015092383 | validation: 1.9493439582893093]
	TIME [epoch: 9.61 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7777648984242618		[learning rate: 0.0071542]
	Learning Rate: 0.00715425
	LOSS [training: 1.7777648984242618 | validation: 2.0302381125113453]
	TIME [epoch: 9.61 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.722226213052565		[learning rate: 0.0071374]
	Learning Rate: 0.00713737
	LOSS [training: 1.722226213052565 | validation: 3.717895653892362]
	TIME [epoch: 9.64 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.020098514968537		[learning rate: 0.0071205]
	Learning Rate: 0.00712054
	LOSS [training: 3.020098514968537 | validation: 2.3460560261194203]
	TIME [epoch: 9.61 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9472368957122381		[learning rate: 0.0071037]
	Learning Rate: 0.00710374
	LOSS [training: 1.9472368957122381 | validation: 1.933071390084777]
	TIME [epoch: 9.62 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7742118293132532		[learning rate: 0.007087]
	Learning Rate: 0.00708698
	LOSS [training: 1.7742118293132532 | validation: 1.9654118344575013]
	TIME [epoch: 9.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.344080904460247		[learning rate: 0.0070703]
	Learning Rate: 0.00707027
	LOSS [training: 2.344080904460247 | validation: 3.0832309195980536]
	TIME [epoch: 9.62 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.303359005002773		[learning rate: 0.0070536]
	Learning Rate: 0.00705359
	LOSS [training: 2.303359005002773 | validation: 1.7131954477429179]
	TIME [epoch: 9.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5454874335948152		[learning rate: 0.007037]
	Learning Rate: 0.00703695
	LOSS [training: 1.5454874335948152 | validation: 1.4378413720217684]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.481609780113759		[learning rate: 0.0070204]
	Learning Rate: 0.00702035
	LOSS [training: 1.481609780113759 | validation: 3.058972486159884]
	TIME [epoch: 9.62 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0990842054865704		[learning rate: 0.0070038]
	Learning Rate: 0.00700379
	LOSS [training: 2.0990842054865704 | validation: 2.553494077906948]
	TIME [epoch: 9.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6542617754839715		[learning rate: 0.0069873]
	Learning Rate: 0.00698727
	LOSS [training: 1.6542617754839715 | validation: 1.7157073789045523]
	TIME [epoch: 9.62 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7094239018762671		[learning rate: 0.0069708]
	Learning Rate: 0.00697079
	LOSS [training: 1.7094239018762671 | validation: 1.6305299089404788]
	TIME [epoch: 9.63 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5402104273392392		[learning rate: 0.0069543]
	Learning Rate: 0.00695435
	LOSS [training: 1.5402104273392392 | validation: 1.7598518822111355]
	TIME [epoch: 9.63 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6997885344210413		[learning rate: 0.0069379]
	Learning Rate: 0.00693794
	LOSS [training: 1.6997885344210413 | validation: 1.825745860916791]
	TIME [epoch: 9.61 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.669640443645968		[learning rate: 0.0069216]
	Learning Rate: 0.00692158
	LOSS [training: 1.669640443645968 | validation: 1.9293001490309822]
	TIME [epoch: 9.61 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9345545883663586		[learning rate: 0.0069053]
	Learning Rate: 0.00690525
	LOSS [training: 1.9345545883663586 | validation: 2.6737466659662608]
	TIME [epoch: 9.61 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0462266663874704		[learning rate: 0.006889]
	Learning Rate: 0.00688896
	LOSS [training: 2.0462266663874704 | validation: 1.772154347631071]
	TIME [epoch: 9.61 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5307753564566855		[learning rate: 0.0068727]
	Learning Rate: 0.00687271
	LOSS [training: 1.5307753564566855 | validation: 2.0892139096472375]
	TIME [epoch: 9.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.439236472723374		[learning rate: 0.0068565]
	Learning Rate: 0.0068565
	LOSS [training: 2.439236472723374 | validation: 4.374780439513976]
	TIME [epoch: 9.61 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.086499732425546		[learning rate: 0.0068403]
	Learning Rate: 0.00684033
	LOSS [training: 3.086499732425546 | validation: 2.375639693501369]
	TIME [epoch: 9.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2095776382267416		[learning rate: 0.0068242]
	Learning Rate: 0.00682419
	LOSS [training: 2.2095776382267416 | validation: 2.359200233728023]
	TIME [epoch: 9.63 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.314010794212622		[learning rate: 0.0068081]
	Learning Rate: 0.0068081
	LOSS [training: 2.314010794212622 | validation: 1.7471733983106539]
	TIME [epoch: 9.61 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.807329717427694		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 1.807329717427694 | validation: 1.9554428204992917]
	TIME [epoch: 9.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0099393699161796		[learning rate: 0.006776]
	Learning Rate: 0.00677601
	LOSS [training: 2.0099393699161796 | validation: 2.2866651459192764]
	TIME [epoch: 9.62 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6979524170129765		[learning rate: 0.00676]
	Learning Rate: 0.00676003
	LOSS [training: 1.6979524170129765 | validation: 1.6199299268587015]
	TIME [epoch: 9.62 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2119722614137225		[learning rate: 0.0067441]
	Learning Rate: 0.00674409
	LOSS [training: 2.2119722614137225 | validation: 1.8433794102668752]
	TIME [epoch: 9.61 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.017221137363363		[learning rate: 0.0067282]
	Learning Rate: 0.00672818
	LOSS [training: 2.017221137363363 | validation: 1.6471143860733815]
	TIME [epoch: 9.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4473998095882004		[learning rate: 0.0067123]
	Learning Rate: 0.00671231
	LOSS [training: 1.4473998095882004 | validation: 1.709622797878899]
	TIME [epoch: 9.63 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5146762596560497		[learning rate: 0.0066965]
	Learning Rate: 0.00669647
	LOSS [training: 1.5146762596560497 | validation: 1.568480473155945]
	TIME [epoch: 9.61 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5047764937719927		[learning rate: 0.0066807]
	Learning Rate: 0.00668068
	LOSS [training: 1.5047764937719927 | validation: 1.7871143587941751]
	TIME [epoch: 9.61 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6159459053846148		[learning rate: 0.0066649]
	Learning Rate: 0.00666492
	LOSS [training: 1.6159459053846148 | validation: 1.7421398981334142]
	TIME [epoch: 9.61 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.624344538561479		[learning rate: 0.0066492]
	Learning Rate: 0.0066492
	LOSS [training: 2.624344538561479 | validation: 2.0751108394309408]
	TIME [epoch: 9.64 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.834652295131583		[learning rate: 0.0066335]
	Learning Rate: 0.00663351
	LOSS [training: 1.834652295131583 | validation: 1.6606520858384954]
	TIME [epoch: 9.62 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6673202732272074		[learning rate: 0.0066179]
	Learning Rate: 0.00661787
	LOSS [training: 1.6673202732272074 | validation: 1.6686756608080395]
	TIME [epoch: 9.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9381554556638456		[learning rate: 0.0066023]
	Learning Rate: 0.00660226
	LOSS [training: 1.9381554556638456 | validation: 2.424340634866777]
	TIME [epoch: 9.61 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4392510906239773		[learning rate: 0.0065867]
	Learning Rate: 0.00658668
	LOSS [training: 2.4392510906239773 | validation: 2.7783471390560925]
	TIME [epoch: 9.63 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.333798985598044		[learning rate: 0.0065711]
	Learning Rate: 0.00657114
	LOSS [training: 2.333798985598044 | validation: 3.1041860934865873]
	TIME [epoch: 9.61 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.797460987800153		[learning rate: 0.0065556]
	Learning Rate: 0.00655564
	LOSS [training: 4.797460987800153 | validation: 5.907594797565416]
	TIME [epoch: 9.59 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.223629508795203		[learning rate: 0.0065402]
	Learning Rate: 0.00654018
	LOSS [training: 5.223629508795203 | validation: 4.098911375747433]
	TIME [epoch: 9.62 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.893467032234239		[learning rate: 0.0065248]
	Learning Rate: 0.00652475
	LOSS [training: 3.893467032234239 | validation: 2.2712579563992494]
	TIME [epoch: 9.61 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2468375736727118		[learning rate: 0.0065094]
	Learning Rate: 0.00650936
	LOSS [training: 2.2468375736727118 | validation: 1.6015907044324202]
	TIME [epoch: 9.61 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.648442268165716		[learning rate: 0.006494]
	Learning Rate: 0.00649401
	LOSS [training: 1.648442268165716 | validation: 2.0982140428034444]
	TIME [epoch: 9.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9618770084953059		[learning rate: 0.0064787]
	Learning Rate: 0.00647869
	LOSS [training: 1.9618770084953059 | validation: 2.297834468961106]
	TIME [epoch: 9.65 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8108339765572752		[learning rate: 0.0064634]
	Learning Rate: 0.00646341
	LOSS [training: 1.8108339765572752 | validation: 1.8134021167265684]
	TIME [epoch: 9.62 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6426824736033852		[learning rate: 0.0064482]
	Learning Rate: 0.00644816
	LOSS [training: 1.6426824736033852 | validation: 1.6483093874380794]
	TIME [epoch: 9.61 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4661142913482812		[learning rate: 0.006433]
	Learning Rate: 0.00643295
	LOSS [training: 1.4661142913482812 | validation: 1.6211869428765737]
	TIME [epoch: 9.61 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6347214215914643		[learning rate: 0.0064178]
	Learning Rate: 0.00641778
	LOSS [training: 1.6347214215914643 | validation: 1.754336462909244]
	TIME [epoch: 9.63 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5809540769220711		[learning rate: 0.0064026]
	Learning Rate: 0.00640264
	LOSS [training: 1.5809540769220711 | validation: 1.7980427818621303]
	TIME [epoch: 9.61 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6498239995919655		[learning rate: 0.0063875]
	Learning Rate: 0.00638754
	LOSS [training: 1.6498239995919655 | validation: 2.235998394522907]
	TIME [epoch: 9.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.728516369798006		[learning rate: 0.0063725]
	Learning Rate: 0.00637247
	LOSS [training: 1.728516369798006 | validation: 1.5220735983800129]
	TIME [epoch: 9.61 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5142997971832055		[learning rate: 0.0063574]
	Learning Rate: 0.00635744
	LOSS [training: 1.5142997971832055 | validation: 1.783055341545694]
	TIME [epoch: 9.64 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7204521704603564		[learning rate: 0.0063424]
	Learning Rate: 0.00634244
	LOSS [training: 1.7204521704603564 | validation: 1.6424544634438427]
	TIME [epoch: 9.63 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6906985870567932		[learning rate: 0.0063275]
	Learning Rate: 0.00632748
	LOSS [training: 1.6906985870567932 | validation: 2.44521336304547]
	TIME [epoch: 9.63 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1326893755249356		[learning rate: 0.0063126]
	Learning Rate: 0.00631255
	LOSS [training: 2.1326893755249356 | validation: 2.2286306427110785]
	TIME [epoch: 9.65 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8625178803610258		[learning rate: 0.0062977]
	Learning Rate: 0.00629766
	LOSS [training: 1.8625178803610258 | validation: 1.8836518277664318]
	TIME [epoch: 9.63 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.769163051607059		[learning rate: 0.0062828]
	Learning Rate: 0.00628281
	LOSS [training: 1.769163051607059 | validation: 1.6077219830512997]
	TIME [epoch: 9.62 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4604083810534847		[learning rate: 0.006268]
	Learning Rate: 0.00626799
	LOSS [training: 1.4604083810534847 | validation: 1.4403843051644425]
	TIME [epoch: 9.62 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6076758917415979		[learning rate: 0.0062532]
	Learning Rate: 0.0062532
	LOSS [training: 1.6076758917415979 | validation: 1.821105189531262]
	TIME [epoch: 9.64 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.557205948013618		[learning rate: 0.0062385]
	Learning Rate: 0.00623845
	LOSS [training: 1.557205948013618 | validation: 1.780639379889005]
	TIME [epoch: 9.63 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.567947952548322		[learning rate: 0.0062237]
	Learning Rate: 0.00622374
	LOSS [training: 1.567947952548322 | validation: 1.668424682686426]
	TIME [epoch: 9.61 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6327467631470405		[learning rate: 0.0062091]
	Learning Rate: 0.00620906
	LOSS [training: 1.6327467631470405 | validation: 1.7364221378356683]
	TIME [epoch: 9.62 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.037406104670808		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 2.037406104670808 | validation: 1.7852154327427832]
	TIME [epoch: 9.63 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7121205068803835		[learning rate: 0.0061798]
	Learning Rate: 0.0061798
	LOSS [training: 1.7121205068803835 | validation: 1.6522853725836786]
	TIME [epoch: 9.62 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2705919112708095		[learning rate: 0.0061652]
	Learning Rate: 0.00616522
	LOSS [training: 2.2705919112708095 | validation: 2.0056975925676035]
	TIME [epoch: 9.61 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3826470023838886		[learning rate: 0.0061507]
	Learning Rate: 0.00615068
	LOSS [training: 3.3826470023838886 | validation: 2.9534857164859565]
	TIME [epoch: 9.61 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4847172305109457		[learning rate: 0.0061362]
	Learning Rate: 0.00613617
	LOSS [training: 2.4847172305109457 | validation: 2.241763754313314]
	TIME [epoch: 9.64 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.819428979381599		[learning rate: 0.0061217]
	Learning Rate: 0.0061217
	LOSS [training: 1.819428979381599 | validation: 1.864529824032137]
	TIME [epoch: 9.62 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7443915541168231		[learning rate: 0.0061073]
	Learning Rate: 0.00610726
	LOSS [training: 1.7443915541168231 | validation: 1.389006598566092]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.407758919934326		[learning rate: 0.0060929]
	Learning Rate: 0.00609285
	LOSS [training: 1.407758919934326 | validation: 1.7436079833396263]
	TIME [epoch: 9.61 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5017041173716064		[learning rate: 0.0060785]
	Learning Rate: 0.00607848
	LOSS [training: 1.5017041173716064 | validation: 1.541776914470379]
	TIME [epoch: 9.63 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5173107058455035		[learning rate: 0.0060641]
	Learning Rate: 0.00606414
	LOSS [training: 1.5173107058455035 | validation: 1.4718632569126695]
	TIME [epoch: 9.61 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3596574203833245		[learning rate: 0.0060498]
	Learning Rate: 0.00604984
	LOSS [training: 1.3596574203833245 | validation: 1.6998461825695472]
	TIME [epoch: 9.59 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6402533257914065		[learning rate: 0.0060356]
	Learning Rate: 0.00603556
	LOSS [training: 1.6402533257914065 | validation: 1.4002446774673456]
	TIME [epoch: 9.63 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0249269230855598		[learning rate: 0.0060213]
	Learning Rate: 0.00602133
	LOSS [training: 2.0249269230855598 | validation: 2.8998502475062278]
	TIME [epoch: 9.62 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9381798758675561		[learning rate: 0.0060071]
	Learning Rate: 0.00600712
	LOSS [training: 1.9381798758675561 | validation: 1.534726725868374]
	TIME [epoch: 9.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7599376967789575		[learning rate: 0.005993]
	Learning Rate: 0.00599296
	LOSS [training: 1.7599376967789575 | validation: 2.1287692289927613]
	TIME [epoch: 9.61 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7704283495940558		[learning rate: 0.0059788]
	Learning Rate: 0.00597882
	LOSS [training: 1.7704283495940558 | validation: 1.7602041857954296]
	TIME [epoch: 9.65 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.52534138089985		[learning rate: 0.0059647]
	Learning Rate: 0.00596472
	LOSS [training: 1.52534138089985 | validation: 1.5315690204491192]
	TIME [epoch: 9.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6652859261983075		[learning rate: 0.0059506]
	Learning Rate: 0.00595065
	LOSS [training: 1.6652859261983075 | validation: 1.4665963379825298]
	TIME [epoch: 9.61 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8039668531422737		[learning rate: 0.0059366]
	Learning Rate: 0.00593661
	LOSS [training: 1.8039668531422737 | validation: 2.991826937296379]
	TIME [epoch: 9.61 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.412548373305815		[learning rate: 0.0059226]
	Learning Rate: 0.00592261
	LOSS [training: 2.412548373305815 | validation: 1.790727104850663]
	TIME [epoch: 9.63 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4940227774104549		[learning rate: 0.0059086]
	Learning Rate: 0.00590863
	LOSS [training: 1.4940227774104549 | validation: 1.6267606769984073]
	TIME [epoch: 9.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5072868517308586		[learning rate: 0.0058947]
	Learning Rate: 0.0058947
	LOSS [training: 1.5072868517308586 | validation: 1.6487376654648662]
	TIME [epoch: 9.59 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.686995246230555		[learning rate: 0.0058808]
	Learning Rate: 0.00588079
	LOSS [training: 1.686995246230555 | validation: 1.988194855749561]
	TIME [epoch: 9.59 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5921033141985128		[learning rate: 0.0058669]
	Learning Rate: 0.00586692
	LOSS [training: 1.5921033141985128 | validation: 1.5751714919563549]
	TIME [epoch: 9.62 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5464277269873516		[learning rate: 0.0058531]
	Learning Rate: 0.00585308
	LOSS [training: 1.5464277269873516 | validation: 1.7304616147130383]
	TIME [epoch: 9.62 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4352123459796817		[learning rate: 0.0058393]
	Learning Rate: 0.00583928
	LOSS [training: 1.4352123459796817 | validation: 1.8027883127926878]
	TIME [epoch: 9.61 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9692483877525693		[learning rate: 0.0058255]
	Learning Rate: 0.0058255
	LOSS [training: 1.9692483877525693 | validation: 1.866905125625239]
	TIME [epoch: 9.63 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7566858880637486		[learning rate: 0.0058118]
	Learning Rate: 0.00581176
	LOSS [training: 1.7566858880637486 | validation: 1.9873568539036313]
	TIME [epoch: 9.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7480370201171613		[learning rate: 0.0057981]
	Learning Rate: 0.00579805
	LOSS [training: 1.7480370201171613 | validation: 1.612964306195251]
	TIME [epoch: 9.61 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2564314906845615		[learning rate: 0.0057844]
	Learning Rate: 0.00578438
	LOSS [training: 2.2564314906845615 | validation: 4.8319669456727885]
	TIME [epoch: 9.61 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.983655628254719		[learning rate: 0.0057707]
	Learning Rate: 0.00577073
	LOSS [training: 3.983655628254719 | validation: 2.0583430178582556]
	TIME [epoch: 9.65 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8147781986948943		[learning rate: 0.0057571]
	Learning Rate: 0.00575712
	LOSS [training: 1.8147781986948943 | validation: 1.8363946895373855]
	TIME [epoch: 9.61 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6985198076053016		[learning rate: 0.0057435]
	Learning Rate: 0.00574354
	LOSS [training: 1.6985198076053016 | validation: 1.6537072691333885]
	TIME [epoch: 9.59 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.469741528656564		[learning rate: 0.00573]
	Learning Rate: 0.00572999
	LOSS [training: 1.469741528656564 | validation: 2.3643367485234537]
	TIME [epoch: 9.61 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8006753601939003		[learning rate: 0.0057165]
	Learning Rate: 0.00571647
	LOSS [training: 1.8006753601939003 | validation: 1.8365073837992913]
	TIME [epoch: 9.65 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7128333375380003		[learning rate: 0.005703]
	Learning Rate: 0.00570299
	LOSS [training: 1.7128333375380003 | validation: 2.1228408072425604]
	TIME [epoch: 9.62 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6081480272615978		[learning rate: 0.0056895]
	Learning Rate: 0.00568954
	LOSS [training: 1.6081480272615978 | validation: 1.647857801335]
	TIME [epoch: 9.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.883714301514304		[learning rate: 0.0056761]
	Learning Rate: 0.00567612
	LOSS [training: 1.883714301514304 | validation: 2.870242622904567]
	TIME [epoch: 9.59 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3144547466701084		[learning rate: 0.0056627]
	Learning Rate: 0.00566273
	LOSS [training: 2.3144547466701084 | validation: 1.7413037678353396]
	TIME [epoch: 9.65 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.436935318042043		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 1.436935318042043 | validation: 1.7014964251319311]
	TIME [epoch: 9.58 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3606255797487006		[learning rate: 0.005636]
	Learning Rate: 0.00563604
	LOSS [training: 1.3606255797487006 | validation: 1.445134400486173]
	TIME [epoch: 9.61 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7290204501205786		[learning rate: 0.0056227]
	Learning Rate: 0.00562275
	LOSS [training: 1.7290204501205786 | validation: 1.8180263438601778]
	TIME [epoch: 9.64 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5263789514875554		[learning rate: 0.0056095]
	Learning Rate: 0.00560949
	LOSS [training: 1.5263789514875554 | validation: 2.238978139686449]
	TIME [epoch: 9.62 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7406878986439103		[learning rate: 0.0055963]
	Learning Rate: 0.00559625
	LOSS [training: 1.7406878986439103 | validation: 1.8865428598551233]
	TIME [epoch: 9.61 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.343282677056385		[learning rate: 0.0055831]
	Learning Rate: 0.00558305
	LOSS [training: 2.343282677056385 | validation: 2.0642044719725625]
	TIME [epoch: 9.59 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6463213432148227		[learning rate: 0.0055699]
	Learning Rate: 0.00556988
	LOSS [training: 1.6463213432148227 | validation: 1.393943961516826]
	TIME [epoch: 9.63 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5006659747618758		[learning rate: 0.0055567]
	Learning Rate: 0.00555674
	LOSS [training: 1.5006659747618758 | validation: 1.6841701758005252]
	TIME [epoch: 9.62 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4403114616632327		[learning rate: 0.0055436]
	Learning Rate: 0.00554364
	LOSS [training: 1.4403114616632327 | validation: 1.3862836264192349]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_300.pth
	Model improved!!!
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5096642926885306		[learning rate: 0.0055306]
	Learning Rate: 0.00553056
	LOSS [training: 1.5096642926885306 | validation: 1.4758493792632181]
	TIME [epoch: 9.61 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4322892695303477		[learning rate: 0.0055175]
	Learning Rate: 0.00551752
	LOSS [training: 1.4322892695303477 | validation: 1.7385995624156965]
	TIME [epoch: 9.65 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.601202052635757		[learning rate: 0.0055045]
	Learning Rate: 0.0055045
	LOSS [training: 1.601202052635757 | validation: 1.6125742364467732]
	TIME [epoch: 9.62 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.409955984843106		[learning rate: 0.0054915]
	Learning Rate: 0.00549152
	LOSS [training: 1.409955984843106 | validation: 1.6192793506357392]
	TIME [epoch: 9.61 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5749860422784525		[learning rate: 0.0054786]
	Learning Rate: 0.00547856
	LOSS [training: 1.5749860422784525 | validation: 1.62503675336004]
	TIME [epoch: 9.62 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4772658399923269		[learning rate: 0.0054656]
	Learning Rate: 0.00546564
	LOSS [training: 1.4772658399923269 | validation: 1.4952171261116725]
	TIME [epoch: 9.64 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3717060902313254		[learning rate: 0.0054527]
	Learning Rate: 0.00545275
	LOSS [training: 1.3717060902313254 | validation: 1.9707945089841665]
	TIME [epoch: 9.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5918770664959783		[learning rate: 0.0054399]
	Learning Rate: 0.00543988
	LOSS [training: 1.5918770664959783 | validation: 1.480000389623086]
	TIME [epoch: 9.61 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2861131713325626		[learning rate: 0.0054271]
	Learning Rate: 0.00542705
	LOSS [training: 1.2861131713325626 | validation: 1.4179794558480603]
	TIME [epoch: 9.59 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4869676192998642		[learning rate: 0.0054143]
	Learning Rate: 0.00541425
	LOSS [training: 1.4869676192998642 | validation: 1.7961674563906556]
	TIME [epoch: 9.6 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5932633486836223		[learning rate: 0.0054015]
	Learning Rate: 0.00540148
	LOSS [training: 1.5932633486836223 | validation: 1.5205786398228014]
	TIME [epoch: 9.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3760210177475827		[learning rate: 0.0053887]
	Learning Rate: 0.00538874
	LOSS [training: 1.3760210177475827 | validation: 1.3465986074526257]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_312.pth
	Model improved!!!
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3387922543091852		[learning rate: 0.005376]
	Learning Rate: 0.00537603
	LOSS [training: 1.3387922543091852 | validation: 1.6541221218559405]
	TIME [epoch: 9.64 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4880300844495935		[learning rate: 0.0053633]
	Learning Rate: 0.00536335
	LOSS [training: 1.4880300844495935 | validation: 1.5162843778422472]
	TIME [epoch: 9.61 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.418385351918511		[learning rate: 0.0053507]
	Learning Rate: 0.00535069
	LOSS [training: 1.418385351918511 | validation: 1.564188868364403]
	TIME [epoch: 9.61 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7210905574910196		[learning rate: 0.0053381]
	Learning Rate: 0.00533807
	LOSS [training: 1.7210905574910196 | validation: 1.6698727776938913]
	TIME [epoch: 9.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4325173194380896		[learning rate: 0.0053255]
	Learning Rate: 0.00532548
	LOSS [training: 1.4325173194380896 | validation: 1.8976648290776235]
	TIME [epoch: 9.63 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6484830792876672		[learning rate: 0.0053129]
	Learning Rate: 0.00531292
	LOSS [training: 1.6484830792876672 | validation: 1.6688100532391148]
	TIME [epoch: 9.61 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6059030855154652		[learning rate: 0.0053004]
	Learning Rate: 0.00530039
	LOSS [training: 1.6059030855154652 | validation: 1.6265558986612347]
	TIME [epoch: 9.61 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4646328605177945		[learning rate: 0.0052879]
	Learning Rate: 0.00528789
	LOSS [training: 1.4646328605177945 | validation: 1.5337377790802378]
	TIME [epoch: 9.64 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6418295270393675		[learning rate: 0.0052754]
	Learning Rate: 0.00527541
	LOSS [training: 1.6418295270393675 | validation: 1.8069531480071852]
	TIME [epoch: 9.63 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4445578624671698		[learning rate: 0.005263]
	Learning Rate: 0.00526297
	LOSS [training: 1.4445578624671698 | validation: 1.4259546900237383]
	TIME [epoch: 9.61 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2443759756090222		[learning rate: 0.0052506]
	Learning Rate: 0.00525055
	LOSS [training: 1.2443759756090222 | validation: 2.085243291449329]
	TIME [epoch: 9.61 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5625221427281866		[learning rate: 0.0052382]
	Learning Rate: 0.00523817
	LOSS [training: 1.5625221427281866 | validation: 1.8421119401298307]
	TIME [epoch: 9.64 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.68190675580068		[learning rate: 0.0052258]
	Learning Rate: 0.00522581
	LOSS [training: 1.68190675580068 | validation: 1.90940167926702]
	TIME [epoch: 9.62 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5146935098834349		[learning rate: 0.0052135]
	Learning Rate: 0.00521349
	LOSS [training: 1.5146935098834349 | validation: 1.437831257717085]
	TIME [epoch: 9.61 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4420867753386868		[learning rate: 0.0052012]
	Learning Rate: 0.00520119
	LOSS [training: 1.4420867753386868 | validation: 1.925785670808638]
	TIME [epoch: 9.59 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.505958258670201		[learning rate: 0.0051889]
	Learning Rate: 0.00518892
	LOSS [training: 1.505958258670201 | validation: 1.4631895919890594]
	TIME [epoch: 9.63 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4360893931411733		[learning rate: 0.0051767]
	Learning Rate: 0.00517668
	LOSS [training: 1.4360893931411733 | validation: 1.5132067932848725]
	TIME [epoch: 9.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5572892100728037		[learning rate: 0.0051645]
	Learning Rate: 0.00516447
	LOSS [training: 1.5572892100728037 | validation: 1.3287672307336544]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_330.pth
	Model improved!!!
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2938443980915315		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 1.2938443980915315 | validation: 1.2921290424178644]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7688124961902667		[learning rate: 0.0051401]
	Learning Rate: 0.00514013
	LOSS [training: 1.7688124961902667 | validation: 2.030770397772144]
	TIME [epoch: 9.63 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.672359370617145		[learning rate: 0.005128]
	Learning Rate: 0.00512801
	LOSS [training: 1.672359370617145 | validation: 1.3961451172021395]
	TIME [epoch: 9.61 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4445111856897968		[learning rate: 0.0051159]
	Learning Rate: 0.00511591
	LOSS [training: 1.4445111856897968 | validation: 1.5036911686020227]
	TIME [epoch: 9.59 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8549037707402563		[learning rate: 0.0051038]
	Learning Rate: 0.00510384
	LOSS [training: 1.8549037707402563 | validation: 1.4910030350613779]
	TIME [epoch: 9.62 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3148444125821688		[learning rate: 0.0050918]
	Learning Rate: 0.00509181
	LOSS [training: 1.3148444125821688 | validation: 1.2923342772940993]
	TIME [epoch: 9.62 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3465873818389653		[learning rate: 0.0050798]
	Learning Rate: 0.00507979
	LOSS [training: 1.3465873818389653 | validation: 1.4055194862628486]
	TIME [epoch: 9.61 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5524837328388907		[learning rate: 0.0050678]
	Learning Rate: 0.00506781
	LOSS [training: 1.5524837328388907 | validation: 1.2689228371737218]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_338.pth
	Model improved!!!
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4984925171959214		[learning rate: 0.0050559]
	Learning Rate: 0.00505586
	LOSS [training: 1.4984925171959214 | validation: 1.9144677865405388]
	TIME [epoch: 9.63 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0127847498252907		[learning rate: 0.0050439]
	Learning Rate: 0.00504393
	LOSS [training: 2.0127847498252907 | validation: 1.7379453149634332]
	TIME [epoch: 9.59 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5933028150552846		[learning rate: 0.005032]
	Learning Rate: 0.00503203
	LOSS [training: 1.5933028150552846 | validation: 1.418514967473418]
	TIME [epoch: 9.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3854301795413826		[learning rate: 0.0050202]
	Learning Rate: 0.00502016
	LOSS [training: 1.3854301795413826 | validation: 1.3695892924613724]
	TIME [epoch: 9.63 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4303443251462984		[learning rate: 0.0050083]
	Learning Rate: 0.00500832
	LOSS [training: 1.4303443251462984 | validation: 1.4255372859548288]
	TIME [epoch: 9.63 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.562352469153002		[learning rate: 0.0049965]
	Learning Rate: 0.00499651
	LOSS [training: 1.562352469153002 | validation: 1.6927270414564075]
	TIME [epoch: 9.61 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.382741265817243		[learning rate: 0.0049847]
	Learning Rate: 0.00498472
	LOSS [training: 1.382741265817243 | validation: 1.7984762612651526]
	TIME [epoch: 9.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5162086741900942		[learning rate: 0.004973]
	Learning Rate: 0.00497296
	LOSS [training: 1.5162086741900942 | validation: 1.440935988492081]
	TIME [epoch: 9.59 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.507078781757419		[learning rate: 0.0049612]
	Learning Rate: 0.00496123
	LOSS [training: 1.507078781757419 | validation: 1.3366253096773408]
	TIME [epoch: 9.63 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4672994766074554		[learning rate: 0.0049495]
	Learning Rate: 0.00494953
	LOSS [training: 1.4672994766074554 | validation: 1.3321662872172846]
	TIME [epoch: 9.61 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4939336607697413		[learning rate: 0.0049379]
	Learning Rate: 0.00493786
	LOSS [training: 1.4939336607697413 | validation: 1.2864284117120617]
	TIME [epoch: 9.61 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2972251710965164		[learning rate: 0.0049262]
	Learning Rate: 0.00492621
	LOSS [training: 1.2972251710965164 | validation: 1.462957619290627]
	TIME [epoch: 9.63 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2770401769113722		[learning rate: 0.0049146]
	Learning Rate: 0.00491459
	LOSS [training: 1.2770401769113722 | validation: 1.323228153732801]
	TIME [epoch: 9.61 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3900095907384304		[learning rate: 0.004903]
	Learning Rate: 0.004903
	LOSS [training: 1.3900095907384304 | validation: 1.8510691136367274]
	TIME [epoch: 9.59 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3888635774757794		[learning rate: 0.0048914]
	Learning Rate: 0.00489143
	LOSS [training: 1.3888635774757794 | validation: 1.3913363681058524]
	TIME [epoch: 9.62 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3674874460357964		[learning rate: 0.0048799]
	Learning Rate: 0.00487989
	LOSS [training: 1.3674874460357964 | validation: 1.7302734653845249]
	TIME [epoch: 9.63 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7385707017859944		[learning rate: 0.0048684]
	Learning Rate: 0.00486838
	LOSS [training: 1.7385707017859944 | validation: 1.3268603460729356]
	TIME [epoch: 9.61 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1876451309961826		[learning rate: 0.0048569]
	Learning Rate: 0.0048569
	LOSS [training: 1.1876451309961826 | validation: 1.309674511598924]
	TIME [epoch: 9.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.383030479323107		[learning rate: 0.0048454]
	Learning Rate: 0.00484544
	LOSS [training: 1.383030479323107 | validation: 1.7233506595540338]
	TIME [epoch: 9.62 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4086289807930674		[learning rate: 0.004834]
	Learning Rate: 0.00483401
	LOSS [training: 1.4086289807930674 | validation: 1.549164202976532]
	TIME [epoch: 9.64 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.289298681572053		[learning rate: 0.0048226]
	Learning Rate: 0.00482261
	LOSS [training: 1.289298681572053 | validation: 1.3420776570839643]
	TIME [epoch: 9.61 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3397680943150128		[learning rate: 0.0048112]
	Learning Rate: 0.00481123
	LOSS [training: 1.3397680943150128 | validation: 1.6848697722092636]
	TIME [epoch: 9.61 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5462501388995964		[learning rate: 0.0047999]
	Learning Rate: 0.00479988
	LOSS [training: 1.5462501388995964 | validation: 1.5534954043747455]
	TIME [epoch: 9.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3485013886186228		[learning rate: 0.0047886]
	Learning Rate: 0.00478856
	LOSS [training: 1.3485013886186228 | validation: 1.541113404006441]
	TIME [epoch: 9.64 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.654361606328641		[learning rate: 0.0047773]
	Learning Rate: 0.00477727
	LOSS [training: 1.654361606328641 | validation: 1.6156343053271747]
	TIME [epoch: 9.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5663977267540858		[learning rate: 0.004766]
	Learning Rate: 0.004766
	LOSS [training: 1.5663977267540858 | validation: 1.5617701063735445]
	TIME [epoch: 9.64 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4934730875084248		[learning rate: 0.0047548]
	Learning Rate: 0.00475476
	LOSS [training: 1.4934730875084248 | validation: 1.3554224606835652]
	TIME [epoch: 9.62 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6232373426007911		[learning rate: 0.0047435]
	Learning Rate: 0.00474354
	LOSS [training: 1.6232373426007911 | validation: 1.5654270068849316]
	TIME [epoch: 9.64 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3792060775118409		[learning rate: 0.0047324]
	Learning Rate: 0.00473235
	LOSS [training: 1.3792060775118409 | validation: 1.4252160300172358]
	TIME [epoch: 9.62 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2216246345359258		[learning rate: 0.0047212]
	Learning Rate: 0.00472119
	LOSS [training: 1.2216246345359258 | validation: 1.4056399192918725]
	TIME [epoch: 9.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2550358505956296		[learning rate: 0.0047101]
	Learning Rate: 0.00471005
	LOSS [training: 1.2550358505956296 | validation: 1.7259573440089468]
	TIME [epoch: 9.65 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9410403430515093		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 1.9410403430515093 | validation: 2.0801796142735776]
	TIME [epoch: 9.62 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8549847632100316		[learning rate: 0.0046879]
	Learning Rate: 0.00468786
	LOSS [training: 1.8549847632100316 | validation: 2.2379756543606537]
	TIME [epoch: 9.62 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3370510372169404		[learning rate: 0.0046768]
	Learning Rate: 0.0046768
	LOSS [training: 2.3370510372169404 | validation: 1.561922752898949]
	TIME [epoch: 9.58 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2982315459621705		[learning rate: 0.0046658]
	Learning Rate: 0.00466577
	LOSS [training: 1.2982315459621705 | validation: 1.6325412683889853]
	TIME [epoch: 9.65 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5764368116488021		[learning rate: 0.0046548]
	Learning Rate: 0.00465476
	LOSS [training: 1.5764368116488021 | validation: 1.51848290161432]
	TIME [epoch: 9.62 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.359269061705649		[learning rate: 0.0046438]
	Learning Rate: 0.00464378
	LOSS [training: 1.359269061705649 | validation: 1.2752263776559232]
	TIME [epoch: 9.64 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2773707942574801		[learning rate: 0.0046328]
	Learning Rate: 0.00463283
	LOSS [training: 1.2773707942574801 | validation: 1.5706886292545719]
	TIME [epoch: 9.59 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6631867987508895		[learning rate: 0.0046219]
	Learning Rate: 0.0046219
	LOSS [training: 1.6631867987508895 | validation: 1.4700005146874917]
	TIME [epoch: 9.65 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4481655360083698		[learning rate: 0.004611]
	Learning Rate: 0.004611
	LOSS [training: 1.4481655360083698 | validation: 1.6362572651316374]
	TIME [epoch: 9.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4963547458543207		[learning rate: 0.0046001]
	Learning Rate: 0.00460012
	LOSS [training: 1.4963547458543207 | validation: 1.6682143620564307]
	TIME [epoch: 9.59 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3848202703130916		[learning rate: 0.0045893]
	Learning Rate: 0.00458927
	LOSS [training: 1.3848202703130916 | validation: 1.5051264139410119]
	TIME [epoch: 9.62 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5321259732365806		[learning rate: 0.0045784]
	Learning Rate: 0.00457844
	LOSS [training: 1.5321259732365806 | validation: 1.4948248221981077]
	TIME [epoch: 9.63 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3211162003394166		[learning rate: 0.0045676]
	Learning Rate: 0.00456765
	LOSS [training: 1.3211162003394166 | validation: 1.2282819467794843]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_382.pth
	Model improved!!!
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.229752269165159		[learning rate: 0.0045569]
	Learning Rate: 0.00455687
	LOSS [training: 1.229752269165159 | validation: 1.35532887322117]
	TIME [epoch: 9.59 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3430923678355262		[learning rate: 0.0045461]
	Learning Rate: 0.00454612
	LOSS [training: 1.3430923678355262 | validation: 1.4693026424953337]
	TIME [epoch: 9.62 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6107610322827248		[learning rate: 0.0045354]
	Learning Rate: 0.0045354
	LOSS [training: 1.6107610322827248 | validation: 1.4621536316624626]
	TIME [epoch: 9.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3106607514512243		[learning rate: 0.0045247]
	Learning Rate: 0.0045247
	LOSS [training: 1.3106607514512243 | validation: 1.6979441955531676]
	TIME [epoch: 9.61 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3599973097199858		[learning rate: 0.004514]
	Learning Rate: 0.00451403
	LOSS [training: 1.3599973097199858 | validation: 1.2435360173486318]
	TIME [epoch: 9.58 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2336367570359745		[learning rate: 0.0045034]
	Learning Rate: 0.00450338
	LOSS [training: 1.2336367570359745 | validation: 1.3882836762126434]
	TIME [epoch: 9.63 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2978865371349422		[learning rate: 0.0044928]
	Learning Rate: 0.00449276
	LOSS [training: 1.2978865371349422 | validation: 1.495146389085959]
	TIME [epoch: 9.61 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3198654779596315		[learning rate: 0.0044822]
	Learning Rate: 0.00448216
	LOSS [training: 1.3198654779596315 | validation: 1.7139836766510934]
	TIME [epoch: 9.58 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3772864320394222		[learning rate: 0.0044716]
	Learning Rate: 0.00447159
	LOSS [training: 1.3772864320394222 | validation: 1.3786340847055973]
	TIME [epoch: 9.61 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2744605886457712		[learning rate: 0.004461]
	Learning Rate: 0.00446104
	LOSS [training: 1.2744605886457712 | validation: 1.4232798872864658]
	TIME [epoch: 9.64 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4173756591279258		[learning rate: 0.0044505]
	Learning Rate: 0.00445051
	LOSS [training: 1.4173756591279258 | validation: 1.7116775617644033]
	TIME [epoch: 9.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6962050066262777		[learning rate: 0.00444]
	Learning Rate: 0.00444002
	LOSS [training: 1.6962050066262777 | validation: 1.7876967975391669]
	TIME [epoch: 9.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.772637149098777		[learning rate: 0.0044295]
	Learning Rate: 0.00442954
	LOSS [training: 1.772637149098777 | validation: 2.0334299350953775]
	TIME [epoch: 9.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5805172219687909		[learning rate: 0.0044191]
	Learning Rate: 0.00441909
	LOSS [training: 1.5805172219687909 | validation: 1.3862149275940785]
	TIME [epoch: 9.62 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4297121493690024		[learning rate: 0.0044087]
	Learning Rate: 0.00440867
	LOSS [training: 1.4297121493690024 | validation: 1.9549046774899512]
	TIME [epoch: 9.59 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7057851259035064		[learning rate: 0.0043983]
	Learning Rate: 0.00439827
	LOSS [training: 1.7057851259035064 | validation: 1.366821746112135]
	TIME [epoch: 9.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3219889758856893		[learning rate: 0.0043879]
	Learning Rate: 0.0043879
	LOSS [training: 1.3219889758856893 | validation: 1.3662979053351212]
	TIME [epoch: 9.62 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2755867146147617		[learning rate: 0.0043775]
	Learning Rate: 0.00437755
	LOSS [training: 1.2755867146147617 | validation: 2.0454514856562085]
	TIME [epoch: 9.63 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5284979979231004		[learning rate: 0.0043672]
	Learning Rate: 0.00436722
	LOSS [training: 1.5284979979231004 | validation: 1.5680041143958159]
	TIME [epoch: 9.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3987837902588176		[learning rate: 0.0043569]
	Learning Rate: 0.00435692
	LOSS [training: 1.3987837902588176 | validation: 1.7666575770650914]
	TIME [epoch: 9.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.354103244702403		[learning rate: 0.0043466]
	Learning Rate: 0.00434664
	LOSS [training: 1.354103244702403 | validation: 1.4784865790456097]
	TIME [epoch: 9.64 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3218967115641393		[learning rate: 0.0043364]
	Learning Rate: 0.00433639
	LOSS [training: 1.3218967115641393 | validation: 1.3138274163047572]
	TIME [epoch: 9.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1599735281647086		[learning rate: 0.0043262]
	Learning Rate: 0.00432616
	LOSS [training: 1.1599735281647086 | validation: 1.3190136407037536]
	TIME [epoch: 9.62 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3196763502570246		[learning rate: 0.004316]
	Learning Rate: 0.00431596
	LOSS [training: 1.3196763502570246 | validation: 1.4317911875610176]
	TIME [epoch: 9.61 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.226407714224722		[learning rate: 0.0043058]
	Learning Rate: 0.00430577
	LOSS [training: 1.226407714224722 | validation: 1.2840361781775167]
	TIME [epoch: 9.62 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.352476391916439		[learning rate: 0.0042956]
	Learning Rate: 0.00429562
	LOSS [training: 1.352476391916439 | validation: 1.3161366656010762]
	TIME [epoch: 9.63 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5358206117702846		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 1.5358206117702846 | validation: 1.900088367458057]
	TIME [epoch: 9.59 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7368644363504153		[learning rate: 0.0042754]
	Learning Rate: 0.00427538
	LOSS [training: 1.7368644363504153 | validation: 1.2423886096804417]
	TIME [epoch: 9.61 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2535251715855107		[learning rate: 0.0042653]
	Learning Rate: 0.00426529
	LOSS [training: 1.2535251715855107 | validation: 1.3527303618051314]
	TIME [epoch: 9.63 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4642686349223357		[learning rate: 0.0042552]
	Learning Rate: 0.00425523
	LOSS [training: 1.4642686349223357 | validation: 1.5823207871681522]
	TIME [epoch: 9.62 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5747770966236003		[learning rate: 0.0042452]
	Learning Rate: 0.00424519
	LOSS [training: 1.5747770966236003 | validation: 1.547202337294095]
	TIME [epoch: 9.59 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.377875493710227		[learning rate: 0.0042352]
	Learning Rate: 0.00423518
	LOSS [training: 1.377875493710227 | validation: 1.3294488141877883]
	TIME [epoch: 9.63 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.246690762585464		[learning rate: 0.0042252]
	Learning Rate: 0.00422519
	LOSS [training: 1.246690762585464 | validation: 1.3855982456630545]
	TIME [epoch: 9.59 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4433135063917941		[learning rate: 0.0042152]
	Learning Rate: 0.00421522
	LOSS [training: 1.4433135063917941 | validation: 2.296182512413121]
	TIME [epoch: 9.58 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.624752303755061		[learning rate: 0.0042053]
	Learning Rate: 0.00420528
	LOSS [training: 1.624752303755061 | validation: 1.7115135970250728]
	TIME [epoch: 9.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7238116513753845		[learning rate: 0.0041954]
	Learning Rate: 0.00419536
	LOSS [training: 1.7238116513753845 | validation: 1.926944281116438]
	TIME [epoch: 9.63 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5743891830307142		[learning rate: 0.0041855]
	Learning Rate: 0.00418546
	LOSS [training: 1.5743891830307142 | validation: 1.5229862372824028]
	TIME [epoch: 9.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2869780474259478		[learning rate: 0.0041756]
	Learning Rate: 0.00417559
	LOSS [training: 1.2869780474259478 | validation: 1.353892450551935]
	TIME [epoch: 9.59 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3020052697108866		[learning rate: 0.0041657]
	Learning Rate: 0.00416574
	LOSS [training: 1.3020052697108866 | validation: 1.4613863815514738]
	TIME [epoch: 9.62 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.355952810030812		[learning rate: 0.0041559]
	Learning Rate: 0.00415592
	LOSS [training: 1.355952810030812 | validation: 1.798153059342569]
	TIME [epoch: 9.65 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3960649287589821		[learning rate: 0.0041461]
	Learning Rate: 0.00414611
	LOSS [training: 1.3960649287589821 | validation: 1.1227429329259477]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_423.pth
	Model improved!!!
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.111683269398028		[learning rate: 0.0041363]
	Learning Rate: 0.00413633
	LOSS [training: 1.111683269398028 | validation: 1.6285252201981377]
	TIME [epoch: 9.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2613290154302994		[learning rate: 0.0041266]
	Learning Rate: 0.00412657
	LOSS [training: 1.2613290154302994 | validation: 1.4495507311511504]
	TIME [epoch: 9.63 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.290118285630654		[learning rate: 0.0041168]
	Learning Rate: 0.00411684
	LOSS [training: 1.290118285630654 | validation: 1.3199881165036922]
	TIME [epoch: 9.64 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.165212489456853		[learning rate: 0.0041071]
	Learning Rate: 0.00410713
	LOSS [training: 1.165212489456853 | validation: 1.2984210933631142]
	TIME [epoch: 9.64 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2061464840050227		[learning rate: 0.0040974]
	Learning Rate: 0.00409744
	LOSS [training: 1.2061464840050227 | validation: 1.2130665281744448]
	TIME [epoch: 9.59 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2147165224646677		[learning rate: 0.0040878]
	Learning Rate: 0.00408778
	LOSS [training: 1.2147165224646677 | validation: 1.545095404808456]
	TIME [epoch: 9.65 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7309817040183488		[learning rate: 0.0040781]
	Learning Rate: 0.00407813
	LOSS [training: 1.7309817040183488 | validation: 1.4000915728989913]
	TIME [epoch: 9.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2773975225478305		[learning rate: 0.0040685]
	Learning Rate: 0.00406851
	LOSS [training: 1.2773975225478305 | validation: 1.298177821482975]
	TIME [epoch: 9.61 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1999225720366604		[learning rate: 0.0040589]
	Learning Rate: 0.00405892
	LOSS [training: 1.1999225720366604 | validation: 1.4508134619725714]
	TIME [epoch: 9.62 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2063979928423763		[learning rate: 0.0040493]
	Learning Rate: 0.00404934
	LOSS [training: 1.2063979928423763 | validation: 1.260164307423385]
	TIME [epoch: 9.64 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.087209768620862		[learning rate: 0.0040398]
	Learning Rate: 0.00403979
	LOSS [training: 1.087209768620862 | validation: 1.7841824875383197]
	TIME [epoch: 9.65 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2115503706312496		[learning rate: 0.0040303]
	Learning Rate: 0.00403026
	LOSS [training: 1.2115503706312496 | validation: 1.7471250750058585]
	TIME [epoch: 9.61 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4029648209307628		[learning rate: 0.0040208]
	Learning Rate: 0.00402076
	LOSS [training: 1.4029648209307628 | validation: 1.6388409940351159]
	TIME [epoch: 9.59 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2419949641545884		[learning rate: 0.0040113]
	Learning Rate: 0.00401127
	LOSS [training: 1.2419949641545884 | validation: 1.3778675576663477]
	TIME [epoch: 9.65 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3590185126959011		[learning rate: 0.0040018]
	Learning Rate: 0.00400181
	LOSS [training: 1.3590185126959011 | validation: 1.5911130119198265]
	TIME [epoch: 9.62 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3907402039098906		[learning rate: 0.0039924]
	Learning Rate: 0.00399237
	LOSS [training: 1.3907402039098906 | validation: 1.2893539569154262]
	TIME [epoch: 9.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.124852809064171		[learning rate: 0.003983]
	Learning Rate: 0.00398295
	LOSS [training: 1.124852809064171 | validation: 1.7067734302405797]
	TIME [epoch: 9.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2006368188791277		[learning rate: 0.0039736]
	Learning Rate: 0.00397356
	LOSS [training: 1.2006368188791277 | validation: 1.279217207838801]
	TIME [epoch: 9.66 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2959986281294023		[learning rate: 0.0039642]
	Learning Rate: 0.00396418
	LOSS [training: 1.2959986281294023 | validation: 1.4618884763488436]
	TIME [epoch: 9.61 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2471100279850036		[learning rate: 0.0039548]
	Learning Rate: 0.00395483
	LOSS [training: 1.2471100279850036 | validation: 1.453713145829761]
	TIME [epoch: 9.63 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2429876573814163		[learning rate: 0.0039455]
	Learning Rate: 0.0039455
	LOSS [training: 1.2429876573814163 | validation: 1.4475139914933446]
	TIME [epoch: 9.63 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.66916532908187		[learning rate: 0.0039362]
	Learning Rate: 0.0039362
	LOSS [training: 1.66916532908187 | validation: 2.889487337588493]
	TIME [epoch: 9.64 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8314391674941568		[learning rate: 0.0039269]
	Learning Rate: 0.00392691
	LOSS [training: 1.8314391674941568 | validation: 1.410045536923848]
	TIME [epoch: 9.61 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5235619540777674		[learning rate: 0.0039176]
	Learning Rate: 0.00391765
	LOSS [training: 1.5235619540777674 | validation: 1.645394551190826]
	TIME [epoch: 9.65 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.564894565368785		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 1.564894565368785 | validation: 1.8895538462245274]
	TIME [epoch: 9.67 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4001439608650614		[learning rate: 0.0038992]
	Learning Rate: 0.00389919
	LOSS [training: 1.4001439608650614 | validation: 1.4613269626631717]
	TIME [epoch: 9.63 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.395917704143868		[learning rate: 0.00389]
	Learning Rate: 0.00388999
	LOSS [training: 1.395917704143868 | validation: 1.4516641109175907]
	TIME [epoch: 9.61 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3257237116621616		[learning rate: 0.0038808]
	Learning Rate: 0.00388082
	LOSS [training: 1.3257237116621616 | validation: 1.3883932625956878]
	TIME [epoch: 9.63 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4463209473817615		[learning rate: 0.0038717]
	Learning Rate: 0.00387166
	LOSS [training: 1.4463209473817615 | validation: 1.617709279145176]
	TIME [epoch: 9.65 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5740063668656714		[learning rate: 0.0038625]
	Learning Rate: 0.00386253
	LOSS [training: 1.5740063668656714 | validation: 1.3304247886756766]
	TIME [epoch: 9.64 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1972468734221557		[learning rate: 0.0038534]
	Learning Rate: 0.00385342
	LOSS [training: 1.1972468734221557 | validation: 1.721625600675386]
	TIME [epoch: 9.61 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8639752261898352		[learning rate: 0.0038443]
	Learning Rate: 0.00384433
	LOSS [training: 1.8639752261898352 | validation: 1.5138463939961981]
	TIME [epoch: 9.62 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3514217329021652		[learning rate: 0.0038353]
	Learning Rate: 0.00383526
	LOSS [training: 1.3514217329021652 | validation: 1.482791676925015]
	TIME [epoch: 9.65 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4464735516006615		[learning rate: 0.0038262]
	Learning Rate: 0.00382621
	LOSS [training: 1.4464735516006615 | validation: 1.3264593108983294]
	TIME [epoch: 9.64 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.440075649876588		[learning rate: 0.0038172]
	Learning Rate: 0.00381719
	LOSS [training: 1.440075649876588 | validation: 1.3536921865961575]
	TIME [epoch: 9.63 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2278883041982538		[learning rate: 0.0038082]
	Learning Rate: 0.00380818
	LOSS [training: 1.2278883041982538 | validation: 1.324198913936932]
	TIME [epoch: 9.66 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3304498586077682		[learning rate: 0.0037992]
	Learning Rate: 0.0037992
	LOSS [training: 1.3304498586077682 | validation: 2.32303515518849]
	TIME [epoch: 9.66 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6522784169339761		[learning rate: 0.0037902]
	Learning Rate: 0.00379024
	LOSS [training: 1.6522784169339761 | validation: 1.269415435646026]
	TIME [epoch: 9.61 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5045852207678028		[learning rate: 0.0037813]
	Learning Rate: 0.0037813
	LOSS [training: 1.5045852207678028 | validation: 1.446200598595987]
	TIME [epoch: 9.63 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.317862773146554		[learning rate: 0.0037724]
	Learning Rate: 0.00377238
	LOSS [training: 1.317862773146554 | validation: 1.6468696504946798]
	TIME [epoch: 9.64 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.281350782385132		[learning rate: 0.0037635]
	Learning Rate: 0.00376348
	LOSS [training: 1.281350782385132 | validation: 1.353306017029081]
	TIME [epoch: 9.64 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2237363013773632		[learning rate: 0.0037546]
	Learning Rate: 0.0037546
	LOSS [training: 1.2237363013773632 | validation: 1.2185804444067272]
	TIME [epoch: 9.63 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2104685358670597		[learning rate: 0.0037457]
	Learning Rate: 0.00374575
	LOSS [training: 1.2104685358670597 | validation: 1.3979166905253626]
	TIME [epoch: 9.62 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4103911384595305		[learning rate: 0.0037369]
	Learning Rate: 0.00373691
	LOSS [training: 1.4103911384595305 | validation: 1.4559503500456186]
	TIME [epoch: 9.67 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4853385077569095		[learning rate: 0.0037281]
	Learning Rate: 0.0037281
	LOSS [training: 1.4853385077569095 | validation: 1.6026289633682405]
	TIME [epoch: 9.63 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4330885942706715		[learning rate: 0.0037193]
	Learning Rate: 0.0037193
	LOSS [training: 1.4330885942706715 | validation: 1.644435697738161]
	TIME [epoch: 9.61 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.246049676821793		[learning rate: 0.0037105]
	Learning Rate: 0.00371053
	LOSS [training: 1.246049676821793 | validation: 1.2169745822087559]
	TIME [epoch: 9.63 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.289525806780143		[learning rate: 0.0037018]
	Learning Rate: 0.00370178
	LOSS [training: 1.289525806780143 | validation: 1.359735301703303]
	TIME [epoch: 9.64 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.186389360033386		[learning rate: 0.003693]
	Learning Rate: 0.00369304
	LOSS [training: 1.186389360033386 | validation: 1.4209100655043192]
	TIME [epoch: 9.61 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.291483542789986		[learning rate: 0.0036843]
	Learning Rate: 0.00368433
	LOSS [training: 1.291483542789986 | validation: 1.395301188697296]
	TIME [epoch: 9.61 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3715603718529867		[learning rate: 0.0036756]
	Learning Rate: 0.00367564
	LOSS [training: 1.3715603718529867 | validation: 1.271758647221501]
	TIME [epoch: 9.64 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2842916721266582		[learning rate: 0.003667]
	Learning Rate: 0.00366697
	LOSS [training: 1.2842916721266582 | validation: 1.2806973361807679]
	TIME [epoch: 9.63 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2236176622080168		[learning rate: 0.0036583]
	Learning Rate: 0.00365832
	LOSS [training: 1.2236176622080168 | validation: 1.3858151586463645]
	TIME [epoch: 9.62 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3873659624702486		[learning rate: 0.0036497]
	Learning Rate: 0.00364969
	LOSS [training: 1.3873659624702486 | validation: 1.4692889889413574]
	TIME [epoch: 9.6 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2420751375748256		[learning rate: 0.0036411]
	Learning Rate: 0.00364108
	LOSS [training: 1.2420751375748256 | validation: 1.3489626843488787]
	TIME [epoch: 9.65 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2566494064086453		[learning rate: 0.0036325]
	Learning Rate: 0.0036325
	LOSS [training: 1.2566494064086453 | validation: 1.2448121838418633]
	TIME [epoch: 9.62 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.210674821226363		[learning rate: 0.0036239]
	Learning Rate: 0.00362393
	LOSS [training: 1.210674821226363 | validation: 1.4965180686369792]
	TIME [epoch: 9.63 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3266428827690533		[learning rate: 0.0036154]
	Learning Rate: 0.00361538
	LOSS [training: 1.3266428827690533 | validation: 1.5053809834684244]
	TIME [epoch: 9.63 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2518208403936137		[learning rate: 0.0036069]
	Learning Rate: 0.00360685
	LOSS [training: 1.2518208403936137 | validation: 1.1215900639549619]
	TIME [epoch: 9.64 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_482.pth
	Model improved!!!
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1047375002413806		[learning rate: 0.0035983]
	Learning Rate: 0.00359834
	LOSS [training: 1.1047375002413806 | validation: 1.1657032424347862]
	TIME [epoch: 9.62 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1945702392991038		[learning rate: 0.0035899]
	Learning Rate: 0.00358986
	LOSS [training: 1.1945702392991038 | validation: 1.5113837582945049]
	TIME [epoch: 9.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4212235858237605		[learning rate: 0.0035814]
	Learning Rate: 0.00358139
	LOSS [training: 1.4212235858237605 | validation: 1.2366114076628092]
	TIME [epoch: 9.61 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1082674860036557		[learning rate: 0.0035729]
	Learning Rate: 0.00357294
	LOSS [training: 1.1082674860036557 | validation: 1.1919680987508505]
	TIME [epoch: 9.63 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1778644892171997		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 1.1778644892171997 | validation: 1.2846358260573834]
	TIME [epoch: 9.61 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1144327395794407		[learning rate: 0.0035561]
	Learning Rate: 0.0035561
	LOSS [training: 1.1144327395794407 | validation: 1.2470019332067688]
	TIME [epoch: 9.6 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2391558815537924		[learning rate: 0.0035477]
	Learning Rate: 0.00354771
	LOSS [training: 1.2391558815537924 | validation: 1.4853497260377393]
	TIME [epoch: 9.63 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3376897679090562		[learning rate: 0.0035393]
	Learning Rate: 0.00353935
	LOSS [training: 1.3376897679090562 | validation: 1.3471026620059854]
	TIME [epoch: 9.61 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1557437786844968		[learning rate: 0.003531]
	Learning Rate: 0.003531
	LOSS [training: 1.1557437786844968 | validation: 1.2484158600617503]
	TIME [epoch: 9.61 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.177323627147479		[learning rate: 0.0035227]
	Learning Rate: 0.00352267
	LOSS [training: 1.177323627147479 | validation: 1.7552592244543856]
	TIME [epoch: 9.61 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3305292019169705		[learning rate: 0.0035144]
	Learning Rate: 0.00351436
	LOSS [training: 1.3305292019169705 | validation: 1.2082111829632651]
	TIME [epoch: 9.63 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4530258140880765		[learning rate: 0.0035061]
	Learning Rate: 0.00350607
	LOSS [training: 1.4530258140880765 | validation: 1.2243381836338665]
	TIME [epoch: 9.61 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.153128775542804		[learning rate: 0.0034978]
	Learning Rate: 0.0034978
	LOSS [training: 1.153128775542804 | validation: 1.308773323947367]
	TIME [epoch: 9.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1011919577523996		[learning rate: 0.0034895]
	Learning Rate: 0.00348955
	LOSS [training: 1.1011919577523996 | validation: 1.1631033510153592]
	TIME [epoch: 9.61 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0965815719315906		[learning rate: 0.0034813]
	Learning Rate: 0.00348132
	LOSS [training: 1.0965815719315906 | validation: 1.1675290178831739]
	TIME [epoch: 9.62 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.108683474745027		[learning rate: 0.0034731]
	Learning Rate: 0.00347311
	LOSS [training: 1.108683474745027 | validation: 1.257280406897833]
	TIME [epoch: 9.61 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2647387442879345		[learning rate: 0.0034649]
	Learning Rate: 0.00346491
	LOSS [training: 1.2647387442879345 | validation: 1.2819649651192702]
	TIME [epoch: 9.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2036228656759662		[learning rate: 0.0034567]
	Learning Rate: 0.00345674
	LOSS [training: 1.2036228656759662 | validation: 1.2641271481150065]
	TIME [epoch: 9.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1085964498122318		[learning rate: 0.0034486]
	Learning Rate: 0.00344859
	LOSS [training: 1.1085964498122318 | validation: 1.2486115511658795]
	TIME [epoch: 9.63 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.165260115133637		[learning rate: 0.0034405]
	Learning Rate: 0.00344045
	LOSS [training: 1.165260115133637 | validation: 1.6549671657633318]
	TIME [epoch: 9.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2944707242752134		[learning rate: 0.0034323]
	Learning Rate: 0.00343234
	LOSS [training: 1.2944707242752134 | validation: 1.2093771291321895]
	TIME [epoch: 9.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1350741642065667		[learning rate: 0.0034242]
	Learning Rate: 0.00342424
	LOSS [training: 1.1350741642065667 | validation: 1.4178604544105797]
	TIME [epoch: 9.62 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.169506536848957		[learning rate: 0.0034162]
	Learning Rate: 0.00341616
	LOSS [training: 1.169506536848957 | validation: 1.1480978902122008]
	TIME [epoch: 9.62 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.107364731312481		[learning rate: 0.0034081]
	Learning Rate: 0.0034081
	LOSS [training: 1.107364731312481 | validation: 1.2375655536166728]
	TIME [epoch: 9.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.190155842691559		[learning rate: 0.0034001]
	Learning Rate: 0.00340006
	LOSS [training: 1.190155842691559 | validation: 1.1660849153761865]
	TIME [epoch: 9.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1834476578656887		[learning rate: 0.003392]
	Learning Rate: 0.00339204
	LOSS [training: 1.1834476578656887 | validation: 1.1976630697261375]
	TIME [epoch: 9.63 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.160982780774714		[learning rate: 0.003384]
	Learning Rate: 0.00338404
	LOSS [training: 1.160982780774714 | validation: 1.2879310194551818]
	TIME [epoch: 9.61 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1650115533922119		[learning rate: 0.0033761]
	Learning Rate: 0.00337606
	LOSS [training: 1.1650115533922119 | validation: 1.24741279175559]
	TIME [epoch: 9.61 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1152926865311925		[learning rate: 0.0033681]
	Learning Rate: 0.0033681
	LOSS [training: 1.1152926865311925 | validation: 1.115380521101498]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_511.pth
	Model improved!!!
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1175623810461388		[learning rate: 0.0033602]
	Learning Rate: 0.00336015
	LOSS [training: 1.1175623810461388 | validation: 1.266387602227413]
	TIME [epoch: 9.64 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1558388962072805		[learning rate: 0.0033522]
	Learning Rate: 0.00335223
	LOSS [training: 2.1558388962072805 | validation: 2.565922514840313]
	TIME [epoch: 9.62 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7021992188579957		[learning rate: 0.0033443]
	Learning Rate: 0.00334432
	LOSS [training: 1.7021992188579957 | validation: 1.3808256056210306]
	TIME [epoch: 9.61 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0692588995354173		[learning rate: 0.0033364]
	Learning Rate: 0.00333643
	LOSS [training: 1.0692588995354173 | validation: 1.1821439946456442]
	TIME [epoch: 9.63 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2595113099380626		[learning rate: 0.0033286]
	Learning Rate: 0.00332856
	LOSS [training: 1.2595113099380626 | validation: 1.524787901795532]
	TIME [epoch: 9.63 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.429248866110644		[learning rate: 0.0033207]
	Learning Rate: 0.00332071
	LOSS [training: 1.429248866110644 | validation: 1.3222551258812625]
	TIME [epoch: 9.62 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3502187941124697		[learning rate: 0.0033129]
	Learning Rate: 0.00331288
	LOSS [training: 1.3502187941124697 | validation: 1.198427601193734]
	TIME [epoch: 9.61 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2587765347648268		[learning rate: 0.0033051]
	Learning Rate: 0.00330506
	LOSS [training: 1.2587765347648268 | validation: 1.2073710760476344]
	TIME [epoch: 9.63 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2099807986019457		[learning rate: 0.0032973]
	Learning Rate: 0.00329727
	LOSS [training: 1.2099807986019457 | validation: 1.4570909809146009]
	TIME [epoch: 9.61 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3563202132733418		[learning rate: 0.0032895]
	Learning Rate: 0.00328949
	LOSS [training: 1.3563202132733418 | validation: 1.2285974527281336]
	TIME [epoch: 9.61 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.36778116351087		[learning rate: 0.0032817]
	Learning Rate: 0.00328173
	LOSS [training: 1.36778116351087 | validation: 1.2182350906691943]
	TIME [epoch: 9.62 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0799293665055385		[learning rate: 0.003274]
	Learning Rate: 0.00327399
	LOSS [training: 1.0799293665055385 | validation: 1.2513657633238315]
	TIME [epoch: 9.64 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0714479517018174		[learning rate: 0.0032663]
	Learning Rate: 0.00326626
	LOSS [training: 1.0714479517018174 | validation: 1.1000175005805826]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_524.pth
	Model improved!!!
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0135753400939063		[learning rate: 0.0032586]
	Learning Rate: 0.00325856
	LOSS [training: 1.0135753400939063 | validation: 1.3119999727807348]
	TIME [epoch: 9.63 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1299742688418424		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 1.1299742688418424 | validation: 1.438048448337179]
	TIME [epoch: 9.61 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1533573011304128		[learning rate: 0.0032432]
	Learning Rate: 0.0032432
	LOSS [training: 1.1533573011304128 | validation: 1.2054333565345048]
	TIME [epoch: 9.65 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0677376683080795		[learning rate: 0.0032356]
	Learning Rate: 0.00323555
	LOSS [training: 1.0677376683080795 | validation: 1.2592658824042757]
	TIME [epoch: 9.59 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0383667286730787		[learning rate: 0.0032279]
	Learning Rate: 0.00322792
	LOSS [training: 1.0383667286730787 | validation: 1.0280775681735463]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_529.pth
	Model improved!!!
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.027981073358453		[learning rate: 0.0032203]
	Learning Rate: 0.00322031
	LOSS [training: 1.027981073358453 | validation: 1.149712265625496]
	TIME [epoch: 9.63 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1707199637738612		[learning rate: 0.0032127]
	Learning Rate: 0.00321271
	LOSS [training: 1.1707199637738612 | validation: 1.3217652345629407]
	TIME [epoch: 9.63 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2296420382713846		[learning rate: 0.0032051]
	Learning Rate: 0.00320513
	LOSS [training: 1.2296420382713846 | validation: 1.4438420000250503]
	TIME [epoch: 9.63 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1817642025898976		[learning rate: 0.0031976]
	Learning Rate: 0.00319757
	LOSS [training: 1.1817642025898976 | validation: 1.55742988363647]
	TIME [epoch: 9.64 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0632584835390213		[learning rate: 0.00319]
	Learning Rate: 0.00319003
	LOSS [training: 1.0632584835390213 | validation: 1.0984168466345055]
	TIME [epoch: 9.66 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1006299983441463		[learning rate: 0.0031825]
	Learning Rate: 0.00318251
	LOSS [training: 1.1006299983441463 | validation: 1.36524623788282]
	TIME [epoch: 9.63 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.194330738007404		[learning rate: 0.003175]
	Learning Rate: 0.003175
	LOSS [training: 1.194330738007404 | validation: 1.319297898272503]
	TIME [epoch: 9.62 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.120765959246789		[learning rate: 0.0031675]
	Learning Rate: 0.00316751
	LOSS [training: 1.120765959246789 | validation: 1.26638693246186]
	TIME [epoch: 9.63 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0775925961104302		[learning rate: 0.00316]
	Learning Rate: 0.00316004
	LOSS [training: 1.0775925961104302 | validation: 1.0052460908759298]
	TIME [epoch: 9.64 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_538.pth
	Model improved!!!
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0165566436066364		[learning rate: 0.0031526]
	Learning Rate: 0.00315258
	LOSS [training: 1.0165566436066364 | validation: 1.2149268181362114]
	TIME [epoch: 9.63 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0378159344350297		[learning rate: 0.0031451]
	Learning Rate: 0.00314515
	LOSS [training: 1.0378159344350297 | validation: 1.0420540533185845]
	TIME [epoch: 9.63 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0126104393838762		[learning rate: 0.0031377]
	Learning Rate: 0.00313773
	LOSS [training: 1.0126104393838762 | validation: 1.2367313714699273]
	TIME [epoch: 9.63 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0201807393968971		[learning rate: 0.0031303]
	Learning Rate: 0.00313033
	LOSS [training: 1.0201807393968971 | validation: 1.146515888153176]
	TIME [epoch: 9.64 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.214059566533196		[learning rate: 0.0031229]
	Learning Rate: 0.00312294
	LOSS [training: 1.214059566533196 | validation: 1.4225940455308201]
	TIME [epoch: 9.63 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1323240553424387		[learning rate: 0.0031156]
	Learning Rate: 0.00311558
	LOSS [training: 1.1323240553424387 | validation: 1.4084854865876293]
	TIME [epoch: 9.62 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0541824723183368		[learning rate: 0.0031082]
	Learning Rate: 0.00310823
	LOSS [training: 1.0541824723183368 | validation: 1.1978605211744038]
	TIME [epoch: 9.65 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.074145254970788		[learning rate: 0.0031009]
	Learning Rate: 0.0031009
	LOSS [training: 1.074145254970788 | validation: 1.101085029522093]
	TIME [epoch: 9.64 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0663267078913043		[learning rate: 0.0030936]
	Learning Rate: 0.00309358
	LOSS [training: 1.0663267078913043 | validation: 1.1167752011618703]
	TIME [epoch: 9.64 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0637124319395344		[learning rate: 0.0030863]
	Learning Rate: 0.00308628
	LOSS [training: 1.0637124319395344 | validation: 1.2183643662535015]
	TIME [epoch: 9.63 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.082317476120667		[learning rate: 0.003079]
	Learning Rate: 0.003079
	LOSS [training: 1.082317476120667 | validation: 1.1862664491854966]
	TIME [epoch: 9.65 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0308070930658193		[learning rate: 0.0030717]
	Learning Rate: 0.00307174
	LOSS [training: 1.0308070930658193 | validation: 1.5048612771689813]
	TIME [epoch: 9.64 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2675621484806041		[learning rate: 0.0030645]
	Learning Rate: 0.0030645
	LOSS [training: 1.2675621484806041 | validation: 1.202417921589893]
	TIME [epoch: 9.61 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0480611507898856		[learning rate: 0.0030573]
	Learning Rate: 0.00305727
	LOSS [training: 1.0480611507898856 | validation: 1.3316264820519155]
	TIME [epoch: 9.62 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2153950028845215		[learning rate: 0.0030501]
	Learning Rate: 0.00305006
	LOSS [training: 1.2153950028845215 | validation: 1.272326907607183]
	TIME [epoch: 9.65 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0384092272189187		[learning rate: 0.0030429]
	Learning Rate: 0.00304286
	LOSS [training: 1.0384092272189187 | validation: 1.1096714895941813]
	TIME [epoch: 9.63 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9910638326071849		[learning rate: 0.0030357]
	Learning Rate: 0.00303568
	LOSS [training: 0.9910638326071849 | validation: 1.0684074270975212]
	TIME [epoch: 9.63 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0141371482439858		[learning rate: 0.0030285]
	Learning Rate: 0.00302852
	LOSS [training: 1.0141371482439858 | validation: 1.7198445028787621]
	TIME [epoch: 9.63 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5436808686415318		[learning rate: 0.0030214]
	Learning Rate: 0.00302138
	LOSS [training: 1.5436808686415318 | validation: 1.1543774401312539]
	TIME [epoch: 9.63 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.11234944027825		[learning rate: 0.0030143]
	Learning Rate: 0.00301425
	LOSS [training: 1.11234944027825 | validation: 1.168823242793378]
	TIME [epoch: 9.62 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0227608307971852		[learning rate: 0.0030071]
	Learning Rate: 0.00300714
	LOSS [training: 1.0227608307971852 | validation: 1.105905763116321]
	TIME [epoch: 9.63 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9847286116291988		[learning rate: 0.003]
	Learning Rate: 0.00300005
	LOSS [training: 0.9847286116291988 | validation: 1.2473516307421286]
	TIME [epoch: 9.64 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1168190131658347		[learning rate: 0.002993]
	Learning Rate: 0.00299297
	LOSS [training: 1.1168190131658347 | validation: 1.0737583213451405]
	TIME [epoch: 9.64 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.070913789402573		[learning rate: 0.0029859]
	Learning Rate: 0.00298591
	LOSS [training: 1.070913789402573 | validation: 1.0106474734789068]
	TIME [epoch: 9.62 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.051875078680706		[learning rate: 0.0029789]
	Learning Rate: 0.00297887
	LOSS [training: 1.051875078680706 | validation: 1.0329505079206174]
	TIME [epoch: 9.62 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.111458233387339		[learning rate: 0.0029718]
	Learning Rate: 0.00297184
	LOSS [training: 1.111458233387339 | validation: 1.570332443655758]
	TIME [epoch: 9.65 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2562923462644648		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 1.2562923462644648 | validation: 1.302950063753877]
	TIME [epoch: 9.61 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.435497051392959		[learning rate: 0.0029578]
	Learning Rate: 0.00295784
	LOSS [training: 1.435497051392959 | validation: 1.6018282772097394]
	TIME [epoch: 9.63 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2617357728083323		[learning rate: 0.0029509]
	Learning Rate: 0.00295086
	LOSS [training: 1.2617357728083323 | validation: 1.1536128639735903]
	TIME [epoch: 9.62 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0135481053990343		[learning rate: 0.0029439]
	Learning Rate: 0.0029439
	LOSS [training: 1.0135481053990343 | validation: 1.3523804563516961]
	TIME [epoch: 9.65 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.192843067193397		[learning rate: 0.002937]
	Learning Rate: 0.00293696
	LOSS [training: 1.192843067193397 | validation: 1.1461211949969732]
	TIME [epoch: 9.63 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0447857973119832		[learning rate: 0.00293]
	Learning Rate: 0.00293003
	LOSS [training: 1.0447857973119832 | validation: 1.0853961197435869]
	TIME [epoch: 9.61 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0002373218757679		[learning rate: 0.0029231]
	Learning Rate: 0.00292312
	LOSS [training: 1.0002373218757679 | validation: 1.0726580628016347]
	TIME [epoch: 9.63 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0758859571780426		[learning rate: 0.0029162]
	Learning Rate: 0.00291622
	LOSS [training: 1.0758859571780426 | validation: 1.1132410337427723]
	TIME [epoch: 9.64 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1003151241771225		[learning rate: 0.0029093]
	Learning Rate: 0.00290934
	LOSS [training: 1.1003151241771225 | validation: 1.0716806542906536]
	TIME [epoch: 9.62 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0916190089648363		[learning rate: 0.0029025]
	Learning Rate: 0.00290248
	LOSS [training: 1.0916190089648363 | validation: 1.0561562411022742]
	TIME [epoch: 9.62 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.190982546664248		[learning rate: 0.0028956]
	Learning Rate: 0.00289563
	LOSS [training: 1.190982546664248 | validation: 1.1266268963886734]
	TIME [epoch: 9.62 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0129692405807402		[learning rate: 0.0028888]
	Learning Rate: 0.0028888
	LOSS [training: 1.0129692405807402 | validation: 1.0328657139224178]
	TIME [epoch: 9.62 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0295624937397894		[learning rate: 0.002882]
	Learning Rate: 0.00288199
	LOSS [training: 1.0295624937397894 | validation: 1.1217036287868765]
	TIME [epoch: 9.61 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0004847250151767		[learning rate: 0.0028752]
	Learning Rate: 0.00287519
	LOSS [training: 1.0004847250151767 | validation: 1.0957921209060222]
	TIME [epoch: 9.62 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9957373003933018		[learning rate: 0.0028684]
	Learning Rate: 0.00286841
	LOSS [training: 0.9957373003933018 | validation: 1.0854189210303877]
	TIME [epoch: 9.67 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9379508187461303		[learning rate: 0.0028616]
	Learning Rate: 0.00286164
	LOSS [training: 0.9379508187461303 | validation: 1.145526170435097]
	TIME [epoch: 9.63 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0863631787593486		[learning rate: 0.0028549]
	Learning Rate: 0.00285489
	LOSS [training: 1.0863631787593486 | validation: 1.014153287575334]
	TIME [epoch: 9.61 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0576963279832685		[learning rate: 0.0028482]
	Learning Rate: 0.00284816
	LOSS [training: 1.0576963279832685 | validation: 0.9693277124130114]
	TIME [epoch: 9.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_582.pth
	Model improved!!!
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.995187461370439		[learning rate: 0.0028414]
	Learning Rate: 0.00284144
	LOSS [training: 0.995187461370439 | validation: 0.9841269470316917]
	TIME [epoch: 9.64 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.084641109296274		[learning rate: 0.0028347]
	Learning Rate: 0.00283474
	LOSS [training: 1.084641109296274 | validation: 1.168804696224812]
	TIME [epoch: 9.64 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.046867476456161		[learning rate: 0.0028281]
	Learning Rate: 0.00282805
	LOSS [training: 1.046867476456161 | validation: 1.146765607481717]
	TIME [epoch: 9.61 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9728400956450608		[learning rate: 0.0028214]
	Learning Rate: 0.00282138
	LOSS [training: 0.9728400956450608 | validation: 1.1094767366129472]
	TIME [epoch: 9.63 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0349113702140036		[learning rate: 0.0028147]
	Learning Rate: 0.00281472
	LOSS [training: 1.0349113702140036 | validation: 1.094075709477594]
	TIME [epoch: 9.63 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0033588524058583		[learning rate: 0.0028081]
	Learning Rate: 0.00280808
	LOSS [training: 1.0033588524058583 | validation: 1.0186880792909359]
	TIME [epoch: 9.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0219534552761782		[learning rate: 0.0028015]
	Learning Rate: 0.00280146
	LOSS [training: 1.0219534552761782 | validation: 1.216607104513651]
	TIME [epoch: 9.62 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9630163278658322		[learning rate: 0.0027949]
	Learning Rate: 0.00279485
	LOSS [training: 0.9630163278658322 | validation: 1.096489840871278]
	TIME [epoch: 9.63 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0642296819753396		[learning rate: 0.0027883]
	Learning Rate: 0.00278826
	LOSS [training: 1.0642296819753396 | validation: 1.0374038225243094]
	TIME [epoch: 9.65 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0578704635424603		[learning rate: 0.0027817]
	Learning Rate: 0.00278168
	LOSS [training: 1.0578704635424603 | validation: 1.0316003649914718]
	TIME [epoch: 9.61 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9682383984620587		[learning rate: 0.0027751]
	Learning Rate: 0.00277512
	LOSS [training: 0.9682383984620587 | validation: 1.325988557879635]
	TIME [epoch: 9.61 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1664505350483192		[learning rate: 0.0027686]
	Learning Rate: 0.00276858
	LOSS [training: 1.1664505350483192 | validation: 1.1875096557608762]
	TIME [epoch: 9.64 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1024551681550678		[learning rate: 0.002762]
	Learning Rate: 0.00276205
	LOSS [training: 1.1024551681550678 | validation: 1.4627838522937473]
	TIME [epoch: 9.62 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1120646481687095		[learning rate: 0.0027555]
	Learning Rate: 0.00275553
	LOSS [training: 1.1120646481687095 | validation: 1.395663252087112]
	TIME [epoch: 9.62 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2004179202041132		[learning rate: 0.002749]
	Learning Rate: 0.00274903
	LOSS [training: 1.2004179202041132 | validation: 1.595803879915859]
	TIME [epoch: 9.62 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.435410747869021		[learning rate: 0.0027425]
	Learning Rate: 0.00274255
	LOSS [training: 1.435410747869021 | validation: 1.4859324218650098]
	TIME [epoch: 9.64 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.055677057697376		[learning rate: 0.0027361]
	Learning Rate: 0.00273608
	LOSS [training: 1.055677057697376 | validation: 1.0636919067377557]
	TIME [epoch: 9.63 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0536228750790957		[learning rate: 0.0027296]
	Learning Rate: 0.00272962
	LOSS [training: 1.0536228750790957 | validation: 1.511817872687928]
	TIME [epoch: 9.62 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4501944431612555		[learning rate: 0.0027232]
	Learning Rate: 0.00272318
	LOSS [training: 1.4501944431612555 | validation: 1.3845890276572228]
	TIME [epoch: 9.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0938723957151044		[learning rate: 0.0027168]
	Learning Rate: 0.00271676
	LOSS [training: 1.0938723957151044 | validation: 1.0565723199200716]
	TIME [epoch: 9.64 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.931984466174524		[learning rate: 0.0027104]
	Learning Rate: 0.00271035
	LOSS [training: 0.931984466174524 | validation: 1.0056784228981561]
	TIME [epoch: 9.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1237642002816384		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 1.1237642002816384 | validation: 1.1530606783698931]
	TIME [epoch: 9.63 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.061133316422137		[learning rate: 0.0026976]
	Learning Rate: 0.00269758
	LOSS [training: 1.061133316422137 | validation: 1.1354025216909684]
	TIME [epoch: 9.63 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0439017393049859		[learning rate: 0.0026912]
	Learning Rate: 0.00269122
	LOSS [training: 1.0439017393049859 | validation: 1.0891440706887816]
	TIME [epoch: 9.63 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9978027256911325		[learning rate: 0.0026849]
	Learning Rate: 0.00268487
	LOSS [training: 0.9978027256911325 | validation: 1.267702106573673]
	TIME [epoch: 9.62 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0324339869790533		[learning rate: 0.0026785]
	Learning Rate: 0.00267854
	LOSS [training: 1.0324339869790533 | validation: 1.0041495185649856]
	TIME [epoch: 9.61 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1219380762178992		[learning rate: 0.0026722]
	Learning Rate: 0.00267222
	LOSS [training: 1.1219380762178992 | validation: 1.1031367703634867]
	TIME [epoch: 9.62 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.036327320093083		[learning rate: 0.0026659]
	Learning Rate: 0.00266591
	LOSS [training: 1.036327320093083 | validation: 0.9759406902049028]
	TIME [epoch: 9.63 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9795169747911346		[learning rate: 0.0026596]
	Learning Rate: 0.00265963
	LOSS [training: 0.9795169747911346 | validation: 0.9551173746870913]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_611.pth
	Model improved!!!
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1003998958589538		[learning rate: 0.0026534]
	Learning Rate: 0.00265335
	LOSS [training: 1.1003998958589538 | validation: 0.9806088969448936]
	TIME [epoch: 9.64 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.031522689631626		[learning rate: 0.0026471]
	Learning Rate: 0.00264709
	LOSS [training: 1.031522689631626 | validation: 0.9607667681790361]
	TIME [epoch: 9.65 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9115135570226359		[learning rate: 0.0026408]
	Learning Rate: 0.00264085
	LOSS [training: 0.9115135570226359 | validation: 1.1447849637084155]
	TIME [epoch: 9.63 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1097911631859454		[learning rate: 0.0026346]
	Learning Rate: 0.00263462
	LOSS [training: 1.1097911631859454 | validation: 1.0853863020841539]
	TIME [epoch: 9.63 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9797461489182799		[learning rate: 0.0026284]
	Learning Rate: 0.00262841
	LOSS [training: 0.9797461489182799 | validation: 1.0047068873947569]
	TIME [epoch: 9.62 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1448941708231881		[learning rate: 0.0026222]
	Learning Rate: 0.00262221
	LOSS [training: 1.1448941708231881 | validation: 0.950478800967619]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_617.pth
	Model improved!!!
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9772286179087548		[learning rate: 0.002616]
	Learning Rate: 0.00261602
	LOSS [training: 0.9772286179087548 | validation: 1.059470338244264]
	TIME [epoch: 9.61 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.006641421076456		[learning rate: 0.0026098]
	Learning Rate: 0.00260985
	LOSS [training: 1.006641421076456 | validation: 0.9694097964824141]
	TIME [epoch: 9.61 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9284010277880463		[learning rate: 0.0026037]
	Learning Rate: 0.00260369
	LOSS [training: 0.9284010277880463 | validation: 1.0724294988967402]
	TIME [epoch: 9.62 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.975713432893877		[learning rate: 0.0025976]
	Learning Rate: 0.00259755
	LOSS [training: 0.975713432893877 | validation: 1.0190230618014362]
	TIME [epoch: 9.62 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9709358454175188		[learning rate: 0.0025914]
	Learning Rate: 0.00259142
	LOSS [training: 0.9709358454175188 | validation: 1.1495940128923667]
	TIME [epoch: 9.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.311801116658275		[learning rate: 0.0025853]
	Learning Rate: 0.00258531
	LOSS [training: 1.311801116658275 | validation: 1.0813275634300576]
	TIME [epoch: 9.59 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0672888621500913		[learning rate: 0.0025792]
	Learning Rate: 0.00257921
	LOSS [training: 1.0672888621500913 | validation: 1.3026555135624245]
	TIME [epoch: 9.64 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9655837672997516		[learning rate: 0.0025731]
	Learning Rate: 0.00257313
	LOSS [training: 0.9655837672997516 | validation: 0.9676211495114336]
	TIME [epoch: 9.61 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9623216768496716		[learning rate: 0.0025671]
	Learning Rate: 0.00256706
	LOSS [training: 0.9623216768496716 | validation: 0.9485875161570425]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_626.pth
	Model improved!!!
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9469224498367405		[learning rate: 0.002561]
	Learning Rate: 0.002561
	LOSS [training: 0.9469224498367405 | validation: 1.2294015036812511]
	TIME [epoch: 9.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0459057048869724		[learning rate: 0.002555]
	Learning Rate: 0.00255496
	LOSS [training: 1.0459057048869724 | validation: 1.0450009651055565]
	TIME [epoch: 9.63 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9095914621930797		[learning rate: 0.0025489]
	Learning Rate: 0.00254894
	LOSS [training: 0.9095914621930797 | validation: 1.001800064187272]
	TIME [epoch: 9.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9181390176219753		[learning rate: 0.0025429]
	Learning Rate: 0.00254292
	LOSS [training: 0.9181390176219753 | validation: 1.2494986096182024]
	TIME [epoch: 9.58 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0040083710384657		[learning rate: 0.0025369]
	Learning Rate: 0.00253693
	LOSS [training: 1.0040083710384657 | validation: 1.4134077990637122]
	TIME [epoch: 9.61 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0457126082659394		[learning rate: 0.0025309]
	Learning Rate: 0.00253094
	LOSS [training: 1.0457126082659394 | validation: 0.9668662994028021]
	TIME [epoch: 9.61 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9024592505198527		[learning rate: 0.002525]
	Learning Rate: 0.00252497
	LOSS [training: 0.9024592505198527 | validation: 1.0823503729072204]
	TIME [epoch: 9.61 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8683226699878848		[learning rate: 0.002519]
	Learning Rate: 0.00251901
	LOSS [training: 0.8683226699878848 | validation: 1.2242715199235568]
	TIME [epoch: 9.59 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9552442233944245		[learning rate: 0.0025131]
	Learning Rate: 0.00251307
	LOSS [training: 0.9552442233944245 | validation: 1.4865968376195673]
	TIME [epoch: 9.63 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9748684507954604		[learning rate: 0.0025071]
	Learning Rate: 0.00250715
	LOSS [training: 0.9748684507954604 | validation: 1.0459332021322367]
	TIME [epoch: 9.61 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0602756393152648		[learning rate: 0.0025012]
	Learning Rate: 0.00250123
	LOSS [training: 1.0602756393152648 | validation: 0.947184915834626]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_637.pth
	Model improved!!!
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.938320343137973		[learning rate: 0.0024953]
	Learning Rate: 0.00249533
	LOSS [training: 0.938320343137973 | validation: 1.0634446054147162]
	TIME [epoch: 9.61 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9704278556770551		[learning rate: 0.0024894]
	Learning Rate: 0.00248945
	LOSS [training: 0.9704278556770551 | validation: 1.0056986692791834]
	TIME [epoch: 9.62 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9497850392285295		[learning rate: 0.0024836]
	Learning Rate: 0.00248357
	LOSS [training: 0.9497850392285295 | validation: 0.9872670851333623]
	TIME [epoch: 9.61 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9462625724015361		[learning rate: 0.0024777]
	Learning Rate: 0.00247771
	LOSS [training: 0.9462625724015361 | validation: 1.1409848625038455]
	TIME [epoch: 9.62 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9316833916126706		[learning rate: 0.0024719]
	Learning Rate: 0.00247187
	LOSS [training: 0.9316833916126706 | validation: 1.0704234104975503]
	TIME [epoch: 9.59 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.026197337716451		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 1.026197337716451 | validation: 1.1568578182947464]
	TIME [epoch: 9.63 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9537357841951752		[learning rate: 0.0024602]
	Learning Rate: 0.00246022
	LOSS [training: 0.9537357841951752 | validation: 1.1307838561058543]
	TIME [epoch: 9.61 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9647571385446311		[learning rate: 0.0024544]
	Learning Rate: 0.00245442
	LOSS [training: 0.9647571385446311 | validation: 1.0422696915149952]
	TIME [epoch: 9.59 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.939802920228583		[learning rate: 0.0024486]
	Learning Rate: 0.00244863
	LOSS [training: 0.939802920228583 | validation: 1.0624216888002582]
	TIME [epoch: 9.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8905978847156557		[learning rate: 0.0024429]
	Learning Rate: 0.00244285
	LOSS [training: 0.8905978847156557 | validation: 1.1452653081171948]
	TIME [epoch: 9.61 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9117310964556099		[learning rate: 0.0024371]
	Learning Rate: 0.00243709
	LOSS [training: 0.9117310964556099 | validation: 1.1738165157161466]
	TIME [epoch: 9.63 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0780199749453814		[learning rate: 0.0024313]
	Learning Rate: 0.00243134
	LOSS [training: 1.0780199749453814 | validation: 0.9849153062781784]
	TIME [epoch: 9.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9273990436030921		[learning rate: 0.0024256]
	Learning Rate: 0.00242561
	LOSS [training: 0.9273990436030921 | validation: 0.9065033060273254]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_650.pth
	Model improved!!!
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8913313710639835		[learning rate: 0.0024199]
	Learning Rate: 0.00241989
	LOSS [training: 0.8913313710639835 | validation: 0.9975609611282436]
	TIME [epoch: 9.61 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9920072882288082		[learning rate: 0.0024142]
	Learning Rate: 0.00241418
	LOSS [training: 0.9920072882288082 | validation: 1.3123972891752067]
	TIME [epoch: 9.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0643223942933768		[learning rate: 0.0024085]
	Learning Rate: 0.00240848
	LOSS [training: 1.0643223942933768 | validation: 0.9950267628799928]
	TIME [epoch: 9.59 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9867338570801		[learning rate: 0.0024028]
	Learning Rate: 0.0024028
	LOSS [training: 0.9867338570801 | validation: 1.0754657017699978]
	TIME [epoch: 9.64 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9389825106428569		[learning rate: 0.0023971]
	Learning Rate: 0.00239713
	LOSS [training: 0.9389825106428569 | validation: 1.09568954752402]
	TIME [epoch: 9.61 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9677562682249443		[learning rate: 0.0023915]
	Learning Rate: 0.00239148
	LOSS [training: 0.9677562682249443 | validation: 1.0947864109874998]
	TIME [epoch: 9.61 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9836282517135396		[learning rate: 0.0023858]
	Learning Rate: 0.00238584
	LOSS [training: 0.9836282517135396 | validation: 1.0505258540113993]
	TIME [epoch: 9.63 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0426847465854558		[learning rate: 0.0023802]
	Learning Rate: 0.00238021
	LOSS [training: 1.0426847465854558 | validation: 1.309978219451628]
	TIME [epoch: 9.61 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9202042026000953		[learning rate: 0.0023746]
	Learning Rate: 0.0023746
	LOSS [training: 0.9202042026000953 | validation: 1.591081660059017]
	TIME [epoch: 9.62 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.073770108522944		[learning rate: 0.002369]
	Learning Rate: 0.00236899
	LOSS [training: 1.073770108522944 | validation: 1.2535379180891804]
	TIME [epoch: 9.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9554795576400303		[learning rate: 0.0023634]
	Learning Rate: 0.00236341
	LOSS [training: 0.9554795576400303 | validation: 1.0575703516164163]
	TIME [epoch: 9.64 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8440043886491913		[learning rate: 0.0023578]
	Learning Rate: 0.00235783
	LOSS [training: 0.8440043886491913 | validation: 0.9275854121425532]
	TIME [epoch: 9.61 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9030889750463496		[learning rate: 0.0023523]
	Learning Rate: 0.00235227
	LOSS [training: 0.9030889750463496 | validation: 0.9067965913537569]
	TIME [epoch: 9.61 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9251529045733733		[learning rate: 0.0023467]
	Learning Rate: 0.00234672
	LOSS [training: 0.9251529045733733 | validation: 0.9494646287537108]
	TIME [epoch: 9.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9628307562705306		[learning rate: 0.0023412]
	Learning Rate: 0.00234119
	LOSS [training: 0.9628307562705306 | validation: 1.2181253132802108]
	TIME [epoch: 9.63 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9295201409814325		[learning rate: 0.0023357]
	Learning Rate: 0.00233566
	LOSS [training: 0.9295201409814325 | validation: 0.8827442966322089]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_666.pth
	Model improved!!!
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8200699989226912		[learning rate: 0.0023302]
	Learning Rate: 0.00233015
	LOSS [training: 0.8200699989226912 | validation: 0.8585709820920354]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_667.pth
	Model improved!!!
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8147466295730942		[learning rate: 0.0023247]
	Learning Rate: 0.00232466
	LOSS [training: 0.8147466295730942 | validation: 0.9562615715207327]
	TIME [epoch: 9.59 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8736774429651704		[learning rate: 0.0023192]
	Learning Rate: 0.00231917
	LOSS [training: 0.8736774429651704 | validation: 1.04239044718623]
	TIME [epoch: 9.61 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9458019014143728		[learning rate: 0.0023137]
	Learning Rate: 0.0023137
	LOSS [training: 0.9458019014143728 | validation: 0.9892315188167345]
	TIME [epoch: 9.59 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9421270279147835		[learning rate: 0.0023082]
	Learning Rate: 0.00230825
	LOSS [training: 0.9421270279147835 | validation: 0.9266454736511741]
	TIME [epoch: 9.59 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9623762436547718		[learning rate: 0.0023028]
	Learning Rate: 0.0023028
	LOSS [training: 0.9623762436547718 | validation: 1.1071003827355854]
	TIME [epoch: 9.59 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8943236468428782		[learning rate: 0.0022974]
	Learning Rate: 0.00229737
	LOSS [training: 0.8943236468428782 | validation: 1.1317625305101038]
	TIME [epoch: 9.62 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8961449518245775		[learning rate: 0.0022919]
	Learning Rate: 0.00229195
	LOSS [training: 0.8961449518245775 | validation: 0.9998869378403185]
	TIME [epoch: 9.59 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8202743936837242		[learning rate: 0.0022865]
	Learning Rate: 0.00228654
	LOSS [training: 0.8202743936837242 | validation: 0.9692122095503836]
	TIME [epoch: 9.59 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9263220056158138		[learning rate: 0.0022811]
	Learning Rate: 0.00228115
	LOSS [training: 0.9263220056158138 | validation: 0.9753119447252527]
	TIME [epoch: 9.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8840740082103788		[learning rate: 0.0022758]
	Learning Rate: 0.00227577
	LOSS [training: 0.8840740082103788 | validation: 0.9291564602091686]
	TIME [epoch: 9.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8807534403336735		[learning rate: 0.0022704]
	Learning Rate: 0.0022704
	LOSS [training: 0.8807534403336735 | validation: 0.9082821934000939]
	TIME [epoch: 9.58 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8288081365178934		[learning rate: 0.002265]
	Learning Rate: 0.00226505
	LOSS [training: 0.8288081365178934 | validation: 1.0434708488360134]
	TIME [epoch: 9.59 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8379269374196922		[learning rate: 0.0022597]
	Learning Rate: 0.0022597
	LOSS [training: 0.8379269374196922 | validation: 0.8449476031791845]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_680.pth
	Model improved!!!
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.824783531609149		[learning rate: 0.0022544]
	Learning Rate: 0.00225437
	LOSS [training: 0.824783531609149 | validation: 0.9444347441138004]
	TIME [epoch: 9.59 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7784071101738975		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 0.7784071101738975 | validation: 1.00285006652012]
	TIME [epoch: 9.59 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7938234183367315		[learning rate: 0.0022437]
	Learning Rate: 0.00224375
	LOSS [training: 0.7938234183367315 | validation: 0.9863070547163075]
	TIME [epoch: 9.59 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7997048784045135		[learning rate: 0.0022385]
	Learning Rate: 0.00223846
	LOSS [training: 0.7997048784045135 | validation: 0.8644323824699056]
	TIME [epoch: 9.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8116754455619756		[learning rate: 0.0022332]
	Learning Rate: 0.00223318
	LOSS [training: 0.8116754455619756 | validation: 1.5462880889404234]
	TIME [epoch: 9.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.184968146163779		[learning rate: 0.0022279]
	Learning Rate: 0.00222791
	LOSS [training: 1.184968146163779 | validation: 1.0538396270058596]
	TIME [epoch: 9.59 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8603550502250649		[learning rate: 0.0022227]
	Learning Rate: 0.00222265
	LOSS [training: 0.8603550502250649 | validation: 0.8278757990644937]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_687.pth
	Model improved!!!
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8421498140010211		[learning rate: 0.0022174]
	Learning Rate: 0.00221741
	LOSS [training: 0.8421498140010211 | validation: 0.7830532035309963]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_688.pth
	Model improved!!!
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8172962050460552		[learning rate: 0.0022122]
	Learning Rate: 0.00221218
	LOSS [training: 0.8172962050460552 | validation: 0.8305273697601352]
	TIME [epoch: 9.58 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8432083288978998		[learning rate: 0.002207]
	Learning Rate: 0.00220696
	LOSS [training: 0.8432083288978998 | validation: 0.9014061142281898]
	TIME [epoch: 9.58 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8005131516960518		[learning rate: 0.0022018]
	Learning Rate: 0.00220176
	LOSS [training: 0.8005131516960518 | validation: 0.9035769958565032]
	TIME [epoch: 9.62 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7946204873101124		[learning rate: 0.0021966]
	Learning Rate: 0.00219656
	LOSS [training: 0.7946204873101124 | validation: 1.0314702682273709]
	TIME [epoch: 9.61 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9528218254113094		[learning rate: 0.0021914]
	Learning Rate: 0.00219138
	LOSS [training: 0.9528218254113094 | validation: 1.0837399927186433]
	TIME [epoch: 9.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.911032060826544		[learning rate: 0.0021862]
	Learning Rate: 0.00218621
	LOSS [training: 0.911032060826544 | validation: 1.0410748650305757]
	TIME [epoch: 9.58 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8075074872704849		[learning rate: 0.0021811]
	Learning Rate: 0.00218106
	LOSS [training: 0.8075074872704849 | validation: 0.8906692342278916]
	TIME [epoch: 9.62 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8770451482257956		[learning rate: 0.0021759]
	Learning Rate: 0.00217591
	LOSS [training: 0.8770451482257956 | validation: 1.0433111502528756]
	TIME [epoch: 9.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8551861358799794		[learning rate: 0.0021708]
	Learning Rate: 0.00217078
	LOSS [training: 0.8551861358799794 | validation: 1.1484398615364133]
	TIME [epoch: 9.59 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9510760253006623		[learning rate: 0.0021657]
	Learning Rate: 0.00216566
	LOSS [training: 0.9510760253006623 | validation: 1.0255612651617407]
	TIME [epoch: 9.61 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7761561863124792		[learning rate: 0.0021605]
	Learning Rate: 0.00216055
	LOSS [training: 0.7761561863124792 | validation: 1.05991131413197]
	TIME [epoch: 9.61 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.794235415690251		[learning rate: 0.0021555]
	Learning Rate: 0.00215545
	LOSS [training: 0.794235415690251 | validation: 1.0366172928544086]
	TIME [epoch: 9.58 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8299873578855369		[learning rate: 0.0021504]
	Learning Rate: 0.00215037
	LOSS [training: 0.8299873578855369 | validation: 0.8632953786105481]
	TIME [epoch: 9.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9027424947477793		[learning rate: 0.0021453]
	Learning Rate: 0.0021453
	LOSS [training: 0.9027424947477793 | validation: 1.213967976743574]
	TIME [epoch: 9.59 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8697654011973489		[learning rate: 0.0021402]
	Learning Rate: 0.00214024
	LOSS [training: 0.8697654011973489 | validation: 0.8240742064224916]
	TIME [epoch: 9.61 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8115913607046845		[learning rate: 0.0021352]
	Learning Rate: 0.00213519
	LOSS [training: 0.8115913607046845 | validation: 0.9546614590281814]
	TIME [epoch: 9.58 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.770405681176042		[learning rate: 0.0021302]
	Learning Rate: 0.00213015
	LOSS [training: 0.770405681176042 | validation: 0.8583682061228509]
	TIME [epoch: 9.58 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8728036920471629		[learning rate: 0.0021251]
	Learning Rate: 0.00212513
	LOSS [training: 0.8728036920471629 | validation: 1.0545136865859477]
	TIME [epoch: 9.61 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8945399599793304		[learning rate: 0.0021201]
	Learning Rate: 0.00212011
	LOSS [training: 0.8945399599793304 | validation: 1.1310430916336622]
	TIME [epoch: 9.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9713295861886403		[learning rate: 0.0021151]
	Learning Rate: 0.00211511
	LOSS [training: 0.9713295861886403 | validation: 0.8114917953528581]
	TIME [epoch: 9.6 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8198245348478501		[learning rate: 0.0021101]
	Learning Rate: 0.00211012
	LOSS [training: 0.8198245348478501 | validation: 1.264732962168711]
	TIME [epoch: 9.59 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.079209582107837		[learning rate: 0.0021051]
	Learning Rate: 0.00210515
	LOSS [training: 1.079209582107837 | validation: 1.3942748396169053]
	TIME [epoch: 9.64 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8936321191059818		[learning rate: 0.0021002]
	Learning Rate: 0.00210018
	LOSS [training: 0.8936321191059818 | validation: 1.0981404337878287]
	TIME [epoch: 9.59 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1768940785261612		[learning rate: 0.0020952]
	Learning Rate: 0.00209523
	LOSS [training: 1.1768940785261612 | validation: 0.9400315652427571]
	TIME [epoch: 9.59 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8573658053399894		[learning rate: 0.0020903]
	Learning Rate: 0.00209028
	LOSS [training: 0.8573658053399894 | validation: 1.2146970850415237]
	TIME [epoch: 9.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9662355986333866		[learning rate: 0.0020854]
	Learning Rate: 0.00208535
	LOSS [training: 0.9662355986333866 | validation: 0.9224533604321582]
	TIME [epoch: 9.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9064782589037381		[learning rate: 0.0020804]
	Learning Rate: 0.00208043
	LOSS [training: 0.9064782589037381 | validation: 0.7918974259845062]
	TIME [epoch: 9.61 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9004376170088131		[learning rate: 0.0020755]
	Learning Rate: 0.00207553
	LOSS [training: 0.9004376170088131 | validation: 0.9086350466018647]
	TIME [epoch: 9.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8659799903226612		[learning rate: 0.0020706]
	Learning Rate: 0.00207063
	LOSS [training: 0.8659799903226612 | validation: 0.9390486120978879]
	TIME [epoch: 9.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8056189700046718		[learning rate: 0.0020657]
	Learning Rate: 0.00206575
	LOSS [training: 0.8056189700046718 | validation: 1.0640456156964841]
	TIME [epoch: 9.62 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8188060031249262		[learning rate: 0.0020609]
	Learning Rate: 0.00206087
	LOSS [training: 0.8188060031249262 | validation: 1.1875941808054782]
	TIME [epoch: 9.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.099521934138048		[learning rate: 0.002056]
	Learning Rate: 0.00205601
	LOSS [training: 1.099521934138048 | validation: 0.8820421213457098]
	TIME [epoch: 9.62 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0465079486330766		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 1.0465079486330766 | validation: 0.9804514863138906]
	TIME [epoch: 9.61 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0031846491207177		[learning rate: 0.0020463]
	Learning Rate: 0.00204632
	LOSS [training: 1.0031846491207177 | validation: 0.9558209844061232]
	TIME [epoch: 9.61 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9446002289282738		[learning rate: 0.0020415]
	Learning Rate: 0.0020415
	LOSS [training: 0.9446002289282738 | validation: 1.0765113574843876]
	TIME [epoch: 9.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8163001263039498		[learning rate: 0.0020367]
	Learning Rate: 0.00203668
	LOSS [training: 0.8163001263039498 | validation: 0.7837720978710108]
	TIME [epoch: 9.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8353807854573431		[learning rate: 0.0020319]
	Learning Rate: 0.00203188
	LOSS [training: 0.8353807854573431 | validation: 1.014778813610636]
	TIME [epoch: 9.59 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.733799461023542		[learning rate: 0.0020271]
	Learning Rate: 0.00202708
	LOSS [training: 0.733799461023542 | validation: 0.8536897151526225]
	TIME [epoch: 9.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7978964868282261		[learning rate: 0.0020223]
	Learning Rate: 0.0020223
	LOSS [training: 0.7978964868282261 | validation: 1.3339086605907164]
	TIME [epoch: 9.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8932835609189628		[learning rate: 0.0020175]
	Learning Rate: 0.00201753
	LOSS [training: 0.8932835609189628 | validation: 0.90928029654959]
	TIME [epoch: 9.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0873710171060975		[learning rate: 0.0020128]
	Learning Rate: 0.00201277
	LOSS [training: 1.0873710171060975 | validation: 1.1818917244803604]
	TIME [epoch: 9.62 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8453420816419392		[learning rate: 0.002008]
	Learning Rate: 0.00200803
	LOSS [training: 0.8453420816419392 | validation: 0.9904698629083781]
	TIME [epoch: 9.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9583528700933215		[learning rate: 0.0020033]
	Learning Rate: 0.00200329
	LOSS [training: 0.9583528700933215 | validation: 0.9538047983308018]
	TIME [epoch: 9.59 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8131550601152309		[learning rate: 0.0019986]
	Learning Rate: 0.00199856
	LOSS [training: 0.8131550601152309 | validation: 0.8981914796234628]
	TIME [epoch: 9.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7394396132973124		[learning rate: 0.0019938]
	Learning Rate: 0.00199385
	LOSS [training: 0.7394396132973124 | validation: 0.8076992994981482]
	TIME [epoch: 9.64 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7924422728976068		[learning rate: 0.0019891]
	Learning Rate: 0.00198915
	LOSS [training: 0.7924422728976068 | validation: 0.8800601766733075]
	TIME [epoch: 9.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7117631830955318		[learning rate: 0.0019845]
	Learning Rate: 0.00198445
	LOSS [training: 0.7117631830955318 | validation: 0.9401860527451948]
	TIME [epoch: 9.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8174187284591106		[learning rate: 0.0019798]
	Learning Rate: 0.00197977
	LOSS [training: 0.8174187284591106 | validation: 0.8038009004875214]
	TIME [epoch: 9.62 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7063732068696403		[learning rate: 0.0019751]
	Learning Rate: 0.0019751
	LOSS [training: 0.7063732068696403 | validation: 0.8809918190399819]
	TIME [epoch: 9.61 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7198781448109665		[learning rate: 0.0019704]
	Learning Rate: 0.00197044
	LOSS [training: 0.7198781448109665 | validation: 1.028129020236828]
	TIME [epoch: 9.61 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7351424731210973		[learning rate: 0.0019658]
	Learning Rate: 0.0019658
	LOSS [training: 0.7351424731210973 | validation: 0.8237271203954554]
	TIME [epoch: 9.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6886678227403169		[learning rate: 0.0019612]
	Learning Rate: 0.00196116
	LOSS [training: 0.6886678227403169 | validation: 0.7181256319302503]
	TIME [epoch: 9.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_740.pth
	Model improved!!!
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7109182617083686		[learning rate: 0.0019565]
	Learning Rate: 0.00195653
	LOSS [training: 0.7109182617083686 | validation: 0.7128282979487374]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_741.pth
	Model improved!!!
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7445816485444862		[learning rate: 0.0019519]
	Learning Rate: 0.00195192
	LOSS [training: 0.7445816485444862 | validation: 0.6895493056991141]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_742.pth
	Model improved!!!
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6673748432197829		[learning rate: 0.0019473]
	Learning Rate: 0.00194731
	LOSS [training: 0.6673748432197829 | validation: 0.7681527810909862]
	TIME [epoch: 9.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7530920813746034		[learning rate: 0.0019427]
	Learning Rate: 0.00194272
	LOSS [training: 0.7530920813746034 | validation: 0.9186759051870087]
	TIME [epoch: 9.64 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7061010588432379		[learning rate: 0.0019381]
	Learning Rate: 0.00193814
	LOSS [training: 0.7061010588432379 | validation: 0.7813719589075159]
	TIME [epoch: 9.62 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6923597161221929		[learning rate: 0.0019336]
	Learning Rate: 0.00193357
	LOSS [training: 0.6923597161221929 | validation: 0.7544323994469946]
	TIME [epoch: 9.62 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7964608933314407		[learning rate: 0.001929]
	Learning Rate: 0.001929
	LOSS [training: 0.7964608933314407 | validation: 0.7565779416577314]
	TIME [epoch: 9.62 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7930952139343329		[learning rate: 0.0019245]
	Learning Rate: 0.00192445
	LOSS [training: 0.7930952139343329 | validation: 1.128703278548966]
	TIME [epoch: 9.64 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7979131480159286		[learning rate: 0.0019199]
	Learning Rate: 0.00191992
	LOSS [training: 0.7979131480159286 | validation: 0.9321186167212323]
	TIME [epoch: 9.64 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7378334540213886		[learning rate: 0.0019154]
	Learning Rate: 0.00191539
	LOSS [training: 0.7378334540213886 | validation: 0.7440143982281285]
	TIME [epoch: 9.62 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7678178691852617		[learning rate: 0.0019109]
	Learning Rate: 0.00191087
	LOSS [training: 0.7678178691852617 | validation: 1.1474260900686224]
	TIME [epoch: 9.63 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.815708339055867		[learning rate: 0.0019064]
	Learning Rate: 0.00190636
	LOSS [training: 0.815708339055867 | validation: 1.0070348512814185]
	TIME [epoch: 9.63 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7515335095498259		[learning rate: 0.0019019]
	Learning Rate: 0.00190186
	LOSS [training: 0.7515335095498259 | validation: 0.8624172570019775]
	TIME [epoch: 9.61 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8386595530655461		[learning rate: 0.0018974]
	Learning Rate: 0.00189738
	LOSS [training: 0.8386595530655461 | validation: 1.1846611461639265]
	TIME [epoch: 9.62 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8404314206057502		[learning rate: 0.0018929]
	Learning Rate: 0.0018929
	LOSS [training: 0.8404314206057502 | validation: 0.8886615430480864]
	TIME [epoch: 9.62 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6936708177182219		[learning rate: 0.0018884]
	Learning Rate: 0.00188844
	LOSS [training: 0.6936708177182219 | validation: 0.7998670097920707]
	TIME [epoch: 9.62 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7434802426722605		[learning rate: 0.001884]
	Learning Rate: 0.00188398
	LOSS [training: 0.7434802426722605 | validation: 0.8361996426832247]
	TIME [epoch: 9.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6437074955399884		[learning rate: 0.0018795]
	Learning Rate: 0.00187954
	LOSS [training: 0.6437074955399884 | validation: 0.6794028983709893]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_758.pth
	Model improved!!!
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6655552680843594		[learning rate: 0.0018751]
	Learning Rate: 0.00187511
	LOSS [training: 0.6655552680843594 | validation: 0.7506915314881565]
	TIME [epoch: 9.64 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7936878906073244		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 0.7936878906073244 | validation: 0.9104995776216523]
	TIME [epoch: 9.63 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7212504556407383		[learning rate: 0.0018663]
	Learning Rate: 0.00186627
	LOSS [training: 0.7212504556407383 | validation: 0.8353775755781567]
	TIME [epoch: 9.62 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6813624276789174		[learning rate: 0.0018619]
	Learning Rate: 0.00186187
	LOSS [training: 0.6813624276789174 | validation: 0.6559559928806017]
	TIME [epoch: 9.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_762.pth
	Model improved!!!
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7703489380593267		[learning rate: 0.0018575]
	Learning Rate: 0.00185748
	LOSS [training: 0.7703489380593267 | validation: 1.0374765794553726]
	TIME [epoch: 9.63 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8490550394737143		[learning rate: 0.0018531]
	Learning Rate: 0.00185309
	LOSS [training: 0.8490550394737143 | validation: 0.8567632272011106]
	TIME [epoch: 9.63 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6895331900573984		[learning rate: 0.0018487]
	Learning Rate: 0.00184872
	LOSS [training: 0.6895331900573984 | validation: 0.80104985903188]
	TIME [epoch: 9.61 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6786123820576553		[learning rate: 0.0018444]
	Learning Rate: 0.00184436
	LOSS [training: 0.6786123820576553 | validation: 0.7039308554385187]
	TIME [epoch: 9.63 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6188655396969089		[learning rate: 0.00184]
	Learning Rate: 0.00184001
	LOSS [training: 0.6188655396969089 | validation: 0.8702697842837174]
	TIME [epoch: 9.61 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7395432319827722		[learning rate: 0.0018357]
	Learning Rate: 0.00183567
	LOSS [training: 0.7395432319827722 | validation: 0.7098325405056981]
	TIME [epoch: 9.62 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7102928448763912		[learning rate: 0.0018313]
	Learning Rate: 0.00183134
	LOSS [training: 0.7102928448763912 | validation: 1.2515077551863303]
	TIME [epoch: 9.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8166633842301081		[learning rate: 0.001827]
	Learning Rate: 0.00182702
	LOSS [training: 0.8166633842301081 | validation: 0.7629349055600525]
	TIME [epoch: 9.64 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7212249687511798		[learning rate: 0.0018227]
	Learning Rate: 0.00182271
	LOSS [training: 0.7212249687511798 | validation: 0.64611268523625]
	TIME [epoch: 9.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_771.pth
	Model improved!!!
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.694388040260687		[learning rate: 0.0018184]
	Learning Rate: 0.00181841
	LOSS [training: 0.694388040260687 | validation: 0.8720876266398997]
	TIME [epoch: 9.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6245859176947682		[learning rate: 0.0018141]
	Learning Rate: 0.00181412
	LOSS [training: 0.6245859176947682 | validation: 0.6757274592426823]
	TIME [epoch: 9.61 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7306595900976797		[learning rate: 0.0018098]
	Learning Rate: 0.00180984
	LOSS [training: 0.7306595900976797 | validation: 0.7845939606415807]
	TIME [epoch: 9.64 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6675304890263764		[learning rate: 0.0018056]
	Learning Rate: 0.00180557
	LOSS [training: 0.6675304890263764 | validation: 0.6648226987017918]
	TIME [epoch: 9.62 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.622583269179253		[learning rate: 0.0018013]
	Learning Rate: 0.00180132
	LOSS [training: 0.622583269179253 | validation: 0.7000769331104513]
	TIME [epoch: 9.61 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6353826793152106		[learning rate: 0.0017971]
	Learning Rate: 0.00179707
	LOSS [training: 0.6353826793152106 | validation: 0.7699405020122003]
	TIME [epoch: 9.61 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6364991404813756		[learning rate: 0.0017928]
	Learning Rate: 0.00179283
	LOSS [training: 0.6364991404813756 | validation: 0.8937810417364948]
	TIME [epoch: 9.61 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7511440558313153		[learning rate: 0.0017886]
	Learning Rate: 0.0017886
	LOSS [training: 0.7511440558313153 | validation: 0.9552978353699609]
	TIME [epoch: 9.59 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9016550049495017		[learning rate: 0.0017844]
	Learning Rate: 0.00178438
	LOSS [training: 0.9016550049495017 | validation: 0.8009413589197368]
	TIME [epoch: 9.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7402381752300368		[learning rate: 0.0017802]
	Learning Rate: 0.00178017
	LOSS [training: 0.7402381752300368 | validation: 0.6906844168498488]
	TIME [epoch: 9.64 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8934922757185998		[learning rate: 0.001776]
	Learning Rate: 0.00177597
	LOSS [training: 0.8934922757185998 | validation: 1.1887806354219024]
	TIME [epoch: 9.6 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8141355991631032		[learning rate: 0.0017718]
	Learning Rate: 0.00177178
	LOSS [training: 0.8141355991631032 | validation: 0.9687588640853696]
	TIME [epoch: 9.62 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.189989552099634		[learning rate: 0.0017676]
	Learning Rate: 0.0017676
	LOSS [training: 1.189989552099634 | validation: 1.178798434378647]
	TIME [epoch: 9.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.838872551462851		[learning rate: 0.0017634]
	Learning Rate: 0.00176343
	LOSS [training: 0.838872551462851 | validation: 0.774835161040509]
	TIME [epoch: 9.61 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6990587277384667		[learning rate: 0.0017593]
	Learning Rate: 0.00175927
	LOSS [training: 0.6990587277384667 | validation: 0.7365052283775956]
	TIME [epoch: 9.61 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7166516137093909		[learning rate: 0.0017551]
	Learning Rate: 0.00175512
	LOSS [training: 0.7166516137093909 | validation: 0.7707602414792775]
	TIME [epoch: 9.61 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6280314169084893		[learning rate: 0.001751]
	Learning Rate: 0.00175098
	LOSS [training: 0.6280314169084893 | validation: 0.6946273155020701]
	TIME [epoch: 9.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6555719444665928		[learning rate: 0.0017469]
	Learning Rate: 0.00174685
	LOSS [training: 0.6555719444665928 | validation: 0.6141530796288419]
	TIME [epoch: 9.64 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_789.pth
	Model improved!!!
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5946314416219026		[learning rate: 0.0017427]
	Learning Rate: 0.00174273
	LOSS [training: 0.5946314416219026 | validation: 0.5864193583402575]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_790.pth
	Model improved!!!
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.064790578173867		[learning rate: 0.0017386]
	Learning Rate: 0.00173862
	LOSS [training: 1.064790578173867 | validation: 0.6588667036477641]
	TIME [epoch: 9.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6788902316415101		[learning rate: 0.0017345]
	Learning Rate: 0.00173452
	LOSS [training: 0.6788902316415101 | validation: 0.6636448927085664]
	TIME [epoch: 9.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6362723040841647		[learning rate: 0.0017304]
	Learning Rate: 0.00173043
	LOSS [training: 0.6362723040841647 | validation: 0.6887640681640806]
	TIME [epoch: 9.61 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6332590063850904		[learning rate: 0.0017263]
	Learning Rate: 0.00172635
	LOSS [training: 0.6332590063850904 | validation: 0.6590032520721131]
	TIME [epoch: 9.6 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6283980251020973		[learning rate: 0.0017223]
	Learning Rate: 0.00172228
	LOSS [training: 0.6283980251020973 | validation: 0.742896117941448]
	TIME [epoch: 9.57 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6550063152065876		[learning rate: 0.0017182]
	Learning Rate: 0.00171821
	LOSS [training: 0.6550063152065876 | validation: 0.6136266088267808]
	TIME [epoch: 9.64 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5552303073847517		[learning rate: 0.0017142]
	Learning Rate: 0.00171416
	LOSS [training: 0.5552303073847517 | validation: 0.6537918571681746]
	TIME [epoch: 9.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6930450204830582		[learning rate: 0.0017101]
	Learning Rate: 0.00171012
	LOSS [training: 0.6930450204830582 | validation: 0.6253776628510346]
	TIME [epoch: 9.59 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5474627538902052		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 0.5474627538902052 | validation: 0.6000194655249169]
	TIME [epoch: 9.61 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5450697257716814		[learning rate: 0.0017021]
	Learning Rate: 0.00170206
	LOSS [training: 0.5450697257716814 | validation: 0.6976871355743259]
	TIME [epoch: 9.62 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8725823942712904		[learning rate: 0.001698]
	Learning Rate: 0.00169804
	LOSS [training: 0.8725823942712904 | validation: 0.9067320299920888]
	TIME [epoch: 9.62 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6572250662270207		[learning rate: 0.001694]
	Learning Rate: 0.00169404
	LOSS [training: 0.6572250662270207 | validation: 0.5647325053645504]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_802.pth
	Model improved!!!
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5993474862911842		[learning rate: 0.00169]
	Learning Rate: 0.00169004
	LOSS [training: 0.5993474862911842 | validation: 0.8165961888850387]
	TIME [epoch: 9.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6903125177997984		[learning rate: 0.0016861]
	Learning Rate: 0.00168606
	LOSS [training: 0.6903125177997984 | validation: 0.6674092083171052]
	TIME [epoch: 9.62 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0482665536890756		[learning rate: 0.0016821]
	Learning Rate: 0.00168208
	LOSS [training: 1.0482665536890756 | validation: 0.7107147702838212]
	TIME [epoch: 9.59 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7347656439960402		[learning rate: 0.0016781]
	Learning Rate: 0.00167811
	LOSS [training: 0.7347656439960402 | validation: 0.7778363096880557]
	TIME [epoch: 9.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5926108769469169		[learning rate: 0.0016742]
	Learning Rate: 0.00167415
	LOSS [training: 0.5926108769469169 | validation: 0.690987516611588]
	TIME [epoch: 9.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6310090722632884		[learning rate: 0.0016702]
	Learning Rate: 0.0016702
	LOSS [training: 0.6310090722632884 | validation: 0.6664763162486795]
	TIME [epoch: 9.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5374948012306109		[learning rate: 0.0016663]
	Learning Rate: 0.00166626
	LOSS [training: 0.5374948012306109 | validation: 0.7431915108613106]
	TIME [epoch: 9.59 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5610777939506894		[learning rate: 0.0016623]
	Learning Rate: 0.00166233
	LOSS [training: 0.5610777939506894 | validation: 0.7279372779030757]
	TIME [epoch: 9.58 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5661546112646099		[learning rate: 0.0016584]
	Learning Rate: 0.00165841
	LOSS [training: 0.5661546112646099 | validation: 0.7235471771970359]
	TIME [epoch: 9.61 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.537998185210585		[learning rate: 0.0016545]
	Learning Rate: 0.0016545
	LOSS [training: 0.537998185210585 | validation: 0.6496614557873306]
	TIME [epoch: 9.59 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6076682983747463		[learning rate: 0.0016506]
	Learning Rate: 0.0016506
	LOSS [training: 0.6076682983747463 | validation: 0.6527770521154076]
	TIME [epoch: 9.58 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5604991327433323		[learning rate: 0.0016467]
	Learning Rate: 0.0016467
	LOSS [training: 0.5604991327433323 | validation: 0.5833749297428554]
	TIME [epoch: 9.58 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5464928394050199		[learning rate: 0.0016428]
	Learning Rate: 0.00164282
	LOSS [training: 0.5464928394050199 | validation: 0.9125876779284989]
	TIME [epoch: 9.61 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.830696343708542		[learning rate: 0.0016389]
	Learning Rate: 0.00163894
	LOSS [training: 0.830696343708542 | validation: 0.655136962921114]
	TIME [epoch: 9.59 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6497226643799162		[learning rate: 0.0016351]
	Learning Rate: 0.00163508
	LOSS [training: 0.6497226643799162 | validation: 0.6005174813946005]
	TIME [epoch: 9.59 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5136727876880597		[learning rate: 0.0016312]
	Learning Rate: 0.00163122
	LOSS [training: 0.5136727876880597 | validation: 0.6060705699133058]
	TIME [epoch: 9.59 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5382204394190568		[learning rate: 0.0016274]
	Learning Rate: 0.00162737
	LOSS [training: 0.5382204394190568 | validation: 0.5597629812597127]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_819.pth
	Model improved!!!
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5582569471534964		[learning rate: 0.0016235]
	Learning Rate: 0.00162353
	LOSS [training: 0.5582569471534964 | validation: 0.5886790558449299]
	TIME [epoch: 9.59 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6356828534673127		[learning rate: 0.0016197]
	Learning Rate: 0.0016197
	LOSS [training: 0.6356828534673127 | validation: 0.845875900995776]
	TIME [epoch: 9.59 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5615789357247538		[learning rate: 0.0016159]
	Learning Rate: 0.00161588
	LOSS [training: 0.5615789357247538 | validation: 0.8209228937357733]
	TIME [epoch: 9.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6330630513983435		[learning rate: 0.0016121]
	Learning Rate: 0.00161207
	LOSS [training: 0.6330630513983435 | validation: 0.6986642808358882]
	TIME [epoch: 9.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5495617232484484		[learning rate: 0.0016083]
	Learning Rate: 0.00160827
	LOSS [training: 0.5495617232484484 | validation: 0.6612138738838994]
	TIME [epoch: 9.59 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.602165093171396		[learning rate: 0.0016045]
	Learning Rate: 0.00160448
	LOSS [training: 0.602165093171396 | validation: 0.5249821607806822]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_825.pth
	Model improved!!!
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5711469529565399		[learning rate: 0.0016007]
	Learning Rate: 0.00160069
	LOSS [training: 0.5711469529565399 | validation: 0.6123945598641711]
	TIME [epoch: 9.62 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5161701170518282		[learning rate: 0.0015969]
	Learning Rate: 0.00159692
	LOSS [training: 0.5161701170518282 | validation: 0.6428909121948757]
	TIME [epoch: 9.6 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5449651504129122		[learning rate: 0.0015931]
	Learning Rate: 0.00159315
	LOSS [training: 0.5449651504129122 | validation: 0.770812406663666]
	TIME [epoch: 9.61 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5546660557530925		[learning rate: 0.0015894]
	Learning Rate: 0.00158939
	LOSS [training: 0.5546660557530925 | validation: 0.6494241335153896]
	TIME [epoch: 9.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.530054110969545		[learning rate: 0.0015856]
	Learning Rate: 0.00158564
	LOSS [training: 0.530054110969545 | validation: 0.581796169489603]
	TIME [epoch: 9.62 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5165068781861768		[learning rate: 0.0015819]
	Learning Rate: 0.0015819
	LOSS [training: 0.5165068781861768 | validation: 0.5815579472111175]
	TIME [epoch: 9.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5102661735452286		[learning rate: 0.0015782]
	Learning Rate: 0.00157817
	LOSS [training: 0.5102661735452286 | validation: 0.659811534073486]
	TIME [epoch: 9.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.519566845675742		[learning rate: 0.0015744]
	Learning Rate: 0.00157445
	LOSS [training: 0.519566845675742 | validation: 0.546462069879431]
	TIME [epoch: 9.59 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5050955972217632		[learning rate: 0.0015707]
	Learning Rate: 0.00157073
	LOSS [training: 0.5050955972217632 | validation: 0.7539309022184801]
	TIME [epoch: 9.63 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5532592926480999		[learning rate: 0.001567]
	Learning Rate: 0.00156703
	LOSS [training: 0.5532592926480999 | validation: 0.7212235902601998]
	TIME [epoch: 9.59 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5596588634061853		[learning rate: 0.0015633]
	Learning Rate: 0.00156333
	LOSS [training: 0.5596588634061853 | validation: 0.7029644051551199]
	TIME [epoch: 9.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5067651448220974		[learning rate: 0.0015596]
	Learning Rate: 0.00155964
	LOSS [training: 0.5067651448220974 | validation: 0.5801770467043007]
	TIME [epoch: 9.6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46235520241025185		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 0.46235520241025185 | validation: 0.6844509799165452]
	TIME [epoch: 9.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6296963589114538		[learning rate: 0.0015523]
	Learning Rate: 0.0015523
	LOSS [training: 0.6296963589114538 | validation: 1.0083378768550657]
	TIME [epoch: 9.59 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9427713445260126		[learning rate: 0.0015486]
	Learning Rate: 0.00154863
	LOSS [training: 0.9427713445260126 | validation: 0.5405880695527242]
	TIME [epoch: 9.59 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6133482033635702		[learning rate: 0.001545]
	Learning Rate: 0.00154498
	LOSS [training: 0.6133482033635702 | validation: 0.6558911463200892]
	TIME [epoch: 9.62 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6709677659070199		[learning rate: 0.0015413]
	Learning Rate: 0.00154134
	LOSS [training: 0.6709677659070199 | validation: 0.6575717195098261]
	TIME [epoch: 9.61 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6354959992312528		[learning rate: 0.0015377]
	Learning Rate: 0.0015377
	LOSS [training: 0.6354959992312528 | validation: 0.5865483616370039]
	TIME [epoch: 9.59 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4935392209406066		[learning rate: 0.0015341]
	Learning Rate: 0.00153407
	LOSS [training: 0.4935392209406066 | validation: 0.47959652153132304]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_844.pth
	Model improved!!!
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6231861425334071		[learning rate: 0.0015305]
	Learning Rate: 0.00153045
	LOSS [training: 0.6231861425334071 | validation: 0.8750887423085209]
	TIME [epoch: 9.61 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5867334559204849		[learning rate: 0.0015268]
	Learning Rate: 0.00152684
	LOSS [training: 0.5867334559204849 | validation: 0.7610680126407747]
	TIME [epoch: 9.59 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5085497888371456		[learning rate: 0.0015232]
	Learning Rate: 0.00152324
	LOSS [training: 0.5085497888371456 | validation: 0.6285367308442882]
	TIME [epoch: 9.6 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4901446300672225		[learning rate: 0.0015196]
	Learning Rate: 0.00151965
	LOSS [training: 0.4901446300672225 | validation: 0.7300630129837107]
	TIME [epoch: 9.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6374265776344356		[learning rate: 0.0015161]
	Learning Rate: 0.00151607
	LOSS [training: 0.6374265776344356 | validation: 1.1863551706100222]
	TIME [epoch: 9.62 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6645974024377045		[learning rate: 0.0015125]
	Learning Rate: 0.00151249
	LOSS [training: 0.6645974024377045 | validation: 0.531487901516195]
	TIME [epoch: 9.59 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4533634823891628		[learning rate: 0.0015089]
	Learning Rate: 0.00150892
	LOSS [training: 0.4533634823891628 | validation: 0.6281397916432682]
	TIME [epoch: 9.59 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5928291759772929		[learning rate: 0.0015054]
	Learning Rate: 0.00150536
	LOSS [training: 0.5928291759772929 | validation: 0.8280422729788524]
	TIME [epoch: 9.61 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5505752286250776		[learning rate: 0.0015018]
	Learning Rate: 0.00150181
	LOSS [training: 0.5505752286250776 | validation: 0.6425505311022657]
	TIME [epoch: 9.59 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4852074528484603		[learning rate: 0.0014983]
	Learning Rate: 0.00149827
	LOSS [training: 0.4852074528484603 | validation: 0.6281583538760143]
	TIME [epoch: 9.58 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4784766326406117		[learning rate: 0.0014947]
	Learning Rate: 0.00149473
	LOSS [training: 0.4784766326406117 | validation: 0.5237731077884566]
	TIME [epoch: 9.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.471727941841518		[learning rate: 0.0014912]
	Learning Rate: 0.00149121
	LOSS [training: 0.471727941841518 | validation: 0.6329556719643198]
	TIME [epoch: 9.61 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5450805823262501		[learning rate: 0.0014877]
	Learning Rate: 0.00148769
	LOSS [training: 0.5450805823262501 | validation: 0.5787511476526908]
	TIME [epoch: 9.59 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4823719214275444		[learning rate: 0.0014842]
	Learning Rate: 0.00148418
	LOSS [training: 0.4823719214275444 | validation: 0.5084915632598708]
	TIME [epoch: 9.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6345778497110364		[learning rate: 0.0014807]
	Learning Rate: 0.00148068
	LOSS [training: 0.6345778497110364 | validation: 0.48617544612050223]
	TIME [epoch: 9.62 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4427969175193927		[learning rate: 0.0014772]
	Learning Rate: 0.00147719
	LOSS [training: 0.4427969175193927 | validation: 0.5275258570756267]
	TIME [epoch: 9.63 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42166221814814026		[learning rate: 0.0014737]
	Learning Rate: 0.0014737
	LOSS [training: 0.42166221814814026 | validation: 0.5088721251590473]
	TIME [epoch: 9.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4959706966904971		[learning rate: 0.0014702]
	Learning Rate: 0.00147023
	LOSS [training: 0.4959706966904971 | validation: 0.5208574491547588]
	TIME [epoch: 9.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5216980814227434		[learning rate: 0.0014668]
	Learning Rate: 0.00146676
	LOSS [training: 0.5216980814227434 | validation: 0.5110353741170377]
	TIME [epoch: 9.62 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4926015926853172		[learning rate: 0.0014633]
	Learning Rate: 0.0014633
	LOSS [training: 0.4926015926853172 | validation: 0.6010259123904949]
	TIME [epoch: 9.62 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5608927494849538		[learning rate: 0.0014598]
	Learning Rate: 0.00145985
	LOSS [training: 0.5608927494849538 | validation: 0.7923235620379581]
	TIME [epoch: 9.59 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5294212744110977		[learning rate: 0.0014564]
	Learning Rate: 0.0014564
	LOSS [training: 0.5294212744110977 | validation: 0.5169933840910028]
	TIME [epoch: 9.61 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4793190687783714		[learning rate: 0.001453]
	Learning Rate: 0.00145297
	LOSS [training: 0.4793190687783714 | validation: 0.5323803994351063]
	TIME [epoch: 9.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43541851486946603		[learning rate: 0.0014495]
	Learning Rate: 0.00144954
	LOSS [training: 0.43541851486946603 | validation: 0.5513802872862701]
	TIME [epoch: 9.61 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49206671711476646		[learning rate: 0.0014461]
	Learning Rate: 0.00144612
	LOSS [training: 0.49206671711476646 | validation: 0.5758912983365729]
	TIME [epoch: 9.57 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.580610824322922		[learning rate: 0.0014427]
	Learning Rate: 0.00144271
	LOSS [training: 0.580610824322922 | validation: 1.2114113817623733]
	TIME [epoch: 9.61 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8771016763656121		[learning rate: 0.0014393]
	Learning Rate: 0.00143931
	LOSS [training: 0.8771016763656121 | validation: 0.5745437689675688]
	TIME [epoch: 9.62 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4658106683014836		[learning rate: 0.0014359]
	Learning Rate: 0.00143591
	LOSS [training: 0.4658106683014836 | validation: 0.5332500025309602]
	TIME [epoch: 9.61 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5775811096229777		[learning rate: 0.0014325]
	Learning Rate: 0.00143253
	LOSS [training: 0.5775811096229777 | validation: 0.5517589083350406]
	TIME [epoch: 9.6 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44017635576042513		[learning rate: 0.0014291]
	Learning Rate: 0.00142915
	LOSS [training: 0.44017635576042513 | validation: 0.8455747888059952]
	TIME [epoch: 9.58 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5841669242856201		[learning rate: 0.0014258]
	Learning Rate: 0.00142578
	LOSS [training: 0.5841669242856201 | validation: 0.6364890740572412]
	TIME [epoch: 9.6 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5006141928823867		[learning rate: 0.0014224]
	Learning Rate: 0.00142241
	LOSS [training: 0.5006141928823867 | validation: 0.5572022868867519]
	TIME [epoch: 9.58 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44530909163683263		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.44530909163683263 | validation: 0.5651355007117204]
	TIME [epoch: 9.58 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5053640875875616		[learning rate: 0.0014157]
	Learning Rate: 0.00141571
	LOSS [training: 0.5053640875875616 | validation: 0.5640084883197195]
	TIME [epoch: 9.6 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6874318048960137		[learning rate: 0.0014124]
	Learning Rate: 0.00141237
	LOSS [training: 0.6874318048960137 | validation: 1.0668739860571017]
	TIME [epoch: 9.62 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.621053993516741		[learning rate: 0.001409]
	Learning Rate: 0.00140904
	LOSS [training: 0.621053993516741 | validation: 0.5718911260276697]
	TIME [epoch: 9.58 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49914087478036456		[learning rate: 0.0014057]
	Learning Rate: 0.00140572
	LOSS [training: 0.49914087478036456 | validation: 0.5033669223266878]
	TIME [epoch: 9.59 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5163955176913962		[learning rate: 0.0014024]
	Learning Rate: 0.0014024
	LOSS [training: 0.5163955176913962 | validation: 0.4597732833253889]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_882.pth
	Model improved!!!
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3832850586773381		[learning rate: 0.0013991]
	Learning Rate: 0.00139909
	LOSS [training: 0.3832850586773381 | validation: 0.7227622982974131]
	TIME [epoch: 9.61 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49355444911416024		[learning rate: 0.0013958]
	Learning Rate: 0.00139579
	LOSS [training: 0.49355444911416024 | validation: 0.6722964947307056]
	TIME [epoch: 9.6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5236905294703754		[learning rate: 0.0013925]
	Learning Rate: 0.0013925
	LOSS [training: 0.5236905294703754 | validation: 0.8432740297075525]
	TIME [epoch: 9.62 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6146495336659118		[learning rate: 0.0013892]
	Learning Rate: 0.00138921
	LOSS [training: 0.6146495336659118 | validation: 0.6777566659626842]
	TIME [epoch: 9.62 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43558942897805525		[learning rate: 0.0013859]
	Learning Rate: 0.00138594
	LOSS [training: 0.43558942897805525 | validation: 0.5777686609481615]
	TIME [epoch: 9.62 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42531594648124094		[learning rate: 0.0013827]
	Learning Rate: 0.00138267
	LOSS [training: 0.42531594648124094 | validation: 0.5435405673004161]
	TIME [epoch: 9.62 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4404211690593434		[learning rate: 0.0013794]
	Learning Rate: 0.00137941
	LOSS [training: 0.4404211690593434 | validation: 0.5209850023232603]
	TIME [epoch: 9.62 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38832312082077525		[learning rate: 0.0013762]
	Learning Rate: 0.00137615
	LOSS [training: 0.38832312082077525 | validation: 0.5330590583310735]
	TIME [epoch: 9.63 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40632950172653304		[learning rate: 0.0013729]
	Learning Rate: 0.00137291
	LOSS [training: 0.40632950172653304 | validation: 0.6782056478615047]
	TIME [epoch: 9.62 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.562337733820643		[learning rate: 0.0013697]
	Learning Rate: 0.00136967
	LOSS [training: 0.562337733820643 | validation: 0.5372368849637468]
	TIME [epoch: 9.62 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4313246659453661		[learning rate: 0.0013664]
	Learning Rate: 0.00136644
	LOSS [training: 0.4313246659453661 | validation: 0.5553379156044923]
	TIME [epoch: 9.64 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43786824767324173		[learning rate: 0.0013632]
	Learning Rate: 0.00136321
	LOSS [training: 0.43786824767324173 | validation: 0.49329961941630857]
	TIME [epoch: 9.62 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46513494434830066		[learning rate: 0.00136]
	Learning Rate: 0.00136
	LOSS [training: 0.46513494434830066 | validation: 0.5128499249364222]
	TIME [epoch: 9.63 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45251227038160613		[learning rate: 0.0013568]
	Learning Rate: 0.00135679
	LOSS [training: 0.45251227038160613 | validation: 0.6310331786026298]
	TIME [epoch: 9.61 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4288215197893976		[learning rate: 0.0013536]
	Learning Rate: 0.00135359
	LOSS [training: 0.4288215197893976 | validation: 0.557151772839674]
	TIME [epoch: 9.63 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3868881824985708		[learning rate: 0.0013504]
	Learning Rate: 0.0013504
	LOSS [training: 0.3868881824985708 | validation: 0.4090798378308936]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_898.pth
	Model improved!!!
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43611193910605806		[learning rate: 0.0013472]
	Learning Rate: 0.00134721
	LOSS [training: 0.43611193910605806 | validation: 0.5106577616964618]
	TIME [epoch: 9.61 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5417517152961421		[learning rate: 0.001344]
	Learning Rate: 0.00134403
	LOSS [training: 0.5417517152961421 | validation: 0.9200925196696332]
	TIME [epoch: 9.63 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49339319718576913		[learning rate: 0.0013409]
	Learning Rate: 0.00134086
	LOSS [training: 0.49339319718576913 | validation: 0.5466994222315256]
	TIME [epoch: 9.64 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4201289702627703		[learning rate: 0.0013377]
	Learning Rate: 0.0013377
	LOSS [training: 0.4201289702627703 | validation: 0.4522212018287308]
	TIME [epoch: 9.6 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4035951169863945		[learning rate: 0.0013345]
	Learning Rate: 0.00133455
	LOSS [training: 0.4035951169863945 | validation: 0.7280016396944033]
	TIME [epoch: 9.62 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5085689158632063		[learning rate: 0.0013314]
	Learning Rate: 0.0013314
	LOSS [training: 0.5085689158632063 | validation: 0.5002095088165502]
	TIME [epoch: 9.6 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48786703267674464		[learning rate: 0.0013283]
	Learning Rate: 0.00132826
	LOSS [training: 0.48786703267674464 | validation: 0.7791566825076092]
	TIME [epoch: 9.63 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5941640868773741		[learning rate: 0.0013251]
	Learning Rate: 0.00132512
	LOSS [training: 0.5941640868773741 | validation: 0.7076650128900103]
	TIME [epoch: 9.63 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4968237612261045		[learning rate: 0.001322]
	Learning Rate: 0.001322
	LOSS [training: 0.4968237612261045 | validation: 0.5599168013024073]
	TIME [epoch: 9.63 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5184170545314066		[learning rate: 0.0013189]
	Learning Rate: 0.00131888
	LOSS [training: 0.5184170545314066 | validation: 0.664528959237407]
	TIME [epoch: 9.6 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6499595759513938		[learning rate: 0.0013158]
	Learning Rate: 0.00131577
	LOSS [training: 0.6499595759513938 | validation: 0.6462228351270196]
	TIME [epoch: 9.63 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5646744079478788		[learning rate: 0.0013127]
	Learning Rate: 0.00131266
	LOSS [training: 0.5646744079478788 | validation: 0.658110332357293]
	TIME [epoch: 9.61 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4434762754164889		[learning rate: 0.0013096]
	Learning Rate: 0.00130957
	LOSS [training: 0.4434762754164889 | validation: 0.4248489645876758]
	TIME [epoch: 9.61 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42281440197658127		[learning rate: 0.0013065]
	Learning Rate: 0.00130648
	LOSS [training: 0.42281440197658127 | validation: 0.5830524523998447]
	TIME [epoch: 9.62 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4488855227785528		[learning rate: 0.0013034]
	Learning Rate: 0.0013034
	LOSS [training: 0.4488855227785528 | validation: 0.5412600458615174]
	TIME [epoch: 9.64 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3941729931816219		[learning rate: 0.0013003]
	Learning Rate: 0.00130032
	LOSS [training: 0.3941729931816219 | validation: 0.47949072638596774]
	TIME [epoch: 9.59 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4490369396760793		[learning rate: 0.0012973]
	Learning Rate: 0.00129726
	LOSS [training: 0.4490369396760793 | validation: 0.7583550221468983]
	TIME [epoch: 9.62 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40994546524989195		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 0.40994546524989195 | validation: 0.46988466738666373]
	TIME [epoch: 9.63 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4551744160654573		[learning rate: 0.0012911]
	Learning Rate: 0.00129114
	LOSS [training: 0.4551744160654573 | validation: 0.5102112047366755]
	TIME [epoch: 9.62 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4112372776606203		[learning rate: 0.0012881]
	Learning Rate: 0.0012881
	LOSS [training: 0.4112372776606203 | validation: 0.4849628527462762]
	TIME [epoch: 9.62 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38754983569832874		[learning rate: 0.0012851]
	Learning Rate: 0.00128506
	LOSS [training: 0.38754983569832874 | validation: 0.5337508257114025]
	TIME [epoch: 9.62 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39867317391840573		[learning rate: 0.001282]
	Learning Rate: 0.00128203
	LOSS [training: 0.39867317391840573 | validation: 0.5252979445542486]
	TIME [epoch: 9.65 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3734544085913375		[learning rate: 0.001279]
	Learning Rate: 0.001279
	LOSS [training: 0.3734544085913375 | validation: 0.574961787992714]
	TIME [epoch: 9.62 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3557833290089506		[learning rate: 0.001276]
	Learning Rate: 0.00127599
	LOSS [training: 0.3557833290089506 | validation: 0.59020863766318]
	TIME [epoch: 9.63 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43095461070272983		[learning rate: 0.001273]
	Learning Rate: 0.00127298
	LOSS [training: 0.43095461070272983 | validation: 0.7711864146315969]
	TIME [epoch: 9.63 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4794040974642414		[learning rate: 0.00127]
	Learning Rate: 0.00126997
	LOSS [training: 0.4794040974642414 | validation: 0.5934910875831796]
	TIME [epoch: 9.64 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44436641066461746		[learning rate: 0.001267]
	Learning Rate: 0.00126698
	LOSS [training: 0.44436641066461746 | validation: 0.6741704892099442]
	TIME [epoch: 9.62 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41999536423446815		[learning rate: 0.001264]
	Learning Rate: 0.00126399
	LOSS [training: 0.41999536423446815 | validation: 0.5629313168304293]
	TIME [epoch: 9.61 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3593379510223901		[learning rate: 0.001261]
	Learning Rate: 0.00126101
	LOSS [training: 0.3593379510223901 | validation: 0.4966876470642134]
	TIME [epoch: 9.63 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3941174299011459		[learning rate: 0.001258]
	Learning Rate: 0.00125803
	LOSS [training: 0.3941174299011459 | validation: 0.5508046815150728]
	TIME [epoch: 9.63 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3775595577249115		[learning rate: 0.0012551]
	Learning Rate: 0.00125507
	LOSS [training: 0.3775595577249115 | validation: 0.4593494428357597]
	TIME [epoch: 9.62 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32146589335370584		[learning rate: 0.0012521]
	Learning Rate: 0.00125211
	LOSS [training: 0.32146589335370584 | validation: 0.3325796715110413]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_930.pth
	Model improved!!!
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4082052864672903		[learning rate: 0.0012492]
	Learning Rate: 0.00124915
	LOSS [training: 0.4082052864672903 | validation: 0.3610215612487334]
	TIME [epoch: 9.63 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4049642665747486		[learning rate: 0.0012462]
	Learning Rate: 0.00124621
	LOSS [training: 0.4049642665747486 | validation: 0.3721553812749094]
	TIME [epoch: 9.62 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3666560324833795		[learning rate: 0.0012433]
	Learning Rate: 0.00124327
	LOSS [training: 0.3666560324833795 | validation: 0.37018222392924194]
	TIME [epoch: 9.61 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3573652918179272		[learning rate: 0.0012403]
	Learning Rate: 0.00124033
	LOSS [training: 0.3573652918179272 | validation: 0.4025192216609399]
	TIME [epoch: 9.61 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36062247869700875		[learning rate: 0.0012374]
	Learning Rate: 0.00123741
	LOSS [training: 0.36062247869700875 | validation: 0.4753637336321475]
	TIME [epoch: 9.63 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35416228378566766		[learning rate: 0.0012345]
	Learning Rate: 0.00123449
	LOSS [training: 0.35416228378566766 | validation: 0.43054936509939895]
	TIME [epoch: 9.61 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31404529676065834		[learning rate: 0.0012316]
	Learning Rate: 0.00123158
	LOSS [training: 0.31404529676065834 | validation: 0.3570433302722769]
	TIME [epoch: 9.62 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36847686220607606		[learning rate: 0.0012287]
	Learning Rate: 0.00122867
	LOSS [training: 0.36847686220607606 | validation: 0.5350788617861646]
	TIME [epoch: 9.62 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38403536950329803		[learning rate: 0.0012258]
	Learning Rate: 0.00122577
	LOSS [training: 0.38403536950329803 | validation: 0.3957808871420673]
	TIME [epoch: 9.64 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3562170217736863		[learning rate: 0.0012229]
	Learning Rate: 0.00122288
	LOSS [training: 0.3562170217736863 | validation: 0.41093235005491624]
	TIME [epoch: 9.62 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40684650314622034		[learning rate: 0.00122]
	Learning Rate: 0.00122
	LOSS [training: 0.40684650314622034 | validation: 0.561911530018834]
	TIME [epoch: 9.62 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4807979625890468		[learning rate: 0.0012171]
	Learning Rate: 0.00121712
	LOSS [training: 0.4807979625890468 | validation: 0.5901720752282164]
	TIME [epoch: 9.63 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4334703571989465		[learning rate: 0.0012142]
	Learning Rate: 0.00121425
	LOSS [training: 0.4334703571989465 | validation: 0.3646371220907663]
	TIME [epoch: 9.64 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43303998915856096		[learning rate: 0.0012114]
	Learning Rate: 0.00121138
	LOSS [training: 0.43303998915856096 | validation: 0.4859378944675827]
	TIME [epoch: 9.61 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3856915455406901		[learning rate: 0.0012085]
	Learning Rate: 0.00120853
	LOSS [training: 0.3856915455406901 | validation: 0.4178812306531002]
	TIME [epoch: 9.63 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3297107825009705		[learning rate: 0.0012057]
	Learning Rate: 0.00120568
	LOSS [training: 0.3297107825009705 | validation: 0.5142256267974927]
	TIME [epoch: 9.65 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5387430829536769		[learning rate: 0.0012028]
	Learning Rate: 0.00120283
	LOSS [training: 0.5387430829536769 | validation: 0.7076380176476724]
	TIME [epoch: 9.62 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4423981633545077		[learning rate: 0.0012]
	Learning Rate: 0.0012
	LOSS [training: 0.4423981633545077 | validation: 0.5197896846677836]
	TIME [epoch: 9.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3560802535546893		[learning rate: 0.0011972]
	Learning Rate: 0.00119716
	LOSS [training: 0.3560802535546893 | validation: 0.4222540440822047]
	TIME [epoch: 9.62 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40366675491476245		[learning rate: 0.0011943]
	Learning Rate: 0.00119434
	LOSS [training: 0.40366675491476245 | validation: 0.5327877861006203]
	TIME [epoch: 9.65 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.500480294165359		[learning rate: 0.0011915]
	Learning Rate: 0.00119152
	LOSS [training: 0.500480294165359 | validation: 0.4381403698769914]
	TIME [epoch: 9.62 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49717074047242005		[learning rate: 0.0011887]
	Learning Rate: 0.00118871
	LOSS [training: 0.49717074047242005 | validation: 0.42477129994296536]
	TIME [epoch: 9.63 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35932822431492956		[learning rate: 0.0011859]
	Learning Rate: 0.00118591
	LOSS [training: 0.35932822431492956 | validation: 0.3826322093475488]
	TIME [epoch: 9.62 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34793659537534805		[learning rate: 0.0011831]
	Learning Rate: 0.00118311
	LOSS [training: 0.34793659537534805 | validation: 0.42533627770435417]
	TIME [epoch: 9.64 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3850705652343796		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.3850705652343796 | validation: 0.3929465856074218]
	TIME [epoch: 9.62 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39871153544781873		[learning rate: 0.0011775]
	Learning Rate: 0.00117754
	LOSS [training: 0.39871153544781873 | validation: 0.44620771963041705]
	TIME [epoch: 9.64 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37223922798662346		[learning rate: 0.0011748]
	Learning Rate: 0.00117476
	LOSS [training: 0.37223922798662346 | validation: 0.5673409793313402]
	TIME [epoch: 9.63 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38166226554370863		[learning rate: 0.001172]
	Learning Rate: 0.00117199
	LOSS [training: 0.38166226554370863 | validation: 0.4063931048529927]
	TIME [epoch: 9.62 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36536009379851003		[learning rate: 0.0011692]
	Learning Rate: 0.00116922
	LOSS [training: 0.36536009379851003 | validation: 0.45876629476392233]
	TIME [epoch: 9.63 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37344453451859194		[learning rate: 0.0011665]
	Learning Rate: 0.00116646
	LOSS [training: 0.37344453451859194 | validation: 0.3984649505964156]
	TIME [epoch: 9.61 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34166843386676865		[learning rate: 0.0011637]
	Learning Rate: 0.00116371
	LOSS [training: 0.34166843386676865 | validation: 0.3931172330314647]
	TIME [epoch: 9.65 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3471051945664576		[learning rate: 0.001161]
	Learning Rate: 0.00116097
	LOSS [training: 0.3471051945664576 | validation: 0.4364052134132426]
	TIME [epoch: 9.63 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3598911272066997		[learning rate: 0.0011582]
	Learning Rate: 0.00115823
	LOSS [training: 0.3598911272066997 | validation: 0.37313457169194736]
	TIME [epoch: 9.63 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32169436912252086		[learning rate: 0.0011555]
	Learning Rate: 0.0011555
	LOSS [training: 0.32169436912252086 | validation: 0.5151515747271433]
	TIME [epoch: 9.62 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33665249920643514		[learning rate: 0.0011528]
	Learning Rate: 0.00115277
	LOSS [training: 0.33665249920643514 | validation: 0.4115680270674961]
	TIME [epoch: 9.65 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3365586397362069		[learning rate: 0.0011501]
	Learning Rate: 0.00115005
	LOSS [training: 0.3365586397362069 | validation: 0.4474245781920811]
	TIME [epoch: 9.63 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32771310469507153		[learning rate: 0.0011473]
	Learning Rate: 0.00114734
	LOSS [training: 0.32771310469507153 | validation: 0.5475338447666783]
	TIME [epoch: 9.62 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42309884780981105		[learning rate: 0.0011446]
	Learning Rate: 0.00114463
	LOSS [training: 0.42309884780981105 | validation: 0.5472893357075106]
	TIME [epoch: 9.63 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3384682408401946		[learning rate: 0.0011419]
	Learning Rate: 0.00114193
	LOSS [training: 0.3384682408401946 | validation: 0.37840138725619327]
	TIME [epoch: 9.65 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4188575396483613		[learning rate: 0.0011392]
	Learning Rate: 0.00113924
	LOSS [training: 0.4188575396483613 | validation: 0.3956067014926893]
	TIME [epoch: 9.62 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35683712124020533		[learning rate: 0.0011366]
	Learning Rate: 0.00113655
	LOSS [training: 0.35683712124020533 | validation: 0.38621824928964016]
	TIME [epoch: 9.62 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3423351450793394		[learning rate: 0.0011339]
	Learning Rate: 0.00113387
	LOSS [training: 0.3423351450793394 | validation: 0.5066812958690133]
	TIME [epoch: 9.64 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3499289817859321		[learning rate: 0.0011312]
	Learning Rate: 0.0011312
	LOSS [training: 0.3499289817859321 | validation: 0.5497461394688938]
	TIME [epoch: 9.63 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45746980413228694		[learning rate: 0.0011285]
	Learning Rate: 0.00112853
	LOSS [training: 0.45746980413228694 | validation: 0.839300097686338]
	TIME [epoch: 9.63 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.539156050380145		[learning rate: 0.0011259]
	Learning Rate: 0.00112587
	LOSS [training: 0.539156050380145 | validation: 0.47469463473627377]
	TIME [epoch: 9.63 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40403351252725495		[learning rate: 0.0011232]
	Learning Rate: 0.00112321
	LOSS [training: 0.40403351252725495 | validation: 0.48180876506018705]
	TIME [epoch: 9.64 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3644413787452815		[learning rate: 0.0011206]
	Learning Rate: 0.00112056
	LOSS [training: 0.3644413787452815 | validation: 0.7940851137772473]
	TIME [epoch: 9.64 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5924118749833405		[learning rate: 0.0011179]
	Learning Rate: 0.00111792
	LOSS [training: 0.5924118749833405 | validation: 0.6536729765921518]
	TIME [epoch: 9.6 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39880095625580747		[learning rate: 0.0011153]
	Learning Rate: 0.00111528
	LOSS [training: 0.39880095625580747 | validation: 0.7542405264109278]
	TIME [epoch: 9.63 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.591655121872633		[learning rate: 0.0011127]
	Learning Rate: 0.00111265
	LOSS [training: 0.591655121872633 | validation: 0.6031818940593808]
	TIME [epoch: 9.63 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35805007773673225		[learning rate: 0.00111]
	Learning Rate: 0.00111003
	LOSS [training: 0.35805007773673225 | validation: 0.48863789235719096]
	TIME [epoch: 9.63 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3490018855321745		[learning rate: 0.0011074]
	Learning Rate: 0.00110741
	LOSS [training: 0.3490018855321745 | validation: 0.41882930633592075]
	TIME [epoch: 9.63 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40338096114248795		[learning rate: 0.0011048]
	Learning Rate: 0.0011048
	LOSS [training: 0.40338096114248795 | validation: 0.3803835535309078]
	TIME [epoch: 9.63 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31811884868588225		[learning rate: 0.0011022]
	Learning Rate: 0.00110219
	LOSS [training: 0.31811884868588225 | validation: 0.40407150343077036]
	TIME [epoch: 9.64 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47699783271114615		[learning rate: 0.0010996]
	Learning Rate: 0.00109959
	LOSS [training: 0.47699783271114615 | validation: 0.5202697168795338]
	TIME [epoch: 9.63 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36432990067894233		[learning rate: 0.001097]
	Learning Rate: 0.001097
	LOSS [training: 0.36432990067894233 | validation: 0.43019783672570394]
	TIME [epoch: 9.62 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36602527690384073		[learning rate: 0.0010944]
	Learning Rate: 0.00109441
	LOSS [training: 0.36602527690384073 | validation: 0.4147046183295214]
	TIME [epoch: 9.63 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3163943702078237		[learning rate: 0.0010918]
	Learning Rate: 0.00109183
	LOSS [training: 0.3163943702078237 | validation: 0.394994438442189]
	TIME [epoch: 9.62 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35534668070882985		[learning rate: 0.0010893]
	Learning Rate: 0.00108925
	LOSS [training: 0.35534668070882985 | validation: 0.48547166789336876]
	TIME [epoch: 9.63 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45790247606526346		[learning rate: 0.0010867]
	Learning Rate: 0.00108668
	LOSS [training: 0.45790247606526346 | validation: 0.782316901794267]
	TIME [epoch: 9.61 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5121054736195572		[learning rate: 0.0010841]
	Learning Rate: 0.00108412
	LOSS [training: 0.5121054736195572 | validation: 0.6483811054088342]
	TIME [epoch: 9.64 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3939777772426315		[learning rate: 0.0010816]
	Learning Rate: 0.00108156
	LOSS [training: 0.3939777772426315 | validation: 0.587226788280538]
	TIME [epoch: 9.6 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3716802350131165		[learning rate: 0.001079]
	Learning Rate: 0.00107901
	LOSS [training: 0.3716802350131165 | validation: 0.5468103323929117]
	TIME [epoch: 9.64 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3610618566184659		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.3610618566184659 | validation: 0.4861826506525057]
	TIME [epoch: 9.62 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3466515803843195		[learning rate: 0.0010739]
	Learning Rate: 0.00107393
	LOSS [training: 0.3466515803843195 | validation: 0.5354165215561789]
	TIME [epoch: 9.63 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47384820949503836		[learning rate: 0.0010714]
	Learning Rate: 0.00107139
	LOSS [training: 0.47384820949503836 | validation: 0.5197201115764896]
	TIME [epoch: 9.62 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3923018770373576		[learning rate: 0.0010689]
	Learning Rate: 0.00106887
	LOSS [training: 0.3923018770373576 | validation: 0.44418070372313934]
	TIME [epoch: 9.63 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.403888865375076		[learning rate: 0.0010663]
	Learning Rate: 0.00106634
	LOSS [training: 0.403888865375076 | validation: 0.47612683491205504]
	TIME [epoch: 9.61 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.367782421574809		[learning rate: 0.0010638]
	Learning Rate: 0.00106383
	LOSS [training: 0.367782421574809 | validation: 0.6267129032696873]
	TIME [epoch: 9.64 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47360033074349595		[learning rate: 0.0010613]
	Learning Rate: 0.00106132
	LOSS [training: 0.47360033074349595 | validation: 0.43503552211715374]
	TIME [epoch: 9.61 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3445732655298747		[learning rate: 0.0010588]
	Learning Rate: 0.00105882
	LOSS [training: 0.3445732655298747 | validation: 0.4170475654201779]
	TIME [epoch: 9.62 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3721307892463869		[learning rate: 0.0010563]
	Learning Rate: 0.00105632
	LOSS [training: 0.3721307892463869 | validation: 0.4097810658434592]
	TIME [epoch: 9.63 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3093716379510883		[learning rate: 0.0010538]
	Learning Rate: 0.00105383
	LOSS [training: 0.3093716379510883 | validation: 0.4497818138974792]
	TIME [epoch: 9.64 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3457995925434294		[learning rate: 0.0010513]
	Learning Rate: 0.00105134
	LOSS [training: 0.3457995925434294 | validation: 0.5528220566775529]
	TIME [epoch: 9.63 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3829013211896321		[learning rate: 0.0010489]
	Learning Rate: 0.00104886
	LOSS [training: 0.3829013211896321 | validation: 0.35905960834651046]
	TIME [epoch: 9.62 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37275789954619987		[learning rate: 0.0010464]
	Learning Rate: 0.00104639
	LOSS [training: 0.37275789954619987 | validation: 0.34040828138268864]
	TIME [epoch: 9.66 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34798274138161883		[learning rate: 0.0010439]
	Learning Rate: 0.00104392
	LOSS [training: 0.34798274138161883 | validation: 0.375143806900296]
	TIME [epoch: 9.61 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3520747034632657		[learning rate: 0.0010415]
	Learning Rate: 0.00104146
	LOSS [training: 0.3520747034632657 | validation: 0.3367437109307153]
	TIME [epoch: 9.62 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3313694886089448		[learning rate: 0.001039]
	Learning Rate: 0.001039
	LOSS [training: 0.3313694886089448 | validation: 0.37291336867318947]
	TIME [epoch: 9.61 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.432157921929198		[learning rate: 0.0010365]
	Learning Rate: 0.00103655
	LOSS [training: 0.432157921929198 | validation: 0.434302357805469]
	TIME [epoch: 9.65 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33656392997653545		[learning rate: 0.0010341]
	Learning Rate: 0.0010341
	LOSS [training: 0.33656392997653545 | validation: 0.38816795788083014]
	TIME [epoch: 9.63 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36823586546243364		[learning rate: 0.0010317]
	Learning Rate: 0.00103166
	LOSS [training: 0.36823586546243364 | validation: 0.47069133342061803]
	TIME [epoch: 9.62 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3036488215534841		[learning rate: 0.0010292]
	Learning Rate: 0.00102923
	LOSS [training: 0.3036488215534841 | validation: 0.3904058234259051]
	TIME [epoch: 9.62 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3172314212451251		[learning rate: 0.0010268]
	Learning Rate: 0.0010268
	LOSS [training: 0.3172314212451251 | validation: 0.428582790954987]
	TIME [epoch: 9.64 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3299708635723378		[learning rate: 0.0010244]
	Learning Rate: 0.00102438
	LOSS [training: 0.3299708635723378 | validation: 0.4220884433640382]
	TIME [epoch: 9.61 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32287905816977686		[learning rate: 0.001022]
	Learning Rate: 0.00102196
	LOSS [training: 0.32287905816977686 | validation: 0.34973688750513826]
	TIME [epoch: 9.61 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26672747539265673		[learning rate: 0.0010196]
	Learning Rate: 0.00101955
	LOSS [training: 0.26672747539265673 | validation: 0.4113832403195467]
	TIME [epoch: 9.63 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2786803011151129		[learning rate: 0.0010171]
	Learning Rate: 0.00101715
	LOSS [training: 0.2786803011151129 | validation: 0.36974840184292723]
	TIME [epoch: 9.61 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3051121290561415		[learning rate: 0.0010147]
	Learning Rate: 0.00101475
	LOSS [training: 0.3051121290561415 | validation: 0.4962469053573516]
	TIME [epoch: 9.61 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41469300303481826		[learning rate: 0.0010124]
	Learning Rate: 0.00101236
	LOSS [training: 0.41469300303481826 | validation: 0.41563296369086616]
	TIME [epoch: 9.61 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3230026216088667		[learning rate: 0.00101]
	Learning Rate: 0.00100997
	LOSS [training: 0.3230026216088667 | validation: 0.36359135908588747]
	TIME [epoch: 9.63 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5517742860057943		[learning rate: 0.0010076]
	Learning Rate: 0.00100759
	LOSS [training: 0.5517742860057943 | validation: 0.5127199162131182]
	TIME [epoch: 9.61 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3285656055655695		[learning rate: 0.0010052]
	Learning Rate: 0.00100521
	LOSS [training: 0.3285656055655695 | validation: 0.3376542895741551]
	TIME [epoch: 9.61 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3607157778936253		[learning rate: 0.0010028]
	Learning Rate: 0.00100284
	LOSS [training: 0.3607157778936253 | validation: 0.4878114843861131]
	TIME [epoch: 9.6 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35127286607656805		[learning rate: 0.0010005]
	Learning Rate: 0.00100047
	LOSS [training: 0.35127286607656805 | validation: 0.45608215593801965]
	TIME [epoch: 9.63 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3506029695403053		[learning rate: 0.00099811]
	Learning Rate: 0.000998112
	LOSS [training: 0.3506029695403053 | validation: 0.71972151729742]
	TIME [epoch: 9.59 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37597600689093014		[learning rate: 0.00099576]
	Learning Rate: 0.000995758
	LOSS [training: 0.37597600689093014 | validation: 0.4490870659295977]
	TIME [epoch: 9.62 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3065158580866628		[learning rate: 0.00099341]
	Learning Rate: 0.000993409
	LOSS [training: 0.3065158580866628 | validation: 0.5511221907075927]
	TIME [epoch: 9.61 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3795289225239738		[learning rate: 0.00099107]
	Learning Rate: 0.000991066
	LOSS [training: 0.3795289225239738 | validation: 0.4663047388368554]
	TIME [epoch: 9.64 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3494599514490374		[learning rate: 0.00098873]
	Learning Rate: 0.000988728
	LOSS [training: 0.3494599514490374 | validation: 0.44504283163139574]
	TIME [epoch: 9.62 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4539919767288664		[learning rate: 0.0009864]
	Learning Rate: 0.000986396
	LOSS [training: 0.4539919767288664 | validation: 0.6031031196367989]
	TIME [epoch: 9.61 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4316048256053314		[learning rate: 0.00098407]
	Learning Rate: 0.000984069
	LOSS [training: 0.4316048256053314 | validation: 0.6244609796558558]
	TIME [epoch: 9.61 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40920588952697645		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 0.40920588952697645 | validation: 0.527234789701456]
	TIME [epoch: 9.63 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3143732352748238		[learning rate: 0.00097943]
	Learning Rate: 0.000979432
	LOSS [training: 0.3143732352748238 | validation: 0.5430158612973014]
	TIME [epoch: 9.61 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33144128396949346		[learning rate: 0.00097712]
	Learning Rate: 0.000977122
	LOSS [training: 0.33144128396949346 | validation: 0.7390094010806375]
	TIME [epoch: 9.62 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37050807007621855		[learning rate: 0.00097482]
	Learning Rate: 0.000974817
	LOSS [training: 0.37050807007621855 | validation: 0.4826733039160112]
	TIME [epoch: 9.63 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3040556066656174		[learning rate: 0.00097252]
	Learning Rate: 0.000972517
	LOSS [training: 0.3040556066656174 | validation: 0.4785751090088259]
	TIME [epoch: 9.62 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30421110785758354		[learning rate: 0.00097022]
	Learning Rate: 0.000970224
	LOSS [training: 0.30421110785758354 | validation: 0.4936072477700494]
	TIME [epoch: 9.6 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2960041954514105		[learning rate: 0.00096793]
	Learning Rate: 0.000967935
	LOSS [training: 0.2960041954514105 | validation: 0.4073786010286837]
	TIME [epoch: 9.61 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40668263727787457		[learning rate: 0.00096565]
	Learning Rate: 0.000965652
	LOSS [training: 0.40668263727787457 | validation: 0.48738458410785657]
	TIME [epoch: 9.64 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29136913784782137		[learning rate: 0.00096337]
	Learning Rate: 0.000963374
	LOSS [training: 0.29136913784782137 | validation: 0.3432782825606979]
	TIME [epoch: 9.61 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2652801767425669		[learning rate: 0.0009611]
	Learning Rate: 0.000961101
	LOSS [training: 0.2652801767425669 | validation: 0.3461933504177725]
	TIME [epoch: 9.61 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28830768639308735		[learning rate: 0.00095883]
	Learning Rate: 0.000958834
	LOSS [training: 0.28830768639308735 | validation: 0.3394594206857989]
	TIME [epoch: 9.61 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26799906799183715		[learning rate: 0.00095657]
	Learning Rate: 0.000956572
	LOSS [training: 0.26799906799183715 | validation: 0.3879101710555807]
	TIME [epoch: 9.61 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26363993723996637		[learning rate: 0.00095432]
	Learning Rate: 0.000954316
	LOSS [training: 0.26363993723996637 | validation: 0.3217488854125476]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1045.pth
	Model improved!!!
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3073881229212646		[learning rate: 0.00095207]
	Learning Rate: 0.000952065
	LOSS [training: 0.3073881229212646 | validation: 0.4212800530993518]
	TIME [epoch: 9.6 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3542039002676811		[learning rate: 0.00094982]
	Learning Rate: 0.000949819
	LOSS [training: 0.3542039002676811 | validation: 0.40216757333295605]
	TIME [epoch: 9.64 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3346342925761456		[learning rate: 0.00094758]
	Learning Rate: 0.000947579
	LOSS [training: 0.3346342925761456 | validation: 0.49417575479005815]
	TIME [epoch: 9.63 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3089297388385025		[learning rate: 0.00094534]
	Learning Rate: 0.000945344
	LOSS [training: 0.3089297388385025 | validation: 0.32743506873138856]
	TIME [epoch: 9.62 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2964325411909772		[learning rate: 0.00094311]
	Learning Rate: 0.000943114
	LOSS [training: 0.2964325411909772 | validation: 0.46460574236142416]
	TIME [epoch: 9.63 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32801057753949325		[learning rate: 0.00094089]
	Learning Rate: 0.000940889
	LOSS [training: 0.32801057753949325 | validation: 0.44088301359263754]
	TIME [epoch: 9.63 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29639125055703847		[learning rate: 0.00093867]
	Learning Rate: 0.00093867
	LOSS [training: 0.29639125055703847 | validation: 0.5157951737780815]
	TIME [epoch: 9.63 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31729604339401707		[learning rate: 0.00093646]
	Learning Rate: 0.000936456
	LOSS [training: 0.31729604339401707 | validation: 0.3795015533557748]
	TIME [epoch: 9.62 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32320041147612344		[learning rate: 0.00093425]
	Learning Rate: 0.000934246
	LOSS [training: 0.32320041147612344 | validation: 0.4234925266546802]
	TIME [epoch: 9.62 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3225019802511687		[learning rate: 0.00093204]
	Learning Rate: 0.000932043
	LOSS [training: 0.3225019802511687 | validation: 0.4232726001146175]
	TIME [epoch: 9.64 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2815301481661877		[learning rate: 0.00092984]
	Learning Rate: 0.000929844
	LOSS [training: 0.2815301481661877 | validation: 0.3955700148723517]
	TIME [epoch: 9.6 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3156637585771004		[learning rate: 0.00092765]
	Learning Rate: 0.000927651
	LOSS [training: 0.3156637585771004 | validation: 0.3725894633793829]
	TIME [epoch: 9.6 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32554487742629135		[learning rate: 0.00092546]
	Learning Rate: 0.000925463
	LOSS [training: 0.32554487742629135 | validation: 0.354732491259952]
	TIME [epoch: 9.62 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31188510069234343		[learning rate: 0.00092328]
	Learning Rate: 0.00092328
	LOSS [training: 0.31188510069234343 | validation: 0.32952225733068824]
	TIME [epoch: 9.64 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29541709739812133		[learning rate: 0.0009211]
	Learning Rate: 0.000921102
	LOSS [training: 0.29541709739812133 | validation: 0.527426252018906]
	TIME [epoch: 9.62 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31402428449424125		[learning rate: 0.00091893]
	Learning Rate: 0.000918929
	LOSS [training: 0.31402428449424125 | validation: 0.3767276420422207]
	TIME [epoch: 9.62 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3040532282314085		[learning rate: 0.00091676]
	Learning Rate: 0.000916762
	LOSS [training: 0.3040532282314085 | validation: 0.45367951337501694]
	TIME [epoch: 9.64 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3051164562716532		[learning rate: 0.0009146]
	Learning Rate: 0.000914599
	LOSS [training: 0.3051164562716532 | validation: 0.37192377887975725]
	TIME [epoch: 9.64 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3625260406506924		[learning rate: 0.00091244]
	Learning Rate: 0.000912442
	LOSS [training: 0.3625260406506924 | validation: 0.533227231591396]
	TIME [epoch: 9.6 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3247853870553317		[learning rate: 0.00091029]
	Learning Rate: 0.000910289
	LOSS [training: 0.3247853870553317 | validation: 0.3689025195407687]
	TIME [epoch: 9.6 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2796474082190212		[learning rate: 0.00090814]
	Learning Rate: 0.000908142
	LOSS [training: 0.2796474082190212 | validation: 0.3585708717901185]
	TIME [epoch: 9.62 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26029706137139325		[learning rate: 0.000906]
	Learning Rate: 0.000906
	LOSS [training: 0.26029706137139325 | validation: 0.3715086868828723]
	TIME [epoch: 9.62 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2716834754058269		[learning rate: 0.00090386]
	Learning Rate: 0.000903863
	LOSS [training: 0.2716834754058269 | validation: 0.4738989973078732]
	TIME [epoch: 9.58 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36342694955976407		[learning rate: 0.00090173]
	Learning Rate: 0.000901731
	LOSS [training: 0.36342694955976407 | validation: 0.5318602868360833]
	TIME [epoch: 9.61 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41181646598907956		[learning rate: 0.0008996]
	Learning Rate: 0.000899604
	LOSS [training: 0.41181646598907956 | validation: 0.413376472879159]
	TIME [epoch: 9.62 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3046255679953885		[learning rate: 0.00089748]
	Learning Rate: 0.000897482
	LOSS [training: 0.3046255679953885 | validation: 0.3687015248551387]
	TIME [epoch: 9.61 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2922309982341298		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.2922309982341298 | validation: 0.4250532511059187]
	TIME [epoch: 9.62 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3041864931149436		[learning rate: 0.00089325]
	Learning Rate: 0.000893253
	LOSS [training: 0.3041864931149436 | validation: 0.470700074816433]
	TIME [epoch: 9.62 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3817223847930947		[learning rate: 0.00089115]
	Learning Rate: 0.000891146
	LOSS [training: 0.3817223847930947 | validation: 0.451658593794842]
	TIME [epoch: 9.63 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30154272971436236		[learning rate: 0.00088904]
	Learning Rate: 0.000889044
	LOSS [training: 0.30154272971436236 | validation: 0.36363105956487674]
	TIME [epoch: 9.62 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2831874102478601		[learning rate: 0.00088695]
	Learning Rate: 0.000886946
	LOSS [training: 0.2831874102478601 | validation: 0.4443919318163654]
	TIME [epoch: 9.6 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2665860075050309		[learning rate: 0.00088485]
	Learning Rate: 0.000884854
	LOSS [training: 0.2665860075050309 | validation: 0.36478932475878667]
	TIME [epoch: 9.61 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2607573050373186		[learning rate: 0.00088277]
	Learning Rate: 0.000882767
	LOSS [training: 0.2607573050373186 | validation: 0.4478640343541905]
	TIME [epoch: 9.6 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34183959121415064		[learning rate: 0.00088068]
	Learning Rate: 0.000880685
	LOSS [training: 0.34183959121415064 | validation: 0.5078242096600641]
	TIME [epoch: 9.63 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27991657755772736		[learning rate: 0.00087861]
	Learning Rate: 0.000878607
	LOSS [training: 0.27991657755772736 | validation: 0.39863837233836136]
	TIME [epoch: 9.61 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2905225863657964		[learning rate: 0.00087653]
	Learning Rate: 0.000876535
	LOSS [training: 0.2905225863657964 | validation: 0.3715822546756056]
	TIME [epoch: 9.64 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2842681589542789		[learning rate: 0.00087447]
	Learning Rate: 0.000874467
	LOSS [training: 0.2842681589542789 | validation: 0.45657942701431764]
	TIME [epoch: 9.6 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3690796778230251		[learning rate: 0.0008724]
	Learning Rate: 0.000872405
	LOSS [training: 0.3690796778230251 | validation: 0.5262212415525365]
	TIME [epoch: 9.62 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29964315929347546		[learning rate: 0.00087035]
	Learning Rate: 0.000870346
	LOSS [training: 0.29964315929347546 | validation: 0.3484939849587778]
	TIME [epoch: 9.62 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2644782181742108		[learning rate: 0.00086829]
	Learning Rate: 0.000868294
	LOSS [training: 0.2644782181742108 | validation: 0.3277675849174166]
	TIME [epoch: 9.62 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25909783913717466		[learning rate: 0.00086625]
	Learning Rate: 0.000866246
	LOSS [training: 0.25909783913717466 | validation: 0.39663368047079106]
	TIME [epoch: 9.6 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32285341254751226		[learning rate: 0.0008642]
	Learning Rate: 0.000864202
	LOSS [training: 0.32285341254751226 | validation: 0.37114756371554186]
	TIME [epoch: 9.6 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25234779042140765		[learning rate: 0.00086216]
	Learning Rate: 0.000862164
	LOSS [training: 0.25234779042140765 | validation: 0.4044979556425898]
	TIME [epoch: 9.62 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3943945409660396		[learning rate: 0.00086013]
	Learning Rate: 0.00086013
	LOSS [training: 0.3943945409660396 | validation: 0.3344972823643728]
	TIME [epoch: 9.62 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2870714906514145		[learning rate: 0.0008581]
	Learning Rate: 0.000858101
	LOSS [training: 0.2870714906514145 | validation: 0.4884900689851038]
	TIME [epoch: 9.61 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3739178434353147		[learning rate: 0.00085608]
	Learning Rate: 0.000856077
	LOSS [training: 0.3739178434353147 | validation: 0.39863629662821737]
	TIME [epoch: 9.61 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28752632466525824		[learning rate: 0.00085406]
	Learning Rate: 0.000854058
	LOSS [training: 0.28752632466525824 | validation: 0.36735480936287557]
	TIME [epoch: 9.62 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24669755539609772		[learning rate: 0.00085204]
	Learning Rate: 0.000852043
	LOSS [training: 0.24669755539609772 | validation: 0.3311940960852848]
	TIME [epoch: 9.6 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28475479751164184		[learning rate: 0.00085003]
	Learning Rate: 0.000850033
	LOSS [training: 0.28475479751164184 | validation: 0.3265883784921105]
	TIME [epoch: 9.59 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28992017873255677		[learning rate: 0.00084803]
	Learning Rate: 0.000848028
	LOSS [training: 0.28992017873255677 | validation: 0.3486088880560898]
	TIME [epoch: 9.6 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2773815545497124		[learning rate: 0.00084603]
	Learning Rate: 0.000846028
	LOSS [training: 0.2773815545497124 | validation: 0.5437339717368429]
	TIME [epoch: 9.61 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3729025735991149		[learning rate: 0.00084403]
	Learning Rate: 0.000844032
	LOSS [training: 0.3729025735991149 | validation: 0.6363825537547968]
	TIME [epoch: 9.64 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3427662167280091		[learning rate: 0.00084204]
	Learning Rate: 0.000842041
	LOSS [training: 0.3427662167280091 | validation: 0.4099164653278824]
	TIME [epoch: 9.6 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29432911960506136		[learning rate: 0.00084005]
	Learning Rate: 0.000840055
	LOSS [training: 0.29432911960506136 | validation: 0.396309371008247]
	TIME [epoch: 9.61 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2873876706084608		[learning rate: 0.00083807]
	Learning Rate: 0.000838073
	LOSS [training: 0.2873876706084608 | validation: 0.43643932196060325]
	TIME [epoch: 9.62 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3102223567205154		[learning rate: 0.0008361]
	Learning Rate: 0.000836096
	LOSS [training: 0.3102223567205154 | validation: 0.4380749503922325]
	TIME [epoch: 9.61 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.413275203511503		[learning rate: 0.00083412]
	Learning Rate: 0.000834124
	LOSS [training: 0.413275203511503 | validation: 0.36767573317071595]
	TIME [epoch: 9.6 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31726146166069996		[learning rate: 0.00083216]
	Learning Rate: 0.000832157
	LOSS [training: 0.31726146166069996 | validation: 0.3736632790839834]
	TIME [epoch: 9.61 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30429761914434195		[learning rate: 0.00083019]
	Learning Rate: 0.000830194
	LOSS [training: 0.30429761914434195 | validation: 0.4164361469224845]
	TIME [epoch: 9.62 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4041952227115787		[learning rate: 0.00082824]
	Learning Rate: 0.000828236
	LOSS [training: 0.4041952227115787 | validation: 0.5904077092194505]
	TIME [epoch: 9.6 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4343177380796427		[learning rate: 0.00082628]
	Learning Rate: 0.000826282
	LOSS [training: 0.4343177380796427 | validation: 0.5079825430607515]
	TIME [epoch: 9.6 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41329748699132446		[learning rate: 0.00082433]
	Learning Rate: 0.000824333
	LOSS [training: 0.41329748699132446 | validation: 0.3972081689373249]
	TIME [epoch: 9.62 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35553217534693404		[learning rate: 0.00082239]
	Learning Rate: 0.000822388
	LOSS [training: 0.35553217534693404 | validation: 0.3786313698756424]
	TIME [epoch: 9.61 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3797994490489262		[learning rate: 0.00082045]
	Learning Rate: 0.000820448
	LOSS [training: 0.3797994490489262 | validation: 0.40463321869164764]
	TIME [epoch: 9.6 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35607706886389034		[learning rate: 0.00081851]
	Learning Rate: 0.000818513
	LOSS [training: 0.35607706886389034 | validation: 0.4468705093752763]
	TIME [epoch: 9.6 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38581770111715497		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.38581770111715497 | validation: 0.4476343938983985]
	TIME [epoch: 9.63 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3547361910739618		[learning rate: 0.00081466]
	Learning Rate: 0.000814656
	LOSS [training: 0.3547361910739618 | validation: 0.36248987325204257]
	TIME [epoch: 9.59 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3003402468953581		[learning rate: 0.00081273]
	Learning Rate: 0.000812734
	LOSS [training: 0.3003402468953581 | validation: 0.5439474997376202]
	TIME [epoch: 9.59 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39964164157425375		[learning rate: 0.00081082]
	Learning Rate: 0.000810817
	LOSS [training: 0.39964164157425375 | validation: 0.5957496799320601]
	TIME [epoch: 9.6 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3526336282805415		[learning rate: 0.0008089]
	Learning Rate: 0.000808905
	LOSS [training: 0.3526336282805415 | validation: 0.45022562993701626]
	TIME [epoch: 9.63 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.299935166337499		[learning rate: 0.000807]
	Learning Rate: 0.000806997
	LOSS [training: 0.299935166337499 | validation: 0.5718948583104594]
	TIME [epoch: 9.6 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3414237371046334		[learning rate: 0.00080509]
	Learning Rate: 0.000805093
	LOSS [training: 0.3414237371046334 | validation: 0.6636936701393689]
	TIME [epoch: 9.61 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3405921090172321		[learning rate: 0.00080319]
	Learning Rate: 0.000803194
	LOSS [training: 0.3405921090172321 | validation: 0.4542321682778828]
	TIME [epoch: 9.62 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.314675848245807		[learning rate: 0.0008013]
	Learning Rate: 0.000801299
	LOSS [training: 0.314675848245807 | validation: 0.6185822379120168]
	TIME [epoch: 9.63 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4031479158739219		[learning rate: 0.00079941]
	Learning Rate: 0.000799409
	LOSS [training: 0.4031479158739219 | validation: 0.5103373898794338]
	TIME [epoch: 9.62 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3276784153679677		[learning rate: 0.00079752]
	Learning Rate: 0.000797524
	LOSS [training: 0.3276784153679677 | validation: 0.5106967379588732]
	TIME [epoch: 9.59 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30845548667393385		[learning rate: 0.00079564]
	Learning Rate: 0.000795642
	LOSS [training: 0.30845548667393385 | validation: 0.42421117018372256]
	TIME [epoch: 9.62 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3158585250289668		[learning rate: 0.00079377]
	Learning Rate: 0.000793766
	LOSS [training: 0.3158585250289668 | validation: 0.3886543731236216]
	TIME [epoch: 9.61 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32432487914930896		[learning rate: 0.00079189]
	Learning Rate: 0.000791893
	LOSS [training: 0.32432487914930896 | validation: 0.500604214576832]
	TIME [epoch: 9.62 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37631448017541214		[learning rate: 0.00079003]
	Learning Rate: 0.000790025
	LOSS [training: 0.37631448017541214 | validation: 0.5711950851932982]
	TIME [epoch: 9.6 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36426632368226136		[learning rate: 0.00078816]
	Learning Rate: 0.000788162
	LOSS [training: 0.36426632368226136 | validation: 0.45158352215995506]
	TIME [epoch: 9.62 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34437531635658325		[learning rate: 0.0007863]
	Learning Rate: 0.000786302
	LOSS [training: 0.34437531635658325 | validation: 0.43048959134777526]
	TIME [epoch: 9.61 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2969430758757479		[learning rate: 0.00078445]
	Learning Rate: 0.000784448
	LOSS [training: 0.2969430758757479 | validation: 0.41588622058696134]
	TIME [epoch: 9.61 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2875545140324064		[learning rate: 0.0007826]
	Learning Rate: 0.000782598
	LOSS [training: 0.2875545140324064 | validation: 0.36820150932953155]
	TIME [epoch: 9.6 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31031413675618313		[learning rate: 0.00078075]
	Learning Rate: 0.000780751
	LOSS [training: 0.31031413675618313 | validation: 0.4102972994119928]
	TIME [epoch: 9.64 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2726725525834916		[learning rate: 0.00077891]
	Learning Rate: 0.00077891
	LOSS [training: 0.2726725525834916 | validation: 0.3762270674486136]
	TIME [epoch: 9.6 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3550935004461791		[learning rate: 0.00077707]
	Learning Rate: 0.000777073
	LOSS [training: 0.3550935004461791 | validation: 0.31296078710897063]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1132.pth
	Model improved!!!
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32307270519122505		[learning rate: 0.00077524]
	Learning Rate: 0.000775239
	LOSS [training: 0.32307270519122505 | validation: 0.34097230488515307]
	TIME [epoch: 9.58 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38046850498034984		[learning rate: 0.00077341]
	Learning Rate: 0.000773411
	LOSS [training: 0.38046850498034984 | validation: 0.3071908572652029]
	TIME [epoch: 9.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1134.pth
	Model improved!!!
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28911538579686014		[learning rate: 0.00077159]
	Learning Rate: 0.000771586
	LOSS [training: 0.28911538579686014 | validation: 0.35630298214998163]
	TIME [epoch: 9.58 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4150916629258541		[learning rate: 0.00076977]
	Learning Rate: 0.000769766
	LOSS [training: 0.4150916629258541 | validation: 0.539618239974371]
	TIME [epoch: 9.61 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44089746253190076		[learning rate: 0.00076795]
	Learning Rate: 0.000767951
	LOSS [training: 0.44089746253190076 | validation: 0.4233128483625434]
	TIME [epoch: 9.61 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30531687605560653		[learning rate: 0.00076614]
	Learning Rate: 0.000766139
	LOSS [training: 0.30531687605560653 | validation: 0.400207275459853]
	TIME [epoch: 9.62 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3266672867368206		[learning rate: 0.00076433]
	Learning Rate: 0.000764332
	LOSS [training: 0.3266672867368206 | validation: 0.3171377385852771]
	TIME [epoch: 9.59 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.304177113160904		[learning rate: 0.00076253]
	Learning Rate: 0.000762529
	LOSS [training: 0.304177113160904 | validation: 0.6236326089862724]
	TIME [epoch: 9.6 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4170593617849347		[learning rate: 0.00076073]
	Learning Rate: 0.00076073
	LOSS [training: 0.4170593617849347 | validation: 0.43644994588640934]
	TIME [epoch: 9.63 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31082911448681605		[learning rate: 0.00075894]
	Learning Rate: 0.000758936
	LOSS [training: 0.31082911448681605 | validation: 0.4122623308489679]
	TIME [epoch: 9.6 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3052711454696172		[learning rate: 0.00075715]
	Learning Rate: 0.000757146
	LOSS [training: 0.3052711454696172 | validation: 0.5529321195247416]
	TIME [epoch: 9.6 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3882131853692529		[learning rate: 0.00075536]
	Learning Rate: 0.00075536
	LOSS [training: 0.3882131853692529 | validation: 0.4691540592895871]
	TIME [epoch: 9.59 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41248474825362125		[learning rate: 0.00075358]
	Learning Rate: 0.000753578
	LOSS [training: 0.41248474825362125 | validation: 0.566606840580999]
	TIME [epoch: 9.63 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35811625797927793		[learning rate: 0.0007518]
	Learning Rate: 0.0007518
	LOSS [training: 0.35811625797927793 | validation: 0.4608910912617229]
	TIME [epoch: 9.6 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33465354093983657		[learning rate: 0.00075003]
	Learning Rate: 0.000750027
	LOSS [training: 0.33465354093983657 | validation: 0.37082334926474914]
	TIME [epoch: 9.6 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37312938248332805		[learning rate: 0.00074826]
	Learning Rate: 0.000748258
	LOSS [training: 0.37312938248332805 | validation: 0.3840136651191122]
	TIME [epoch: 9.59 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2772870190962265		[learning rate: 0.00074649]
	Learning Rate: 0.000746493
	LOSS [training: 0.2772870190962265 | validation: 0.4150933703750066]
	TIME [epoch: 9.63 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3015546037127969		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.3015546037127969 | validation: 0.4807520988550422]
	TIME [epoch: 9.61 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34198315298063325		[learning rate: 0.00074298]
	Learning Rate: 0.000742975
	LOSS [training: 0.34198315298063325 | validation: 0.4277004356409384]
	TIME [epoch: 9.61 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33880096552359096		[learning rate: 0.00074122]
	Learning Rate: 0.000741223
	LOSS [training: 0.33880096552359096 | validation: 0.4119856962830379]
	TIME [epoch: 9.61 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3162225609308648		[learning rate: 0.00073947]
	Learning Rate: 0.000739474
	LOSS [training: 0.3162225609308648 | validation: 0.38948490559583165]
	TIME [epoch: 9.61 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32575058750823965		[learning rate: 0.00073773]
	Learning Rate: 0.00073773
	LOSS [training: 0.32575058750823965 | validation: 0.47054239133691667]
	TIME [epoch: 9.61 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31926785865079393		[learning rate: 0.00073599]
	Learning Rate: 0.00073599
	LOSS [training: 0.31926785865079393 | validation: 0.3510958857938377]
	TIME [epoch: 9.61 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30956556138420444		[learning rate: 0.00073425]
	Learning Rate: 0.000734254
	LOSS [training: 0.30956556138420444 | validation: 0.4078856255882988]
	TIME [epoch: 9.64 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.314342580804217		[learning rate: 0.00073252]
	Learning Rate: 0.000732522
	LOSS [training: 0.314342580804217 | validation: 0.42378065579665875]
	TIME [epoch: 9.61 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2927162947663627		[learning rate: 0.00073079]
	Learning Rate: 0.000730794
	LOSS [training: 0.2927162947663627 | validation: 0.3219762024129673]
	TIME [epoch: 9.59 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28427263561884025		[learning rate: 0.00072907]
	Learning Rate: 0.00072907
	LOSS [training: 0.28427263561884025 | validation: 0.29688513649000586]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1159.pth
	Model improved!!!
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2576623532000742		[learning rate: 0.00072735]
	Learning Rate: 0.00072735
	LOSS [training: 0.2576623532000742 | validation: 0.3654498854200419]
	TIME [epoch: 9.63 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2749098274608901		[learning rate: 0.00072563]
	Learning Rate: 0.000725634
	LOSS [training: 0.2749098274608901 | validation: 0.42760306774889656]
	TIME [epoch: 9.62 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3302119057651304		[learning rate: 0.00072392]
	Learning Rate: 0.000723923
	LOSS [training: 0.3302119057651304 | validation: 0.4735904653139379]
	TIME [epoch: 9.61 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28958915229343773		[learning rate: 0.00072222]
	Learning Rate: 0.000722215
	LOSS [training: 0.28958915229343773 | validation: 0.37117087933612763]
	TIME [epoch: 9.61 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3146684789656276		[learning rate: 0.00072051]
	Learning Rate: 0.000720512
	LOSS [training: 0.3146684789656276 | validation: 0.374608161778405]
	TIME [epoch: 9.63 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2708173640224985		[learning rate: 0.00071881]
	Learning Rate: 0.000718812
	LOSS [training: 0.2708173640224985 | validation: 0.3262980674348346]
	TIME [epoch: 9.6 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3341559259219923		[learning rate: 0.00071712]
	Learning Rate: 0.000717117
	LOSS [training: 0.3341559259219923 | validation: 0.3052323091342056]
	TIME [epoch: 9.62 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2420925524838597		[learning rate: 0.00071542]
	Learning Rate: 0.000715425
	LOSS [training: 0.2420925524838597 | validation: 0.3802009949514983]
	TIME [epoch: 9.62 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3145366013735825		[learning rate: 0.00071374]
	Learning Rate: 0.000713738
	LOSS [training: 0.3145366013735825 | validation: 0.3053944442452406]
	TIME [epoch: 9.61 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3022951381479354		[learning rate: 0.00071205]
	Learning Rate: 0.000712054
	LOSS [training: 0.3022951381479354 | validation: 0.34030370047920117]
	TIME [epoch: 9.61 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29612941714034274		[learning rate: 0.00071037]
	Learning Rate: 0.000710374
	LOSS [training: 0.29612941714034274 | validation: 0.30696595016473743]
	TIME [epoch: 9.61 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2680931803850212		[learning rate: 0.0007087]
	Learning Rate: 0.000708698
	LOSS [training: 0.2680931803850212 | validation: 0.3093916931265826]
	TIME [epoch: 9.62 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2748732847642409		[learning rate: 0.00070703]
	Learning Rate: 0.000707027
	LOSS [training: 0.2748732847642409 | validation: 0.2906117389280148]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1172.pth
	Model improved!!!
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23633766518861932		[learning rate: 0.00070536]
	Learning Rate: 0.000705359
	LOSS [training: 0.23633766518861932 | validation: 0.329813440383042]
	TIME [epoch: 9.6 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.256090722072063		[learning rate: 0.0007037]
	Learning Rate: 0.000703695
	LOSS [training: 0.256090722072063 | validation: 0.2610593816759982]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1174.pth
	Model improved!!!
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26379140092886705		[learning rate: 0.00070204]
	Learning Rate: 0.000702035
	LOSS [training: 0.26379140092886705 | validation: 0.32736528440920226]
	TIME [epoch: 9.62 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25068339027613595		[learning rate: 0.00070038]
	Learning Rate: 0.000700379
	LOSS [training: 0.25068339027613595 | validation: 0.45655744860665126]
	TIME [epoch: 9.59 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.470189442663551		[learning rate: 0.00069873]
	Learning Rate: 0.000698727
	LOSS [training: 0.470189442663551 | validation: 0.7498237773304061]
	TIME [epoch: 9.59 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3891326011379632		[learning rate: 0.00069708]
	Learning Rate: 0.000697079
	LOSS [training: 0.3891326011379632 | validation: 0.5176540821094653]
	TIME [epoch: 9.6 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29081481987381663		[learning rate: 0.00069543]
	Learning Rate: 0.000695435
	LOSS [training: 0.29081481987381663 | validation: 0.37334090249626245]
	TIME [epoch: 9.6 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2674097031225299		[learning rate: 0.00069379]
	Learning Rate: 0.000693794
	LOSS [training: 0.2674097031225299 | validation: 0.45585864966284506]
	TIME [epoch: 9.58 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2624735922785179		[learning rate: 0.00069216]
	Learning Rate: 0.000692158
	LOSS [training: 0.2624735922785179 | validation: 0.31647408730821774]
	TIME [epoch: 9.58 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2320373592194623		[learning rate: 0.00069053]
	Learning Rate: 0.000690525
	LOSS [training: 0.2320373592194623 | validation: 0.33954030280536474]
	TIME [epoch: 9.6 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2392709619326257		[learning rate: 0.0006889]
	Learning Rate: 0.000688896
	LOSS [training: 0.2392709619326257 | validation: 0.2992679999056032]
	TIME [epoch: 9.58 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2541225912389939		[learning rate: 0.00068727]
	Learning Rate: 0.000687271
	LOSS [training: 0.2541225912389939 | validation: 0.318784253882105]
	TIME [epoch: 9.58 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2531381115138829		[learning rate: 0.00068565]
	Learning Rate: 0.00068565
	LOSS [training: 0.2531381115138829 | validation: 0.31957718670057095]
	TIME [epoch: 9.58 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30686168511310863		[learning rate: 0.00068403]
	Learning Rate: 0.000684033
	LOSS [training: 0.30686168511310863 | validation: 0.38285181425612363]
	TIME [epoch: 9.61 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3092384022645983		[learning rate: 0.00068242]
	Learning Rate: 0.000682419
	LOSS [training: 0.3092384022645983 | validation: 0.353765637964054]
	TIME [epoch: 9.59 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2681884235638875		[learning rate: 0.00068081]
	Learning Rate: 0.00068081
	LOSS [training: 0.2681884235638875 | validation: 0.3409478900803767]
	TIME [epoch: 9.59 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2769535122324542		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.2769535122324542 | validation: 0.3126532234809932]
	TIME [epoch: 9.58 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30495540999537873		[learning rate: 0.0006776]
	Learning Rate: 0.000677601
	LOSS [training: 0.30495540999537873 | validation: 0.33292584673795406]
	TIME [epoch: 9.61 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.312381025150287		[learning rate: 0.000676]
	Learning Rate: 0.000676003
	LOSS [training: 0.312381025150287 | validation: 0.38860740173342295]
	TIME [epoch: 9.58 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3036340453227411		[learning rate: 0.00067441]
	Learning Rate: 0.000674409
	LOSS [training: 0.3036340453227411 | validation: 0.34703138604964523]
	TIME [epoch: 9.58 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3209921141531648		[learning rate: 0.00067282]
	Learning Rate: 0.000672818
	LOSS [training: 0.3209921141531648 | validation: 0.44553640358467683]
	TIME [epoch: 9.59 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2979778471876678		[learning rate: 0.00067123]
	Learning Rate: 0.000671231
	LOSS [training: 0.2979778471876678 | validation: 0.4293183235231882]
	TIME [epoch: 9.59 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2897737357317868		[learning rate: 0.00066965]
	Learning Rate: 0.000669647
	LOSS [training: 0.2897737357317868 | validation: 0.3550296305024629]
	TIME [epoch: 9.6 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.292068512856832		[learning rate: 0.00066807]
	Learning Rate: 0.000668068
	LOSS [training: 0.292068512856832 | validation: 0.3364105145535046]
	TIME [epoch: 9.59 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2447453686374783		[learning rate: 0.00066649]
	Learning Rate: 0.000666492
	LOSS [training: 0.2447453686374783 | validation: 0.3075017360030276]
	TIME [epoch: 9.61 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.250611118227059		[learning rate: 0.00066492]
	Learning Rate: 0.00066492
	LOSS [training: 0.250611118227059 | validation: 0.38089067951183275]
	TIME [epoch: 9.59 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2749322124939134		[learning rate: 0.00066335]
	Learning Rate: 0.000663351
	LOSS [training: 0.2749322124939134 | validation: 0.35773122971241195]
	TIME [epoch: 9.59 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3001825558640851		[learning rate: 0.00066179]
	Learning Rate: 0.000661786
	LOSS [training: 0.3001825558640851 | validation: 0.4609445704749415]
	TIME [epoch: 9.59 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3130087904637744		[learning rate: 0.00066023]
	Learning Rate: 0.000660225
	LOSS [training: 0.3130087904637744 | validation: 0.4020076593786166]
	TIME [epoch: 9.61 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24044501646843824		[learning rate: 0.00065867]
	Learning Rate: 0.000658668
	LOSS [training: 0.24044501646843824 | validation: 0.3283953404441723]
	TIME [epoch: 9.59 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2288992180406845		[learning rate: 0.00065711]
	Learning Rate: 0.000657114
	LOSS [training: 0.2288992180406845 | validation: 0.3275729304724513]
	TIME [epoch: 9.58 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23883452422048132		[learning rate: 0.00065556]
	Learning Rate: 0.000655564
	LOSS [training: 0.23883452422048132 | validation: 0.37656608647658746]
	TIME [epoch: 9.6 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26325505764037754		[learning rate: 0.00065402]
	Learning Rate: 0.000654018
	LOSS [training: 0.26325505764037754 | validation: 0.306667290434029]
	TIME [epoch: 9.62 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2348474113933583		[learning rate: 0.00065248]
	Learning Rate: 0.000652475
	LOSS [training: 0.2348474113933583 | validation: 0.27243834927627897]
	TIME [epoch: 9.6 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2329443198866405		[learning rate: 0.00065094]
	Learning Rate: 0.000650936
	LOSS [training: 0.2329443198866405 | validation: 0.513349597181056]
	TIME [epoch: 9.6 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35137306034411414		[learning rate: 0.0006494]
	Learning Rate: 0.000649401
	LOSS [training: 0.35137306034411414 | validation: 0.3197314129576885]
	TIME [epoch: 9.6 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26780064444605467		[learning rate: 0.00064787]
	Learning Rate: 0.000647869
	LOSS [training: 0.26780064444605467 | validation: 0.3045096659537551]
	TIME [epoch: 9.62 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26468573487062674		[learning rate: 0.00064634]
	Learning Rate: 0.000646341
	LOSS [training: 0.26468573487062674 | validation: 0.4715834450064871]
	TIME [epoch: 9.59 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3487125370005046		[learning rate: 0.00064482]
	Learning Rate: 0.000644816
	LOSS [training: 0.3487125370005046 | validation: 0.4180880364521559]
	TIME [epoch: 9.59 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29369818349304505		[learning rate: 0.0006433]
	Learning Rate: 0.000643295
	LOSS [training: 0.29369818349304505 | validation: 0.4379400770900603]
	TIME [epoch: 9.61 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27559899196828164		[learning rate: 0.00064178]
	Learning Rate: 0.000641778
	LOSS [training: 0.27559899196828164 | validation: 0.40252199858316134]
	TIME [epoch: 9.61 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3501462538501031		[learning rate: 0.00064026]
	Learning Rate: 0.000640264
	LOSS [training: 0.3501462538501031 | validation: 0.42559448032855757]
	TIME [epoch: 9.6 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26872191424920533		[learning rate: 0.00063875]
	Learning Rate: 0.000638754
	LOSS [training: 0.26872191424920533 | validation: 0.4226958867136639]
	TIME [epoch: 9.6 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28793721244088866		[learning rate: 0.00063725]
	Learning Rate: 0.000637247
	LOSS [training: 0.28793721244088866 | validation: 0.3652876027781371]
	TIME [epoch: 9.62 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25639876108859794		[learning rate: 0.00063574]
	Learning Rate: 0.000635744
	LOSS [training: 0.25639876108859794 | validation: 0.2842762764076767]
	TIME [epoch: 9.59 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24522034849751498		[learning rate: 0.00063424]
	Learning Rate: 0.000634244
	LOSS [training: 0.24522034849751498 | validation: 0.28844290454659016]
	TIME [epoch: 9.6 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23840397047750256		[learning rate: 0.00063275]
	Learning Rate: 0.000632748
	LOSS [training: 0.23840397047750256 | validation: 0.27961701005831946]
	TIME [epoch: 9.6 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23065385376041272		[learning rate: 0.00063126]
	Learning Rate: 0.000631255
	LOSS [training: 0.23065385376041272 | validation: 0.28813559607263173]
	TIME [epoch: 9.62 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30070053440225786		[learning rate: 0.00062977]
	Learning Rate: 0.000629766
	LOSS [training: 0.30070053440225786 | validation: 0.3739811516775082]
	TIME [epoch: 9.6 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48822787378529087		[learning rate: 0.00062828]
	Learning Rate: 0.000628281
	LOSS [training: 0.48822787378529087 | validation: 0.32008613975383754]
	TIME [epoch: 9.6 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2875961054623736		[learning rate: 0.0006268]
	Learning Rate: 0.000626799
	LOSS [training: 0.2875961054623736 | validation: 0.2916013609169696]
	TIME [epoch: 9.61 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25669989693779016		[learning rate: 0.00062532]
	Learning Rate: 0.00062532
	LOSS [training: 0.25669989693779016 | validation: 0.2756608419498493]
	TIME [epoch: 9.63 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29807049407906067		[learning rate: 0.00062385]
	Learning Rate: 0.000623845
	LOSS [training: 0.29807049407906067 | validation: 0.3129475722024286]
	TIME [epoch: 9.59 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3135041944741601		[learning rate: 0.00062237]
	Learning Rate: 0.000622374
	LOSS [training: 0.3135041944741601 | validation: 0.35351342278502884]
	TIME [epoch: 9.6 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3021730312483769		[learning rate: 0.00062091]
	Learning Rate: 0.000620906
	LOSS [training: 0.3021730312483769 | validation: 0.3455770979372912]
	TIME [epoch: 9.62 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25157521512488296		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.25157521512488296 | validation: 0.3107950261081356]
	TIME [epoch: 9.61 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24358813800121598		[learning rate: 0.00061798]
	Learning Rate: 0.00061798
	LOSS [training: 0.24358813800121598 | validation: 0.3544291046166215]
	TIME [epoch: 9.6 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24255930888689878		[learning rate: 0.00061652]
	Learning Rate: 0.000616522
	LOSS [training: 0.24255930888689878 | validation: 0.2825988554913021]
	TIME [epoch: 9.6 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21675041460732195		[learning rate: 0.00061507]
	Learning Rate: 0.000615068
	LOSS [training: 0.21675041460732195 | validation: 0.3880798281887836]
	TIME [epoch: 9.62 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2448216935334142		[learning rate: 0.00061362]
	Learning Rate: 0.000613617
	LOSS [training: 0.2448216935334142 | validation: 0.31184350985684073]
	TIME [epoch: 9.6 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2305390265334438		[learning rate: 0.00061217]
	Learning Rate: 0.00061217
	LOSS [training: 0.2305390265334438 | validation: 0.3178919509810419]
	TIME [epoch: 9.6 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28294834102021227		[learning rate: 0.00061073]
	Learning Rate: 0.000610726
	LOSS [training: 0.28294834102021227 | validation: 0.2922666044420255]
	TIME [epoch: 9.61 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29194858480365393		[learning rate: 0.00060929]
	Learning Rate: 0.000609285
	LOSS [training: 0.29194858480365393 | validation: 0.28388239393695097]
	TIME [epoch: 9.62 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2662421991533654		[learning rate: 0.00060785]
	Learning Rate: 0.000607848
	LOSS [training: 0.2662421991533654 | validation: 0.28250221082066673]
	TIME [epoch: 9.61 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2629195917610302		[learning rate: 0.00060641]
	Learning Rate: 0.000606414
	LOSS [training: 0.2629195917610302 | validation: 0.29625117037261284]
	TIME [epoch: 9.6 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2529777620099837		[learning rate: 0.00060498]
	Learning Rate: 0.000604983
	LOSS [training: 0.2529777620099837 | validation: 0.33310353265986364]
	TIME [epoch: 9.6 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30499564118708117		[learning rate: 0.00060356]
	Learning Rate: 0.000603557
	LOSS [training: 0.30499564118708117 | validation: 0.28840278340607284]
	TIME [epoch: 9.62 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2582305534087932		[learning rate: 0.00060213]
	Learning Rate: 0.000602133
	LOSS [training: 0.2582305534087932 | validation: 0.3098989136215836]
	TIME [epoch: 9.6 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23851115104778894		[learning rate: 0.00060071]
	Learning Rate: 0.000600712
	LOSS [training: 0.23851115104778894 | validation: 0.2963300690963894]
	TIME [epoch: 9.6 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2289833517288896		[learning rate: 0.0005993]
	Learning Rate: 0.000599296
	LOSS [training: 0.2289833517288896 | validation: 0.31406700701614226]
	TIME [epoch: 9.62 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29705103798948895		[learning rate: 0.00059788]
	Learning Rate: 0.000597882
	LOSS [training: 0.29705103798948895 | validation: 0.5528572917237197]
	TIME [epoch: 9.61 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3181556876756376		[learning rate: 0.00059647]
	Learning Rate: 0.000596471
	LOSS [training: 0.3181556876756376 | validation: 0.3690371761204327]
	TIME [epoch: 9.59 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27487709746328354		[learning rate: 0.00059506]
	Learning Rate: 0.000595065
	LOSS [training: 0.27487709746328354 | validation: 0.3686361460536015]
	TIME [epoch: 9.6 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26165781760644813		[learning rate: 0.00059366]
	Learning Rate: 0.000593661
	LOSS [training: 0.26165781760644813 | validation: 0.32599143156929844]
	TIME [epoch: 9.62 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23090738240798386		[learning rate: 0.00059226]
	Learning Rate: 0.000592261
	LOSS [training: 0.23090738240798386 | validation: 0.3017511211226938]
	TIME [epoch: 9.6 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2133553162103839		[learning rate: 0.00059086]
	Learning Rate: 0.000590863
	LOSS [training: 0.2133553162103839 | validation: 0.28155251571053874]
	TIME [epoch: 9.6 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21143661415962964		[learning rate: 0.00058947]
	Learning Rate: 0.00058947
	LOSS [training: 0.21143661415962964 | validation: 0.27917920620694264]
	TIME [epoch: 9.6 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2132540752302085		[learning rate: 0.00058808]
	Learning Rate: 0.000588079
	LOSS [training: 0.2132540752302085 | validation: 0.3486898141559614]
	TIME [epoch: 9.62 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2158531088877563		[learning rate: 0.00058669]
	Learning Rate: 0.000586692
	LOSS [training: 0.2158531088877563 | validation: 0.387410498805002]
	TIME [epoch: 9.61 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22193835816328886		[learning rate: 0.00058531]
	Learning Rate: 0.000585308
	LOSS [training: 0.22193835816328886 | validation: 0.3121419260234526]
	TIME [epoch: 9.59 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2117914872820475		[learning rate: 0.00058393]
	Learning Rate: 0.000583927
	LOSS [training: 0.2117914872820475 | validation: 0.26636738989472925]
	TIME [epoch: 9.59 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2240171571263252		[learning rate: 0.00058255]
	Learning Rate: 0.00058255
	LOSS [training: 0.2240171571263252 | validation: 0.2867363163604043]
	TIME [epoch: 9.61 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22930746616951514		[learning rate: 0.00058118]
	Learning Rate: 0.000581176
	LOSS [training: 0.22930746616951514 | validation: 0.32781383008656134]
	TIME [epoch: 9.59 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23581358762452093		[learning rate: 0.00057981]
	Learning Rate: 0.000579805
	LOSS [training: 0.23581358762452093 | validation: 0.29167418600369144]
	TIME [epoch: 9.59 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2619646658416016		[learning rate: 0.00057844]
	Learning Rate: 0.000578437
	LOSS [training: 0.2619646658416016 | validation: 0.3048572257465613]
	TIME [epoch: 9.6 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.280937937946093		[learning rate: 0.00057707]
	Learning Rate: 0.000577073
	LOSS [training: 0.280937937946093 | validation: 0.3167121492365499]
	TIME [epoch: 9.6 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23996492828727028		[learning rate: 0.00057571]
	Learning Rate: 0.000575712
	LOSS [training: 0.23996492828727028 | validation: 0.3113116295901544]
	TIME [epoch: 9.6 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26597022232015755		[learning rate: 0.00057435]
	Learning Rate: 0.000574354
	LOSS [training: 0.26597022232015755 | validation: 0.29230261702799964]
	TIME [epoch: 9.6 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21707287057536034		[learning rate: 0.000573]
	Learning Rate: 0.000572999
	LOSS [training: 0.21707287057536034 | validation: 0.2733256257313526]
	TIME [epoch: 9.63 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22204048481250913		[learning rate: 0.00057165]
	Learning Rate: 0.000571647
	LOSS [training: 0.22204048481250913 | validation: 0.30827874841464215]
	TIME [epoch: 9.6 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3383706786696649		[learning rate: 0.0005703]
	Learning Rate: 0.000570299
	LOSS [training: 0.3383706786696649 | validation: 0.4675080593292904]
	TIME [epoch: 9.6 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31094188190923094		[learning rate: 0.00056895]
	Learning Rate: 0.000568954
	LOSS [training: 0.31094188190923094 | validation: 0.43297046992166816]
	TIME [epoch: 9.61 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3027215732224911		[learning rate: 0.00056761]
	Learning Rate: 0.000567612
	LOSS [training: 0.3027215732224911 | validation: 0.37684841538750946]
	TIME [epoch: 9.61 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.240709174440431		[learning rate: 0.00056627]
	Learning Rate: 0.000566273
	LOSS [training: 0.240709174440431 | validation: 0.3576104294494628]
	TIME [epoch: 9.6 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2527960164365443		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.2527960164365443 | validation: 0.3525520198495389]
	TIME [epoch: 9.6 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2342750408773801		[learning rate: 0.0005636]
	Learning Rate: 0.000563604
	LOSS [training: 0.2342750408773801 | validation: 0.3662320574690349]
	TIME [epoch: 9.6 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24260865793879058		[learning rate: 0.00056227]
	Learning Rate: 0.000562275
	LOSS [training: 0.24260865793879058 | validation: 0.33162838551085627]
	TIME [epoch: 9.62 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22591557016176594		[learning rate: 0.00056095]
	Learning Rate: 0.000560949
	LOSS [training: 0.22591557016176594 | validation: 0.29065230288137683]
	TIME [epoch: 9.6 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19798122776137803		[learning rate: 0.00055963]
	Learning Rate: 0.000559625
	LOSS [training: 0.19798122776137803 | validation: 0.2980158657021614]
	TIME [epoch: 9.6 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.250869919867119		[learning rate: 0.00055831]
	Learning Rate: 0.000558305
	LOSS [training: 0.250869919867119 | validation: 0.40436124053007866]
	TIME [epoch: 9.62 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3156466651476958		[learning rate: 0.00055699]
	Learning Rate: 0.000556988
	LOSS [training: 0.3156466651476958 | validation: 0.3137408182731255]
	TIME [epoch: 9.61 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24782211693607953		[learning rate: 0.00055567]
	Learning Rate: 0.000555674
	LOSS [training: 0.24782211693607953 | validation: 0.35302071461008866]
	TIME [epoch: 9.61 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2566127547042072		[learning rate: 0.00055436]
	Learning Rate: 0.000554364
	LOSS [training: 0.2566127547042072 | validation: 0.2994906406887082]
	TIME [epoch: 9.59 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22365902492961745		[learning rate: 0.00055306]
	Learning Rate: 0.000553056
	LOSS [training: 0.22365902492961745 | validation: 0.32055773268879734]
	TIME [epoch: 9.62 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2184139465125839		[learning rate: 0.00055175]
	Learning Rate: 0.000551752
	LOSS [training: 0.2184139465125839 | validation: 0.3418662905386563]
	TIME [epoch: 9.61 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20703335144487078		[learning rate: 0.00055045]
	Learning Rate: 0.00055045
	LOSS [training: 0.20703335144487078 | validation: 0.3126412504625601]
	TIME [epoch: 9.59 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20648021865137753		[learning rate: 0.00054915]
	Learning Rate: 0.000549152
	LOSS [training: 0.20648021865137753 | validation: 0.3282754407190396]
	TIME [epoch: 9.59 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21162883723695014		[learning rate: 0.00054786]
	Learning Rate: 0.000547856
	LOSS [training: 0.21162883723695014 | validation: 0.3974045685896481]
	TIME [epoch: 9.62 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22059678734439095		[learning rate: 0.00054656]
	Learning Rate: 0.000546564
	LOSS [training: 0.22059678734439095 | validation: 0.3874032770219402]
	TIME [epoch: 9.6 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.230769694428291		[learning rate: 0.00054527]
	Learning Rate: 0.000545275
	LOSS [training: 0.230769694428291 | validation: 0.38613135338319254]
	TIME [epoch: 9.59 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24659971965758887		[learning rate: 0.00054399]
	Learning Rate: 0.000543988
	LOSS [training: 0.24659971965758887 | validation: 0.49133265085961486]
	TIME [epoch: 9.6 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26672174607732924		[learning rate: 0.00054271]
	Learning Rate: 0.000542705
	LOSS [training: 0.26672174607732924 | validation: 0.3815086796286288]
	TIME [epoch: 9.61 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21151365965523442		[learning rate: 0.00054143]
	Learning Rate: 0.000541425
	LOSS [training: 0.21151365965523442 | validation: 0.40711977030697866]
	TIME [epoch: 9.6 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21041031314690412		[learning rate: 0.00054015]
	Learning Rate: 0.000540148
	LOSS [training: 0.21041031314690412 | validation: 0.32129100318994236]
	TIME [epoch: 9.59 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23165645942099986		[learning rate: 0.00053887]
	Learning Rate: 0.000538874
	LOSS [training: 0.23165645942099986 | validation: 0.3524097169954497]
	TIME [epoch: 9.61 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.258682484177573		[learning rate: 0.0005376]
	Learning Rate: 0.000537603
	LOSS [training: 0.258682484177573 | validation: 0.3570452521047296]
	TIME [epoch: 9.61 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22992223066310574		[learning rate: 0.00053633]
	Learning Rate: 0.000536335
	LOSS [training: 0.22992223066310574 | validation: 0.3043517265707915]
	TIME [epoch: 9.6 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19646436809538845		[learning rate: 0.00053507]
	Learning Rate: 0.00053507
	LOSS [training: 0.19646436809538845 | validation: 0.392516582275388]
	TIME [epoch: 9.6 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21517076974198868		[learning rate: 0.00053381]
	Learning Rate: 0.000533807
	LOSS [training: 0.21517076974198868 | validation: 0.32052277894611947]
	TIME [epoch: 9.61 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21552969244278192		[learning rate: 0.00053255]
	Learning Rate: 0.000532548
	LOSS [training: 0.21552969244278192 | validation: 0.3707348990727239]
	TIME [epoch: 9.6 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23162399058556246		[learning rate: 0.00053129]
	Learning Rate: 0.000531292
	LOSS [training: 0.23162399058556246 | validation: 0.3323509140913815]
	TIME [epoch: 9.61 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22334593812314205		[learning rate: 0.00053004]
	Learning Rate: 0.000530039
	LOSS [training: 0.22334593812314205 | validation: 0.3583904163072167]
	TIME [epoch: 9.6 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20759964467803166		[learning rate: 0.00052879]
	Learning Rate: 0.000528789
	LOSS [training: 0.20759964467803166 | validation: 0.2996985152722337]
	TIME [epoch: 9.6 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20415434808724137		[learning rate: 0.00052754]
	Learning Rate: 0.000527541
	LOSS [training: 0.20415434808724137 | validation: 0.33327209607457475]
	TIME [epoch: 9.59 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2101380465232638		[learning rate: 0.0005263]
	Learning Rate: 0.000526297
	LOSS [training: 0.2101380465232638 | validation: 0.2832013169220812]
	TIME [epoch: 9.6 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19402046363548733		[learning rate: 0.00052506]
	Learning Rate: 0.000525055
	LOSS [training: 0.19402046363548733 | validation: 0.3102582427000114]
	TIME [epoch: 9.6 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.215589728512325		[learning rate: 0.00052382]
	Learning Rate: 0.000523817
	LOSS [training: 0.215589728512325 | validation: 0.2964818734647871]
	TIME [epoch: 9.63 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20894891350711		[learning rate: 0.00052258]
	Learning Rate: 0.000522581
	LOSS [training: 0.20894891350711 | validation: 0.320835705813718]
	TIME [epoch: 9.61 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30885555701809936		[learning rate: 0.00052135]
	Learning Rate: 0.000521348
	LOSS [training: 0.30885555701809936 | validation: 0.34170791327432104]
	TIME [epoch: 9.61 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24636808931866513		[learning rate: 0.00052012]
	Learning Rate: 0.000520119
	LOSS [training: 0.24636808931866513 | validation: 0.3028005863647068]
	TIME [epoch: 9.61 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20316109399704904		[learning rate: 0.00051889]
	Learning Rate: 0.000518892
	LOSS [training: 0.20316109399704904 | validation: 0.31655635544303856]
	TIME [epoch: 9.62 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19139702181741902		[learning rate: 0.00051767]
	Learning Rate: 0.000517668
	LOSS [training: 0.19139702181741902 | validation: 0.32222196420469673]
	TIME [epoch: 9.6 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24291895661352875		[learning rate: 0.00051645]
	Learning Rate: 0.000516447
	LOSS [training: 0.24291895661352875 | validation: 0.3106259652921069]
	TIME [epoch: 9.61 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2354110958147097		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.2354110958147097 | validation: 0.3964920885667685]
	TIME [epoch: 9.61 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.383856148906633		[learning rate: 0.00051401]
	Learning Rate: 0.000514013
	LOSS [training: 0.383856148906633 | validation: 0.29735101540043263]
	TIME [epoch: 9.61 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21149994442586273		[learning rate: 0.0005128]
	Learning Rate: 0.000512801
	LOSS [training: 0.21149994442586273 | validation: 0.28322435760782694]
	TIME [epoch: 9.61 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21109279801320618		[learning rate: 0.00051159]
	Learning Rate: 0.000511591
	LOSS [training: 0.21109279801320618 | validation: 0.3627929542441398]
	TIME [epoch: 9.61 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26383342394127063		[learning rate: 0.00051038]
	Learning Rate: 0.000510384
	LOSS [training: 0.26383342394127063 | validation: 0.3527669463908361]
	TIME [epoch: 9.61 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2620339713781326		[learning rate: 0.00050918]
	Learning Rate: 0.00050918
	LOSS [training: 0.2620339713781326 | validation: 0.3936336904127269]
	TIME [epoch: 9.59 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2504439164483109		[learning rate: 0.00050798]
	Learning Rate: 0.000507979
	LOSS [training: 0.2504439164483109 | validation: 0.3397858636506143]
	TIME [epoch: 9.6 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21998643247370966		[learning rate: 0.00050678]
	Learning Rate: 0.000506781
	LOSS [training: 0.21998643247370966 | validation: 0.38743233369489705]
	TIME [epoch: 9.59 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23656275667532745		[learning rate: 0.00050559]
	Learning Rate: 0.000505586
	LOSS [training: 0.23656275667532745 | validation: 0.38476127858443493]
	TIME [epoch: 9.63 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28695681069183415		[learning rate: 0.00050439]
	Learning Rate: 0.000504393
	LOSS [training: 0.28695681069183415 | validation: 0.3885130648475402]
	TIME [epoch: 9.6 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22365345096087016		[learning rate: 0.0005032]
	Learning Rate: 0.000503203
	LOSS [training: 0.22365345096087016 | validation: 0.3204917109473837]
	TIME [epoch: 9.61 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20115743550185866		[learning rate: 0.00050202]
	Learning Rate: 0.000502016
	LOSS [training: 0.20115743550185866 | validation: 0.30967099499294926]
	TIME [epoch: 9.6 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22090822303703206		[learning rate: 0.00050083]
	Learning Rate: 0.000500832
	LOSS [training: 0.22090822303703206 | validation: 0.38379644112162853]
	TIME [epoch: 9.62 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2769209089499093		[learning rate: 0.00049965]
	Learning Rate: 0.000499651
	LOSS [training: 0.2769209089499093 | validation: 0.36697472817575205]
	TIME [epoch: 9.61 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20594513191117728		[learning rate: 0.00049847]
	Learning Rate: 0.000498472
	LOSS [training: 0.20594513191117728 | validation: 0.36841700740329514]
	TIME [epoch: 9.6 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26575605677399855		[learning rate: 0.0004973]
	Learning Rate: 0.000497296
	LOSS [training: 0.26575605677399855 | validation: 0.38528494861314566]
	TIME [epoch: 9.61 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2401006586941575		[learning rate: 0.00049612]
	Learning Rate: 0.000496123
	LOSS [training: 0.2401006586941575 | validation: 0.35273739145269917]
	TIME [epoch: 9.61 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2792374386733135		[learning rate: 0.00049495]
	Learning Rate: 0.000494953
	LOSS [training: 0.2792374386733135 | validation: 0.3403958522741822]
	TIME [epoch: 9.59 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21515533701499417		[learning rate: 0.00049379]
	Learning Rate: 0.000493786
	LOSS [training: 0.21515533701499417 | validation: 0.3328111602511614]
	TIME [epoch: 9.61 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20730078862175833		[learning rate: 0.00049262]
	Learning Rate: 0.000492621
	LOSS [training: 0.20730078862175833 | validation: 0.269807556429721]
	TIME [epoch: 9.63 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20017317232794882		[learning rate: 0.00049146]
	Learning Rate: 0.000491459
	LOSS [training: 0.20017317232794882 | validation: 0.2887981371717078]
	TIME [epoch: 9.61 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20519278377197744		[learning rate: 0.0004903]
	Learning Rate: 0.0004903
	LOSS [training: 0.20519278377197744 | validation: 0.2779548630644366]
	TIME [epoch: 9.61 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19853226134568552		[learning rate: 0.00048914]
	Learning Rate: 0.000489143
	LOSS [training: 0.19853226134568552 | validation: 0.2935711389551408]
	TIME [epoch: 9.59 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21526170781018936		[learning rate: 0.00048799]
	Learning Rate: 0.000487989
	LOSS [training: 0.21526170781018936 | validation: 0.3048661223321116]
	TIME [epoch: 9.62 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25707197762280326		[learning rate: 0.00048684]
	Learning Rate: 0.000486838
	LOSS [training: 0.25707197762280326 | validation: 0.2968506777968188]
	TIME [epoch: 9.6 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20559779929750438		[learning rate: 0.00048569]
	Learning Rate: 0.00048569
	LOSS [training: 0.20559779929750438 | validation: 0.3352714715033997]
	TIME [epoch: 9.61 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23771816998569725		[learning rate: 0.00048454]
	Learning Rate: 0.000484544
	LOSS [training: 0.23771816998569725 | validation: 0.38827517487813157]
	TIME [epoch: 9.6 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2554244372877952		[learning rate: 0.0004834]
	Learning Rate: 0.000483401
	LOSS [training: 0.2554244372877952 | validation: 0.4354743516606719]
	TIME [epoch: 9.62 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23021621580646504		[learning rate: 0.00048226]
	Learning Rate: 0.000482261
	LOSS [training: 0.23021621580646504 | validation: 0.33581753090797717]
	TIME [epoch: 9.6 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.207747991465981		[learning rate: 0.00048112]
	Learning Rate: 0.000481123
	LOSS [training: 0.207747991465981 | validation: 0.337517385347276]
	TIME [epoch: 9.61 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21032771725090188		[learning rate: 0.00047999]
	Learning Rate: 0.000479988
	LOSS [training: 0.21032771725090188 | validation: 0.3405431313864722]
	TIME [epoch: 9.62 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2075694387844753		[learning rate: 0.00047886]
	Learning Rate: 0.000478856
	LOSS [training: 0.2075694387844753 | validation: 0.28148672679319214]
	TIME [epoch: 9.61 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19441354523459572		[learning rate: 0.00047773]
	Learning Rate: 0.000477727
	LOSS [training: 0.19441354523459572 | validation: 0.30897532518905113]
	TIME [epoch: 9.61 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22336328118803417		[learning rate: 0.0004766]
	Learning Rate: 0.0004766
	LOSS [training: 0.22336328118803417 | validation: 0.3204161607738603]
	TIME [epoch: 9.61 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22615856544278684		[learning rate: 0.00047548]
	Learning Rate: 0.000475476
	LOSS [training: 0.22615856544278684 | validation: 0.4156727155776517]
	TIME [epoch: 9.61 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31860308582143304		[learning rate: 0.00047435]
	Learning Rate: 0.000474354
	LOSS [training: 0.31860308582143304 | validation: 0.3695359212062271]
	TIME [epoch: 9.6 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3003506672237083		[learning rate: 0.00047324]
	Learning Rate: 0.000473235
	LOSS [training: 0.3003506672237083 | validation: 0.5986342834086916]
	TIME [epoch: 9.6 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30521670904349507		[learning rate: 0.00047212]
	Learning Rate: 0.000472119
	LOSS [training: 0.30521670904349507 | validation: 0.4005226430571605]
	TIME [epoch: 9.61 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22652866532253157		[learning rate: 0.00047101]
	Learning Rate: 0.000471005
	LOSS [training: 0.22652866532253157 | validation: 0.33175563810727066]
	TIME [epoch: 9.62 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21309261974824048		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.21309261974824048 | validation: 0.3077215251528327]
	TIME [epoch: 9.6 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25033916614044244		[learning rate: 0.00046879]
	Learning Rate: 0.000468786
	LOSS [training: 0.25033916614044244 | validation: 0.3560713834534732]
	TIME [epoch: 9.59 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28957173809875775		[learning rate: 0.00046768]
	Learning Rate: 0.00046768
	LOSS [training: 0.28957173809875775 | validation: 0.312266621547615]
	TIME [epoch: 9.61 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2288183859049941		[learning rate: 0.00046658]
	Learning Rate: 0.000466577
	LOSS [training: 0.2288183859049941 | validation: 0.29427897183354673]
	TIME [epoch: 9.62 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23888210114498315		[learning rate: 0.00046548]
	Learning Rate: 0.000465476
	LOSS [training: 0.23888210114498315 | validation: 0.41616498273911345]
	TIME [epoch: 9.6 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22916640169522468		[learning rate: 0.00046438]
	Learning Rate: 0.000464378
	LOSS [training: 0.22916640169522468 | validation: 0.36210936643787583]
	TIME [epoch: 9.6 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2364666401192868		[learning rate: 0.00046328]
	Learning Rate: 0.000463283
	LOSS [training: 0.2364666401192868 | validation: 0.3830665876076793]
	TIME [epoch: 9.63 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21874604980650747		[learning rate: 0.00046219]
	Learning Rate: 0.00046219
	LOSS [training: 0.21874604980650747 | validation: 0.338415546380657]
	TIME [epoch: 9.61 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22968704607653273		[learning rate: 0.0004611]
	Learning Rate: 0.0004611
	LOSS [training: 0.22968704607653273 | validation: 0.3662057088930941]
	TIME [epoch: 9.61 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22449581538136282		[learning rate: 0.00046001]
	Learning Rate: 0.000460012
	LOSS [training: 0.22449581538136282 | validation: 0.33611364334245225]
	TIME [epoch: 9.61 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21576711974479545		[learning rate: 0.00045893]
	Learning Rate: 0.000458927
	LOSS [training: 0.21576711974479545 | validation: 0.3749929464688367]
	TIME [epoch: 9.62 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23112269095550642		[learning rate: 0.00045784]
	Learning Rate: 0.000457844
	LOSS [training: 0.23112269095550642 | validation: 0.35350649068169987]
	TIME [epoch: 9.6 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2355221842053447		[learning rate: 0.00045676]
	Learning Rate: 0.000456764
	LOSS [training: 0.2355221842053447 | validation: 0.362679945615254]
	TIME [epoch: 9.61 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21730849816409575		[learning rate: 0.00045569]
	Learning Rate: 0.000455687
	LOSS [training: 0.21730849816409575 | validation: 0.30399811007458305]
	TIME [epoch: 9.59 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22443458072245187		[learning rate: 0.00045461]
	Learning Rate: 0.000454612
	LOSS [training: 0.22443458072245187 | validation: 0.37670500930424666]
	TIME [epoch: 9.63 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20542021355016607		[learning rate: 0.00045354]
	Learning Rate: 0.00045354
	LOSS [training: 0.20542021355016607 | validation: 0.2987091452373666]
	TIME [epoch: 9.59 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20617573599319824		[learning rate: 0.00045247]
	Learning Rate: 0.00045247
	LOSS [training: 0.20617573599319824 | validation: 0.31988402403576705]
	TIME [epoch: 9.6 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23741531607826422		[learning rate: 0.0004514]
	Learning Rate: 0.000451403
	LOSS [training: 0.23741531607826422 | validation: 0.3303757604696692]
	TIME [epoch: 9.6 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23327788360341795		[learning rate: 0.00045034]
	Learning Rate: 0.000450338
	LOSS [training: 0.23327788360341795 | validation: 0.29185379380145454]
	TIME [epoch: 9.62 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22874189492569333		[learning rate: 0.00044928]
	Learning Rate: 0.000449276
	LOSS [training: 0.22874189492569333 | validation: 0.2924265974385228]
	TIME [epoch: 9.61 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.223233162550141		[learning rate: 0.00044822]
	Learning Rate: 0.000448216
	LOSS [training: 0.223233162550141 | validation: 0.3570694604013101]
	TIME [epoch: 9.6 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23287367586053884		[learning rate: 0.00044716]
	Learning Rate: 0.000447159
	LOSS [training: 0.23287367586053884 | validation: 0.34207896689065936]
	TIME [epoch: 9.61 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24879437660735318		[learning rate: 0.0004461]
	Learning Rate: 0.000446104
	LOSS [training: 0.24879437660735318 | validation: 0.26278927423585374]
	TIME [epoch: 9.6 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23078193992837065		[learning rate: 0.00044505]
	Learning Rate: 0.000445051
	LOSS [training: 0.23078193992837065 | validation: 0.29244656345775377]
	TIME [epoch: 9.61 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23232382577587982		[learning rate: 0.000444]
	Learning Rate: 0.000444002
	LOSS [training: 0.23232382577587982 | validation: 0.32780863420092815]
	TIME [epoch: 9.61 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2138463570343176		[learning rate: 0.00044295]
	Learning Rate: 0.000442954
	LOSS [training: 0.2138463570343176 | validation: 0.27788115019684234]
	TIME [epoch: 9.62 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2704128882752091		[learning rate: 0.00044191]
	Learning Rate: 0.000441909
	LOSS [training: 0.2704128882752091 | validation: 0.266707201222952]
	TIME [epoch: 9.6 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24491102581159335		[learning rate: 0.00044087]
	Learning Rate: 0.000440867
	LOSS [training: 0.24491102581159335 | validation: 0.2887994862480461]
	TIME [epoch: 9.6 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2302179336929127		[learning rate: 0.00043983]
	Learning Rate: 0.000439827
	LOSS [training: 0.2302179336929127 | validation: 0.28103130357181655]
	TIME [epoch: 9.61 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24806545055357088		[learning rate: 0.00043879]
	Learning Rate: 0.00043879
	LOSS [training: 0.24806545055357088 | validation: 0.30029319296731866]
	TIME [epoch: 9.61 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2275021343669436		[learning rate: 0.00043775]
	Learning Rate: 0.000437755
	LOSS [training: 0.2275021343669436 | validation: 0.2895210908687885]
	TIME [epoch: 9.6 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2416334112083381		[learning rate: 0.00043672]
	Learning Rate: 0.000436722
	LOSS [training: 0.2416334112083381 | validation: 0.29581793272875867]
	TIME [epoch: 9.6 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24107881815972446		[learning rate: 0.00043569]
	Learning Rate: 0.000435692
	LOSS [training: 0.24107881815972446 | validation: 0.2854834348738386]
	TIME [epoch: 9.59 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23226054514483777		[learning rate: 0.00043466]
	Learning Rate: 0.000434664
	LOSS [training: 0.23226054514483777 | validation: 0.3265897866348365]
	TIME [epoch: 9.61 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23513106035762615		[learning rate: 0.00043364]
	Learning Rate: 0.000433639
	LOSS [training: 0.23513106035762615 | validation: 0.30846838805594873]
	TIME [epoch: 9.59 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23205852226906157		[learning rate: 0.00043262]
	Learning Rate: 0.000432616
	LOSS [training: 0.23205852226906157 | validation: 0.33088297133683]
	TIME [epoch: 9.58 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22018095070327903		[learning rate: 0.0004316]
	Learning Rate: 0.000431595
	LOSS [training: 0.22018095070327903 | validation: 0.32163549470002634]
	TIME [epoch: 9.6 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22741118186616155		[learning rate: 0.00043058]
	Learning Rate: 0.000430577
	LOSS [training: 0.22741118186616155 | validation: 0.302117266321114]
	TIME [epoch: 9.62 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21382292859804436		[learning rate: 0.00042956]
	Learning Rate: 0.000429562
	LOSS [training: 0.21382292859804436 | validation: 0.33963152829060206]
	TIME [epoch: 9.61 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21639793422414638		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.21639793422414638 | validation: 0.40092775449880436]
	TIME [epoch: 9.61 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2775220059031815		[learning rate: 0.00042754]
	Learning Rate: 0.000427538
	LOSS [training: 0.2775220059031815 | validation: 0.4467681064988468]
	TIME [epoch: 9.62 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28840657060887376		[learning rate: 0.00042653]
	Learning Rate: 0.000426529
	LOSS [training: 0.28840657060887376 | validation: 0.40626390541937296]
	TIME [epoch: 9.61 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28096700326308444		[learning rate: 0.00042552]
	Learning Rate: 0.000425523
	LOSS [training: 0.28096700326308444 | validation: 0.5086974876729699]
	TIME [epoch: 9.6 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2898500319073179		[learning rate: 0.00042452]
	Learning Rate: 0.000424519
	LOSS [training: 0.2898500319073179 | validation: 0.34241602963932644]
	TIME [epoch: 9.6 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2596378760835779		[learning rate: 0.00042352]
	Learning Rate: 0.000423518
	LOSS [training: 0.2596378760835779 | validation: 0.3466556020306446]
	TIME [epoch: 9.62 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23978913699675736		[learning rate: 0.00042252]
	Learning Rate: 0.000422519
	LOSS [training: 0.23978913699675736 | validation: 0.32665429940434804]
	TIME [epoch: 9.59 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21785052826264145		[learning rate: 0.00042152]
	Learning Rate: 0.000421522
	LOSS [training: 0.21785052826264145 | validation: 0.3659555795097218]
	TIME [epoch: 9.6 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21965906603183843		[learning rate: 0.00042053]
	Learning Rate: 0.000420528
	LOSS [training: 0.21965906603183843 | validation: 0.31706794621745743]
	TIME [epoch: 9.58 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22665190573295485		[learning rate: 0.00041954]
	Learning Rate: 0.000419536
	LOSS [training: 0.22665190573295485 | validation: 0.3204045681638272]
	TIME [epoch: 9.62 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2238442562563896		[learning rate: 0.00041855]
	Learning Rate: 0.000418546
	LOSS [training: 0.2238442562563896 | validation: 0.40116172536843137]
	TIME [epoch: 9.59 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21974409742509726		[learning rate: 0.00041756]
	Learning Rate: 0.000417559
	LOSS [training: 0.21974409742509726 | validation: 0.3142847659578149]
	TIME [epoch: 9.59 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19690806962721746		[learning rate: 0.00041657]
	Learning Rate: 0.000416574
	LOSS [training: 0.19690806962721746 | validation: 0.2829801521258996]
	TIME [epoch: 9.61 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19203581540662254		[learning rate: 0.00041559]
	Learning Rate: 0.000415591
	LOSS [training: 0.19203581540662254 | validation: 0.3166165767891487]
	TIME [epoch: 9.59 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21058980556502077		[learning rate: 0.00041461]
	Learning Rate: 0.000414611
	LOSS [training: 0.21058980556502077 | validation: 0.2952409066112939]
	TIME [epoch: 9.6 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1931728941262471		[learning rate: 0.00041363]
	Learning Rate: 0.000413633
	LOSS [training: 0.1931728941262471 | validation: 0.28497431433922304]
	TIME [epoch: 9.6 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20880170129643344		[learning rate: 0.00041266]
	Learning Rate: 0.000412657
	LOSS [training: 0.20880170129643344 | validation: 0.2983321652096047]
	TIME [epoch: 9.61 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2054412797699344		[learning rate: 0.00041168]
	Learning Rate: 0.000411684
	LOSS [training: 0.2054412797699344 | validation: 0.2739957701041233]
	TIME [epoch: 9.61 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1924651687600792		[learning rate: 0.00041071]
	Learning Rate: 0.000410713
	LOSS [training: 0.1924651687600792 | validation: 0.2805362372329732]
	TIME [epoch: 9.6 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21455298674560982		[learning rate: 0.00040974]
	Learning Rate: 0.000409744
	LOSS [training: 0.21455298674560982 | validation: 0.2774704809671276]
	TIME [epoch: 9.58 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18884244871849887		[learning rate: 0.00040878]
	Learning Rate: 0.000408778
	LOSS [training: 0.18884244871849887 | validation: 0.2887909050376831]
	TIME [epoch: 9.62 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23228232105201116		[learning rate: 0.00040781]
	Learning Rate: 0.000407813
	LOSS [training: 0.23228232105201116 | validation: 0.29028171391129637]
	TIME [epoch: 9.6 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26669006431086106		[learning rate: 0.00040685]
	Learning Rate: 0.000406851
	LOSS [training: 0.26669006431086106 | validation: 0.4001098755346614]
	TIME [epoch: 9.61 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26895248143259115		[learning rate: 0.00040589]
	Learning Rate: 0.000405892
	LOSS [training: 0.26895248143259115 | validation: 0.31737141859716517]
	TIME [epoch: 9.6 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1958300560048494		[learning rate: 0.00040493]
	Learning Rate: 0.000404934
	LOSS [training: 0.1958300560048494 | validation: 0.2844356769149043]
	TIME [epoch: 9.62 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19502243654651383		[learning rate: 0.00040398]
	Learning Rate: 0.000403979
	LOSS [training: 0.19502243654651383 | validation: 0.31516775451955525]
	TIME [epoch: 9.6 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23075346100328592		[learning rate: 0.00040303]
	Learning Rate: 0.000403026
	LOSS [training: 0.23075346100328592 | validation: 0.45413018457062027]
	TIME [epoch: 9.6 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2949817286759909		[learning rate: 0.00040208]
	Learning Rate: 0.000402076
	LOSS [training: 0.2949817286759909 | validation: 0.4687432779370459]
	TIME [epoch: 9.61 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2640008177287326		[learning rate: 0.00040113]
	Learning Rate: 0.000401127
	LOSS [training: 0.2640008177287326 | validation: 0.34333674124615005]
	TIME [epoch: 9.62 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21899246542150913		[learning rate: 0.00040018]
	Learning Rate: 0.000400181
	LOSS [training: 0.21899246542150913 | validation: 0.34672253948436377]
	TIME [epoch: 9.61 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2116575106892009		[learning rate: 0.00039924]
	Learning Rate: 0.000399237
	LOSS [training: 0.2116575106892009 | validation: 0.3177003250251726]
	TIME [epoch: 9.6 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22132440538872472		[learning rate: 0.0003983]
	Learning Rate: 0.000398295
	LOSS [training: 0.22132440538872472 | validation: 0.31950940904554037]
	TIME [epoch: 9.62 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21319863661389213		[learning rate: 0.00039736]
	Learning Rate: 0.000397356
	LOSS [training: 0.21319863661389213 | validation: 0.30593270710748177]
	TIME [epoch: 9.61 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23816889572435967		[learning rate: 0.00039642]
	Learning Rate: 0.000396418
	LOSS [training: 0.23816889572435967 | validation: 0.41685354924870716]
	TIME [epoch: 9.61 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28338777604203713		[learning rate: 0.00039548]
	Learning Rate: 0.000395483
	LOSS [training: 0.28338777604203713 | validation: 0.29007994708216644]
	TIME [epoch: 9.61 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21133308237094175		[learning rate: 0.00039455]
	Learning Rate: 0.00039455
	LOSS [training: 0.21133308237094175 | validation: 0.3420591540450016]
	TIME [epoch: 9.63 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20792387874084345		[learning rate: 0.00039362]
	Learning Rate: 0.00039362
	LOSS [training: 0.20792387874084345 | validation: 0.31147696666623154]
	TIME [epoch: 9.61 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20866518633662232		[learning rate: 0.00039269]
	Learning Rate: 0.000392691
	LOSS [training: 0.20866518633662232 | validation: 0.29583913714905963]
	TIME [epoch: 9.6 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20812031719619353		[learning rate: 0.00039177]
	Learning Rate: 0.000391765
	LOSS [training: 0.20812031719619353 | validation: 0.2814414183881967]
	TIME [epoch: 9.6 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20957721195685672		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.20957721195685672 | validation: 0.31942274820466743]
	TIME [epoch: 9.63 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20535479654794025		[learning rate: 0.00038992]
	Learning Rate: 0.000389919
	LOSS [training: 0.20535479654794025 | validation: 0.3157163910569051]
	TIME [epoch: 9.6 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2005361386754006		[learning rate: 0.000389]
	Learning Rate: 0.000388999
	LOSS [training: 0.2005361386754006 | validation: 0.31301227559562395]
	TIME [epoch: 9.58 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1930855406419257		[learning rate: 0.00038808]
	Learning Rate: 0.000388082
	LOSS [training: 0.1930855406419257 | validation: 0.2988639932372462]
	TIME [epoch: 9.6 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2070617817602603		[learning rate: 0.00038717]
	Learning Rate: 0.000387166
	LOSS [training: 0.2070617817602603 | validation: 0.29872887751638005]
	TIME [epoch: 9.61 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18536202873419935		[learning rate: 0.00038625]
	Learning Rate: 0.000386253
	LOSS [training: 0.18536202873419935 | validation: 0.2969154646014716]
	TIME [epoch: 9.6 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1964742560349222		[learning rate: 0.00038534]
	Learning Rate: 0.000385342
	LOSS [training: 0.1964742560349222 | validation: 0.27422563327586763]
	TIME [epoch: 9.61 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21220133564134783		[learning rate: 0.00038443]
	Learning Rate: 0.000384433
	LOSS [training: 0.21220133564134783 | validation: 0.2978479265936839]
	TIME [epoch: 9.62 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2270774940764099		[learning rate: 0.00038353]
	Learning Rate: 0.000383526
	LOSS [training: 0.2270774940764099 | validation: 0.27694369596674767]
	TIME [epoch: 9.62 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20199009078197516		[learning rate: 0.00038262]
	Learning Rate: 0.000382621
	LOSS [training: 0.20199009078197516 | validation: 0.33050127638031085]
	TIME [epoch: 9.59 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1913235207770339		[learning rate: 0.00038172]
	Learning Rate: 0.000381719
	LOSS [training: 0.1913235207770339 | validation: 0.3440509517193122]
	TIME [epoch: 9.59 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21922788140695498		[learning rate: 0.00038082]
	Learning Rate: 0.000380818
	LOSS [training: 0.21922788140695498 | validation: 0.3205634584180034]
	TIME [epoch: 9.61 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1906747980093469		[learning rate: 0.00037992]
	Learning Rate: 0.00037992
	LOSS [training: 0.1906747980093469 | validation: 0.3388348140975894]
	TIME [epoch: 9.61 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19526336895746094		[learning rate: 0.00037902]
	Learning Rate: 0.000379024
	LOSS [training: 0.19526336895746094 | validation: 0.3179882272134386]
	TIME [epoch: 9.59 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2005635387154831		[learning rate: 0.00037813]
	Learning Rate: 0.00037813
	LOSS [training: 0.2005635387154831 | validation: 0.3401725457584135]
	TIME [epoch: 9.61 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20175028194936032		[learning rate: 0.00037724]
	Learning Rate: 0.000377238
	LOSS [training: 0.20175028194936032 | validation: 0.3022440830159824]
	TIME [epoch: 9.62 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21358968821069363		[learning rate: 0.00037635]
	Learning Rate: 0.000376348
	LOSS [training: 0.21358968821069363 | validation: 0.2695685683447433]
	TIME [epoch: 9.61 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18735379835692642		[learning rate: 0.00037546]
	Learning Rate: 0.00037546
	LOSS [training: 0.18735379835692642 | validation: 0.28788004142764884]
	TIME [epoch: 9.6 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19147323818938833		[learning rate: 0.00037457]
	Learning Rate: 0.000374575
	LOSS [training: 0.19147323818938833 | validation: 0.27661280438727376]
	TIME [epoch: 9.62 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1852415834416026		[learning rate: 0.00037369]
	Learning Rate: 0.000373691
	LOSS [training: 0.1852415834416026 | validation: 0.332868942346955]
	TIME [epoch: 9.61 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2084084707046526		[learning rate: 0.00037281]
	Learning Rate: 0.00037281
	LOSS [training: 0.2084084707046526 | validation: 0.3213805151633089]
	TIME [epoch: 9.61 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2098736895289081		[learning rate: 0.00037193]
	Learning Rate: 0.00037193
	LOSS [training: 0.2098736895289081 | validation: 0.30673534978535505]
	TIME [epoch: 9.59 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2006643829640602		[learning rate: 0.00037105]
	Learning Rate: 0.000371053
	LOSS [training: 0.2006643829640602 | validation: 0.3182244424291256]
	TIME [epoch: 9.63 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18964650635496647		[learning rate: 0.00037018]
	Learning Rate: 0.000370178
	LOSS [training: 0.18964650635496647 | validation: 0.3117390603674181]
	TIME [epoch: 9.62 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2227285476108022		[learning rate: 0.0003693]
	Learning Rate: 0.000369305
	LOSS [training: 0.2227285476108022 | validation: 0.33243545110144695]
	TIME [epoch: 9.61 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22379642824625776		[learning rate: 0.00036843]
	Learning Rate: 0.000368433
	LOSS [training: 0.22379642824625776 | validation: 0.4085298750611379]
	TIME [epoch: 9.6 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.254562260305241		[learning rate: 0.00036756]
	Learning Rate: 0.000367564
	LOSS [training: 0.254562260305241 | validation: 0.3997633039349488]
	TIME [epoch: 9.62 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2171228770974596		[learning rate: 0.0003667]
	Learning Rate: 0.000366697
	LOSS [training: 0.2171228770974596 | validation: 0.33173154379711456]
	TIME [epoch: 9.6 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.196917111484922		[learning rate: 0.00036583]
	Learning Rate: 0.000365832
	LOSS [training: 0.196917111484922 | validation: 0.33028683429906514]
	TIME [epoch: 9.6 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20623513203672647		[learning rate: 0.00036497]
	Learning Rate: 0.000364969
	LOSS [training: 0.20623513203672647 | validation: 0.3428135792255607]
	TIME [epoch: 9.59 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19405777451298145		[learning rate: 0.00036411]
	Learning Rate: 0.000364108
	LOSS [training: 0.19405777451298145 | validation: 0.33740443143049065]
	TIME [epoch: 9.62 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20550045089833358		[learning rate: 0.00036325]
	Learning Rate: 0.00036325
	LOSS [training: 0.20550045089833358 | validation: 0.3155123428916072]
	TIME [epoch: 9.6 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1953043888089593		[learning rate: 0.00036239]
	Learning Rate: 0.000362393
	LOSS [training: 0.1953043888089593 | validation: 0.29702918576861315]
	TIME [epoch: 9.6 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20278649628212758		[learning rate: 0.00036154]
	Learning Rate: 0.000361538
	LOSS [training: 0.20278649628212758 | validation: 0.2889101772354808]
	TIME [epoch: 9.6 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2223509516685341		[learning rate: 0.00036069]
	Learning Rate: 0.000360685
	LOSS [training: 0.2223509516685341 | validation: 0.3444556687340585]
	TIME [epoch: 9.62 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2173088945896436		[learning rate: 0.00035983]
	Learning Rate: 0.000359834
	LOSS [training: 0.2173088945896436 | validation: 0.3109840168993774]
	TIME [epoch: 9.61 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19962704736665574		[learning rate: 0.00035899]
	Learning Rate: 0.000358986
	LOSS [training: 0.19962704736665574 | validation: 0.3058081816645666]
	TIME [epoch: 9.59 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2049853661373561		[learning rate: 0.00035814]
	Learning Rate: 0.000358139
	LOSS [training: 0.2049853661373561 | validation: 0.30304094304622176]
	TIME [epoch: 9.61 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20851029449159678		[learning rate: 0.00035729]
	Learning Rate: 0.000357294
	LOSS [training: 0.20851029449159678 | validation: 0.30353254914032585]
	TIME [epoch: 9.61 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21227271124505576		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.21227271124505576 | validation: 0.2803467701859168]
	TIME [epoch: 9.59 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20489009039733533		[learning rate: 0.00035561]
	Learning Rate: 0.00035561
	LOSS [training: 0.20489009039733533 | validation: 0.33110401571933346]
	TIME [epoch: 9.61 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24721100604731347		[learning rate: 0.00035477]
	Learning Rate: 0.000354771
	LOSS [training: 0.24721100604731347 | validation: 0.34655539961045084]
	TIME [epoch: 9.62 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22977900820356564		[learning rate: 0.00035393]
	Learning Rate: 0.000353935
	LOSS [training: 0.22977900820356564 | validation: 0.3619948748217369]
	TIME [epoch: 9.61 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19926030623477273		[learning rate: 0.0003531]
	Learning Rate: 0.0003531
	LOSS [training: 0.19926030623477273 | validation: 0.2961876205608741]
	TIME [epoch: 9.6 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21822700663591038		[learning rate: 0.00035227]
	Learning Rate: 0.000352267
	LOSS [training: 0.21822700663591038 | validation: 0.3261614966953822]
	TIME [epoch: 9.61 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22363223842787056		[learning rate: 0.00035144]
	Learning Rate: 0.000351436
	LOSS [training: 0.22363223842787056 | validation: 0.3030614481137781]
	TIME [epoch: 9.61 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2126211631310262		[learning rate: 0.00035061]
	Learning Rate: 0.000350607
	LOSS [training: 0.2126211631310262 | validation: 0.3194780777906494]
	TIME [epoch: 9.61 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22566819912394093		[learning rate: 0.00034978]
	Learning Rate: 0.00034978
	LOSS [training: 0.22566819912394093 | validation: 0.3214204168730774]
	TIME [epoch: 9.59 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20088486780117581		[learning rate: 0.00034895]
	Learning Rate: 0.000348955
	LOSS [training: 0.20088486780117581 | validation: 0.3038949506215376]
	TIME [epoch: 9.61 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2136465343899542		[learning rate: 0.00034813]
	Learning Rate: 0.000348132
	LOSS [training: 0.2136465343899542 | validation: 0.32394757935166896]
	TIME [epoch: 9.61 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1882736644429276		[learning rate: 0.00034731]
	Learning Rate: 0.000347311
	LOSS [training: 0.1882736644429276 | validation: 0.297617654687921]
	TIME [epoch: 9.61 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19453403925369067		[learning rate: 0.00034649]
	Learning Rate: 0.000346491
	LOSS [training: 0.19453403925369067 | validation: 0.31550567629575627]
	TIME [epoch: 9.58 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19264564064399242		[learning rate: 0.00034567]
	Learning Rate: 0.000345674
	LOSS [training: 0.19264564064399242 | validation: 0.30932136714781544]
	TIME [epoch: 9.62 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2088827498663126		[learning rate: 0.00034486]
	Learning Rate: 0.000344859
	LOSS [training: 0.2088827498663126 | validation: 0.3055712262086611]
	TIME [epoch: 9.6 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1893553583608314		[learning rate: 0.00034405]
	Learning Rate: 0.000344045
	LOSS [training: 0.1893553583608314 | validation: 0.2972470770396118]
	TIME [epoch: 9.6 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19953541446747936		[learning rate: 0.00034323]
	Learning Rate: 0.000343233
	LOSS [training: 0.19953541446747936 | validation: 0.2812730889334004]
	TIME [epoch: 9.59 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19920235201552466		[learning rate: 0.00034242]
	Learning Rate: 0.000342424
	LOSS [training: 0.19920235201552466 | validation: 0.3487432076850929]
	TIME [epoch: 9.63 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2204711407836905		[learning rate: 0.00034162]
	Learning Rate: 0.000341616
	LOSS [training: 0.2204711407836905 | validation: 0.2993854371348554]
	TIME [epoch: 9.59 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18239567458850697		[learning rate: 0.00034081]
	Learning Rate: 0.00034081
	LOSS [training: 0.18239567458850697 | validation: 0.3092123033168133]
	TIME [epoch: 9.59 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1984038539259902		[learning rate: 0.00034001]
	Learning Rate: 0.000340006
	LOSS [training: 0.1984038539259902 | validation: 0.29382284826198507]
	TIME [epoch: 9.6 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1991576489529435		[learning rate: 0.0003392]
	Learning Rate: 0.000339204
	LOSS [training: 0.1991576489529435 | validation: 0.30460625431220456]
	TIME [epoch: 9.63 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20216771239782885		[learning rate: 0.0003384]
	Learning Rate: 0.000338404
	LOSS [training: 0.20216771239782885 | validation: 0.2966690241052916]
	TIME [epoch: 9.6 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19559773690556312		[learning rate: 0.00033761]
	Learning Rate: 0.000337606
	LOSS [training: 0.19559773690556312 | validation: 0.2960320499403888]
	TIME [epoch: 9.6 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2052759032006155		[learning rate: 0.00033681]
	Learning Rate: 0.00033681
	LOSS [training: 0.2052759032006155 | validation: 0.28332448296770935]
	TIME [epoch: 9.61 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18970138240815665		[learning rate: 0.00033602]
	Learning Rate: 0.000336015
	LOSS [training: 0.18970138240815665 | validation: 0.30272978296473196]
	TIME [epoch: 9.61 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18124966020506975		[learning rate: 0.00033522]
	Learning Rate: 0.000335223
	LOSS [training: 0.18124966020506975 | validation: 0.28533624229863846]
	TIME [epoch: 9.6 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18396846211063472		[learning rate: 0.00033443]
	Learning Rate: 0.000334432
	LOSS [training: 0.18396846211063472 | validation: 0.2959881201698024]
	TIME [epoch: 9.6 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21877091883277583		[learning rate: 0.00033364]
	Learning Rate: 0.000333643
	LOSS [training: 0.21877091883277583 | validation: 0.3973877796238075]
	TIME [epoch: 9.64 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2935235662020075		[learning rate: 0.00033286]
	Learning Rate: 0.000332856
	LOSS [training: 0.2935235662020075 | validation: 0.40125040101762866]
	TIME [epoch: 9.6 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26771316342589546		[learning rate: 0.00033207]
	Learning Rate: 0.000332071
	LOSS [training: 0.26771316342589546 | validation: 0.4120139545313032]
	TIME [epoch: 9.59 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24377414475537823		[learning rate: 0.00033129]
	Learning Rate: 0.000331288
	LOSS [training: 0.24377414475537823 | validation: 0.32733116152943936]
	TIME [epoch: 9.6 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1946537338478		[learning rate: 0.00033051]
	Learning Rate: 0.000330506
	LOSS [training: 0.1946537338478 | validation: 0.385076882966303]
	TIME [epoch: 9.61 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23012387170494714		[learning rate: 0.00032973]
	Learning Rate: 0.000329726
	LOSS [training: 0.23012387170494714 | validation: 0.38274255648289235]
	TIME [epoch: 9.62 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2141739849038622		[learning rate: 0.00032895]
	Learning Rate: 0.000328949
	LOSS [training: 0.2141739849038622 | validation: 0.3457675147482564]
	TIME [epoch: 9.58 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18890438953732913		[learning rate: 0.00032817]
	Learning Rate: 0.000328173
	LOSS [training: 0.18890438953732913 | validation: 0.3047794012900272]
	TIME [epoch: 9.62 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18930741235110574		[learning rate: 0.0003274]
	Learning Rate: 0.000327399
	LOSS [training: 0.18930741235110574 | validation: 0.298961888907427]
	TIME [epoch: 9.62 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17130994012521972		[learning rate: 0.00032663]
	Learning Rate: 0.000326626
	LOSS [training: 0.17130994012521972 | validation: 0.2933622360903535]
	TIME [epoch: 9.61 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18178804884031136		[learning rate: 0.00032586]
	Learning Rate: 0.000325856
	LOSS [training: 0.18178804884031136 | validation: 0.2909128095441087]
	TIME [epoch: 9.59 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18855610191885103		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.18855610191885103 | validation: 0.2631770276005628]
	TIME [epoch: 9.62 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19031053040482507		[learning rate: 0.00032432]
	Learning Rate: 0.00032432
	LOSS [training: 0.19031053040482507 | validation: 0.2917446943961081]
	TIME [epoch: 9.61 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.189119196092323		[learning rate: 0.00032356]
	Learning Rate: 0.000323555
	LOSS [training: 0.189119196092323 | validation: 0.2566017129924869]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1503.pth
	Model improved!!!
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17572270221088843		[learning rate: 0.00032279]
	Learning Rate: 0.000322792
	LOSS [training: 0.17572270221088843 | validation: 0.28703595621722955]
	TIME [epoch: 9.58 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1796939981102499		[learning rate: 0.00032203]
	Learning Rate: 0.000322031
	LOSS [training: 0.1796939981102499 | validation: 0.2988268977307782]
	TIME [epoch: 9.6 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19217753905716134		[learning rate: 0.00032127]
	Learning Rate: 0.000321271
	LOSS [training: 0.19217753905716134 | validation: 0.28344393355602004]
	TIME [epoch: 9.59 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19174297048671096		[learning rate: 0.00032051]
	Learning Rate: 0.000320513
	LOSS [training: 0.19174297048671096 | validation: 0.2777829928570384]
	TIME [epoch: 9.61 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18312462855488337		[learning rate: 0.00031976]
	Learning Rate: 0.000319757
	LOSS [training: 0.18312462855488337 | validation: 0.2968697366829706]
	TIME [epoch: 9.59 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19689806386651781		[learning rate: 0.000319]
	Learning Rate: 0.000319003
	LOSS [training: 0.19689806386651781 | validation: 0.25183524301633375]
	TIME [epoch: 9.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1509.pth
	Model improved!!!
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18183187415180097		[learning rate: 0.00031825]
	Learning Rate: 0.000318251
	LOSS [training: 0.18183187415180097 | validation: 0.2655379364068296]
	TIME [epoch: 9.6 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1956468270146949		[learning rate: 0.0003175]
	Learning Rate: 0.0003175
	LOSS [training: 0.1956468270146949 | validation: 0.24994862220968408]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1511.pth
	Model improved!!!
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1976213493367805		[learning rate: 0.00031675]
	Learning Rate: 0.000316751
	LOSS [training: 0.1976213493367805 | validation: 0.25185008952570936]
	TIME [epoch: 9.6 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18304593107694767		[learning rate: 0.000316]
	Learning Rate: 0.000316004
	LOSS [training: 0.18304593107694767 | validation: 0.31629434838244874]
	TIME [epoch: 9.62 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18438250773021211		[learning rate: 0.00031526]
	Learning Rate: 0.000315258
	LOSS [training: 0.18438250773021211 | validation: 0.2933422558215017]
	TIME [epoch: 9.61 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1786754301078816		[learning rate: 0.00031451]
	Learning Rate: 0.000314515
	LOSS [training: 0.1786754301078816 | validation: 0.2981102361098119]
	TIME [epoch: 9.62 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20526643301733216		[learning rate: 0.00031377]
	Learning Rate: 0.000313773
	LOSS [training: 0.20526643301733216 | validation: 0.2831412711757427]
	TIME [epoch: 9.64 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20021192524037162		[learning rate: 0.00031303]
	Learning Rate: 0.000313033
	LOSS [training: 0.20021192524037162 | validation: 0.38495017639840245]
	TIME [epoch: 9.62 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2603782578173818		[learning rate: 0.00031229]
	Learning Rate: 0.000312294
	LOSS [training: 0.2603782578173818 | validation: 0.39138346483106007]
	TIME [epoch: 9.61 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2350576212905493		[learning rate: 0.00031156]
	Learning Rate: 0.000311558
	LOSS [training: 0.2350576212905493 | validation: 0.3908250866994213]
	TIME [epoch: 9.62 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23246110298301964		[learning rate: 0.00031082]
	Learning Rate: 0.000310823
	LOSS [training: 0.23246110298301964 | validation: 0.3745175906556164]
	TIME [epoch: 9.65 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21645990917654484		[learning rate: 0.00031009]
	Learning Rate: 0.00031009
	LOSS [training: 0.21645990917654484 | validation: 0.3160524542052649]
	TIME [epoch: 9.62 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19621912987098353		[learning rate: 0.00030936]
	Learning Rate: 0.000309358
	LOSS [training: 0.19621912987098353 | validation: 0.35969850366491524]
	TIME [epoch: 9.6 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20877914415992369		[learning rate: 0.00030863]
	Learning Rate: 0.000308628
	LOSS [training: 0.20877914415992369 | validation: 0.35293996153538304]
	TIME [epoch: 9.62 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21141639257222175		[learning rate: 0.0003079]
	Learning Rate: 0.0003079
	LOSS [training: 0.21141639257222175 | validation: 0.29659589242317785]
	TIME [epoch: 9.64 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19280959152195823		[learning rate: 0.00030717]
	Learning Rate: 0.000307174
	LOSS [training: 0.19280959152195823 | validation: 0.2820769890608413]
	TIME [epoch: 9.61 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2018260579155528		[learning rate: 0.00030645]
	Learning Rate: 0.00030645
	LOSS [training: 0.2018260579155528 | validation: 0.30347765285459205]
	TIME [epoch: 9.62 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1872206374253323		[learning rate: 0.00030573]
	Learning Rate: 0.000305727
	LOSS [training: 0.1872206374253323 | validation: 0.3183463185713982]
	TIME [epoch: 9.61 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19900272482060938		[learning rate: 0.00030501]
	Learning Rate: 0.000305005
	LOSS [training: 0.19900272482060938 | validation: 0.3185298007166577]
	TIME [epoch: 9.63 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21652281675512		[learning rate: 0.00030429]
	Learning Rate: 0.000304286
	LOSS [training: 0.21652281675512 | validation: 0.2973935599659859]
	TIME [epoch: 9.61 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1881498444256022		[learning rate: 0.00030357]
	Learning Rate: 0.000303568
	LOSS [training: 0.1881498444256022 | validation: 0.25134619472242875]
	TIME [epoch: 9.6 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18293737403364815		[learning rate: 0.00030285]
	Learning Rate: 0.000302852
	LOSS [training: 0.18293737403364815 | validation: 0.2628590878081664]
	TIME [epoch: 9.63 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18419267831058775		[learning rate: 0.00030214]
	Learning Rate: 0.000302138
	LOSS [training: 0.18419267831058775 | validation: 0.29207738193616617]
	TIME [epoch: 9.61 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2700084876575257		[learning rate: 0.00030143]
	Learning Rate: 0.000301425
	LOSS [training: 0.2700084876575257 | validation: 0.3457755426436129]
	TIME [epoch: 9.62 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29317496224751827		[learning rate: 0.00030071]
	Learning Rate: 0.000300714
	LOSS [training: 0.29317496224751827 | validation: 0.2627793462026445]
	TIME [epoch: 9.61 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1812229141379501		[learning rate: 0.0003]
	Learning Rate: 0.000300005
	LOSS [training: 0.1812229141379501 | validation: 0.2881738715795173]
	TIME [epoch: 9.64 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18281292517722117		[learning rate: 0.0002993]
	Learning Rate: 0.000299297
	LOSS [training: 0.18281292517722117 | validation: 0.28242164660274105]
	TIME [epoch: 9.62 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19407492129792187		[learning rate: 0.00029859]
	Learning Rate: 0.000298591
	LOSS [training: 0.19407492129792187 | validation: 0.26547765270280993]
	TIME [epoch: 9.62 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18798813515135876		[learning rate: 0.00029789]
	Learning Rate: 0.000297887
	LOSS [training: 0.18798813515135876 | validation: 0.30317347911027226]
	TIME [epoch: 9.62 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19140159975524293		[learning rate: 0.00029718]
	Learning Rate: 0.000297184
	LOSS [training: 0.19140159975524293 | validation: 0.26578282928359465]
	TIME [epoch: 9.65 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1799728617712014		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.1799728617712014 | validation: 0.2546557235354845]
	TIME [epoch: 9.61 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1743105591503505		[learning rate: 0.00029578]
	Learning Rate: 0.000295784
	LOSS [training: 0.1743105591503505 | validation: 0.2503675817981271]
	TIME [epoch: 9.62 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18297985603971917		[learning rate: 0.00029509]
	Learning Rate: 0.000295086
	LOSS [training: 0.18297985603971917 | validation: 0.27220635320135683]
	TIME [epoch: 9.6 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1783579288392921		[learning rate: 0.00029439]
	Learning Rate: 0.00029439
	LOSS [training: 0.1783579288392921 | validation: 0.28013273593792154]
	TIME [epoch: 9.65 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20418791848437318		[learning rate: 0.0002937]
	Learning Rate: 0.000293696
	LOSS [training: 0.20418791848437318 | validation: 0.25415849928598777]
	TIME [epoch: 9.61 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21257616316514363		[learning rate: 0.000293]
	Learning Rate: 0.000293003
	LOSS [training: 0.21257616316514363 | validation: 0.267307847420093]
	TIME [epoch: 9.62 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18904943964982995		[learning rate: 0.00029231]
	Learning Rate: 0.000292312
	LOSS [training: 0.18904943964982995 | validation: 0.24443263707322854]
	TIME [epoch: 9.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1546.pth
	Model improved!!!
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18076708726742013		[learning rate: 0.00029162]
	Learning Rate: 0.000291622
	LOSS [training: 0.18076708726742013 | validation: 0.2455379959811797]
	TIME [epoch: 9.64 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19207471183526886		[learning rate: 0.00029093]
	Learning Rate: 0.000290934
	LOSS [training: 0.19207471183526886 | validation: 0.26909489993781516]
	TIME [epoch: 9.62 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2015528169596828		[learning rate: 0.00029025]
	Learning Rate: 0.000290248
	LOSS [training: 0.2015528169596828 | validation: 0.25122569886286905]
	TIME [epoch: 9.63 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2009281769242885		[learning rate: 0.00028956]
	Learning Rate: 0.000289563
	LOSS [training: 0.2009281769242885 | validation: 0.31053756488509787]
	TIME [epoch: 9.63 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19207243247212477		[learning rate: 0.00028888]
	Learning Rate: 0.00028888
	LOSS [training: 0.19207243247212477 | validation: 0.26204184145538156]
	TIME [epoch: 9.62 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19155809747043953		[learning rate: 0.0002882]
	Learning Rate: 0.000288199
	LOSS [training: 0.19155809747043953 | validation: 0.2974741981650302]
	TIME [epoch: 9.6 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22079572465465694		[learning rate: 0.00028752]
	Learning Rate: 0.000287519
	LOSS [training: 0.22079572465465694 | validation: 0.3664538456679574]
	TIME [epoch: 9.62 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22754574408208478		[learning rate: 0.00028684]
	Learning Rate: 0.000286841
	LOSS [training: 0.22754574408208478 | validation: 0.3759565845160552]
	TIME [epoch: 9.63 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2245343419515327		[learning rate: 0.00028616]
	Learning Rate: 0.000286164
	LOSS [training: 0.2245343419515327 | validation: 0.33515371207879385]
	TIME [epoch: 9.62 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2207555481228792		[learning rate: 0.00028549]
	Learning Rate: 0.000285489
	LOSS [training: 0.2207555481228792 | validation: 0.3162805336255083]
	TIME [epoch: 9.59 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18770587912570763		[learning rate: 0.00028482]
	Learning Rate: 0.000284816
	LOSS [training: 0.18770587912570763 | validation: 0.2995684865108508]
	TIME [epoch: 9.61 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17827431595920862		[learning rate: 0.00028414]
	Learning Rate: 0.000284144
	LOSS [training: 0.17827431595920862 | validation: 0.2593067566841129]
	TIME [epoch: 9.64 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22569549939811778		[learning rate: 0.00028347]
	Learning Rate: 0.000283474
	LOSS [training: 0.22569549939811778 | validation: 0.2852674571247956]
	TIME [epoch: 9.6 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2301232020263367		[learning rate: 0.00028281]
	Learning Rate: 0.000282805
	LOSS [training: 0.2301232020263367 | validation: 0.2811744885649198]
	TIME [epoch: 9.62 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20859737761518984		[learning rate: 0.00028214]
	Learning Rate: 0.000282138
	LOSS [training: 0.20859737761518984 | validation: 0.2366451194160576]
	TIME [epoch: 9.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1561.pth
	Model improved!!!
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19900102473543066		[learning rate: 0.00028147]
	Learning Rate: 0.000281472
	LOSS [training: 0.19900102473543066 | validation: 0.2539500003429284]
	TIME [epoch: 9.61 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19107136796444463		[learning rate: 0.00028081]
	Learning Rate: 0.000280808
	LOSS [training: 0.19107136796444463 | validation: 0.278890045956506]
	TIME [epoch: 9.62 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20793772231656665		[learning rate: 0.00028015]
	Learning Rate: 0.000280146
	LOSS [training: 0.20793772231656665 | validation: 0.24547526059375052]
	TIME [epoch: 9.58 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2091959933242728		[learning rate: 0.00027949]
	Learning Rate: 0.000279485
	LOSS [training: 0.2091959933242728 | validation: 0.2637749526064791]
	TIME [epoch: 9.63 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2241669671419045		[learning rate: 0.00027883]
	Learning Rate: 0.000278826
	LOSS [training: 0.2241669671419045 | validation: 0.2659384555522832]
	TIME [epoch: 9.62 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20416371409157827		[learning rate: 0.00027817]
	Learning Rate: 0.000278168
	LOSS [training: 0.20416371409157827 | validation: 0.23442065419514876]
	TIME [epoch: 9.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1567.pth
	Model improved!!!
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18257328885524096		[learning rate: 0.00027751]
	Learning Rate: 0.000277512
	LOSS [training: 0.18257328885524096 | validation: 0.24542582228455984]
	TIME [epoch: 9.61 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17696699483155243		[learning rate: 0.00027686]
	Learning Rate: 0.000276858
	LOSS [training: 0.17696699483155243 | validation: 0.2621427624662261]
	TIME [epoch: 9.63 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18221931526967966		[learning rate: 0.0002762]
	Learning Rate: 0.000276204
	LOSS [training: 0.18221931526967966 | validation: 0.2974975949807582]
	TIME [epoch: 9.6 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17844907116989348		[learning rate: 0.00027555]
	Learning Rate: 0.000275553
	LOSS [training: 0.17844907116989348 | validation: 0.26213269525512367]
	TIME [epoch: 9.62 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19147239079813877		[learning rate: 0.0002749]
	Learning Rate: 0.000274903
	LOSS [training: 0.19147239079813877 | validation: 0.25265997876788243]
	TIME [epoch: 9.63 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19300180743852405		[learning rate: 0.00027425]
	Learning Rate: 0.000274255
	LOSS [training: 0.19300180743852405 | validation: 0.23956736691801098]
	TIME [epoch: 9.61 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19060288474003156		[learning rate: 0.00027361]
	Learning Rate: 0.000273608
	LOSS [training: 0.19060288474003156 | validation: 0.26530446526263696]
	TIME [epoch: 9.62 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21815813335642242		[learning rate: 0.00027296]
	Learning Rate: 0.000272962
	LOSS [training: 0.21815813335642242 | validation: 0.26430347549029387]
	TIME [epoch: 9.6 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19044682085916423		[learning rate: 0.00027232]
	Learning Rate: 0.000272318
	LOSS [training: 0.19044682085916423 | validation: 0.26192469192288187]
	TIME [epoch: 9.62 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19505445355122836		[learning rate: 0.00027168]
	Learning Rate: 0.000271676
	LOSS [training: 0.19505445355122836 | validation: 0.2446182759829794]
	TIME [epoch: 9.59 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1888037307641886		[learning rate: 0.00027104]
	Learning Rate: 0.000271035
	LOSS [training: 0.1888037307641886 | validation: 0.26641743220643094]
	TIME [epoch: 9.61 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1974601168776506		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.1974601168776506 | validation: 0.25302298600327716]
	TIME [epoch: 9.61 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20795488520331337		[learning rate: 0.00026976]
	Learning Rate: 0.000269758
	LOSS [training: 0.20795488520331337 | validation: 0.2585102260610938]
	TIME [epoch: 9.64 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20506004219097135		[learning rate: 0.00026912]
	Learning Rate: 0.000269122
	LOSS [training: 0.20506004219097135 | validation: 0.2804183387308395]
	TIME [epoch: 9.62 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1989378528297626		[learning rate: 0.00026849]
	Learning Rate: 0.000268487
	LOSS [training: 0.1989378528297626 | validation: 0.2803738923285169]
	TIME [epoch: 9.6 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19528515071523633		[learning rate: 0.00026785]
	Learning Rate: 0.000267854
	LOSS [training: 0.19528515071523633 | validation: 0.25227991466517324]
	TIME [epoch: 9.62 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1888663043802668		[learning rate: 0.00026722]
	Learning Rate: 0.000267222
	LOSS [training: 0.1888663043802668 | validation: 0.2757212807068748]
	TIME [epoch: 9.63 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1727475779428432		[learning rate: 0.00026659]
	Learning Rate: 0.000266591
	LOSS [training: 0.1727475779428432 | validation: 0.27658989796442474]
	TIME [epoch: 9.6 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19686645349694137		[learning rate: 0.00026596]
	Learning Rate: 0.000265963
	LOSS [training: 0.19686645349694137 | validation: 0.2974768010074996]
	TIME [epoch: 9.61 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19925308001236447		[learning rate: 0.00026534]
	Learning Rate: 0.000265335
	LOSS [training: 0.19925308001236447 | validation: 0.2949535162328585]
	TIME [epoch: 9.61 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17548825137597782		[learning rate: 0.00026471]
	Learning Rate: 0.000264709
	LOSS [training: 0.17548825137597782 | validation: 0.2687982256603524]
	TIME [epoch: 9.62 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18707917534109253		[learning rate: 0.00026408]
	Learning Rate: 0.000264085
	LOSS [training: 0.18707917534109253 | validation: 0.2521761658890592]
	TIME [epoch: 9.6 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19189941019192958		[learning rate: 0.00026346]
	Learning Rate: 0.000263462
	LOSS [training: 0.19189941019192958 | validation: 0.26220887952503746]
	TIME [epoch: 9.61 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1724121512032191		[learning rate: 0.00026284]
	Learning Rate: 0.00026284
	LOSS [training: 0.1724121512032191 | validation: 0.23474143661294705]
	TIME [epoch: 9.62 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1727156088015486		[learning rate: 0.00026222]
	Learning Rate: 0.00026222
	LOSS [training: 0.1727156088015486 | validation: 0.2464863463411132]
	TIME [epoch: 9.62 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1934266054977008		[learning rate: 0.0002616]
	Learning Rate: 0.000261602
	LOSS [training: 0.1934266054977008 | validation: 0.2533020960137953]
	TIME [epoch: 9.59 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19946400463456257		[learning rate: 0.00026098]
	Learning Rate: 0.000260985
	LOSS [training: 0.19946400463456257 | validation: 0.2295124008753673]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1594.pth
	Model improved!!!
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18478207037331665		[learning rate: 0.00026037]
	Learning Rate: 0.000260369
	LOSS [training: 0.18478207037331665 | validation: 0.27817272839076057]
	TIME [epoch: 9.63 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.194513224917397		[learning rate: 0.00025976]
	Learning Rate: 0.000259755
	LOSS [training: 0.194513224917397 | validation: 0.2755839678809467]
	TIME [epoch: 9.61 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1916633564964815		[learning rate: 0.00025914]
	Learning Rate: 0.000259142
	LOSS [training: 0.1916633564964815 | validation: 0.24918304140005126]
	TIME [epoch: 9.62 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19939751581662327		[learning rate: 0.00025853]
	Learning Rate: 0.000258531
	LOSS [training: 0.19939751581662327 | validation: 0.31722311401970404]
	TIME [epoch: 9.59 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20239907013711447		[learning rate: 0.00025792]
	Learning Rate: 0.000257921
	LOSS [training: 0.20239907013711447 | validation: 0.2610644614838342]
	TIME [epoch: 9.62 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19215647472704606		[learning rate: 0.00025731]
	Learning Rate: 0.000257313
	LOSS [training: 0.19215647472704606 | validation: 0.25734335625926863]
	TIME [epoch: 9.62 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2183271863817689		[learning rate: 0.00025671]
	Learning Rate: 0.000256706
	LOSS [training: 0.2183271863817689 | validation: 0.2822417028521854]
	TIME [epoch: 9.6 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22388879963059213		[learning rate: 0.0002561]
	Learning Rate: 0.0002561
	LOSS [training: 0.22388879963059213 | validation: 0.27747262787111693]
	TIME [epoch: 9.64 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21617166086608633		[learning rate: 0.0002555]
	Learning Rate: 0.000255496
	LOSS [training: 0.21617166086608633 | validation: 0.2665249547991678]
	TIME [epoch: 9.62 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17765994089534715		[learning rate: 0.00025489]
	Learning Rate: 0.000254894
	LOSS [training: 0.17765994089534715 | validation: 0.25023049460696956]
	TIME [epoch: 9.61 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1714414950837504		[learning rate: 0.00025429]
	Learning Rate: 0.000254292
	LOSS [training: 0.1714414950837504 | validation: 0.2443671801428893]
	TIME [epoch: 9.6 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17837113635129404		[learning rate: 0.00025369]
	Learning Rate: 0.000253693
	LOSS [training: 0.17837113635129404 | validation: 0.2765343731410982]
	TIME [epoch: 9.64 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2073995196204804		[learning rate: 0.00025309]
	Learning Rate: 0.000253094
	LOSS [training: 0.2073995196204804 | validation: 0.2834049756232932]
	TIME [epoch: 9.61 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2144305396983758		[learning rate: 0.0002525]
	Learning Rate: 0.000252497
	LOSS [training: 0.2144305396983758 | validation: 0.33270662179005606]
	TIME [epoch: 9.62 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23157086356056525		[learning rate: 0.0002519]
	Learning Rate: 0.000251902
	LOSS [training: 0.23157086356056525 | validation: 0.3075554018961468]
	TIME [epoch: 9.62 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19093216856152945		[learning rate: 0.00025131]
	Learning Rate: 0.000251307
	LOSS [training: 0.19093216856152945 | validation: 0.28751958151317697]
	TIME [epoch: 9.64 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18386359817224987		[learning rate: 0.00025071]
	Learning Rate: 0.000250714
	LOSS [training: 0.18386359817224987 | validation: 0.27337199978930193]
	TIME [epoch: 9.59 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1720689359859962		[learning rate: 0.00025012]
	Learning Rate: 0.000250123
	LOSS [training: 0.1720689359859962 | validation: 0.2766652802042179]
	TIME [epoch: 9.6 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20133426982181618		[learning rate: 0.00024953]
	Learning Rate: 0.000249533
	LOSS [training: 0.20133426982181618 | validation: 0.2897799670324968]
	TIME [epoch: 9.6 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1803900644748893		[learning rate: 0.00024894]
	Learning Rate: 0.000248945
	LOSS [training: 0.1803900644748893 | validation: 0.2742867316272257]
	TIME [epoch: 9.64 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1812211604295786		[learning rate: 0.00024836]
	Learning Rate: 0.000248357
	LOSS [training: 0.1812211604295786 | validation: 0.3517101523426996]
	TIME [epoch: 9.6 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2127832998186804		[learning rate: 0.00024777]
	Learning Rate: 0.000247771
	LOSS [training: 0.2127832998186804 | validation: 0.28248135406574487]
	TIME [epoch: 9.61 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17556605336201464		[learning rate: 0.00024719]
	Learning Rate: 0.000247187
	LOSS [training: 0.17556605336201464 | validation: 0.28710539280449987]
	TIME [epoch: 9.62 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1730786202710018		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.1730786202710018 | validation: 0.30294250385878246]
	TIME [epoch: 9.62 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17506933834897542		[learning rate: 0.00024602]
	Learning Rate: 0.000246022
	LOSS [training: 0.17506933834897542 | validation: 0.3005194543842697]
	TIME [epoch: 9.61 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1886429969442335		[learning rate: 0.00024544]
	Learning Rate: 0.000245442
	LOSS [training: 0.1886429969442335 | validation: 0.3194091305568758]
	TIME [epoch: 9.62 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18752273210772594		[learning rate: 0.00024486]
	Learning Rate: 0.000244863
	LOSS [training: 0.18752273210772594 | validation: 0.28798793897016006]
	TIME [epoch: 9.63 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16799266268854107		[learning rate: 0.00024429]
	Learning Rate: 0.000244285
	LOSS [training: 0.16799266268854107 | validation: 0.2982252054382782]
	TIME [epoch: 9.61 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18875985097657624		[learning rate: 0.00024371]
	Learning Rate: 0.000243709
	LOSS [training: 0.18875985097657624 | validation: 0.33742047894280164]
	TIME [epoch: 9.6 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18985739693387557		[learning rate: 0.00024313]
	Learning Rate: 0.000243134
	LOSS [training: 0.18985739693387557 | validation: 0.31152417638419644]
	TIME [epoch: 9.6 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17904933037367116		[learning rate: 0.00024256]
	Learning Rate: 0.000242561
	LOSS [training: 0.17904933037367116 | validation: 0.3124628540185727]
	TIME [epoch: 9.62 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17147555683251242		[learning rate: 0.00024199]
	Learning Rate: 0.000241989
	LOSS [training: 0.17147555683251242 | validation: 0.2560279012021093]
	TIME [epoch: 9.62 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16994906923490766		[learning rate: 0.00024142]
	Learning Rate: 0.000241418
	LOSS [training: 0.16994906923490766 | validation: 0.26316237685624566]
	TIME [epoch: 9.6 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1772725373172047		[learning rate: 0.00024085]
	Learning Rate: 0.000240848
	LOSS [training: 0.1772725373172047 | validation: 0.2625738393266506]
	TIME [epoch: 9.61 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1675549084020312		[learning rate: 0.00024028]
	Learning Rate: 0.00024028
	LOSS [training: 0.1675549084020312 | validation: 0.2435876583210824]
	TIME [epoch: 9.61 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18538651012937954		[learning rate: 0.00023971]
	Learning Rate: 0.000239713
	LOSS [training: 0.18538651012937954 | validation: 0.2649192834538021]
	TIME [epoch: 9.62 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21861287869972362		[learning rate: 0.00023915]
	Learning Rate: 0.000239148
	LOSS [training: 0.21861287869972362 | validation: 0.25652624709943894]
	TIME [epoch: 9.6 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2436939097431543		[learning rate: 0.00023858]
	Learning Rate: 0.000238584
	LOSS [training: 0.2436939097431543 | validation: 0.25615263140514777]
	TIME [epoch: 9.61 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1960927448917107		[learning rate: 0.00023802]
	Learning Rate: 0.000238021
	LOSS [training: 0.1960927448917107 | validation: 0.25702497938320007]
	TIME [epoch: 9.61 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20396687925927354		[learning rate: 0.00023746]
	Learning Rate: 0.00023746
	LOSS [training: 0.20396687925927354 | validation: 0.2371137066889972]
	TIME [epoch: 9.61 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18079229576655234		[learning rate: 0.0002369]
	Learning Rate: 0.000236899
	LOSS [training: 0.18079229576655234 | validation: 0.2729702287280009]
	TIME [epoch: 9.61 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18135223173284998		[learning rate: 0.00023634]
	Learning Rate: 0.000236341
	LOSS [training: 0.18135223173284998 | validation: 0.25681014253449136]
	TIME [epoch: 9.63 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1795040143770605		[learning rate: 0.00023578]
	Learning Rate: 0.000235783
	LOSS [training: 0.1795040143770605 | validation: 0.2626637385970738]
	TIME [epoch: 9.61 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19298339913569487		[learning rate: 0.00023523]
	Learning Rate: 0.000235227
	LOSS [training: 0.19298339913569487 | validation: 0.2450755599153777]
	TIME [epoch: 9.6 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19322013643286506		[learning rate: 0.00023467]
	Learning Rate: 0.000234672
	LOSS [training: 0.19322013643286506 | validation: 0.254556463615596]
	TIME [epoch: 9.59 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19425671817991091		[learning rate: 0.00023412]
	Learning Rate: 0.000234119
	LOSS [training: 0.19425671817991091 | validation: 0.2577653248701147]
	TIME [epoch: 9.61 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18259290260094502		[learning rate: 0.00023357]
	Learning Rate: 0.000233566
	LOSS [training: 0.18259290260094502 | validation: 0.3262074988190161]
	TIME [epoch: 9.6 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25676814528697045		[learning rate: 0.00023302]
	Learning Rate: 0.000233015
	LOSS [training: 0.25676814528697045 | validation: 0.3735803698372567]
	TIME [epoch: 9.59 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2340842154551262		[learning rate: 0.00023247]
	Learning Rate: 0.000232466
	LOSS [training: 0.2340842154551262 | validation: 0.2785768008327712]
	TIME [epoch: 9.61 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17227833456684277		[learning rate: 0.00023192]
	Learning Rate: 0.000231917
	LOSS [training: 0.17227833456684277 | validation: 0.28118991364021345]
	TIME [epoch: 9.59 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1765976906733546		[learning rate: 0.00023137]
	Learning Rate: 0.00023137
	LOSS [training: 0.1765976906733546 | validation: 0.2917645678878956]
	TIME [epoch: 9.6 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20237678380296717		[learning rate: 0.00023082]
	Learning Rate: 0.000230825
	LOSS [training: 0.20237678380296717 | validation: 0.3317965401529823]
	TIME [epoch: 9.59 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18686940434213573		[learning rate: 0.00023028]
	Learning Rate: 0.00023028
	LOSS [training: 0.18686940434213573 | validation: 0.31718531423549495]
	TIME [epoch: 9.61 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16729998433606202		[learning rate: 0.00022974]
	Learning Rate: 0.000229737
	LOSS [training: 0.16729998433606202 | validation: 0.2471444675996576]
	TIME [epoch: 9.61 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16253494506308933		[learning rate: 0.00022919]
	Learning Rate: 0.000229195
	LOSS [training: 0.16253494506308933 | validation: 0.2839284940550623]
	TIME [epoch: 9.59 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18034463022596275		[learning rate: 0.00022865]
	Learning Rate: 0.000228654
	LOSS [training: 0.18034463022596275 | validation: 0.2919536052546133]
	TIME [epoch: 9.59 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17850788649007232		[learning rate: 0.00022811]
	Learning Rate: 0.000228115
	LOSS [training: 0.17850788649007232 | validation: 0.26531188851395815]
	TIME [epoch: 9.62 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17540344414514714		[learning rate: 0.00022758]
	Learning Rate: 0.000227577
	LOSS [training: 0.17540344414514714 | validation: 0.2706771187263561]
	TIME [epoch: 9.59 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17054305459674862		[learning rate: 0.00022704]
	Learning Rate: 0.00022704
	LOSS [training: 0.17054305459674862 | validation: 0.2624394704990413]
	TIME [epoch: 9.6 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19163236111288734		[learning rate: 0.0002265]
	Learning Rate: 0.000226505
	LOSS [training: 0.19163236111288734 | validation: 0.2794293169217943]
	TIME [epoch: 9.61 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18283758284860305		[learning rate: 0.00022597]
	Learning Rate: 0.00022597
	LOSS [training: 0.18283758284860305 | validation: 0.26408933908191456]
	TIME [epoch: 9.6 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17832233964569114		[learning rate: 0.00022544]
	Learning Rate: 0.000225437
	LOSS [training: 0.17832233964569114 | validation: 0.2372419188777426]
	TIME [epoch: 9.6 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1805988642757707		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.1805988642757707 | validation: 0.28952572407429616]
	TIME [epoch: 9.58 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17982668773799673		[learning rate: 0.00022437]
	Learning Rate: 0.000224375
	LOSS [training: 0.17982668773799673 | validation: 0.31458086996890744]
	TIME [epoch: 9.61 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19902737872988585		[learning rate: 0.00022385]
	Learning Rate: 0.000223846
	LOSS [training: 0.19902737872988585 | validation: 0.24096441470132512]
	TIME [epoch: 9.6 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16311083626431644		[learning rate: 0.00022332]
	Learning Rate: 0.000223318
	LOSS [training: 0.16311083626431644 | validation: 0.28074232944461885]
	TIME [epoch: 9.61 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17689020702365874		[learning rate: 0.00022279]
	Learning Rate: 0.000222791
	LOSS [training: 0.17689020702365874 | validation: 0.2507978341643722]
	TIME [epoch: 9.58 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17064740326878855		[learning rate: 0.00022227]
	Learning Rate: 0.000222265
	LOSS [training: 0.17064740326878855 | validation: 0.2599747003407766]
	TIME [epoch: 9.63 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1628832273786118		[learning rate: 0.00022174]
	Learning Rate: 0.000221741
	LOSS [training: 0.1628832273786118 | validation: 0.2598804267357625]
	TIME [epoch: 9.57 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16728541721088788		[learning rate: 0.00022122]
	Learning Rate: 0.000221218
	LOSS [training: 0.16728541721088788 | validation: 0.24550292513659439]
	TIME [epoch: 9.6 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1659924156755479		[learning rate: 0.0002207]
	Learning Rate: 0.000220696
	LOSS [training: 0.1659924156755479 | validation: 0.2416384277918215]
	TIME [epoch: 9.59 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16480763047044938		[learning rate: 0.00022018]
	Learning Rate: 0.000220176
	LOSS [training: 0.16480763047044938 | validation: 0.2642691973101926]
	TIME [epoch: 9.62 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17239764559204906		[learning rate: 0.00021966]
	Learning Rate: 0.000219656
	LOSS [training: 0.17239764559204906 | validation: 0.26641990352571526]
	TIME [epoch: 9.6 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1621605565345205		[learning rate: 0.00021914]
	Learning Rate: 0.000219138
	LOSS [training: 0.1621605565345205 | validation: 0.28963851990851913]
	TIME [epoch: 9.61 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16838564660298322		[learning rate: 0.00021862]
	Learning Rate: 0.000218621
	LOSS [training: 0.16838564660298322 | validation: 0.2939360677913831]
	TIME [epoch: 9.59 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17721552591671091		[learning rate: 0.00021811]
	Learning Rate: 0.000218106
	LOSS [training: 0.17721552591671091 | validation: 0.26916104465284507]
	TIME [epoch: 9.62 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17570309376465001		[learning rate: 0.00021759]
	Learning Rate: 0.000217591
	LOSS [training: 0.17570309376465001 | validation: 0.26167036193853466]
	TIME [epoch: 9.58 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15788675535761726		[learning rate: 0.00021708]
	Learning Rate: 0.000217078
	LOSS [training: 0.15788675535761726 | validation: 0.24125575529928805]
	TIME [epoch: 9.6 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16854581146827383		[learning rate: 0.00021657]
	Learning Rate: 0.000216566
	LOSS [training: 0.16854581146827383 | validation: 0.2531329682407489]
	TIME [epoch: 9.58 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16453147319815925		[learning rate: 0.00021605]
	Learning Rate: 0.000216055
	LOSS [training: 0.16453147319815925 | validation: 0.2713869380069005]
	TIME [epoch: 9.6 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1718740033017546		[learning rate: 0.00021555]
	Learning Rate: 0.000215545
	LOSS [training: 0.1718740033017546 | validation: 0.26173840742928123]
	TIME [epoch: 9.58 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16376679738129507		[learning rate: 0.00021504]
	Learning Rate: 0.000215037
	LOSS [training: 0.16376679738129507 | validation: 0.24797952602804318]
	TIME [epoch: 9.59 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16003856253627208		[learning rate: 0.00021453]
	Learning Rate: 0.00021453
	LOSS [training: 0.16003856253627208 | validation: 0.2756952273408753]
	TIME [epoch: 9.58 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16471314830065215		[learning rate: 0.00021402]
	Learning Rate: 0.000214024
	LOSS [training: 0.16471314830065215 | validation: 0.24413112135172127]
	TIME [epoch: 9.62 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17012198545838933		[learning rate: 0.00021352]
	Learning Rate: 0.000213519
	LOSS [training: 0.17012198545838933 | validation: 0.269746412649336]
	TIME [epoch: 9.6 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18996712151430875		[learning rate: 0.00021302]
	Learning Rate: 0.000213015
	LOSS [training: 0.18996712151430875 | validation: 0.3039426394002798]
	TIME [epoch: 9.6 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18352689224266563		[learning rate: 0.00021251]
	Learning Rate: 0.000212513
	LOSS [training: 0.18352689224266563 | validation: 0.2602159435594976]
	TIME [epoch: 9.61 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17332668303069407		[learning rate: 0.00021201]
	Learning Rate: 0.000212011
	LOSS [training: 0.17332668303069407 | validation: 0.28842973161467045]
	TIME [epoch: 9.6 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18107731967434998		[learning rate: 0.00021151]
	Learning Rate: 0.000211511
	LOSS [training: 0.18107731967434998 | validation: 0.24623042810293597]
	TIME [epoch: 9.59 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1618319409299326		[learning rate: 0.00021101]
	Learning Rate: 0.000211012
	LOSS [training: 0.1618319409299326 | validation: 0.2596534187266678]
	TIME [epoch: 9.6 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1701066582433559		[learning rate: 0.00021051]
	Learning Rate: 0.000210514
	LOSS [training: 0.1701066582433559 | validation: 0.25552202287685577]
	TIME [epoch: 9.62 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17837662535221402		[learning rate: 0.00021002]
	Learning Rate: 0.000210018
	LOSS [training: 0.17837662535221402 | validation: 0.22915278729260036]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1686.pth
	Model improved!!!
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1674235473335561		[learning rate: 0.00020952]
	Learning Rate: 0.000209523
	LOSS [training: 0.1674235473335561 | validation: 0.2272894985581697]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1687.pth
	Model improved!!!
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1663504974235864		[learning rate: 0.00020903]
	Learning Rate: 0.000209028
	LOSS [training: 0.1663504974235864 | validation: 0.2322797754240441]
	TIME [epoch: 9.61 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1765185569234295		[learning rate: 0.00020854]
	Learning Rate: 0.000208535
	LOSS [training: 0.1765185569234295 | validation: 0.2543288762498848]
	TIME [epoch: 9.61 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17551560974110053		[learning rate: 0.00020804]
	Learning Rate: 0.000208043
	LOSS [training: 0.17551560974110053 | validation: 0.26648738932972066]
	TIME [epoch: 9.6 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16464938424397713		[learning rate: 0.00020755]
	Learning Rate: 0.000207553
	LOSS [training: 0.16464938424397713 | validation: 0.24560430688844065]
	TIME [epoch: 9.61 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1914570976682123		[learning rate: 0.00020706]
	Learning Rate: 0.000207063
	LOSS [training: 0.1914570976682123 | validation: 0.24262364693017296]
	TIME [epoch: 9.62 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1898705453602603		[learning rate: 0.00020657]
	Learning Rate: 0.000206575
	LOSS [training: 0.1898705453602603 | validation: 0.244596544452928]
	TIME [epoch: 9.6 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1749577142803653		[learning rate: 0.00020609]
	Learning Rate: 0.000206087
	LOSS [training: 0.1749577142803653 | validation: 0.240835028641569]
	TIME [epoch: 9.61 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17274039675858754		[learning rate: 0.0002056]
	Learning Rate: 0.000205601
	LOSS [training: 0.17274039675858754 | validation: 0.23529011399132654]
	TIME [epoch: 9.59 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18153140527705158		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.18153140527705158 | validation: 0.27460179262496204]
	TIME [epoch: 9.61 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17637601983257817		[learning rate: 0.00020463]
	Learning Rate: 0.000204632
	LOSS [training: 0.17637601983257817 | validation: 0.2985713058690758]
	TIME [epoch: 9.6 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19351424155148278		[learning rate: 0.00020415]
	Learning Rate: 0.00020415
	LOSS [training: 0.19351424155148278 | validation: 0.33548442392148636]
	TIME [epoch: 9.6 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2162362086300654		[learning rate: 0.00020367]
	Learning Rate: 0.000203668
	LOSS [training: 0.2162362086300654 | validation: 0.3181182958910636]
	TIME [epoch: 9.58 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1873481230388012		[learning rate: 0.00020319]
	Learning Rate: 0.000203188
	LOSS [training: 0.1873481230388012 | validation: 0.25827922927374886]
	TIME [epoch: 9.61 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16619139214368078		[learning rate: 0.00020271]
	Learning Rate: 0.000202708
	LOSS [training: 0.16619139214368078 | validation: 0.24643190763084272]
	TIME [epoch: 9.6 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16707832421282304		[learning rate: 0.00020223]
	Learning Rate: 0.00020223
	LOSS [training: 0.16707832421282304 | validation: 0.23518757870657056]
	TIME [epoch: 9.61 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1784842174429691		[learning rate: 0.00020175]
	Learning Rate: 0.000201753
	LOSS [training: 0.1784842174429691 | validation: 0.2573430024094548]
	TIME [epoch: 9.59 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16392630630923327		[learning rate: 0.00020128]
	Learning Rate: 0.000201277
	LOSS [training: 0.16392630630923327 | validation: 0.25985476226079596]
	TIME [epoch: 9.61 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18256414984344665		[learning rate: 0.0002008]
	Learning Rate: 0.000200803
	LOSS [training: 0.18256414984344665 | validation: 0.25799203513669167]
	TIME [epoch: 9.6 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17447591620600647		[learning rate: 0.00020033]
	Learning Rate: 0.000200329
	LOSS [training: 0.17447591620600647 | validation: 0.23900028395406797]
	TIME [epoch: 9.6 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16269042095454467		[learning rate: 0.00019986]
	Learning Rate: 0.000199856
	LOSS [training: 0.16269042095454467 | validation: 0.24654907934962098]
	TIME [epoch: 9.6 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1543445593069786		[learning rate: 0.00019938]
	Learning Rate: 0.000199385
	LOSS [training: 0.1543445593069786 | validation: 0.24976224133753172]
	TIME [epoch: 9.61 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1589545976826847		[learning rate: 0.00019891]
	Learning Rate: 0.000198915
	LOSS [training: 0.1589545976826847 | validation: 0.24969053169960867]
	TIME [epoch: 9.61 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15486864963169206		[learning rate: 0.00019845]
	Learning Rate: 0.000198445
	LOSS [training: 0.15486864963169206 | validation: 0.2781296336803794]
	TIME [epoch: 9.59 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17391234414330978		[learning rate: 0.00019798]
	Learning Rate: 0.000197977
	LOSS [training: 0.17391234414330978 | validation: 0.27444272106239825]
	TIME [epoch: 9.62 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1683827327959067		[learning rate: 0.00019751]
	Learning Rate: 0.00019751
	LOSS [training: 0.1683827327959067 | validation: 0.27221667608351113]
	TIME [epoch: 9.59 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19420810768521005		[learning rate: 0.00019704]
	Learning Rate: 0.000197044
	LOSS [training: 0.19420810768521005 | validation: 0.3193501423787155]
	TIME [epoch: 9.6 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19707230210978083		[learning rate: 0.00019658]
	Learning Rate: 0.00019658
	LOSS [training: 0.19707230210978083 | validation: 0.2714905587174094]
	TIME [epoch: 9.61 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18929843750072664		[learning rate: 0.00019612]
	Learning Rate: 0.000196116
	LOSS [training: 0.18929843750072664 | validation: 0.27638462894629723]
	TIME [epoch: 9.62 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1702162172205261		[learning rate: 0.00019565]
	Learning Rate: 0.000195653
	LOSS [training: 0.1702162172205261 | validation: 0.2980501202627028]
	TIME [epoch: 9.6 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17889547504857567		[learning rate: 0.00019519]
	Learning Rate: 0.000195192
	LOSS [training: 0.17889547504857567 | validation: 0.27391957164801084]
	TIME [epoch: 9.61 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17151945959606946		[learning rate: 0.00019473]
	Learning Rate: 0.000194731
	LOSS [training: 0.17151945959606946 | validation: 0.29567072743924483]
	TIME [epoch: 9.6 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1812611211863609		[learning rate: 0.00019427]
	Learning Rate: 0.000194272
	LOSS [training: 0.1812611211863609 | validation: 0.2567418398557531]
	TIME [epoch: 9.61 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17242112558741138		[learning rate: 0.00019381]
	Learning Rate: 0.000193814
	LOSS [training: 0.17242112558741138 | validation: 0.2743138436658964]
	TIME [epoch: 9.59 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17334062680414303		[learning rate: 0.00019336]
	Learning Rate: 0.000193357
	LOSS [training: 0.17334062680414303 | validation: 0.29530026848039315]
	TIME [epoch: 9.59 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1712558418804512		[learning rate: 0.0001929]
	Learning Rate: 0.0001929
	LOSS [training: 0.1712558418804512 | validation: 0.24194019500412964]
	TIME [epoch: 9.61 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15866144871342558		[learning rate: 0.00019245]
	Learning Rate: 0.000192445
	LOSS [training: 0.15866144871342558 | validation: 0.26748649075694747]
	TIME [epoch: 9.6 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16590136036529315		[learning rate: 0.00019199]
	Learning Rate: 0.000191992
	LOSS [training: 0.16590136036529315 | validation: 0.28471012194877565]
	TIME [epoch: 9.59 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17863897478680724		[learning rate: 0.00019154]
	Learning Rate: 0.000191539
	LOSS [training: 0.17863897478680724 | validation: 0.30294726338285544]
	TIME [epoch: 9.58 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17026545619402594		[learning rate: 0.00019109]
	Learning Rate: 0.000191087
	LOSS [training: 0.17026545619402594 | validation: 0.27500824641507016]
	TIME [epoch: 9.62 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17087041012458157		[learning rate: 0.00019064]
	Learning Rate: 0.000190636
	LOSS [training: 0.17087041012458157 | validation: 0.2763725899867749]
	TIME [epoch: 9.59 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18928797043828835		[learning rate: 0.00019019]
	Learning Rate: 0.000190186
	LOSS [training: 0.18928797043828835 | validation: 0.29230055885747014]
	TIME [epoch: 9.59 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18107182299335464		[learning rate: 0.00018974]
	Learning Rate: 0.000189738
	LOSS [training: 0.18107182299335464 | validation: 0.2534271107568528]
	TIME [epoch: 9.6 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1770717272906693		[learning rate: 0.00018929]
	Learning Rate: 0.00018929
	LOSS [training: 0.1770717272906693 | validation: 0.24521200164992493]
	TIME [epoch: 9.62 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16562869493469928		[learning rate: 0.00018884]
	Learning Rate: 0.000188844
	LOSS [training: 0.16562869493469928 | validation: 0.23591270208418372]
	TIME [epoch: 9.6 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1727887746781592		[learning rate: 0.0001884]
	Learning Rate: 0.000188398
	LOSS [training: 0.1727887746781592 | validation: 0.2303886266267856]
	TIME [epoch: 9.59 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17741506450223551		[learning rate: 0.00018795]
	Learning Rate: 0.000187954
	LOSS [training: 0.17741506450223551 | validation: 0.2587835459473897]
	TIME [epoch: 9.6 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17739911702245276		[learning rate: 0.00018751]
	Learning Rate: 0.000187511
	LOSS [training: 0.17739911702245276 | validation: 0.23781336832093267]
	TIME [epoch: 9.62 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1717718284387118		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.1717718284387118 | validation: 0.2570202534500944]
	TIME [epoch: 9.62 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19989346520827062		[learning rate: 0.00018663]
	Learning Rate: 0.000186627
	LOSS [training: 0.19989346520827062 | validation: 0.23740569795314762]
	TIME [epoch: 9.6 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1697675644306486		[learning rate: 0.00018619]
	Learning Rate: 0.000186187
	LOSS [training: 0.1697675644306486 | validation: 0.2501339225725429]
	TIME [epoch: 9.6 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16779984131893994		[learning rate: 0.00018575]
	Learning Rate: 0.000185748
	LOSS [training: 0.16779984131893994 | validation: 0.2675403585995374]
	TIME [epoch: 9.6 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19426089672475846		[learning rate: 0.00018531]
	Learning Rate: 0.000185309
	LOSS [training: 0.19426089672475846 | validation: 0.2640728218068066]
	TIME [epoch: 9.59 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21255438086924766		[learning rate: 0.00018487]
	Learning Rate: 0.000184872
	LOSS [training: 0.21255438086924766 | validation: 0.2418228142591356]
	TIME [epoch: 9.6 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20571533110479118		[learning rate: 0.00018444]
	Learning Rate: 0.000184436
	LOSS [training: 0.20571533110479118 | validation: 0.26973561451304884]
	TIME [epoch: 9.62 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23419900511172526		[learning rate: 0.000184]
	Learning Rate: 0.000184001
	LOSS [training: 0.23419900511172526 | validation: 0.26960617270472365]
	TIME [epoch: 9.59 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23675373074745476		[learning rate: 0.00018357]
	Learning Rate: 0.000183567
	LOSS [training: 0.23675373074745476 | validation: 0.2583801222948627]
	TIME [epoch: 9.61 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21593384460562307		[learning rate: 0.00018313]
	Learning Rate: 0.000183134
	LOSS [training: 0.21593384460562307 | validation: 0.25093771996890224]
	TIME [epoch: 9.61 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21275035958770078		[learning rate: 0.0001827]
	Learning Rate: 0.000182702
	LOSS [training: 0.21275035958770078 | validation: 0.2554382907491935]
	TIME [epoch: 9.63 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19969736445036396		[learning rate: 0.00018227]
	Learning Rate: 0.000182271
	LOSS [training: 0.19969736445036396 | validation: 0.2401378212317195]
	TIME [epoch: 9.6 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17805298457613278		[learning rate: 0.00018184]
	Learning Rate: 0.000181841
	LOSS [training: 0.17805298457613278 | validation: 0.24489750593888993]
	TIME [epoch: 9.59 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17511426357474424		[learning rate: 0.00018141]
	Learning Rate: 0.000181412
	LOSS [training: 0.17511426357474424 | validation: 0.28833138168201816]
	TIME [epoch: 9.6 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19338346047604382		[learning rate: 0.00018098]
	Learning Rate: 0.000180984
	LOSS [training: 0.19338346047604382 | validation: 0.268853659687805]
	TIME [epoch: 9.61 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1713001405474091		[learning rate: 0.00018056]
	Learning Rate: 0.000180557
	LOSS [training: 0.1713001405474091 | validation: 0.24021144686562246]
	TIME [epoch: 9.6 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17563987181765903		[learning rate: 0.00018013]
	Learning Rate: 0.000180132
	LOSS [training: 0.17563987181765903 | validation: 0.2603838099210046]
	TIME [epoch: 9.6 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1726112115730507		[learning rate: 0.00017971]
	Learning Rate: 0.000179707
	LOSS [training: 0.1726112115730507 | validation: 0.2502683076135907]
	TIME [epoch: 9.62 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18900738740584205		[learning rate: 0.00017928]
	Learning Rate: 0.000179283
	LOSS [training: 0.18900738740584205 | validation: 0.26025218460312505]
	TIME [epoch: 9.61 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17877478854217183		[learning rate: 0.00017886]
	Learning Rate: 0.00017886
	LOSS [training: 0.17877478854217183 | validation: 0.2415469755179885]
	TIME [epoch: 9.6 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17827494634440344		[learning rate: 0.00017844]
	Learning Rate: 0.000178438
	LOSS [training: 0.17827494634440344 | validation: 0.2437747615456728]
	TIME [epoch: 9.61 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16823539051557626		[learning rate: 0.00017802]
	Learning Rate: 0.000178017
	LOSS [training: 0.16823539051557626 | validation: 0.23268452243526555]
	TIME [epoch: 9.61 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1751778769687645		[learning rate: 0.0001776]
	Learning Rate: 0.000177597
	LOSS [training: 0.1751778769687645 | validation: 0.26742993534080617]
	TIME [epoch: 9.61 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18082946071277253		[learning rate: 0.00017718]
	Learning Rate: 0.000177178
	LOSS [training: 0.18082946071277253 | validation: 0.2571102997970183]
	TIME [epoch: 9.6 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18917943318357938		[learning rate: 0.00017676]
	Learning Rate: 0.00017676
	LOSS [training: 0.18917943318357938 | validation: 0.2337130059336866]
	TIME [epoch: 9.59 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17610374167669735		[learning rate: 0.00017634]
	Learning Rate: 0.000176343
	LOSS [training: 0.17610374167669735 | validation: 0.23937057282022728]
	TIME [epoch: 9.61 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17556450034132068		[learning rate: 0.00017593]
	Learning Rate: 0.000175927
	LOSS [training: 0.17556450034132068 | validation: 0.23927022645211188]
	TIME [epoch: 9.6 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2059661840565247		[learning rate: 0.00017551]
	Learning Rate: 0.000175512
	LOSS [training: 0.2059661840565247 | validation: 0.24470617234839953]
	TIME [epoch: 9.61 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18005721146638654		[learning rate: 0.0001751]
	Learning Rate: 0.000175098
	LOSS [training: 0.18005721146638654 | validation: 0.26170778648785553]
	TIME [epoch: 9.6 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18800977394508497		[learning rate: 0.00017469]
	Learning Rate: 0.000174685
	LOSS [training: 0.18800977394508497 | validation: 0.25730171585601025]
	TIME [epoch: 9.62 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19339763888729947		[learning rate: 0.00017427]
	Learning Rate: 0.000174273
	LOSS [training: 0.19339763888729947 | validation: 0.28722272909973046]
	TIME [epoch: 9.59 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1955994554001635		[learning rate: 0.00017386]
	Learning Rate: 0.000173862
	LOSS [training: 0.1955994554001635 | validation: 0.3182692203867336]
	TIME [epoch: 9.6 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23777114846533517		[learning rate: 0.00017345]
	Learning Rate: 0.000173452
	LOSS [training: 0.23777114846533517 | validation: 0.2778149873212024]
	TIME [epoch: 9.61 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19195517645659768		[learning rate: 0.00017304]
	Learning Rate: 0.000173043
	LOSS [training: 0.19195517645659768 | validation: 0.2583248368114798]
	TIME [epoch: 9.61 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19112676546217905		[learning rate: 0.00017263]
	Learning Rate: 0.000172635
	LOSS [training: 0.19112676546217905 | validation: 0.264642341117516]
	TIME [epoch: 9.59 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17423098060831568		[learning rate: 0.00017223]
	Learning Rate: 0.000172228
	LOSS [training: 0.17423098060831568 | validation: 0.2588351647421695]
	TIME [epoch: 9.61 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16514274959457592		[learning rate: 0.00017182]
	Learning Rate: 0.000171821
	LOSS [training: 0.16514274959457592 | validation: 0.26329184860227606]
	TIME [epoch: 9.64 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16236375079603832		[learning rate: 0.00017142]
	Learning Rate: 0.000171416
	LOSS [training: 0.16236375079603832 | validation: 0.25363545480160044]
	TIME [epoch: 9.6 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1741591540881392		[learning rate: 0.00017101]
	Learning Rate: 0.000171012
	LOSS [training: 0.1741591540881392 | validation: 0.27795611204758397]
	TIME [epoch: 9.61 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1768681327905873		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.1768681327905873 | validation: 0.2728999714574468]
	TIME [epoch: 9.6 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17497956316275048		[learning rate: 0.00017021]
	Learning Rate: 0.000170206
	LOSS [training: 0.17497956316275048 | validation: 0.2808832675023176]
	TIME [epoch: 9.63 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1736159097788728		[learning rate: 0.0001698]
	Learning Rate: 0.000169804
	LOSS [training: 0.1736159097788728 | validation: 0.27359810702409654]
	TIME [epoch: 9.61 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18386206688434853		[learning rate: 0.0001694]
	Learning Rate: 0.000169404
	LOSS [training: 0.18386206688434853 | validation: 0.2652889684631294]
	TIME [epoch: 9.61 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15966480662317134		[learning rate: 0.000169]
	Learning Rate: 0.000169004
	LOSS [training: 0.15966480662317134 | validation: 0.246731522713221]
	TIME [epoch: 9.6 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16616654640814932		[learning rate: 0.00016861]
	Learning Rate: 0.000168606
	LOSS [training: 0.16616654640814932 | validation: 0.24100970714822845]
	TIME [epoch: 9.62 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1600209597128602		[learning rate: 0.00016821]
	Learning Rate: 0.000168208
	LOSS [training: 0.1600209597128602 | validation: 0.23154476885707248]
	TIME [epoch: 9.6 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1597282168668612		[learning rate: 0.00016781]
	Learning Rate: 0.000167811
	LOSS [training: 0.1597282168668612 | validation: 0.25866940579419334]
	TIME [epoch: 9.6 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16313482226433226		[learning rate: 0.00016742]
	Learning Rate: 0.000167415
	LOSS [training: 0.16313482226433226 | validation: 0.2636778824866]
	TIME [epoch: 9.62 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18185328620146585		[learning rate: 0.00016702]
	Learning Rate: 0.00016702
	LOSS [training: 0.18185328620146585 | validation: 0.25204891451079015]
	TIME [epoch: 9.62 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16862054288981437		[learning rate: 0.00016663]
	Learning Rate: 0.000166626
	LOSS [training: 0.16862054288981437 | validation: 0.2266465737363434]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1784.pth
	Model improved!!!
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16211256545944558		[learning rate: 0.00016623]
	Learning Rate: 0.000166233
	LOSS [training: 0.16211256545944558 | validation: 0.25366143824562143]
	TIME [epoch: 9.6 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15989547150097888		[learning rate: 0.00016584]
	Learning Rate: 0.000165841
	LOSS [training: 0.15989547150097888 | validation: 0.27414865906082575]
	TIME [epoch: 9.64 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17308745886826432		[learning rate: 0.00016545]
	Learning Rate: 0.00016545
	LOSS [training: 0.17308745886826432 | validation: 0.2820658865914223]
	TIME [epoch: 9.61 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15585439744237858		[learning rate: 0.00016506]
	Learning Rate: 0.00016506
	LOSS [training: 0.15585439744237858 | validation: 0.2543533908766127]
	TIME [epoch: 9.58 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16089579060772846		[learning rate: 0.00016467]
	Learning Rate: 0.00016467
	LOSS [training: 0.16089579060772846 | validation: 0.2769609177365392]
	TIME [epoch: 9.6 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1630062274986251		[learning rate: 0.00016428]
	Learning Rate: 0.000164282
	LOSS [training: 0.1630062274986251 | validation: 0.26611652616621984]
	TIME [epoch: 9.62 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16331348460826606		[learning rate: 0.00016389]
	Learning Rate: 0.000163894
	LOSS [training: 0.16331348460826606 | validation: 0.28767972855319834]
	TIME [epoch: 9.6 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17523329121789652		[learning rate: 0.00016351]
	Learning Rate: 0.000163508
	LOSS [training: 0.17523329121789652 | validation: 0.2542667496782678]
	TIME [epoch: 9.6 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15911458687416663		[learning rate: 0.00016312]
	Learning Rate: 0.000163122
	LOSS [training: 0.15911458687416663 | validation: 0.24341419885902227]
	TIME [epoch: 9.6 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1566217801960137		[learning rate: 0.00016274]
	Learning Rate: 0.000162737
	LOSS [training: 0.1566217801960137 | validation: 0.27075266450959384]
	TIME [epoch: 9.61 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16313836254011782		[learning rate: 0.00016235]
	Learning Rate: 0.000162353
	LOSS [training: 0.16313836254011782 | validation: 0.2882798926931567]
	TIME [epoch: 9.6 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.149978809462096		[learning rate: 0.00016197]
	Learning Rate: 0.00016197
	LOSS [training: 0.149978809462096 | validation: 0.24779669783530403]
	TIME [epoch: 9.6 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16039962262780175		[learning rate: 0.00016159]
	Learning Rate: 0.000161588
	LOSS [training: 0.16039962262780175 | validation: 0.28943520722304644]
	TIME [epoch: 9.59 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17023661846670862		[learning rate: 0.00016121]
	Learning Rate: 0.000161207
	LOSS [training: 0.17023661846670862 | validation: 0.2978304622613667]
	TIME [epoch: 9.61 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18032783523995763		[learning rate: 0.00016083]
	Learning Rate: 0.000160827
	LOSS [training: 0.18032783523995763 | validation: 0.2736669711878665]
	TIME [epoch: 9.59 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1728572139719729		[learning rate: 0.00016045]
	Learning Rate: 0.000160448
	LOSS [training: 0.1728572139719729 | validation: 0.2570299957423317]
	TIME [epoch: 9.6 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17747929413536284		[learning rate: 0.00016007]
	Learning Rate: 0.000160069
	LOSS [training: 0.17747929413536284 | validation: 0.24335900077655573]
	TIME [epoch: 9.63 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16150639584713403		[learning rate: 0.00015969]
	Learning Rate: 0.000159692
	LOSS [training: 0.16150639584713403 | validation: 0.2663713587928143]
	TIME [epoch: 9.6 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17403342635251756		[learning rate: 0.00015931]
	Learning Rate: 0.000159315
	LOSS [training: 0.17403342635251756 | validation: 0.29154073066017866]
	TIME [epoch: 9.58 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17414338944228422		[learning rate: 0.00015894]
	Learning Rate: 0.000158939
	LOSS [training: 0.17414338944228422 | validation: 0.30534906647496257]
	TIME [epoch: 9.6 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16734178437984998		[learning rate: 0.00015856]
	Learning Rate: 0.000158564
	LOSS [training: 0.16734178437984998 | validation: 0.2844033255640607]
	TIME [epoch: 9.61 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17327176793299523		[learning rate: 0.00015819]
	Learning Rate: 0.00015819
	LOSS [training: 0.17327176793299523 | validation: 0.28796529633712603]
	TIME [epoch: 9.6 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17325580019528886		[learning rate: 0.00015782]
	Learning Rate: 0.000157817
	LOSS [training: 0.17325580019528886 | validation: 0.27815895903007926]
	TIME [epoch: 9.6 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1712734165544928		[learning rate: 0.00015744]
	Learning Rate: 0.000157445
	LOSS [training: 0.1712734165544928 | validation: 0.28225100556651883]
	TIME [epoch: 9.61 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1743911208808332		[learning rate: 0.00015707]
	Learning Rate: 0.000157073
	LOSS [training: 0.1743911208808332 | validation: 0.2764346632851526]
	TIME [epoch: 9.63 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16299101920588233		[learning rate: 0.0001567]
	Learning Rate: 0.000156703
	LOSS [training: 0.16299101920588233 | validation: 0.2865058098507265]
	TIME [epoch: 9.6 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15064589955630273		[learning rate: 0.00015633]
	Learning Rate: 0.000156333
	LOSS [training: 0.15064589955630273 | validation: 0.2620036474089468]
	TIME [epoch: 9.62 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14886046677813897		[learning rate: 0.00015596]
	Learning Rate: 0.000155964
	LOSS [training: 0.14886046677813897 | validation: 0.26736049161757325]
	TIME [epoch: 9.61 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16286772201382185		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.16286772201382185 | validation: 0.25344155646767413]
	TIME [epoch: 9.61 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16075957966199145		[learning rate: 0.00015523]
	Learning Rate: 0.00015523
	LOSS [training: 0.16075957966199145 | validation: 0.2814604113609481]
	TIME [epoch: 9.57 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.160314422124338		[learning rate: 0.00015486]
	Learning Rate: 0.000154863
	LOSS [training: 0.160314422124338 | validation: 0.2906218620590318]
	TIME [epoch: 9.6 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17054919988541345		[learning rate: 0.0001545]
	Learning Rate: 0.000154498
	LOSS [training: 0.17054919988541345 | validation: 0.27307386258922334]
	TIME [epoch: 9.62 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17201171915286148		[learning rate: 0.00015413]
	Learning Rate: 0.000154134
	LOSS [training: 0.17201171915286148 | validation: 0.28221340858816396]
	TIME [epoch: 9.61 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16937578723219854		[learning rate: 0.00015377]
	Learning Rate: 0.00015377
	LOSS [training: 0.16937578723219854 | validation: 0.269912272375552]
	TIME [epoch: 9.6 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17336753609751646		[learning rate: 0.00015341]
	Learning Rate: 0.000153407
	LOSS [training: 0.17336753609751646 | validation: 0.2416990808180073]
	TIME [epoch: 9.6 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17177439085997875		[learning rate: 0.00015305]
	Learning Rate: 0.000153045
	LOSS [training: 0.17177439085997875 | validation: 0.245660985634855]
	TIME [epoch: 9.63 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16776804551616123		[learning rate: 0.00015268]
	Learning Rate: 0.000152684
	LOSS [training: 0.16776804551616123 | validation: 0.24640422305860546]
	TIME [epoch: 9.6 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16754258024643273		[learning rate: 0.00015232]
	Learning Rate: 0.000152324
	LOSS [training: 0.16754258024643273 | validation: 0.23708706654491274]
	TIME [epoch: 9.6 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15948744145881544		[learning rate: 0.00015196]
	Learning Rate: 0.000151965
	LOSS [training: 0.15948744145881544 | validation: 0.24969636373098297]
	TIME [epoch: 9.6 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15804709254678392		[learning rate: 0.00015161]
	Learning Rate: 0.000151607
	LOSS [training: 0.15804709254678392 | validation: 0.2407583321315265]
	TIME [epoch: 9.61 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16255140416525896		[learning rate: 0.00015125]
	Learning Rate: 0.000151249
	LOSS [training: 0.16255140416525896 | validation: 0.24362426635828932]
	TIME [epoch: 9.63 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1629175273856338		[learning rate: 0.00015089]
	Learning Rate: 0.000150892
	LOSS [training: 0.1629175273856338 | validation: 0.24853398883580813]
	TIME [epoch: 9.6 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16640015701805702		[learning rate: 0.00015054]
	Learning Rate: 0.000150536
	LOSS [training: 0.16640015701805702 | validation: 0.2622894182003895]
	TIME [epoch: 9.61 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16718360158912704		[learning rate: 0.00015018]
	Learning Rate: 0.000150181
	LOSS [training: 0.16718360158912704 | validation: 0.2500671469990691]
	TIME [epoch: 9.63 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1655929636400293		[learning rate: 0.00014983]
	Learning Rate: 0.000149827
	LOSS [training: 0.1655929636400293 | validation: 0.22869842099719154]
	TIME [epoch: 9.6 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16163941160933926		[learning rate: 0.00014947]
	Learning Rate: 0.000149473
	LOSS [training: 0.16163941160933926 | validation: 0.2324879701436778]
	TIME [epoch: 9.6 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1594928404921101		[learning rate: 0.00014912]
	Learning Rate: 0.000149121
	LOSS [training: 0.1594928404921101 | validation: 0.23211460144448537]
	TIME [epoch: 9.61 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15462071972109692		[learning rate: 0.00014877]
	Learning Rate: 0.000148769
	LOSS [training: 0.15462071972109692 | validation: 0.2246171444275225]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1832.pth
	Model improved!!!
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1643678177621465		[learning rate: 0.00014842]
	Learning Rate: 0.000148418
	LOSS [training: 0.1643678177621465 | validation: 0.236562155229658]
	TIME [epoch: 9.89 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15926528770735812		[learning rate: 0.00014807]
	Learning Rate: 0.000148068
	LOSS [training: 0.15926528770735812 | validation: 0.24923340356808182]
	TIME [epoch: 9.57 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17083410071714328		[learning rate: 0.00014772]
	Learning Rate: 0.000147719
	LOSS [training: 0.17083410071714328 | validation: 0.2388681150200598]
	TIME [epoch: 9.6 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16592909682184556		[learning rate: 0.00014737]
	Learning Rate: 0.00014737
	LOSS [training: 0.16592909682184556 | validation: 0.26656176734876014]
	TIME [epoch: 9.57 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1547399187482207		[learning rate: 0.00014702]
	Learning Rate: 0.000147023
	LOSS [training: 0.1547399187482207 | validation: 0.24997063503221506]
	TIME [epoch: 9.57 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16101728578815658		[learning rate: 0.00014668]
	Learning Rate: 0.000146676
	LOSS [training: 0.16101728578815658 | validation: 0.2435840893549804]
	TIME [epoch: 9.57 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15261523841068309		[learning rate: 0.00014633]
	Learning Rate: 0.00014633
	LOSS [training: 0.15261523841068309 | validation: 0.25438071133362816]
	TIME [epoch: 9.6 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14905926873012165		[learning rate: 0.00014598]
	Learning Rate: 0.000145985
	LOSS [training: 0.14905926873012165 | validation: 0.23728136848774106]
	TIME [epoch: 9.57 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15907025013762088		[learning rate: 0.00014564]
	Learning Rate: 0.00014564
	LOSS [training: 0.15907025013762088 | validation: 0.22467326326036655]
	TIME [epoch: 9.58 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16039116816658777		[learning rate: 0.0001453]
	Learning Rate: 0.000145297
	LOSS [training: 0.16039116816658777 | validation: 0.26198424005696]
	TIME [epoch: 9.58 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15287540694330284		[learning rate: 0.00014495]
	Learning Rate: 0.000144954
	LOSS [training: 0.15287540694330284 | validation: 0.24560912312348548]
	TIME [epoch: 9.59 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16340957279893387		[learning rate: 0.00014461]
	Learning Rate: 0.000144612
	LOSS [training: 0.16340957279893387 | validation: 0.24398375170065464]
	TIME [epoch: 9.57 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15823061781839104		[learning rate: 0.00014427]
	Learning Rate: 0.000144271
	LOSS [training: 0.15823061781839104 | validation: 0.23112541964820765]
	TIME [epoch: 9.57 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15992093870165586		[learning rate: 0.00014393]
	Learning Rate: 0.000143931
	LOSS [training: 0.15992093870165586 | validation: 0.2458172491389979]
	TIME [epoch: 9.59 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17255931106146877		[learning rate: 0.00014359]
	Learning Rate: 0.000143591
	LOSS [training: 0.17255931106146877 | validation: 0.24935725041403714]
	TIME [epoch: 9.58 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16564970028668713		[learning rate: 0.00014325]
	Learning Rate: 0.000143253
	LOSS [training: 0.16564970028668713 | validation: 0.2602240985827272]
	TIME [epoch: 9.58 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16517824066706194		[learning rate: 0.00014291]
	Learning Rate: 0.000142915
	LOSS [training: 0.16517824066706194 | validation: 0.24277148049203373]
	TIME [epoch: 9.58 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16253594890115938		[learning rate: 0.00014258]
	Learning Rate: 0.000142578
	LOSS [training: 0.16253594890115938 | validation: 0.23837518413510206]
	TIME [epoch: 9.59 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16158102821704912		[learning rate: 0.00014224]
	Learning Rate: 0.000142241
	LOSS [training: 0.16158102821704912 | validation: 0.2352071365470998]
	TIME [epoch: 9.57 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16743241709913767		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.16743241709913767 | validation: 0.24483448260628607]
	TIME [epoch: 9.56 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16637736107184686		[learning rate: 0.00014157]
	Learning Rate: 0.000141571
	LOSS [training: 0.16637736107184686 | validation: 0.24714411012510515]
	TIME [epoch: 9.58 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17846993352455653		[learning rate: 0.00014124]
	Learning Rate: 0.000141237
	LOSS [training: 0.17846993352455653 | validation: 0.22846383106457985]
	TIME [epoch: 9.6 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1753833618584322		[learning rate: 0.0001409]
	Learning Rate: 0.000140904
	LOSS [training: 0.1753833618584322 | validation: 0.2572207091234296]
	TIME [epoch: 9.58 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1989190825421126		[learning rate: 0.00014057]
	Learning Rate: 0.000140572
	LOSS [training: 0.1989190825421126 | validation: 0.26677276119022797]
	TIME [epoch: 9.58 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1942369398477562		[learning rate: 0.00014024]
	Learning Rate: 0.00014024
	LOSS [training: 0.1942369398477562 | validation: 0.2383294141595035]
	TIME [epoch: 9.61 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17699183942220403		[learning rate: 0.00013991]
	Learning Rate: 0.000139909
	LOSS [training: 0.17699183942220403 | validation: 0.23639430981677018]
	TIME [epoch: 9.59 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.174640154332805		[learning rate: 0.00013958]
	Learning Rate: 0.000139579
	LOSS [training: 0.174640154332805 | validation: 0.23472444884096194]
	TIME [epoch: 9.59 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17750461165902226		[learning rate: 0.00013925]
	Learning Rate: 0.00013925
	LOSS [training: 0.17750461165902226 | validation: 0.23519073639849672]
	TIME [epoch: 9.58 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17739669121223606		[learning rate: 0.00013892]
	Learning Rate: 0.000138921
	LOSS [training: 0.17739669121223606 | validation: 0.23245637508760794]
	TIME [epoch: 9.61 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16573945067187484		[learning rate: 0.00013859]
	Learning Rate: 0.000138594
	LOSS [training: 0.16573945067187484 | validation: 0.2619088304033997]
	TIME [epoch: 9.59 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.173265046360767		[learning rate: 0.00013827]
	Learning Rate: 0.000138267
	LOSS [training: 0.173265046360767 | validation: 0.25399073331574284]
	TIME [epoch: 9.59 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1793525681158093		[learning rate: 0.00013794]
	Learning Rate: 0.000137941
	LOSS [training: 0.1793525681158093 | validation: 0.2303926163379395]
	TIME [epoch: 9.6 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16550513307547043		[learning rate: 0.00013762]
	Learning Rate: 0.000137615
	LOSS [training: 0.16550513307547043 | validation: 0.22667465289878802]
	TIME [epoch: 9.61 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1569204722229256		[learning rate: 0.00013729]
	Learning Rate: 0.000137291
	LOSS [training: 0.1569204722229256 | validation: 0.24266566989719945]
	TIME [epoch: 9.59 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16120315934671037		[learning rate: 0.00013697]
	Learning Rate: 0.000136967
	LOSS [training: 0.16120315934671037 | validation: 0.2437395591117123]
	TIME [epoch: 9.6 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1551341900628842		[learning rate: 0.00013664]
	Learning Rate: 0.000136644
	LOSS [training: 0.1551341900628842 | validation: 0.23456130239167172]
	TIME [epoch: 9.58 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15815576940407783		[learning rate: 0.00013632]
	Learning Rate: 0.000136321
	LOSS [training: 0.15815576940407783 | validation: 0.2583229374857229]
	TIME [epoch: 9.61 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15713561744643317		[learning rate: 0.000136]
	Learning Rate: 0.000136
	LOSS [training: 0.15713561744643317 | validation: 0.2623963511815165]
	TIME [epoch: 9.59 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15642453892166308		[learning rate: 0.00013568]
	Learning Rate: 0.000135679
	LOSS [training: 0.15642453892166308 | validation: 0.23116513417606085]
	TIME [epoch: 9.6 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1587954344770894		[learning rate: 0.00013536]
	Learning Rate: 0.000135359
	LOSS [training: 0.1587954344770894 | validation: 0.2336305386854952]
	TIME [epoch: 9.61 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1553741841431966		[learning rate: 0.00013504]
	Learning Rate: 0.00013504
	LOSS [training: 0.1553741841431966 | validation: 0.24329882014501675]
	TIME [epoch: 9.59 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1672411425964223		[learning rate: 0.00013472]
	Learning Rate: 0.000134721
	LOSS [training: 0.1672411425964223 | validation: 0.2630788317444663]
	TIME [epoch: 9.6 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19555457464181647		[learning rate: 0.0001344]
	Learning Rate: 0.000134403
	LOSS [training: 0.19555457464181647 | validation: 0.2769901009697]
	TIME [epoch: 9.61 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20178363453072895		[learning rate: 0.00013409]
	Learning Rate: 0.000134086
	LOSS [training: 0.20178363453072895 | validation: 0.2547000844744682]
	TIME [epoch: 9.6 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17613261132584865		[learning rate: 0.00013377]
	Learning Rate: 0.00013377
	LOSS [training: 0.17613261132584865 | validation: 0.2439650122849254]
	TIME [epoch: 9.6 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16397926967176		[learning rate: 0.00013345]
	Learning Rate: 0.000133455
	LOSS [training: 0.16397926967176 | validation: 0.22741274757817717]
	TIME [epoch: 9.59 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16607449614248443		[learning rate: 0.00013314]
	Learning Rate: 0.00013314
	LOSS [training: 0.16607449614248443 | validation: 0.2382707654725522]
	TIME [epoch: 9.59 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16692424383532775		[learning rate: 0.00013283]
	Learning Rate: 0.000132826
	LOSS [training: 0.16692424383532775 | validation: 0.22444573470470489]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1880.pth
	Model improved!!!
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16009410274885089		[learning rate: 0.00013251]
	Learning Rate: 0.000132512
	LOSS [training: 0.16009410274885089 | validation: 0.2523943876101456]
	TIME [epoch: 9.59 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16204358637996352		[learning rate: 0.0001322]
	Learning Rate: 0.0001322
	LOSS [training: 0.16204358637996352 | validation: 0.25473808794799757]
	TIME [epoch: 9.6 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15761947238690127		[learning rate: 0.00013189]
	Learning Rate: 0.000131888
	LOSS [training: 0.15761947238690127 | validation: 0.26123735505036016]
	TIME [epoch: 9.6 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15201030402522026		[learning rate: 0.00013158]
	Learning Rate: 0.000131577
	LOSS [training: 0.15201030402522026 | validation: 0.2569070924395947]
	TIME [epoch: 9.63 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1579210046944015		[learning rate: 0.00013127]
	Learning Rate: 0.000131266
	LOSS [training: 0.1579210046944015 | validation: 0.24918730204100797]
	TIME [epoch: 9.59 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16764172596180382		[learning rate: 0.00013096]
	Learning Rate: 0.000130957
	LOSS [training: 0.16764172596180382 | validation: 0.2586078675049008]
	TIME [epoch: 9.61 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15587087871452554		[learning rate: 0.00013065]
	Learning Rate: 0.000130648
	LOSS [training: 0.15587087871452554 | validation: 0.26009779628075086]
	TIME [epoch: 9.6 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15226775069315526		[learning rate: 0.00013034]
	Learning Rate: 0.00013034
	LOSS [training: 0.15226775069315526 | validation: 0.24608413649337954]
	TIME [epoch: 9.62 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15285407434187034		[learning rate: 0.00013003]
	Learning Rate: 0.000130032
	LOSS [training: 0.15285407434187034 | validation: 0.2504304849557627]
	TIME [epoch: 9.59 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1642247299638228		[learning rate: 0.00012973]
	Learning Rate: 0.000129726
	LOSS [training: 0.1642247299638228 | validation: 0.23927178867064303]
	TIME [epoch: 9.61 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1572965065018565		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.1572965065018565 | validation: 0.26556589953667725]
	TIME [epoch: 9.61 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17467233203142446		[learning rate: 0.00012911]
	Learning Rate: 0.000129114
	LOSS [training: 0.17467233203142446 | validation: 0.25989040638016975]
	TIME [epoch: 9.6 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16857805456736463		[learning rate: 0.00012881]
	Learning Rate: 0.00012881
	LOSS [training: 0.16857805456736463 | validation: 0.25827016436370115]
	TIME [epoch: 9.59 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16476192573390744		[learning rate: 0.00012851]
	Learning Rate: 0.000128506
	LOSS [training: 0.16476192573390744 | validation: 0.2501200440656447]
	TIME [epoch: 9.61 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.161887586768174		[learning rate: 0.0001282]
	Learning Rate: 0.000128203
	LOSS [training: 0.161887586768174 | validation: 0.25989811318161193]
	TIME [epoch: 9.61 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1771140397322323		[learning rate: 0.0001279]
	Learning Rate: 0.0001279
	LOSS [training: 0.1771140397322323 | validation: 0.2477380009003452]
	TIME [epoch: 9.61 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17211565281314545		[learning rate: 0.0001276]
	Learning Rate: 0.000127599
	LOSS [training: 0.17211565281314545 | validation: 0.25901261681715865]
	TIME [epoch: 9.6 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1711400732509806		[learning rate: 0.0001273]
	Learning Rate: 0.000127298
	LOSS [training: 0.1711400732509806 | validation: 0.2518819904079755]
	TIME [epoch: 9.58 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16523188870625072		[learning rate: 0.000127]
	Learning Rate: 0.000126997
	LOSS [training: 0.16523188870625072 | validation: 0.23339624262803313]
	TIME [epoch: 9.61 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1574275910557923		[learning rate: 0.0001267]
	Learning Rate: 0.000126698
	LOSS [training: 0.1574275910557923 | validation: 0.2375560016598329]
	TIME [epoch: 9.59 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17330864868596513		[learning rate: 0.0001264]
	Learning Rate: 0.000126399
	LOSS [training: 0.17330864868596513 | validation: 0.2406911136356563]
	TIME [epoch: 9.59 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18071196662290606		[learning rate: 0.0001261]
	Learning Rate: 0.000126101
	LOSS [training: 0.18071196662290606 | validation: 0.2363715256633833]
	TIME [epoch: 9.6 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18274670626404907		[learning rate: 0.0001258]
	Learning Rate: 0.000125803
	LOSS [training: 0.18274670626404907 | validation: 0.24769659951772652]
	TIME [epoch: 9.61 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17021719144206687		[learning rate: 0.00012551]
	Learning Rate: 0.000125507
	LOSS [training: 0.17021719144206687 | validation: 0.22972124791029244]
	TIME [epoch: 9.59 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17174314469038632		[learning rate: 0.00012521]
	Learning Rate: 0.000125211
	LOSS [training: 0.17174314469038632 | validation: 0.2559500682116602]
	TIME [epoch: 9.59 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16516269685458468		[learning rate: 0.00012492]
	Learning Rate: 0.000124915
	LOSS [training: 0.16516269685458468 | validation: 0.23936330652343507]
	TIME [epoch: 9.64 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16651314803447642		[learning rate: 0.00012462]
	Learning Rate: 0.000124621
	LOSS [training: 0.16651314803447642 | validation: 0.24290295171849038]
	TIME [epoch: 9.61 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15346708783257906		[learning rate: 0.00012433]
	Learning Rate: 0.000124327
	LOSS [training: 0.15346708783257906 | validation: 0.24603230597748998]
	TIME [epoch: 9.59 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1636473795595395		[learning rate: 0.00012403]
	Learning Rate: 0.000124033
	LOSS [training: 0.1636473795595395 | validation: 0.2427486397015165]
	TIME [epoch: 9.6 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17938074996896958		[learning rate: 0.00012374]
	Learning Rate: 0.000123741
	LOSS [training: 0.17938074996896958 | validation: 0.2540245841692341]
	TIME [epoch: 9.61 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15798297237457432		[learning rate: 0.00012345]
	Learning Rate: 0.000123449
	LOSS [training: 0.15798297237457432 | validation: 0.24336541320626748]
	TIME [epoch: 9.61 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16116424397104945		[learning rate: 0.00012316]
	Learning Rate: 0.000123158
	LOSS [training: 0.16116424397104945 | validation: 0.23766031556022144]
	TIME [epoch: 9.58 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1590149240846006		[learning rate: 0.00012287]
	Learning Rate: 0.000122867
	LOSS [training: 0.1590149240846006 | validation: 0.2572964072855812]
	TIME [epoch: 9.59 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17405937973399782		[learning rate: 0.00012258]
	Learning Rate: 0.000122577
	LOSS [training: 0.17405937973399782 | validation: 0.2375541075056411]
	TIME [epoch: 9.61 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16804002698509088		[learning rate: 0.00012229]
	Learning Rate: 0.000122288
	LOSS [training: 0.16804002698509088 | validation: 0.22661822831144768]
	TIME [epoch: 9.61 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16393405205784464		[learning rate: 0.000122]
	Learning Rate: 0.000122
	LOSS [training: 0.16393405205784464 | validation: 0.21637266087980644]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240219_184940/states/model_tr_study5_1916.pth
	Model improved!!!
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16041472145934396		[learning rate: 0.00012171]
	Learning Rate: 0.000121712
	LOSS [training: 0.16041472145934396 | validation: 0.24168875454099464]
	TIME [epoch: 9.61 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1631237010416514		[learning rate: 0.00012142]
	Learning Rate: 0.000121425
	LOSS [training: 0.1631237010416514 | validation: 0.24017725469086262]
	TIME [epoch: 9.61 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16933058657719974		[learning rate: 0.00012114]
	Learning Rate: 0.000121138
	LOSS [training: 0.16933058657719974 | validation: 0.2341160458630893]
	TIME [epoch: 9.58 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16224204434896664		[learning rate: 0.00012085]
	Learning Rate: 0.000120853
	LOSS [training: 0.16224204434896664 | validation: 0.22805727995762326]
	TIME [epoch: 9.6 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16560371282438172		[learning rate: 0.00012057]
	Learning Rate: 0.000120568
	LOSS [training: 0.16560371282438172 | validation: 0.2358804143641163]
	TIME [epoch: 9.62 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16155076304596563		[learning rate: 0.00012028]
	Learning Rate: 0.000120283
	LOSS [training: 0.16155076304596563 | validation: 0.23664354273500648]
	TIME [epoch: 9.59 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15656063948058946		[learning rate: 0.00012]
	Learning Rate: 0.00012
	LOSS [training: 0.15656063948058946 | validation: 0.2223911271107059]
	TIME [epoch: 9.6 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16574684716941213		[learning rate: 0.00011972]
	Learning Rate: 0.000119716
	LOSS [training: 0.16574684716941213 | validation: 0.27014406374318634]
	TIME [epoch: 9.58 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17835613535266903		[learning rate: 0.00011943]
	Learning Rate: 0.000119434
	LOSS [training: 0.17835613535266903 | validation: 0.27699856189470656]
	TIME [epoch: 9.62 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16721096528718368		[learning rate: 0.00011915]
	Learning Rate: 0.000119152
	LOSS [training: 0.16721096528718368 | validation: 0.2596507609895813]
	TIME [epoch: 9.59 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16876673506960677		[learning rate: 0.00011887]
	Learning Rate: 0.000118871
	LOSS [training: 0.16876673506960677 | validation: 0.2900447241397752]
	TIME [epoch: 9.6 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16443108608497195		[learning rate: 0.00011859]
	Learning Rate: 0.000118591
	LOSS [training: 0.16443108608497195 | validation: 0.2795152236011103]
	TIME [epoch: 9.6 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16326879283063084		[learning rate: 0.00011831]
	Learning Rate: 0.000118311
	LOSS [training: 0.16326879283063084 | validation: 0.2631341683818408]
	TIME [epoch: 9.62 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15967034874000363		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.15967034874000363 | validation: 0.2755258579199251]
	TIME [epoch: 9.6 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16189877488942597		[learning rate: 0.00011775]
	Learning Rate: 0.000117754
	LOSS [training: 0.16189877488942597 | validation: 0.27152924423139274]
	TIME [epoch: 9.6 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17532899016655595		[learning rate: 0.00011748]
	Learning Rate: 0.000117476
	LOSS [training: 0.17532899016655595 | validation: 0.2995906141369749]
	TIME [epoch: 9.61 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17622262954918666		[learning rate: 0.0001172]
	Learning Rate: 0.000117199
	LOSS [training: 0.17622262954918666 | validation: 0.278133179839427]
	TIME [epoch: 9.62 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16891185187395918		[learning rate: 0.00011692]
	Learning Rate: 0.000116922
	LOSS [training: 0.16891185187395918 | validation: 0.2602196554686437]
	TIME [epoch: 9.59 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16359762643503503		[learning rate: 0.00011665]
	Learning Rate: 0.000116647
	LOSS [training: 0.16359762643503503 | validation: 0.2612552345936081]
	TIME [epoch: 9.59 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16064868575296276		[learning rate: 0.00011637]
	Learning Rate: 0.000116371
	LOSS [training: 0.16064868575296276 | validation: 0.2654648746530643]
	TIME [epoch: 9.61 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1615305569005452		[learning rate: 0.0001161]
	Learning Rate: 0.000116097
	LOSS [training: 0.1615305569005452 | validation: 0.23775814419848942]
	TIME [epoch: 9.6 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16568492824889533		[learning rate: 0.00011582]
	Learning Rate: 0.000115823
	LOSS [training: 0.16568492824889533 | validation: 0.22549497513840958]
	TIME [epoch: 9.59 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1572527872760068		[learning rate: 0.00011555]
	Learning Rate: 0.00011555
	LOSS [training: 0.1572527872760068 | validation: 0.23750679429685057]
	TIME [epoch: 9.6 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16302220798583714		[learning rate: 0.00011528]
	Learning Rate: 0.000115277
	LOSS [training: 0.16302220798583714 | validation: 0.22780950828689672]
	TIME [epoch: 9.61 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16246417189148027		[learning rate: 0.00011501]
	Learning Rate: 0.000115005
	LOSS [training: 0.16246417189148027 | validation: 0.23624517913786086]
	TIME [epoch: 9.59 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15827317542968475		[learning rate: 0.00011473]
	Learning Rate: 0.000114734
	LOSS [training: 0.15827317542968475 | validation: 0.22517422918823526]
	TIME [epoch: 9.59 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1653490777054555		[learning rate: 0.00011446]
	Learning Rate: 0.000114463
	LOSS [training: 0.1653490777054555 | validation: 0.23755121577964722]
	TIME [epoch: 9.59 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16509694968769306		[learning rate: 0.00011419]
	Learning Rate: 0.000114193
	LOSS [training: 0.16509694968769306 | validation: 0.2537642473550871]
	TIME [epoch: 9.63 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16295347062341167		[learning rate: 0.00011392]
	Learning Rate: 0.000113924
	LOSS [training: 0.16295347062341167 | validation: 0.2783810344852736]
	TIME [epoch: 9.61 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16270269464918113		[learning rate: 0.00011366]
	Learning Rate: 0.000113655
	LOSS [training: 0.16270269464918113 | validation: 0.2699545524218152]
	TIME [epoch: 9.59 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15801920916264142		[learning rate: 0.00011339]
	Learning Rate: 0.000113387
	LOSS [training: 0.15801920916264142 | validation: 0.253149295047299]
	TIME [epoch: 9.61 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16639402155346525		[learning rate: 0.00011312]
	Learning Rate: 0.00011312
	LOSS [training: 0.16639402155346525 | validation: 0.26934303401091764]
	TIME [epoch: 9.6 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16551897609895752		[learning rate: 0.00011285]
	Learning Rate: 0.000112853
	LOSS [training: 0.16551897609895752 | validation: 0.2618654260368949]
	TIME [epoch: 9.59 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1654941930022315		[learning rate: 0.00011259]
	Learning Rate: 0.000112587
	LOSS [training: 0.1654941930022315 | validation: 0.27098594083502653]
	TIME [epoch: 9.6 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16432745295625623		[learning rate: 0.00011232]
	Learning Rate: 0.000112321
	LOSS [training: 0.16432745295625623 | validation: 0.24390442278736132]
	TIME [epoch: 9.62 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15535864147677522		[learning rate: 0.00011206]
	Learning Rate: 0.000112056
	LOSS [training: 0.15535864147677522 | validation: 0.2844817243868804]
	TIME [epoch: 9.6 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16494689994219044		[learning rate: 0.00011179]
	Learning Rate: 0.000111792
	LOSS [training: 0.16494689994219044 | validation: 0.25839740164422265]
	TIME [epoch: 9.59 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16242277888179327		[learning rate: 0.00011153]
	Learning Rate: 0.000111528
	LOSS [training: 0.16242277888179327 | validation: 0.2406851877036619]
	TIME [epoch: 9.59 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16198978491695984		[learning rate: 0.00011127]
	Learning Rate: 0.000111265
	LOSS [training: 0.16198978491695984 | validation: 0.24262535371418792]
	TIME [epoch: 9.63 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16714625580484546		[learning rate: 0.000111]
	Learning Rate: 0.000111003
	LOSS [training: 0.16714625580484546 | validation: 0.25155490606602604]
	TIME [epoch: 9.59 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1525954975391597		[learning rate: 0.00011074]
	Learning Rate: 0.000110741
	LOSS [training: 0.1525954975391597 | validation: 0.24989835520303672]
	TIME [epoch: 9.6 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15863635925699224		[learning rate: 0.00011048]
	Learning Rate: 0.00011048
	LOSS [training: 0.15863635925699224 | validation: 0.23606202091941325]
	TIME [epoch: 9.58 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16342435259803528		[learning rate: 0.00011022]
	Learning Rate: 0.000110219
	LOSS [training: 0.16342435259803528 | validation: 0.2660872174636772]
	TIME [epoch: 9.62 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16783389758031036		[learning rate: 0.00010996]
	Learning Rate: 0.000109959
	LOSS [training: 0.16783389758031036 | validation: 0.2524529651264156]
	TIME [epoch: 9.59 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1540600693764776		[learning rate: 0.0001097]
	Learning Rate: 0.0001097
	LOSS [training: 0.1540600693764776 | validation: 0.26326613532682897]
	TIME [epoch: 9.6 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16002684072281032		[learning rate: 0.00010944]
	Learning Rate: 0.000109441
	LOSS [training: 0.16002684072281032 | validation: 0.2797658628479189]
	TIME [epoch: 9.61 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16597730751943138		[learning rate: 0.00010918]
	Learning Rate: 0.000109183
	LOSS [training: 0.16597730751943138 | validation: 0.26854792497371666]
	TIME [epoch: 9.61 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16604961599606052		[learning rate: 0.00010893]
	Learning Rate: 0.000108925
	LOSS [training: 0.16604961599606052 | validation: 0.26235564599786876]
	TIME [epoch: 9.59 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17708094024436918		[learning rate: 0.00010867]
	Learning Rate: 0.000108668
	LOSS [training: 0.17708094024436918 | validation: 0.26694491346730764]
	TIME [epoch: 9.59 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18168529157406266		[learning rate: 0.00010841]
	Learning Rate: 0.000108412
	LOSS [training: 0.18168529157406266 | validation: 0.2617149956968616]
	TIME [epoch: 9.62 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16397754259470615		[learning rate: 0.00010816]
	Learning Rate: 0.000108156
	LOSS [training: 0.16397754259470615 | validation: 0.2447396615448983]
	TIME [epoch: 9.6 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16281778224559268		[learning rate: 0.0001079]
	Learning Rate: 0.000107901
	LOSS [training: 0.16281778224559268 | validation: 0.26668610067555343]
	TIME [epoch: 9.59 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1633029427693009		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.1633029427693009 | validation: 0.24137961334806676]
	TIME [epoch: 9.59 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1653474957023307		[learning rate: 0.00010739]
	Learning Rate: 0.000107393
	LOSS [training: 0.1653474957023307 | validation: 0.24749889557073296]
	TIME [epoch: 9.61 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15792556775747038		[learning rate: 0.00010714]
	Learning Rate: 0.000107139
	LOSS [training: 0.15792556775747038 | validation: 0.24338208494142835]
	TIME [epoch: 9.62 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1664786125695063		[learning rate: 0.00010689]
	Learning Rate: 0.000106887
	LOSS [training: 0.1664786125695063 | validation: 0.26554316811392203]
	TIME [epoch: 9.58 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15816832358140448		[learning rate: 0.00010663]
	Learning Rate: 0.000106634
	LOSS [training: 0.15816832358140448 | validation: 0.2613812050255049]
	TIME [epoch: 9.59 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1652289923969531		[learning rate: 0.00010638]
	Learning Rate: 0.000106383
	LOSS [training: 0.1652289923969531 | validation: 0.2667622471901529]
	TIME [epoch: 9.6 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16404998066883875		[learning rate: 0.00010613]
	Learning Rate: 0.000106132
	LOSS [training: 0.16404998066883875 | validation: 0.2534031232603592]
	TIME [epoch: 9.61 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16894194719820305		[learning rate: 0.00010588]
	Learning Rate: 0.000105882
	LOSS [training: 0.16894194719820305 | validation: 0.2453962815020596]
	TIME [epoch: 9.61 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16426458290920734		[learning rate: 0.00010563]
	Learning Rate: 0.000105632
	LOSS [training: 0.16426458290920734 | validation: 0.24651433930027117]
	TIME [epoch: 9.6 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15686174686848733		[learning rate: 0.00010538]
	Learning Rate: 0.000105383
	LOSS [training: 0.15686174686848733 | validation: 0.2536061993744126]
	TIME [epoch: 9.61 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1612478157728206		[learning rate: 0.00010513]
	Learning Rate: 0.000105134
	LOSS [training: 0.1612478157728206 | validation: 0.2397484719697438]
	TIME [epoch: 9.66 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15852561497519652		[learning rate: 0.00010489]
	Learning Rate: 0.000104886
	LOSS [training: 0.15852561497519652 | validation: 0.2530797383666858]
	TIME [epoch: 9.59 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16122270807376132		[learning rate: 0.00010464]
	Learning Rate: 0.000104639
	LOSS [training: 0.16122270807376132 | validation: 0.24008223468211712]
	TIME [epoch: 9.62 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16036137400520942		[learning rate: 0.00010439]
	Learning Rate: 0.000104392
	LOSS [training: 0.16036137400520942 | validation: 0.24451682627675358]
	TIME [epoch: 9.58 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15408783181995647		[learning rate: 0.00010415]
	Learning Rate: 0.000104146
	LOSS [training: 0.15408783181995647 | validation: 0.24541680217289766]
	TIME [epoch: 9.59 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16282603025854955		[learning rate: 0.0001039]
	Learning Rate: 0.0001039
	LOSS [training: 0.16282603025854955 | validation: 0.2588946297371738]
	TIME [epoch: 9.59 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1637104995539524		[learning rate: 0.00010365]
	Learning Rate: 0.000103655
	LOSS [training: 0.1637104995539524 | validation: 0.25872944461177905]
	TIME [epoch: 9.62 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1571568332643645		[learning rate: 0.00010341]
	Learning Rate: 0.00010341
	LOSS [training: 0.1571568332643645 | validation: 0.25464144187290233]
	TIME [epoch: 9.58 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15965076967833444		[learning rate: 0.00010317]
	Learning Rate: 0.000103166
	LOSS [training: 0.15965076967833444 | validation: 0.23975177773635142]
	TIME [epoch: 9.59 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16312137381653047		[learning rate: 0.00010292]
	Learning Rate: 0.000102923
	LOSS [training: 0.16312137381653047 | validation: 0.25161562971792045]
	TIME [epoch: 9.6 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16778219307525416		[learning rate: 0.00010268]
	Learning Rate: 0.00010268
	LOSS [training: 0.16778219307525416 | validation: 0.24660705122672905]
	TIME [epoch: 9.61 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16601556202697912		[learning rate: 0.00010244]
	Learning Rate: 0.000102438
	LOSS [training: 0.16601556202697912 | validation: 0.24292652291487987]
	TIME [epoch: 9.6 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17305157098697038		[learning rate: 0.0001022]
	Learning Rate: 0.000102196
	LOSS [training: 0.17305157098697038 | validation: 0.24674684698098073]
	TIME [epoch: 9.6 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16688046391714365		[learning rate: 0.00010196]
	Learning Rate: 0.000101955
	LOSS [training: 0.16688046391714365 | validation: 0.23476956189941245]
	TIME [epoch: 9.61 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18029939597796316		[learning rate: 0.00010171]
	Learning Rate: 0.000101715
	LOSS [training: 0.18029939597796316 | validation: 0.25093562017496795]
	TIME [epoch: 9.59 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1749990718076226		[learning rate: 0.00010147]
	Learning Rate: 0.000101475
	LOSS [training: 0.1749990718076226 | validation: 0.23188916127566425]
	TIME [epoch: 9.59 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1764740158072972		[learning rate: 0.00010124]
	Learning Rate: 0.000101236
	LOSS [training: 0.1764740158072972 | validation: 0.23983629743730261]
	TIME [epoch: 9.6 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16120878255933496		[learning rate: 0.000101]
	Learning Rate: 0.000100997
	LOSS [training: 0.16120878255933496 | validation: 0.23955170491132968]
	TIME [epoch: 9.62 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17149041521515979		[learning rate: 0.00010076]
	Learning Rate: 0.000100759
	LOSS [training: 0.17149041521515979 | validation: 0.2638855558967122]
	TIME [epoch: 9.61 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16913658018358593		[learning rate: 0.00010052]
	Learning Rate: 0.000100521
	LOSS [training: 0.16913658018358593 | validation: 0.24233276666769]
	TIME [epoch: 9.6 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16324860839854033		[learning rate: 0.00010028]
	Learning Rate: 0.000100284
	LOSS [training: 0.16324860839854033 | validation: 0.2384426481347911]
	TIME [epoch: 9.59 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16432107669624826		[learning rate: 0.00010005]
	Learning Rate: 0.000100047
	LOSS [training: 0.16432107669624826 | validation: 0.24474399889010337]
	TIME [epoch: 9.61 sec]
Finished training in 19404.437 seconds.
