Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r0', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4045959719

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 12.011041123230783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.011041123230783 | validation: 11.562692037785911]
	TIME [epoch: 80.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.043642913691704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.043642913691704 | validation: 12.233437554568372]
	TIME [epoch: 9.58 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.979544560437342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.979544560437342 | validation: 11.532456372711751]
	TIME [epoch: 9.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.474736124144345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.474736124144345 | validation: 11.107248389446509]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.233833574915343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.233833574915343 | validation: 10.953520398866898]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.94045321149056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.94045321149056 | validation: 10.853642442077394]
	TIME [epoch: 9.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.464190433443244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.464190433443244 | validation: 10.678517233841403]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.617745129559465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.617745129559465 | validation: 10.598399332680009]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.41873190291042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.41873190291042 | validation: 10.693262532243342]
	TIME [epoch: 9.57 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.134932250721977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.134932250721977 | validation: 10.44869915547772]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.224366826829108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.224366826829108 | validation: 10.3405887105043]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.98404477589031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.98404477589031 | validation: 10.372400043428266]
	TIME [epoch: 9.56 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.973620150725031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.973620150725031 | validation: 10.32357902455567]
	TIME [epoch: 9.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.86990770167448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.86990770167448 | validation: 10.272715414207799]
	TIME [epoch: 9.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.755206819760186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.755206819760186 | validation: 10.48299431868079]
	TIME [epoch: 9.6 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.953926727766165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.953926727766165 | validation: 10.244084234516704]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.708509280047712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.708509280047712 | validation: 10.294413968488511]
	TIME [epoch: 9.57 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.758862351966744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.758862351966744 | validation: 9.883772354826768]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.782201122998284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.782201122998284 | validation: 10.019211164816124]
	TIME [epoch: 9.58 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.473836655390473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.473836655390473 | validation: 9.889063919073246]
	TIME [epoch: 9.56 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.06645469452284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.06645469452284 | validation: 10.585927002594072]
	TIME [epoch: 9.56 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.331163112997267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.331163112997267 | validation: 9.363790263641166]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.189092370933613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.189092370933613 | validation: 9.757669891871766]
	TIME [epoch: 9.57 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.751191427376817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.751191427376817 | validation: 9.304014753424214]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.375484560956816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.375484560956816 | validation: 9.23295282456583]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.514131580510461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.514131580510461 | validation: 9.220145498362044]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.768675173855415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.768675173855415 | validation: 9.196762661772194]
	TIME [epoch: 9.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.1796021911996375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.1796021911996375 | validation: 9.054364055752103]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.154512046388265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.154512046388265 | validation: 8.951927864981208]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.680121052749539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.680121052749539 | validation: 8.776118256054838]
	TIME [epoch: 9.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.970788511455053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.970788511455053 | validation: 8.399064897177768]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.300869015961203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.300869015961203 | validation: 8.761066361599367]
	TIME [epoch: 9.57 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.422108611709608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.422108611709608 | validation: 7.918631707275384]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.612796287649729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.612796287649729 | validation: 8.731493998813601]
	TIME [epoch: 9.57 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.4297664534620775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4297664534620775 | validation: 8.040201712645464]
	TIME [epoch: 9.56 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.733064114300979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.733064114300979 | validation: 7.238978793610158]
	TIME [epoch: 9.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.91378932862174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.91378932862174 | validation: 8.511617102838505]
	TIME [epoch: 9.6 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.56644130804099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.56644130804099 | validation: 6.3833281054400315]
	TIME [epoch: 9.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.9030690320642005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9030690320642005 | validation: 6.534748692167359]
	TIME [epoch: 9.58 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.87722609905015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.87722609905015 | validation: 6.564337910324404]
	TIME [epoch: 9.59 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.803187782328104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.803187782328104 | validation: 6.804997475213822]
	TIME [epoch: 9.6 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.789144025878081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.789144025878081 | validation: 6.624637310707128]
	TIME [epoch: 9.58 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.640096185229863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.640096185229863 | validation: 6.261132890577421]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.667845176705396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.667845176705396 | validation: 6.487612726344232]
	TIME [epoch: 9.6 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.567758838372993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.567758838372993 | validation: 6.570648581537737]
	TIME [epoch: 9.58 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.852368785389258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.852368785389258 | validation: 6.169561448840711]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.640145573744278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.640145573744278 | validation: 6.4334856362461075]
	TIME [epoch: 9.58 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.543221618164791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.543221618164791 | validation: 6.856337785045162]
	TIME [epoch: 9.61 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.530472575798887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.530472575798887 | validation: 6.1570886054500935]
	TIME [epoch: 9.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.497192143383803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.497192143383803 | validation: 6.247085119529832]
	TIME [epoch: 9.57 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.521092079091201		[learning rate: 0.0099811]
	Learning Rate: 0.00998112
	LOSS [training: 4.521092079091201 | validation: 6.921237749191057]
	TIME [epoch: 9.56 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.515105771873773		[learning rate: 0.0099576]
	Learning Rate: 0.00995758
	LOSS [training: 4.515105771873773 | validation: 6.4950783942016415]
	TIME [epoch: 9.58 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.420539849546687		[learning rate: 0.0099341]
	Learning Rate: 0.00993409
	LOSS [training: 4.420539849546687 | validation: 6.084544583096008]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.352571255720415		[learning rate: 0.0099107]
	Learning Rate: 0.00991066
	LOSS [training: 4.352571255720415 | validation: 6.416410819698069]
	TIME [epoch: 9.56 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.507744180768429		[learning rate: 0.0098873]
	Learning Rate: 0.00988728
	LOSS [training: 4.507744180768429 | validation: 6.041559793097499]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.508686175912475		[learning rate: 0.009864]
	Learning Rate: 0.00986396
	LOSS [training: 4.508686175912475 | validation: 6.2129681944769555]
	TIME [epoch: 9.58 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.477278271694497		[learning rate: 0.0098407]
	Learning Rate: 0.00984069
	LOSS [training: 4.477278271694497 | validation: 6.192096751465733]
	TIME [epoch: 9.57 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.525314112237604		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 4.525314112237604 | validation: 7.381263557070552]
	TIME [epoch: 9.55 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.781674124700549		[learning rate: 0.0097943]
	Learning Rate: 0.00979432
	LOSS [training: 4.781674124700549 | validation: 6.266882024596763]
	TIME [epoch: 9.58 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.200945885906455		[learning rate: 0.0097712]
	Learning Rate: 0.00977122
	LOSS [training: 4.200945885906455 | validation: 6.218330364914088]
	TIME [epoch: 9.56 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.3406602777742345		[learning rate: 0.0097482]
	Learning Rate: 0.00974817
	LOSS [training: 4.3406602777742345 | validation: 6.333344367713192]
	TIME [epoch: 9.56 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.237315589033663		[learning rate: 0.0097252]
	Learning Rate: 0.00972517
	LOSS [training: 4.237315589033663 | validation: 6.468424277625549]
	TIME [epoch: 9.55 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.100584397477952		[learning rate: 0.0097022]
	Learning Rate: 0.00970223
	LOSS [training: 4.100584397477952 | validation: 5.894906936490697]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.14798897047725		[learning rate: 0.0096793]
	Learning Rate: 0.00967935
	LOSS [training: 4.14798897047725 | validation: 6.791398206479433]
	TIME [epoch: 9.55 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.231007391085475		[learning rate: 0.0096565]
	Learning Rate: 0.00965652
	LOSS [training: 4.231007391085475 | validation: 6.543617442424278]
	TIME [epoch: 9.54 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.332577874300223		[learning rate: 0.0096337]
	Learning Rate: 0.00963374
	LOSS [training: 4.332577874300223 | validation: 5.863213381583482]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.305271227256884		[learning rate: 0.009611]
	Learning Rate: 0.00961101
	LOSS [training: 4.305271227256884 | validation: 6.343899301400287]
	TIME [epoch: 9.57 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.160153032751104		[learning rate: 0.0095883]
	Learning Rate: 0.00958834
	LOSS [training: 4.160153032751104 | validation: 5.841051419990972]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.268093655561641		[learning rate: 0.0095657]
	Learning Rate: 0.00956573
	LOSS [training: 4.268093655561641 | validation: 5.979992347594282]
	TIME [epoch: 9.55 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.263250244739227		[learning rate: 0.0095432]
	Learning Rate: 0.00954316
	LOSS [training: 4.263250244739227 | validation: 5.995876133594452]
	TIME [epoch: 9.59 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.073953980440928		[learning rate: 0.0095207]
	Learning Rate: 0.00952065
	LOSS [training: 4.073953980440928 | validation: 5.710378267536814]
	TIME [epoch: 9.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.1751289061078705		[learning rate: 0.0094982]
	Learning Rate: 0.00949819
	LOSS [training: 4.1751289061078705 | validation: 5.870639961860298]
	TIME [epoch: 9.56 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.066117284334718		[learning rate: 0.0094758]
	Learning Rate: 0.00947579
	LOSS [training: 4.066117284334718 | validation: 5.920296889085802]
	TIME [epoch: 9.56 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.088611443509375		[learning rate: 0.0094534]
	Learning Rate: 0.00945344
	LOSS [training: 4.088611443509375 | validation: 6.010986353808136]
	TIME [epoch: 9.58 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.031646538545051		[learning rate: 0.0094311]
	Learning Rate: 0.00943114
	LOSS [training: 4.031646538545051 | validation: 5.837829199107959]
	TIME [epoch: 9.56 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.2717056717985535		[learning rate: 0.0094089]
	Learning Rate: 0.00940889
	LOSS [training: 4.2717056717985535 | validation: 6.135929097057481]
	TIME [epoch: 9.55 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.111232720269311		[learning rate: 0.0093867]
	Learning Rate: 0.0093867
	LOSS [training: 4.111232720269311 | validation: 6.090068978636166]
	TIME [epoch: 9.56 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.092416941904213		[learning rate: 0.0093646]
	Learning Rate: 0.00936456
	LOSS [training: 4.092416941904213 | validation: 5.631145837990138]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7220847964119614		[learning rate: 0.0093425]
	Learning Rate: 0.00934247
	LOSS [training: 3.7220847964119614 | validation: 6.2639500356514075]
	TIME [epoch: 9.55 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.954356193672558		[learning rate: 0.0093204]
	Learning Rate: 0.00932043
	LOSS [training: 3.954356193672558 | validation: 5.777648562595289]
	TIME [epoch: 9.56 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.138493790315855		[learning rate: 0.0092984]
	Learning Rate: 0.00929844
	LOSS [training: 4.138493790315855 | validation: 5.726204572865506]
	TIME [epoch: 9.57 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.876529197258668		[learning rate: 0.0092765]
	Learning Rate: 0.00927651
	LOSS [training: 4.876529197258668 | validation: 6.182102309110656]
	TIME [epoch: 9.58 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.722945738255037		[learning rate: 0.0092546]
	Learning Rate: 0.00925463
	LOSS [training: 4.722945738255037 | validation: 6.1885625942959]
	TIME [epoch: 9.56 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.135179945228314		[learning rate: 0.0092328]
	Learning Rate: 0.0092328
	LOSS [training: 4.135179945228314 | validation: 6.095657422504424]
	TIME [epoch: 9.57 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.004837293324323		[learning rate: 0.009211]
	Learning Rate: 0.00921102
	LOSS [training: 4.004837293324323 | validation: 5.5568325134854035]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.046555125461379		[learning rate: 0.0091893]
	Learning Rate: 0.00918929
	LOSS [training: 4.046555125461379 | validation: 5.559016622836365]
	TIME [epoch: 9.56 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.227076213489449		[learning rate: 0.0091676]
	Learning Rate: 0.00916762
	LOSS [training: 4.227076213489449 | validation: 6.125087714242182]
	TIME [epoch: 9.55 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.042878959673526		[learning rate: 0.009146]
	Learning Rate: 0.00914599
	LOSS [training: 4.042878959673526 | validation: 5.845206518853877]
	TIME [epoch: 9.56 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8905081672088015		[learning rate: 0.0091244]
	Learning Rate: 0.00912442
	LOSS [training: 3.8905081672088015 | validation: 5.567342439091637]
	TIME [epoch: 9.59 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.1506724755417626		[learning rate: 0.0091029]
	Learning Rate: 0.00910289
	LOSS [training: 4.1506724755417626 | validation: 5.541568159403282]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7705515574656205		[learning rate: 0.0090814]
	Learning Rate: 0.00908142
	LOSS [training: 3.7705515574656205 | validation: 5.813691623237944]
	TIME [epoch: 9.56 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.802704658152133		[learning rate: 0.00906]
	Learning Rate: 0.00906
	LOSS [training: 3.802704658152133 | validation: 5.563350211202089]
	TIME [epoch: 9.56 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.1720679554697595		[learning rate: 0.0090386]
	Learning Rate: 0.00903863
	LOSS [training: 4.1720679554697595 | validation: 6.196812138115787]
	TIME [epoch: 9.58 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.905182070503033		[learning rate: 0.0090173]
	Learning Rate: 0.00901731
	LOSS [training: 3.905182070503033 | validation: 5.432197986414028]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.852699427432893		[learning rate: 0.008996]
	Learning Rate: 0.00899604
	LOSS [training: 3.852699427432893 | validation: 5.701842898338714]
	TIME [epoch: 9.56 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.814483086018613		[learning rate: 0.0089748]
	Learning Rate: 0.00897482
	LOSS [training: 3.814483086018613 | validation: 6.051124418946979]
	TIME [epoch: 9.58 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.885046090416816		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 3.885046090416816 | validation: 5.727132773918318]
	TIME [epoch: 9.58 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.986779216826097		[learning rate: 0.0089325]
	Learning Rate: 0.00893253
	LOSS [training: 3.986779216826097 | validation: 5.7091049779571525]
	TIME [epoch: 9.56 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7234904810655296		[learning rate: 0.0089115]
	Learning Rate: 0.00891146
	LOSS [training: 3.7234904810655296 | validation: 5.3910725251280995]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.692323584747709		[learning rate: 0.0088904]
	Learning Rate: 0.00889044
	LOSS [training: 3.692323584747709 | validation: 5.623572420739984]
	TIME [epoch: 9.58 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9802697166678316		[learning rate: 0.0088695]
	Learning Rate: 0.00886946
	LOSS [training: 3.9802697166678316 | validation: 5.396886935035776]
	TIME [epoch: 9.57 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8653107112388865		[learning rate: 0.0088485]
	Learning Rate: 0.00884854
	LOSS [training: 3.8653107112388865 | validation: 5.900708476367578]
	TIME [epoch: 9.56 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.158849453728206		[learning rate: 0.0088277]
	Learning Rate: 0.00882767
	LOSS [training: 4.158849453728206 | validation: 5.406770919495663]
	TIME [epoch: 9.55 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8872625015122844		[learning rate: 0.0088068]
	Learning Rate: 0.00880685
	LOSS [training: 3.8872625015122844 | validation: 5.4214826581228595]
	TIME [epoch: 9.58 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9586973061252144		[learning rate: 0.0087861]
	Learning Rate: 0.00878607
	LOSS [training: 3.9586973061252144 | validation: 5.493481486914377]
	TIME [epoch: 9.56 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.850347195873887		[learning rate: 0.0087653]
	Learning Rate: 0.00876535
	LOSS [training: 3.850347195873887 | validation: 5.308878956450551]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.667204834133057		[learning rate: 0.0087447]
	Learning Rate: 0.00874467
	LOSS [training: 3.667204834133057 | validation: 5.628256343208789]
	TIME [epoch: 9.55 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.660033690464266		[learning rate: 0.008724]
	Learning Rate: 0.00872405
	LOSS [training: 4.660033690464266 | validation: 6.183217864778956]
	TIME [epoch: 9.58 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8692435656015904		[learning rate: 0.0087035]
	Learning Rate: 0.00870347
	LOSS [training: 3.8692435656015904 | validation: 5.372423096980385]
	TIME [epoch: 9.55 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.874917916558226		[learning rate: 0.0086829]
	Learning Rate: 0.00868294
	LOSS [training: 3.874917916558226 | validation: 5.486342223719371]
	TIME [epoch: 9.56 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5713339403071087		[learning rate: 0.0086625]
	Learning Rate: 0.00866246
	LOSS [training: 3.5713339403071087 | validation: 5.505510557052739]
	TIME [epoch: 9.57 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5478624969229235		[learning rate: 0.008642]
	Learning Rate: 0.00864202
	LOSS [training: 3.5478624969229235 | validation: 5.389181701366506]
	TIME [epoch: 9.57 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6855315914261295		[learning rate: 0.0086216]
	Learning Rate: 0.00862164
	LOSS [training: 3.6855315914261295 | validation: 5.139922436030548]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.500786863893164		[learning rate: 0.0086013]
	Learning Rate: 0.0086013
	LOSS [training: 3.500786863893164 | validation: 5.6837916303164775]
	TIME [epoch: 9.56 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9241705874680313		[learning rate: 0.008581]
	Learning Rate: 0.00858101
	LOSS [training: 3.9241705874680313 | validation: 5.697919793169344]
	TIME [epoch: 9.58 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8557108395767288		[learning rate: 0.0085608]
	Learning Rate: 0.00856077
	LOSS [training: 3.8557108395767288 | validation: 5.629515287200511]
	TIME [epoch: 9.57 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6497049976201597		[learning rate: 0.0085406]
	Learning Rate: 0.00854058
	LOSS [training: 3.6497049976201597 | validation: 4.973333020786562]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.364259466877713		[learning rate: 0.0085204]
	Learning Rate: 0.00852043
	LOSS [training: 3.364259466877713 | validation: 4.694705957069672]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3319868472328635		[learning rate: 0.0085003]
	Learning Rate: 0.00850033
	LOSS [training: 3.3319868472328635 | validation: 4.966093400656115]
	TIME [epoch: 9.58 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.696050197887465		[learning rate: 0.0084803]
	Learning Rate: 0.00848028
	LOSS [training: 3.696050197887465 | validation: 5.437728845640557]
	TIME [epoch: 9.55 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3746110576398727		[learning rate: 0.0084603]
	Learning Rate: 0.00846028
	LOSS [training: 3.3746110576398727 | validation: 5.495016477791016]
	TIME [epoch: 9.56 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4821582825669743		[learning rate: 0.0084403]
	Learning Rate: 0.00844032
	LOSS [training: 3.4821582825669743 | validation: 5.053409007478225]
	TIME [epoch: 9.56 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.274814290220543		[learning rate: 0.0084204]
	Learning Rate: 0.00842041
	LOSS [training: 3.274814290220543 | validation: 4.781872171962975]
	TIME [epoch: 9.58 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5020732513265775		[learning rate: 0.0084005]
	Learning Rate: 0.00840055
	LOSS [training: 3.5020732513265775 | validation: 4.6538117029324955]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2592774124608646		[learning rate: 0.0083807]
	Learning Rate: 0.00838073
	LOSS [training: 3.2592774124608646 | validation: 5.318965661300962]
	TIME [epoch: 9.58 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7316199827994447		[learning rate: 0.008361]
	Learning Rate: 0.00836096
	LOSS [training: 3.7316199827994447 | validation: 5.316930767391852]
	TIME [epoch: 9.58 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.340874677874779		[learning rate: 0.0083412]
	Learning Rate: 0.00834124
	LOSS [training: 3.340874677874779 | validation: 4.500811121276965]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.259110682833505		[learning rate: 0.0083216]
	Learning Rate: 0.00832157
	LOSS [training: 3.259110682833505 | validation: 4.288647661603297]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.921269718370143		[learning rate: 0.0083019]
	Learning Rate: 0.00830194
	LOSS [training: 2.921269718370143 | validation: 4.60082447258919]
	TIME [epoch: 9.55 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0403360336522134		[learning rate: 0.0082824]
	Learning Rate: 0.00828236
	LOSS [training: 3.0403360336522134 | validation: 4.227254153460063]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.877548628722363		[learning rate: 0.0082628]
	Learning Rate: 0.00826282
	LOSS [training: 2.877548628722363 | validation: 3.4818231930372656]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5784539657907786		[learning rate: 0.0082433]
	Learning Rate: 0.00824333
	LOSS [training: 3.5784539657907786 | validation: 4.596674554264125]
	TIME [epoch: 9.55 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0833940310707018		[learning rate: 0.0082239]
	Learning Rate: 0.00822388
	LOSS [training: 2.0833940310707018 | validation: 1.4302512065352935]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6257793859715615		[learning rate: 0.0082045]
	Learning Rate: 0.00820448
	LOSS [training: 2.6257793859715615 | validation: 1.5657616913806756]
	TIME [epoch: 9.58 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8426828300851543		[learning rate: 0.0081851]
	Learning Rate: 0.00818513
	LOSS [training: 1.8426828300851543 | validation: 1.2788728873592201]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2542245699881973		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 2.2542245699881973 | validation: 2.431777079345344]
	TIME [epoch: 9.56 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8617387025417607		[learning rate: 0.0081466]
	Learning Rate: 0.00814656
	LOSS [training: 1.8617387025417607 | validation: 2.1469207592195043]
	TIME [epoch: 9.57 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8032231767238067		[learning rate: 0.0081273]
	Learning Rate: 0.00812735
	LOSS [training: 1.8032231767238067 | validation: 1.9098243466847133]
	TIME [epoch: 9.56 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0664265932534747		[learning rate: 0.0081082]
	Learning Rate: 0.00810817
	LOSS [training: 2.0664265932534747 | validation: 2.1254903085258445]
	TIME [epoch: 9.55 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6955545466768283		[learning rate: 0.008089]
	Learning Rate: 0.00808905
	LOSS [training: 1.6955545466768283 | validation: 3.848974182650818]
	TIME [epoch: 9.55 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1024345921225374		[learning rate: 0.00807]
	Learning Rate: 0.00806997
	LOSS [training: 2.1024345921225374 | validation: 1.6517148632588403]
	TIME [epoch: 9.57 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.849211275741117		[learning rate: 0.0080509]
	Learning Rate: 0.00805093
	LOSS [training: 1.849211275741117 | validation: 2.16396290970049]
	TIME [epoch: 9.55 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0759338241882315		[learning rate: 0.0080319]
	Learning Rate: 0.00803194
	LOSS [training: 2.0759338241882315 | validation: 1.6662436073542883]
	TIME [epoch: 9.55 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7569578104405585		[learning rate: 0.008013]
	Learning Rate: 0.00801299
	LOSS [training: 1.7569578104405585 | validation: 1.799687279211837]
	TIME [epoch: 9.55 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4603289278028495		[learning rate: 0.0079941]
	Learning Rate: 0.00799409
	LOSS [training: 1.4603289278028495 | validation: 3.1331846502435874]
	TIME [epoch: 9.57 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.308336040563013		[learning rate: 0.0079752]
	Learning Rate: 0.00797524
	LOSS [training: 2.308336040563013 | validation: 1.8641560889532591]
	TIME [epoch: 9.55 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9904776432972606		[learning rate: 0.0079564]
	Learning Rate: 0.00795642
	LOSS [training: 1.9904776432972606 | validation: 2.3141348822965124]
	TIME [epoch: 9.55 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3171186667858348		[learning rate: 0.0079377]
	Learning Rate: 0.00793766
	LOSS [training: 1.3171186667858348 | validation: 1.0283229759359598]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3775614646739271		[learning rate: 0.0079189]
	Learning Rate: 0.00791893
	LOSS [training: 1.3775614646739271 | validation: 1.0923350496953723]
	TIME [epoch: 9.58 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0924233179244667		[learning rate: 0.0079003]
	Learning Rate: 0.00790025
	LOSS [training: 1.0924233179244667 | validation: 1.7717117990541895]
	TIME [epoch: 9.55 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6151455569574389		[learning rate: 0.0078816]
	Learning Rate: 0.00788162
	LOSS [training: 1.6151455569574389 | validation: 2.3041039178641882]
	TIME [epoch: 9.55 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5840208080386655		[learning rate: 0.007863]
	Learning Rate: 0.00786303
	LOSS [training: 1.5840208080386655 | validation: 1.2908441570366]
	TIME [epoch: 9.56 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3291259233243593		[learning rate: 0.0078445]
	Learning Rate: 0.00784448
	LOSS [training: 1.3291259233243593 | validation: 1.6523539020709572]
	TIME [epoch: 9.56 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4247825323095622		[learning rate: 0.007826]
	Learning Rate: 0.00782597
	LOSS [training: 1.4247825323095622 | validation: 0.9712967012817805]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4460999761722824		[learning rate: 0.0078075]
	Learning Rate: 0.00780751
	LOSS [training: 2.4460999761722824 | validation: 2.145115988492835]
	TIME [epoch: 9.55 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8624974141365545		[learning rate: 0.0077891]
	Learning Rate: 0.0077891
	LOSS [training: 1.8624974141365545 | validation: 1.7560473223965647]
	TIME [epoch: 9.57 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.252564637553678		[learning rate: 0.0077707]
	Learning Rate: 0.00777072
	LOSS [training: 2.252564637553678 | validation: 2.533402662790648]
	TIME [epoch: 9.55 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7813436831896148		[learning rate: 0.0077524]
	Learning Rate: 0.00775239
	LOSS [training: 1.7813436831896148 | validation: 0.8465031024327749]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9533828891074112		[learning rate: 0.0077341]
	Learning Rate: 0.00773411
	LOSS [training: 0.9533828891074112 | validation: 4.291769709168719]
	TIME [epoch: 9.55 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3316424931596353		[learning rate: 0.0077159]
	Learning Rate: 0.00771586
	LOSS [training: 2.3316424931596353 | validation: 1.3081673283185198]
	TIME [epoch: 9.58 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.55501571331074		[learning rate: 0.0076977]
	Learning Rate: 0.00769766
	LOSS [training: 1.55501571331074 | validation: 1.6457134095452532]
	TIME [epoch: 9.55 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3579606047973907		[learning rate: 0.0076795]
	Learning Rate: 0.00767951
	LOSS [training: 1.3579606047973907 | validation: 3.4334301696428033]
	TIME [epoch: 9.55 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0378303300346343		[learning rate: 0.0076614]
	Learning Rate: 0.00766139
	LOSS [training: 2.0378303300346343 | validation: 1.011108154378302]
	TIME [epoch: 9.55 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3720881747221902		[learning rate: 0.0076433]
	Learning Rate: 0.00764332
	LOSS [training: 2.3720881747221902 | validation: 1.7893208242886243]
	TIME [epoch: 9.57 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7911841552165246		[learning rate: 0.0076253]
	Learning Rate: 0.00762529
	LOSS [training: 1.7911841552165246 | validation: 1.0898466144976688]
	TIME [epoch: 9.54 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4303397918833893		[learning rate: 0.0076073]
	Learning Rate: 0.0076073
	LOSS [training: 1.4303397918833893 | validation: 0.9496223379088307]
	TIME [epoch: 9.55 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2041065501534125		[learning rate: 0.0075894]
	Learning Rate: 0.00758936
	LOSS [training: 1.2041065501534125 | validation: 1.6959215159114092]
	TIME [epoch: 9.56 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5757978983924414		[learning rate: 0.0075715]
	Learning Rate: 0.00757146
	LOSS [training: 1.5757978983924414 | validation: 1.5066683344426883]
	TIME [epoch: 9.58 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3653811408191732		[learning rate: 0.0075536]
	Learning Rate: 0.0075536
	LOSS [training: 1.3653811408191732 | validation: 1.1186873429060387]
	TIME [epoch: 9.56 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.351098424844341		[learning rate: 0.0075358]
	Learning Rate: 0.00753578
	LOSS [training: 1.351098424844341 | validation: 1.5720808545001506]
	TIME [epoch: 9.54 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3822220384954833		[learning rate: 0.007518]
	Learning Rate: 0.007518
	LOSS [training: 1.3822220384954833 | validation: 1.3741322928658468]
	TIME [epoch: 9.57 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1931406672827143		[learning rate: 0.0075003]
	Learning Rate: 0.00750027
	LOSS [training: 1.1931406672827143 | validation: 2.298354191134354]
	TIME [epoch: 9.56 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8527984269527231		[learning rate: 0.0074826]
	Learning Rate: 0.00748258
	LOSS [training: 1.8527984269527231 | validation: 1.1423951974787494]
	TIME [epoch: 9.55 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4717907012401086		[learning rate: 0.0074649]
	Learning Rate: 0.00746493
	LOSS [training: 1.4717907012401086 | validation: 2.2583815050059646]
	TIME [epoch: 9.55 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3673095112104934		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 1.3673095112104934 | validation: 0.8623034036664194]
	TIME [epoch: 9.57 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.196707451916474		[learning rate: 0.0074298]
	Learning Rate: 0.00742975
	LOSS [training: 1.196707451916474 | validation: 1.0938272818995558]
	TIME [epoch: 9.55 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6445800012731873		[learning rate: 0.0074122]
	Learning Rate: 0.00741223
	LOSS [training: 1.6445800012731873 | validation: 2.4412516335572367]
	TIME [epoch: 9.55 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5011976354650134		[learning rate: 0.0073947]
	Learning Rate: 0.00739474
	LOSS [training: 1.5011976354650134 | validation: 2.199288705436]
	TIME [epoch: 9.55 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7125853031538594		[learning rate: 0.0073773]
	Learning Rate: 0.0073773
	LOSS [training: 1.7125853031538594 | validation: 2.0574429185431207]
	TIME [epoch: 9.57 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6409753343023727		[learning rate: 0.0073599]
	Learning Rate: 0.0073599
	LOSS [training: 1.6409753343023727 | validation: 2.0027124871567024]
	TIME [epoch: 9.55 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.584547146608183		[learning rate: 0.0073425]
	Learning Rate: 0.00734254
	LOSS [training: 3.584547146608183 | validation: 2.3678033929920743]
	TIME [epoch: 9.55 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.045194119767579		[learning rate: 0.0073252]
	Learning Rate: 0.00732522
	LOSS [training: 2.045194119767579 | validation: 2.0770660723601404]
	TIME [epoch: 9.55 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.566157201633151		[learning rate: 0.0073079]
	Learning Rate: 0.00730794
	LOSS [training: 1.566157201633151 | validation: 0.8148650964999375]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1950849250285596		[learning rate: 0.0072907]
	Learning Rate: 0.0072907
	LOSS [training: 1.1950849250285596 | validation: 1.1316813724955979]
	TIME [epoch: 9.56 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7956423218160704		[learning rate: 0.0072735]
	Learning Rate: 0.0072735
	LOSS [training: 1.7956423218160704 | validation: 0.8777069515625204]
	TIME [epoch: 9.55 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5867785725371768		[learning rate: 0.0072563]
	Learning Rate: 0.00725635
	LOSS [training: 1.5867785725371768 | validation: 1.093568603764855]
	TIME [epoch: 9.57 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1863522309875587		[learning rate: 0.0072392]
	Learning Rate: 0.00723923
	LOSS [training: 1.1863522309875587 | validation: 1.9527833025610972]
	TIME [epoch: 9.55 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.509426794792059		[learning rate: 0.0072222]
	Learning Rate: 0.00722215
	LOSS [training: 1.509426794792059 | validation: 1.2855931079203184]
	TIME [epoch: 9.55 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1285055067085334		[learning rate: 0.0072051]
	Learning Rate: 0.00720512
	LOSS [training: 1.1285055067085334 | validation: 0.8044976692574578]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5046950025056183		[learning rate: 0.0071881]
	Learning Rate: 0.00718812
	LOSS [training: 1.5046950025056183 | validation: 1.7615282488268338]
	TIME [epoch: 9.58 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2425125862032278		[learning rate: 0.0071712]
	Learning Rate: 0.00717117
	LOSS [training: 1.2425125862032278 | validation: 1.2344709230741615]
	TIME [epoch: 9.55 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4516160497055668		[learning rate: 0.0071542]
	Learning Rate: 0.00715425
	LOSS [training: 1.4516160497055668 | validation: 2.1676230841535467]
	TIME [epoch: 9.55 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.047725482636872		[learning rate: 0.0071374]
	Learning Rate: 0.00713737
	LOSS [training: 2.047725482636872 | validation: 2.1334600186547483]
	TIME [epoch: 9.56 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.453304645659268		[learning rate: 0.0071205]
	Learning Rate: 0.00712054
	LOSS [training: 1.453304645659268 | validation: 2.4224197604833893]
	TIME [epoch: 9.58 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0175778138238596		[learning rate: 0.0071037]
	Learning Rate: 0.00710374
	LOSS [training: 2.0175778138238596 | validation: 2.3972036250111612]
	TIME [epoch: 9.55 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9307626447748554		[learning rate: 0.007087]
	Learning Rate: 0.00708698
	LOSS [training: 1.9307626447748554 | validation: 1.7461456120618732]
	TIME [epoch: 9.55 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5579438297939343		[learning rate: 0.0070703]
	Learning Rate: 0.00707027
	LOSS [training: 1.5579438297939343 | validation: 1.4773256698331312]
	TIME [epoch: 9.56 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4075816507967809		[learning rate: 0.0070536]
	Learning Rate: 0.00705359
	LOSS [training: 1.4075816507967809 | validation: 1.4128151656839465]
	TIME [epoch: 9.57 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3293139594585903		[learning rate: 0.007037]
	Learning Rate: 0.00703695
	LOSS [training: 1.3293139594585903 | validation: 1.750085357938232]
	TIME [epoch: 9.54 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3453678309242254		[learning rate: 0.0070204]
	Learning Rate: 0.00702035
	LOSS [training: 1.3453678309242254 | validation: 1.6151823917988213]
	TIME [epoch: 9.55 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3191764242023905		[learning rate: 0.0070038]
	Learning Rate: 0.00700379
	LOSS [training: 1.3191764242023905 | validation: 2.0513251390180436]
	TIME [epoch: 9.56 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7214299470039314		[learning rate: 0.0069873]
	Learning Rate: 0.00698727
	LOSS [training: 1.7214299470039314 | validation: 2.371851747499089]
	TIME [epoch: 9.56 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6698048131884107		[learning rate: 0.0069708]
	Learning Rate: 0.00697079
	LOSS [training: 1.6698048131884107 | validation: 1.7344239963208627]
	TIME [epoch: 9.55 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0149648870573245		[learning rate: 0.0069543]
	Learning Rate: 0.00695435
	LOSS [training: 2.0149648870573245 | validation: 2.0295349450272018]
	TIME [epoch: 9.56 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.610696882518551		[learning rate: 0.0069379]
	Learning Rate: 0.00693794
	LOSS [training: 1.610696882518551 | validation: 1.875548578284703]
	TIME [epoch: 9.57 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5227249914704932		[learning rate: 0.0069216]
	Learning Rate: 0.00692158
	LOSS [training: 1.5227249914704932 | validation: 1.811006058007349]
	TIME [epoch: 9.56 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8787463046571156		[learning rate: 0.0069053]
	Learning Rate: 0.00690525
	LOSS [training: 1.8787463046571156 | validation: 2.0202567724622478]
	TIME [epoch: 9.54 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7115097170739588		[learning rate: 0.006889]
	Learning Rate: 0.00688896
	LOSS [training: 1.7115097170739588 | validation: 1.8203648992314225]
	TIME [epoch: 9.55 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5817821046143588		[learning rate: 0.0068727]
	Learning Rate: 0.00687271
	LOSS [training: 1.5817821046143588 | validation: 1.963198357815842]
	TIME [epoch: 9.58 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6788949103717044		[learning rate: 0.0068565]
	Learning Rate: 0.0068565
	LOSS [training: 1.6788949103717044 | validation: 2.040466013681103]
	TIME [epoch: 9.54 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7001400924994776		[learning rate: 0.0068403]
	Learning Rate: 0.00684033
	LOSS [training: 1.7001400924994776 | validation: 2.692894560615295]
	TIME [epoch: 9.55 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0217437027883554		[learning rate: 0.0068242]
	Learning Rate: 0.00682419
	LOSS [training: 2.0217437027883554 | validation: 1.7810619417958782]
	TIME [epoch: 9.55 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.621679453454195		[learning rate: 0.0068081]
	Learning Rate: 0.0068081
	LOSS [training: 1.621679453454195 | validation: 1.831875340742152]
	TIME [epoch: 9.57 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5840840838483172		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 1.5840840838483172 | validation: 1.9443383224902635]
	TIME [epoch: 9.55 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6933174339017358		[learning rate: 0.006776]
	Learning Rate: 0.00677601
	LOSS [training: 1.6933174339017358 | validation: 1.7701826017106885]
	TIME [epoch: 9.55 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6636157375387808		[learning rate: 0.00676]
	Learning Rate: 0.00676003
	LOSS [training: 1.6636157375387808 | validation: 1.6693044583604013]
	TIME [epoch: 9.56 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6267119529569878		[learning rate: 0.0067441]
	Learning Rate: 0.00674409
	LOSS [training: 1.6267119529569878 | validation: 1.6229345375060549]
	TIME [epoch: 9.57 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.382716551188053		[learning rate: 0.0067282]
	Learning Rate: 0.00672818
	LOSS [training: 1.382716551188053 | validation: 1.355072632050705]
	TIME [epoch: 9.55 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0424972660363925		[learning rate: 0.0067123]
	Learning Rate: 0.00671231
	LOSS [training: 1.0424972660363925 | validation: 0.7360983108564912]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1120635309677347		[learning rate: 0.0066965]
	Learning Rate: 0.00669647
	LOSS [training: 1.1120635309677347 | validation: 0.7936135217581459]
	TIME [epoch: 9.59 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.21899707516117		[learning rate: 0.0066807]
	Learning Rate: 0.00668068
	LOSS [training: 1.21899707516117 | validation: 1.2525746923586178]
	TIME [epoch: 9.56 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2132833913983703		[learning rate: 0.0066649]
	Learning Rate: 0.00666492
	LOSS [training: 1.2132833913983703 | validation: 1.208248268993727]
	TIME [epoch: 9.57 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.201003398714104		[learning rate: 0.0066492]
	Learning Rate: 0.0066492
	LOSS [training: 1.201003398714104 | validation: 1.4301897437117361]
	TIME [epoch: 9.56 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.857395300554772		[learning rate: 0.0066335]
	Learning Rate: 0.00663351
	LOSS [training: 1.857395300554772 | validation: 1.751062948908796]
	TIME [epoch: 9.59 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7127694683217212		[learning rate: 0.0066179]
	Learning Rate: 0.00661787
	LOSS [training: 1.7127694683217212 | validation: 1.7864123327372932]
	TIME [epoch: 9.56 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.572706331526528		[learning rate: 0.0066023]
	Learning Rate: 0.00660226
	LOSS [training: 1.572706331526528 | validation: 1.9504858030684096]
	TIME [epoch: 9.56 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5781684654286798		[learning rate: 0.0065867]
	Learning Rate: 0.00658668
	LOSS [training: 1.5781684654286798 | validation: 1.949085921198548]
	TIME [epoch: 9.56 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4455228562684972		[learning rate: 0.0065711]
	Learning Rate: 0.00657114
	LOSS [training: 1.4455228562684972 | validation: 1.4398161515351715]
	TIME [epoch: 9.58 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.486469556694967		[learning rate: 0.0065556]
	Learning Rate: 0.00655564
	LOSS [training: 1.486469556694967 | validation: 1.9633017469208154]
	TIME [epoch: 9.56 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7761994772647653		[learning rate: 0.0065402]
	Learning Rate: 0.00654018
	LOSS [training: 1.7761994772647653 | validation: 1.800500153371792]
	TIME [epoch: 9.56 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.472306122072119		[learning rate: 0.0065248]
	Learning Rate: 0.00652475
	LOSS [training: 1.472306122072119 | validation: 1.463818080235896]
	TIME [epoch: 9.55 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.085383496950839		[learning rate: 0.0065094]
	Learning Rate: 0.00650936
	LOSS [training: 1.085383496950839 | validation: 2.2211649457954543]
	TIME [epoch: 9.58 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.460541439007908		[learning rate: 0.006494]
	Learning Rate: 0.00649401
	LOSS [training: 1.460541439007908 | validation: 0.8524012518883086]
	TIME [epoch: 9.55 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4178336958208249		[learning rate: 0.0064787]
	Learning Rate: 0.00647869
	LOSS [training: 1.4178336958208249 | validation: 2.0506177791960063]
	TIME [epoch: 9.55 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6596865056727956		[learning rate: 0.0064634]
	Learning Rate: 0.00646341
	LOSS [training: 1.6596865056727956 | validation: 1.1405837539187693]
	TIME [epoch: 9.58 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1385525196758266		[learning rate: 0.0064482]
	Learning Rate: 0.00644816
	LOSS [training: 1.1385525196758266 | validation: 0.920211311737944]
	TIME [epoch: 9.57 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1150392322038614		[learning rate: 0.006433]
	Learning Rate: 0.00643295
	LOSS [training: 1.1150392322038614 | validation: 1.1442733325076784]
	TIME [epoch: 9.56 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2711511669168125		[learning rate: 0.0064178]
	Learning Rate: 0.00641778
	LOSS [training: 1.2711511669168125 | validation: 1.8906238853787734]
	TIME [epoch: 9.56 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.370172944977174		[learning rate: 0.0064026]
	Learning Rate: 0.00640264
	LOSS [training: 1.370172944977174 | validation: 0.9410667107114943]
	TIME [epoch: 9.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.172015505085572		[learning rate: 0.0063875]
	Learning Rate: 0.00638754
	LOSS [training: 1.172015505085572 | validation: 2.4385231399296736]
	TIME [epoch: 9.57 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.56577933305635		[learning rate: 0.0063725]
	Learning Rate: 0.00637247
	LOSS [training: 1.56577933305635 | validation: 1.3189598572540628]
	TIME [epoch: 9.57 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1732463221308145		[learning rate: 0.0063574]
	Learning Rate: 0.00635744
	LOSS [training: 1.1732463221308145 | validation: 1.1534780430944396]
	TIME [epoch: 9.57 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2659718016793315		[learning rate: 0.0063424]
	Learning Rate: 0.00634244
	LOSS [training: 1.2659718016793315 | validation: 0.7353534933847732]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0160519021901093		[learning rate: 0.0063275]
	Learning Rate: 0.00632748
	LOSS [training: 1.0160519021901093 | validation: 1.2134394145932792]
	TIME [epoch: 9.56 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9656311507973067		[learning rate: 0.0063126]
	Learning Rate: 0.00631255
	LOSS [training: 0.9656311507973067 | validation: 0.6800423218572069]
	TIME [epoch: 9.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240219_184940/states/model_tr_study5_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.976185477090698		[learning rate: 0.0062977]
	Learning Rate: 0.00629766
	LOSS [training: 0.976185477090698 | validation: 0.9173291120047287]
	TIME [epoch: 9.58 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3774857773350633		[learning rate: 0.0062828]
	Learning Rate: 0.00628281
	LOSS [training: 1.3774857773350633 | validation: 1.117980560901951]
	TIME [epoch: 9.58 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.324354342026456		[learning rate: 0.006268]
	Learning Rate: 0.00626799
	LOSS [training: 1.324354342026456 | validation: 1.0390286409119702]
	TIME [epoch: 9.57 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.043313212233967		[learning rate: 0.0062532]
	Learning Rate: 0.0062532
	LOSS [training: 1.043313212233967 | validation: 1.2685400971843908]
	TIME [epoch: 9.57 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0460783494661912		[learning rate: 0.0062385]
	Learning Rate: 0.00623845
	LOSS [training: 1.0460783494661912 | validation: 1.255412244370689]
	TIME [epoch: 9.58 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9503737791165218		[learning rate: 0.0062237]
	Learning Rate: 0.00622374
	LOSS [training: 0.9503737791165218 | validation: 1.2475447884362962]
	TIME [epoch: 9.57 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9571390482851282		[learning rate: 0.0062091]
	Learning Rate: 0.00620906
	LOSS [training: 0.9571390482851282 | validation: 0.8930980661640787]
	TIME [epoch: 9.57 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0171824594511643		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 1.0171824594511643 | validation: 1.1432041595646845]
	TIME [epoch: 9.57 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9738339690723304		[learning rate: 0.0061798]
	Learning Rate: 0.0061798
	LOSS [training: 0.9738339690723304 | validation: 1.0734157935089008]
	TIME [epoch: 9.61 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0348325913272414		[learning rate: 0.0061652]
	Learning Rate: 0.00616522
	LOSS [training: 1.0348325913272414 | validation: 1.839042221756277]
	TIME [epoch: 9.56 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2208325277825387		[learning rate: 0.0061507]
	Learning Rate: 0.00615068
	LOSS [training: 1.2208325277825387 | validation: 1.5193052360502635]
	TIME [epoch: 9.56 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1633455644459663		[learning rate: 0.0061362]
	Learning Rate: 0.00613617
	LOSS [training: 1.1633455644459663 | validation: 1.4640387152705432]
	TIME [epoch: 9.56 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3080210755168447		[learning rate: 0.0061217]
	Learning Rate: 0.0061217
	LOSS [training: 1.3080210755168447 | validation: 1.708002616630608]
	TIME [epoch: 9.61 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2438322561073603		[learning rate: 0.0061073]
	Learning Rate: 0.00610726
	LOSS [training: 1.2438322561073603 | validation: 1.459360169209202]
	TIME [epoch: 9.54 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2382882260169428		[learning rate: 0.0060929]
	Learning Rate: 0.00609285
	LOSS [training: 1.2382882260169428 | validation: 1.9992332532866164]
	TIME [epoch: 9.56 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6380518682016192		[learning rate: 0.0060785]
	Learning Rate: 0.00607848
	LOSS [training: 1.6380518682016192 | validation: 1.623058036555621]
	TIME [epoch: 9.56 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3448771351253845		[learning rate: 0.0060641]
	Learning Rate: 0.00606414
	LOSS [training: 1.3448771351253845 | validation: 0.9198991278353168]
	TIME [epoch: 9.61 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.327495762204873		[learning rate: 0.0060498]
	Learning Rate: 0.00604984
	LOSS [training: 1.327495762204873 | validation: 1.374900784067987]
	TIME [epoch: 9.56 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1534980745661811		[learning rate: 0.0060356]
	Learning Rate: 0.00603556
	LOSS [training: 1.1534980745661811 | validation: 0.7024709211947077]
	TIME [epoch: 9.57 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7838902895432194		[learning rate: 0.0060213]
	Learning Rate: 0.00602133
	LOSS [training: 0.7838902895432194 | validation: 0.7731357377910762]
	TIME [epoch: 9.57 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0137628249528097		[learning rate: 0.0060071]
	Learning Rate: 0.00600712
	LOSS [training: 1.0137628249528097 | validation: 0.848783660064579]
	TIME [epoch: 9.59 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5102551366028842		[learning rate: 0.005993]
	Learning Rate: 0.00599296
	LOSS [training: 1.5102551366028842 | validation: 1.2922023310289896]
	TIME [epoch: 9.56 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2602109538414317		[learning rate: 0.0059788]
	Learning Rate: 0.00597882
	LOSS [training: 1.2602109538414317 | validation: 0.9929899473041053]
	TIME [epoch: 9.58 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.114891028575816		[learning rate: 0.0059647]
	Learning Rate: 0.00596472
	LOSS [training: 1.114891028575816 | validation: 1.2852613240088548]
	TIME [epoch: 9.59 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0210398282666666		[learning rate: 0.0059506]
	Learning Rate: 0.00595065
	LOSS [training: 1.0210398282666666 | validation: 1.2570025727162457]
	TIME [epoch: 9.56 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.164758102131082		[learning rate: 0.0059366]
	Learning Rate: 0.00593661
	LOSS [training: 1.164758102131082 | validation: 1.6369755363863931]
	TIME [epoch: 9.56 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2906576805989047		[learning rate: 0.0059226]
	Learning Rate: 0.00592261
	LOSS [training: 1.2906576805989047 | validation: 1.2838655146893667]
	TIME [epoch: 9.56 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0917304473365372		[learning rate: 0.0059086]
	Learning Rate: 0.00590863
	LOSS [training: 1.0917304473365372 | validation: 0.9016609336526837]
	TIME [epoch: 9.58 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0654550924294348		[learning rate: 0.0058947]
	Learning Rate: 0.0058947
	LOSS [training: 1.0654550924294348 | validation: 1.0653587785363572]
	TIME [epoch: 9.56 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5262279348171286		[learning rate: 0.0058808]
	Learning Rate: 0.00588079
	LOSS [training: 1.5262279348171286 | validation: 1.7494954890422951]
	TIME [epoch: 9.56 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0197186986230666		[learning rate: 0.0058669]
	Learning Rate: 0.00586692
	LOSS [training: 1.0197186986230666 | validation: 0.9745002415933504]
	TIME [epoch: 9.56 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4518746267805234		[learning rate: 0.0058531]
	Learning Rate: 0.00585308
	LOSS [training: 1.4518746267805234 | validation: 1.5078221825867804]
	TIME [epoch: 9.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1880005229495327		[learning rate: 0.0058393]
	Learning Rate: 0.00583928
	LOSS [training: 1.1880005229495327 | validation: 2.03589145012633]
	TIME [epoch: 9.56 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3287700058333605		[learning rate: 0.0058255]
	Learning Rate: 0.0058255
	LOSS [training: 1.3287700058333605 | validation: 1.3404398973430116]
	TIME [epoch: 9.56 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2047596360503183		[learning rate: 0.0058118]
	Learning Rate: 0.00581176
	LOSS [training: 1.2047596360503183 | validation: 1.3703050118822415]
	TIME [epoch: 9.56 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1635567296201876		[learning rate: 0.0057981]
	Learning Rate: 0.00579805
	LOSS [training: 1.1635567296201876 | validation: 1.99462606056588]
	TIME [epoch: 9.57 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1553391465693168		[learning rate: 0.0057844]
	Learning Rate: 0.00578438
	LOSS [training: 1.1553391465693168 | validation: 0.9883638575219404]
	TIME [epoch: 9.55 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0831271163442842		[learning rate: 0.0057707]
	Learning Rate: 0.00577073
	LOSS [training: 1.0831271163442842 | validation: 1.2382935793776069]
	TIME [epoch: 9.56 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2696810275597836		[learning rate: 0.0057571]
	Learning Rate: 0.00575712
	LOSS [training: 1.2696810275597836 | validation: 1.3892592015901786]
	TIME [epoch: 9.56 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.099249346269478		[learning rate: 0.0057435]
	Learning Rate: 0.00574354
	LOSS [training: 1.099249346269478 | validation: 1.0022099353831708]
	TIME [epoch: 9.57 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9175265434587108		[learning rate: 0.00573]
	Learning Rate: 0.00572999
	LOSS [training: 0.9175265434587108 | validation: 2.2974396864272535]
	TIME [epoch: 9.55 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2325811852988129		[learning rate: 0.0057165]
	Learning Rate: 0.00571647
	LOSS [training: 1.2325811852988129 | validation: 0.9487316112399704]
	TIME [epoch: 9.55 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0093266606485591		[learning rate: 0.005703]
	Learning Rate: 0.00570299
	LOSS [training: 1.0093266606485591 | validation: 0.9258820082221695]
	TIME [epoch: 9.58 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9716084347703553		[learning rate: 0.0056895]
	Learning Rate: 0.00568954
	LOSS [training: 0.9716084347703553 | validation: 0.9170983011171043]
	TIME [epoch: 9.56 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8376855782161303		[learning rate: 0.0056761]
	Learning Rate: 0.00567612
	LOSS [training: 0.8376855782161303 | validation: 1.0154734271549166]
	TIME [epoch: 9.56 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.972441536004624		[learning rate: 0.0056627]
	Learning Rate: 0.00566273
	LOSS [training: 0.972441536004624 | validation: 1.038624244059927]
	TIME [epoch: 9.56 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9378354673963514		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 0.9378354673963514 | validation: 0.8193029633385092]
	TIME [epoch: 9.58 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8211025546194664		[learning rate: 0.005636]
	Learning Rate: 0.00563604
	LOSS [training: 0.8211025546194664 | validation: 1.0525263356713925]
	TIME [epoch: 9.55 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3392407280087937		[learning rate: 0.0056227]
	Learning Rate: 0.00562275
	LOSS [training: 1.3392407280087937 | validation: 1.2173394303510692]
	TIME [epoch: 9.56 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1489489527515055		[learning rate: 0.0056095]
	Learning Rate: 0.00560949
	LOSS [training: 1.1489489527515055 | validation: 0.7813047632196388]
	TIME [epoch: 9.57 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9591947367081912		[learning rate: 0.0055963]
	Learning Rate: 0.00559625
	LOSS [training: 0.9591947367081912 | validation: 1.0454550679816417]
	TIME [epoch: 9.58 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9454906430066184		[learning rate: 0.0055831]
	Learning Rate: 0.00558305
	LOSS [training: 0.9454906430066184 | validation: 1.6455247530996537]
	TIME [epoch: 9.55 sec]
EPOCH 298/2000:
	Training over batches...
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.05
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.025
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.0125
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.00625
