Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r0', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 739022494

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 5/5] avg loss: 11.939565443937072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.939565443937072 | validation: 10.461962454846974]
	TIME [epoch: 80 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 5/5] avg loss: 11.646707299533862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.646707299533862 | validation: 10.041897572911378]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 5/5] avg loss: 11.014409484226865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.014409484226865 | validation: 9.818105688889116]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.82557544666468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.82557544666468 | validation: 9.55502540374453]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.662440661490615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.662440661490615 | validation: 9.752170056176947]
	TIME [epoch: 9.72 sec]
EPOCH 6/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.688489376729951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.688489376729951 | validation: 9.533632491459313]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.540296724294276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.540296724294276 | validation: 8.963128091112038]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.358211200221955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.358211200221955 | validation: 8.579631349225552]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.298970435769638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.298970435769638 | validation: 9.055457454245689]
	TIME [epoch: 9.72 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.380029469096854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.380029469096854 | validation: 8.076761587420542]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.071014057408174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.071014057408174 | validation: 7.879595946585915]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.969799253272996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.969799253272996 | validation: 7.974263979628911]
	TIME [epoch: 9.73 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.884395302690251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.884395302690251 | validation: 7.828111081705875]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.869010705943749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.869010705943749 | validation: 7.6445006771416955]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.764574391844851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.764574391844851 | validation: 7.9065261936914455]
	TIME [epoch: 9.71 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.195622159938948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.195622159938948 | validation: 7.686784821626818]
	TIME [epoch: 9.71 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.610502143027082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.610502143027082 | validation: 7.462635023845315]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.501570199508308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.501570199508308 | validation: 7.411680411762687]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.450615112188371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.450615112188371 | validation: 8.749483102861511]
	TIME [epoch: 9.73 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.845929847303408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.845929847303408 | validation: 8.994432409299106]
	TIME [epoch: 9.7 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.39154512955072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.39154512955072 | validation: 7.4754365563729515]
	TIME [epoch: 9.69 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.285351058146516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.285351058146516 | validation: 8.362115600898914]
	TIME [epoch: 9.69 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.78510648613381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.78510648613381 | validation: 8.791698879733651]
	TIME [epoch: 9.72 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.12170281965146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.12170281965146 | validation: 9.069099257824437]
	TIME [epoch: 9.69 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.943193571119952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.943193571119952 | validation: 8.133426628884845]
	TIME [epoch: 9.69 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.68108741363723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.68108741363723 | validation: 8.073081965177868]
	TIME [epoch: 9.72 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.580841954633746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.580841954633746 | validation: 8.31313555570687]
	TIME [epoch: 9.7 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.516004490624187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.516004490624187 | validation: 8.066520991759678]
	TIME [epoch: 9.68 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.394111351263037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.394111351263037 | validation: 8.256754997412955]
	TIME [epoch: 9.69 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.305917973833541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.305917973833541 | validation: 7.784849900440259]
	TIME [epoch: 9.72 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.67352722907164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.67352722907164 | validation: 8.431140976633296]
	TIME [epoch: 9.69 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.722014235792128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.722014235792128 | validation: 7.840122598226487]
	TIME [epoch: 9.7 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.3893881510427235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.3893881510427235 | validation: 7.6518761733113045]
	TIME [epoch: 9.72 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.245540635568088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.245540635568088 | validation: 7.210024913007615]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_34.pth
	Model improved!!!
EPOCH 35/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.145721157235343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.145721157235343 | validation: 7.3789385570140675]
	TIME [epoch: 9.69 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.89226093469199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.89226093469199 | validation: 7.1559684494801505]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.051670332392412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.051670332392412 | validation: 7.145057547329659]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_37.pth
	Model improved!!!
EPOCH 38/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.807277342370734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.807277342370734 | validation: 7.732130030837005]
	TIME [epoch: 9.69 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.001068082864267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.001068082864267 | validation: 7.177952668796374]
	TIME [epoch: 9.7 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.800280315188635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.800280315188635 | validation: 7.248151614994706]
	TIME [epoch: 9.72 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.715218605544064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.715218605544064 | validation: 7.308290520460915]
	TIME [epoch: 9.71 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.801133880677331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.801133880677331 | validation: 7.337510121254804]
	TIME [epoch: 9.69 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.81408168691482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.81408168691482 | validation: 7.137833942319294]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_43.pth
	Model improved!!!
EPOCH 44/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.853887611769403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.853887611769403 | validation: 7.2537642391177615]
	TIME [epoch: 9.72 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.781406566590819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.781406566590819 | validation: 7.134140483076351]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.659612409511925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.659612409511925 | validation: 7.153324714612341]
	TIME [epoch: 9.72 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.686656474697815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.686656474697815 | validation: 7.654826592800589]
	TIME [epoch: 9.72 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.761544543464844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.761544543464844 | validation: 7.187955334365287]
	TIME [epoch: 9.72 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.6894073144359485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6894073144359485 | validation: 7.142810947474536]
	TIME [epoch: 9.71 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.758498275868912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.758498275868912 | validation: 7.119403128834819]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_50.pth
	Model improved!!!
EPOCH 51/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.656207269903609		[learning rate: 0.0099613]
	Learning Rate: 0.00996129
	LOSS [training: 6.656207269903609 | validation: 7.2940905028781415]
	TIME [epoch: 9.73 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.710030620577591		[learning rate: 0.0099131]
	Learning Rate: 0.00991312
	LOSS [training: 6.710030620577591 | validation: 7.154807881469456]
	TIME [epoch: 9.71 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.624165541352271		[learning rate: 0.0098652]
	Learning Rate: 0.00986519
	LOSS [training: 6.624165541352271 | validation: 7.11407486030505]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_53.pth
	Model improved!!!
EPOCH 54/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.632227874378179		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 6.632227874378179 | validation: 7.298679651106706]
	TIME [epoch: 9.7 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.677123667280246		[learning rate: 0.00977]
	Learning Rate: 0.00977
	LOSS [training: 6.677123667280246 | validation: 7.146345309979649]
	TIME [epoch: 9.73 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.568187519151545		[learning rate: 0.0097228]
	Learning Rate: 0.00972276
	LOSS [training: 6.568187519151545 | validation: 7.14485522033115]
	TIME [epoch: 9.7 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.663673430262466		[learning rate: 0.0096757]
	Learning Rate: 0.00967574
	LOSS [training: 6.663673430262466 | validation: 7.222978051290182]
	TIME [epoch: 9.69 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.726025025070617		[learning rate: 0.009629]
	Learning Rate: 0.00962895
	LOSS [training: 6.726025025070617 | validation: 7.028497999153644]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_58.pth
	Model improved!!!
EPOCH 59/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.696842251865165		[learning rate: 0.0095824]
	Learning Rate: 0.00958239
	LOSS [training: 6.696842251865165 | validation: 7.135676689166004]
	TIME [epoch: 9.7 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.671407729968348		[learning rate: 0.009536]
	Learning Rate: 0.00953605
	LOSS [training: 6.671407729968348 | validation: 7.090837130726483]
	TIME [epoch: 9.69 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.673493623653336		[learning rate: 0.0094899]
	Learning Rate: 0.00948993
	LOSS [training: 6.673493623653336 | validation: 7.186330949403946]
	TIME [epoch: 9.7 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.524241320824757		[learning rate: 0.009444]
	Learning Rate: 0.00944404
	LOSS [training: 6.524241320824757 | validation: 6.954250189067084]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_62.pth
	Model improved!!!
EPOCH 63/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.438605002047703		[learning rate: 0.0093984]
	Learning Rate: 0.00939837
	LOSS [training: 7.438605002047703 | validation: 7.482167223531497]
	TIME [epoch: 9.71 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.752589115387177		[learning rate: 0.0093529]
	Learning Rate: 0.00935292
	LOSS [training: 6.752589115387177 | validation: 6.9404777939187055]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_64.pth
	Model improved!!!
EPOCH 65/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.496892586432258		[learning rate: 0.0093077]
	Learning Rate: 0.00930769
	LOSS [training: 6.496892586432258 | validation: 6.96950140588201]
	TIME [epoch: 9.71 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.443157119846234		[learning rate: 0.0092627]
	Learning Rate: 0.00926268
	LOSS [training: 6.443157119846234 | validation: 6.827079170647046]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_66.pth
	Model improved!!!
EPOCH 67/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.292246343957134		[learning rate: 0.0092179]
	Learning Rate: 0.00921789
	LOSS [training: 6.292246343957134 | validation: 6.586052487784693]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_67.pth
	Model improved!!!
EPOCH 68/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.3538388004971535		[learning rate: 0.0091733]
	Learning Rate: 0.00917332
	LOSS [training: 6.3538388004971535 | validation: 5.843338507592525]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_68.pth
	Model improved!!!
EPOCH 69/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.53230585891842		[learning rate: 0.009129]
	Learning Rate: 0.00912895
	LOSS [training: 5.53230585891842 | validation: 6.486049979429932]
	TIME [epoch: 9.71 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.86087462295613		[learning rate: 0.0090848]
	Learning Rate: 0.00908481
	LOSS [training: 5.86087462295613 | validation: 6.421413604797739]
	TIME [epoch: 9.72 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.690120602766404		[learning rate: 0.0090409]
	Learning Rate: 0.00904088
	LOSS [training: 6.690120602766404 | validation: 4.96215003445745]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_71.pth
	Model improved!!!
EPOCH 72/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.401679587261104		[learning rate: 0.0089972]
	Learning Rate: 0.00899716
	LOSS [training: 5.401679587261104 | validation: 4.809469407123269]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_72.pth
	Model improved!!!
EPOCH 73/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.2126056258638		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 5.2126056258638 | validation: 3.881368686824789]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_73.pth
	Model improved!!!
EPOCH 74/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.264589988847646		[learning rate: 0.0089103]
	Learning Rate: 0.00891035
	LOSS [training: 5.264589988847646 | validation: 5.232917878598005]
	TIME [epoch: 9.7 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.100721019571937		[learning rate: 0.0088673]
	Learning Rate: 0.00886726
	LOSS [training: 5.100721019571937 | validation: 4.0122419105179175]
	TIME [epoch: 9.7 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.08794184497823		[learning rate: 0.0088244]
	Learning Rate: 0.00882438
	LOSS [training: 5.08794184497823 | validation: 3.687895020341482]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_76.pth
	Model improved!!!
EPOCH 77/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.332230151435421		[learning rate: 0.0087817]
	Learning Rate: 0.00878171
	LOSS [training: 5.332230151435421 | validation: 6.0747175988898245]
	TIME [epoch: 9.73 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.198969519105945		[learning rate: 0.0087392]
	Learning Rate: 0.00873924
	LOSS [training: 5.198969519105945 | validation: 4.1629828322407185]
	TIME [epoch: 9.7 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.142431609750622		[learning rate: 0.008697]
	Learning Rate: 0.00869698
	LOSS [training: 5.142431609750622 | validation: 3.88194489607518]
	TIME [epoch: 9.69 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.831858125766455		[learning rate: 0.0086549]
	Learning Rate: 0.00865492
	LOSS [training: 4.831858125766455 | validation: 3.8373661010234343]
	TIME [epoch: 9.69 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.814950021727412		[learning rate: 0.0086131]
	Learning Rate: 0.00861307
	LOSS [training: 4.814950021727412 | validation: 4.309654146893947]
	TIME [epoch: 9.71 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.79091192621475		[learning rate: 0.0085714]
	Learning Rate: 0.00857142
	LOSS [training: 4.79091192621475 | validation: 3.546803223753091]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_82.pth
	Model improved!!!
EPOCH 83/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.586324731800322		[learning rate: 0.00853]
	Learning Rate: 0.00852997
	LOSS [training: 4.586324731800322 | validation: 4.59241722234161]
	TIME [epoch: 9.69 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.933515711312657		[learning rate: 0.0084887]
	Learning Rate: 0.00848872
	LOSS [training: 4.933515711312657 | validation: 3.880112606546486]
	TIME [epoch: 9.72 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.8225897038008565		[learning rate: 0.0084477]
	Learning Rate: 0.00844767
	LOSS [training: 4.8225897038008565 | validation: 4.221031333877402]
	TIME [epoch: 9.69 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.819474246476845		[learning rate: 0.0084068]
	Learning Rate: 0.00840682
	LOSS [training: 4.819474246476845 | validation: 5.030795596339401]
	TIME [epoch: 9.69 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.524653711147676		[learning rate: 0.0083662]
	Learning Rate: 0.00836616
	LOSS [training: 5.524653711147676 | validation: 3.9403524233100327]
	TIME [epoch: 9.68 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.8859391287555365		[learning rate: 0.0083257]
	Learning Rate: 0.00832571
	LOSS [training: 4.8859391287555365 | validation: 3.9532838309374077]
	TIME [epoch: 9.72 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.509178835745866		[learning rate: 0.0082854]
	Learning Rate: 0.00828544
	LOSS [training: 4.509178835745866 | validation: 3.565170539997008]
	TIME [epoch: 9.69 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.488375249656114		[learning rate: 0.0082454]
	Learning Rate: 0.00824538
	LOSS [training: 4.488375249656114 | validation: 3.543451975433975]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_90.pth
	Model improved!!!
EPOCH 91/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.700374723675761		[learning rate: 0.0082055]
	Learning Rate: 0.0082055
	LOSS [training: 4.700374723675761 | validation: 4.279843996498677]
	TIME [epoch: 9.74 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.220917359358868		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 5.220917359358868 | validation: 4.325524859433664]
	TIME [epoch: 9.69 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.655170269254531		[learning rate: 0.0081263]
	Learning Rate: 0.00812634
	LOSS [training: 4.655170269254531 | validation: 3.383515353041691]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_93.pth
	Model improved!!!
EPOCH 94/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.610093249854036		[learning rate: 0.008087]
	Learning Rate: 0.00808704
	LOSS [training: 4.610093249854036 | validation: 3.518091357558841]
	TIME [epoch: 9.69 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.455808116572824		[learning rate: 0.0080479]
	Learning Rate: 0.00804793
	LOSS [training: 4.455808116572824 | validation: 3.311897569026835]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_95.pth
	Model improved!!!
EPOCH 96/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.5065475898744225		[learning rate: 0.008009]
	Learning Rate: 0.00800901
	LOSS [training: 4.5065475898744225 | validation: 3.4027395375160188]
	TIME [epoch: 9.7 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.441332784241789		[learning rate: 0.0079703]
	Learning Rate: 0.00797028
	LOSS [training: 4.441332784241789 | validation: 3.650619330030884]
	TIME [epoch: 9.68 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.358994992517747		[learning rate: 0.0079317]
	Learning Rate: 0.00793174
	LOSS [training: 4.358994992517747 | validation: 4.3661641716798725]
	TIME [epoch: 9.69 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.547044346920779		[learning rate: 0.0078934]
	Learning Rate: 0.00789338
	LOSS [training: 4.547044346920779 | validation: 3.3913873875246816]
	TIME [epoch: 9.7 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.528150674979625		[learning rate: 0.0078552]
	Learning Rate: 0.00785521
	LOSS [training: 4.528150674979625 | validation: 3.514484831468286]
	TIME [epoch: 9.68 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.50702107957797		[learning rate: 0.0078172]
	Learning Rate: 0.00781722
	LOSS [training: 4.50702107957797 | validation: 3.796332784487952]
	TIME [epoch: 9.69 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.0754443374867115		[learning rate: 0.0077794]
	Learning Rate: 0.00777942
	LOSS [training: 5.0754443374867115 | validation: 4.112228695685637]
	TIME [epoch: 9.7 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.588474286568076		[learning rate: 0.0077418]
	Learning Rate: 0.0077418
	LOSS [training: 4.588474286568076 | validation: 3.5224818371411595]
	TIME [epoch: 9.7 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.616956382469903		[learning rate: 0.0077044]
	Learning Rate: 0.00770437
	LOSS [training: 4.616956382469903 | validation: 3.899288699778929]
	TIME [epoch: 9.69 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.944836910997471		[learning rate: 0.0076671]
	Learning Rate: 0.00766711
	LOSS [training: 4.944836910997471 | validation: 4.078580653419657]
	TIME [epoch: 9.69 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.813617941783663		[learning rate: 0.00763]
	Learning Rate: 0.00763003
	LOSS [training: 4.813617941783663 | validation: 3.336207384101457]
	TIME [epoch: 9.72 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.893566690920961		[learning rate: 0.0075931]
	Learning Rate: 0.00759313
	LOSS [training: 4.893566690920961 | validation: 3.791581450897273]
	TIME [epoch: 9.69 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.821989159944124		[learning rate: 0.0075564]
	Learning Rate: 0.00755642
	LOSS [training: 4.821989159944124 | validation: 3.52957003274925]
	TIME [epoch: 9.7 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.582882374445964		[learning rate: 0.0075199]
	Learning Rate: 0.00751987
	LOSS [training: 4.582882374445964 | validation: 4.01719015947628]
	TIME [epoch: 9.71 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.688793531489331		[learning rate: 0.0074835]
	Learning Rate: 0.00748351
	LOSS [training: 4.688793531489331 | validation: 3.3090045612762737]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_110.pth
	Model improved!!!
EPOCH 111/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.317911360348805		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 4.317911360348805 | validation: 4.352622231708469]
	TIME [epoch: 9.68 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.703047206320231		[learning rate: 0.0074113]
	Learning Rate: 0.00741131
	LOSS [training: 4.703047206320231 | validation: 3.859989853803545]
	TIME [epoch: 9.68 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.538962353071196		[learning rate: 0.0073755]
	Learning Rate: 0.00737547
	LOSS [training: 4.538962353071196 | validation: 3.2524489824571385]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_113.pth
	Model improved!!!
EPOCH 114/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.487674836357782		[learning rate: 0.0073398]
	Learning Rate: 0.0073398
	LOSS [training: 4.487674836357782 | validation: 3.6523871209695074]
	TIME [epoch: 9.68 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.502343713510666		[learning rate: 0.0073043]
	Learning Rate: 0.00730431
	LOSS [training: 4.502343713510666 | validation: 3.1057851303808968]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_115.pth
	Model improved!!!
EPOCH 116/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.584112816884295		[learning rate: 0.007269]
	Learning Rate: 0.00726898
	LOSS [training: 4.584112816884295 | validation: 3.1749117506537745]
	TIME [epoch: 9.72 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.357566919328635		[learning rate: 0.0072338]
	Learning Rate: 0.00723383
	LOSS [training: 4.357566919328635 | validation: 3.943590043639919]
	TIME [epoch: 9.69 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.094436348599055		[learning rate: 0.0071989]
	Learning Rate: 0.00719885
	LOSS [training: 5.094436348599055 | validation: 3.8449907976056585]
	TIME [epoch: 9.69 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.438226323093377		[learning rate: 0.007164]
	Learning Rate: 0.00716404
	LOSS [training: 4.438226323093377 | validation: 3.2819841714850853]
	TIME [epoch: 9.69 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.296630279974228		[learning rate: 0.0071294]
	Learning Rate: 0.00712939
	LOSS [training: 4.296630279974228 | validation: 3.402401507779241]
	TIME [epoch: 9.71 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.343986006672208		[learning rate: 0.0070949]
	Learning Rate: 0.00709492
	LOSS [training: 4.343986006672208 | validation: 3.3172435202316333]
	TIME [epoch: 9.68 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.542976519889237		[learning rate: 0.0070606]
	Learning Rate: 0.00706061
	LOSS [training: 4.542976519889237 | validation: 3.4831640632647294]
	TIME [epoch: 9.69 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.5896380359505216		[learning rate: 0.0070265]
	Learning Rate: 0.00702646
	LOSS [training: 4.5896380359505216 | validation: 3.878544315391031]
	TIME [epoch: 9.71 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.395399332466421		[learning rate: 0.0069925]
	Learning Rate: 0.00699248
	LOSS [training: 4.395399332466421 | validation: 3.3565548007961525]
	TIME [epoch: 9.7 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.250100932572881		[learning rate: 0.0069587]
	Learning Rate: 0.00695867
	LOSS [training: 4.250100932572881 | validation: 3.070227392019945]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_125.pth
	Model improved!!!
EPOCH 126/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.281112859859666		[learning rate: 0.006925]
	Learning Rate: 0.00692502
	LOSS [training: 4.281112859859666 | validation: 3.146518661916098]
	TIME [epoch: 9.69 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.341997320798458		[learning rate: 0.0068915]
	Learning Rate: 0.00689153
	LOSS [training: 4.341997320798458 | validation: 3.6120655299444095]
	TIME [epoch: 9.71 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.297427980598288		[learning rate: 0.0068582]
	Learning Rate: 0.00685821
	LOSS [training: 4.297427980598288 | validation: 3.1848039101709094]
	TIME [epoch: 9.69 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.3597756899637625		[learning rate: 0.006825]
	Learning Rate: 0.00682504
	LOSS [training: 4.3597756899637625 | validation: 3.759275619916317]
	TIME [epoch: 9.69 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.611959677608975		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 4.611959677608975 | validation: 3.1837157284530804]
	TIME [epoch: 9.7 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.276144119894437		[learning rate: 0.0067592]
	Learning Rate: 0.00675919
	LOSS [training: 4.276144119894437 | validation: 3.1235990878166975]
	TIME [epoch: 9.69 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.130447525217223		[learning rate: 0.0067265]
	Learning Rate: 0.00672651
	LOSS [training: 5.130447525217223 | validation: 3.610018908453597]
	TIME [epoch: 9.69 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.490595176895773		[learning rate: 0.006694]
	Learning Rate: 0.00669398
	LOSS [training: 4.490595176895773 | validation: 3.9580666513144105]
	TIME [epoch: 9.68 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.598363847277634		[learning rate: 0.0066616]
	Learning Rate: 0.00666161
	LOSS [training: 4.598363847277634 | validation: 3.0725296249534653]
	TIME [epoch: 9.7 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.438820665011002		[learning rate: 0.0066294]
	Learning Rate: 0.00662939
	LOSS [training: 4.438820665011002 | validation: 3.2911938339404156]
	TIME [epoch: 9.68 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.354394280902916		[learning rate: 0.0065973]
	Learning Rate: 0.00659733
	LOSS [training: 4.354394280902916 | validation: 3.321543459488532]
	TIME [epoch: 9.68 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.37540052928148		[learning rate: 0.0065654]
	Learning Rate: 0.00656543
	LOSS [training: 4.37540052928148 | validation: 3.2511007198736728]
	TIME [epoch: 9.7 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.348910048582773		[learning rate: 0.0065337]
	Learning Rate: 0.00653368
	LOSS [training: 4.348910048582773 | validation: 3.3270705272574386]
	TIME [epoch: 9.68 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.296010791599639		[learning rate: 0.0065021]
	Learning Rate: 0.00650208
	LOSS [training: 4.296010791599639 | validation: 3.921868803750117]
	TIME [epoch: 9.68 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.5449507354183		[learning rate: 0.0064706]
	Learning Rate: 0.00647064
	LOSS [training: 4.5449507354183 | validation: 3.6635886334359773]
	TIME [epoch: 9.68 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.389317419889408		[learning rate: 0.0064394]
	Learning Rate: 0.00643935
	LOSS [training: 4.389317419889408 | validation: 3.2623652728063792]
	TIME [epoch: 9.7 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.203824570944918		[learning rate: 0.0064082]
	Learning Rate: 0.00640821
	LOSS [training: 4.203824570944918 | validation: 3.4524009336795562]
	TIME [epoch: 9.67 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.5254816370289195		[learning rate: 0.0063772]
	Learning Rate: 0.00637722
	LOSS [training: 4.5254816370289195 | validation: 3.3780217023223873]
	TIME [epoch: 9.68 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.363412653931874		[learning rate: 0.0063464]
	Learning Rate: 0.00634638
	LOSS [training: 4.363412653931874 | validation: 3.6608204381075264]
	TIME [epoch: 9.69 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.443843027904244		[learning rate: 0.0063157]
	Learning Rate: 0.00631569
	LOSS [training: 4.443843027904244 | validation: 3.7099528231688033]
	TIME [epoch: 9.99 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.266056311661266		[learning rate: 0.0062852]
	Learning Rate: 0.00628515
	LOSS [training: 4.266056311661266 | validation: 3.7243909967516853]
	TIME [epoch: 9.71 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.043196586478171		[learning rate: 0.0062548]
	Learning Rate: 0.00625476
	LOSS [training: 5.043196586478171 | validation: 3.353434552395508]
	TIME [epoch: 9.7 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.398896999297165		[learning rate: 0.0062245]
	Learning Rate: 0.00622451
	LOSS [training: 4.398896999297165 | validation: 3.6873741186853937]
	TIME [epoch: 9.72 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.373777026689484		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 4.373777026689484 | validation: 3.54078530062884]
	TIME [epoch: 9.7 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.281724430801954		[learning rate: 0.0061645]
	Learning Rate: 0.00616446
	LOSS [training: 4.281724430801954 | validation: 3.267800302902736]
	TIME [epoch: 9.7 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.259828855418067		[learning rate: 0.0061346]
	Learning Rate: 0.00613465
	LOSS [training: 4.259828855418067 | validation: 3.137565525800841]
	TIME [epoch: 9.72 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.28879594412945		[learning rate: 0.006105]
	Learning Rate: 0.00610498
	LOSS [training: 4.28879594412945 | validation: 3.160499253828356]
	TIME [epoch: 9.71 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.251385522383269		[learning rate: 0.0060755]
	Learning Rate: 0.00607546
	LOSS [training: 4.251385522383269 | validation: 3.055802192545533]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_153.pth
	Model improved!!!
EPOCH 154/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.354586492701852		[learning rate: 0.0060461]
	Learning Rate: 0.00604608
	LOSS [training: 4.354586492701852 | validation: 3.4442328456683176]
	TIME [epoch: 9.7 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.236952340131806		[learning rate: 0.0060168]
	Learning Rate: 0.00601684
	LOSS [training: 4.236952340131806 | validation: 3.6210235347545496]
	TIME [epoch: 9.71 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.3341033677547305		[learning rate: 0.0059877]
	Learning Rate: 0.00598774
	LOSS [training: 4.3341033677547305 | validation: 3.2857918923978695]
	TIME [epoch: 9.7 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.210566809997796		[learning rate: 0.0059588]
	Learning Rate: 0.00595879
	LOSS [training: 4.210566809997796 | validation: 3.420176114275286]
	TIME [epoch: 9.7 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.2990776040990415		[learning rate: 0.00593]
	Learning Rate: 0.00592997
	LOSS [training: 4.2990776040990415 | validation: 3.2160858860347865]
	TIME [epoch: 9.71 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.288469142347303		[learning rate: 0.0059013]
	Learning Rate: 0.0059013
	LOSS [training: 4.288469142347303 | validation: 3.2858584516113245]
	TIME [epoch: 9.7 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.266694015890721		[learning rate: 0.0058728]
	Learning Rate: 0.00587276
	LOSS [training: 4.266694015890721 | validation: 3.2500797466074016]
	TIME [epoch: 9.7 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.331329515327207		[learning rate: 0.0058444]
	Learning Rate: 0.00584436
	LOSS [training: 4.331329515327207 | validation: 3.2093070003569513]
	TIME [epoch: 9.7 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.305343798987461		[learning rate: 0.0058161]
	Learning Rate: 0.0058161
	LOSS [training: 4.305343798987461 | validation: 3.148249768038078]
	TIME [epoch: 9.73 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.295119814018588		[learning rate: 0.005788]
	Learning Rate: 0.00578797
	LOSS [training: 4.295119814018588 | validation: 3.1949165079201975]
	TIME [epoch: 9.7 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.278385313586604		[learning rate: 0.00576]
	Learning Rate: 0.00575998
	LOSS [training: 4.278385313586604 | validation: 3.901124733870395]
	TIME [epoch: 9.7 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.326143145187985		[learning rate: 0.0057321]
	Learning Rate: 0.00573213
	LOSS [training: 4.326143145187985 | validation: 3.1333939209710127]
	TIME [epoch: 9.71 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.197862033579684		[learning rate: 0.0057044]
	Learning Rate: 0.00570441
	LOSS [training: 4.197862033579684 | validation: 3.4135979880167286]
	TIME [epoch: 9.7 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.306731330836877		[learning rate: 0.0056768]
	Learning Rate: 0.00567682
	LOSS [training: 4.306731330836877 | validation: 3.4598334716743375]
	TIME [epoch: 9.69 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.421937129611055		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 4.421937129611055 | validation: 3.338910753312998]
	TIME [epoch: 9.71 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.2454825629874		[learning rate: 0.0056221]
	Learning Rate: 0.00562205
	LOSS [training: 4.2454825629874 | validation: 3.0984959624167248]
	TIME [epoch: 9.71 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.3322774915472735		[learning rate: 0.0055949]
	Learning Rate: 0.00559486
	LOSS [training: 4.3322774915472735 | validation: 3.0590051912091427]
	TIME [epoch: 9.7 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.244145240218313		[learning rate: 0.0055678]
	Learning Rate: 0.00556781
	LOSS [training: 4.244145240218313 | validation: 3.3475801603675883]
	TIME [epoch: 9.69 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.2892818040893514		[learning rate: 0.0055409]
	Learning Rate: 0.00554088
	LOSS [training: 4.2892818040893514 | validation: 3.0813145317119304]
	TIME [epoch: 9.72 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.257105328604951		[learning rate: 0.0055141]
	Learning Rate: 0.00551409
	LOSS [training: 4.257105328604951 | validation: 3.232653147491317]
	TIME [epoch: 9.7 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.251479083167081		[learning rate: 0.0054874]
	Learning Rate: 0.00548742
	LOSS [training: 4.251479083167081 | validation: 3.198454379167334]
	TIME [epoch: 9.7 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.190413319703401		[learning rate: 0.0054609]
	Learning Rate: 0.00546089
	LOSS [training: 4.190413319703401 | validation: 3.365465963712532]
	TIME [epoch: 9.71 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.1604809461665		[learning rate: 0.0054345]
	Learning Rate: 0.00543448
	LOSS [training: 4.1604809461665 | validation: 3.116661914855722]
	TIME [epoch: 9.71 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.133908018950393		[learning rate: 0.0054082]
	Learning Rate: 0.0054082
	LOSS [training: 4.133908018950393 | validation: 3.039037363088021]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_177.pth
	Model improved!!!
EPOCH 178/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.185753112913167		[learning rate: 0.005382]
	Learning Rate: 0.00538205
	LOSS [training: 4.185753112913167 | validation: 3.182626951813099]
	TIME [epoch: 9.7 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.242324867832032		[learning rate: 0.005356]
	Learning Rate: 0.00535602
	LOSS [training: 4.242324867832032 | validation: 3.1488617752054484]
	TIME [epoch: 9.73 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.178260848942193		[learning rate: 0.0053301]
	Learning Rate: 0.00533012
	LOSS [training: 4.178260848942193 | validation: 3.1005769975058093]
	TIME [epoch: 9.7 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.1884623990587855		[learning rate: 0.0053043]
	Learning Rate: 0.00530434
	LOSS [training: 4.1884623990587855 | validation: 3.3722785497638057]
	TIME [epoch: 9.7 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.2223279291805955		[learning rate: 0.0052787]
	Learning Rate: 0.00527869
	LOSS [training: 4.2223279291805955 | validation: 3.2865455143990085]
	TIME [epoch: 9.7 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.258762852024245		[learning rate: 0.0052532]
	Learning Rate: 0.00525316
	LOSS [training: 4.258762852024245 | validation: 3.018860077128355]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_183.pth
	Model improved!!!
EPOCH 184/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.115973626973898		[learning rate: 0.0052278]
	Learning Rate: 0.00522776
	LOSS [training: 4.115973626973898 | validation: 3.1879569133872003]
	TIME [epoch: 9.69 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.249447803201662		[learning rate: 0.0052025]
	Learning Rate: 0.00520248
	LOSS [training: 4.249447803201662 | validation: 3.319000162780233]
	TIME [epoch: 9.69 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.189925524310999		[learning rate: 0.0051773]
	Learning Rate: 0.00517732
	LOSS [training: 4.189925524310999 | validation: 3.342125411613904]
	TIME [epoch: 9.71 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.154796437806044		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 4.154796437806044 | validation: 3.0118823214126276]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_187.pth
	Model improved!!!
EPOCH 188/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.167341863195761		[learning rate: 0.0051274]
	Learning Rate: 0.00512737
	LOSS [training: 4.167341863195761 | validation: 3.127835258809089]
	TIME [epoch: 9.7 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.161061025849956		[learning rate: 0.0051026]
	Learning Rate: 0.00510258
	LOSS [training: 4.161061025849956 | validation: 3.1898264543624153]
	TIME [epoch: 9.71 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.089624225030888		[learning rate: 0.0050779]
	Learning Rate: 0.0050779
	LOSS [training: 4.089624225030888 | validation: 2.990560177296319]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_190.pth
	Model improved!!!
EPOCH 191/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.183280764783531		[learning rate: 0.0050533]
	Learning Rate: 0.00505334
	LOSS [training: 4.183280764783531 | validation: 3.109286622279314]
	TIME [epoch: 9.71 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.206115933345844		[learning rate: 0.0050289]
	Learning Rate: 0.00502891
	LOSS [training: 4.206115933345844 | validation: 3.2775103771237175]
	TIME [epoch: 9.7 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.138567822428268		[learning rate: 0.0050046]
	Learning Rate: 0.00500459
	LOSS [training: 4.138567822428268 | validation: 3.15143107323539]
	TIME [epoch: 9.73 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.324358326336194		[learning rate: 0.0049804]
	Learning Rate: 0.00498039
	LOSS [training: 4.324358326336194 | validation: 3.3736209501545047]
	TIME [epoch: 9.7 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.22933091282459		[learning rate: 0.0049563]
	Learning Rate: 0.0049563
	LOSS [training: 4.22933091282459 | validation: 3.1509773058604242]
	TIME [epoch: 9.7 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.171358305868158		[learning rate: 0.0049323]
	Learning Rate: 0.00493234
	LOSS [training: 4.171358305868158 | validation: 2.95975927206041]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_196.pth
	Model improved!!!
EPOCH 197/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.25067599284094		[learning rate: 0.0049085]
	Learning Rate: 0.00490848
	LOSS [training: 4.25067599284094 | validation: 3.019048263432484]
	TIME [epoch: 9.72 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.061673376639486		[learning rate: 0.0048847]
	Learning Rate: 0.00488475
	LOSS [training: 4.061673376639486 | validation: 3.169223062490514]
	TIME [epoch: 9.7 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.195233906125263		[learning rate: 0.0048611]
	Learning Rate: 0.00486113
	LOSS [training: 4.195233906125263 | validation: 3.0615387225241775]
	TIME [epoch: 9.69 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.176214585043967		[learning rate: 0.0048376]
	Learning Rate: 0.00483762
	LOSS [training: 4.176214585043967 | validation: 3.046586196062618]
	TIME [epoch: 9.7 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.13193986397691		[learning rate: 0.0048142]
	Learning Rate: 0.00481422
	LOSS [training: 4.13193986397691 | validation: 3.312539719279065]
	TIME [epoch: 9.72 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.171851283274568		[learning rate: 0.0047909]
	Learning Rate: 0.00479094
	LOSS [training: 4.171851283274568 | validation: 3.1420865136951135]
	TIME [epoch: 9.71 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.0700860480694665		[learning rate: 0.0047678]
	Learning Rate: 0.00476778
	LOSS [training: 4.0700860480694665 | validation: 3.0266459130800025]
	TIME [epoch: 9.7 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.12022078416504		[learning rate: 0.0047447]
	Learning Rate: 0.00474472
	LOSS [training: 4.12022078416504 | validation: 3.0984382379919815]
	TIME [epoch: 9.73 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.096008560213763		[learning rate: 0.0047218]
	Learning Rate: 0.00472177
	LOSS [training: 4.096008560213763 | validation: 3.427778486185099]
	TIME [epoch: 9.7 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.310007055289506		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 4.310007055289506 | validation: 2.958573228237445]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_206.pth
	Model improved!!!
EPOCH 207/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.086270049786536		[learning rate: 0.0046762]
	Learning Rate: 0.00467622
	LOSS [training: 4.086270049786536 | validation: 3.0342279372830814]
	TIME [epoch: 9.7 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.100973650247235		[learning rate: 0.0046536]
	Learning Rate: 0.0046536
	LOSS [training: 4.100973650247235 | validation: 3.149851121286342]
	TIME [epoch: 9.71 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.136826290905631		[learning rate: 0.0046311]
	Learning Rate: 0.0046311
	LOSS [training: 4.136826290905631 | validation: 3.1024805606667973]
	TIME [epoch: 9.68 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.274153638449934		[learning rate: 0.0046087]
	Learning Rate: 0.00460871
	LOSS [training: 4.274153638449934 | validation: 3.065265428598193]
	TIME [epoch: 9.68 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.056210408461714		[learning rate: 0.0045864]
	Learning Rate: 0.00458642
	LOSS [training: 4.056210408461714 | validation: 3.3814834952189994]
	TIME [epoch: 9.7 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.128298443218027		[learning rate: 0.0045642]
	Learning Rate: 0.00456424
	LOSS [training: 4.128298443218027 | validation: 3.0441668493087253]
	TIME [epoch: 9.68 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.183951625320902		[learning rate: 0.0045422]
	Learning Rate: 0.00454217
	LOSS [training: 4.183951625320902 | validation: 3.2552631857685093]
	TIME [epoch: 9.68 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.116939840452476		[learning rate: 0.0045202]
	Learning Rate: 0.0045202
	LOSS [training: 4.116939840452476 | validation: 3.546574197891539]
	TIME [epoch: 9.69 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.242885182340215		[learning rate: 0.0044983]
	Learning Rate: 0.00449834
	LOSS [training: 4.242885182340215 | validation: 3.3749318991475117]
	TIME [epoch: 9.7 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.179439719952307		[learning rate: 0.0044766]
	Learning Rate: 0.00447659
	LOSS [training: 4.179439719952307 | validation: 3.249679305076294]
	TIME [epoch: 9.69 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.096433385454063		[learning rate: 0.0044549]
	Learning Rate: 0.00445494
	LOSS [training: 4.096433385454063 | validation: 3.068741792514511]
	TIME [epoch: 9.69 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.124168268667747		[learning rate: 0.0044334]
	Learning Rate: 0.0044334
	LOSS [training: 4.124168268667747 | validation: 3.041388668040594]
	TIME [epoch: 9.7 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.07285111116906		[learning rate: 0.004412]
	Learning Rate: 0.00441196
	LOSS [training: 4.07285111116906 | validation: 3.2076423249452053]
	TIME [epoch: 9.69 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.0902580649904134		[learning rate: 0.0043906]
	Learning Rate: 0.00439062
	LOSS [training: 4.0902580649904134 | validation: 3.254842810542168]
	TIME [epoch: 9.69 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.064982343920414		[learning rate: 0.0043694]
	Learning Rate: 0.00436939
	LOSS [training: 4.064982343920414 | validation: 3.2592877256190174]
	TIME [epoch: 9.7 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.200779317218358		[learning rate: 0.0043483]
	Learning Rate: 0.00434826
	LOSS [training: 4.200779317218358 | validation: 3.369228649163787]
	TIME [epoch: 9.73 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.097095272051105		[learning rate: 0.0043272]
	Learning Rate: 0.00432724
	LOSS [training: 4.097095272051105 | validation: 3.18592735583571]
	TIME [epoch: 9.69 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.20832333871542		[learning rate: 0.0043063]
	Learning Rate: 0.00430631
	LOSS [training: 4.20832333871542 | validation: 3.2155292422464035]
	TIME [epoch: 9.69 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.024517744544158		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 4.024517744544158 | validation: 3.098451183709792]
	TIME [epoch: 9.71 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.0989157195681205		[learning rate: 0.0042648]
	Learning Rate: 0.00426476
	LOSS [training: 4.0989157195681205 | validation: 3.1679306824481803]
	TIME [epoch: 9.7 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.072606967583143		[learning rate: 0.0042441]
	Learning Rate: 0.00424414
	LOSS [training: 4.072606967583143 | validation: 3.2869146402040954]
	TIME [epoch: 9.69 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.126738291535221		[learning rate: 0.0042236]
	Learning Rate: 0.00422361
	LOSS [training: 4.126738291535221 | validation: 3.302613118180932]
	TIME [epoch: 9.71 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.108161350199579		[learning rate: 0.0042032]
	Learning Rate: 0.00420319
	LOSS [training: 4.108161350199579 | validation: 3.2145663611737123]
	TIME [epoch: 9.7 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.981675170250134		[learning rate: 0.0041829]
	Learning Rate: 0.00418286
	LOSS [training: 3.981675170250134 | validation: 3.570231394079475]
	TIME [epoch: 9.7 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.074970846542757		[learning rate: 0.0041626]
	Learning Rate: 0.00416264
	LOSS [training: 4.074970846542757 | validation: 3.0161452932571162]
	TIME [epoch: 9.69 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.924547107627734		[learning rate: 0.0041425]
	Learning Rate: 0.00414251
	LOSS [training: 3.924547107627734 | validation: 3.7137145842583372]
	TIME [epoch: 9.72 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9610910368697048		[learning rate: 0.0041225]
	Learning Rate: 0.00412247
	LOSS [training: 3.9610910368697048 | validation: 3.1478638585951875]
	TIME [epoch: 9.69 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.289870605944629		[learning rate: 0.0041025]
	Learning Rate: 0.00410254
	LOSS [training: 3.289870605944629 | validation: 1.7875232783719759]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_234.pth
	Model improved!!!
EPOCH 235/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.893638418028425		[learning rate: 0.0040827]
	Learning Rate: 0.0040827
	LOSS [training: 1.893638418028425 | validation: 1.6007452305318786]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_235.pth
	Model improved!!!
EPOCH 236/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.477828310916807		[learning rate: 0.004063]
	Learning Rate: 0.00406296
	LOSS [training: 1.477828310916807 | validation: 2.5896640760187317]
	TIME [epoch: 9.7 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.288950119540069		[learning rate: 0.0040433]
	Learning Rate: 0.00404331
	LOSS [training: 2.288950119540069 | validation: 1.2903429923352354]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_237.pth
	Model improved!!!
EPOCH 238/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9516544856507636		[learning rate: 0.0040238]
	Learning Rate: 0.00402375
	LOSS [training: 1.9516544856507636 | validation: 2.07647693336819]
	TIME [epoch: 9.7 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0176158110569253		[learning rate: 0.0040043]
	Learning Rate: 0.0040043
	LOSS [training: 2.0176158110569253 | validation: 1.6711181504894856]
	TIME [epoch: 9.72 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6364194391527804		[learning rate: 0.0039849]
	Learning Rate: 0.00398493
	LOSS [training: 1.6364194391527804 | validation: 1.3266801562001387]
	TIME [epoch: 9.69 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6873247981564883		[learning rate: 0.0039657]
	Learning Rate: 0.00396566
	LOSS [training: 1.6873247981564883 | validation: 1.757151162955223]
	TIME [epoch: 9.7 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9281838906390782		[learning rate: 0.0039465]
	Learning Rate: 0.00394649
	LOSS [training: 1.9281838906390782 | validation: 1.6207342057837253]
	TIME [epoch: 9.7 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7272153827154753		[learning rate: 0.0039274]
	Learning Rate: 0.0039274
	LOSS [training: 1.7272153827154753 | validation: 1.8912114916886633]
	TIME [epoch: 9.72 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8071240137075555		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 1.8071240137075555 | validation: 1.9257588420667828]
	TIME [epoch: 9.69 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5936096796654176		[learning rate: 0.0038895]
	Learning Rate: 0.00388951
	LOSS [training: 1.5936096796654176 | validation: 1.4231793456733428]
	TIME [epoch: 9.69 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4315474633982153		[learning rate: 0.0038707]
	Learning Rate: 0.0038707
	LOSS [training: 1.4315474633982153 | validation: 1.5370352803727338]
	TIME [epoch: 9.72 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2935596004047456		[learning rate: 0.003852]
	Learning Rate: 0.00385198
	LOSS [training: 1.2935596004047456 | validation: 1.27613142525891]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_247.pth
	Model improved!!!
EPOCH 248/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.332916672250451		[learning rate: 0.0038334]
	Learning Rate: 0.00383335
	LOSS [training: 1.332916672250451 | validation: 1.5234144231524949]
	TIME [epoch: 9.7 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.003856356685192		[learning rate: 0.0038148]
	Learning Rate: 0.00381482
	LOSS [training: 2.003856356685192 | validation: 1.6429007150935484]
	TIME [epoch: 9.71 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7014892685152994		[learning rate: 0.0037964]
	Learning Rate: 0.00379637
	LOSS [training: 1.7014892685152994 | validation: 1.4309347353277702]
	TIME [epoch: 9.7 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5245475030588698		[learning rate: 0.003778]
	Learning Rate: 0.00377801
	LOSS [training: 1.5245475030588698 | validation: 1.7972861524423078]
	TIME [epoch: 9.69 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.380056584642313		[learning rate: 0.0037597]
	Learning Rate: 0.00375974
	LOSS [training: 1.380056584642313 | validation: 1.2359254678618896]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_252.pth
	Model improved!!!
EPOCH 253/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2719533419573144		[learning rate: 0.0037416]
	Learning Rate: 0.00374156
	LOSS [training: 1.2719533419573144 | validation: 1.4050933526159042]
	TIME [epoch: 9.72 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5911889233697565		[learning rate: 0.0037235]
	Learning Rate: 0.00372347
	LOSS [training: 1.5911889233697565 | validation: 1.2553401967909377]
	TIME [epoch: 9.69 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9761442426731102		[learning rate: 0.0037055]
	Learning Rate: 0.00370546
	LOSS [training: 1.9761442426731102 | validation: 1.585944610264698]
	TIME [epoch: 9.68 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5471669944294901		[learning rate: 0.0036875]
	Learning Rate: 0.00368754
	LOSS [training: 1.5471669944294901 | validation: 1.4151295365257708]
	TIME [epoch: 9.69 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.52650870434237		[learning rate: 0.0036697]
	Learning Rate: 0.00366971
	LOSS [training: 1.52650870434237 | validation: 1.5470505281408993]
	TIME [epoch: 9.71 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4432713794523675		[learning rate: 0.003652]
	Learning Rate: 0.00365196
	LOSS [training: 1.4432713794523675 | validation: 1.2156153278563508]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_258.pth
	Model improved!!!
EPOCH 259/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.544588486758475		[learning rate: 0.0036343]
	Learning Rate: 0.0036343
	LOSS [training: 1.544588486758475 | validation: 1.6781811465649998]
	TIME [epoch: 9.69 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9296447379270432		[learning rate: 0.0036167]
	Learning Rate: 0.00361673
	LOSS [training: 1.9296447379270432 | validation: 1.6202411701039776]
	TIME [epoch: 9.71 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4704103456331443		[learning rate: 0.0035992]
	Learning Rate: 0.00359924
	LOSS [training: 1.4704103456331443 | validation: 1.6391965535220372]
	TIME [epoch: 9.69 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4830211493899832		[learning rate: 0.0035818]
	Learning Rate: 0.00358183
	LOSS [training: 1.4830211493899832 | validation: 1.2083203711784487]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_262.pth
	Model improved!!!
EPOCH 263/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3718512290150557		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 1.3718512290150557 | validation: 1.750300854608514]
	TIME [epoch: 9.68 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5255112947138887		[learning rate: 0.0035473]
	Learning Rate: 0.00354727
	LOSS [training: 1.5255112947138887 | validation: 1.2761712484285448]
	TIME [epoch: 9.71 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6185089720579846		[learning rate: 0.0035301]
	Learning Rate: 0.00353012
	LOSS [training: 1.6185089720579846 | validation: 1.3138474878725168]
	TIME [epoch: 9.69 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2455574902833049		[learning rate: 0.003513]
	Learning Rate: 0.00351305
	LOSS [training: 1.2455574902833049 | validation: 1.2933263925987297]
	TIME [epoch: 9.68 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.142901051804195		[learning rate: 0.0034961]
	Learning Rate: 0.00349606
	LOSS [training: 1.142901051804195 | validation: 1.5253393796363752]
	TIME [epoch: 9.69 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3411016837803031		[learning rate: 0.0034792]
	Learning Rate: 0.00347915
	LOSS [training: 1.3411016837803031 | validation: 1.420923105295048]
	TIME [epoch: 9.71 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4619609039149712		[learning rate: 0.0034623]
	Learning Rate: 0.00346233
	LOSS [training: 1.4619609039149712 | validation: 1.4503705496537054]
	TIME [epoch: 9.68 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.390104027760437		[learning rate: 0.0034456]
	Learning Rate: 0.00344559
	LOSS [training: 1.390104027760437 | validation: 1.3794049919747686]
	TIME [epoch: 9.68 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.40134896312184		[learning rate: 0.0034289]
	Learning Rate: 0.00342892
	LOSS [training: 1.40134896312184 | validation: 1.749988477580734]
	TIME [epoch: 9.71 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5641657190602394		[learning rate: 0.0034123]
	Learning Rate: 0.00341234
	LOSS [training: 1.5641657190602394 | validation: 1.394204574907675]
	TIME [epoch: 9.68 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2013879959782279		[learning rate: 0.0033958]
	Learning Rate: 0.00339584
	LOSS [training: 1.2013879959782279 | validation: 1.3333071976872461]
	TIME [epoch: 9.69 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2052706900840187		[learning rate: 0.0033794]
	Learning Rate: 0.00337942
	LOSS [training: 1.2052706900840187 | validation: 1.3670623220058125]
	TIME [epoch: 9.7 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2229565021438968		[learning rate: 0.0033631]
	Learning Rate: 0.00336308
	LOSS [training: 1.2229565021438968 | validation: 1.2028251970554686]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_275.pth
	Model improved!!!
EPOCH 276/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1645742094264953		[learning rate: 0.0033468]
	Learning Rate: 0.00334681
	LOSS [training: 1.1645742094264953 | validation: 1.7057698947481703]
	TIME [epoch: 9.69 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.352589628437922		[learning rate: 0.0033306]
	Learning Rate: 0.00333063
	LOSS [training: 1.352589628437922 | validation: 1.5114224361251152]
	TIME [epoch: 9.68 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4833731501551628		[learning rate: 0.0033145]
	Learning Rate: 0.00331452
	LOSS [training: 1.4833731501551628 | validation: 1.336075219012866]
	TIME [epoch: 9.71 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6940961348452093		[learning rate: 0.0032985]
	Learning Rate: 0.00329849
	LOSS [training: 1.6940961348452093 | validation: 1.604682302091042]
	TIME [epoch: 9.68 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5534427177133434		[learning rate: 0.0032825]
	Learning Rate: 0.00328254
	LOSS [training: 1.5534427177133434 | validation: 1.201549392010891]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_280.pth
	Model improved!!!
EPOCH 281/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1344786202882842		[learning rate: 0.0032667]
	Learning Rate: 0.00326667
	LOSS [training: 1.1344786202882842 | validation: 1.372112123912006]
	TIME [epoch: 9.71 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2246284066210449		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 1.2246284066210449 | validation: 1.4086791183764058]
	TIME [epoch: 9.71 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4076688809582598		[learning rate: 0.0032352]
	Learning Rate: 0.00323515
	LOSS [training: 1.4076688809582598 | validation: 1.194826604208825]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_283.pth
	Model improved!!!
EPOCH 284/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.242866077353288		[learning rate: 0.0032195]
	Learning Rate: 0.00321951
	LOSS [training: 1.242866077353288 | validation: 1.2709830599832128]
	TIME [epoch: 9.7 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3180054032418518		[learning rate: 0.0032039]
	Learning Rate: 0.00320394
	LOSS [training: 1.3180054032418518 | validation: 1.2513681778140615]
	TIME [epoch: 9.71 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.238316662440232		[learning rate: 0.0031884]
	Learning Rate: 0.00318845
	LOSS [training: 1.238316662440232 | validation: 1.3499254145585433]
	TIME [epoch: 9.69 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1807014150203181		[learning rate: 0.003173]
	Learning Rate: 0.00317303
	LOSS [training: 1.1807014150203181 | validation: 1.1161056554457125]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_287.pth
	Model improved!!!
EPOCH 288/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2207979928263781		[learning rate: 0.0031577]
	Learning Rate: 0.00315768
	LOSS [training: 1.2207979928263781 | validation: 1.3727995634747934]
	TIME [epoch: 9.7 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.465459067905067		[learning rate: 0.0031424]
	Learning Rate: 0.00314241
	LOSS [training: 1.465459067905067 | validation: 1.806227534603645]
	TIME [epoch: 9.72 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4257878983579604		[learning rate: 0.0031272]
	Learning Rate: 0.00312722
	LOSS [training: 1.4257878983579604 | validation: 1.89554989981886]
	TIME [epoch: 9.7 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2942074139298982		[learning rate: 0.0031121]
	Learning Rate: 0.00311209
	LOSS [training: 1.2942074139298982 | validation: 1.6275564713605086]
	TIME [epoch: 9.7 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2683426025725004		[learning rate: 0.003097]
	Learning Rate: 0.00309704
	LOSS [training: 1.2683426025725004 | validation: 1.2884789403475432]
	TIME [epoch: 9.7 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.330328266789405		[learning rate: 0.0030821]
	Learning Rate: 0.00308207
	LOSS [training: 1.330328266789405 | validation: 1.3110597021752233]
	TIME [epoch: 9.71 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.277162398341415		[learning rate: 0.0030672]
	Learning Rate: 0.00306716
	LOSS [training: 1.277162398341415 | validation: 1.3894601542662013]
	TIME [epoch: 9.7 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3613101468964923		[learning rate: 0.0030523]
	Learning Rate: 0.00305233
	LOSS [training: 1.3613101468964923 | validation: 1.4249550495392935]
	TIME [epoch: 9.69 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2348776063850289		[learning rate: 0.0030376]
	Learning Rate: 0.00303757
	LOSS [training: 1.2348776063850289 | validation: 1.1745963604537937]
	TIME [epoch: 9.72 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1396924011625036		[learning rate: 0.0030229]
	Learning Rate: 0.00302288
	LOSS [training: 1.1396924011625036 | validation: 1.2712718229322864]
	TIME [epoch: 9.7 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.205674252983818		[learning rate: 0.0030083]
	Learning Rate: 0.00300826
	LOSS [training: 1.205674252983818 | validation: 1.1529494701576202]
	TIME [epoch: 9.69 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0945168452165395		[learning rate: 0.0029937]
	Learning Rate: 0.00299372
	LOSS [training: 1.0945168452165395 | validation: 1.1696248615665175]
	TIME [epoch: 9.7 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0990024055931127		[learning rate: 0.0029792]
	Learning Rate: 0.00297924
	LOSS [training: 1.0990024055931127 | validation: 1.0974953213591545]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_300.pth
	Model improved!!!
EPOCH 301/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0611274166463507		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 1.0611274166463507 | validation: 1.3685636420548297]
	TIME [epoch: 9.69 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.157067716250763		[learning rate: 0.0029505]
	Learning Rate: 0.00295049
	LOSS [training: 1.157067716250763 | validation: 1.5389054390412242]
	TIME [epoch: 9.69 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.153511068071407		[learning rate: 0.0029362]
	Learning Rate: 0.00293623
	LOSS [training: 1.153511068071407 | validation: 1.1550296961069586]
	TIME [epoch: 9.71 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2912440074492035		[learning rate: 0.002922]
	Learning Rate: 0.00292203
	LOSS [training: 1.2912440074492035 | validation: 1.5220635053075784]
	TIME [epoch: 9.69 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1592943113489673		[learning rate: 0.0029079]
	Learning Rate: 0.0029079
	LOSS [training: 1.1592943113489673 | validation: 1.6250502381497187]
	TIME [epoch: 9.69 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3771318154113423		[learning rate: 0.0028938]
	Learning Rate: 0.00289383
	LOSS [training: 1.3771318154113423 | validation: 1.4756699152873083]
	TIME [epoch: 9.69 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1886174443343602		[learning rate: 0.0028798]
	Learning Rate: 0.00287984
	LOSS [training: 1.1886174443343602 | validation: 1.1419483757747773]
	TIME [epoch: 9.7 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0096415527922527		[learning rate: 0.0028659]
	Learning Rate: 0.00286591
	LOSS [training: 1.0096415527922527 | validation: 1.1386525934933167]
	TIME [epoch: 9.69 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.04282816739866		[learning rate: 0.0028521]
	Learning Rate: 0.00285205
	LOSS [training: 1.04282816739866 | validation: 1.1085605007774928]
	TIME [epoch: 9.68 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.242897172743605		[learning rate: 0.0028383]
	Learning Rate: 0.00283826
	LOSS [training: 1.242897172743605 | validation: 1.391618054076488]
	TIME [epoch: 9.71 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.094180546084821		[learning rate: 0.0028245]
	Learning Rate: 0.00282454
	LOSS [training: 1.094180546084821 | validation: 1.158638510357902]
	TIME [epoch: 9.68 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.094384002682334		[learning rate: 0.0028109]
	Learning Rate: 0.00281088
	LOSS [training: 1.094384002682334 | validation: 1.1425847631240311]
	TIME [epoch: 9.68 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1887362837328301		[learning rate: 0.0027973]
	Learning Rate: 0.00279729
	LOSS [training: 1.1887362837328301 | validation: 1.2128214138425681]
	TIME [epoch: 9.7 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1731533192452837		[learning rate: 0.0027838]
	Learning Rate: 0.00278376
	LOSS [training: 1.1731533192452837 | validation: 1.256636013265967]
	TIME [epoch: 9.69 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0876147556571805		[learning rate: 0.0027703]
	Learning Rate: 0.0027703
	LOSS [training: 1.0876147556571805 | validation: 1.2507136511735923]
	TIME [epoch: 9.68 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1872817298986589		[learning rate: 0.0027569]
	Learning Rate: 0.0027569
	LOSS [training: 1.1872817298986589 | validation: 1.587892737615533]
	TIME [epoch: 9.68 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.209740939344235		[learning rate: 0.0027436]
	Learning Rate: 0.00274357
	LOSS [training: 1.209740939344235 | validation: 1.066076032753283]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_317.pth
	Model improved!!!
EPOCH 318/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1330665432618994		[learning rate: 0.0027303]
	Learning Rate: 0.0027303
	LOSS [training: 1.1330665432618994 | validation: 1.292130118265896]
	TIME [epoch: 9.69 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1494758411329768		[learning rate: 0.0027171]
	Learning Rate: 0.0027171
	LOSS [training: 1.1494758411329768 | validation: 2.5926245989968355]
	TIME [epoch: 9.68 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5077628029240793		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 1.5077628029240793 | validation: 1.1182308883381822]
	TIME [epoch: 9.7 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4696136727598823		[learning rate: 0.0026909]
	Learning Rate: 0.00269088
	LOSS [training: 1.4696136727598823 | validation: 1.4253725314628733]
	TIME [epoch: 9.69 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.152277967171979		[learning rate: 0.0026779]
	Learning Rate: 0.00267787
	LOSS [training: 1.152277967171979 | validation: 1.093480585537351]
	TIME [epoch: 9.68 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0693410337244043		[learning rate: 0.0026649]
	Learning Rate: 0.00266492
	LOSS [training: 1.0693410337244043 | validation: 1.14280631720047]
	TIME [epoch: 9.69 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.958915726477778		[learning rate: 0.002652]
	Learning Rate: 0.00265203
	LOSS [training: 0.958915726477778 | validation: 1.0217542378491025]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_324.pth
	Model improved!!!
EPOCH 325/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9486165854111446		[learning rate: 0.0026392]
	Learning Rate: 0.00263921
	LOSS [training: 0.9486165854111446 | validation: 1.0842156253593391]
	TIME [epoch: 9.7 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0975200661398667		[learning rate: 0.0026264]
	Learning Rate: 0.00262645
	LOSS [training: 1.0975200661398667 | validation: 1.5374492247043252]
	TIME [epoch: 9.69 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0364265338037175		[learning rate: 0.0026137]
	Learning Rate: 0.00261374
	LOSS [training: 1.0364265338037175 | validation: 1.1605905942013253]
	TIME [epoch: 9.71 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.984025789745556		[learning rate: 0.0026011]
	Learning Rate: 0.00260111
	LOSS [training: 0.984025789745556 | validation: 1.0336404716178098]
	TIME [epoch: 9.69 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0907295808476154		[learning rate: 0.0025885]
	Learning Rate: 0.00258853
	LOSS [training: 1.0907295808476154 | validation: 1.155389356728279]
	TIME [epoch: 9.7 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0443825201943313		[learning rate: 0.002576]
	Learning Rate: 0.00257601
	LOSS [training: 1.0443825201943313 | validation: 1.1383979234201027]
	TIME [epoch: 9.7 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9482150643204903		[learning rate: 0.0025636]
	Learning Rate: 0.00256355
	LOSS [training: 0.9482150643204903 | validation: 1.050973661143986]
	TIME [epoch: 9.72 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.013284972324962		[learning rate: 0.0025512]
	Learning Rate: 0.00255115
	LOSS [training: 1.013284972324962 | validation: 1.0336272124669563]
	TIME [epoch: 9.69 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3514154538793153		[learning rate: 0.0025388]
	Learning Rate: 0.00253882
	LOSS [training: 1.3514154538793153 | validation: 1.1939501798851704]
	TIME [epoch: 9.69 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1069375712806164		[learning rate: 0.0025265]
	Learning Rate: 0.00252654
	LOSS [training: 1.1069375712806164 | validation: 1.2523069866349354]
	TIME [epoch: 9.7 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1084402900476351		[learning rate: 0.0025143]
	Learning Rate: 0.00251432
	LOSS [training: 1.1084402900476351 | validation: 1.257283218493183]
	TIME [epoch: 9.7 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0694377347150383		[learning rate: 0.0025022]
	Learning Rate: 0.00250216
	LOSS [training: 1.0694377347150383 | validation: 1.2868957241468366]
	TIME [epoch: 9.7 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1081416226502898		[learning rate: 0.0024901]
	Learning Rate: 0.00249006
	LOSS [training: 1.1081416226502898 | validation: 1.1395238920943558]
	TIME [epoch: 9.7 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9539485417286236		[learning rate: 0.002478]
	Learning Rate: 0.00247802
	LOSS [training: 0.9539485417286236 | validation: 1.0684142921972597]
	TIME [epoch: 9.74 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.948100699708383		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 0.948100699708383 | validation: 1.1622152156248848]
	TIME [epoch: 9.7 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2845167433972582		[learning rate: 0.0024541]
	Learning Rate: 0.00245411
	LOSS [training: 1.2845167433972582 | validation: 1.4457677724195706]
	TIME [epoch: 9.7 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.133694516238585		[learning rate: 0.0024422]
	Learning Rate: 0.00244225
	LOSS [training: 1.133694516238585 | validation: 1.0529355878973479]
	TIME [epoch: 9.72 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0661201335368125		[learning rate: 0.0024304]
	Learning Rate: 0.00243044
	LOSS [training: 1.0661201335368125 | validation: 1.0041685272117256]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_342.pth
	Model improved!!!
EPOCH 343/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.015009573577597		[learning rate: 0.0024187]
	Learning Rate: 0.00241868
	LOSS [training: 1.015009573577597 | validation: 1.3636678520448493]
	TIME [epoch: 9.69 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1264673618944872		[learning rate: 0.002407]
	Learning Rate: 0.00240699
	LOSS [training: 1.1264673618944872 | validation: 1.148226564261362]
	TIME [epoch: 9.69 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.392407764113845		[learning rate: 0.0023953]
	Learning Rate: 0.00239535
	LOSS [training: 1.392407764113845 | validation: 1.5875272578975612]
	TIME [epoch: 9.73 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1540359538869536		[learning rate: 0.0023838]
	Learning Rate: 0.00238376
	LOSS [training: 1.1540359538869536 | validation: 1.3111344479472553]
	TIME [epoch: 9.69 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.97154393377135		[learning rate: 0.0023722]
	Learning Rate: 0.00237224
	LOSS [training: 0.97154393377135 | validation: 1.0496931736038229]
	TIME [epoch: 9.7 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9756008191139957		[learning rate: 0.0023608]
	Learning Rate: 0.00236076
	LOSS [training: 0.9756008191139957 | validation: 1.1681669110911426]
	TIME [epoch: 9.71 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0203903149673035		[learning rate: 0.0023493]
	Learning Rate: 0.00234935
	LOSS [training: 1.0203903149673035 | validation: 1.3464452402164915]
	TIME [epoch: 9.71 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0459414647257959		[learning rate: 0.002338]
	Learning Rate: 0.00233799
	LOSS [training: 1.0459414647257959 | validation: 1.1135848826355237]
	TIME [epoch: 9.7 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0073870109667775		[learning rate: 0.0023267]
	Learning Rate: 0.00232668
	LOSS [training: 1.0073870109667775 | validation: 1.185447596446017]
	TIME [epoch: 9.7 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9402984388011895		[learning rate: 0.0023154]
	Learning Rate: 0.00231543
	LOSS [training: 0.9402984388011895 | validation: 1.2900901037363321]
	TIME [epoch: 9.72 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1091528495966263		[learning rate: 0.0023042]
	Learning Rate: 0.00230423
	LOSS [training: 1.1091528495966263 | validation: 1.3431865384086643]
	TIME [epoch: 9.71 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.006679179478		[learning rate: 0.0022931]
	Learning Rate: 0.00229309
	LOSS [training: 1.006679179478 | validation: 1.1353058629708466]
	TIME [epoch: 9.7 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.012269415951618		[learning rate: 0.002282]
	Learning Rate: 0.002282
	LOSS [training: 1.012269415951618 | validation: 1.0240521185527056]
	TIME [epoch: 9.71 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9568856231043805		[learning rate: 0.002271]
	Learning Rate: 0.00227097
	LOSS [training: 0.9568856231043805 | validation: 1.3166975756125499]
	TIME [epoch: 9.69 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0793564279138717		[learning rate: 0.00226]
	Learning Rate: 0.00225998
	LOSS [training: 1.0793564279138717 | validation: 1.218038375848946]
	TIME [epoch: 9.69 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2500389777733365		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 1.2500389777733365 | validation: 1.3729238833712958]
	TIME [epoch: 9.69 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0229350062379632		[learning rate: 0.0022382]
	Learning Rate: 0.00223818
	LOSS [training: 1.0229350062379632 | validation: 1.3346828102758839]
	TIME [epoch: 9.72 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.019980449882833		[learning rate: 0.0022274]
	Learning Rate: 0.00222736
	LOSS [training: 1.019980449882833 | validation: 1.0628127856514262]
	TIME [epoch: 9.69 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.033953817140153		[learning rate: 0.0022166]
	Learning Rate: 0.00221658
	LOSS [training: 1.033953817140153 | validation: 1.2530958921327557]
	TIME [epoch: 9.71 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9695751734477831		[learning rate: 0.0022059]
	Learning Rate: 0.00220586
	LOSS [training: 0.9695751734477831 | validation: 1.2358819642230154]
	TIME [epoch: 9.72 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0485092854431932		[learning rate: 0.0021952]
	Learning Rate: 0.0021952
	LOSS [training: 1.0485092854431932 | validation: 1.1155310684324298]
	TIME [epoch: 9.7 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9903109733968669		[learning rate: 0.0021846]
	Learning Rate: 0.00218458
	LOSS [training: 0.9903109733968669 | validation: 1.201004163026136]
	TIME [epoch: 9.69 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9276893353914767		[learning rate: 0.002174]
	Learning Rate: 0.00217402
	LOSS [training: 0.9276893353914767 | validation: 1.102677558741923]
	TIME [epoch: 9.7 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9376895996523154		[learning rate: 0.0021635]
	Learning Rate: 0.0021635
	LOSS [training: 0.9376895996523154 | validation: 1.3270766079347975]
	TIME [epoch: 9.72 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0134081454672506		[learning rate: 0.002153]
	Learning Rate: 0.00215304
	LOSS [training: 1.0134081454672506 | validation: 1.197623866747668]
	TIME [epoch: 9.69 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9992523795704397		[learning rate: 0.0021426]
	Learning Rate: 0.00214263
	LOSS [training: 0.9992523795704397 | validation: 1.2652043411597975]
	TIME [epoch: 9.7 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9987668146192974		[learning rate: 0.0021323]
	Learning Rate: 0.00213227
	LOSS [training: 0.9987668146192974 | validation: 1.1451308751694698]
	TIME [epoch: 9.71 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9357584467729414		[learning rate: 0.002122]
	Learning Rate: 0.00212196
	LOSS [training: 0.9357584467729414 | validation: 1.0298568500922922]
	TIME [epoch: 9.68 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9145460679258886		[learning rate: 0.0021117]
	Learning Rate: 0.0021117
	LOSS [training: 0.9145460679258886 | validation: 1.066010757336089]
	TIME [epoch: 9.69 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9290517285968534		[learning rate: 0.0021015]
	Learning Rate: 0.00210149
	LOSS [training: 0.9290517285968534 | validation: 1.0063502492979033]
	TIME [epoch: 9.71 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0422550583169845		[learning rate: 0.0020913]
	Learning Rate: 0.00209132
	LOSS [training: 1.0422550583169845 | validation: 1.302057809048928]
	TIME [epoch: 9.71 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9913173435553462		[learning rate: 0.0020812]
	Learning Rate: 0.00208121
	LOSS [training: 0.9913173435553462 | validation: 1.1672649527975905]
	TIME [epoch: 9.69 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9291735626374276		[learning rate: 0.0020711]
	Learning Rate: 0.00207115
	LOSS [training: 0.9291735626374276 | validation: 1.0424601105905944]
	TIME [epoch: 9.71 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9223673169345743		[learning rate: 0.0020611]
	Learning Rate: 0.00206113
	LOSS [training: 0.9223673169345743 | validation: 1.263799941612937]
	TIME [epoch: 9.72 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8779453157116327		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 0.8779453157116327 | validation: 1.1867422321916223]
	TIME [epoch: 9.7 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9132179062911903		[learning rate: 0.0020412]
	Learning Rate: 0.00204124
	LOSS [training: 0.9132179062911903 | validation: 1.0138195288947287]
	TIME [epoch: 9.7 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9310089349581097		[learning rate: 0.0020314]
	Learning Rate: 0.00203137
	LOSS [training: 0.9310089349581097 | validation: 1.0815619454311347]
	TIME [epoch: 9.71 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8794127616180599		[learning rate: 0.0020215]
	Learning Rate: 0.00202155
	LOSS [training: 0.8794127616180599 | validation: 1.0532337053850882]
	TIME [epoch: 9.69 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8935994640981741		[learning rate: 0.0020118]
	Learning Rate: 0.00201177
	LOSS [training: 0.8935994640981741 | validation: 1.0768539062962186]
	TIME [epoch: 9.68 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.900407453053184		[learning rate: 0.002002]
	Learning Rate: 0.00200204
	LOSS [training: 0.900407453053184 | validation: 1.0047444623172543]
	TIME [epoch: 9.68 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8679863331063531		[learning rate: 0.0019924]
	Learning Rate: 0.00199236
	LOSS [training: 0.8679863331063531 | validation: 1.0436088149998874]
	TIME [epoch: 9.7 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8468395885664348		[learning rate: 0.0019827]
	Learning Rate: 0.00198273
	LOSS [training: 0.8468395885664348 | validation: 1.1378563770909331]
	TIME [epoch: 9.68 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8404072353864571		[learning rate: 0.0019731]
	Learning Rate: 0.00197314
	LOSS [training: 0.8404072353864571 | validation: 1.2049472246686255]
	TIME [epoch: 9.68 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9994952522280709		[learning rate: 0.0019636]
	Learning Rate: 0.0019636
	LOSS [training: 0.9994952522280709 | validation: 1.0309311981710332]
	TIME [epoch: 9.71 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.895177764921679		[learning rate: 0.0019541]
	Learning Rate: 0.0019541
	LOSS [training: 0.895177764921679 | validation: 1.0291805766381503]
	TIME [epoch: 9.68 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8279645591354188		[learning rate: 0.0019447]
	Learning Rate: 0.00194465
	LOSS [training: 0.8279645591354188 | validation: 1.0223982904180997]
	TIME [epoch: 9.68 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8155879385358556		[learning rate: 0.0019352]
	Learning Rate: 0.00193525
	LOSS [training: 0.8155879385358556 | validation: 0.9728461454858999]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_389.pth
	Model improved!!!
EPOCH 390/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9213675926736509		[learning rate: 0.0019259]
	Learning Rate: 0.00192589
	LOSS [training: 0.9213675926736509 | validation: 1.076177692055326]
	TIME [epoch: 9.7 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.870939246845343		[learning rate: 0.0019166]
	Learning Rate: 0.00191658
	LOSS [training: 0.870939246845343 | validation: 1.0787292257979952]
	TIME [epoch: 9.69 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9128100092121206		[learning rate: 0.0019073]
	Learning Rate: 0.00190731
	LOSS [training: 0.9128100092121206 | validation: 1.0893100367727062]
	TIME [epoch: 9.7 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9812710028867648		[learning rate: 0.0018981]
	Learning Rate: 0.00189809
	LOSS [training: 0.9812710028867648 | validation: 1.128495046852923]
	TIME [epoch: 9.72 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8976826905711229		[learning rate: 0.0018889]
	Learning Rate: 0.00188891
	LOSS [training: 0.8976826905711229 | validation: 1.0875313636905939]
	TIME [epoch: 9.71 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.903240624146244		[learning rate: 0.0018798]
	Learning Rate: 0.00187977
	LOSS [training: 0.903240624146244 | validation: 1.0072783309878877]
	TIME [epoch: 9.68 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8779135258212282		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 0.8779135258212282 | validation: 1.5133724007377083]
	TIME [epoch: 9.7 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1260822105660753		[learning rate: 0.0018616]
	Learning Rate: 0.00186164
	LOSS [training: 1.1260822105660753 | validation: 1.2015125144366041]
	TIME [epoch: 9.72 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9450326364468518		[learning rate: 0.0018526]
	Learning Rate: 0.00185263
	LOSS [training: 0.9450326364468518 | validation: 0.9995312701368474]
	TIME [epoch: 9.69 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.096353926933187		[learning rate: 0.0018437]
	Learning Rate: 0.00184367
	LOSS [training: 1.096353926933187 | validation: 1.0601201955001323]
	TIME [epoch: 9.7 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8291563902607267		[learning rate: 0.0018348]
	Learning Rate: 0.00183476
	LOSS [training: 0.8291563902607267 | validation: 1.158007998780246]
	TIME [epoch: 9.72 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9579487796451349		[learning rate: 0.0018259]
	Learning Rate: 0.00182589
	LOSS [training: 0.9579487796451349 | validation: 1.3176730280486322]
	TIME [epoch: 9.69 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9680597697927352		[learning rate: 0.0018171]
	Learning Rate: 0.00181706
	LOSS [training: 0.9680597697927352 | validation: 0.9755130120305401]
	TIME [epoch: 9.7 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8896112783614715		[learning rate: 0.0018083]
	Learning Rate: 0.00180827
	LOSS [training: 0.8896112783614715 | validation: 1.040999266179018]
	TIME [epoch: 9.71 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8277780917359457		[learning rate: 0.0017995]
	Learning Rate: 0.00179952
	LOSS [training: 0.8277780917359457 | validation: 0.9413814525914959]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_404.pth
	Model improved!!!
EPOCH 405/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9382195331079423		[learning rate: 0.0017908]
	Learning Rate: 0.00179082
	LOSS [training: 0.9382195331079423 | validation: 1.1302484292220314]
	TIME [epoch: 9.69 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8602947561124872		[learning rate: 0.0017822]
	Learning Rate: 0.00178216
	LOSS [training: 0.8602947561124872 | validation: 1.006674457745774]
	TIME [epoch: 9.68 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8944637104445959		[learning rate: 0.0017735]
	Learning Rate: 0.00177354
	LOSS [training: 0.8944637104445959 | validation: 0.9561258951060632]
	TIME [epoch: 9.71 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0015509120297539		[learning rate: 0.001765]
	Learning Rate: 0.00176497
	LOSS [training: 1.0015509120297539 | validation: 1.0758527606859287]
	TIME [epoch: 9.69 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8586909795894894		[learning rate: 0.0017564]
	Learning Rate: 0.00175643
	LOSS [training: 0.8586909795894894 | validation: 0.9743878414538284]
	TIME [epoch: 9.68 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8458106193458835		[learning rate: 0.0017479]
	Learning Rate: 0.00174794
	LOSS [training: 0.8458106193458835 | validation: 1.0220460786047678]
	TIME [epoch: 9.71 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8400273606190567		[learning rate: 0.0017395]
	Learning Rate: 0.00173949
	LOSS [training: 0.8400273606190567 | validation: 0.9778873382150138]
	TIME [epoch: 9.71 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8605856712917346		[learning rate: 0.0017311]
	Learning Rate: 0.00173107
	LOSS [training: 0.8605856712917346 | validation: 1.0782604928556]
	TIME [epoch: 9.68 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0704033386543361		[learning rate: 0.0017227]
	Learning Rate: 0.0017227
	LOSS [training: 1.0704033386543361 | validation: 1.0007011359053037]
	TIME [epoch: 9.69 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8592363233894172		[learning rate: 0.0017144]
	Learning Rate: 0.00171437
	LOSS [training: 0.8592363233894172 | validation: 1.0043537952962684]
	TIME [epoch: 9.71 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9182924678290589		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 0.9182924678290589 | validation: 1.1698452338513976]
	TIME [epoch: 9.69 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9812341237451527		[learning rate: 0.0016978]
	Learning Rate: 0.00169783
	LOSS [training: 0.9812341237451527 | validation: 1.043491013337873]
	TIME [epoch: 9.7 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.098189780958815		[learning rate: 0.0016896]
	Learning Rate: 0.00168962
	LOSS [training: 1.098189780958815 | validation: 1.088310449467388]
	TIME [epoch: 9.73 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8308950526991291		[learning rate: 0.0016815]
	Learning Rate: 0.00168145
	LOSS [training: 0.8308950526991291 | validation: 0.933278594918834]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_418.pth
	Model improved!!!
EPOCH 419/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7967704958325432		[learning rate: 0.0016733]
	Learning Rate: 0.00167332
	LOSS [training: 0.7967704958325432 | validation: 1.3071494474930767]
	TIME [epoch: 10 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8634116668874885		[learning rate: 0.0016652]
	Learning Rate: 0.00166523
	LOSS [training: 0.8634116668874885 | validation: 1.0473064279133106]
	TIME [epoch: 9.7 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8759758518657437		[learning rate: 0.0016572]
	Learning Rate: 0.00165718
	LOSS [training: 0.8759758518657437 | validation: 0.9533029527887427]
	TIME [epoch: 9.72 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8335304269305744		[learning rate: 0.0016492]
	Learning Rate: 0.00164916
	LOSS [training: 0.8335304269305744 | validation: 0.9436934245006782]
	TIME [epoch: 9.7 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.919866492667472		[learning rate: 0.0016412]
	Learning Rate: 0.00164119
	LOSS [training: 0.919866492667472 | validation: 1.0717104654725977]
	TIME [epoch: 9.7 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9994583881243692		[learning rate: 0.0016332]
	Learning Rate: 0.00163325
	LOSS [training: 0.9994583881243692 | validation: 1.2130479594285253]
	TIME [epoch: 9.72 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0650848755193199		[learning rate: 0.0016254]
	Learning Rate: 0.00162535
	LOSS [training: 1.0650848755193199 | validation: 1.5286885408578688]
	TIME [epoch: 9.7 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0493312784979627		[learning rate: 0.0016175]
	Learning Rate: 0.00161749
	LOSS [training: 1.0493312784979627 | validation: 1.0192267504930743]
	TIME [epoch: 9.7 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9356155315961294		[learning rate: 0.0016097]
	Learning Rate: 0.00160967
	LOSS [training: 0.9356155315961294 | validation: 0.9579322227498408]
	TIME [epoch: 9.7 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9024144376710866		[learning rate: 0.0016019]
	Learning Rate: 0.00160189
	LOSS [training: 0.9024144376710866 | validation: 1.1767507626778546]
	TIME [epoch: 9.72 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8935694328934682		[learning rate: 0.0015941]
	Learning Rate: 0.00159414
	LOSS [training: 0.8935694328934682 | validation: 1.068689176966718]
	TIME [epoch: 9.7 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9510446141617728		[learning rate: 0.0015864]
	Learning Rate: 0.00158643
	LOSS [training: 0.9510446141617728 | validation: 1.0910510373409392]
	TIME [epoch: 9.7 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8690470025311992		[learning rate: 0.0015788]
	Learning Rate: 0.00157876
	LOSS [training: 0.8690470025311992 | validation: 1.0432737683452107]
	TIME [epoch: 9.72 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8055368636233512		[learning rate: 0.0015711]
	Learning Rate: 0.00157112
	LOSS [training: 0.8055368636233512 | validation: 1.0105507554395285]
	TIME [epoch: 9.7 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.827125184357261		[learning rate: 0.0015635]
	Learning Rate: 0.00156353
	LOSS [training: 0.827125184357261 | validation: 1.0047346357288993]
	TIME [epoch: 9.7 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8451131149299341		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 0.8451131149299341 | validation: 0.909183099098217]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_434.pth
	Model improved!!!
EPOCH 435/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8264485233604353		[learning rate: 0.0015484]
	Learning Rate: 0.00154844
	LOSS [training: 0.8264485233604353 | validation: 1.0015746214919943]
	TIME [epoch: 9.72 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7765979244361272		[learning rate: 0.001541]
	Learning Rate: 0.00154095
	LOSS [training: 0.7765979244361272 | validation: 1.0389293946981837]
	TIME [epoch: 9.69 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9198911754311722		[learning rate: 0.0015335]
	Learning Rate: 0.0015335
	LOSS [training: 0.9198911754311722 | validation: 1.4068426465733674]
	TIME [epoch: 9.69 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0244709407663557		[learning rate: 0.0015261]
	Learning Rate: 0.00152609
	LOSS [training: 1.0244709407663557 | validation: 0.9914753959483054]
	TIME [epoch: 9.72 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0708146429853183		[learning rate: 0.0015187]
	Learning Rate: 0.00151871
	LOSS [training: 1.0708146429853183 | validation: 1.0741999144178285]
	TIME [epoch: 9.7 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.890579529307869		[learning rate: 0.0015114]
	Learning Rate: 0.00151136
	LOSS [training: 0.890579529307869 | validation: 1.099390599046562]
	TIME [epoch: 9.69 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8204887032588927		[learning rate: 0.0015041]
	Learning Rate: 0.00150405
	LOSS [training: 0.8204887032588927 | validation: 0.9628124192981521]
	TIME [epoch: 9.69 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9072106068971543		[learning rate: 0.0014968]
	Learning Rate: 0.00149678
	LOSS [training: 0.9072106068971543 | validation: 1.029961750044563]
	TIME [epoch: 9.72 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.772154151306354		[learning rate: 0.0014895]
	Learning Rate: 0.00148954
	LOSS [training: 0.772154151306354 | validation: 0.9095988709082535]
	TIME [epoch: 9.7 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8081876435952047		[learning rate: 0.0014823]
	Learning Rate: 0.00148234
	LOSS [training: 0.8081876435952047 | validation: 1.1121968180358652]
	TIME [epoch: 9.69 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.977135872621098		[learning rate: 0.0014752]
	Learning Rate: 0.00147517
	LOSS [training: 0.977135872621098 | validation: 1.6916856316851883]
	TIME [epoch: 9.72 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1214056781434203		[learning rate: 0.001468]
	Learning Rate: 0.00146804
	LOSS [training: 1.1214056781434203 | validation: 1.1608283177865015]
	TIME [epoch: 9.7 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9400365122453532		[learning rate: 0.0014609]
	Learning Rate: 0.00146094
	LOSS [training: 0.9400365122453532 | validation: 0.9682503035213746]
	TIME [epoch: 9.69 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7511825752163984		[learning rate: 0.0014539]
	Learning Rate: 0.00145387
	LOSS [training: 0.7511825752163984 | validation: 1.009251419056458]
	TIME [epoch: 9.7 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9316095402997678		[learning rate: 0.0014468]
	Learning Rate: 0.00144684
	LOSS [training: 0.9316095402997678 | validation: 1.0205219086441353]
	TIME [epoch: 9.71 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8278787362404252		[learning rate: 0.0014398]
	Learning Rate: 0.00143985
	LOSS [training: 0.8278787362404252 | validation: 0.995821740678532]
	TIME [epoch: 9.69 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8081012521749663		[learning rate: 0.0014329]
	Learning Rate: 0.00143288
	LOSS [training: 0.8081012521749663 | validation: 1.0057277644280769]
	TIME [epoch: 9.69 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7966685473461786		[learning rate: 0.001426]
	Learning Rate: 0.00142595
	LOSS [training: 0.7966685473461786 | validation: 0.9486898260865628]
	TIME [epoch: 9.73 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.835117765804369		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.835117765804369 | validation: 1.0233215822925343]
	TIME [epoch: 9.69 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.757384373829732		[learning rate: 0.0014122]
	Learning Rate: 0.0014122
	LOSS [training: 0.757384373829732 | validation: 1.0554950118565425]
	TIME [epoch: 9.69 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9200054938700463		[learning rate: 0.0014054]
	Learning Rate: 0.00140537
	LOSS [training: 0.9200054938700463 | validation: 0.9695603648707851]
	TIME [epoch: 9.72 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.76586802883619		[learning rate: 0.0013986]
	Learning Rate: 0.00139857
	LOSS [training: 0.76586802883619 | validation: 1.0381600387805927]
	TIME [epoch: 9.71 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8449925553359241		[learning rate: 0.0013918]
	Learning Rate: 0.00139181
	LOSS [training: 0.8449925553359241 | validation: 0.9733014200196106]
	TIME [epoch: 9.69 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8924498795774664		[learning rate: 0.0013851]
	Learning Rate: 0.00138508
	LOSS [training: 0.8924498795774664 | validation: 1.1683199915766402]
	TIME [epoch: 9.7 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8384338222848964		[learning rate: 0.0013784]
	Learning Rate: 0.00137838
	LOSS [training: 0.8384338222848964 | validation: 1.0445660847920502]
	TIME [epoch: 9.72 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7900661650693943		[learning rate: 0.0013717]
	Learning Rate: 0.00137171
	LOSS [training: 0.7900661650693943 | validation: 0.8988161798714857]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_460.pth
	Model improved!!!
EPOCH 461/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7873849891590495		[learning rate: 0.0013651]
	Learning Rate: 0.00136508
	LOSS [training: 0.7873849891590495 | validation: 1.0459579228233784]
	TIME [epoch: 9.7 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7535103429685952		[learning rate: 0.0013585]
	Learning Rate: 0.00135848
	LOSS [training: 0.7535103429685952 | validation: 0.9532309324987276]
	TIME [epoch: 9.72 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9253516464954255		[learning rate: 0.0013519]
	Learning Rate: 0.00135191
	LOSS [training: 0.9253516464954255 | validation: 0.9617483937070631]
	TIME [epoch: 9.7 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7730906227770917		[learning rate: 0.0013454]
	Learning Rate: 0.00134537
	LOSS [training: 0.7730906227770917 | validation: 0.890769265847577]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_464.pth
	Model improved!!!
EPOCH 465/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7278441586103032		[learning rate: 0.0013389]
	Learning Rate: 0.00133887
	LOSS [training: 0.7278441586103032 | validation: 0.9996633693331859]
	TIME [epoch: 9.7 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8742313005205572		[learning rate: 0.0013324]
	Learning Rate: 0.00133239
	LOSS [training: 0.8742313005205572 | validation: 1.0082841827605493]
	TIME [epoch: 9.72 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7768853554061185		[learning rate: 0.0013259]
	Learning Rate: 0.00132595
	LOSS [training: 0.7768853554061185 | validation: 1.0901216585384579]
	TIME [epoch: 9.7 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8740519198609501		[learning rate: 0.0013195]
	Learning Rate: 0.00131954
	LOSS [training: 0.8740519198609501 | validation: 1.0246775792944482]
	TIME [epoch: 9.7 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8166977455905016		[learning rate: 0.0013132]
	Learning Rate: 0.00131315
	LOSS [training: 0.8166977455905016 | validation: 1.2221718884746744]
	TIME [epoch: 9.7 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9223036414141937		[learning rate: 0.0013068]
	Learning Rate: 0.0013068
	LOSS [training: 0.9223036414141937 | validation: 1.0724904619107127]
	TIME [epoch: 9.72 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0095075082074338		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 1.0095075082074338 | validation: 1.0441416292911598]
	TIME [epoch: 9.7 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7441150586024536		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 0.7441150586024536 | validation: 0.921748317917318]
	TIME [epoch: 9.7 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7782005992109134		[learning rate: 0.0012879]
	Learning Rate: 0.00128794
	LOSS [training: 0.7782005992109134 | validation: 1.073015582622498]
	TIME [epoch: 9.72 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8391698812737529		[learning rate: 0.0012817]
	Learning Rate: 0.00128171
	LOSS [training: 0.8391698812737529 | validation: 0.9486631093043559]
	TIME [epoch: 9.69 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7550505852803616		[learning rate: 0.0012755]
	Learning Rate: 0.00127551
	LOSS [training: 0.7550505852803616 | validation: 1.0493381524139245]
	TIME [epoch: 9.69 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8486673864501941		[learning rate: 0.0012693]
	Learning Rate: 0.00126934
	LOSS [training: 0.8486673864501941 | validation: 1.0195493253691001]
	TIME [epoch: 9.71 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7648272811195823		[learning rate: 0.0012632]
	Learning Rate: 0.0012632
	LOSS [training: 0.7648272811195823 | validation: 1.1069461309365236]
	TIME [epoch: 9.7 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8362465174395908		[learning rate: 0.0012571]
	Learning Rate: 0.0012571
	LOSS [training: 0.8362465174395908 | validation: 0.9960720676679448]
	TIME [epoch: 9.69 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8125924901536038		[learning rate: 0.001251]
	Learning Rate: 0.00125102
	LOSS [training: 0.8125924901536038 | validation: 1.0342879569111691]
	TIME [epoch: 9.69 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7353872578133648		[learning rate: 0.001245]
	Learning Rate: 0.00124497
	LOSS [training: 0.7353872578133648 | validation: 1.0001509652752703]
	TIME [epoch: 9.72 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7749024545867262		[learning rate: 0.0012389]
	Learning Rate: 0.00123895
	LOSS [training: 0.7749024545867262 | validation: 0.9140129958254539]
	TIME [epoch: 9.7 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7248542958253434		[learning rate: 0.001233]
	Learning Rate: 0.00123296
	LOSS [training: 0.7248542958253434 | validation: 0.8734591004696256]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_482.pth
	Model improved!!!
EPOCH 483/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7296057765481676		[learning rate: 0.001227]
	Learning Rate: 0.00122699
	LOSS [training: 0.7296057765481676 | validation: 0.9041640415752753]
	TIME [epoch: 9.71 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7534229983795591		[learning rate: 0.0012211]
	Learning Rate: 0.00122106
	LOSS [training: 0.7534229983795591 | validation: 1.18085381452371]
	TIME [epoch: 9.69 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8837826927372496		[learning rate: 0.0012152]
	Learning Rate: 0.00121515
	LOSS [training: 0.8837826927372496 | validation: 0.9287923167916411]
	TIME [epoch: 9.68 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.729378253053801		[learning rate: 0.0012093]
	Learning Rate: 0.00120928
	LOSS [training: 0.729378253053801 | validation: 0.8936126085201509]
	TIME [epoch: 9.68 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7217695150563739		[learning rate: 0.0012034]
	Learning Rate: 0.00120343
	LOSS [training: 0.7217695150563739 | validation: 0.8916034812898493]
	TIME [epoch: 9.71 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7551487993845466		[learning rate: 0.0011976]
	Learning Rate: 0.00119761
	LOSS [training: 0.7551487993845466 | validation: 1.067512157550389]
	TIME [epoch: 9.68 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7685552567421075		[learning rate: 0.0011918]
	Learning Rate: 0.00119182
	LOSS [training: 0.7685552567421075 | validation: 0.9514162364594103]
	TIME [epoch: 9.68 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7039805846567115		[learning rate: 0.0011861]
	Learning Rate: 0.00118606
	LOSS [training: 0.7039805846567115 | validation: 0.9336074667077204]
	TIME [epoch: 9.7 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7508916955623309		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.7508916955623309 | validation: 0.8872801106075886]
	TIME [epoch: 9.69 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7607464571138662		[learning rate: 0.0011746]
	Learning Rate: 0.00117461
	LOSS [training: 0.7607464571138662 | validation: 0.9657096422695748]
	TIME [epoch: 9.68 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7581422549510228		[learning rate: 0.0011689]
	Learning Rate: 0.00116893
	LOSS [training: 0.7581422549510228 | validation: 0.956984511086105]
	TIME [epoch: 9.69 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6999705774818196		[learning rate: 0.0011633]
	Learning Rate: 0.00116328
	LOSS [training: 0.6999705774818196 | validation: 1.0043850708634283]
	TIME [epoch: 9.73 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7537870043575599		[learning rate: 0.0011577]
	Learning Rate: 0.00115765
	LOSS [training: 0.7537870043575599 | validation: 0.9540330841019986]
	TIME [epoch: 9.69 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7187768359385969		[learning rate: 0.0011521]
	Learning Rate: 0.00115206
	LOSS [training: 0.7187768359385969 | validation: 0.9367245444198775]
	TIME [epoch: 9.68 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8065075984978496		[learning rate: 0.0011465]
	Learning Rate: 0.00114648
	LOSS [training: 0.8065075984978496 | validation: 0.9553266030374793]
	TIME [epoch: 9.7 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.749727746722628		[learning rate: 0.0011409]
	Learning Rate: 0.00114094
	LOSS [training: 0.749727746722628 | validation: 0.9096695301102589]
	TIME [epoch: 9.68 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7354736261074717		[learning rate: 0.0011354]
	Learning Rate: 0.00113542
	LOSS [training: 0.7354736261074717 | validation: 0.9236827510053095]
	TIME [epoch: 9.69 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8035233421742811		[learning rate: 0.0011299]
	Learning Rate: 0.00112993
	LOSS [training: 0.8035233421742811 | validation: 0.9217980386983876]
	TIME [epoch: 9.7 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7324243270969367		[learning rate: 0.0011245]
	Learning Rate: 0.00112447
	LOSS [training: 0.7324243270969367 | validation: 0.9396705204639685]
	TIME [epoch: 9.71 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7448010762791536		[learning rate: 0.001119]
	Learning Rate: 0.00111903
	LOSS [training: 0.7448010762791536 | validation: 0.9877417163460135]
	TIME [epoch: 9.69 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7431904924556851		[learning rate: 0.0011136]
	Learning Rate: 0.00111362
	LOSS [training: 0.7431904924556851 | validation: 0.9730640356656076]
	TIME [epoch: 9.69 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7516249253653734		[learning rate: 0.0011082]
	Learning Rate: 0.00110823
	LOSS [training: 0.7516249253653734 | validation: 1.0439183449814968]
	TIME [epoch: 9.73 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7866343404488141		[learning rate: 0.0011029]
	Learning Rate: 0.00110287
	LOSS [training: 0.7866343404488141 | validation: 0.9409009369025368]
	TIME [epoch: 9.7 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7617917969433179		[learning rate: 0.0010975]
	Learning Rate: 0.00109754
	LOSS [training: 0.7617917969433179 | validation: 0.9556208562469135]
	TIME [epoch: 9.69 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7706244858322737		[learning rate: 0.0010922]
	Learning Rate: 0.00109223
	LOSS [training: 0.7706244858322737 | validation: 1.0553068253846332]
	TIME [epoch: 9.72 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8414454425713626		[learning rate: 0.001087]
	Learning Rate: 0.00108695
	LOSS [training: 0.8414454425713626 | validation: 1.0984784896614204]
	TIME [epoch: 9.71 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7918542384633764		[learning rate: 0.0010817]
	Learning Rate: 0.0010817
	LOSS [training: 0.7918542384633764 | validation: 1.1358151339831246]
	TIME [epoch: 9.71 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7856083275393326		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.7856083275393326 | validation: 1.0213153741861623]
	TIME [epoch: 9.7 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7471365491119387		[learning rate: 0.0010713]
	Learning Rate: 0.00107126
	LOSS [training: 0.7471365491119387 | validation: 0.9296474620574645]
	TIME [epoch: 9.73 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7738556910183199		[learning rate: 0.0010661]
	Learning Rate: 0.00106608
	LOSS [training: 0.7738556910183199 | validation: 1.001066878637158]
	TIME [epoch: 9.71 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7850283034052691		[learning rate: 0.0010609]
	Learning Rate: 0.00106092
	LOSS [training: 0.7850283034052691 | validation: 0.9672083275019562]
	TIME [epoch: 9.71 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7982183829630166		[learning rate: 0.0010558]
	Learning Rate: 0.00105579
	LOSS [training: 0.7982183829630166 | validation: 0.9589869891525042]
	TIME [epoch: 9.72 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.751260935080421		[learning rate: 0.0010507]
	Learning Rate: 0.00105069
	LOSS [training: 0.751260935080421 | validation: 0.9534087430555421]
	TIME [epoch: 9.71 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7546792875778696		[learning rate: 0.0010456]
	Learning Rate: 0.00104561
	LOSS [training: 0.7546792875778696 | validation: 0.9092953011182917]
	TIME [epoch: 9.7 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.72409248754648		[learning rate: 0.0010406]
	Learning Rate: 0.00104055
	LOSS [training: 0.72409248754648 | validation: 0.9449287736099102]
	TIME [epoch: 9.71 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7556228533137841		[learning rate: 0.0010355]
	Learning Rate: 0.00103552
	LOSS [training: 0.7556228533137841 | validation: 0.9827481897171296]
	TIME [epoch: 9.73 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8114321847483428		[learning rate: 0.0010305]
	Learning Rate: 0.00103051
	LOSS [training: 0.8114321847483428 | validation: 0.9163589684100043]
	TIME [epoch: 9.7 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7193438778478634		[learning rate: 0.0010255]
	Learning Rate: 0.00102553
	LOSS [training: 0.7193438778478634 | validation: 1.1221850763930892]
	TIME [epoch: 9.7 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8134151511144548		[learning rate: 0.0010206]
	Learning Rate: 0.00102057
	LOSS [training: 0.8134151511144548 | validation: 0.933410027429814]
	TIME [epoch: 9.73 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7185948283130964		[learning rate: 0.0010156]
	Learning Rate: 0.00101563
	LOSS [training: 0.7185948283130964 | validation: 1.0072890385299103]
	TIME [epoch: 9.7 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8587329809946154		[learning rate: 0.0010107]
	Learning Rate: 0.00101072
	LOSS [training: 0.8587329809946154 | validation: 1.0509935772839853]
	TIME [epoch: 9.71 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.779484993920994		[learning rate: 0.0010058]
	Learning Rate: 0.00100583
	LOSS [training: 0.779484993920994 | validation: 1.0267611743072704]
	TIME [epoch: 9.71 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8075252398340274		[learning rate: 0.001001]
	Learning Rate: 0.00100097
	LOSS [training: 0.8075252398340274 | validation: 0.9451542987254865]
	TIME [epoch: 9.73 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7251709680592617		[learning rate: 0.00099613]
	Learning Rate: 0.000996129
	LOSS [training: 0.7251709680592617 | validation: 0.904965648968902]
	TIME [epoch: 9.7 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6835264898325699		[learning rate: 0.00099131]
	Learning Rate: 0.000991312
	LOSS [training: 0.6835264898325699 | validation: 0.8613098367655162]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_527.pth
	Model improved!!!
EPOCH 528/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6673433624874424		[learning rate: 0.00098652]
	Learning Rate: 0.000986519
	LOSS [training: 0.6673433624874424 | validation: 0.9017069788597687]
	TIME [epoch: 9.71 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6697710630802927		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 0.6697710630802927 | validation: 0.887703342842602]
	TIME [epoch: 9.69 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7428908957786379		[learning rate: 0.000977]
	Learning Rate: 0.000977
	LOSS [training: 0.7428908957786379 | validation: 0.9751455247679326]
	TIME [epoch: 9.69 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7484725526046351		[learning rate: 0.00097228]
	Learning Rate: 0.000972276
	LOSS [training: 0.7484725526046351 | validation: 0.9153845493584719]
	TIME [epoch: 9.69 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6952164777769528		[learning rate: 0.00096757]
	Learning Rate: 0.000967574
	LOSS [training: 0.6952164777769528 | validation: 0.8949231730563293]
	TIME [epoch: 9.71 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6868090800980715		[learning rate: 0.00096289]
	Learning Rate: 0.000962895
	LOSS [training: 0.6868090800980715 | validation: 0.9316321701445407]
	TIME [epoch: 9.69 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7215587292909514		[learning rate: 0.00095824]
	Learning Rate: 0.000958239
	LOSS [training: 0.7215587292909514 | validation: 0.9549719121448927]
	TIME [epoch: 9.69 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.804068200374956		[learning rate: 0.0009536]
	Learning Rate: 0.000953605
	LOSS [training: 0.804068200374956 | validation: 1.0078755594478959]
	TIME [epoch: 9.71 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7086169906593061		[learning rate: 0.00094899]
	Learning Rate: 0.000948993
	LOSS [training: 0.7086169906593061 | validation: 0.9889628197619311]
	TIME [epoch: 9.69 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6913148006698595		[learning rate: 0.0009444]
	Learning Rate: 0.000944404
	LOSS [training: 0.6913148006698595 | validation: 0.8754907778646197]
	TIME [epoch: 9.69 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7186341771541757		[learning rate: 0.00093984]
	Learning Rate: 0.000939837
	LOSS [training: 0.7186341771541757 | validation: 0.9456626832546858]
	TIME [epoch: 9.71 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6889819222080841		[learning rate: 0.00093529]
	Learning Rate: 0.000935292
	LOSS [training: 0.6889819222080841 | validation: 0.8960906222323175]
	TIME [epoch: 9.7 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7300824750366959		[learning rate: 0.00093077]
	Learning Rate: 0.000930769
	LOSS [training: 0.7300824750366959 | validation: 0.9114041294444829]
	TIME [epoch: 9.69 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.718021652552929		[learning rate: 0.00092627]
	Learning Rate: 0.000926268
	LOSS [training: 0.718021652552929 | validation: 0.8861284504031812]
	TIME [epoch: 9.69 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.751508907378823		[learning rate: 0.00092179]
	Learning Rate: 0.000921789
	LOSS [training: 0.751508907378823 | validation: 0.945912284815325]
	TIME [epoch: 9.71 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7276537932321653		[learning rate: 0.00091733]
	Learning Rate: 0.000917331
	LOSS [training: 0.7276537932321653 | validation: 0.9784589603769142]
	TIME [epoch: 9.69 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8006122398985352		[learning rate: 0.0009129]
	Learning Rate: 0.000912895
	LOSS [training: 0.8006122398985352 | validation: 1.0117189113790017]
	TIME [epoch: 9.68 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7380788502515367		[learning rate: 0.00090848]
	Learning Rate: 0.000908481
	LOSS [training: 0.7380788502515367 | validation: 1.0646950671051507]
	TIME [epoch: 9.71 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7719934826707401		[learning rate: 0.00090409]
	Learning Rate: 0.000904088
	LOSS [training: 0.7719934826707401 | validation: 0.9607598622825048]
	TIME [epoch: 9.69 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7223085532609748		[learning rate: 0.00089972]
	Learning Rate: 0.000899716
	LOSS [training: 0.7223085532609748 | validation: 0.8871491389406683]
	TIME [epoch: 9.69 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7697356867139505		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.7697356867139505 | validation: 1.0219651767120976]
	TIME [epoch: 9.69 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7577010265175113		[learning rate: 0.00089104]
	Learning Rate: 0.000891035
	LOSS [training: 0.7577010265175113 | validation: 0.9141832861159966]
	TIME [epoch: 9.71 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7240838606146385		[learning rate: 0.00088673]
	Learning Rate: 0.000886726
	LOSS [training: 0.7240838606146385 | validation: 0.9590861913382751]
	TIME [epoch: 9.69 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7537081149216207		[learning rate: 0.00088244]
	Learning Rate: 0.000882438
	LOSS [training: 0.7537081149216207 | validation: 0.9923694100502828]
	TIME [epoch: 9.69 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7103685348084278		[learning rate: 0.00087817]
	Learning Rate: 0.000878171
	LOSS [training: 0.7103685348084278 | validation: 1.0361848613576488]
	TIME [epoch: 9.71 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7413484777073689		[learning rate: 0.00087392]
	Learning Rate: 0.000873924
	LOSS [training: 0.7413484777073689 | validation: 0.9968099516388219]
	TIME [epoch: 9.69 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7219459376459503		[learning rate: 0.0008697]
	Learning Rate: 0.000869698
	LOSS [training: 0.7219459376459503 | validation: 0.9736533164178858]
	TIME [epoch: 9.69 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.734177119628833		[learning rate: 0.00086549]
	Learning Rate: 0.000865492
	LOSS [training: 0.734177119628833 | validation: 0.9350291871611809]
	TIME [epoch: 9.69 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7585608575052317		[learning rate: 0.00086131]
	Learning Rate: 0.000861307
	LOSS [training: 0.7585608575052317 | validation: 0.917984028746931]
	TIME [epoch: 9.71 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.706413407713721		[learning rate: 0.00085714]
	Learning Rate: 0.000857142
	LOSS [training: 0.706413407713721 | validation: 0.9084009877971378]
	TIME [epoch: 9.69 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7103367503245666		[learning rate: 0.000853]
	Learning Rate: 0.000852997
	LOSS [training: 0.7103367503245666 | validation: 0.9717629684232219]
	TIME [epoch: 9.69 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7418551706562541		[learning rate: 0.00084887]
	Learning Rate: 0.000848872
	LOSS [training: 0.7418551706562541 | validation: 0.9364767556403126]
	TIME [epoch: 9.71 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.731885591578848		[learning rate: 0.00084477]
	Learning Rate: 0.000844767
	LOSS [training: 0.731885591578848 | validation: 0.8679508832081438]
	TIME [epoch: 9.69 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.692875956562235		[learning rate: 0.00084068]
	Learning Rate: 0.000840682
	LOSS [training: 0.692875956562235 | validation: 0.9876620449860142]
	TIME [epoch: 9.68 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7743199264110984		[learning rate: 0.00083662]
	Learning Rate: 0.000836616
	LOSS [training: 0.7743199264110984 | validation: 0.9413707997484169]
	TIME [epoch: 9.71 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.736695530669981		[learning rate: 0.00083257]
	Learning Rate: 0.000832571
	LOSS [training: 0.736695530669981 | validation: 0.9608126083043266]
	TIME [epoch: 9.69 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7143379466242709		[learning rate: 0.00082854]
	Learning Rate: 0.000828544
	LOSS [training: 0.7143379466242709 | validation: 0.936083818647567]
	TIME [epoch: 9.69 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7677390426023138		[learning rate: 0.00082454]
	Learning Rate: 0.000824538
	LOSS [training: 0.7677390426023138 | validation: 0.9686909062962019]
	TIME [epoch: 9.69 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7485077621322879		[learning rate: 0.00082055]
	Learning Rate: 0.00082055
	LOSS [training: 0.7485077621322879 | validation: 0.8947157340204782]
	TIME [epoch: 9.71 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7115899262173109		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.7115899262173109 | validation: 0.878686938042236]
	TIME [epoch: 9.69 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6822928358440331		[learning rate: 0.00081263]
	Learning Rate: 0.000812633
	LOSS [training: 0.6822928358440331 | validation: 0.9707479329100478]
	TIME [epoch: 9.69 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7044332725594373		[learning rate: 0.0008087]
	Learning Rate: 0.000808704
	LOSS [training: 0.7044332725594373 | validation: 0.8800500153717215]
	TIME [epoch: 9.71 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.661215470425355		[learning rate: 0.00080479]
	Learning Rate: 0.000804793
	LOSS [training: 0.661215470425355 | validation: 0.86622040700482]
	TIME [epoch: 9.69 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6867699708297003		[learning rate: 0.0008009]
	Learning Rate: 0.000800901
	LOSS [training: 0.6867699708297003 | validation: 0.8980332337914244]
	TIME [epoch: 9.69 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6651300440610373		[learning rate: 0.00079703]
	Learning Rate: 0.000797028
	LOSS [training: 0.6651300440610373 | validation: 0.9907467048101866]
	TIME [epoch: 9.69 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7591965744014797		[learning rate: 0.00079317]
	Learning Rate: 0.000793174
	LOSS [training: 0.7591965744014797 | validation: 0.8988885824326265]
	TIME [epoch: 9.7 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6568409559312411		[learning rate: 0.00078934]
	Learning Rate: 0.000789338
	LOSS [training: 0.6568409559312411 | validation: 0.9312859813070656]
	TIME [epoch: 9.68 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7430978204837775		[learning rate: 0.00078552]
	Learning Rate: 0.000785521
	LOSS [training: 0.7430978204837775 | validation: 0.8788567074226308]
	TIME [epoch: 9.68 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6734438379935563		[learning rate: 0.00078172]
	Learning Rate: 0.000781723
	LOSS [training: 0.6734438379935563 | validation: 0.9185733716865414]
	TIME [epoch: 9.71 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6891584382984639		[learning rate: 0.00077794]
	Learning Rate: 0.000777942
	LOSS [training: 0.6891584382984639 | validation: 0.9140719515055027]
	TIME [epoch: 9.68 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6784760482719274		[learning rate: 0.00077418]
	Learning Rate: 0.00077418
	LOSS [training: 0.6784760482719274 | validation: 0.8821794458978048]
	TIME [epoch: 9.68 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7403312619272002		[learning rate: 0.00077044]
	Learning Rate: 0.000770436
	LOSS [training: 0.7403312619272002 | validation: 0.9151999703835202]
	TIME [epoch: 9.7 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7388200334775679		[learning rate: 0.00076671]
	Learning Rate: 0.000766711
	LOSS [training: 0.7388200334775679 | validation: 0.908112537767571]
	TIME [epoch: 9.69 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7215188946260085		[learning rate: 0.000763]
	Learning Rate: 0.000763003
	LOSS [training: 0.7215188946260085 | validation: 0.8661770679446467]
	TIME [epoch: 9.68 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6909018256817141		[learning rate: 0.00075931]
	Learning Rate: 0.000759313
	LOSS [training: 0.6909018256817141 | validation: 0.9490829568462427]
	TIME [epoch: 9.68 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8555528842056932		[learning rate: 0.00075564]
	Learning Rate: 0.000755641
	LOSS [training: 0.8555528842056932 | validation: 1.0155527907842994]
	TIME [epoch: 9.71 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7270340909430788		[learning rate: 0.00075199]
	Learning Rate: 0.000751987
	LOSS [training: 0.7270340909430788 | validation: 0.9938506647199415]
	TIME [epoch: 9.69 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6987427358528204		[learning rate: 0.00074835]
	Learning Rate: 0.000748351
	LOSS [training: 0.6987427358528204 | validation: 0.9634009992164646]
	TIME [epoch: 9.68 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7621270949082284		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.7621270949082284 | validation: 0.9489493354162835]
	TIME [epoch: 9.7 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7029113142162866		[learning rate: 0.00074113]
	Learning Rate: 0.000741131
	LOSS [training: 0.7029113142162866 | validation: 0.9165537772556205]
	TIME [epoch: 9.69 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6696091512065729		[learning rate: 0.00073755]
	Learning Rate: 0.000737547
	LOSS [training: 0.6696091512065729 | validation: 0.8806467959834794]
	TIME [epoch: 9.68 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.754743953844313		[learning rate: 0.00073398]
	Learning Rate: 0.00073398
	LOSS [training: 0.754743953844313 | validation: 0.9346073717050524]
	TIME [epoch: 9.68 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6909522971025316		[learning rate: 0.00073043]
	Learning Rate: 0.00073043
	LOSS [training: 0.6909522971025316 | validation: 0.9028187637970677]
	TIME [epoch: 9.71 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7126286200859498		[learning rate: 0.0007269]
	Learning Rate: 0.000726898
	LOSS [training: 0.7126286200859498 | validation: 0.9997748816638574]
	TIME [epoch: 9.68 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7975801072041515		[learning rate: 0.00072338]
	Learning Rate: 0.000723383
	LOSS [training: 0.7975801072041515 | validation: 0.8661904705652811]
	TIME [epoch: 9.68 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6933798592767557		[learning rate: 0.00071989]
	Learning Rate: 0.000719885
	LOSS [training: 0.6933798592767557 | validation: 0.9115175028945538]
	TIME [epoch: 9.71 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7399889155404222		[learning rate: 0.0007164]
	Learning Rate: 0.000716404
	LOSS [training: 0.7399889155404222 | validation: 0.8729288882792979]
	TIME [epoch: 9.69 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6853921789550742		[learning rate: 0.00071294]
	Learning Rate: 0.000712939
	LOSS [training: 0.6853921789550742 | validation: 0.8935155170749315]
	TIME [epoch: 9.68 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6651261326549112		[learning rate: 0.00070949]
	Learning Rate: 0.000709492
	LOSS [training: 0.6651261326549112 | validation: 0.9005845365583071]
	TIME [epoch: 9.69 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6778053296368517		[learning rate: 0.00070606]
	Learning Rate: 0.000706061
	LOSS [training: 0.6778053296368517 | validation: 1.0375856231482739]
	TIME [epoch: 9.7 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7265406636131515		[learning rate: 0.00070265]
	Learning Rate: 0.000702647
	LOSS [training: 0.7265406636131515 | validation: 0.9372095604986609]
	TIME [epoch: 9.68 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6747991753383487		[learning rate: 0.00069925]
	Learning Rate: 0.000699248
	LOSS [training: 0.6747991753383487 | validation: 0.9146279646502206]
	TIME [epoch: 9.68 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6841664106593605		[learning rate: 0.00069587]
	Learning Rate: 0.000695867
	LOSS [training: 0.6841664106593605 | validation: 0.9495074321034804]
	TIME [epoch: 9.71 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.722355162230967		[learning rate: 0.0006925]
	Learning Rate: 0.000692502
	LOSS [training: 0.722355162230967 | validation: 0.9247540957003034]
	TIME [epoch: 9.68 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6564082262616512		[learning rate: 0.00068915]
	Learning Rate: 0.000689153
	LOSS [training: 0.6564082262616512 | validation: 0.9603601661878999]
	TIME [epoch: 9.68 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7407217697792816		[learning rate: 0.00068582]
	Learning Rate: 0.000685821
	LOSS [training: 0.7407217697792816 | validation: 1.0583799421607665]
	TIME [epoch: 9.7 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.720562895328323		[learning rate: 0.0006825]
	Learning Rate: 0.000682504
	LOSS [training: 0.720562895328323 | validation: 0.9632077046032338]
	TIME [epoch: 9.68 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6918424278152399		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.6918424278152399 | validation: 0.9552296889735402]
	TIME [epoch: 9.68 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6987250985907363		[learning rate: 0.00067592]
	Learning Rate: 0.000675919
	LOSS [training: 0.6987250985907363 | validation: 0.9655348035952844]
	TIME [epoch: 9.68 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7181623900839256		[learning rate: 0.00067265]
	Learning Rate: 0.000672651
	LOSS [training: 0.7181623900839256 | validation: 1.0257049448749396]
	TIME [epoch: 9.7 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6972294167529761		[learning rate: 0.0006694]
	Learning Rate: 0.000669398
	LOSS [training: 0.6972294167529761 | validation: 0.9726674345647964]
	TIME [epoch: 9.68 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.695256850720799		[learning rate: 0.00066616]
	Learning Rate: 0.000666161
	LOSS [training: 0.695256850720799 | validation: 0.9767745086700618]
	TIME [epoch: 9.68 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7195306363988618		[learning rate: 0.00066294]
	Learning Rate: 0.000662939
	LOSS [training: 0.7195306363988618 | validation: 0.9572023043156613]
	TIME [epoch: 9.7 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7025879401173369		[learning rate: 0.00065973]
	Learning Rate: 0.000659733
	LOSS [training: 0.7025879401173369 | validation: 0.9692296966259635]
	TIME [epoch: 9.68 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7152314231354667		[learning rate: 0.00065654]
	Learning Rate: 0.000656543
	LOSS [training: 0.7152314231354667 | validation: 0.9773094134286128]
	TIME [epoch: 9.68 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6908909444504072		[learning rate: 0.00065337]
	Learning Rate: 0.000653368
	LOSS [training: 0.6908909444504072 | validation: 0.9180975708776171]
	TIME [epoch: 9.69 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7126899914776581		[learning rate: 0.00065021]
	Learning Rate: 0.000650209
	LOSS [training: 0.7126899914776581 | validation: 0.8953580381551832]
	TIME [epoch: 9.7 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6737319709448515		[learning rate: 0.00064706]
	Learning Rate: 0.000647064
	LOSS [training: 0.6737319709448515 | validation: 0.8808476036052744]
	TIME [epoch: 9.68 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6880373043101425		[learning rate: 0.00064394]
	Learning Rate: 0.000643935
	LOSS [training: 0.6880373043101425 | validation: 0.9648476913161198]
	TIME [epoch: 9.68 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7020844344183355		[learning rate: 0.00064082]
	Learning Rate: 0.000640821
	LOSS [training: 0.7020844344183355 | validation: 0.9519220499040912]
	TIME [epoch: 9.7 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6879935974745439		[learning rate: 0.00063772]
	Learning Rate: 0.000637722
	LOSS [training: 0.6879935974745439 | validation: 0.9409272595084031]
	TIME [epoch: 9.68 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6766501059415042		[learning rate: 0.00063464]
	Learning Rate: 0.000634638
	LOSS [training: 0.6766501059415042 | validation: 0.9527254897804192]
	TIME [epoch: 9.69 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7704012242898799		[learning rate: 0.00063157]
	Learning Rate: 0.000631569
	LOSS [training: 0.7704012242898799 | validation: 0.97304820099997]
	TIME [epoch: 9.71 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6952421185818516		[learning rate: 0.00062852]
	Learning Rate: 0.000628515
	LOSS [training: 0.6952421185818516 | validation: 0.9559103218806724]
	TIME [epoch: 9.7 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6872608866625358		[learning rate: 0.00062548]
	Learning Rate: 0.000625476
	LOSS [training: 0.6872608866625358 | validation: 0.9283609015333579]
	TIME [epoch: 9.69 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.678833548563047		[learning rate: 0.00062245]
	Learning Rate: 0.000622451
	LOSS [training: 0.678833548563047 | validation: 1.046687980942058]
	TIME [epoch: 9.68 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7472163070040428		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.7472163070040428 | validation: 0.9869979700813833]
	TIME [epoch: 9.71 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7054021299499598		[learning rate: 0.00061645]
	Learning Rate: 0.000616445
	LOSS [training: 0.7054021299499598 | validation: 0.9190386437109865]
	TIME [epoch: 9.69 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6640800093691387		[learning rate: 0.00061346]
	Learning Rate: 0.000613465
	LOSS [training: 0.6640800093691387 | validation: 0.8860551772338496]
	TIME [epoch: 9.68 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6566160441919433		[learning rate: 0.0006105]
	Learning Rate: 0.000610498
	LOSS [training: 0.6566160441919433 | validation: 0.8647597206210638]
	TIME [epoch: 9.7 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6706218052912519		[learning rate: 0.00060755]
	Learning Rate: 0.000607546
	LOSS [training: 0.6706218052912519 | validation: 0.8842990864488703]
	TIME [epoch: 9.69 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6628572117783055		[learning rate: 0.00060461]
	Learning Rate: 0.000604608
	LOSS [training: 0.6628572117783055 | validation: 0.9183498122482628]
	TIME [epoch: 9.68 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7045970410325116		[learning rate: 0.00060168]
	Learning Rate: 0.000601684
	LOSS [training: 0.7045970410325116 | validation: 0.9217421239199273]
	TIME [epoch: 9.69 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6736578522952664		[learning rate: 0.00059877]
	Learning Rate: 0.000598774
	LOSS [training: 0.6736578522952664 | validation: 0.8642317963215578]
	TIME [epoch: 9.7 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6697615202044183		[learning rate: 0.00059588]
	Learning Rate: 0.000595879
	LOSS [training: 0.6697615202044183 | validation: 0.8891124576989086]
	TIME [epoch: 9.69 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6623317529956867		[learning rate: 0.000593]
	Learning Rate: 0.000592997
	LOSS [training: 0.6623317529956867 | validation: 0.9830078145587889]
	TIME [epoch: 9.68 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7121326099600374		[learning rate: 0.00059013]
	Learning Rate: 0.000590129
	LOSS [training: 0.7121326099600374 | validation: 0.8828712710259647]
	TIME [epoch: 9.7 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.652129962119884		[learning rate: 0.00058728]
	Learning Rate: 0.000587276
	LOSS [training: 0.652129962119884 | validation: 0.9081633574850564]
	TIME [epoch: 9.68 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6561935004723395		[learning rate: 0.00058444]
	Learning Rate: 0.000584436
	LOSS [training: 0.6561935004723395 | validation: 0.8407020981460542]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_636.pth
	Model improved!!!
EPOCH 637/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6498145654211888		[learning rate: 0.00058161]
	Learning Rate: 0.00058161
	LOSS [training: 0.6498145654211888 | validation: 0.8458033605227715]
	TIME [epoch: 9.69 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.666504513855344		[learning rate: 0.0005788]
	Learning Rate: 0.000578797
	LOSS [training: 0.666504513855344 | validation: 0.9443661176452193]
	TIME [epoch: 9.69 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6777557593373444		[learning rate: 0.000576]
	Learning Rate: 0.000575998
	LOSS [training: 0.6777557593373444 | validation: 0.8728794075853398]
	TIME [epoch: 9.68 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6551037275255959		[learning rate: 0.00057321]
	Learning Rate: 0.000573213
	LOSS [training: 0.6551037275255959 | validation: 0.8790440901942274]
	TIME [epoch: 9.68 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6622400687602137		[learning rate: 0.00057044]
	Learning Rate: 0.000570441
	LOSS [training: 0.6622400687602137 | validation: 0.9037096436864331]
	TIME [epoch: 9.7 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6433743959628425		[learning rate: 0.00056768]
	Learning Rate: 0.000567682
	LOSS [training: 0.6433743959628425 | validation: 0.8700920869695321]
	TIME [epoch: 9.68 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7330572916010154		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.7330572916010154 | validation: 0.9288449468197035]
	TIME [epoch: 9.68 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.727364447977703		[learning rate: 0.0005622]
	Learning Rate: 0.000562205
	LOSS [training: 0.727364447977703 | validation: 0.8889215003904221]
	TIME [epoch: 9.67 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6531720400656231		[learning rate: 0.00055949]
	Learning Rate: 0.000559486
	LOSS [training: 0.6531720400656231 | validation: 0.8667624235440802]
	TIME [epoch: 9.7 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6602547285106597		[learning rate: 0.00055678]
	Learning Rate: 0.000556781
	LOSS [training: 0.6602547285106597 | validation: 0.9467191339621281]
	TIME [epoch: 9.67 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6896787855406773		[learning rate: 0.00055409]
	Learning Rate: 0.000554088
	LOSS [training: 0.6896787855406773 | validation: 0.9553676983887173]
	TIME [epoch: 9.68 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6804755049897043		[learning rate: 0.00055141]
	Learning Rate: 0.000551409
	LOSS [training: 0.6804755049897043 | validation: 0.9220873281732835]
	TIME [epoch: 9.69 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6860506866728112		[learning rate: 0.00054874]
	Learning Rate: 0.000548742
	LOSS [training: 0.6860506866728112 | validation: 0.9231935406818363]
	TIME [epoch: 9.68 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6691545035094963		[learning rate: 0.00054609]
	Learning Rate: 0.000546089
	LOSS [training: 0.6691545035094963 | validation: 0.9454463579261253]
	TIME [epoch: 9.67 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6716506117165869		[learning rate: 0.00054345]
	Learning Rate: 0.000543448
	LOSS [training: 0.6716506117165869 | validation: 0.92907271350631]
	TIME [epoch: 9.69 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6551098937184519		[learning rate: 0.00054082]
	Learning Rate: 0.00054082
	LOSS [training: 0.6551098937184519 | validation: 0.9224964594900162]
	TIME [epoch: 9.69 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6544442825065485		[learning rate: 0.0005382]
	Learning Rate: 0.000538205
	LOSS [training: 0.6544442825065485 | validation: 0.9027253344986553]
	TIME [epoch: 9.68 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6454043833121632		[learning rate: 0.0005356]
	Learning Rate: 0.000535602
	LOSS [training: 0.6454043833121632 | validation: 0.9255075350312834]
	TIME [epoch: 9.68 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7090062574583105		[learning rate: 0.00053301]
	Learning Rate: 0.000533012
	LOSS [training: 0.7090062574583105 | validation: 0.942230728073543]
	TIME [epoch: 9.7 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6979705703494794		[learning rate: 0.00053043]
	Learning Rate: 0.000530434
	LOSS [training: 0.6979705703494794 | validation: 0.9029537218999073]
	TIME [epoch: 9.68 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6427118287551102		[learning rate: 0.00052787]
	Learning Rate: 0.000527869
	LOSS [training: 0.6427118287551102 | validation: 0.9147549258412011]
	TIME [epoch: 9.67 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6329167787675968		[learning rate: 0.00052532]
	Learning Rate: 0.000525317
	LOSS [training: 0.6329167787675968 | validation: 0.8902359705279562]
	TIME [epoch: 9.68 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6391720608038265		[learning rate: 0.00052278]
	Learning Rate: 0.000522776
	LOSS [training: 0.6391720608038265 | validation: 0.8705031571041957]
	TIME [epoch: 9.69 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6505060426243684		[learning rate: 0.00052025]
	Learning Rate: 0.000520248
	LOSS [training: 0.6505060426243684 | validation: 0.894717867273165]
	TIME [epoch: 9.68 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6704794820664826		[learning rate: 0.00051773]
	Learning Rate: 0.000517732
	LOSS [training: 0.6704794820664826 | validation: 0.9120728239633745]
	TIME [epoch: 9.68 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6910003739000969		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.6910003739000969 | validation: 0.9617597848093314]
	TIME [epoch: 9.7 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6742934242824348		[learning rate: 0.00051274]
	Learning Rate: 0.000512737
	LOSS [training: 0.6742934242824348 | validation: 0.8999161827853626]
	TIME [epoch: 9.68 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6755199627471032		[learning rate: 0.00051026]
	Learning Rate: 0.000510258
	LOSS [training: 0.6755199627471032 | validation: 0.8900173348775074]
	TIME [epoch: 9.67 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.687531982090434		[learning rate: 0.00050779]
	Learning Rate: 0.00050779
	LOSS [training: 0.687531982090434 | validation: 0.8798673104908642]
	TIME [epoch: 9.69 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6822125919618334		[learning rate: 0.00050533]
	Learning Rate: 0.000505334
	LOSS [training: 0.6822125919618334 | validation: 0.8589162558098682]
	TIME [epoch: 9.68 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6415173017502879		[learning rate: 0.00050289]
	Learning Rate: 0.000502891
	LOSS [training: 0.6415173017502879 | validation: 0.8855724713494426]
	TIME [epoch: 9.68 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6545913695012051		[learning rate: 0.00050046]
	Learning Rate: 0.000500459
	LOSS [training: 0.6545913695012051 | validation: 0.8404608913768342]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_668.pth
	Model improved!!!
EPOCH 669/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6366119962162893		[learning rate: 0.00049804]
	Learning Rate: 0.000498039
	LOSS [training: 0.6366119962162893 | validation: 0.8587014966914134]
	TIME [epoch: 9.7 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6427232459314985		[learning rate: 0.00049563]
	Learning Rate: 0.00049563
	LOSS [training: 0.6427232459314985 | validation: 0.8906919378428153]
	TIME [epoch: 9.68 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6716641679611988		[learning rate: 0.00049323]
	Learning Rate: 0.000493234
	LOSS [training: 0.6716641679611988 | validation: 0.9308714001165709]
	TIME [epoch: 9.68 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6590332128303447		[learning rate: 0.00049085]
	Learning Rate: 0.000490848
	LOSS [training: 0.6590332128303447 | validation: 0.8702590893952359]
	TIME [epoch: 9.69 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.624528581320307		[learning rate: 0.00048847]
	Learning Rate: 0.000488475
	LOSS [training: 0.624528581320307 | validation: 0.8596659598178938]
	TIME [epoch: 9.69 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6807209553886441		[learning rate: 0.00048611]
	Learning Rate: 0.000486113
	LOSS [training: 0.6807209553886441 | validation: 0.8699481972518859]
	TIME [epoch: 9.68 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6467679086711361		[learning rate: 0.00048376]
	Learning Rate: 0.000483762
	LOSS [training: 0.6467679086711361 | validation: 0.8824038643844245]
	TIME [epoch: 9.68 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7027459676040583		[learning rate: 0.00048142]
	Learning Rate: 0.000481422
	LOSS [training: 0.7027459676040583 | validation: 0.8492969528133475]
	TIME [epoch: 9.7 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6899186113731018		[learning rate: 0.00047909]
	Learning Rate: 0.000479094
	LOSS [training: 0.6899186113731018 | validation: 0.8923368536651367]
	TIME [epoch: 9.68 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6673925040497735		[learning rate: 0.00047678]
	Learning Rate: 0.000476777
	LOSS [training: 0.6673925040497735 | validation: 0.8477011580190645]
	TIME [epoch: 9.68 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6447269799311652		[learning rate: 0.00047447]
	Learning Rate: 0.000474472
	LOSS [training: 0.6447269799311652 | validation: 0.885093283671645]
	TIME [epoch: 9.7 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6556268467094453		[learning rate: 0.00047218]
	Learning Rate: 0.000472177
	LOSS [training: 0.6556268467094453 | validation: 0.8515308901042093]
	TIME [epoch: 9.68 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6621785863447304		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.6621785863447304 | validation: 0.9627621519851844]
	TIME [epoch: 9.67 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7429351094427814		[learning rate: 0.00046762]
	Learning Rate: 0.000467622
	LOSS [training: 0.7429351094427814 | validation: 0.8737033319172309]
	TIME [epoch: 9.68 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6254064346427957		[learning rate: 0.00046536]
	Learning Rate: 0.00046536
	LOSS [training: 0.6254064346427957 | validation: 0.850809602902957]
	TIME [epoch: 9.69 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6873239097493687		[learning rate: 0.00046311]
	Learning Rate: 0.00046311
	LOSS [training: 0.6873239097493687 | validation: 0.8642514890585858]
	TIME [epoch: 9.67 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6464174224845479		[learning rate: 0.00046087]
	Learning Rate: 0.000460871
	LOSS [training: 0.6464174224845479 | validation: 0.8841945409033583]
	TIME [epoch: 9.68 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6231741766290448		[learning rate: 0.00045864]
	Learning Rate: 0.000458642
	LOSS [training: 0.6231741766290448 | validation: 0.8507470045172614]
	TIME [epoch: 9.7 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.631586486778261		[learning rate: 0.00045642]
	Learning Rate: 0.000456424
	LOSS [training: 0.631586486778261 | validation: 0.8999987912445788]
	TIME [epoch: 9.68 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6651231897891594		[learning rate: 0.00045422]
	Learning Rate: 0.000454217
	LOSS [training: 0.6651231897891594 | validation: 0.871568549989388]
	TIME [epoch: 9.68 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6443736956860974		[learning rate: 0.00045202]
	Learning Rate: 0.00045202
	LOSS [training: 0.6443736956860974 | validation: 0.9409070214196309]
	TIME [epoch: 9.69 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6631464653114323		[learning rate: 0.00044983]
	Learning Rate: 0.000449834
	LOSS [training: 0.6631464653114323 | validation: 0.8470431386780375]
	TIME [epoch: 9.69 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6250113977261459		[learning rate: 0.00044766]
	Learning Rate: 0.000447659
	LOSS [training: 0.6250113977261459 | validation: 0.8669193015852724]
	TIME [epoch: 9.68 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.659500102303447		[learning rate: 0.00044549]
	Learning Rate: 0.000445494
	LOSS [training: 0.659500102303447 | validation: 0.878680412166346]
	TIME [epoch: 9.68 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6123305261673881		[learning rate: 0.00044334]
	Learning Rate: 0.00044334
	LOSS [training: 0.6123305261673881 | validation: 0.8474869468223338]
	TIME [epoch: 9.71 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6476347686478918		[learning rate: 0.0004412]
	Learning Rate: 0.000441196
	LOSS [training: 0.6476347686478918 | validation: 0.8545458223405337]
	TIME [epoch: 9.68 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6278680674073761		[learning rate: 0.00043906]
	Learning Rate: 0.000439063
	LOSS [training: 0.6278680674073761 | validation: 0.8614901400587721]
	TIME [epoch: 9.68 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6211684982736012		[learning rate: 0.00043694]
	Learning Rate: 0.000436939
	LOSS [training: 0.6211684982736012 | validation: 0.8721967609266479]
	TIME [epoch: 9.7 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6306275570529347		[learning rate: 0.00043483]
	Learning Rate: 0.000434826
	LOSS [training: 0.6306275570529347 | validation: 0.8901969289560352]
	TIME [epoch: 9.68 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6999217279383566		[learning rate: 0.00043272]
	Learning Rate: 0.000432724
	LOSS [training: 0.6999217279383566 | validation: 0.8946986692831658]
	TIME [epoch: 9.69 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6586073717124693		[learning rate: 0.00043063]
	Learning Rate: 0.000430631
	LOSS [training: 0.6586073717124693 | validation: 0.8485506184281922]
	TIME [epoch: 9.67 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6355844558604768		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.6355844558604768 | validation: 0.8731184515751682]
	TIME [epoch: 9.7 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6442347731315964		[learning rate: 0.00042648]
	Learning Rate: 0.000426476
	LOSS [training: 0.6442347731315964 | validation: 0.8947942551509748]
	TIME [epoch: 9.68 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6255917459375555		[learning rate: 0.00042441]
	Learning Rate: 0.000424414
	LOSS [training: 0.6255917459375555 | validation: 0.8668135236242617]
	TIME [epoch: 9.68 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6395203105055499		[learning rate: 0.00042236]
	Learning Rate: 0.000422361
	LOSS [training: 0.6395203105055499 | validation: 0.8336199049461448]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_703.pth
	Model improved!!!
EPOCH 704/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6439499174204879		[learning rate: 0.00042032]
	Learning Rate: 0.000420319
	LOSS [training: 0.6439499174204879 | validation: 0.8299086470303455]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_704.pth
	Model improved!!!
EPOCH 705/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6232498631679319		[learning rate: 0.00041829]
	Learning Rate: 0.000418286
	LOSS [training: 0.6232498631679319 | validation: 0.8836670682774395]
	TIME [epoch: 9.69 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6635959303332102		[learning rate: 0.00041626]
	Learning Rate: 0.000416264
	LOSS [training: 0.6635959303332102 | validation: 0.8817265358422425]
	TIME [epoch: 9.7 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6223379172768674		[learning rate: 0.00041425]
	Learning Rate: 0.000414251
	LOSS [training: 0.6223379172768674 | validation: 0.8708190301356754]
	TIME [epoch: 9.68 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6362730295948396		[learning rate: 0.00041225]
	Learning Rate: 0.000412247
	LOSS [training: 0.6362730295948396 | validation: 0.8857432607571315]
	TIME [epoch: 9.68 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6517731271826694		[learning rate: 0.00041025]
	Learning Rate: 0.000410254
	LOSS [training: 0.6517731271826694 | validation: 0.8476285997632842]
	TIME [epoch: 9.68 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6089983113037759		[learning rate: 0.00040827]
	Learning Rate: 0.00040827
	LOSS [training: 0.6089983113037759 | validation: 0.8562634740133811]
	TIME [epoch: 9.69 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6600164579054093		[learning rate: 0.0004063]
	Learning Rate: 0.000406296
	LOSS [training: 0.6600164579054093 | validation: 0.9583239409848323]
	TIME [epoch: 9.69 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6850966118461042		[learning rate: 0.00040433]
	Learning Rate: 0.000404331
	LOSS [training: 0.6850966118461042 | validation: 0.8953043915642073]
	TIME [epoch: 9.68 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6462505622672557		[learning rate: 0.00040238]
	Learning Rate: 0.000402376
	LOSS [training: 0.6462505622672557 | validation: 0.9524890212897849]
	TIME [epoch: 9.69 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6505688039708286		[learning rate: 0.00040043]
	Learning Rate: 0.00040043
	LOSS [training: 0.6505688039708286 | validation: 0.8576536075697316]
	TIME [epoch: 9.69 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6093940514826314		[learning rate: 0.00039849]
	Learning Rate: 0.000398493
	LOSS [training: 0.6093940514826314 | validation: 0.8545711342007318]
	TIME [epoch: 9.68 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6310919059628016		[learning rate: 0.00039657]
	Learning Rate: 0.000396566
	LOSS [training: 0.6310919059628016 | validation: 0.8663203097975929]
	TIME [epoch: 9.68 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6149801730091529		[learning rate: 0.00039465]
	Learning Rate: 0.000394649
	LOSS [training: 0.6149801730091529 | validation: 0.8687773965959892]
	TIME [epoch: 9.7 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6360637766759644		[learning rate: 0.00039274]
	Learning Rate: 0.00039274
	LOSS [training: 0.6360637766759644 | validation: 0.853399123087456]
	TIME [epoch: 9.68 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6119397365796165		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.6119397365796165 | validation: 0.8419569359584236]
	TIME [epoch: 9.68 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6209594249272918		[learning rate: 0.00038895]
	Learning Rate: 0.000388951
	LOSS [training: 0.6209594249272918 | validation: 0.881604803122263]
	TIME [epoch: 9.69 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6919492243395903		[learning rate: 0.00038707]
	Learning Rate: 0.00038707
	LOSS [training: 0.6919492243395903 | validation: 0.8822958651249418]
	TIME [epoch: 9.69 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6415340988138895		[learning rate: 0.0003852]
	Learning Rate: 0.000385198
	LOSS [training: 0.6415340988138895 | validation: 0.9170878846439361]
	TIME [epoch: 9.68 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.671556473571616		[learning rate: 0.00038334]
	Learning Rate: 0.000383335
	LOSS [training: 0.671556473571616 | validation: 0.8823799288975989]
	TIME [epoch: 9.69 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6277453932767169		[learning rate: 0.00038148]
	Learning Rate: 0.000381482
	LOSS [training: 0.6277453932767169 | validation: 0.9000061186637187]
	TIME [epoch: 9.7 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6382964857010868		[learning rate: 0.00037964]
	Learning Rate: 0.000379637
	LOSS [training: 0.6382964857010868 | validation: 0.8636512357004896]
	TIME [epoch: 9.69 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6365925333336877		[learning rate: 0.0003778]
	Learning Rate: 0.000377801
	LOSS [training: 0.6365925333336877 | validation: 0.8963384830777225]
	TIME [epoch: 9.68 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6174973960555896		[learning rate: 0.00037597]
	Learning Rate: 0.000375974
	LOSS [training: 0.6174973960555896 | validation: 0.8604964525569412]
	TIME [epoch: 9.7 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.628870592530614		[learning rate: 0.00037416]
	Learning Rate: 0.000374156
	LOSS [training: 0.628870592530614 | validation: 0.8442439844381053]
	TIME [epoch: 9.69 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6355271274047267		[learning rate: 0.00037235]
	Learning Rate: 0.000372347
	LOSS [training: 0.6355271274047267 | validation: 0.8989941735952328]
	TIME [epoch: 9.68 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6433613444309213		[learning rate: 0.00037055]
	Learning Rate: 0.000370546
	LOSS [training: 0.6433613444309213 | validation: 0.9549493737104304]
	TIME [epoch: 9.67 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6519157794516357		[learning rate: 0.00036875]
	Learning Rate: 0.000368754
	LOSS [training: 0.6519157794516357 | validation: 0.8163109400065056]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_731.pth
	Model improved!!!
EPOCH 732/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6328368182100907		[learning rate: 0.00036697]
	Learning Rate: 0.000366971
	LOSS [training: 0.6328368182100907 | validation: 0.8508930809428157]
	TIME [epoch: 9.68 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6305585591688796		[learning rate: 0.0003652]
	Learning Rate: 0.000365196
	LOSS [training: 0.6305585591688796 | validation: 0.8140250370899631]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_733.pth
	Model improved!!!
EPOCH 734/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.619308713518055		[learning rate: 0.00036343]
	Learning Rate: 0.00036343
	LOSS [training: 0.619308713518055 | validation: 0.8346381021631996]
	TIME [epoch: 9.71 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6132241436389154		[learning rate: 0.00036167]
	Learning Rate: 0.000361673
	LOSS [training: 0.6132241436389154 | validation: 0.832180715335306]
	TIME [epoch: 9.68 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6278029096940532		[learning rate: 0.00035992]
	Learning Rate: 0.000359924
	LOSS [training: 0.6278029096940532 | validation: 0.8355212080462657]
	TIME [epoch: 9.68 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6506716541820918		[learning rate: 0.00035818]
	Learning Rate: 0.000358183
	LOSS [training: 0.6506716541820918 | validation: 0.8568254396797506]
	TIME [epoch: 9.68 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6414576109945797		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.6414576109945797 | validation: 0.8793163004931066]
	TIME [epoch: 9.7 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6486182861380636		[learning rate: 0.00035473]
	Learning Rate: 0.000354727
	LOSS [training: 0.6486182861380636 | validation: 0.8399795833433311]
	TIME [epoch: 9.68 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.624463073852825		[learning rate: 0.00035301]
	Learning Rate: 0.000353012
	LOSS [training: 0.624463073852825 | validation: 0.8507613866840701]
	TIME [epoch: 9.68 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.611804269262698		[learning rate: 0.0003513]
	Learning Rate: 0.000351305
	LOSS [training: 0.611804269262698 | validation: 0.8705630305056867]
	TIME [epoch: 9.69 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6253948934225785		[learning rate: 0.00034961]
	Learning Rate: 0.000349606
	LOSS [training: 0.6253948934225785 | validation: 0.923375093550454]
	TIME [epoch: 9.69 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7467887586725445		[learning rate: 0.00034792]
	Learning Rate: 0.000347915
	LOSS [training: 0.7467887586725445 | validation: 1.0173962855992986]
	TIME [epoch: 9.67 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7713216346038883		[learning rate: 0.00034623]
	Learning Rate: 0.000346233
	LOSS [training: 0.7713216346038883 | validation: 1.0062082584186771]
	TIME [epoch: 9.68 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.73167724435311		[learning rate: 0.00034456]
	Learning Rate: 0.000344559
	LOSS [training: 0.73167724435311 | validation: 0.985817034753521]
	TIME [epoch: 9.69 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6817084072805203		[learning rate: 0.00034289]
	Learning Rate: 0.000342892
	LOSS [training: 0.6817084072805203 | validation: 0.8893066652029558]
	TIME [epoch: 9.68 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.646564242734542		[learning rate: 0.00034123]
	Learning Rate: 0.000341234
	LOSS [training: 0.646564242734542 | validation: 0.8596886300030757]
	TIME [epoch: 9.68 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6253119786631623		[learning rate: 0.00033958]
	Learning Rate: 0.000339584
	LOSS [training: 0.6253119786631623 | validation: 0.8588327096058379]
	TIME [epoch: 9.71 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6259026694272111		[learning rate: 0.00033794]
	Learning Rate: 0.000337942
	LOSS [training: 0.6259026694272111 | validation: 0.9085996682181693]
	TIME [epoch: 9.68 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6230975309668111		[learning rate: 0.00033631]
	Learning Rate: 0.000336308
	LOSS [training: 0.6230975309668111 | validation: 0.8672295651479098]
	TIME [epoch: 9.68 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6239532874959666		[learning rate: 0.00033468]
	Learning Rate: 0.000334681
	LOSS [training: 0.6239532874959666 | validation: 0.8713735236882744]
	TIME [epoch: 9.7 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6097923392006824		[learning rate: 0.00033306]
	Learning Rate: 0.000333063
	LOSS [training: 0.6097923392006824 | validation: 0.9016124763116707]
	TIME [epoch: 9.69 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6572571143271364		[learning rate: 0.00033145]
	Learning Rate: 0.000331452
	LOSS [training: 0.6572571143271364 | validation: 0.8933274376875247]
	TIME [epoch: 9.67 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6530196703198307		[learning rate: 0.00032985]
	Learning Rate: 0.000329849
	LOSS [training: 0.6530196703198307 | validation: 0.8501121170818822]
	TIME [epoch: 9.68 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6260227095756725		[learning rate: 0.00032825]
	Learning Rate: 0.000328254
	LOSS [training: 0.6260227095756725 | validation: 0.8667580755220974]
	TIME [epoch: 9.7 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.613578433111392		[learning rate: 0.00032667]
	Learning Rate: 0.000326667
	LOSS [training: 0.613578433111392 | validation: 0.8788029531792494]
	TIME [epoch: 9.68 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6333037972728317		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.6333037972728317 | validation: 0.8693901035677376]
	TIME [epoch: 9.68 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6109212505722217		[learning rate: 0.00032352]
	Learning Rate: 0.000323515
	LOSS [training: 0.6109212505722217 | validation: 0.8581939971041991]
	TIME [epoch: 9.7 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6217470222559026		[learning rate: 0.00032195]
	Learning Rate: 0.000321951
	LOSS [training: 0.6217470222559026 | validation: 0.8302010944648683]
	TIME [epoch: 9.68 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6176947788155134		[learning rate: 0.00032039]
	Learning Rate: 0.000320394
	LOSS [training: 0.6176947788155134 | validation: 0.8746558664124712]
	TIME [epoch: 9.68 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6105974732837357		[learning rate: 0.00031884]
	Learning Rate: 0.000318845
	LOSS [training: 0.6105974732837357 | validation: 0.8488407093021348]
	TIME [epoch: 9.68 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6320580437590932		[learning rate: 0.0003173]
	Learning Rate: 0.000317303
	LOSS [training: 0.6320580437590932 | validation: 0.8607422088300877]
	TIME [epoch: 9.7 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6191506625984684		[learning rate: 0.00031577]
	Learning Rate: 0.000315768
	LOSS [training: 0.6191506625984684 | validation: 0.8490369148518684]
	TIME [epoch: 9.68 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6174266446505966		[learning rate: 0.00031424]
	Learning Rate: 0.000314241
	LOSS [training: 0.6174266446505966 | validation: 0.878775452573289]
	TIME [epoch: 9.68 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6254108844196227		[learning rate: 0.00031272]
	Learning Rate: 0.000312722
	LOSS [training: 0.6254108844196227 | validation: 0.856592540611814]
	TIME [epoch: 9.69 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6053978830464944		[learning rate: 0.00031121]
	Learning Rate: 0.000311209
	LOSS [training: 0.6053978830464944 | validation: 0.834596748550492]
	TIME [epoch: 9.69 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6142839444891222		[learning rate: 0.0003097]
	Learning Rate: 0.000309704
	LOSS [training: 0.6142839444891222 | validation: 0.8365583204711414]
	TIME [epoch: 9.68 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6040832330284613		[learning rate: 0.00030821]
	Learning Rate: 0.000308207
	LOSS [training: 0.6040832330284613 | validation: 0.8433397469572793]
	TIME [epoch: 9.69 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6124481725824624		[learning rate: 0.00030672]
	Learning Rate: 0.000306716
	LOSS [training: 0.6124481725824624 | validation: 0.8451900802446097]
	TIME [epoch: 9.69 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.611899119544502		[learning rate: 0.00030523]
	Learning Rate: 0.000305233
	LOSS [training: 0.611899119544502 | validation: 0.8638082587271442]
	TIME [epoch: 9.69 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6021331001981297		[learning rate: 0.00030376]
	Learning Rate: 0.000303757
	LOSS [training: 0.6021331001981297 | validation: 0.8599759355609738]
	TIME [epoch: 9.68 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6315397320646368		[learning rate: 0.00030229]
	Learning Rate: 0.000302288
	LOSS [training: 0.6315397320646368 | validation: 0.8413892721118071]
	TIME [epoch: 9.7 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6317237761743881		[learning rate: 0.00030083]
	Learning Rate: 0.000300826
	LOSS [training: 0.6317237761743881 | validation: 0.869078050860727]
	TIME [epoch: 9.68 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6130102173739644		[learning rate: 0.00029937]
	Learning Rate: 0.000299372
	LOSS [training: 0.6130102173739644 | validation: 0.8670454685894825]
	TIME [epoch: 9.68 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.621162057843828		[learning rate: 0.00029792]
	Learning Rate: 0.000297924
	LOSS [training: 0.621162057843828 | validation: 0.8975782860519875]
	TIME [epoch: 9.7 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6627886370198087		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.6627886370198087 | validation: 0.9535218425342885]
	TIME [epoch: 9.69 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.739259224903632		[learning rate: 0.00029505]
	Learning Rate: 0.000295049
	LOSS [training: 0.739259224903632 | validation: 0.9272488047162283]
	TIME [epoch: 9.68 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6578770806148901		[learning rate: 0.00029362]
	Learning Rate: 0.000293623
	LOSS [training: 0.6578770806148901 | validation: 0.8423305599718556]
	TIME [epoch: 9.68 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6250542838158715		[learning rate: 0.0002922]
	Learning Rate: 0.000292203
	LOSS [training: 0.6250542838158715 | validation: 0.839176997860879]
	TIME [epoch: 9.7 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.615371434333629		[learning rate: 0.00029079]
	Learning Rate: 0.00029079
	LOSS [training: 0.615371434333629 | validation: 0.8362461269496606]
	TIME [epoch: 9.68 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6214379333281924		[learning rate: 0.00028938]
	Learning Rate: 0.000289383
	LOSS [training: 0.6214379333281924 | validation: 0.8632457190324453]
	TIME [epoch: 9.68 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6336457928823144		[learning rate: 0.00028798]
	Learning Rate: 0.000287984
	LOSS [training: 0.6336457928823144 | validation: 0.936849906520967]
	TIME [epoch: 9.7 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6608750179675943		[learning rate: 0.00028659]
	Learning Rate: 0.000286591
	LOSS [training: 0.6608750179675943 | validation: 0.8849686832061773]
	TIME [epoch: 9.68 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6139565318782877		[learning rate: 0.00028521]
	Learning Rate: 0.000285205
	LOSS [training: 0.6139565318782877 | validation: 0.8382860477873194]
	TIME [epoch: 9.67 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6094111606646532		[learning rate: 0.00028383]
	Learning Rate: 0.000283826
	LOSS [training: 0.6094111606646532 | validation: 0.8452509761142076]
	TIME [epoch: 9.68 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6282644367890723		[learning rate: 0.00028245]
	Learning Rate: 0.000282454
	LOSS [training: 0.6282644367890723 | validation: 0.8454335861803548]
	TIME [epoch: 9.69 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5996212131071454		[learning rate: 0.00028109]
	Learning Rate: 0.000281088
	LOSS [training: 0.5996212131071454 | validation: 0.8365026579284764]
	TIME [epoch: 9.68 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6091585122522767		[learning rate: 0.00027973]
	Learning Rate: 0.000279729
	LOSS [training: 0.6091585122522767 | validation: 0.8756835553390101]
	TIME [epoch: 9.67 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6017869930886021		[learning rate: 0.00027838]
	Learning Rate: 0.000278376
	LOSS [training: 0.6017869930886021 | validation: 0.8789744129358628]
	TIME [epoch: 9.7 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6395651346240907		[learning rate: 0.00027703]
	Learning Rate: 0.00027703
	LOSS [training: 0.6395651346240907 | validation: 0.8819767574834464]
	TIME [epoch: 9.68 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6209252566164805		[learning rate: 0.00027569]
	Learning Rate: 0.00027569
	LOSS [training: 0.6209252566164805 | validation: 0.8559022376994684]
	TIME [epoch: 9.68 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.662643060522038		[learning rate: 0.00027436]
	Learning Rate: 0.000274357
	LOSS [training: 0.662643060522038 | validation: 0.9365718840125682]
	TIME [epoch: 9.69 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6914975088086954		[learning rate: 0.00027303]
	Learning Rate: 0.00027303
	LOSS [training: 0.6914975088086954 | validation: 0.8652497161083065]
	TIME [epoch: 9.69 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6384780800278782		[learning rate: 0.00027171]
	Learning Rate: 0.00027171
	LOSS [training: 0.6384780800278782 | validation: 0.8549166147173597]
	TIME [epoch: 9.68 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6329746324486345		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.6329746324486345 | validation: 0.8613179262819826]
	TIME [epoch: 9.68 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6516599294859542		[learning rate: 0.00026909]
	Learning Rate: 0.000269088
	LOSS [training: 0.6516599294859542 | validation: 0.8682613833594176]
	TIME [epoch: 9.7 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6522479850452408		[learning rate: 0.00026779]
	Learning Rate: 0.000267787
	LOSS [training: 0.6522479850452408 | validation: 0.8930083802986424]
	TIME [epoch: 9.68 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.703035785184961		[learning rate: 0.00026649]
	Learning Rate: 0.000266492
	LOSS [training: 0.703035785184961 | validation: 0.8736233852411955]
	TIME [epoch: 9.68 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6427577668293857		[learning rate: 0.0002652]
	Learning Rate: 0.000265203
	LOSS [training: 0.6427577668293857 | validation: 0.8250514450001234]
	TIME [epoch: 9.7 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6301554111032643		[learning rate: 0.00026392]
	Learning Rate: 0.000263921
	LOSS [training: 0.6301554111032643 | validation: 0.8522821133525648]
	TIME [epoch: 9.69 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.623801864062517		[learning rate: 0.00026264]
	Learning Rate: 0.000262645
	LOSS [training: 0.623801864062517 | validation: 0.8458014514065463]
	TIME [epoch: 9.69 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6139200555991347		[learning rate: 0.00026137]
	Learning Rate: 0.000261374
	LOSS [training: 0.6139200555991347 | validation: 0.8337263659856089]
	TIME [epoch: 9.68 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6094062923709443		[learning rate: 0.00026011]
	Learning Rate: 0.00026011
	LOSS [training: 0.6094062923709443 | validation: 0.8374252359949091]
	TIME [epoch: 9.71 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6312638909352627		[learning rate: 0.00025885]
	Learning Rate: 0.000258853
	LOSS [training: 0.6312638909352627 | validation: 0.8559691723892506]
	TIME [epoch: 9.68 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6277888860357567		[learning rate: 0.0002576]
	Learning Rate: 0.000257601
	LOSS [training: 0.6277888860357567 | validation: 0.8545221889462207]
	TIME [epoch: 9.68 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6574831845682585		[learning rate: 0.00025636]
	Learning Rate: 0.000256355
	LOSS [training: 0.6574831845682585 | validation: 0.8980642470880577]
	TIME [epoch: 9.71 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6859831595466526		[learning rate: 0.00025512]
	Learning Rate: 0.000255115
	LOSS [training: 0.6859831595466526 | validation: 0.8248328022743526]
	TIME [epoch: 9.69 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6316931630991428		[learning rate: 0.00025388]
	Learning Rate: 0.000253882
	LOSS [training: 0.6316931630991428 | validation: 0.8536496458734578]
	TIME [epoch: 9.69 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6372030263377922		[learning rate: 0.00025265]
	Learning Rate: 0.000252654
	LOSS [training: 0.6372030263377922 | validation: 0.8300448204479963]
	TIME [epoch: 9.69 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6324531699655849		[learning rate: 0.00025143]
	Learning Rate: 0.000251432
	LOSS [training: 0.6324531699655849 | validation: 0.8303961974248173]
	TIME [epoch: 9.69 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6061541279934739		[learning rate: 0.00025022]
	Learning Rate: 0.000250216
	LOSS [training: 0.6061541279934739 | validation: 0.849502778170785]
	TIME [epoch: 9.68 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6577048939904399		[learning rate: 0.00024901]
	Learning Rate: 0.000249006
	LOSS [training: 0.6577048939904399 | validation: 0.9147907715829091]
	TIME [epoch: 9.68 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6783150124682091		[learning rate: 0.0002478]
	Learning Rate: 0.000247802
	LOSS [training: 0.6783150124682091 | validation: 0.8514646328583634]
	TIME [epoch: 9.71 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6247616292315977		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.6247616292315977 | validation: 0.8363174952424658]
	TIME [epoch: 9.68 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6250029356340204		[learning rate: 0.00024541]
	Learning Rate: 0.000245411
	LOSS [training: 0.6250029356340204 | validation: 0.863734974206295]
	TIME [epoch: 9.68 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6129906963077832		[learning rate: 0.00024422]
	Learning Rate: 0.000244225
	LOSS [training: 0.6129906963077832 | validation: 0.8205085324534895]
	TIME [epoch: 9.71 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6303895732228926		[learning rate: 0.00024304]
	Learning Rate: 0.000243044
	LOSS [training: 0.6303895732228926 | validation: 0.8457352614145569]
	TIME [epoch: 9.69 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6366843393593642		[learning rate: 0.00024187]
	Learning Rate: 0.000241868
	LOSS [training: 0.6366843393593642 | validation: 0.8817717889492647]
	TIME [epoch: 9.68 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.642994460092817		[learning rate: 0.0002407]
	Learning Rate: 0.000240699
	LOSS [training: 0.642994460092817 | validation: 0.8245851013580383]
	TIME [epoch: 9.68 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6151858028189092		[learning rate: 0.00023953]
	Learning Rate: 0.000239535
	LOSS [training: 0.6151858028189092 | validation: 0.8481467844894792]
	TIME [epoch: 9.71 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6028116496185542		[learning rate: 0.00023838]
	Learning Rate: 0.000238376
	LOSS [training: 0.6028116496185542 | validation: 0.8547876826593123]
	TIME [epoch: 9.68 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6106126175614766		[learning rate: 0.00023722]
	Learning Rate: 0.000237224
	LOSS [training: 0.6106126175614766 | validation: 0.8414287678002245]
	TIME [epoch: 9.69 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5999909931231572		[learning rate: 0.00023608]
	Learning Rate: 0.000236076
	LOSS [training: 0.5999909931231572 | validation: 0.8345850091723895]
	TIME [epoch: 9.71 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6138188577197624		[learning rate: 0.00023493]
	Learning Rate: 0.000234935
	LOSS [training: 0.6138188577197624 | validation: 0.8976421079248962]
	TIME [epoch: 9.69 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.62517796074542		[learning rate: 0.0002338]
	Learning Rate: 0.000233799
	LOSS [training: 0.62517796074542 | validation: 0.8541991630221955]
	TIME [epoch: 9.69 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6198817656660843		[learning rate: 0.00023267]
	Learning Rate: 0.000232668
	LOSS [training: 0.6198817656660843 | validation: 0.8213915461948658]
	TIME [epoch: 9.69 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6007808311889795		[learning rate: 0.00023154]
	Learning Rate: 0.000231543
	LOSS [training: 0.6007808311889795 | validation: 0.837668891186209]
	TIME [epoch: 9.71 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6199476808754885		[learning rate: 0.00023042]
	Learning Rate: 0.000230423
	LOSS [training: 0.6199476808754885 | validation: 0.8360461732126606]
	TIME [epoch: 9.68 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6183749842922627		[learning rate: 0.00022931]
	Learning Rate: 0.000229309
	LOSS [training: 0.6183749842922627 | validation: 0.8229399981762495]
	TIME [epoch: 9.69 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6050143968351407		[learning rate: 0.0002282]
	Learning Rate: 0.0002282
	LOSS [training: 0.6050143968351407 | validation: 0.8330241553125736]
	TIME [epoch: 9.71 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5946336607152372		[learning rate: 0.0002271]
	Learning Rate: 0.000227097
	LOSS [training: 0.5946336607152372 | validation: 0.8459954819638221]
	TIME [epoch: 9.69 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.611272633273078		[learning rate: 0.000226]
	Learning Rate: 0.000225998
	LOSS [training: 0.611272633273078 | validation: 0.8459173483826246]
	TIME [epoch: 9.69 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5936570714965426		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.5936570714965426 | validation: 0.869640803710231]
	TIME [epoch: 9.7 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6284717699682437		[learning rate: 0.00022382]
	Learning Rate: 0.000223818
	LOSS [training: 0.6284717699682437 | validation: 0.8555710475869157]
	TIME [epoch: 9.69 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6141464235924878		[learning rate: 0.00022274]
	Learning Rate: 0.000222736
	LOSS [training: 0.6141464235924878 | validation: 0.8801569300058231]
	TIME [epoch: 9.68 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6040943658608385		[learning rate: 0.00022166]
	Learning Rate: 0.000221658
	LOSS [training: 0.6040943658608385 | validation: 0.845218008243514]
	TIME [epoch: 9.69 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6026253760790333		[learning rate: 0.00022059]
	Learning Rate: 0.000220587
	LOSS [training: 0.6026253760790333 | validation: 0.8609252603184936]
	TIME [epoch: 9.71 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6159342240425661		[learning rate: 0.00021952]
	Learning Rate: 0.00021952
	LOSS [training: 0.6159342240425661 | validation: 0.84552155061501]
	TIME [epoch: 9.68 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5989806662014197		[learning rate: 0.00021846]
	Learning Rate: 0.000218458
	LOSS [training: 0.5989806662014197 | validation: 0.8477187830439893]
	TIME [epoch: 9.69 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5922782872018125		[learning rate: 0.0002174]
	Learning Rate: 0.000217402
	LOSS [training: 0.5922782872018125 | validation: 0.8507493103601478]
	TIME [epoch: 9.71 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6051585847362031		[learning rate: 0.00021635]
	Learning Rate: 0.00021635
	LOSS [training: 0.6051585847362031 | validation: 0.8092063334817462]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_841.pth
	Model improved!!!
EPOCH 842/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6089321966891871		[learning rate: 0.0002153]
	Learning Rate: 0.000215304
	LOSS [training: 0.6089321966891871 | validation: 0.8529501563853296]
	TIME [epoch: 9.7 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6137542386725556		[learning rate: 0.00021426]
	Learning Rate: 0.000214263
	LOSS [training: 0.6137542386725556 | validation: 0.851914907498367]
	TIME [epoch: 9.69 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6090018330935832		[learning rate: 0.00021323]
	Learning Rate: 0.000213227
	LOSS [training: 0.6090018330935832 | validation: 0.8812574705054003]
	TIME [epoch: 9.71 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6195533894759062		[learning rate: 0.0002122]
	Learning Rate: 0.000212196
	LOSS [training: 0.6195533894759062 | validation: 0.8368315717702112]
	TIME [epoch: 9.69 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6078724568937155		[learning rate: 0.00021117]
	Learning Rate: 0.00021117
	LOSS [training: 0.6078724568937155 | validation: 0.8782099057316697]
	TIME [epoch: 9.69 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6374245311557567		[learning rate: 0.00021015]
	Learning Rate: 0.000210149
	LOSS [training: 0.6374245311557567 | validation: 0.9024298007417714]
	TIME [epoch: 9.71 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6561840025402877		[learning rate: 0.00020913]
	Learning Rate: 0.000209132
	LOSS [training: 0.6561840025402877 | validation: 0.9363845413952799]
	TIME [epoch: 9.7 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.66931465749407		[learning rate: 0.00020812]
	Learning Rate: 0.000208121
	LOSS [training: 0.66931465749407 | validation: 0.8909801203134404]
	TIME [epoch: 9.69 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6358885327064552		[learning rate: 0.00020711]
	Learning Rate: 0.000207114
	LOSS [training: 0.6358885327064552 | validation: 0.8834514344893861]
	TIME [epoch: 9.69 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6299473130003448		[learning rate: 0.00020611]
	Learning Rate: 0.000206113
	LOSS [training: 0.6299473130003448 | validation: 0.8819347782885819]
	TIME [epoch: 9.71 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6160708873561072		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.6160708873561072 | validation: 0.9025029401190257]
	TIME [epoch: 9.69 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.61764995717176		[learning rate: 0.00020412]
	Learning Rate: 0.000204124
	LOSS [training: 0.61764995717176 | validation: 0.8544932359934108]
	TIME [epoch: 9.68 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6089348848231539		[learning rate: 0.00020314]
	Learning Rate: 0.000203137
	LOSS [training: 0.6089348848231539 | validation: 0.8213336791096708]
	TIME [epoch: 9.7 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6049289164021798		[learning rate: 0.00020215]
	Learning Rate: 0.000202155
	LOSS [training: 0.6049289164021798 | validation: 0.8881376110621529]
	TIME [epoch: 9.69 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6656770481849256		[learning rate: 0.00020118]
	Learning Rate: 0.000201177
	LOSS [training: 0.6656770481849256 | validation: 0.8201373474639527]
	TIME [epoch: 9.69 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6270365872030226		[learning rate: 0.0002002]
	Learning Rate: 0.000200204
	LOSS [training: 0.6270365872030226 | validation: 0.8296478345138759]
	TIME [epoch: 9.7 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5906873494769295		[learning rate: 0.00019924]
	Learning Rate: 0.000199236
	LOSS [training: 0.5906873494769295 | validation: 0.8506636272148014]
	TIME [epoch: 9.7 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6196126925404888		[learning rate: 0.00019827]
	Learning Rate: 0.000198273
	LOSS [training: 0.6196126925404888 | validation: 0.8380488961209096]
	TIME [epoch: 9.69 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6075590945279872		[learning rate: 0.00019731]
	Learning Rate: 0.000197314
	LOSS [training: 0.6075590945279872 | validation: 0.7936957913373454]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r0_20240218_115024/states/model_tr_study5_860.pth
	Model improved!!!
EPOCH 861/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6001214592875945		[learning rate: 0.00019636]
	Learning Rate: 0.00019636
	LOSS [training: 0.6001214592875945 | validation: 0.8445848526202749]
	TIME [epoch: 9.72 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6109612743894447		[learning rate: 0.00019541]
	Learning Rate: 0.00019541
	LOSS [training: 0.6109612743894447 | validation: 0.8415696854745898]
	TIME [epoch: 9.68 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5964666973379291		[learning rate: 0.00019447]
	Learning Rate: 0.000194465
	LOSS [training: 0.5964666973379291 | validation: 0.8356099770452755]
	TIME [epoch: 9.68 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5917404854211812		[learning rate: 0.00019352]
	Learning Rate: 0.000193525
	LOSS [training: 0.5917404854211812 | validation: 0.8285336708582807]
	TIME [epoch: 9.68 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5966841597662269		[learning rate: 0.00019259]
	Learning Rate: 0.000192589
	LOSS [training: 0.5966841597662269 | validation: 0.8406464808527799]
	TIME [epoch: 9.71 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5901362755523427		[learning rate: 0.00019166]
	Learning Rate: 0.000191658
	LOSS [training: 0.5901362755523427 | validation: 0.810921425656436]
	TIME [epoch: 9.68 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6142559660360059		[learning rate: 0.00019073]
	Learning Rate: 0.000190731
	LOSS [training: 0.6142559660360059 | validation: 0.8618444478738646]
	TIME [epoch: 9.68 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6085204032395659		[learning rate: 0.00018981]
	Learning Rate: 0.000189809
	LOSS [training: 0.6085204032395659 | validation: 0.8207999241717908]
	TIME [epoch: 9.69 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6167109866875184		[learning rate: 0.00018889]
	Learning Rate: 0.000188891
	LOSS [training: 0.6167109866875184 | validation: 0.8641339537001804]
	TIME [epoch: 9.69 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5980265524225239		[learning rate: 0.00018798]
	Learning Rate: 0.000187977
	LOSS [training: 0.5980265524225239 | validation: 0.849940453877758]
	TIME [epoch: 9.67 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6092897517516425		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.6092897517516425 | validation: 0.8386669449469518]
	TIME [epoch: 9.68 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6066357505245286		[learning rate: 0.00018616]
	Learning Rate: 0.000186164
	LOSS [training: 0.6066357505245286 | validation: 0.8251533234834362]
	TIME [epoch: 9.68 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6015573080370535		[learning rate: 0.00018526]
	Learning Rate: 0.000185263
	LOSS [training: 0.6015573080370535 | validation: 0.8195160891170117]
	TIME [epoch: 9.68 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6103822651776593		[learning rate: 0.00018437]
	Learning Rate: 0.000184367
	LOSS [training: 0.6103822651776593 | validation: 0.8180471097774856]
	TIME [epoch: 9.67 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6111105766377317		[learning rate: 0.00018348]
	Learning Rate: 0.000183476
	LOSS [training: 0.6111105766377317 | validation: 0.8318059798475629]
	TIME [epoch: 9.7 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6014306883373705		[learning rate: 0.00018259]
	Learning Rate: 0.000182589
	LOSS [training: 0.6014306883373705 | validation: 0.794029310017714]
	TIME [epoch: 9.67 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6012645017988889		[learning rate: 0.00018171]
	Learning Rate: 0.000181706
	LOSS [training: 0.6012645017988889 | validation: 0.8363820707249392]
	TIME [epoch: 9.67 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6121885730259513		[learning rate: 0.00018083]
	Learning Rate: 0.000180827
	LOSS [training: 0.6121885730259513 | validation: 0.8318500773090667]
	TIME [epoch: 9.69 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.633644262932803		[learning rate: 0.00017995]
	Learning Rate: 0.000179953
	LOSS [training: 0.633644262932803 | validation: 0.8311063266020443]
	TIME [epoch: 9.68 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5972396124407169		[learning rate: 0.00017908]
	Learning Rate: 0.000179082
	LOSS [training: 0.5972396124407169 | validation: 0.8198238055216696]
	TIME [epoch: 9.66 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5947678699247116		[learning rate: 0.00017822]
	Learning Rate: 0.000178216
	LOSS [training: 0.5947678699247116 | validation: 0.8022922844714916]
	TIME [epoch: 9.65 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.602254832440565		[learning rate: 0.00017735]
	Learning Rate: 0.000177354
	LOSS [training: 0.602254832440565 | validation: 0.8047226034658648]
	TIME [epoch: 9.68 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6092394912767268		[learning rate: 0.0001765]
	Learning Rate: 0.000176497
	LOSS [training: 0.6092394912767268 | validation: 0.8326380262106627]
	TIME [epoch: 9.66 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.612785877617801		[learning rate: 0.00017564]
	Learning Rate: 0.000175643
	LOSS [training: 0.612785877617801 | validation: 0.8244445467969347]
	TIME [epoch: 9.66 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5988322759917502		[learning rate: 0.00017479]
	Learning Rate: 0.000174794
	LOSS [training: 0.5988322759917502 | validation: 0.8225662450812987]
	TIME [epoch: 9.67 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.591493965949559		[learning rate: 0.00017395]
	Learning Rate: 0.000173949
	LOSS [training: 0.591493965949559 | validation: 0.8146794640851038]
	TIME [epoch: 9.66 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5984948102316262		[learning rate: 0.00017311]
	Learning Rate: 0.000173107
	LOSS [training: 0.5984948102316262 | validation: 0.8053298901708966]
	TIME [epoch: 9.66 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6019776920589986		[learning rate: 0.00017227]
	Learning Rate: 0.00017227
	LOSS [training: 0.6019776920589986 | validation: 0.8107080334428167]
	TIME [epoch: 9.66 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6053889560048107		[learning rate: 0.00017144]
	Learning Rate: 0.000171437
	LOSS [training: 0.6053889560048107 | validation: 0.8681165215642173]
	TIME [epoch: 9.69 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6561173444251021		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.6561173444251021 | validation: 0.8602029000176321]
	TIME [epoch: 9.67 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6201149627050903		[learning rate: 0.00016978]
	Learning Rate: 0.000169783
	LOSS [training: 0.6201149627050903 | validation: 0.8236701658113296]
	TIME [epoch: 9.66 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6029320101760135		[learning rate: 0.00016896]
	Learning Rate: 0.000168962
	LOSS [training: 0.6029320101760135 | validation: 0.822237828458087]
	TIME [epoch: 9.68 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6156657073069244		[learning rate: 0.00016815]
	Learning Rate: 0.000168145
	LOSS [training: 0.6156657073069244 | validation: 0.8586936048356794]
	TIME [epoch: 9.66 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6088660631808775		[learning rate: 0.00016733]
	Learning Rate: 0.000167332
	LOSS [training: 0.6088660631808775 | validation: 0.835129438271656]
	TIME [epoch: 9.66 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6170165742090964		[learning rate: 0.00016652]
	Learning Rate: 0.000166523
	LOSS [training: 0.6170165742090964 | validation: 0.8596046877107321]
	TIME [epoch: 9.67 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5939838111227291		[learning rate: 0.00016572]
	Learning Rate: 0.000165718
	LOSS [training: 0.5939838111227291 | validation: 0.8403847081840925]
	TIME [epoch: 9.68 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5966082809298264		[learning rate: 0.00016492]
	Learning Rate: 0.000164916
	LOSS [training: 0.5966082809298264 | validation: 0.834675085898414]
	TIME [epoch: 9.66 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6012453525345072		[learning rate: 0.00016412]
	Learning Rate: 0.000164119
	LOSS [training: 0.6012453525345072 | validation: 0.8329063853928468]
	TIME [epoch: 9.66 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5967811593665152		[learning rate: 0.00016332]
	Learning Rate: 0.000163325
	LOSS [training: 0.5967811593665152 | validation: 0.8314948408474067]
	TIME [epoch: 9.68 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5934136422080858		[learning rate: 0.00016254]
	Learning Rate: 0.000162535
	LOSS [training: 0.5934136422080858 | validation: 0.8349791885627719]
	TIME [epoch: 9.66 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5870333370659434		[learning rate: 0.00016175]
	Learning Rate: 0.000161749
	LOSS [training: 0.5870333370659434 | validation: 0.8399825527875223]
	TIME [epoch: 9.66 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6002361227763741		[learning rate: 0.00016097]
	Learning Rate: 0.000160967
	LOSS [training: 0.6002361227763741 | validation: 0.8301975699254996]
	TIME [epoch: 9.67 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5981100479274588		[learning rate: 0.00016019]
	Learning Rate: 0.000160189
	LOSS [training: 0.5981100479274588 | validation: 0.8266728602238937]
	TIME [epoch: 9.67 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5869793502460271		[learning rate: 0.00015941]
	Learning Rate: 0.000159414
	LOSS [training: 0.5869793502460271 | validation: 0.8306495763525266]
	TIME [epoch: 9.66 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6084286892231653		[learning rate: 0.00015864]
	Learning Rate: 0.000158643
	LOSS [training: 0.6084286892231653 | validation: 0.8496959083641652]
	TIME [epoch: 9.66 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6282552874282681		[learning rate: 0.00015788]
	Learning Rate: 0.000157876
	LOSS [training: 0.6282552874282681 | validation: 0.8831279521179765]
	TIME [epoch: 9.68 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6692314262341481		[learning rate: 0.00015711]
	Learning Rate: 0.000157112
	LOSS [training: 0.6692314262341481 | validation: 0.875648275474325]
	TIME [epoch: 9.65 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6150644916773286		[learning rate: 0.00015635]
	Learning Rate: 0.000156353
	LOSS [training: 0.6150644916773286 | validation: 0.8351888451562743]
	TIME [epoch: 9.66 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5965618462818308		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.5965618462818308 | validation: 0.835326846605154]
	TIME [epoch: 9.68 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5973457006082061		[learning rate: 0.00015484]
	Learning Rate: 0.000154844
	LOSS [training: 0.5973457006082061 | validation: 0.8146197433322943]
	TIME [epoch: 9.66 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6057024934065085		[learning rate: 0.0001541]
	Learning Rate: 0.000154095
	LOSS [training: 0.6057024934065085 | validation: 0.8345649877669056]
	TIME [epoch: 9.66 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5936658561638417		[learning rate: 0.00015335]
	Learning Rate: 0.00015335
	LOSS [training: 0.5936658561638417 | validation: 0.8125430043893107]
	TIME [epoch: 9.66 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.592656931875978		[learning rate: 0.00015261]
	Learning Rate: 0.000152609
	LOSS [training: 0.592656931875978 | validation: 0.8325373321871052]
	TIME [epoch: 9.67 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5913081869983572		[learning rate: 0.00015187]
	Learning Rate: 0.000151871
	LOSS [training: 0.5913081869983572 | validation: 0.8348596682817777]
	TIME [epoch: 9.66 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5926266355465342		[learning rate: 0.00015114]
	Learning Rate: 0.000151136
	LOSS [training: 0.5926266355465342 | validation: 0.8399354858844348]
	TIME [epoch: 9.66 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.588352684547556		[learning rate: 0.00015041]
	Learning Rate: 0.000150405
	LOSS [training: 0.588352684547556 | validation: 0.8406679341828234]
	TIME [epoch: 9.68 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6032181240374463		[learning rate: 0.00014968]
	Learning Rate: 0.000149678
	LOSS [training: 0.6032181240374463 | validation: 0.8488171297137784]
	TIME [epoch: 9.66 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6011890374755248		[learning rate: 0.00014895]
	Learning Rate: 0.000148954
	LOSS [training: 0.6011890374755248 | validation: 0.8450636484758083]
	TIME [epoch: 9.66 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.609827609485421		[learning rate: 0.00014823]
	Learning Rate: 0.000148234
	LOSS [training: 0.609827609485421 | validation: 0.850994311151812]
	TIME [epoch: 9.66 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6021118798867294		[learning rate: 0.00014752]
	Learning Rate: 0.000147517
	LOSS [training: 0.6021118798867294 | validation: 0.8324798032944049]
	TIME [epoch: 9.68 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5954107191460662		[learning rate: 0.0001468]
	Learning Rate: 0.000146804
	LOSS [training: 0.5954107191460662 | validation: 0.8289552658783734]
	TIME [epoch: 9.66 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5987948143647343		[learning rate: 0.00014609]
	Learning Rate: 0.000146094
	LOSS [training: 0.5987948143647343 | validation: 0.8598567269062078]
	TIME [epoch: 9.65 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5969653305848556		[learning rate: 0.00014539]
	Learning Rate: 0.000145387
	LOSS [training: 0.5969653305848556 | validation: 0.8348287591526022]
	TIME [epoch: 9.68 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5833118036591756		[learning rate: 0.00014468]
	Learning Rate: 0.000144684
	LOSS [training: 0.5833118036591756 | validation: 0.8510819974484116]
	TIME [epoch: 9.67 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5894423452486359		[learning rate: 0.00014398]
	Learning Rate: 0.000143985
	LOSS [training: 0.5894423452486359 | validation: 0.8520478775869919]
	TIME [epoch: 9.66 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6046586646643213		[learning rate: 0.00014329]
	Learning Rate: 0.000143288
	LOSS [training: 0.6046586646643213 | validation: 0.8628259004641121]
	TIME [epoch: 9.67 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6028518807080934		[learning rate: 0.0001426]
	Learning Rate: 0.000142595
	LOSS [training: 0.6028518807080934 | validation: 0.8536424260302827]
	TIME [epoch: 9.66 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5930079921634883		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.5930079921634883 | validation: 0.8747121227443235]
	TIME [epoch: 9.66 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6001218089095272		[learning rate: 0.00014122]
	Learning Rate: 0.000141219
	LOSS [training: 0.6001218089095272 | validation: 0.8476348040790197]
	TIME [epoch: 9.66 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5916741749416605		[learning rate: 0.00014054]
	Learning Rate: 0.000140537
	LOSS [training: 0.5916741749416605 | validation: 0.8428844477172026]
	TIME [epoch: 9.68 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5928078525302165		[learning rate: 0.00013986]
	Learning Rate: 0.000139857
	LOSS [training: 0.5928078525302165 | validation: 0.8602379144462468]
	TIME [epoch: 9.67 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5922734202183244		[learning rate: 0.00013918]
	Learning Rate: 0.000139181
	LOSS [training: 0.5922734202183244 | validation: 0.8228028152901297]
	TIME [epoch: 9.66 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5859575108679375		[learning rate: 0.00013851]
	Learning Rate: 0.000138508
	LOSS [training: 0.5859575108679375 | validation: 0.815441429550479]
	TIME [epoch: 9.68 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5927959040856253		[learning rate: 0.00013784]
	Learning Rate: 0.000137838
	LOSS [training: 0.5927959040856253 | validation: 0.8348969927945947]
	TIME [epoch: 9.66 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.583404767461039		[learning rate: 0.00013717]
	Learning Rate: 0.000137171
	LOSS [training: 0.583404767461039 | validation: 0.8307836038362086]
	TIME [epoch: 9.66 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5876172863096825		[learning rate: 0.00013651]
	Learning Rate: 0.000136508
	LOSS [training: 0.5876172863096825 | validation: 0.827949430481666]
	TIME [epoch: 9.66 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5910158804653906		[learning rate: 0.00013585]
	Learning Rate: 0.000135848
	LOSS [training: 0.5910158804653906 | validation: 0.8509786757814934]
	TIME [epoch: 9.67 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.599027921647925		[learning rate: 0.00013519]
	Learning Rate: 0.000135191
	LOSS [training: 0.599027921647925 | validation: 0.8439482329373488]
	TIME [epoch: 9.66 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5882305250873514		[learning rate: 0.00013454]
	Learning Rate: 0.000134537
	LOSS [training: 0.5882305250873514 | validation: 0.8334840561672633]
	TIME [epoch: 9.65 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5931069449030402		[learning rate: 0.00013389]
	Learning Rate: 0.000133887
	LOSS [training: 0.5931069449030402 | validation: 0.8121757369371594]
	TIME [epoch: 9.68 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6023633390163917		[learning rate: 0.00013324]
	Learning Rate: 0.000133239
	LOSS [training: 0.6023633390163917 | validation: 0.8426769723072667]
	TIME [epoch: 9.66 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5833311898207232		[learning rate: 0.00013259]
	Learning Rate: 0.000132595
	LOSS [training: 0.5833311898207232 | validation: 0.8301273907097132]
	TIME [epoch: 9.66 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5897120570616338		[learning rate: 0.00013195]
	Learning Rate: 0.000131954
	LOSS [training: 0.5897120570616338 | validation: 0.8231119705656872]
	TIME [epoch: 9.67 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5926928506472412		[learning rate: 0.00013132]
	Learning Rate: 0.000131315
	LOSS [training: 0.5926928506472412 | validation: 0.8301114374715047]
	TIME [epoch: 9.67 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6022897813941739		[learning rate: 0.00013068]
	Learning Rate: 0.00013068
	LOSS [training: 0.6022897813941739 | validation: 0.8317144190066332]
	TIME [epoch: 9.65 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5997288644933653		[learning rate: 0.00013005]
	Learning Rate: 0.000130048
	LOSS [training: 0.5997288644933653 | validation: 0.855047152385045]
	TIME [epoch: 9.66 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5952610744077063		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.5952610744077063 | validation: 0.8491882221484673]
	TIME [epoch: 9.68 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5857399347572304		[learning rate: 0.00012879]
	Learning Rate: 0.000128794
	LOSS [training: 0.5857399347572304 | validation: 0.8287222745977545]
	TIME [epoch: 9.66 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5956851753507684		[learning rate: 0.00012817]
	Learning Rate: 0.000128171
	LOSS [training: 0.5956851753507684 | validation: 0.8282062626688647]
	TIME [epoch: 9.66 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5908110253062754		[learning rate: 0.00012755]
	Learning Rate: 0.000127551
	LOSS [training: 0.5908110253062754 | validation: 0.8270319161125776]
	TIME [epoch: 9.67 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5981928010991995		[learning rate: 0.00012693]
	Learning Rate: 0.000126934
	LOSS [training: 0.5981928010991995 | validation: 0.8381027319992087]
	TIME [epoch: 9.66 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6115293548222038		[learning rate: 0.00012632]
	Learning Rate: 0.00012632
	LOSS [training: 0.6115293548222038 | validation: 0.8297723875827447]
	TIME [epoch: 9.66 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5996472823012212		[learning rate: 0.00012571]
	Learning Rate: 0.00012571
	LOSS [training: 0.5996472823012212 | validation: 0.8268384788414116]
	TIME [epoch: 9.66 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6101524175309485		[learning rate: 0.0001251]
	Learning Rate: 0.000125102
	LOSS [training: 0.6101524175309485 | validation: 0.8642153617608287]
	TIME [epoch: 9.69 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6131089332638681		[learning rate: 0.0001245]
	Learning Rate: 0.000124497
	LOSS [training: 0.6131089332638681 | validation: 0.8304773970530969]
	TIME [epoch: 9.66 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6159658321484007		[learning rate: 0.00012389]
	Learning Rate: 0.000123895
	LOSS [training: 0.6159658321484007 | validation: 0.8657734762072076]
	TIME [epoch: 9.66 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5976169619971732		[learning rate: 0.0001233]
	Learning Rate: 0.000123296
	LOSS [training: 0.5976169619971732 | validation: 0.8089175441438216]
	TIME [epoch: 9.69 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5986367233776724		[learning rate: 0.0001227]
	Learning Rate: 0.000122699
	LOSS [training: 0.5986367233776724 | validation: 0.8589483985103781]
	TIME [epoch: 9.66 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6073243143599081		[learning rate: 0.00012211]
	Learning Rate: 0.000122106
	LOSS [training: 0.6073243143599081 | validation: 0.8932844923234415]
	TIME [epoch: 9.66 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6387718518425214		[learning rate: 0.00012152]
	Learning Rate: 0.000121515
	LOSS [training: 0.6387718518425214 | validation: 0.9228031447492382]
	TIME [epoch: 9.67 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6341604972290492		[learning rate: 0.00012093]
	Learning Rate: 0.000120928
	LOSS [training: 0.6341604972290492 | validation: 0.8693862316773053]
	TIME [epoch: 9.68 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6068403863602273		[learning rate: 0.00012034]
	Learning Rate: 0.000120343
	LOSS [training: 0.6068403863602273 | validation: 0.8317757377540054]
	TIME [epoch: 9.66 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6069484826063661		[learning rate: 0.00011976]
	Learning Rate: 0.000119761
	LOSS [training: 0.6069484826063661 | validation: 0.8281268158206015]
	TIME [epoch: 9.66 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5939718394393875		[learning rate: 0.00011918]
	Learning Rate: 0.000119182
	LOSS [training: 0.5939718394393875 | validation: 0.8417605614648624]
	TIME [epoch: 9.68 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5918460844003334		[learning rate: 0.00011861]
	Learning Rate: 0.000118606
	LOSS [training: 0.5918460844003334 | validation: 0.8417376405782712]
	TIME [epoch: 9.67 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5898268898753806		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.5898268898753806 | validation: 0.8581759892229002]
	TIME [epoch: 9.66 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5966830187513498		[learning rate: 0.00011746]
	Learning Rate: 0.000117461
	LOSS [training: 0.5966830187513498 | validation: 0.8592761546919957]
	TIME [epoch: 9.67 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6014215957461884		[learning rate: 0.00011689]
	Learning Rate: 0.000116893
	LOSS [training: 0.6014215957461884 | validation: 0.877897926718999]
	TIME [epoch: 9.66 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5980878234386708		[learning rate: 0.00011633]
	Learning Rate: 0.000116328
	LOSS [training: 0.5980878234386708 | validation: 0.8692748604373626]
	TIME [epoch: 9.66 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6049935694361116		[learning rate: 0.00011577]
	Learning Rate: 0.000115765
	LOSS [training: 0.6049935694361116 | validation: 0.8911425175595619]
	TIME [epoch: 9.65 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6370372855517499		[learning rate: 0.00011521]
	Learning Rate: 0.000115206
	LOSS [training: 0.6370372855517499 | validation: 0.8832012176518864]
	TIME [epoch: 9.69 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.633214116311969		[learning rate: 0.00011465]
	Learning Rate: 0.000114649
	LOSS [training: 0.633214116311969 | validation: 0.8685607662777747]
	TIME [epoch: 9.66 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6041484828271969		[learning rate: 0.00011409]
	Learning Rate: 0.000114094
	LOSS [training: 0.6041484828271969 | validation: 0.8548350832276899]
	TIME [epoch: 9.66 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5923741790531254		[learning rate: 0.00011354]
	Learning Rate: 0.000113542
	LOSS [training: 0.5923741790531254 | validation: 0.8451169990910831]
	TIME [epoch: 9.68 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5879393638426176		[learning rate: 0.00011299]
	Learning Rate: 0.000112993
	LOSS [training: 0.5879393638426176 | validation: 0.863985501577297]
	TIME [epoch: 9.67 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5961116237550443		[learning rate: 0.00011245]
	Learning Rate: 0.000112447
	LOSS [training: 0.5961116237550443 | validation: 0.8734953176843939]
	TIME [epoch: 9.65 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.594157113429149		[learning rate: 0.0001119]
	Learning Rate: 0.000111903
	LOSS [training: 0.594157113429149 | validation: 0.8561065676540598]
	TIME [epoch: 9.66 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5897915702029486		[learning rate: 0.00011136]
	Learning Rate: 0.000111362
	LOSS [training: 0.5897915702029486 | validation: 0.8386635159537752]
	TIME [epoch: 9.67 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5955321034190607		[learning rate: 0.00011082]
	Learning Rate: 0.000110823
	LOSS [training: 0.5955321034190607 | validation: 0.8678482234866889]
	TIME [epoch: 9.67 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5924925883388478		[learning rate: 0.00011029]
	Learning Rate: 0.000110288
	LOSS [training: 0.5924925883388478 | validation: 0.841637632586576]
	TIME [epoch: 9.66 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6193415020088858		[learning rate: 0.00010975]
	Learning Rate: 0.000109754
	LOSS [training: 0.6193415020088858 | validation: 0.8833458491986113]
	TIME [epoch: 9.68 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6411251571533092		[learning rate: 0.00010922]
	Learning Rate: 0.000109223
	LOSS [training: 0.6411251571533092 | validation: 0.8685671340542226]
	TIME [epoch: 9.67 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6327855552147257		[learning rate: 0.0001087]
	Learning Rate: 0.000108695
	LOSS [training: 0.6327855552147257 | validation: 0.8821079467343047]
	TIME [epoch: 9.66 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6295774448904388		[learning rate: 0.00010817]
	Learning Rate: 0.00010817
	LOSS [training: 0.6295774448904388 | validation: 0.8621941553728781]
	TIME [epoch: 9.67 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6037457324174428		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.6037457324174428 | validation: 0.8479752093671078]
	TIME [epoch: 9.68 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5947051234059315		[learning rate: 0.00010713]
	Learning Rate: 0.000107126
	LOSS [training: 0.5947051234059315 | validation: 0.8509630182563107]
	TIME [epoch: 9.66 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5964668103179308		[learning rate: 0.00010661]
	Learning Rate: 0.000106608
	LOSS [training: 0.5964668103179308 | validation: 0.8562372249247931]
	TIME [epoch: 9.66 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5981195613266089		[learning rate: 0.00010609]
	Learning Rate: 0.000106092
	LOSS [training: 0.5981195613266089 | validation: 0.8296628832624177]
	TIME [epoch: 9.68 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5889891281390709		[learning rate: 0.00010558]
	Learning Rate: 0.000105579
	LOSS [training: 0.5889891281390709 | validation: 0.8346701027548754]
	TIME [epoch: 9.66 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5846879757623664		[learning rate: 0.00010507]
	Learning Rate: 0.000105069
	LOSS [training: 0.5846879757623664 | validation: 0.8535225232520588]
	TIME [epoch: 9.67 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.597997105476796		[learning rate: 0.00010456]
	Learning Rate: 0.000104561
	LOSS [training: 0.597997105476796 | validation: 0.8239495545856959]
	TIME [epoch: 9.68 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5893843446243657		[learning rate: 0.00010406]
	Learning Rate: 0.000104055
	LOSS [training: 0.5893843446243657 | validation: 0.8618304878471744]
	TIME [epoch: 9.67 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5926283934144497		[learning rate: 0.00010355]
	Learning Rate: 0.000103552
	LOSS [training: 0.5926283934144497 | validation: 0.8138991372858603]
	TIME [epoch: 9.66 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5930736005643085		[learning rate: 0.00010305]
	Learning Rate: 0.000103051
	LOSS [training: 0.5930736005643085 | validation: 0.8349404732403015]
	TIME [epoch: 9.67 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5823720445856908		[learning rate: 0.00010255]
	Learning Rate: 0.000102553
	LOSS [training: 0.5823720445856908 | validation: 0.8232063640160597]
	TIME [epoch: 9.68 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5811180016958838		[learning rate: 0.00010206]
	Learning Rate: 0.000102057
	LOSS [training: 0.5811180016958838 | validation: 0.846615274471834]
	TIME [epoch: 9.66 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5858469224943945		[learning rate: 0.00010156]
	Learning Rate: 0.000101563
	LOSS [training: 0.5858469224943945 | validation: 0.8213896920084227]
	TIME [epoch: 9.65 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5924960031929581		[learning rate: 0.00010107]
	Learning Rate: 0.000101072
	LOSS [training: 0.5924960031929581 | validation: 0.8517462833342111]
	TIME [epoch: 9.68 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5987050233863118		[learning rate: 0.00010058]
	Learning Rate: 0.000100583
	LOSS [training: 0.5987050233863118 | validation: 0.8175700819914473]
	TIME [epoch: 9.67 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5873525945771437		[learning rate: 0.0001001]
	Learning Rate: 0.000100097
	LOSS [training: 0.5873525945771437 | validation: 0.8386683555795521]
	TIME [epoch: 9.66 sec]
Finished training in 9806.876 seconds.
