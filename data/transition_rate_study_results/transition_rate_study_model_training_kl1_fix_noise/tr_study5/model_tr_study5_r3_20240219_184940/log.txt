Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r3', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1437924779

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.952573091834392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.952573091834392 | validation: 11.6211466178411]
	TIME [epoch: 80.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.919217918328577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.919217918328577 | validation: 10.95229535656314]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.465816895803247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.465816895803247 | validation: 10.80505024816229]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.125307254012744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.125307254012744 | validation: 10.70370068818806]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.029987253363803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.029987253363803 | validation: 10.56598561508686]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.909820990461927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.909820990461927 | validation: 10.570451435403593]
	TIME [epoch: 9.52 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.558584195234165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.558584195234165 | validation: 10.081618532321482]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.29597876671031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.29597876671031 | validation: 10.276012030652089]
	TIME [epoch: 9.52 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.304412891186967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.304412891186967 | validation: 9.91438744086693]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.484716738413749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.484716738413749 | validation: 10.086319250316349]
	TIME [epoch: 9.53 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.855209563832243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.855209563832243 | validation: 9.35244565430751]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.392153514190898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.392153514190898 | validation: 10.13819862150559]
	TIME [epoch: 9.51 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.534913931334374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.534913931334374 | validation: 8.67347849414318]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.619655086195541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.619655086195541 | validation: 11.902295695167846]
	TIME [epoch: 9.54 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.395235903861217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.395235903861217 | validation: 10.242274879949052]
	TIME [epoch: 9.51 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.535434143888585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.535434143888585 | validation: 8.684271656294]
	TIME [epoch: 9.51 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.289564751622972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.289564751622972 | validation: 8.90798066585951]
	TIME [epoch: 9.53 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.601209684787772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.601209684787772 | validation: 9.448608010381829]
	TIME [epoch: 9.51 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.132902512587183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.132902512587183 | validation: 8.429502855832952]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.7817867360060875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.7817867360060875 | validation: 8.028551080090345]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.344756352793094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.344756352793094 | validation: 8.49225083241163]
	TIME [epoch: 9.53 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.097069811170153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.097069811170153 | validation: 9.267490225284146]
	TIME [epoch: 9.51 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.535342070979874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.535342070979874 | validation: 8.1266450786058]
	TIME [epoch: 9.5 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.016069769108611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.016069769108611 | validation: 7.987831053937581]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.64143403470184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.64143403470184 | validation: 7.702104513856526]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.781337975025883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.781337975025883 | validation: 6.869781787244125]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.0111662888422215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.0111662888422215 | validation: 7.18827485144212]
	TIME [epoch: 9.54 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.016199701935436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.016199701935436 | validation: 7.057539898576753]
	TIME [epoch: 9.51 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.210045480498481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.210045480498481 | validation: 6.934909949648285]
	TIME [epoch: 9.5 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.168990358406812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.168990358406812 | validation: 6.387507712913722]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.7862807327220445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7862807327220445 | validation: 6.516657917017394]
	TIME [epoch: 9.53 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.93239934871645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.93239934871645 | validation: 6.379258323165848]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.8157080873738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8157080873738 | validation: 6.123216979595098]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.659713738768924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.659713738768924 | validation: 6.97242520192388]
	TIME [epoch: 9.52 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.9006676378266025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9006676378266025 | validation: 6.134349453105633]
	TIME [epoch: 9.5 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.744543723270645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.744543723270645 | validation: 6.396467087389761]
	TIME [epoch: 9.5 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.951942430576804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.951942430576804 | validation: 5.997942535382699]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.33881322525636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.33881322525636 | validation: 7.691714780878274]
	TIME [epoch: 9.53 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.227562581555011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.227562581555011 | validation: 6.010908646341452]
	TIME [epoch: 9.49 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.415079057241118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.415079057241118 | validation: 6.079515662419245]
	TIME [epoch: 9.49 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.6227474932351225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6227474932351225 | validation: 6.190703701977563]
	TIME [epoch: 9.52 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.83617431812999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.83617431812999 | validation: 6.044146566361515]
	TIME [epoch: 9.51 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.6128376313158395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6128376313158395 | validation: 6.28944499412481]
	TIME [epoch: 9.49 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.503535916515556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.503535916515556 | validation: 5.934364514104332]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.5531350927333945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5531350927333945 | validation: 6.158965379294266]
	TIME [epoch: 9.52 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.348518831665935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.348518831665935 | validation: 5.831130976146755]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.331248858817554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.331248858817554 | validation: 6.361667917588766]
	TIME [epoch: 9.52 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.387108733116547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.387108733116547 | validation: 5.905543392526449]
	TIME [epoch: 9.53 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.291148578218609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.291148578218609 | validation: 6.82963007686011]
	TIME [epoch: 9.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.7331423887422925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7331423887422925 | validation: 6.071377501575052]
	TIME [epoch: 9.49 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.329489046627428		[learning rate: 0.0099811]
	Learning Rate: 0.00998112
	LOSS [training: 5.329489046627428 | validation: 5.933221806164452]
	TIME [epoch: 9.51 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.212918329881261		[learning rate: 0.0099576]
	Learning Rate: 0.00995758
	LOSS [training: 5.212918329881261 | validation: 5.839194419114405]
	TIME [epoch: 9.5 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.241952744323504		[learning rate: 0.0099341]
	Learning Rate: 0.00993409
	LOSS [training: 5.241952744323504 | validation: 5.540666909063474]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.12103228447791		[learning rate: 0.0099107]
	Learning Rate: 0.00991066
	LOSS [training: 5.12103228447791 | validation: 5.940506486450988]
	TIME [epoch: 9.52 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.049495033271944		[learning rate: 0.0098873]
	Learning Rate: 0.00988728
	LOSS [training: 5.049495033271944 | validation: 5.4749434548192175]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.881213636764743		[learning rate: 0.009864]
	Learning Rate: 0.00986396
	LOSS [training: 5.881213636764743 | validation: 7.006749328204437]
	TIME [epoch: 9.52 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.902437566152512		[learning rate: 0.0098407]
	Learning Rate: 0.00984069
	LOSS [training: 5.902437566152512 | validation: 6.089737385576075]
	TIME [epoch: 9.52 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.704909859532673		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 5.704909859532673 | validation: 5.6235988373499275]
	TIME [epoch: 9.54 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.411139318528997		[learning rate: 0.0097943]
	Learning Rate: 0.00979432
	LOSS [training: 5.411139318528997 | validation: 6.002130337850219]
	TIME [epoch: 9.52 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.083502813678878		[learning rate: 0.0097712]
	Learning Rate: 0.00977122
	LOSS [training: 5.083502813678878 | validation: 5.629132697059034]
	TIME [epoch: 9.52 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.779278432068195		[learning rate: 0.0097482]
	Learning Rate: 0.00974817
	LOSS [training: 4.779278432068195 | validation: 6.073944474179475]
	TIME [epoch: 9.52 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.267542823349761		[learning rate: 0.0097252]
	Learning Rate: 0.00972517
	LOSS [training: 5.267542823349761 | validation: 5.424839640984667]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.058213664234186		[learning rate: 0.0097022]
	Learning Rate: 0.00970223
	LOSS [training: 5.058213664234186 | validation: 5.433707135978298]
	TIME [epoch: 9.52 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.8540240572394		[learning rate: 0.0096793]
	Learning Rate: 0.00967935
	LOSS [training: 4.8540240572394 | validation: 5.884547107893491]
	TIME [epoch: 9.52 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.958272167964444		[learning rate: 0.0096565]
	Learning Rate: 0.00965652
	LOSS [training: 4.958272167964444 | validation: 5.9979717604425815]
	TIME [epoch: 9.54 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.298963679710316		[learning rate: 0.0096337]
	Learning Rate: 0.00963374
	LOSS [training: 5.298963679710316 | validation: 5.996217823647349]
	TIME [epoch: 9.53 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.950035710287039		[learning rate: 0.009611]
	Learning Rate: 0.00961101
	LOSS [training: 4.950035710287039 | validation: 5.194101829784812]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.756395022746471		[learning rate: 0.0095883]
	Learning Rate: 0.00958834
	LOSS [training: 4.756395022746471 | validation: 5.4481018856036165]
	TIME [epoch: 9.53 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.805688370975814		[learning rate: 0.0095657]
	Learning Rate: 0.00956573
	LOSS [training: 4.805688370975814 | validation: 5.2323309778388785]
	TIME [epoch: 9.54 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.119829225590303		[learning rate: 0.0095432]
	Learning Rate: 0.00954316
	LOSS [training: 5.119829225590303 | validation: 5.153577451583155]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.147861550909835		[learning rate: 0.0095207]
	Learning Rate: 0.00952065
	LOSS [training: 5.147861550909835 | validation: 5.194737563954204]
	TIME [epoch: 9.52 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.426213474323318		[learning rate: 0.0094982]
	Learning Rate: 0.00949819
	LOSS [training: 5.426213474323318 | validation: 6.049929343906391]
	TIME [epoch: 9.54 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.782118797124154		[learning rate: 0.0094758]
	Learning Rate: 0.00947579
	LOSS [training: 5.782118797124154 | validation: 6.342444013574926]
	TIME [epoch: 9.52 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.121130200257211		[learning rate: 0.0094534]
	Learning Rate: 0.00945344
	LOSS [training: 5.121130200257211 | validation: 5.151859666133263]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.575696796812318		[learning rate: 0.0094311]
	Learning Rate: 0.00943114
	LOSS [training: 4.575696796812318 | validation: 5.970912307130848]
	TIME [epoch: 9.53 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.901122932382365		[learning rate: 0.0094089]
	Learning Rate: 0.00940889
	LOSS [training: 4.901122932382365 | validation: 5.23037155183165]
	TIME [epoch: 9.53 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.321018933104919		[learning rate: 0.0093867]
	Learning Rate: 0.0093867
	LOSS [training: 5.321018933104919 | validation: 6.448870087032384]
	TIME [epoch: 9.51 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.5545296348834		[learning rate: 0.0093646]
	Learning Rate: 0.00936456
	LOSS [training: 5.5545296348834 | validation: 5.590552053317529]
	TIME [epoch: 9.51 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.297591234779669		[learning rate: 0.0093425]
	Learning Rate: 0.00934247
	LOSS [training: 5.297591234779669 | validation: 5.980759234452494]
	TIME [epoch: 9.53 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.863540943318673		[learning rate: 0.0093204]
	Learning Rate: 0.00932043
	LOSS [training: 5.863540943318673 | validation: 5.773520321254753]
	TIME [epoch: 9.51 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.26592066379025		[learning rate: 0.0092984]
	Learning Rate: 0.00929844
	LOSS [training: 5.26592066379025 | validation: 5.862897489763643]
	TIME [epoch: 9.51 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.1173474535260866		[learning rate: 0.0092765]
	Learning Rate: 0.00927651
	LOSS [training: 5.1173474535260866 | validation: 5.779974241498287]
	TIME [epoch: 9.52 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.5300732108678		[learning rate: 0.0092546]
	Learning Rate: 0.00925463
	LOSS [training: 5.5300732108678 | validation: 6.046500226475453]
	TIME [epoch: 9.52 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.452734810336953		[learning rate: 0.0092328]
	Learning Rate: 0.0092328
	LOSS [training: 5.452734810336953 | validation: 5.611275773551811]
	TIME [epoch: 9.51 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.184698700260299		[learning rate: 0.009211]
	Learning Rate: 0.00921102
	LOSS [training: 5.184698700260299 | validation: 5.964617534855145]
	TIME [epoch: 9.51 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.931750536619378		[learning rate: 0.0091893]
	Learning Rate: 0.00918929
	LOSS [training: 4.931750536619378 | validation: 5.977409980504241]
	TIME [epoch: 9.53 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.737512572662351		[learning rate: 0.0091676]
	Learning Rate: 0.00916762
	LOSS [training: 5.737512572662351 | validation: 5.794817103908968]
	TIME [epoch: 9.5 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.488187977218061		[learning rate: 0.009146]
	Learning Rate: 0.00914599
	LOSS [training: 5.488187977218061 | validation: 5.818925859022161]
	TIME [epoch: 9.51 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.562167256774498		[learning rate: 0.0091244]
	Learning Rate: 0.00912442
	LOSS [training: 5.562167256774498 | validation: 5.38463727525265]
	TIME [epoch: 9.52 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.230658743870698		[learning rate: 0.0091029]
	Learning Rate: 0.00910289
	LOSS [training: 5.230658743870698 | validation: 5.490587058096205]
	TIME [epoch: 9.51 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.35385475061384		[learning rate: 0.0090814]
	Learning Rate: 0.00908142
	LOSS [training: 5.35385475061384 | validation: 5.48727905713376]
	TIME [epoch: 9.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.405455994860017		[learning rate: 0.00906]
	Learning Rate: 0.00906
	LOSS [training: 5.405455994860017 | validation: 5.520774910979037]
	TIME [epoch: 9.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.960127008585745		[learning rate: 0.0090386]
	Learning Rate: 0.00903863
	LOSS [training: 4.960127008585745 | validation: 5.537522171174893]
	TIME [epoch: 9.53 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.28354159020766		[learning rate: 0.0090173]
	Learning Rate: 0.00901731
	LOSS [training: 5.28354159020766 | validation: 5.397673532071288]
	TIME [epoch: 9.51 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.076341865397643		[learning rate: 0.008996]
	Learning Rate: 0.00899604
	LOSS [training: 5.076341865397643 | validation: 5.484730118425773]
	TIME [epoch: 9.52 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.351655938562977		[learning rate: 0.0089748]
	Learning Rate: 0.00897482
	LOSS [training: 5.351655938562977 | validation: 6.0790681721888635]
	TIME [epoch: 9.53 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.498318026919192		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 5.498318026919192 | validation: 5.399471559243355]
	TIME [epoch: 9.52 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.647533270843372		[learning rate: 0.0089325]
	Learning Rate: 0.00893253
	LOSS [training: 5.647533270843372 | validation: 6.612405764673029]
	TIME [epoch: 9.51 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.706085510310585		[learning rate: 0.0089115]
	Learning Rate: 0.00891146
	LOSS [training: 5.706085510310585 | validation: 5.475381967427897]
	TIME [epoch: 9.51 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.093124690828802		[learning rate: 0.0088904]
	Learning Rate: 0.00889044
	LOSS [training: 5.093124690828802 | validation: 5.204440182247781]
	TIME [epoch: 9.53 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.677460987772801		[learning rate: 0.0088695]
	Learning Rate: 0.00886946
	LOSS [training: 5.677460987772801 | validation: 5.807439128153521]
	TIME [epoch: 9.51 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.491467946969542		[learning rate: 0.0088485]
	Learning Rate: 0.00884854
	LOSS [training: 5.491467946969542 | validation: 5.355165227948828]
	TIME [epoch: 9.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.166202395884895		[learning rate: 0.0088277]
	Learning Rate: 0.00882767
	LOSS [training: 5.166202395884895 | validation: 5.338567096499832]
	TIME [epoch: 9.53 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.296782707267065		[learning rate: 0.0088068]
	Learning Rate: 0.00880685
	LOSS [training: 5.296782707267065 | validation: 5.298605612461408]
	TIME [epoch: 9.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.012158995174474		[learning rate: 0.0087861]
	Learning Rate: 0.00878607
	LOSS [training: 5.012158995174474 | validation: 8.057023786518279]
	TIME [epoch: 9.51 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.257476976518823		[learning rate: 0.0087653]
	Learning Rate: 0.00876535
	LOSS [training: 6.257476976518823 | validation: 4.977058480501015]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.915829865508556		[learning rate: 0.0087447]
	Learning Rate: 0.00874467
	LOSS [training: 4.915829865508556 | validation: 5.278994827656966]
	TIME [epoch: 9.53 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.5046703223714095		[learning rate: 0.008724]
	Learning Rate: 0.00872405
	LOSS [training: 4.5046703223714095 | validation: 5.077374233043812]
	TIME [epoch: 9.52 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.203633027013165		[learning rate: 0.0087035]
	Learning Rate: 0.00870347
	LOSS [training: 4.203633027013165 | validation: 4.798614829907177]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.720307872398917		[learning rate: 0.0086829]
	Learning Rate: 0.00868294
	LOSS [training: 4.720307872398917 | validation: 4.444799007349781]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.306510939324594		[learning rate: 0.0086625]
	Learning Rate: 0.00866246
	LOSS [training: 4.306510939324594 | validation: 5.952415761377108]
	TIME [epoch: 9.52 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.318742677284432		[learning rate: 0.008642]
	Learning Rate: 0.00864202
	LOSS [training: 5.318742677284432 | validation: 3.681054887227842]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.202690652248761		[learning rate: 0.0086216]
	Learning Rate: 0.00862164
	LOSS [training: 4.202690652248761 | validation: 3.740890036938172]
	TIME [epoch: 9.53 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7150107730832787		[learning rate: 0.0086013]
	Learning Rate: 0.0086013
	LOSS [training: 3.7150107730832787 | validation: 2.9729256579069294]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4799523615067387		[learning rate: 0.008581]
	Learning Rate: 0.00858101
	LOSS [training: 3.4799523615067387 | validation: 4.620359500676943]
	TIME [epoch: 9.51 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.703043913309453		[learning rate: 0.0085608]
	Learning Rate: 0.00856077
	LOSS [training: 3.703043913309453 | validation: 3.3929696327941943]
	TIME [epoch: 9.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.335903915560382		[learning rate: 0.0085406]
	Learning Rate: 0.00854058
	LOSS [training: 3.335903915560382 | validation: 2.4015873993567944]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0791000607486962		[learning rate: 0.0085204]
	Learning Rate: 0.00852043
	LOSS [training: 3.0791000607486962 | validation: 4.737729300751206]
	TIME [epoch: 9.52 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2504937302582513		[learning rate: 0.0085003]
	Learning Rate: 0.00850033
	LOSS [training: 3.2504937302582513 | validation: 2.8179638687350645]
	TIME [epoch: 9.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.878745392120776		[learning rate: 0.0084803]
	Learning Rate: 0.00848028
	LOSS [training: 2.878745392120776 | validation: 2.6077294286429766]
	TIME [epoch: 9.52 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3018534522227947		[learning rate: 0.0084603]
	Learning Rate: 0.00846028
	LOSS [training: 3.3018534522227947 | validation: 3.791044199160991]
	TIME [epoch: 9.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.167260881350555		[learning rate: 0.0084403]
	Learning Rate: 0.00844032
	LOSS [training: 3.167260881350555 | validation: 2.510398757145618]
	TIME [epoch: 9.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7783742449277122		[learning rate: 0.0084204]
	Learning Rate: 0.00842041
	LOSS [training: 2.7783742449277122 | validation: 2.621798159989097]
	TIME [epoch: 9.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6219834592225064		[learning rate: 0.0084005]
	Learning Rate: 0.00840055
	LOSS [training: 3.6219834592225064 | validation: 2.677269908448872]
	TIME [epoch: 9.52 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5800181942712004		[learning rate: 0.0083807]
	Learning Rate: 0.00838073
	LOSS [training: 2.5800181942712004 | validation: 3.2613840467208095]
	TIME [epoch: 9.49 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.965835415827997		[learning rate: 0.008361]
	Learning Rate: 0.00836096
	LOSS [training: 2.965835415827997 | validation: 4.61553208703194]
	TIME [epoch: 9.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.858436636986854		[learning rate: 0.0083412]
	Learning Rate: 0.00834124
	LOSS [training: 2.858436636986854 | validation: 2.687889630557073]
	TIME [epoch: 9.52 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3482668369672672		[learning rate: 0.0083216]
	Learning Rate: 0.00832157
	LOSS [training: 2.3482668369672672 | validation: 3.4264615911875875]
	TIME [epoch: 9.51 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6585747771414763		[learning rate: 0.0083019]
	Learning Rate: 0.00830194
	LOSS [training: 2.6585747771414763 | validation: 2.034636854559464]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.693376461212118		[learning rate: 0.0082824]
	Learning Rate: 0.00828236
	LOSS [training: 2.693376461212118 | validation: 2.527739977091587]
	TIME [epoch: 9.53 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.077211707971192		[learning rate: 0.0082628]
	Learning Rate: 0.00826282
	LOSS [training: 3.077211707971192 | validation: 2.9497901728138562]
	TIME [epoch: 9.55 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0706244978166484		[learning rate: 0.0082433]
	Learning Rate: 0.00824333
	LOSS [training: 3.0706244978166484 | validation: 2.7571404808184776]
	TIME [epoch: 9.52 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8673609473244333		[learning rate: 0.0082239]
	Learning Rate: 0.00822388
	LOSS [training: 2.8673609473244333 | validation: 7.324933577017169]
	TIME [epoch: 9.53 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.867227387896678		[learning rate: 0.0082045]
	Learning Rate: 0.00820448
	LOSS [training: 4.867227387896678 | validation: 2.6893378102060157]
	TIME [epoch: 9.54 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8434728687182926		[learning rate: 0.0081851]
	Learning Rate: 0.00818513
	LOSS [training: 2.8434728687182926 | validation: 2.040111553583232]
	TIME [epoch: 9.53 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1061341156391573		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 2.1061341156391573 | validation: 2.0748334016146472]
	TIME [epoch: 9.53 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4442713049025278		[learning rate: 0.0081466]
	Learning Rate: 0.00814656
	LOSS [training: 2.4442713049025278 | validation: 1.9254803058795364]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.300208834427558		[learning rate: 0.0081273]
	Learning Rate: 0.00812735
	LOSS [training: 2.300208834427558 | validation: 1.9265576114398912]
	TIME [epoch: 9.54 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9426774984616777		[learning rate: 0.0081082]
	Learning Rate: 0.00810817
	LOSS [training: 1.9426774984616777 | validation: 1.7678664958469006]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.119793553456488		[learning rate: 0.008089]
	Learning Rate: 0.00808905
	LOSS [training: 2.119793553456488 | validation: 1.828341531040884]
	TIME [epoch: 9.52 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9187722741098039		[learning rate: 0.00807]
	Learning Rate: 0.00806997
	LOSS [training: 1.9187722741098039 | validation: 2.1934329094793843]
	TIME [epoch: 9.55 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1797851886222546		[learning rate: 0.0080509]
	Learning Rate: 0.00805093
	LOSS [training: 2.1797851886222546 | validation: 2.8922889730925]
	TIME [epoch: 9.53 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0216522848609535		[learning rate: 0.0080319]
	Learning Rate: 0.00803194
	LOSS [training: 2.0216522848609535 | validation: 3.28878082706261]
	TIME [epoch: 9.52 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8459276315514677		[learning rate: 0.008013]
	Learning Rate: 0.00801299
	LOSS [training: 3.8459276315514677 | validation: 2.184599457504774]
	TIME [epoch: 9.53 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9177447740981433		[learning rate: 0.0079941]
	Learning Rate: 0.00799409
	LOSS [training: 1.9177447740981433 | validation: 1.6542587317064537]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7786176934149034		[learning rate: 0.0079752]
	Learning Rate: 0.00797524
	LOSS [training: 1.7786176934149034 | validation: 2.0401722801711037]
	TIME [epoch: 9.52 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.73287247453227		[learning rate: 0.0079564]
	Learning Rate: 0.00795642
	LOSS [training: 1.73287247453227 | validation: 1.603075719523688]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.506495245030513		[learning rate: 0.0079377]
	Learning Rate: 0.00793766
	LOSS [training: 2.506495245030513 | validation: 2.7109768200410747]
	TIME [epoch: 9.54 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7321833053675144		[learning rate: 0.0079189]
	Learning Rate: 0.00791893
	LOSS [training: 3.7321833053675144 | validation: 2.8498015262722958]
	TIME [epoch: 9.52 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5483996779468177		[learning rate: 0.0079003]
	Learning Rate: 0.00790025
	LOSS [training: 3.5483996779468177 | validation: 1.945291617788983]
	TIME [epoch: 9.51 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7961842788677864		[learning rate: 0.0078816]
	Learning Rate: 0.00788162
	LOSS [training: 1.7961842788677864 | validation: 1.5586137598975731]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.008799505924382		[learning rate: 0.007863]
	Learning Rate: 0.00786303
	LOSS [training: 2.008799505924382 | validation: 2.391168656459023]
	TIME [epoch: 9.52 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9578163810596863		[learning rate: 0.0078445]
	Learning Rate: 0.00784448
	LOSS [training: 1.9578163810596863 | validation: 1.8019671675667621]
	TIME [epoch: 9.51 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0037886750325296		[learning rate: 0.007826]
	Learning Rate: 0.00782597
	LOSS [training: 2.0037886750325296 | validation: 1.592613384854797]
	TIME [epoch: 9.51 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.749249276222875		[learning rate: 0.0078075]
	Learning Rate: 0.00780751
	LOSS [training: 1.749249276222875 | validation: 3.8179725609280424]
	TIME [epoch: 9.54 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.900619479383709		[learning rate: 0.0077891]
	Learning Rate: 0.0077891
	LOSS [training: 2.900619479383709 | validation: 1.4126298427187112]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7518187367766465		[learning rate: 0.0077707]
	Learning Rate: 0.00777072
	LOSS [training: 1.7518187367766465 | validation: 2.011702656755339]
	TIME [epoch: 9.51 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.725130383826859		[learning rate: 0.0077524]
	Learning Rate: 0.00775239
	LOSS [training: 1.725130383826859 | validation: 1.7202519443498931]
	TIME [epoch: 9.52 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.049266251274463		[learning rate: 0.0077341]
	Learning Rate: 0.00773411
	LOSS [training: 2.049266251274463 | validation: 1.7967880529774842]
	TIME [epoch: 9.51 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1361971546922716		[learning rate: 0.0077159]
	Learning Rate: 0.00771586
	LOSS [training: 2.1361971546922716 | validation: 2.8617361689028047]
	TIME [epoch: 9.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.16574740636291		[learning rate: 0.0076977]
	Learning Rate: 0.00769766
	LOSS [training: 3.16574740636291 | validation: 1.9383469928952781]
	TIME [epoch: 9.51 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.740629736737387		[learning rate: 0.0076795]
	Learning Rate: 0.00767951
	LOSS [training: 1.740629736737387 | validation: 2.267408478680537]
	TIME [epoch: 9.53 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7108115051823738		[learning rate: 0.0076614]
	Learning Rate: 0.00766139
	LOSS [training: 1.7108115051823738 | validation: 1.8795292046678647]
	TIME [epoch: 9.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6678685845640893		[learning rate: 0.0076433]
	Learning Rate: 0.00764332
	LOSS [training: 1.6678685845640893 | validation: 1.7803972961806114]
	TIME [epoch: 9.51 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8134311107632155		[learning rate: 0.0076253]
	Learning Rate: 0.00762529
	LOSS [training: 1.8134311107632155 | validation: 1.9147185415605816]
	TIME [epoch: 9.52 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6375180271327647		[learning rate: 0.0076073]
	Learning Rate: 0.0076073
	LOSS [training: 1.6375180271327647 | validation: 1.5866934942157407]
	TIME [epoch: 9.51 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.703933769286061		[learning rate: 0.0075894]
	Learning Rate: 0.00758936
	LOSS [training: 1.703933769286061 | validation: 1.3677025416348574]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6638897285780991		[learning rate: 0.0075715]
	Learning Rate: 0.00757146
	LOSS [training: 1.6638897285780991 | validation: 1.3778515913426923]
	TIME [epoch: 9.53 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.443746160345168		[learning rate: 0.0075536]
	Learning Rate: 0.0075536
	LOSS [training: 1.443746160345168 | validation: 1.5583222361318056]
	TIME [epoch: 9.52 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6331696459692182		[learning rate: 0.0075358]
	Learning Rate: 0.00753578
	LOSS [training: 1.6331696459692182 | validation: 2.0686364145184273]
	TIME [epoch: 9.51 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7264672170675923		[learning rate: 0.007518]
	Learning Rate: 0.007518
	LOSS [training: 2.7264672170675923 | validation: 1.9215121926621788]
	TIME [epoch: 9.52 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9003313985011698		[learning rate: 0.0075003]
	Learning Rate: 0.00750027
	LOSS [training: 1.9003313985011698 | validation: 1.7513885190478147]
	TIME [epoch: 9.54 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.709668461455594		[learning rate: 0.0074826]
	Learning Rate: 0.00748258
	LOSS [training: 1.709668461455594 | validation: 1.7773988637327787]
	TIME [epoch: 9.52 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5216636868619469		[learning rate: 0.0074649]
	Learning Rate: 0.00746493
	LOSS [training: 1.5216636868619469 | validation: 1.7237897688931838]
	TIME [epoch: 9.51 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5543598666556777		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 1.5543598666556777 | validation: 1.7006883332299003]
	TIME [epoch: 9.52 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.463388569105254		[learning rate: 0.0074298]
	Learning Rate: 0.00742975
	LOSS [training: 1.463388569105254 | validation: 1.4343087894177353]
	TIME [epoch: 9.52 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.595517024811404		[learning rate: 0.0074122]
	Learning Rate: 0.00741223
	LOSS [training: 1.595517024811404 | validation: 1.443457999594466]
	TIME [epoch: 9.51 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6722233535238236		[learning rate: 0.0073947]
	Learning Rate: 0.00739474
	LOSS [training: 1.6722233535238236 | validation: 2.0591108812373156]
	TIME [epoch: 9.51 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6134848418425691		[learning rate: 0.0073773]
	Learning Rate: 0.0073773
	LOSS [training: 1.6134848418425691 | validation: 1.9652501476684807]
	TIME [epoch: 9.53 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.603779758326197		[learning rate: 0.0073599]
	Learning Rate: 0.0073599
	LOSS [training: 1.603779758326197 | validation: 1.4203536371376777]
	TIME [epoch: 9.51 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.447452612739638		[learning rate: 0.0073425]
	Learning Rate: 0.00734254
	LOSS [training: 1.447452612739638 | validation: 1.2468230099549238]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5346991573087716		[learning rate: 0.0073252]
	Learning Rate: 0.00732522
	LOSS [training: 1.5346991573087716 | validation: 1.5469794390034388]
	TIME [epoch: 9.51 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2543478931115875		[learning rate: 0.0073079]
	Learning Rate: 0.00730794
	LOSS [training: 2.2543478931115875 | validation: 1.8639809765136732]
	TIME [epoch: 9.51 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8099044111256208		[learning rate: 0.0072907]
	Learning Rate: 0.0072907
	LOSS [training: 1.8099044111256208 | validation: 1.6071058745411415]
	TIME [epoch: 9.49 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4244637079056894		[learning rate: 0.0072735]
	Learning Rate: 0.0072735
	LOSS [training: 1.4244637079056894 | validation: 1.8762046121167846]
	TIME [epoch: 9.49 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5673462393663005		[learning rate: 0.0072563]
	Learning Rate: 0.00725635
	LOSS [training: 1.5673462393663005 | validation: 3.5345441944967932]
	TIME [epoch: 9.51 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9114000965173326		[learning rate: 0.0072392]
	Learning Rate: 0.00723923
	LOSS [training: 1.9114000965173326 | validation: 1.5903279566433537]
	TIME [epoch: 9.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4169703119507955		[learning rate: 0.0072222]
	Learning Rate: 0.00722215
	LOSS [training: 1.4169703119507955 | validation: 1.4552408645485446]
	TIME [epoch: 9.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.428381317682106		[learning rate: 0.0072051]
	Learning Rate: 0.00720512
	LOSS [training: 1.428381317682106 | validation: 1.5105211223218868]
	TIME [epoch: 9.51 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.493563269517072		[learning rate: 0.0071881]
	Learning Rate: 0.00718812
	LOSS [training: 1.493563269517072 | validation: 1.4076881227599563]
	TIME [epoch: 9.51 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.451054679798662		[learning rate: 0.0071712]
	Learning Rate: 0.00717117
	LOSS [training: 1.451054679798662 | validation: 1.6178727263321764]
	TIME [epoch: 9.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4835167155546514		[learning rate: 0.0071542]
	Learning Rate: 0.00715425
	LOSS [training: 1.4835167155546514 | validation: 1.390060541068169]
	TIME [epoch: 9.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6109091520666727		[learning rate: 0.0071374]
	Learning Rate: 0.00713737
	LOSS [training: 1.6109091520666727 | validation: 1.9099604186657713]
	TIME [epoch: 9.52 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1068363607270735		[learning rate: 0.0071205]
	Learning Rate: 0.00712054
	LOSS [training: 2.1068363607270735 | validation: 1.464566331817166]
	TIME [epoch: 9.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3913944495673969		[learning rate: 0.0071037]
	Learning Rate: 0.00710374
	LOSS [training: 1.3913944495673969 | validation: 3.2879506335176547]
	TIME [epoch: 9.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.36338751525799		[learning rate: 0.007087]
	Learning Rate: 0.00708698
	LOSS [training: 2.36338751525799 | validation: 1.9701490841915072]
	TIME [epoch: 9.51 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6380860386452454		[learning rate: 0.0070703]
	Learning Rate: 0.00707027
	LOSS [training: 1.6380860386452454 | validation: 1.0603040376517994]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3855253442490791		[learning rate: 0.0070536]
	Learning Rate: 0.00705359
	LOSS [training: 1.3855253442490791 | validation: 1.193666108646116]
	TIME [epoch: 9.51 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4851137822103961		[learning rate: 0.007037]
	Learning Rate: 0.00703695
	LOSS [training: 1.4851137822103961 | validation: 1.1240621523156231]
	TIME [epoch: 9.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4454695525515224		[learning rate: 0.0070204]
	Learning Rate: 0.00702035
	LOSS [training: 1.4454695525515224 | validation: 1.5335897184854674]
	TIME [epoch: 9.52 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4941722650111446		[learning rate: 0.0070038]
	Learning Rate: 0.00700379
	LOSS [training: 1.4941722650111446 | validation: 1.2512093341581763]
	TIME [epoch: 9.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.463214466043961		[learning rate: 0.0069873]
	Learning Rate: 0.00698727
	LOSS [training: 1.463214466043961 | validation: 1.8299591715140375]
	TIME [epoch: 9.48 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2285627007024353		[learning rate: 0.0069708]
	Learning Rate: 0.00697079
	LOSS [training: 2.2285627007024353 | validation: 1.6928924604904267]
	TIME [epoch: 9.51 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5705762249488406		[learning rate: 0.0069543]
	Learning Rate: 0.00695435
	LOSS [training: 1.5705762249488406 | validation: 1.1087884939060744]
	TIME [epoch: 9.49 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2936346032133916		[learning rate: 0.0069379]
	Learning Rate: 0.00693794
	LOSS [training: 1.2936346032133916 | validation: 1.048042738948424]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2374972145710033		[learning rate: 0.0069216]
	Learning Rate: 0.00692158
	LOSS [training: 1.2374972145710033 | validation: 1.149132763875879]
	TIME [epoch: 9.53 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4553346668514564		[learning rate: 0.0069053]
	Learning Rate: 0.00690525
	LOSS [training: 1.4553346668514564 | validation: 1.309882405300318]
	TIME [epoch: 9.54 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4697749715937134		[learning rate: 0.006889]
	Learning Rate: 0.00688896
	LOSS [training: 1.4697749715937134 | validation: 1.2846083576276197]
	TIME [epoch: 9.53 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.288694173431508		[learning rate: 0.0068727]
	Learning Rate: 0.00687271
	LOSS [training: 1.288694173431508 | validation: 1.3606275228293203]
	TIME [epoch: 9.52 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2915542359281287		[learning rate: 0.0068565]
	Learning Rate: 0.0068565
	LOSS [training: 1.2915542359281287 | validation: 1.9170960224585105]
	TIME [epoch: 9.54 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6371475435812883		[learning rate: 0.0068403]
	Learning Rate: 0.00684033
	LOSS [training: 1.6371475435812883 | validation: 1.727162517859793]
	TIME [epoch: 9.53 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4040454709392989		[learning rate: 0.0068242]
	Learning Rate: 0.00682419
	LOSS [training: 1.4040454709392989 | validation: 1.2867284172395983]
	TIME [epoch: 9.51 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.213058539223002		[learning rate: 0.0068081]
	Learning Rate: 0.0068081
	LOSS [training: 1.213058539223002 | validation: 1.0876817066878193]
	TIME [epoch: 9.52 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6882052430428076		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 1.6882052430428076 | validation: 2.2017670911460248]
	TIME [epoch: 9.54 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5355784633734875		[learning rate: 0.006776]
	Learning Rate: 0.00677601
	LOSS [training: 1.5355784633734875 | validation: 1.3885946784569347]
	TIME [epoch: 9.52 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6236713784317303		[learning rate: 0.00676]
	Learning Rate: 0.00676003
	LOSS [training: 1.6236713784317303 | validation: 1.592821062792786]
	TIME [epoch: 9.52 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4027833190507426		[learning rate: 0.0067441]
	Learning Rate: 0.00674409
	LOSS [training: 1.4027833190507426 | validation: 1.6240551989620071]
	TIME [epoch: 9.55 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4849401970472802		[learning rate: 0.0067282]
	Learning Rate: 0.00672818
	LOSS [training: 1.4849401970472802 | validation: 2.049403117354177]
	TIME [epoch: 9.53 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1198748676786012		[learning rate: 0.0067123]
	Learning Rate: 0.00671231
	LOSS [training: 2.1198748676786012 | validation: 2.9692831301009743]
	TIME [epoch: 9.52 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6716612085194538		[learning rate: 0.0066965]
	Learning Rate: 0.00669647
	LOSS [training: 1.6716612085194538 | validation: 1.533876279309181]
	TIME [epoch: 9.52 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3738958184864356		[learning rate: 0.0066807]
	Learning Rate: 0.00668068
	LOSS [training: 1.3738958184864356 | validation: 1.620431241317379]
	TIME [epoch: 9.54 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3593884835720502		[learning rate: 0.0066649]
	Learning Rate: 0.00666492
	LOSS [training: 1.3593884835720502 | validation: 1.2435585816946568]
	TIME [epoch: 9.51 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1883499276945289		[learning rate: 0.0066492]
	Learning Rate: 0.0066492
	LOSS [training: 1.1883499276945289 | validation: 1.0934931337845664]
	TIME [epoch: 9.51 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.267007337798987		[learning rate: 0.0066335]
	Learning Rate: 0.00663351
	LOSS [training: 1.267007337798987 | validation: 1.4310321261403118]
	TIME [epoch: 9.53 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1778968808192967		[learning rate: 0.0066179]
	Learning Rate: 0.00661787
	LOSS [training: 1.1778968808192967 | validation: 1.1209625722491368]
	TIME [epoch: 9.52 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1591836405312406		[learning rate: 0.0066023]
	Learning Rate: 0.00660226
	LOSS [training: 1.1591836405312406 | validation: 1.4428541318320802]
	TIME [epoch: 9.52 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.188562908006372		[learning rate: 0.0065867]
	Learning Rate: 0.00658668
	LOSS [training: 1.188562908006372 | validation: 1.1207972859543955]
	TIME [epoch: 9.52 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3480922125897266		[learning rate: 0.0065711]
	Learning Rate: 0.00657114
	LOSS [training: 1.3480922125897266 | validation: 1.199637205291025]
	TIME [epoch: 9.54 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6059414387279864		[learning rate: 0.0065556]
	Learning Rate: 0.00655564
	LOSS [training: 1.6059414387279864 | validation: 1.1065868690431366]
	TIME [epoch: 9.52 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1095145978761571		[learning rate: 0.0065402]
	Learning Rate: 0.00654018
	LOSS [training: 1.1095145978761571 | validation: 1.0722199007605677]
	TIME [epoch: 9.52 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4320108355329473		[learning rate: 0.0065248]
	Learning Rate: 0.00652475
	LOSS [training: 1.4320108355329473 | validation: 1.0077859016289683]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3892329021205716		[learning rate: 0.0065094]
	Learning Rate: 0.00650936
	LOSS [training: 1.3892329021205716 | validation: 0.9388352653101103]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2574778815530245		[learning rate: 0.006494]
	Learning Rate: 0.00649401
	LOSS [training: 1.2574778815530245 | validation: 1.2171172592187478]
	TIME [epoch: 9.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.282537734429662		[learning rate: 0.0064787]
	Learning Rate: 0.00647869
	LOSS [training: 1.282537734429662 | validation: 1.3954424821482447]
	TIME [epoch: 9.51 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1489830777670675		[learning rate: 0.0064634]
	Learning Rate: 0.00646341
	LOSS [training: 1.1489830777670675 | validation: 1.0281258388790986]
	TIME [epoch: 9.52 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1806534576391396		[learning rate: 0.0064482]
	Learning Rate: 0.00644816
	LOSS [training: 1.1806534576391396 | validation: 1.0719458501979897]
	TIME [epoch: 9.51 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4316670432839138		[learning rate: 0.006433]
	Learning Rate: 0.00643295
	LOSS [training: 1.4316670432839138 | validation: 1.0168415926174859]
	TIME [epoch: 9.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.059673443201409		[learning rate: 0.0064178]
	Learning Rate: 0.00641778
	LOSS [training: 1.059673443201409 | validation: 1.1594402154789512]
	TIME [epoch: 9.53 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2797148361985982		[learning rate: 0.0064026]
	Learning Rate: 0.00640264
	LOSS [training: 1.2797148361985982 | validation: 1.0775721537466794]
	TIME [epoch: 9.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1479612010634752		[learning rate: 0.0063875]
	Learning Rate: 0.00638754
	LOSS [training: 1.1479612010634752 | validation: 1.1638592931441492]
	TIME [epoch: 9.51 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2250058519635165		[learning rate: 0.0063725]
	Learning Rate: 0.00637247
	LOSS [training: 1.2250058519635165 | validation: 1.884282955205756]
	TIME [epoch: 9.51 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2990734782677762		[learning rate: 0.0063574]
	Learning Rate: 0.00635744
	LOSS [training: 1.2990734782677762 | validation: 1.1257495677303846]
	TIME [epoch: 9.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2476488023235355		[learning rate: 0.0063424]
	Learning Rate: 0.00634244
	LOSS [training: 1.2476488023235355 | validation: 1.5410066950715282]
	TIME [epoch: 9.49 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.19413076718135		[learning rate: 0.0063275]
	Learning Rate: 0.00632748
	LOSS [training: 1.19413076718135 | validation: 1.2645998182582388]
	TIME [epoch: 9.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2335276681102456		[learning rate: 0.0063126]
	Learning Rate: 0.00631255
	LOSS [training: 1.2335276681102456 | validation: 1.3601645940721585]
	TIME [epoch: 9.52 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1226407740232587		[learning rate: 0.0062977]
	Learning Rate: 0.00629766
	LOSS [training: 1.1226407740232587 | validation: 1.1967023568829274]
	TIME [epoch: 9.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3161266810767498		[learning rate: 0.0062828]
	Learning Rate: 0.00628281
	LOSS [training: 1.3161266810767498 | validation: 1.134248511446607]
	TIME [epoch: 9.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3591640078605238		[learning rate: 0.006268]
	Learning Rate: 0.00626799
	LOSS [training: 1.3591640078605238 | validation: 1.3993472649272283]
	TIME [epoch: 9.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4858935261906834		[learning rate: 0.0062532]
	Learning Rate: 0.0062532
	LOSS [training: 1.4858935261906834 | validation: 1.1364033872940034]
	TIME [epoch: 9.51 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1666759555056232		[learning rate: 0.0062385]
	Learning Rate: 0.00623845
	LOSS [training: 1.1666759555056232 | validation: 1.4493328154984584]
	TIME [epoch: 9.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7236958777507208		[learning rate: 0.0062237]
	Learning Rate: 0.00622374
	LOSS [training: 1.7236958777507208 | validation: 1.4754219684206271]
	TIME [epoch: 9.49 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4243508965125244		[learning rate: 0.0062091]
	Learning Rate: 0.00620906
	LOSS [training: 1.4243508965125244 | validation: 2.0770674072495483]
	TIME [epoch: 9.52 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2147256900985561		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 1.2147256900985561 | validation: 1.9265461613148318]
	TIME [epoch: 9.49 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3021245282448888		[learning rate: 0.0061798]
	Learning Rate: 0.0061798
	LOSS [training: 1.3021245282448888 | validation: 1.2812188173177521]
	TIME [epoch: 9.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3344339716039528		[learning rate: 0.0061652]
	Learning Rate: 0.00616522
	LOSS [training: 1.3344339716039528 | validation: 0.9692362025854133]
	TIME [epoch: 9.52 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1143961653436716		[learning rate: 0.0061507]
	Learning Rate: 0.00615068
	LOSS [training: 1.1143961653436716 | validation: 1.1171597291121251]
	TIME [epoch: 9.51 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1072066943662484		[learning rate: 0.0061362]
	Learning Rate: 0.00613617
	LOSS [training: 1.1072066943662484 | validation: 1.050406796932228]
	TIME [epoch: 9.49 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2473048098653667		[learning rate: 0.0061217]
	Learning Rate: 0.0061217
	LOSS [training: 1.2473048098653667 | validation: 0.9994554194452365]
	TIME [epoch: 9.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0162320440023915		[learning rate: 0.0061073]
	Learning Rate: 0.00610726
	LOSS [training: 1.0162320440023915 | validation: 1.0957041993909382]
	TIME [epoch: 9.51 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0943922247440685		[learning rate: 0.0060929]
	Learning Rate: 0.00609285
	LOSS [training: 1.0943922247440685 | validation: 1.2097936748344225]
	TIME [epoch: 9.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2495376228779242		[learning rate: 0.0060785]
	Learning Rate: 0.00607848
	LOSS [training: 1.2495376228779242 | validation: 1.0535665726881112]
	TIME [epoch: 9.49 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1791644215126584		[learning rate: 0.0060641]
	Learning Rate: 0.00606414
	LOSS [training: 1.1791644215126584 | validation: 1.343936026857172]
	TIME [epoch: 9.51 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.151896859185336		[learning rate: 0.0060498]
	Learning Rate: 0.00604984
	LOSS [training: 1.151896859185336 | validation: 1.1131249414859592]
	TIME [epoch: 9.51 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1527887280583513		[learning rate: 0.0060356]
	Learning Rate: 0.00603556
	LOSS [training: 1.1527887280583513 | validation: 1.0006390831760692]
	TIME [epoch: 9.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1765015575509394		[learning rate: 0.0060213]
	Learning Rate: 0.00602133
	LOSS [training: 1.1765015575509394 | validation: 1.3701407439002993]
	TIME [epoch: 9.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2578818405548327		[learning rate: 0.0060071]
	Learning Rate: 0.00600712
	LOSS [training: 1.2578818405548327 | validation: 1.6822768032134479]
	TIME [epoch: 9.52 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7095334645082354		[learning rate: 0.005993]
	Learning Rate: 0.00599296
	LOSS [training: 2.7095334645082354 | validation: 1.810960411613023]
	TIME [epoch: 9.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3934944592093568		[learning rate: 0.0059788]
	Learning Rate: 0.00597882
	LOSS [training: 1.3934944592093568 | validation: 1.077041786235878]
	TIME [epoch: 9.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1442108226991587		[learning rate: 0.0059647]
	Learning Rate: 0.00596472
	LOSS [training: 1.1442108226991587 | validation: 1.5755433035477433]
	TIME [epoch: 9.51 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0991242123141904		[learning rate: 0.0059506]
	Learning Rate: 0.00595065
	LOSS [training: 1.0991242123141904 | validation: 1.3729311136389493]
	TIME [epoch: 9.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.73306321832055		[learning rate: 0.0059366]
	Learning Rate: 0.00593661
	LOSS [training: 1.73306321832055 | validation: 1.3509405417904348]
	TIME [epoch: 9.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1278858987926133		[learning rate: 0.0059226]
	Learning Rate: 0.00592261
	LOSS [training: 1.1278858987926133 | validation: 1.0008597747527668]
	TIME [epoch: 9.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0513973170572595		[learning rate: 0.0059086]
	Learning Rate: 0.00590863
	LOSS [training: 1.0513973170572595 | validation: 1.1806797256737782]
	TIME [epoch: 9.52 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2226541908182302		[learning rate: 0.0058947]
	Learning Rate: 0.0058947
	LOSS [training: 1.2226541908182302 | validation: 2.7975165644570166]
	TIME [epoch: 9.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.835668132056797		[learning rate: 0.0058808]
	Learning Rate: 0.00588079
	LOSS [training: 1.835668132056797 | validation: 0.9621785683101018]
	TIME [epoch: 9.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.925427244269013		[learning rate: 0.0058669]
	Learning Rate: 0.00586692
	LOSS [training: 0.925427244269013 | validation: 0.922809698045661]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_276.pth
	Model improved!!!
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0299276736609997		[learning rate: 0.0058531]
	Learning Rate: 0.00585308
	LOSS [training: 1.0299276736609997 | validation: 1.5171374198617358]
	TIME [epoch: 9.53 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2063654447162078		[learning rate: 0.0058393]
	Learning Rate: 0.00583928
	LOSS [training: 1.2063654447162078 | validation: 0.8925002407511917]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_278.pth
	Model improved!!!
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5400780326256671		[learning rate: 0.0058255]
	Learning Rate: 0.0058255
	LOSS [training: 1.5400780326256671 | validation: 1.1909615753309586]
	TIME [epoch: 9.53 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0627374537834253		[learning rate: 0.0058118]
	Learning Rate: 0.00581176
	LOSS [training: 1.0627374537834253 | validation: 1.0321627771687227]
	TIME [epoch: 9.53 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0073057253083297		[learning rate: 0.0057981]
	Learning Rate: 0.00579805
	LOSS [training: 1.0073057253083297 | validation: 1.0507387889677853]
	TIME [epoch: 9.52 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2119341823573386		[learning rate: 0.0057844]
	Learning Rate: 0.00578438
	LOSS [training: 1.2119341823573386 | validation: 1.089713653916934]
	TIME [epoch: 9.52 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.026507825153264		[learning rate: 0.0057707]
	Learning Rate: 0.00577073
	LOSS [training: 1.026507825153264 | validation: 1.0761207630664582]
	TIME [epoch: 9.54 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0031051673490596		[learning rate: 0.0057571]
	Learning Rate: 0.00575712
	LOSS [training: 1.0031051673490596 | validation: 1.1300198618416084]
	TIME [epoch: 9.52 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.07481962295295		[learning rate: 0.0057435]
	Learning Rate: 0.00574354
	LOSS [training: 1.07481962295295 | validation: 1.2053862723455564]
	TIME [epoch: 9.52 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2860103832396184		[learning rate: 0.00573]
	Learning Rate: 0.00572999
	LOSS [training: 1.2860103832396184 | validation: 0.9639255662911635]
	TIME [epoch: 9.52 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0513868024609605		[learning rate: 0.0057165]
	Learning Rate: 0.00571647
	LOSS [training: 1.0513868024609605 | validation: 1.0368036821786608]
	TIME [epoch: 9.53 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1810822278975135		[learning rate: 0.005703]
	Learning Rate: 0.00570299
	LOSS [training: 1.1810822278975135 | validation: 2.6045365023438127]
	TIME [epoch: 9.51 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8887147962543018		[learning rate: 0.0056895]
	Learning Rate: 0.00568954
	LOSS [training: 1.8887147962543018 | validation: 0.8761154204951254]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2380689858429679		[learning rate: 0.0056761]
	Learning Rate: 0.00567612
	LOSS [training: 1.2380689858429679 | validation: 0.9889166420911977]
	TIME [epoch: 9.53 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1949740936755802		[learning rate: 0.0056627]
	Learning Rate: 0.00566273
	LOSS [training: 1.1949740936755802 | validation: 0.7944310660136545]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r3_20240219_184940/states/model_tr_study5_291.pth
	Model improved!!!
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2179870215019613		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 1.2179870215019613 | validation: 1.3540461305036389]
	TIME [epoch: 9.51 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1233239635394758		[learning rate: 0.005636]
	Learning Rate: 0.00563604
	LOSS [training: 1.1233239635394758 | validation: 0.8485207178613194]
	TIME [epoch: 9.53 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9344102784907203		[learning rate: 0.0056227]
	Learning Rate: 0.00562275
	LOSS [training: 0.9344102784907203 | validation: 1.3143928623668677]
	TIME [epoch: 9.53 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0574458478148534		[learning rate: 0.0056095]
	Learning Rate: 0.00560949
	LOSS [training: 1.0574458478148534 | validation: 0.8502935859207582]
	TIME [epoch: 9.51 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1146726267391476		[learning rate: 0.0055963]
	Learning Rate: 0.00559625
	LOSS [training: 1.1146726267391476 | validation: 2.467377945459358]
	TIME [epoch: 9.51 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5399995453157573		[learning rate: 0.0055831]
	Learning Rate: 0.00558305
	LOSS [training: 1.5399995453157573 | validation: 0.831247211764655]
	TIME [epoch: 9.53 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8626462807400405		[learning rate: 0.0055699]
	Learning Rate: 0.00556988
	LOSS [training: 0.8626462807400405 | validation: 0.9511154985090562]
	TIME [epoch: 9.51 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9029692605660549		[learning rate: 0.0055567]
	Learning Rate: 0.00555674
	LOSS [training: 0.9029692605660549 | validation: 0.8124990903675144]
	TIME [epoch: 9.51 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1884412844846157		[learning rate: 0.0055436]
	Learning Rate: 0.00554364
	LOSS [training: 1.1884412844846157 | validation: 1.3545799464967165]
	TIME [epoch: 9.53 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1396949977352502		[learning rate: 0.0055306]
	Learning Rate: 0.00553056
	LOSS [training: 1.1396949977352502 | validation: 1.0498922335714165]
	TIME [epoch: 9.52 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.054635701397434		[learning rate: 0.0055175]
	Learning Rate: 0.00551752
	LOSS [training: 1.054635701397434 | validation: 1.0991936255416415]
	TIME [epoch: 9.51 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0533144720189334		[learning rate: 0.0055045]
	Learning Rate: 0.0055045
	LOSS [training: 1.0533144720189334 | validation: 1.6771435697984243]
	TIME [epoch: 9.51 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1975636677361305		[learning rate: 0.0054915]
	Learning Rate: 0.00549152
	LOSS [training: 1.1975636677361305 | validation: 1.020407620844314]
	TIME [epoch: 9.53 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0215981418643918		[learning rate: 0.0054786]
	Learning Rate: 0.00547856
	LOSS [training: 1.0215981418643918 | validation: 0.9433639813570857]
	TIME [epoch: 9.51 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9604468789651783		[learning rate: 0.0054656]
	Learning Rate: 0.00546564
	LOSS [training: 0.9604468789651783 | validation: 1.2730225706551273]
	TIME [epoch: 9.51 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4031111628915092		[learning rate: 0.0054527]
	Learning Rate: 0.00545275
	LOSS [training: 1.4031111628915092 | validation: 1.9587827141674437]
	TIME [epoch: 9.52 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1573119016086253		[learning rate: 0.0054399]
	Learning Rate: 0.00543988
	LOSS [training: 1.1573119016086253 | validation: 1.0511990059352991]
	TIME [epoch: 9.52 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0978306985278359		[learning rate: 0.0054271]
	Learning Rate: 0.00542705
	LOSS [training: 1.0978306985278359 | validation: 0.8990102106597283]
	TIME [epoch: 9.51 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9114466747310586		[learning rate: 0.0054143]
	Learning Rate: 0.00541425
	LOSS [training: 0.9114466747310586 | validation: 1.8457843489279508]
	TIME [epoch: 9.51 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.166947952474186		[learning rate: 0.0054015]
	Learning Rate: 0.00540148
	LOSS [training: 1.166947952474186 | validation: 0.8663455919013677]
	TIME [epoch: 9.53 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.012380682932121		[learning rate: 0.0053887]
	Learning Rate: 0.00538874
	LOSS [training: 1.012380682932121 | validation: 1.6021557382281129]
	TIME [epoch: 9.51 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1637158458898251		[learning rate: 0.005376]
	Learning Rate: 0.00537603
	LOSS [training: 1.1637158458898251 | validation: 1.1900902313647905]
	TIME [epoch: 9.51 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0119633308749014		[learning rate: 0.0053633]
	Learning Rate: 0.00536335
	LOSS [training: 1.0119633308749014 | validation: 0.9203052612512879]
	TIME [epoch: 9.52 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9752491108828061		[learning rate: 0.0053507]
	Learning Rate: 0.00535069
	LOSS [training: 0.9752491108828061 | validation: 0.9943304157384785]
	TIME [epoch: 9.51 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9567215170047829		[learning rate: 0.0053381]
	Learning Rate: 0.00533807
	LOSS [training: 0.9567215170047829 | validation: 0.9184202545869417]
	TIME [epoch: 9.51 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9994388200797406		[learning rate: 0.0053255]
	Learning Rate: 0.00532548
	LOSS [training: 0.9994388200797406 | validation: 0.9926462985256481]
	TIME [epoch: 9.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1395508444211642		[learning rate: 0.0053129]
	Learning Rate: 0.00531292
	LOSS [training: 1.1395508444211642 | validation: 1.1777433002893873]
	TIME [epoch: 9.52 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9818137839402239		[learning rate: 0.0053004]
	Learning Rate: 0.00530039
	LOSS [training: 0.9818137839402239 | validation: 1.4378007390538188]
	TIME [epoch: 9.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1421357087732147		[learning rate: 0.0052879]
	Learning Rate: 0.00528789
	LOSS [training: 1.1421357087732147 | validation: 0.964099972842508]
	TIME [epoch: 9.51 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9524314207856467		[learning rate: 0.0052754]
	Learning Rate: 0.00527541
	LOSS [training: 0.9524314207856467 | validation: 0.9807311173901682]
	TIME [epoch: 9.52 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0077953981370367		[learning rate: 0.005263]
	Learning Rate: 0.00526297
	LOSS [training: 1.0077953981370367 | validation: 1.4461717010303934]
	TIME [epoch: 9.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0812149455568556		[learning rate: 0.0052506]
	Learning Rate: 0.00525055
	LOSS [training: 1.0812149455568556 | validation: 1.0882308466115822]
	TIME [epoch: 9.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9773548225354596		[learning rate: 0.0052382]
	Learning Rate: 0.00523817
	LOSS [training: 0.9773548225354596 | validation: 1.2629162979413564]
	TIME [epoch: 9.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3323347282401947		[learning rate: 0.0052258]
	Learning Rate: 0.00522581
	LOSS [training: 1.3323347282401947 | validation: 2.6264099732764836]
	TIME [epoch: 9.52 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5207977674230762		[learning rate: 0.0052135]
	Learning Rate: 0.00521349
	LOSS [training: 1.5207977674230762 | validation: 0.9602140883954703]
	TIME [epoch: 9.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.129567441868963		[learning rate: 0.0052012]
	Learning Rate: 0.00520119
	LOSS [training: 1.129567441868963 | validation: 1.0874696051956207]
	TIME [epoch: 9.49 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0638569117260515		[learning rate: 0.0051889]
	Learning Rate: 0.00518892
	LOSS [training: 1.0638569117260515 | validation: 0.9719946118527023]
	TIME [epoch: 9.52 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0359122268891232		[learning rate: 0.0051767]
	Learning Rate: 0.00517668
	LOSS [training: 1.0359122268891232 | validation: 0.7984409082511285]
	TIME [epoch: 9.51 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1165422721163467		[learning rate: 0.0051645]
	Learning Rate: 0.00516447
	LOSS [training: 1.1165422721163467 | validation: 1.1450319839528291]
	TIME [epoch: 9.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0610377460195397		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 1.0610377460195397 | validation: 1.3545451092738683]
	TIME [epoch: 9.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0862710036937775		[learning rate: 0.0051401]
	Learning Rate: 0.00514013
	LOSS [training: 1.0862710036937775 | validation: 1.0762717278570788]
	TIME [epoch: 9.52 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8512744820990935		[learning rate: 0.005128]
	Learning Rate: 0.00512801
	LOSS [training: 0.8512744820990935 | validation: 0.9656686707852782]
	TIME [epoch: 9.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0857244779830981		[learning rate: 0.0051159]
	Learning Rate: 0.00511591
	LOSS [training: 1.0857244779830981 | validation: 1.404355338809815]
	TIME [epoch: 9.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0245701812528427		[learning rate: 0.0051038]
	Learning Rate: 0.00510384
	LOSS [training: 1.0245701812528427 | validation: 1.2164468555931733]
	TIME [epoch: 9.52 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9899514458358734		[learning rate: 0.0050918]
ERROR:
nan encountered in epoch 335 (validation loss).
