Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r1', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 568214647

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.280209417265576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.280209417265576 | validation: 8.50031804635145]
	TIME [epoch: 80 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.20787177966342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.20787177966342 | validation: 7.638325193063423]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.34154208906005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.34154208906005 | validation: 7.868937245441389]
	TIME [epoch: 9.68 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.31203980712353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.31203980712353 | validation: 7.638529805614767]
	TIME [epoch: 9.7 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.569145296941011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.569145296941011 | validation: 9.074458458415974]
	TIME [epoch: 9.67 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.327709096267352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.327709096267352 | validation: 9.37937795833109]
	TIME [epoch: 9.67 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.755542188776216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.755542188776216 | validation: 12.54860568955181]
	TIME [epoch: 9.67 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 12.363625759221241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.363625759221241 | validation: 11.438400946332868]
	TIME [epoch: 9.7 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.27378478927222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.27378478927222 | validation: 8.977598583063777]
	TIME [epoch: 9.67 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.90561246766874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.90561246766874 | validation: 8.719175915158138]
	TIME [epoch: 9.67 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.531371296565172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.531371296565172 | validation: 9.24161756384148]
	TIME [epoch: 9.7 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.650871741581986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.650871741581986 | validation: 7.52160961893213]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.878093543767685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.878093543767685 | validation: 8.016102461834627]
	TIME [epoch: 9.68 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.018438538040702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.018438538040702 | validation: 7.958488492778248]
	TIME [epoch: 9.69 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.938562010098951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.938562010098951 | validation: 8.656723127272631]
	TIME [epoch: 9.69 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.310882765414412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.310882765414412 | validation: 8.134916592475335]
	TIME [epoch: 9.67 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.083935880486829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.083935880486829 | validation: 7.1168411296642535]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.804242643923869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.804242643923869 | validation: 7.415118616950547]
	TIME [epoch: 9.71 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.951892337838136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.951892337838136 | validation: 7.192989561581567]
	TIME [epoch: 9.69 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.760845977280333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.760845977280333 | validation: 6.85778974526661]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.853974913165023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.853974913165023 | validation: 6.907713512767044]
	TIME [epoch: 9.66 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.757127016180311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.757127016180311 | validation: 7.5563939972673735]
	TIME [epoch: 9.69 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.063904064919353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.063904064919353 | validation: 7.24729574636327]
	TIME [epoch: 9.67 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.954895092617333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.954895092617333 | validation: 7.619834575979253]
	TIME [epoch: 9.67 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.708554256327462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.708554256327462 | validation: 7.116074434224652]
	TIME [epoch: 9.66 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.177950328910718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.177950328910718 | validation: 8.78308720623053]
	TIME [epoch: 9.7 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.15551868611455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.15551868611455 | validation: 7.7004839798211355]
	TIME [epoch: 9.66 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.298804532798266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.298804532798266 | validation: 7.436515289661381]
	TIME [epoch: 9.66 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.764316009628902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.764316009628902 | validation: 7.395670999829979]
	TIME [epoch: 9.69 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.797193115365434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.797193115365434 | validation: 7.491113415643177]
	TIME [epoch: 9.66 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.830052643086205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.830052643086205 | validation: 7.1491133255469554]
	TIME [epoch: 9.66 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.250519125698913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.250519125698913 | validation: 7.175171575495101]
	TIME [epoch: 9.67 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.576005586544122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.576005586544122 | validation: 7.12916925736688]
	TIME [epoch: 9.68 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.7320353340317265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.7320353340317265 | validation: 7.254838995834953]
	TIME [epoch: 9.67 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.438216487650085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.438216487650085 | validation: 7.141432704331954]
	TIME [epoch: 9.66 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.603091266266588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.603091266266588 | validation: 7.561103938752613]
	TIME [epoch: 9.7 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.508673381177298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.508673381177298 | validation: 9.168261872077837]
	TIME [epoch: 9.68 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.875601209597672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.875601209597672 | validation: 9.02445764754789]
	TIME [epoch: 9.66 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.336193091635579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.336193091635579 | validation: 9.25060326014964]
	TIME [epoch: 9.69 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.534128158027729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.534128158027729 | validation: 7.5595097387676145]
	TIME [epoch: 9.67 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.915610013678927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.915610013678927 | validation: 6.880704351471453]
	TIME [epoch: 9.66 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.753135332924826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.753135332924826 | validation: 6.7148848759319755]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.371693250415331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.371693250415331 | validation: 6.780663124995443]
	TIME [epoch: 9.69 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.9066844796976286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.9066844796976286 | validation: 8.451429967416455]
	TIME [epoch: 9.65 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.030009035647002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.030009035647002 | validation: 6.84300576684346]
	TIME [epoch: 9.66 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.746141868691103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.746141868691103 | validation: 8.625868085750207]
	TIME [epoch: 9.67 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.484352708143769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.484352708143769 | validation: 6.861812478986519]
	TIME [epoch: 9.68 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.363067442624616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.363067442624616 | validation: 6.601882669314207]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.319292537795818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.319292537795818 | validation: 7.50480360410021]
	TIME [epoch: 9.67 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.329904390788807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.329904390788807 | validation: 6.868027759365454]
	TIME [epoch: 9.69 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.091103915648256		[learning rate: 0.0099811]
	Learning Rate: 0.00998112
	LOSS [training: 7.091103915648256 | validation: 7.4038325362966555]
	TIME [epoch: 9.66 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.984446589071318		[learning rate: 0.0099576]
	Learning Rate: 0.00995758
	LOSS [training: 7.984446589071318 | validation: 7.121725364288375]
	TIME [epoch: 9.66 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.302723887493639		[learning rate: 0.0099341]
	Learning Rate: 0.00993409
	LOSS [training: 7.302723887493639 | validation: 6.470736137791597]
	TIME [epoch: 9.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.2551198437589814		[learning rate: 0.0099107]
	Learning Rate: 0.00991066
	LOSS [training: 7.2551198437589814 | validation: 8.394091143868948]
	TIME [epoch: 9.68 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.140336022175909		[learning rate: 0.0098873]
	Learning Rate: 0.00988728
	LOSS [training: 8.140336022175909 | validation: 8.121760901445768]
	TIME [epoch: 9.68 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.05800771512109		[learning rate: 0.009864]
	Learning Rate: 0.00986396
	LOSS [training: 8.05800771512109 | validation: 8.416330327485941]
	TIME [epoch: 9.66 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.419685798114457		[learning rate: 0.0098407]
	Learning Rate: 0.00984069
	LOSS [training: 8.419685798114457 | validation: 7.459983953989934]
	TIME [epoch: 9.68 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.355366723485503		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 7.355366723485503 | validation: 6.945221163606022]
	TIME [epoch: 9.67 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.78543826939692		[learning rate: 0.0097943]
	Learning Rate: 0.00979432
	LOSS [training: 7.78543826939692 | validation: 7.277588789571322]
	TIME [epoch: 9.67 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.428795002093767		[learning rate: 0.0097712]
	Learning Rate: 0.00977122
	LOSS [training: 7.428795002093767 | validation: 7.1949458318722455]
	TIME [epoch: 9.67 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.314253489697293		[learning rate: 0.0097482]
	Learning Rate: 0.00974817
	LOSS [training: 7.314253489697293 | validation: 6.4443827614171845]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.08258406654482		[learning rate: 0.0097252]
	Learning Rate: 0.00972517
	LOSS [training: 7.08258406654482 | validation: 6.68528781504828]
	TIME [epoch: 9.66 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.032466359626584		[learning rate: 0.0097022]
	Learning Rate: 0.00970223
	LOSS [training: 7.032466359626584 | validation: 6.85253059761491]
	TIME [epoch: 9.65 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.153160595323518		[learning rate: 0.0096793]
	Learning Rate: 0.00967935
	LOSS [training: 7.153160595323518 | validation: 6.646484448330007]
	TIME [epoch: 9.69 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.0782287997383		[learning rate: 0.0096565]
	Learning Rate: 0.00965652
	LOSS [training: 7.0782287997383 | validation: 6.761573449567424]
	TIME [epoch: 9.66 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.174959354702931		[learning rate: 0.0096337]
	Learning Rate: 0.00963374
	LOSS [training: 8.174959354702931 | validation: 6.877376132338057]
	TIME [epoch: 9.67 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.590084428426851		[learning rate: 0.009611]
	Learning Rate: 0.00961101
	LOSS [training: 7.590084428426851 | validation: 8.281456606793247]
	TIME [epoch: 9.65 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.11305249460263		[learning rate: 0.0095883]
	Learning Rate: 0.00958834
	LOSS [training: 8.11305249460263 | validation: 7.032584834444914]
	TIME [epoch: 9.69 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.281758522693627		[learning rate: 0.0095657]
	Learning Rate: 0.00956573
	LOSS [training: 7.281758522693627 | validation: 6.464847362882104]
	TIME [epoch: 9.66 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.969089112129128		[learning rate: 0.0095432]
	Learning Rate: 0.00954316
	LOSS [training: 6.969089112129128 | validation: 6.7846640469620345]
	TIME [epoch: 9.66 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.629513810360004		[learning rate: 0.0095207]
	Learning Rate: 0.00952065
	LOSS [training: 7.629513810360004 | validation: 8.078187075297304]
	TIME [epoch: 9.68 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.068462568733324		[learning rate: 0.0094982]
	Learning Rate: 0.00949819
	LOSS [training: 8.068462568733324 | validation: 8.353382581510754]
	TIME [epoch: 9.67 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.01577603081834		[learning rate: 0.0094758]
	Learning Rate: 0.00947579
	LOSS [training: 8.01577603081834 | validation: 8.176551309947731]
	TIME [epoch: 9.65 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.942007981160634		[learning rate: 0.0094534]
	Learning Rate: 0.00945344
	LOSS [training: 7.942007981160634 | validation: 7.595517551901811]
	TIME [epoch: 9.66 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.006145574467418		[learning rate: 0.0094311]
	Learning Rate: 0.00943114
	LOSS [training: 8.006145574467418 | validation: 7.752334852376341]
	TIME [epoch: 9.69 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.838231764149079		[learning rate: 0.0094089]
	Learning Rate: 0.00940889
	LOSS [training: 7.838231764149079 | validation: 8.481228055780198]
	TIME [epoch: 9.67 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.566490419486431		[learning rate: 0.0093867]
	Learning Rate: 0.0093867
	LOSS [training: 8.566490419486431 | validation: 8.87230263823792]
	TIME [epoch: 9.66 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.304757314895333		[learning rate: 0.0093646]
	Learning Rate: 0.00936456
	LOSS [training: 9.304757314895333 | validation: 10.304111095942467]
	TIME [epoch: 9.68 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.407243641399711		[learning rate: 0.0093425]
	Learning Rate: 0.00934247
	LOSS [training: 9.407243641399711 | validation: 9.30320003762248]
	TIME [epoch: 9.66 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.543331509785599		[learning rate: 0.0093204]
	Learning Rate: 0.00932043
	LOSS [training: 8.543331509785599 | validation: 8.189683649769595]
	TIME [epoch: 9.66 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.837630238293156		[learning rate: 0.0092984]
	Learning Rate: 0.00929844
	LOSS [training: 7.837630238293156 | validation: 7.6892480988234695]
	TIME [epoch: 9.67 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.748349078293489		[learning rate: 0.0092765]
	Learning Rate: 0.00927651
	LOSS [training: 7.748349078293489 | validation: 6.629755303738435]
	TIME [epoch: 9.67 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.912985513327378		[learning rate: 0.0092546]
	Learning Rate: 0.00925463
	LOSS [training: 6.912985513327378 | validation: 6.527362973317818]
	TIME [epoch: 9.66 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.413427410017201		[learning rate: 0.0092328]
	Learning Rate: 0.0092328
	LOSS [training: 7.413427410017201 | validation: 5.089499385063397]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.861704423779		[learning rate: 0.009211]
	Learning Rate: 0.00921102
	LOSS [training: 6.861704423779 | validation: 5.8083723575812085]
	TIME [epoch: 9.7 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.685311129831318		[learning rate: 0.0091893]
	Learning Rate: 0.00918929
	LOSS [training: 7.685311129831318 | validation: 8.537440345613977]
	TIME [epoch: 9.67 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.4161775679527935		[learning rate: 0.0091676]
	Learning Rate: 0.00916762
	LOSS [training: 7.4161775679527935 | validation: 5.455805666403271]
	TIME [epoch: 9.67 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.450422977723102		[learning rate: 0.009146]
	Learning Rate: 0.00914599
	LOSS [training: 6.450422977723102 | validation: 5.640337179738084]
	TIME [epoch: 9.66 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.013457627835413		[learning rate: 0.0091244]
	Learning Rate: 0.00912442
	LOSS [training: 6.013457627835413 | validation: 5.079041391662789]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.774068026447074		[learning rate: 0.0091029]
	Learning Rate: 0.00910289
	LOSS [training: 5.774068026447074 | validation: 7.533719992746419]
	TIME [epoch: 9.67 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.836325826389133		[learning rate: 0.0090814]
	Learning Rate: 0.00908142
	LOSS [training: 6.836325826389133 | validation: 5.014036435215636]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.4109156242497445		[learning rate: 0.00906]
	Learning Rate: 0.00906
	LOSS [training: 5.4109156242497445 | validation: 4.943257077771405]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.026088085417722		[learning rate: 0.0090386]
	Learning Rate: 0.00903863
	LOSS [training: 6.026088085417722 | validation: 5.4797325583128895]
	TIME [epoch: 9.66 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.9881473274018475		[learning rate: 0.0090173]
	Learning Rate: 0.00901731
	LOSS [training: 5.9881473274018475 | validation: 5.678178123307982]
	TIME [epoch: 9.66 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.855326398396632		[learning rate: 0.008996]
	Learning Rate: 0.00899604
	LOSS [training: 5.855326398396632 | validation: 5.880545090708956]
	TIME [epoch: 9.66 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.501471227893336		[learning rate: 0.0089748]
	Learning Rate: 0.00897482
	LOSS [training: 5.501471227893336 | validation: 4.857273332915879]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.963512995888429		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 4.963512995888429 | validation: 6.091723446914269]
	TIME [epoch: 9.67 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.183788480505614		[learning rate: 0.0089325]
	Learning Rate: 0.00893253
	LOSS [training: 5.183788480505614 | validation: 4.622840056231706]
	TIME [epoch: 9.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.821307362509065		[learning rate: 0.0089115]
	Learning Rate: 0.00891146
	LOSS [training: 4.821307362509065 | validation: 6.011499734664978]
	TIME [epoch: 9.7 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.971967519026225		[learning rate: 0.0088904]
	Learning Rate: 0.00889044
	LOSS [training: 4.971967519026225 | validation: 4.501443437984906]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.630783696350381		[learning rate: 0.0088695]
	Learning Rate: 0.00886946
	LOSS [training: 4.630783696350381 | validation: 4.784987907318545]
	TIME [epoch: 9.67 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.944792283843163		[learning rate: 0.0088485]
	Learning Rate: 0.00884854
	LOSS [training: 4.944792283843163 | validation: 6.674189288796608]
	TIME [epoch: 9.66 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.926321420642731		[learning rate: 0.0088277]
	Learning Rate: 0.00882767
	LOSS [training: 5.926321420642731 | validation: 4.843085582086753]
	TIME [epoch: 9.69 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.215014123502934		[learning rate: 0.0088068]
	Learning Rate: 0.00880685
	LOSS [training: 5.215014123502934 | validation: 4.826225442759457]
	TIME [epoch: 9.67 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.398986542532409		[learning rate: 0.0087861]
	Learning Rate: 0.00878607
	LOSS [training: 4.398986542532409 | validation: 5.173657778363368]
	TIME [epoch: 9.66 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.559490895713422		[learning rate: 0.0087653]
	Learning Rate: 0.00876535
	LOSS [training: 4.559490895713422 | validation: 4.361909567341284]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.39705021343294		[learning rate: 0.0087447]
	Learning Rate: 0.00874467
	LOSS [training: 4.39705021343294 | validation: 4.209625861116112]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.923097231567951		[learning rate: 0.008724]
	Learning Rate: 0.00872405
	LOSS [training: 4.923097231567951 | validation: 5.771361058609771]
	TIME [epoch: 9.66 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.723577212342319		[learning rate: 0.0087035]
	Learning Rate: 0.00870347
	LOSS [training: 4.723577212342319 | validation: 6.082305229230333]
	TIME [epoch: 9.66 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.805763725413314		[learning rate: 0.0086829]
	Learning Rate: 0.00868294
	LOSS [training: 4.805763725413314 | validation: 4.039653710973838]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.291501246272973		[learning rate: 0.0086625]
	Learning Rate: 0.00866246
	LOSS [training: 4.291501246272973 | validation: 5.206518119471534]
	TIME [epoch: 9.67 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.559316750043472		[learning rate: 0.008642]
	Learning Rate: 0.00864202
	LOSS [training: 4.559316750043472 | validation: 6.473043499250551]
	TIME [epoch: 9.66 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.182970301563838		[learning rate: 0.0086216]
	Learning Rate: 0.00862164
	LOSS [training: 5.182970301563838 | validation: 4.550611856527308]
	TIME [epoch: 9.67 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.31972902597999		[learning rate: 0.0086013]
	Learning Rate: 0.0086013
	LOSS [training: 3.31972902597999 | validation: 2.5030606434733893]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3593426291901594		[learning rate: 0.008581]
	Learning Rate: 0.00858101
	LOSS [training: 3.3593426291901594 | validation: 3.0664104118417037]
	TIME [epoch: 9.67 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9651791265523726		[learning rate: 0.0085608]
	Learning Rate: 0.00856077
	LOSS [training: 2.9651791265523726 | validation: 3.1461032425454833]
	TIME [epoch: 9.66 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9330305076714502		[learning rate: 0.0085406]
	Learning Rate: 0.00854058
	LOSS [training: 3.9330305076714502 | validation: 8.892974600833451]
	TIME [epoch: 9.67 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.615879302618142		[learning rate: 0.0085204]
	Learning Rate: 0.00852043
	LOSS [training: 6.615879302618142 | validation: 3.8270483052183337]
	TIME [epoch: 9.68 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9628232724026313		[learning rate: 0.0085003]
	Learning Rate: 0.00850033
	LOSS [training: 3.9628232724026313 | validation: 5.461327880409812]
	TIME [epoch: 9.66 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6951114987400446		[learning rate: 0.0084803]
	Learning Rate: 0.00848028
	LOSS [training: 3.6951114987400446 | validation: 2.5736980107240153]
	TIME [epoch: 9.66 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3885472026351975		[learning rate: 0.0084603]
	Learning Rate: 0.00846028
	LOSS [training: 2.3885472026351975 | validation: 2.259112364222827]
	TIME [epoch: 9.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3119785539049835		[learning rate: 0.0084403]
	Learning Rate: 0.00844032
	LOSS [training: 2.3119785539049835 | validation: 2.681743892111971]
	TIME [epoch: 9.68 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1516090365767084		[learning rate: 0.0084204]
	Learning Rate: 0.00842041
	LOSS [training: 2.1516090365767084 | validation: 3.758540535497385]
	TIME [epoch: 9.66 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.627257303764587		[learning rate: 0.0084005]
	Learning Rate: 0.00840055
	LOSS [training: 2.627257303764587 | validation: 1.8426305215073862]
	TIME [epoch: 9.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.257173240897944		[learning rate: 0.0083807]
	Learning Rate: 0.00838073
	LOSS [training: 2.257173240897944 | validation: 2.099586737368716]
	TIME [epoch: 9.68 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.281355579328161		[learning rate: 0.008361]
	Learning Rate: 0.00836096
	LOSS [training: 2.281355579328161 | validation: 2.19575677117701]
	TIME [epoch: 9.66 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.273701388078443		[learning rate: 0.0083412]
	Learning Rate: 0.00834124
	LOSS [training: 2.273701388078443 | validation: 1.7406818332408989]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.994221882775492		[learning rate: 0.0083216]
	Learning Rate: 0.00832157
	LOSS [training: 1.994221882775492 | validation: 2.270872457594941]
	TIME [epoch: 9.66 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1827880554344588		[learning rate: 0.0083019]
	Learning Rate: 0.00830194
	LOSS [training: 2.1827880554344588 | validation: 2.342892126721765]
	TIME [epoch: 9.69 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.248407080180029		[learning rate: 0.0082824]
	Learning Rate: 0.00828236
	LOSS [training: 2.248407080180029 | validation: 1.656109308623791]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.02626365671116		[learning rate: 0.0082628]
	Learning Rate: 0.00826282
	LOSS [training: 2.02626365671116 | validation: 2.9236540459027665]
	TIME [epoch: 9.65 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.195763577197885		[learning rate: 0.0082433]
	Learning Rate: 0.00824333
	LOSS [training: 2.195763577197885 | validation: 2.7449826298024913]
	TIME [epoch: 9.66 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4931011804442087		[learning rate: 0.0082239]
	Learning Rate: 0.00822388
	LOSS [training: 3.4931011804442087 | validation: 3.70524599445996]
	TIME [epoch: 9.68 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.863806803087328		[learning rate: 0.0082045]
	Learning Rate: 0.00820448
	LOSS [training: 2.863806803087328 | validation: 1.5977804353888596]
	TIME [epoch: 9.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.995371867803287		[learning rate: 0.0081851]
	Learning Rate: 0.00818513
	LOSS [training: 1.995371867803287 | validation: 2.2596861857355663]
	TIME [epoch: 9.65 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7856589470417716		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 1.7856589470417716 | validation: 2.596939704676223]
	TIME [epoch: 9.67 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.894252314349071		[learning rate: 0.0081466]
	Learning Rate: 0.00814656
	LOSS [training: 2.894252314349071 | validation: 2.37290172596583]
	TIME [epoch: 9.65 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.176772095375499		[learning rate: 0.0081273]
	Learning Rate: 0.00812735
	LOSS [training: 4.176772095375499 | validation: 3.0074289689498643]
	TIME [epoch: 9.66 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5766095329797545		[learning rate: 0.0081082]
	Learning Rate: 0.00810817
	LOSS [training: 2.5766095329797545 | validation: 1.5277843935916013]
	TIME [epoch: 9.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.91618250655947		[learning rate: 0.008089]
	Learning Rate: 0.00808905
	LOSS [training: 2.91618250655947 | validation: 2.5799882847093047]
	TIME [epoch: 9.68 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.806652498429881		[learning rate: 0.00807]
	Learning Rate: 0.00806997
	LOSS [training: 2.806652498429881 | validation: 4.400752571427487]
	TIME [epoch: 9.66 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.217338354645815		[learning rate: 0.0080509]
	Learning Rate: 0.00805093
	LOSS [training: 4.217338354645815 | validation: 2.142690668082129]
	TIME [epoch: 9.66 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.704988941184071		[learning rate: 0.0080319]
	Learning Rate: 0.00803194
	LOSS [training: 2.704988941184071 | validation: 2.885282868137646]
	TIME [epoch: 9.66 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1302119325999627		[learning rate: 0.008013]
	Learning Rate: 0.00801299
	LOSS [training: 2.1302119325999627 | validation: 2.1733706789639466]
	TIME [epoch: 9.68 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8333960563208638		[learning rate: 0.0079941]
	Learning Rate: 0.00799409
	LOSS [training: 1.8333960563208638 | validation: 2.66606188771529]
	TIME [epoch: 9.66 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.995522574455527		[learning rate: 0.0079752]
	Learning Rate: 0.00797524
	LOSS [training: 2.995522574455527 | validation: 2.2432391323476115]
	TIME [epoch: 9.66 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2753908122504525		[learning rate: 0.0079564]
	Learning Rate: 0.00795642
	LOSS [training: 3.2753908122504525 | validation: 3.790218057208441]
	TIME [epoch: 9.68 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.386467478941421		[learning rate: 0.0079377]
	Learning Rate: 0.00793766
	LOSS [training: 3.386467478941421 | validation: 1.9951826167721363]
	TIME [epoch: 9.66 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2891436199291944		[learning rate: 0.0079189]
	Learning Rate: 0.00791893
	LOSS [training: 2.2891436199291944 | validation: 3.512160106962724]
	TIME [epoch: 9.66 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7106587657324774		[learning rate: 0.0079003]
	Learning Rate: 0.00790025
	LOSS [training: 2.7106587657324774 | validation: 2.821621804948104]
	TIME [epoch: 9.65 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2025802115972146		[learning rate: 0.0078816]
	Learning Rate: 0.00788162
	LOSS [training: 2.2025802115972146 | validation: 1.8464455890443652]
	TIME [epoch: 9.68 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6401670646554727		[learning rate: 0.007863]
	Learning Rate: 0.00786303
	LOSS [training: 1.6401670646554727 | validation: 1.7937585705061754]
	TIME [epoch: 9.65 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9350981372536473		[learning rate: 0.0078445]
	Learning Rate: 0.00784448
	LOSS [training: 1.9350981372536473 | validation: 2.6873736189805766]
	TIME [epoch: 9.65 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8111521596252556		[learning rate: 0.007826]
	Learning Rate: 0.00782597
	LOSS [training: 1.8111521596252556 | validation: 3.063082238723452]
	TIME [epoch: 9.68 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0421878355775296		[learning rate: 0.0078075]
	Learning Rate: 0.00780751
	LOSS [training: 2.0421878355775296 | validation: 2.4049786025207767]
	TIME [epoch: 9.66 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.141093295561082		[learning rate: 0.0077891]
	Learning Rate: 0.0077891
	LOSS [training: 2.141093295561082 | validation: 2.234647011374249]
	TIME [epoch: 9.65 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.316954238382978		[learning rate: 0.0077707]
	Learning Rate: 0.00777072
	LOSS [training: 2.316954238382978 | validation: 2.251545652568079]
	TIME [epoch: 9.67 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.021731690357589		[learning rate: 0.0077524]
	Learning Rate: 0.00775239
	LOSS [training: 2.021731690357589 | validation: 3.2148245954056804]
	TIME [epoch: 9.66 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.500288689225709		[learning rate: 0.0077341]
	Learning Rate: 0.00773411
	LOSS [training: 3.500288689225709 | validation: 2.1542578458716553]
	TIME [epoch: 9.65 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9215904647376447		[learning rate: 0.0077159]
	Learning Rate: 0.00771586
	LOSS [training: 1.9215904647376447 | validation: 2.1611628834082826]
	TIME [epoch: 9.65 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.803635228778914		[learning rate: 0.0076977]
	Learning Rate: 0.00769766
	LOSS [training: 1.803635228778914 | validation: 1.5197347284166998]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5720493541145546		[learning rate: 0.0076795]
	Learning Rate: 0.00767951
	LOSS [training: 1.5720493541145546 | validation: 1.9486729922413935]
	TIME [epoch: 9.65 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8442054668430412		[learning rate: 0.0076614]
	Learning Rate: 0.00766139
	LOSS [training: 1.8442054668430412 | validation: 2.0929461606243303]
	TIME [epoch: 9.66 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.629404942987899		[learning rate: 0.0076433]
	Learning Rate: 0.00764332
	LOSS [training: 2.629404942987899 | validation: 3.1460178696794943]
	TIME [epoch: 9.68 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.515241985311244		[learning rate: 0.0076253]
	Learning Rate: 0.00762529
	LOSS [training: 2.515241985311244 | validation: 4.844498309755381]
	TIME [epoch: 9.65 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8082181361595664		[learning rate: 0.0076073]
	Learning Rate: 0.0076073
	LOSS [training: 2.8082181361595664 | validation: 1.828075927058294]
	TIME [epoch: 9.65 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.716995236302957		[learning rate: 0.0075894]
	Learning Rate: 0.00758936
	LOSS [training: 1.716995236302957 | validation: 2.1657316524536583]
	TIME [epoch: 9.66 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7311843028327332		[learning rate: 0.0075715]
	Learning Rate: 0.00757146
	LOSS [training: 1.7311843028327332 | validation: 1.437262646988994]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.959667152765809		[learning rate: 0.0075536]
	Learning Rate: 0.0075536
	LOSS [training: 1.959667152765809 | validation: 3.2738362444441953]
	TIME [epoch: 9.68 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.131873936783388		[learning rate: 0.0075358]
	Learning Rate: 0.00753578
	LOSS [training: 2.131873936783388 | validation: 3.43927237240513]
	TIME [epoch: 9.67 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.297130604053264		[learning rate: 0.007518]
	Learning Rate: 0.007518
	LOSS [training: 2.297130604053264 | validation: 1.6539830584860704]
	TIME [epoch: 9.69 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8296513488761648		[learning rate: 0.0075003]
	Learning Rate: 0.00750027
	LOSS [training: 1.8296513488761648 | validation: 1.8257086519802517]
	TIME [epoch: 9.69 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9524112129520248		[learning rate: 0.0074826]
	Learning Rate: 0.00748258
	LOSS [training: 1.9524112129520248 | validation: 2.420017398883204]
	TIME [epoch: 9.67 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.03125998690958		[learning rate: 0.0074649]
	Learning Rate: 0.00746493
	LOSS [training: 2.03125998690958 | validation: 2.046184554142338]
	TIME [epoch: 9.67 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7752208874648936		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 1.7752208874648936 | validation: 2.653865113029765]
	TIME [epoch: 9.7 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4883443893751567		[learning rate: 0.0074298]
	Learning Rate: 0.00742975
	LOSS [training: 2.4883443893751567 | validation: 1.921495746141727]
	TIME [epoch: 9.69 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7414286486412158		[learning rate: 0.0074122]
	Learning Rate: 0.00741223
	LOSS [training: 1.7414286486412158 | validation: 2.598005031283152]
	TIME [epoch: 9.68 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8080687190818991		[learning rate: 0.0073947]
	Learning Rate: 0.00739474
	LOSS [training: 1.8080687190818991 | validation: 1.6364533957499838]
	TIME [epoch: 9.68 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1575337073553147		[learning rate: 0.0073773]
	Learning Rate: 0.0073773
	LOSS [training: 2.1575337073553147 | validation: 1.6625894038819025]
	TIME [epoch: 9.69 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4637869390995373		[learning rate: 0.0073599]
	Learning Rate: 0.0073599
	LOSS [training: 1.4637869390995373 | validation: 1.4287555301556478]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8761938918735823		[learning rate: 0.0073425]
	Learning Rate: 0.00734254
	LOSS [training: 1.8761938918735823 | validation: 1.7481758405179335]
	TIME [epoch: 9.67 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2312272821352197		[learning rate: 0.0073252]
	Learning Rate: 0.00732522
	LOSS [training: 2.2312272821352197 | validation: 3.0206018131145322]
	TIME [epoch: 9.7 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.907259632338151		[learning rate: 0.0073079]
	Learning Rate: 0.00730794
	LOSS [training: 1.907259632338151 | validation: 1.6666957268211393]
	TIME [epoch: 9.67 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.308406592892431		[learning rate: 0.0072907]
	Learning Rate: 0.0072907
	LOSS [training: 2.308406592892431 | validation: 3.327626960421991]
	TIME [epoch: 9.65 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8837077509493922		[learning rate: 0.0072735]
	Learning Rate: 0.0072735
	LOSS [training: 1.8837077509493922 | validation: 1.3477851797031741]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6901787946628033		[learning rate: 0.0072563]
	Learning Rate: 0.00725635
	LOSS [training: 1.6901787946628033 | validation: 2.0920986633424627]
	TIME [epoch: 9.68 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0323478893056097		[learning rate: 0.0072392]
	Learning Rate: 0.00723923
	LOSS [training: 2.0323478893056097 | validation: 2.018207103779338]
	TIME [epoch: 9.67 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2527437133859527		[learning rate: 0.0072222]
	Learning Rate: 0.00722215
	LOSS [training: 2.2527437133859527 | validation: 2.5822788340146094]
	TIME [epoch: 9.67 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2681122727587235		[learning rate: 0.0072051]
	Learning Rate: 0.00720512
	LOSS [training: 2.2681122727587235 | validation: 1.3060509194341041]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8350122095253414		[learning rate: 0.0071881]
	Learning Rate: 0.00718812
	LOSS [training: 1.8350122095253414 | validation: 2.5248037635554175]
	TIME [epoch: 9.68 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9722952976727914		[learning rate: 0.0071712]
	Learning Rate: 0.00717117
	LOSS [training: 1.9722952976727914 | validation: 1.591809645000427]
	TIME [epoch: 9.67 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6216122526326255		[learning rate: 0.0071542]
	Learning Rate: 0.00715425
	LOSS [training: 1.6216122526326255 | validation: 1.6669960977112124]
	TIME [epoch: 9.67 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5379857579674476		[learning rate: 0.0071374]
	Learning Rate: 0.00713737
	LOSS [training: 1.5379857579674476 | validation: 1.6552565117887554]
	TIME [epoch: 9.68 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9046144663681297		[learning rate: 0.0071205]
	Learning Rate: 0.00712054
	LOSS [training: 1.9046144663681297 | validation: 2.895166297867224]
	TIME [epoch: 9.66 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9393363237902719		[learning rate: 0.0071037]
	Learning Rate: 0.00710374
	LOSS [training: 1.9393363237902719 | validation: 2.3297352282576633]
	TIME [epoch: 9.66 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2108136626397106		[learning rate: 0.007087]
	Learning Rate: 0.00708698
	LOSS [training: 2.2108136626397106 | validation: 1.5804716412640687]
	TIME [epoch: 9.67 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9583771619640085		[learning rate: 0.0070703]
	Learning Rate: 0.00707027
	LOSS [training: 1.9583771619640085 | validation: 2.8762868081569644]
	TIME [epoch: 9.67 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.533552231033462		[learning rate: 0.0070536]
	Learning Rate: 0.00705359
	LOSS [training: 2.533552231033462 | validation: 2.347796691430527]
	TIME [epoch: 9.66 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.028843964590828		[learning rate: 0.007037]
	Learning Rate: 0.00703695
	LOSS [training: 2.028843964590828 | validation: 1.4092216668088806]
	TIME [epoch: 9.66 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5820331226920796		[learning rate: 0.0070204]
	Learning Rate: 0.00702035
	LOSS [training: 1.5820331226920796 | validation: 1.5726329320640724]
	TIME [epoch: 9.68 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5192959167978504		[learning rate: 0.0070038]
	Learning Rate: 0.00700379
	LOSS [training: 1.5192959167978504 | validation: 2.084846454898533]
	TIME [epoch: 9.65 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8385655005285368		[learning rate: 0.0069873]
	Learning Rate: 0.00698727
	LOSS [training: 1.8385655005285368 | validation: 2.195607661844895]
	TIME [epoch: 9.65 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7255990969160677		[learning rate: 0.0069708]
	Learning Rate: 0.00697079
	LOSS [training: 1.7255990969160677 | validation: 1.4387791578485432]
	TIME [epoch: 9.67 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5145848759541543		[learning rate: 0.0069543]
	Learning Rate: 0.00695435
	LOSS [training: 1.5145848759541543 | validation: 1.4345064086975332]
	TIME [epoch: 9.65 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.094246647759166		[learning rate: 0.0069379]
	Learning Rate: 0.00693794
	LOSS [training: 2.094246647759166 | validation: 1.7430847185694465]
	TIME [epoch: 9.65 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4468381570657995		[learning rate: 0.0069216]
	Learning Rate: 0.00692158
	LOSS [training: 1.4468381570657995 | validation: 1.4481510355265823]
	TIME [epoch: 9.65 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4346356258336193		[learning rate: 0.0069053]
	Learning Rate: 0.00690525
	LOSS [training: 1.4346356258336193 | validation: 1.9889317836400902]
	TIME [epoch: 9.68 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7093637805927275		[learning rate: 0.006889]
	Learning Rate: 0.00688896
	LOSS [training: 1.7093637805927275 | validation: 2.3751225670283667]
	TIME [epoch: 9.65 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9138209238173007		[learning rate: 0.0068727]
	Learning Rate: 0.00687271
	LOSS [training: 1.9138209238173007 | validation: 1.3064633879711307]
	TIME [epoch: 9.66 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.666592294753806		[learning rate: 0.0068565]
	Learning Rate: 0.0068565
	LOSS [training: 1.666592294753806 | validation: 1.4132902817330553]
	TIME [epoch: 9.68 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.44385555153656		[learning rate: 0.0068403]
	Learning Rate: 0.00684033
	LOSS [training: 1.44385555153656 | validation: 1.5821032527371626]
	TIME [epoch: 9.64 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6371115932259133		[learning rate: 0.0068242]
	Learning Rate: 0.00682419
	LOSS [training: 1.6371115932259133 | validation: 1.6192335137175047]
	TIME [epoch: 9.64 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5053246624490748		[learning rate: 0.0068081]
	Learning Rate: 0.0068081
	LOSS [training: 1.5053246624490748 | validation: 1.2968143993231476]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_213.pth
	Model improved!!!
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6803105572518497		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 1.6803105572518497 | validation: 1.504759747506186]
	TIME [epoch: 9.68 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5544513760031784		[learning rate: 0.006776]
	Learning Rate: 0.00677601
	LOSS [training: 1.5544513760031784 | validation: 1.3461078534611104]
	TIME [epoch: 9.66 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4504737815066537		[learning rate: 0.00676]
	Learning Rate: 0.00676003
	LOSS [training: 1.4504737815066537 | validation: 1.641265716215511]
	TIME [epoch: 9.65 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4081213706817173		[learning rate: 0.0067441]
	Learning Rate: 0.00674409
	LOSS [training: 1.4081213706817173 | validation: 1.5631208803937637]
	TIME [epoch: 9.67 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3414133179202192		[learning rate: 0.0067282]
	Learning Rate: 0.00672818
	LOSS [training: 1.3414133179202192 | validation: 1.2902477119191529]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_218.pth
	Model improved!!!
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4117423571904453		[learning rate: 0.0067123]
	Learning Rate: 0.00671231
	LOSS [training: 1.4117423571904453 | validation: 1.5426962737090526]
	TIME [epoch: 9.65 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4995115146102291		[learning rate: 0.0066965]
	Learning Rate: 0.00669647
	LOSS [training: 1.4995115146102291 | validation: 1.5327013770786966]
	TIME [epoch: 9.66 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4048918587036305		[learning rate: 0.0066807]
	Learning Rate: 0.00668068
	LOSS [training: 1.4048918587036305 | validation: 1.3070686710614647]
	TIME [epoch: 9.68 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7857790445284745		[learning rate: 0.0066649]
	Learning Rate: 0.00666492
	LOSS [training: 1.7857790445284745 | validation: 2.500960059651531]
	TIME [epoch: 9.65 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.165756741529924		[learning rate: 0.0066492]
	Learning Rate: 0.0066492
	LOSS [training: 2.165756741529924 | validation: 1.8329130233989355]
	TIME [epoch: 9.65 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4382316776883064		[learning rate: 0.0066335]
	Learning Rate: 0.00663351
	LOSS [training: 1.4382316776883064 | validation: 1.4654112698314656]
	TIME [epoch: 9.67 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4175201796153272		[learning rate: 0.0066179]
	Learning Rate: 0.00661787
	LOSS [training: 1.4175201796153272 | validation: 1.4577122534654683]
	TIME [epoch: 9.67 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6361589933441287		[learning rate: 0.0066023]
	Learning Rate: 0.00660226
	LOSS [training: 1.6361589933441287 | validation: 1.585566080592294]
	TIME [epoch: 9.65 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4536669798882473		[learning rate: 0.0065867]
	Learning Rate: 0.00658668
	LOSS [training: 1.4536669798882473 | validation: 1.3981545010441934]
	TIME [epoch: 9.65 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3247197152712356		[learning rate: 0.0065711]
	Learning Rate: 0.00657114
	LOSS [training: 1.3247197152712356 | validation: 1.4531364400314084]
	TIME [epoch: 9.68 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3450851608386505		[learning rate: 0.0065556]
	Learning Rate: 0.00655564
	LOSS [training: 1.3450851608386505 | validation: 1.4347355596967963]
	TIME [epoch: 9.66 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.370789650175022		[learning rate: 0.0065402]
	Learning Rate: 0.00654018
	LOSS [training: 1.370789650175022 | validation: 1.356328934552596]
	TIME [epoch: 9.65 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4187567710706193		[learning rate: 0.0065248]
	Learning Rate: 0.00652475
	LOSS [training: 1.4187567710706193 | validation: 1.3094685193937543]
	TIME [epoch: 9.67 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3994033523642777		[learning rate: 0.0065094]
	Learning Rate: 0.00650936
	LOSS [training: 1.3994033523642777 | validation: 1.2567853788060743]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.202160129214432		[learning rate: 0.006494]
	Learning Rate: 0.00649401
	LOSS [training: 1.202160129214432 | validation: 1.5428337327652935]
	TIME [epoch: 9.64 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4838856478602336		[learning rate: 0.0064787]
	Learning Rate: 0.00647869
	LOSS [training: 1.4838856478602336 | validation: 1.271016119715381]
	TIME [epoch: 9.66 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6850646807962852		[learning rate: 0.0064634]
	Learning Rate: 0.00646341
	LOSS [training: 1.6850646807962852 | validation: 1.5851908121545808]
	TIME [epoch: 9.67 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.719483882630043		[learning rate: 0.0064482]
	Learning Rate: 0.00644816
	LOSS [training: 2.719483882630043 | validation: 1.3480051616513786]
	TIME [epoch: 9.66 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3812337666364627		[learning rate: 0.006433]
	Learning Rate: 0.00643295
	LOSS [training: 1.3812337666364627 | validation: 1.500555566827273]
	TIME [epoch: 9.65 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.41432694591644		[learning rate: 0.0064178]
	Learning Rate: 0.00641778
	LOSS [training: 1.41432694591644 | validation: 1.4872140380204257]
	TIME [epoch: 9.66 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5191822004313185		[learning rate: 0.0064026]
	Learning Rate: 0.00640264
	LOSS [training: 1.5191822004313185 | validation: 1.2016577642273831]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.528870707894885		[learning rate: 0.0063875]
	Learning Rate: 0.00638754
	LOSS [training: 1.528870707894885 | validation: 1.9229725306047354]
	TIME [epoch: 9.66 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.361620778552951		[learning rate: 0.0063725]
	Learning Rate: 0.00637247
	LOSS [training: 1.361620778552951 | validation: 1.8226608153171504]
	TIME [epoch: 9.66 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6793281479170665		[learning rate: 0.0063574]
	Learning Rate: 0.00635744
	LOSS [training: 1.6793281479170665 | validation: 1.4544382037980084]
	TIME [epoch: 9.68 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0142038844779724		[learning rate: 0.0063424]
	Learning Rate: 0.00634244
	LOSS [training: 2.0142038844779724 | validation: 1.52623189571795]
	TIME [epoch: 9.67 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2595852875281583		[learning rate: 0.0063275]
	Learning Rate: 0.00632748
	LOSS [training: 1.2595852875281583 | validation: 1.0401505345372513]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1376134290549644		[learning rate: 0.0063126]
	Learning Rate: 0.00631255
	LOSS [training: 1.1376134290549644 | validation: 1.2665269838328168]
	TIME [epoch: 9.67 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.417793526686012		[learning rate: 0.0062977]
	Learning Rate: 0.00629766
	LOSS [training: 1.417793526686012 | validation: 1.1853274515248802]
	TIME [epoch: 9.66 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3610583600416488		[learning rate: 0.0062828]
	Learning Rate: 0.00628281
	LOSS [training: 1.3610583600416488 | validation: 1.4747186824818124]
	TIME [epoch: 9.66 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2431925760564577		[learning rate: 0.006268]
	Learning Rate: 0.00626799
	LOSS [training: 1.2431925760564577 | validation: 1.6147538914474597]
	TIME [epoch: 9.64 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2399296727801166		[learning rate: 0.0062532]
	Learning Rate: 0.0062532
	LOSS [training: 1.2399296727801166 | validation: 0.9786339433244229]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6989287252533416		[learning rate: 0.0062385]
	Learning Rate: 0.00623845
	LOSS [training: 1.6989287252533416 | validation: 1.4076448665758983]
	TIME [epoch: 9.66 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5075129889928438		[learning rate: 0.0062237]
	Learning Rate: 0.00622374
	LOSS [training: 1.5075129889928438 | validation: 1.8126484044666222]
	TIME [epoch: 9.66 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3312874414687665		[learning rate: 0.0062091]
	Learning Rate: 0.00620906
	LOSS [training: 1.3312874414687665 | validation: 1.4753145914606198]
	TIME [epoch: 9.66 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4593487097538422		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 1.4593487097538422 | validation: 1.4852449356606747]
	TIME [epoch: 9.69 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.449406561408471		[learning rate: 0.0061798]
	Learning Rate: 0.0061798
	LOSS [training: 1.449406561408471 | validation: 1.5919046733606639]
	TIME [epoch: 9.65 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5315093391188033		[learning rate: 0.0061652]
	Learning Rate: 0.00616522
	LOSS [training: 1.5315093391188033 | validation: 1.0964877104493025]
	TIME [epoch: 9.65 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.089050333101722		[learning rate: 0.0061507]
	Learning Rate: 0.00615068
	LOSS [training: 1.089050333101722 | validation: 1.232747842037655]
	TIME [epoch: 9.67 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1213116115250916		[learning rate: 0.0061362]
	Learning Rate: 0.00613617
	LOSS [training: 1.1213116115250916 | validation: 0.9546571084029393]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0227197258646052		[learning rate: 0.0061217]
	Learning Rate: 0.0061217
	LOSS [training: 1.0227197258646052 | validation: 1.3258658545248563]
	TIME [epoch: 9.65 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.164783964112464		[learning rate: 0.0061073]
	Learning Rate: 0.00610726
	LOSS [training: 1.164783964112464 | validation: 1.6810647347847538]
	TIME [epoch: 9.66 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2281551199463343		[learning rate: 0.0060929]
	Learning Rate: 0.00609285
	LOSS [training: 1.2281551199463343 | validation: 1.0636293422111167]
	TIME [epoch: 9.67 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1591054522700985		[learning rate: 0.0060785]
	Learning Rate: 0.00607848
	LOSS [training: 1.1591054522700985 | validation: 1.5148545544390992]
	TIME [epoch: 9.65 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.092033493542873		[learning rate: 0.0060641]
	Learning Rate: 0.00606414
	LOSS [training: 1.092033493542873 | validation: 1.2360218571613406]
	TIME [epoch: 9.66 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.187636591484741		[learning rate: 0.0060498]
	Learning Rate: 0.00604984
	LOSS [training: 1.187636591484741 | validation: 1.1818598294141835]
	TIME [epoch: 9.66 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.203870442803043		[learning rate: 0.0060356]
	Learning Rate: 0.00603556
	LOSS [training: 1.203870442803043 | validation: 1.2964409333490496]
	TIME [epoch: 9.66 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1105066895370268		[learning rate: 0.0060213]
	Learning Rate: 0.00602133
	LOSS [training: 1.1105066895370268 | validation: 1.0315987238635587]
	TIME [epoch: 9.65 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.115117114026076		[learning rate: 0.0060071]
	Learning Rate: 0.00600712
	LOSS [training: 1.115117114026076 | validation: 0.8227997283972256]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.803845273831487		[learning rate: 0.005993]
	Learning Rate: 0.00599296
	LOSS [training: 1.803845273831487 | validation: 2.848185112562299]
	TIME [epoch: 9.68 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.529753615398461		[learning rate: 0.0059788]
	Learning Rate: 0.00597882
	LOSS [training: 1.529753615398461 | validation: 1.3528701839260049]
	TIME [epoch: 9.65 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0269645919335195		[learning rate: 0.0059647]
	Learning Rate: 0.00596472
	LOSS [training: 1.0269645919335195 | validation: 1.0462242868432328]
	TIME [epoch: 9.65 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0480704471785978		[learning rate: 0.0059506]
	Learning Rate: 0.00595065
	LOSS [training: 1.0480704471785978 | validation: 0.9251624871998158]
	TIME [epoch: 9.65 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2130319767145425		[learning rate: 0.0059366]
	Learning Rate: 0.00593661
	LOSS [training: 1.2130319767145425 | validation: 1.6886262031232802]
	TIME [epoch: 9.67 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2272745444750905		[learning rate: 0.0059226]
	Learning Rate: 0.00592261
	LOSS [training: 1.2272745444750905 | validation: 1.2570405103855722]
	TIME [epoch: 9.66 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9940837436263982		[learning rate: 0.0059086]
	Learning Rate: 0.00590863
	LOSS [training: 0.9940837436263982 | validation: 1.2968116288208396]
	TIME [epoch: 9.67 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.082754883297742		[learning rate: 0.0058947]
	Learning Rate: 0.0058947
	LOSS [training: 1.082754883297742 | validation: 1.1471597456102602]
	TIME [epoch: 9.68 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9618065761632011		[learning rate: 0.0058808]
	Learning Rate: 0.00588079
	LOSS [training: 0.9618065761632011 | validation: 1.7828553761971466]
	TIME [epoch: 9.66 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0469920883625936		[learning rate: 0.0058669]
	Learning Rate: 0.00586692
	LOSS [training: 1.0469920883625936 | validation: 1.0415110413907704]
	TIME [epoch: 9.65 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3859641769716553		[learning rate: 0.0058531]
	Learning Rate: 0.00585308
	LOSS [training: 1.3859641769716553 | validation: 1.1895154957883254]
	TIME [epoch: 9.67 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1098741830222123		[learning rate: 0.0058393]
	Learning Rate: 0.00583928
	LOSS [training: 1.1098741830222123 | validation: 1.2259538646377945]
	TIME [epoch: 9.66 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9158137305354715		[learning rate: 0.0058255]
	Learning Rate: 0.0058255
	LOSS [training: 0.9158137305354715 | validation: 1.3283610427314672]
	TIME [epoch: 9.65 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.851446544803828		[learning rate: 0.0058118]
	Learning Rate: 0.00581176
	LOSS [training: 1.851446544803828 | validation: 1.3897182758127264]
	TIME [epoch: 9.65 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4103785873565526		[learning rate: 0.0057981]
	Learning Rate: 0.00579805
	LOSS [training: 1.4103785873565526 | validation: 1.112136220484353]
	TIME [epoch: 9.67 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0513779214577617		[learning rate: 0.0057844]
	Learning Rate: 0.00578438
	LOSS [training: 1.0513779214577617 | validation: 0.9929224500572242]
	TIME [epoch: 9.65 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9338896011580253		[learning rate: 0.0057707]
	Learning Rate: 0.00577073
	LOSS [training: 0.9338896011580253 | validation: 0.8040499617943491]
	TIME [epoch: 9.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_283.pth
	Model improved!!!
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9345374276780645		[learning rate: 0.0057571]
	Learning Rate: 0.00575712
	LOSS [training: 0.9345374276780645 | validation: 1.2147286345224881]
	TIME [epoch: 9.67 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0775569914014418		[learning rate: 0.0057435]
	Learning Rate: 0.00574354
	LOSS [training: 1.0775569914014418 | validation: 1.0766661499578367]
	TIME [epoch: 9.65 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9954792136062004		[learning rate: 0.00573]
	Learning Rate: 0.00572999
	LOSS [training: 0.9954792136062004 | validation: 1.2072376468954553]
	TIME [epoch: 9.65 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0894801330402526		[learning rate: 0.0057165]
	Learning Rate: 0.00571647
	LOSS [training: 1.0894801330402526 | validation: 1.5944081122808065]
	TIME [epoch: 9.64 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2518511892981201		[learning rate: 0.005703]
	Learning Rate: 0.00570299
	LOSS [training: 1.2518511892981201 | validation: 1.1332513381246327]
	TIME [epoch: 9.67 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.951923974905089		[learning rate: 0.0056895]
	Learning Rate: 0.00568954
	LOSS [training: 0.951923974905089 | validation: 0.9888783512919382]
	TIME [epoch: 9.65 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3910027472989588		[learning rate: 0.0056761]
	Learning Rate: 0.00567612
	LOSS [training: 1.3910027472989588 | validation: 2.7461914151429974]
	TIME [epoch: 9.64 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0483864671789425		[learning rate: 0.0056627]
	Learning Rate: 0.00566273
	LOSS [training: 2.0483864671789425 | validation: 2.1070277298868065]
	TIME [epoch: 9.66 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.411847932027877		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 1.411847932027877 | validation: 1.6324423242636377]
	TIME [epoch: 9.66 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4113817275319076		[learning rate: 0.005636]
	Learning Rate: 0.00563604
	LOSS [training: 1.4113817275319076 | validation: 1.2898414583530682]
	TIME [epoch: 9.65 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1138261011734225		[learning rate: 0.0056227]
	Learning Rate: 0.00562275
	LOSS [training: 1.1138261011734225 | validation: 0.8419165066022799]
	TIME [epoch: 9.65 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8491519701105957		[learning rate: 0.0056095]
	Learning Rate: 0.00560949
	LOSS [training: 0.8491519701105957 | validation: 0.9691864218318458]
	TIME [epoch: 9.67 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9147898967990857		[learning rate: 0.0055963]
	Learning Rate: 0.00559625
	LOSS [training: 0.9147898967990857 | validation: 1.4133754054669343]
	TIME [epoch: 9.66 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.007866072718691		[learning rate: 0.0055831]
	Learning Rate: 0.00558305
	LOSS [training: 1.007866072718691 | validation: 1.0892372430461834]
	TIME [epoch: 9.66 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9241406935106623		[learning rate: 0.0055699]
	Learning Rate: 0.00556988
	LOSS [training: 0.9241406935106623 | validation: 1.0416400065102787]
	TIME [epoch: 9.68 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5577611044130555		[learning rate: 0.0055567]
	Learning Rate: 0.00555674
	LOSS [training: 1.5577611044130555 | validation: 2.3830846389748355]
	TIME [epoch: 9.67 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.670153244293046		[learning rate: 0.0055436]
	Learning Rate: 0.00554364
	LOSS [training: 1.670153244293046 | validation: 1.3640198788706368]
	TIME [epoch: 9.66 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0400176914887667		[learning rate: 0.0055306]
	Learning Rate: 0.00553056
	LOSS [training: 1.0400176914887667 | validation: 0.8247933370043754]
	TIME [epoch: 9.65 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8818780404279039		[learning rate: 0.0055175]
	Learning Rate: 0.00551752
	LOSS [training: 0.8818780404279039 | validation: 0.9460644924707863]
	TIME [epoch: 9.68 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.939710468186328		[learning rate: 0.0055045]
	Learning Rate: 0.0055045
	LOSS [training: 0.939710468186328 | validation: 0.9448717909576931]
	TIME [epoch: 9.66 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9264364854017266		[learning rate: 0.0054915]
	Learning Rate: 0.00549152
	LOSS [training: 0.9264364854017266 | validation: 0.9613360170155189]
	TIME [epoch: 9.65 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4626801756316294		[learning rate: 0.0054786]
	Learning Rate: 0.00547856
	LOSS [training: 1.4626801756316294 | validation: 1.0804964847191314]
	TIME [epoch: 9.68 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.952318404597294		[learning rate: 0.0054656]
	Learning Rate: 0.00546564
	LOSS [training: 0.952318404597294 | validation: 0.9368489010489651]
	TIME [epoch: 9.66 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.925188323585709		[learning rate: 0.0054527]
	Learning Rate: 0.00545275
	LOSS [training: 0.925188323585709 | validation: 1.3047919426977759]
	TIME [epoch: 9.67 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8647254685655945		[learning rate: 0.0054399]
	Learning Rate: 0.00543988
	LOSS [training: 0.8647254685655945 | validation: 1.4648766036800986]
	TIME [epoch: 9.66 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9878358309337283		[learning rate: 0.0054271]
	Learning Rate: 0.00542705
	LOSS [training: 0.9878358309337283 | validation: 0.9993420999181285]
	TIME [epoch: 9.68 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8800667141887875		[learning rate: 0.0054143]
	Learning Rate: 0.00541425
	LOSS [training: 0.8800667141887875 | validation: 1.123896025913791]
	TIME [epoch: 9.65 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.221684090881873		[learning rate: 0.0054015]
	Learning Rate: 0.00540148
	LOSS [training: 1.221684090881873 | validation: 0.9320073089550428]
	TIME [epoch: 9.65 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.946035765221828		[learning rate: 0.0053887]
	Learning Rate: 0.00538874
	LOSS [training: 0.946035765221828 | validation: 0.9698572800580857]
	TIME [epoch: 9.7 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8612866595674002		[learning rate: 0.005376]
	Learning Rate: 0.00537603
	LOSS [training: 0.8612866595674002 | validation: 0.7192287790189942]
	TIME [epoch: 9.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9462964073562858		[learning rate: 0.0053633]
	Learning Rate: 0.00536335
	LOSS [training: 0.9462964073562858 | validation: 1.0997271404959446]
	TIME [epoch: 9.67 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9140865085475912		[learning rate: 0.0053507]
	Learning Rate: 0.00535069
	LOSS [training: 0.9140865085475912 | validation: 1.5148559322151034]
	TIME [epoch: 9.67 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9326908913476719		[learning rate: 0.0053381]
	Learning Rate: 0.00533807
	LOSS [training: 0.9326908913476719 | validation: 0.8787802718734584]
	TIME [epoch: 9.67 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8028380038635505		[learning rate: 0.0053255]
	Learning Rate: 0.00532548
	LOSS [training: 0.8028380038635505 | validation: 1.3568494732242695]
	TIME [epoch: 9.66 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8560141058128898		[learning rate: 0.0053129]
	Learning Rate: 0.00531292
	LOSS [training: 0.8560141058128898 | validation: 0.9866158477294401]
	TIME [epoch: 9.66 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8643573223437391		[learning rate: 0.0053004]
	Learning Rate: 0.00530039
	LOSS [training: 0.8643573223437391 | validation: 0.9138929825546722]
	TIME [epoch: 9.68 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0801066083497317		[learning rate: 0.0052879]
	Learning Rate: 0.00528789
	LOSS [training: 1.0801066083497317 | validation: 0.9164263599013869]
	TIME [epoch: 9.66 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.850308579266476		[learning rate: 0.0052754]
	Learning Rate: 0.00527541
	LOSS [training: 0.850308579266476 | validation: 1.4507518171856355]
	TIME [epoch: 9.65 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0997418936089312		[learning rate: 0.005263]
	Learning Rate: 0.00526297
	LOSS [training: 1.0997418936089312 | validation: 1.0014765348968755]
	TIME [epoch: 9.66 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9323088597447381		[learning rate: 0.0052506]
	Learning Rate: 0.00525055
	LOSS [training: 0.9323088597447381 | validation: 0.7317182978255298]
	TIME [epoch: 9.67 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7385015568161719		[learning rate: 0.0052382]
	Learning Rate: 0.00523817
	LOSS [training: 0.7385015568161719 | validation: 0.8536426435116741]
	TIME [epoch: 9.66 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8772771909735513		[learning rate: 0.0052258]
	Learning Rate: 0.00522581
	LOSS [training: 0.8772771909735513 | validation: 0.8358897153105919]
	TIME [epoch: 9.67 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8952500306839223		[learning rate: 0.0052135]
	Learning Rate: 0.00521349
	LOSS [training: 0.8952500306839223 | validation: 0.8639422239065803]
	TIME [epoch: 9.68 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.88372093372707		[learning rate: 0.0052012]
	Learning Rate: 0.00520119
	LOSS [training: 0.88372093372707 | validation: 0.7621854419459021]
	TIME [epoch: 9.65 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8695024211655215		[learning rate: 0.0051889]
	Learning Rate: 0.00518892
	LOSS [training: 0.8695024211655215 | validation: 1.0928149372810243]
	TIME [epoch: 9.66 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8881580679993185		[learning rate: 0.0051767]
	Learning Rate: 0.00517668
	LOSS [training: 0.8881580679993185 | validation: 0.8978529097273181]
	TIME [epoch: 9.68 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7065619211025423		[learning rate: 0.0051645]
	Learning Rate: 0.00516447
	LOSS [training: 0.7065619211025423 | validation: 1.1648012057745971]
	TIME [epoch: 9.67 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2660445901631316		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 1.2660445901631316 | validation: 0.7387354781697075]
	TIME [epoch: 9.66 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6778265429570276		[learning rate: 0.0051401]
	Learning Rate: 0.00514013
	LOSS [training: 0.6778265429570276 | validation: 1.1485759998868599]
	TIME [epoch: 9.65 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.831741873318434		[learning rate: 0.005128]
	Learning Rate: 0.00512801
	LOSS [training: 0.831741873318434 | validation: 1.1495426558561481]
	TIME [epoch: 9.67 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9804033269744604		[learning rate: 0.0051159]
	Learning Rate: 0.00511591
	LOSS [training: 0.9804033269744604 | validation: 1.1411857072120866]
	TIME [epoch: 9.65 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1196611652407333		[learning rate: 0.0051038]
	Learning Rate: 0.00510384
	LOSS [training: 1.1196611652407333 | validation: 0.7657029507266414]
	TIME [epoch: 9.66 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8169841228349842		[learning rate: 0.0050918]
	Learning Rate: 0.00509181
	LOSS [training: 0.8169841228349842 | validation: 0.5853300532474768]
	TIME [epoch: 9.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7418061193060138		[learning rate: 0.0050798]
	Learning Rate: 0.00507979
	LOSS [training: 0.7418061193060138 | validation: 0.5720870915713598]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_337.pth
	Model improved!!!
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6886113081816412		[learning rate: 0.0050678]
	Learning Rate: 0.00506781
	LOSS [training: 0.6886113081816412 | validation: 0.832520185475656]
	TIME [epoch: 9.67 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8725235023296877		[learning rate: 0.0050559]
	Learning Rate: 0.00505586
	LOSS [training: 0.8725235023296877 | validation: 1.3780370653145293]
	TIME [epoch: 9.66 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0741537873226181		[learning rate: 0.0050439]
	Learning Rate: 0.00504393
	LOSS [training: 1.0741537873226181 | validation: 1.1406818100448113]
	TIME [epoch: 9.68 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0282833869578507		[learning rate: 0.005032]
	Learning Rate: 0.00503203
	LOSS [training: 1.0282833869578507 | validation: 0.612706172828249]
	TIME [epoch: 9.65 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.628051917245355		[learning rate: 0.0050202]
	Learning Rate: 0.00502016
	LOSS [training: 0.628051917245355 | validation: 0.7924710031009543]
	TIME [epoch: 9.66 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6501256813488138		[learning rate: 0.0050083]
	Learning Rate: 0.00500832
	LOSS [training: 0.6501256813488138 | validation: 0.630689631327089]
	TIME [epoch: 9.66 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.632392886984196		[learning rate: 0.0049965]
	Learning Rate: 0.00499651
	LOSS [training: 0.632392886984196 | validation: 0.8001686354235281]
	TIME [epoch: 9.67 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6630442302502058		[learning rate: 0.0049847]
	Learning Rate: 0.00498472
	LOSS [training: 0.6630442302502058 | validation: 1.5065758341429012]
	TIME [epoch: 9.65 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0158747816545624		[learning rate: 0.004973]
	Learning Rate: 0.00497296
	LOSS [training: 1.0158747816545624 | validation: 0.6426024671011501]
	TIME [epoch: 9.65 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7872510393245816		[learning rate: 0.0049612]
	Learning Rate: 0.00496123
	LOSS [training: 0.7872510393245816 | validation: 0.7713454747858165]
	TIME [epoch: 9.67 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9080785045282529		[learning rate: 0.0049495]
	Learning Rate: 0.00494953
	LOSS [training: 0.9080785045282529 | validation: 0.6786919465559208]
	TIME [epoch: 9.65 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6458755666693154		[learning rate: 0.0049379]
	Learning Rate: 0.00493786
	LOSS [training: 0.6458755666693154 | validation: 0.7494889640066046]
	TIME [epoch: 9.65 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.826653618209248		[learning rate: 0.0049262]
	Learning Rate: 0.00492621
	LOSS [training: 0.826653618209248 | validation: 0.7831534298473067]
	TIME [epoch: 9.67 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7557339833648884		[learning rate: 0.0049146]
	Learning Rate: 0.00491459
	LOSS [training: 0.7557339833648884 | validation: 0.7199531191820091]
	TIME [epoch: 9.66 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7958752261915842		[learning rate: 0.004903]
	Learning Rate: 0.004903
	LOSS [training: 0.7958752261915842 | validation: 0.6152039654820504]
	TIME [epoch: 9.65 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9163534644124566		[learning rate: 0.0048914]
	Learning Rate: 0.00489143
	LOSS [training: 0.9163534644124566 | validation: 0.7033750390699504]
	TIME [epoch: 9.66 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2755139102086475		[learning rate: 0.0048799]
	Learning Rate: 0.00487989
	LOSS [training: 1.2755139102086475 | validation: 1.6023595270839175]
	TIME [epoch: 9.69 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0341282027585337		[learning rate: 0.0048684]
	Learning Rate: 0.00486838
	LOSS [training: 1.0341282027585337 | validation: 0.5607315075145143]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_355.pth
	Model improved!!!
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6347815715940424		[learning rate: 0.0048569]
	Learning Rate: 0.0048569
	LOSS [training: 0.6347815715940424 | validation: 0.8109426230881875]
	TIME [epoch: 9.66 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8993731976250435		[learning rate: 0.0048454]
	Learning Rate: 0.00484544
	LOSS [training: 0.8993731976250435 | validation: 0.8544561008006926]
	TIME [epoch: 9.69 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7890877454572667		[learning rate: 0.004834]
	Learning Rate: 0.00483401
	LOSS [training: 0.7890877454572667 | validation: 0.8589770907968624]
	TIME [epoch: 9.69 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7562286987853998		[learning rate: 0.0048226]
	Learning Rate: 0.00482261
	LOSS [training: 0.7562286987853998 | validation: 0.6335391993694129]
	TIME [epoch: 9.66 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7495681523227055		[learning rate: 0.0048112]
	Learning Rate: 0.00481123
	LOSS [training: 0.7495681523227055 | validation: 0.8685405571775564]
	TIME [epoch: 9.67 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7761221166199348		[learning rate: 0.0047999]
	Learning Rate: 0.00479988
	LOSS [training: 0.7761221166199348 | validation: 0.6239997627737883]
	TIME [epoch: 9.69 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8223268232377551		[learning rate: 0.0047886]
	Learning Rate: 0.00478856
	LOSS [training: 0.8223268232377551 | validation: 0.4592285411664525]
	TIME [epoch: 9.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_362.pth
	Model improved!!!
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7022245870091707		[learning rate: 0.0047773]
	Learning Rate: 0.00477727
	LOSS [training: 0.7022245870091707 | validation: 1.420698879573552]
	TIME [epoch: 9.68 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8625088676329273		[learning rate: 0.004766]
	Learning Rate: 0.004766
	LOSS [training: 0.8625088676329273 | validation: 0.5588776140425737]
	TIME [epoch: 9.68 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7196201776075571		[learning rate: 0.0047548]
	Learning Rate: 0.00475476
	LOSS [training: 0.7196201776075571 | validation: 1.8053956483974023]
	TIME [epoch: 9.67 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.864348758949054		[learning rate: 0.0047435]
	Learning Rate: 0.00474354
	LOSS [training: 0.864348758949054 | validation: 0.7573297883946067]
	TIME [epoch: 9.67 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.690596088687945		[learning rate: 0.0047324]
	Learning Rate: 0.00473235
	LOSS [training: 0.690596088687945 | validation: 0.861441233189653]
	TIME [epoch: 9.66 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6347506952339939		[learning rate: 0.0047212]
	Learning Rate: 0.00472119
	LOSS [training: 0.6347506952339939 | validation: 0.9783449338044622]
	TIME [epoch: 9.68 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7844148686051524		[learning rate: 0.0047101]
	Learning Rate: 0.00471005
	LOSS [training: 0.7844148686051524 | validation: 1.3364134524985127]
	TIME [epoch: 9.66 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8890380305531801		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 0.8890380305531801 | validation: 0.8031069089491389]
	TIME [epoch: 9.66 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7211307328433074		[learning rate: 0.0046879]
	Learning Rate: 0.00468786
	LOSS [training: 0.7211307328433074 | validation: 0.5327361744600541]
	TIME [epoch: 9.67 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6395936802970658		[learning rate: 0.0046768]
	Learning Rate: 0.0046768
	LOSS [training: 0.6395936802970658 | validation: 0.7389503701019424]
	TIME [epoch: 9.68 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6554109400852928		[learning rate: 0.0046658]
	Learning Rate: 0.00466577
	LOSS [training: 0.6554109400852928 | validation: 0.8030047014125004]
	TIME [epoch: 9.66 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8547531616887593		[learning rate: 0.0046548]
	Learning Rate: 0.00465476
	LOSS [training: 0.8547531616887593 | validation: 1.4507212470487765]
	TIME [epoch: 9.66 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2177900943564535		[learning rate: 0.0046438]
	Learning Rate: 0.00464378
	LOSS [training: 1.2177900943564535 | validation: 0.8254233030666541]
	TIME [epoch: 9.68 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0072384471154892		[learning rate: 0.0046328]
	Learning Rate: 0.00463283
	LOSS [training: 1.0072384471154892 | validation: 1.4366485910162254]
	TIME [epoch: 9.66 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1128419772743208		[learning rate: 0.0046219]
	Learning Rate: 0.0046219
	LOSS [training: 1.1128419772743208 | validation: 0.7056265526582877]
	TIME [epoch: 9.66 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8562248744994099		[learning rate: 0.004611]
	Learning Rate: 0.004611
	LOSS [training: 0.8562248744994099 | validation: 0.9486782957333064]
	TIME [epoch: 9.67 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0871532407469573		[learning rate: 0.0046001]
	Learning Rate: 0.00460012
	LOSS [training: 1.0871532407469573 | validation: 0.873993228985525]
	TIME [epoch: 9.67 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8703788885969063		[learning rate: 0.0045893]
	Learning Rate: 0.00458927
	LOSS [training: 0.8703788885969063 | validation: 1.196816416852836]
	TIME [epoch: 9.66 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9711337744344615		[learning rate: 0.0045784]
	Learning Rate: 0.00457844
	LOSS [training: 0.9711337744344615 | validation: 0.6218350205961256]
	TIME [epoch: 9.65 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8915292804678341		[learning rate: 0.0045676]
	Learning Rate: 0.00456765
	LOSS [training: 0.8915292804678341 | validation: 0.8991021245841821]
	TIME [epoch: 9.68 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8954243570320923		[learning rate: 0.0045569]
	Learning Rate: 0.00455687
	LOSS [training: 0.8954243570320923 | validation: 0.55666969161413]
	TIME [epoch: 9.66 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6389359000229431		[learning rate: 0.0045461]
	Learning Rate: 0.00454612
	LOSS [training: 0.6389359000229431 | validation: 0.6330051461885126]
	TIME [epoch: 9.66 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7533894983220512		[learning rate: 0.0045354]
	Learning Rate: 0.0045354
	LOSS [training: 0.7533894983220512 | validation: 0.9561720279714655]
	TIME [epoch: 9.69 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7939621602399283		[learning rate: 0.0045247]
	Learning Rate: 0.0045247
	LOSS [training: 0.7939621602399283 | validation: 0.8645371399514743]
	TIME [epoch: 9.67 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7848343550502285		[learning rate: 0.004514]
	Learning Rate: 0.00451403
	LOSS [training: 0.7848343550502285 | validation: 0.8760175321404251]
	TIME [epoch: 9.66 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.724786120663437		[learning rate: 0.0045034]
	Learning Rate: 0.00450338
	LOSS [training: 0.724786120663437 | validation: 1.21829825034699]
	TIME [epoch: 9.66 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9466208650793716		[learning rate: 0.0044928]
	Learning Rate: 0.00449276
	LOSS [training: 0.9466208650793716 | validation: 0.6113990728493562]
	TIME [epoch: 9.68 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6847055699595375		[learning rate: 0.0044822]
	Learning Rate: 0.00448216
	LOSS [training: 0.6847055699595375 | validation: 0.9704018550871105]
	TIME [epoch: 9.66 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7740446761798653		[learning rate: 0.0044716]
	Learning Rate: 0.00447159
	LOSS [training: 0.7740446761798653 | validation: 0.703519636911007]
	TIME [epoch: 9.66 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7508818928429184		[learning rate: 0.004461]
	Learning Rate: 0.00446104
	LOSS [training: 0.7508818928429184 | validation: 0.6731253490974518]
	TIME [epoch: 9.69 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6455794676978683		[learning rate: 0.0044505]
	Learning Rate: 0.00445051
	LOSS [training: 0.6455794676978683 | validation: 0.7587355214092603]
	TIME [epoch: 9.66 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9285283497961039		[learning rate: 0.00444]
	Learning Rate: 0.00444002
	LOSS [training: 0.9285283497961039 | validation: 0.5906538930056788]
	TIME [epoch: 9.66 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.56925115595629		[learning rate: 0.0044295]
	Learning Rate: 0.00442954
	LOSS [training: 0.56925115595629 | validation: 0.7217524415596006]
	TIME [epoch: 9.66 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6824682451170555		[learning rate: 0.0044191]
	Learning Rate: 0.00441909
	LOSS [training: 0.6824682451170555 | validation: 0.5840617120320774]
	TIME [epoch: 9.68 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6570526175758208		[learning rate: 0.0044087]
	Learning Rate: 0.00440867
	LOSS [training: 0.6570526175758208 | validation: 0.5695132525270655]
	TIME [epoch: 9.66 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6005724820210638		[learning rate: 0.0043983]
	Learning Rate: 0.00439827
	LOSS [training: 0.6005724820210638 | validation: 0.6504618324127802]
	TIME [epoch: 9.66 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5801135621635922		[learning rate: 0.0043879]
	Learning Rate: 0.0043879
	LOSS [training: 0.5801135621635922 | validation: 0.4698003290927922]
	TIME [epoch: 9.69 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.669571826119687		[learning rate: 0.0043775]
	Learning Rate: 0.00437755
	LOSS [training: 0.669571826119687 | validation: 1.1584395426515048]
	TIME [epoch: 9.66 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7864681558135869		[learning rate: 0.0043672]
	Learning Rate: 0.00436722
	LOSS [training: 0.7864681558135869 | validation: 0.5223277905856386]
	TIME [epoch: 9.66 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6513069625118076		[learning rate: 0.0043569]
	Learning Rate: 0.00435692
	LOSS [training: 0.6513069625118076 | validation: 0.5034019230184151]
	TIME [epoch: 9.67 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7239242875377405		[learning rate: 0.0043466]
	Learning Rate: 0.00434664
	LOSS [training: 0.7239242875377405 | validation: 0.8206692497758649]
	TIME [epoch: 9.67 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7038064813974084		[learning rate: 0.0043364]
	Learning Rate: 0.00433639
	LOSS [training: 0.7038064813974084 | validation: 0.9175573475813549]
	TIME [epoch: 9.66 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8219765628776512		[learning rate: 0.0043262]
	Learning Rate: 0.00432616
	LOSS [training: 0.8219765628776512 | validation: 1.5217425956535524]
	TIME [epoch: 9.66 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.007058767327631		[learning rate: 0.004316]
	Learning Rate: 0.00431596
	LOSS [training: 1.007058767327631 | validation: 1.3256405250609526]
	TIME [epoch: 9.68 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9439416826836797		[learning rate: 0.0043058]
	Learning Rate: 0.00430577
	LOSS [training: 0.9439416826836797 | validation: 0.6351645147436197]
	TIME [epoch: 9.66 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5588758783347253		[learning rate: 0.0042956]
	Learning Rate: 0.00429562
	LOSS [training: 0.5588758783347253 | validation: 0.9726028627263014]
	TIME [epoch: 9.66 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6975726078330365		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 0.6975726078330365 | validation: 0.8270800476122157]
	TIME [epoch: 9.68 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6592133750927212		[learning rate: 0.0042754]
	Learning Rate: 0.00427538
	LOSS [training: 0.6592133750927212 | validation: 0.6330684437746771]
	TIME [epoch: 9.66 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6294380078362767		[learning rate: 0.0042653]
	Learning Rate: 0.00426529
	LOSS [training: 0.6294380078362767 | validation: 0.5677850278979617]
	TIME [epoch: 9.66 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6266394083686391		[learning rate: 0.0042552]
	Learning Rate: 0.00425523
	LOSS [training: 0.6266394083686391 | validation: 0.6092313254689267]
	TIME [epoch: 9.66 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.582359218165084		[learning rate: 0.0042452]
	Learning Rate: 0.00424519
	LOSS [training: 0.582359218165084 | validation: 0.5988945227518218]
	TIME [epoch: 9.67 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6453740923851374		[learning rate: 0.0042352]
	Learning Rate: 0.00423518
	LOSS [training: 0.6453740923851374 | validation: 0.5701919548483566]
	TIME [epoch: 9.66 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6080988147863077		[learning rate: 0.0042252]
	Learning Rate: 0.00422519
	LOSS [training: 0.6080988147863077 | validation: 0.5894931903187738]
	TIME [epoch: 9.65 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6450606207897281		[learning rate: 0.0042152]
	Learning Rate: 0.00421522
	LOSS [training: 0.6450606207897281 | validation: 0.7004833295128722]
	TIME [epoch: 9.68 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6845280069261548		[learning rate: 0.0042053]
	Learning Rate: 0.00420528
	LOSS [training: 0.6845280069261548 | validation: 0.4603749466818089]
	TIME [epoch: 9.66 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5206082525800435		[learning rate: 0.0041954]
	Learning Rate: 0.00419536
	LOSS [training: 0.5206082525800435 | validation: 0.5037630094877238]
	TIME [epoch: 9.66 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5549961379264235		[learning rate: 0.0041855]
	Learning Rate: 0.00418546
	LOSS [training: 0.5549961379264235 | validation: 0.758969749923984]
	TIME [epoch: 9.67 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7764067691619374		[learning rate: 0.0041756]
	Learning Rate: 0.00417559
	LOSS [training: 0.7764067691619374 | validation: 1.6602233549825958]
	TIME [epoch: 9.67 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.202982762285647		[learning rate: 0.0041657]
	Learning Rate: 0.00416574
	LOSS [training: 1.202982762285647 | validation: 0.676004066900533]
	TIME [epoch: 9.65 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8874929323034785		[learning rate: 0.0041559]
	Learning Rate: 0.00415592
	LOSS [training: 0.8874929323034785 | validation: 1.2994436747780975]
	TIME [epoch: 9.65 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0097585165973082		[learning rate: 0.0041461]
	Learning Rate: 0.00414611
	LOSS [training: 1.0097585165973082 | validation: 0.7295662505352332]
	TIME [epoch: 9.68 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9018956678885399		[learning rate: 0.0041363]
	Learning Rate: 0.00413633
	LOSS [training: 0.9018956678885399 | validation: 1.6015563532877999]
	TIME [epoch: 9.66 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9095166537538397		[learning rate: 0.0041266]
	Learning Rate: 0.00412657
	LOSS [training: 0.9095166537538397 | validation: 0.5729214991540011]
	TIME [epoch: 9.65 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8537499048843786		[learning rate: 0.0041168]
	Learning Rate: 0.00411684
	LOSS [training: 0.8537499048843786 | validation: 0.49844851294529796]
	TIME [epoch: 9.67 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6264020354147322		[learning rate: 0.0041071]
	Learning Rate: 0.00410713
	LOSS [training: 0.6264020354147322 | validation: 0.5324704617863797]
	TIME [epoch: 9.66 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6323683352796875		[learning rate: 0.0040974]
	Learning Rate: 0.00409744
	LOSS [training: 0.6323683352796875 | validation: 0.6906470448765458]
	TIME [epoch: 9.65 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.622702232489599		[learning rate: 0.0040878]
	Learning Rate: 0.00408778
	LOSS [training: 0.622702232489599 | validation: 0.5944794636408478]
	TIME [epoch: 9.65 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.703785156029274		[learning rate: 0.0040781]
	Learning Rate: 0.00407813
	LOSS [training: 0.703785156029274 | validation: 1.0075185555278179]
	TIME [epoch: 9.68 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7358967178254291		[learning rate: 0.0040685]
	Learning Rate: 0.00406851
	LOSS [training: 0.7358967178254291 | validation: 0.5011400426912888]
	TIME [epoch: 9.66 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5057305455023507		[learning rate: 0.0040589]
	Learning Rate: 0.00405892
	LOSS [training: 0.5057305455023507 | validation: 0.6318530462267086]
	TIME [epoch: 9.65 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5502852019914526		[learning rate: 0.0040493]
	Learning Rate: 0.00404934
	LOSS [training: 0.5502852019914526 | validation: 0.6959832772593839]
	TIME [epoch: 9.68 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.562571621254518		[learning rate: 0.0040398]
	Learning Rate: 0.00403979
	LOSS [training: 0.562571621254518 | validation: 0.7009618862474796]
	TIME [epoch: 9.66 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6549237142737392		[learning rate: 0.0040303]
	Learning Rate: 0.00403026
	LOSS [training: 0.6549237142737392 | validation: 0.6231786148972615]
	TIME [epoch: 9.66 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5912080119531862		[learning rate: 0.0040208]
	Learning Rate: 0.00402076
	LOSS [training: 0.5912080119531862 | validation: 0.41493141294942604]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5367042055461522		[learning rate: 0.0040113]
	Learning Rate: 0.00401127
	LOSS [training: 0.5367042055461522 | validation: 0.7604097548563737]
	TIME [epoch: 9.67 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5477771803673646		[learning rate: 0.0040018]
	Learning Rate: 0.00400181
	LOSS [training: 0.5477771803673646 | validation: 0.4681125499951668]
	TIME [epoch: 9.66 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6350375133836028		[learning rate: 0.0039924]
	Learning Rate: 0.00399237
	LOSS [training: 0.6350375133836028 | validation: 0.5286813140087897]
	TIME [epoch: 9.66 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7691168431780994		[learning rate: 0.003983]
	Learning Rate: 0.00398295
	LOSS [training: 0.7691168431780994 | validation: 1.0247937145042538]
	TIME [epoch: 9.69 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6959925590823091		[learning rate: 0.0039736]
	Learning Rate: 0.00397356
	LOSS [training: 0.6959925590823091 | validation: 0.5943405443674815]
	TIME [epoch: 9.67 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.596124300580793		[learning rate: 0.0039642]
	Learning Rate: 0.00396418
	LOSS [training: 0.596124300580793 | validation: 0.3991995616374264]
	TIME [epoch: 9.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_442.pth
	Model improved!!!
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5213943066215396		[learning rate: 0.0039548]
	Learning Rate: 0.00395483
	LOSS [training: 0.5213943066215396 | validation: 0.6886670972902684]
	TIME [epoch: 9.66 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8781558017113411		[learning rate: 0.0039455]
	Learning Rate: 0.0039455
	LOSS [training: 0.8781558017113411 | validation: 1.126388420817277]
	TIME [epoch: 9.66 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8698323915324423		[learning rate: 0.0039362]
	Learning Rate: 0.0039362
	LOSS [training: 0.8698323915324423 | validation: 0.4388558278292933]
	TIME [epoch: 9.65 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8939437945188049		[learning rate: 0.0039269]
	Learning Rate: 0.00392691
	LOSS [training: 0.8939437945188049 | validation: 1.0245408300706433]
	TIME [epoch: 9.65 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.812181339456098		[learning rate: 0.0039176]
	Learning Rate: 0.00391765
	LOSS [training: 0.812181339456098 | validation: 0.5720946282977196]
	TIME [epoch: 9.67 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5947710594601107		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 0.5947710594601107 | validation: 0.573593598751033]
	TIME [epoch: 9.66 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6865243276552495		[learning rate: 0.0038992]
	Learning Rate: 0.00389919
	LOSS [training: 0.6865243276552495 | validation: 0.6125638004527885]
	TIME [epoch: 9.65 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.800475484262496		[learning rate: 0.00389]
	Learning Rate: 0.00388999
	LOSS [training: 0.800475484262496 | validation: 0.7248336716603367]
	TIME [epoch: 9.65 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9636685138776191		[learning rate: 0.0038808]
	Learning Rate: 0.00388082
	LOSS [training: 0.9636685138776191 | validation: 1.1322892339740869]
	TIME [epoch: 9.68 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8120223777112191		[learning rate: 0.0038717]
	Learning Rate: 0.00387166
	LOSS [training: 0.8120223777112191 | validation: 0.5009160797896199]
	TIME [epoch: 9.65 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6680128868955363		[learning rate: 0.0038625]
	Learning Rate: 0.00386253
	LOSS [training: 0.6680128868955363 | validation: 0.7498383983114664]
	TIME [epoch: 9.66 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5558066905634559		[learning rate: 0.0038534]
	Learning Rate: 0.00385342
	LOSS [training: 0.5558066905634559 | validation: 0.5379621985134763]
	TIME [epoch: 9.68 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6024108521019882		[learning rate: 0.0038443]
	Learning Rate: 0.00384433
	LOSS [training: 0.6024108521019882 | validation: 0.5723188770386288]
	TIME [epoch: 9.66 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6419196068292663		[learning rate: 0.0038353]
	Learning Rate: 0.00383526
	LOSS [training: 0.6419196068292663 | validation: 0.5604916646170427]
	TIME [epoch: 9.65 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6301282808394554		[learning rate: 0.0038262]
	Learning Rate: 0.00382621
	LOSS [training: 0.6301282808394554 | validation: 0.4679214354425338]
	TIME [epoch: 9.65 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5257778103884082		[learning rate: 0.0038172]
	Learning Rate: 0.00381719
	LOSS [training: 0.5257778103884082 | validation: 0.5534673117392227]
	TIME [epoch: 9.68 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5779077387351995		[learning rate: 0.0038082]
	Learning Rate: 0.00380818
	LOSS [training: 0.5779077387351995 | validation: 0.4553844116809967]
	TIME [epoch: 9.65 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7528520967828892		[learning rate: 0.0037992]
	Learning Rate: 0.0037992
	LOSS [training: 0.7528520967828892 | validation: 1.0442822045936675]
	TIME [epoch: 9.65 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.787551748036537		[learning rate: 0.0037902]
	Learning Rate: 0.00379024
	LOSS [training: 0.787551748036537 | validation: 0.6094311907794904]
	TIME [epoch: 9.67 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5808689031494716		[learning rate: 0.0037813]
	Learning Rate: 0.0037813
	LOSS [training: 0.5808689031494716 | validation: 0.4794295776625922]
	TIME [epoch: 9.65 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4570699332446351		[learning rate: 0.0037724]
	Learning Rate: 0.00377238
	LOSS [training: 0.4570699332446351 | validation: 0.6024801123044943]
	TIME [epoch: 9.66 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5443901792922025		[learning rate: 0.0037635]
	Learning Rate: 0.00376348
	LOSS [training: 0.5443901792922025 | validation: 0.4661137722217626]
	TIME [epoch: 9.66 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6419532564079922		[learning rate: 0.0037546]
	Learning Rate: 0.0037546
	LOSS [training: 0.6419532564079922 | validation: 0.8508962839179305]
	TIME [epoch: 9.67 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7746727055001347		[learning rate: 0.0037457]
	Learning Rate: 0.00374575
	LOSS [training: 0.7746727055001347 | validation: 0.5977297699856221]
	TIME [epoch: 9.65 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6392765305566998		[learning rate: 0.0037369]
	Learning Rate: 0.00373691
	LOSS [training: 0.6392765305566998 | validation: 0.5074905328340416]
	TIME [epoch: 9.65 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6063570971066639		[learning rate: 0.0037281]
	Learning Rate: 0.0037281
	LOSS [training: 0.6063570971066639 | validation: 0.5378115946808505]
	TIME [epoch: 9.68 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6854357186656908		[learning rate: 0.0037193]
	Learning Rate: 0.0037193
	LOSS [training: 0.6854357186656908 | validation: 0.5560427867991016]
	TIME [epoch: 9.65 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.556013621960084		[learning rate: 0.0037105]
	Learning Rate: 0.00371053
	LOSS [training: 0.556013621960084 | validation: 0.8550011386580093]
	TIME [epoch: 9.66 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6614405090938031		[learning rate: 0.0037018]
	Learning Rate: 0.00370178
	LOSS [training: 0.6614405090938031 | validation: 0.5737155199185909]
	TIME [epoch: 9.67 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5736509500331135		[learning rate: 0.003693]
	Learning Rate: 0.00369304
	LOSS [training: 0.5736509500331135 | validation: 0.711093035120103]
	TIME [epoch: 9.67 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5599809534055824		[learning rate: 0.0036843]
	Learning Rate: 0.00368433
	LOSS [training: 0.5599809534055824 | validation: 0.9626488799895253]
	TIME [epoch: 9.66 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8185365472455022		[learning rate: 0.0036756]
	Learning Rate: 0.00367564
	LOSS [training: 0.8185365472455022 | validation: 0.5607647951414562]
	TIME [epoch: 9.65 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48082797661169796		[learning rate: 0.003667]
	Learning Rate: 0.00366697
	LOSS [training: 0.48082797661169796 | validation: 0.7227861160133371]
	TIME [epoch: 9.68 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7633055931588195		[learning rate: 0.0036583]
	Learning Rate: 0.00365832
	LOSS [training: 0.7633055931588195 | validation: 0.46187311568731837]
	TIME [epoch: 9.65 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6512198053304793		[learning rate: 0.0036497]
	Learning Rate: 0.00364969
	LOSS [training: 0.6512198053304793 | validation: 0.7609013632141699]
	TIME [epoch: 9.65 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5961745035884969		[learning rate: 0.0036411]
	Learning Rate: 0.00364108
	LOSS [training: 0.5961745035884969 | validation: 0.4685765237277424]
	TIME [epoch: 9.67 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5525698623903432		[learning rate: 0.0036325]
	Learning Rate: 0.0036325
	LOSS [training: 0.5525698623903432 | validation: 0.4558046824264089]
	TIME [epoch: 9.66 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5718749617914957		[learning rate: 0.0036239]
	Learning Rate: 0.00362393
	LOSS [training: 0.5718749617914957 | validation: 0.6666882777480225]
	TIME [epoch: 9.65 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5842811173655376		[learning rate: 0.0036154]
	Learning Rate: 0.00361538
	LOSS [training: 0.5842811173655376 | validation: 0.42929379689332264]
	TIME [epoch: 9.66 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5475940232895108		[learning rate: 0.0036069]
	Learning Rate: 0.00360685
	LOSS [training: 0.5475940232895108 | validation: 0.5615261744698187]
	TIME [epoch: 9.68 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.628664732290549		[learning rate: 0.0035983]
	Learning Rate: 0.00359834
	LOSS [training: 0.628664732290549 | validation: 0.9888728222022352]
	TIME [epoch: 9.66 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6672138099739964		[learning rate: 0.0035899]
	Learning Rate: 0.00358986
	LOSS [training: 0.6672138099739964 | validation: 0.41351604668395764]
	TIME [epoch: 9.65 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5266866941884233		[learning rate: 0.0035814]
	Learning Rate: 0.00358139
	LOSS [training: 0.5266866941884233 | validation: 0.6970129868931343]
	TIME [epoch: 9.68 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6414843020412111		[learning rate: 0.0035729]
	Learning Rate: 0.00357294
	LOSS [training: 0.6414843020412111 | validation: 1.061521592508679]
	TIME [epoch: 9.66 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.649514582861621		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 0.649514582861621 | validation: 0.8093425559093634]
	TIME [epoch: 9.65 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7078923895538358		[learning rate: 0.0035561]
	Learning Rate: 0.0035561
	LOSS [training: 0.7078923895538358 | validation: 0.6580071827197334]
	TIME [epoch: 9.66 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6063518535241744		[learning rate: 0.0035477]
	Learning Rate: 0.00354771
	LOSS [training: 0.6063518535241744 | validation: 0.6905069138896517]
	TIME [epoch: 9.68 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5360302947961093		[learning rate: 0.0035393]
	Learning Rate: 0.00353935
	LOSS [training: 0.5360302947961093 | validation: 0.38037030297634233]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_490.pth
	Model improved!!!
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5759619431957698		[learning rate: 0.003531]
	Learning Rate: 0.003531
	LOSS [training: 0.5759619431957698 | validation: 0.530495881572828]
	TIME [epoch: 9.65 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5682078354552861		[learning rate: 0.0035227]
	Learning Rate: 0.00352267
	LOSS [training: 0.5682078354552861 | validation: 0.4201115444626244]
	TIME [epoch: 9.67 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49972966710185923		[learning rate: 0.0035144]
	Learning Rate: 0.00351436
	LOSS [training: 0.49972966710185923 | validation: 0.6558051748285496]
	TIME [epoch: 9.65 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4849732646451007		[learning rate: 0.0035061]
	Learning Rate: 0.00350607
	LOSS [training: 0.4849732646451007 | validation: 0.41406758772515145]
	TIME [epoch: 9.65 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5192269511841479		[learning rate: 0.0034978]
	Learning Rate: 0.0034978
	LOSS [training: 0.5192269511841479 | validation: 0.36564344744171495]
	TIME [epoch: 9.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_495.pth
	Model improved!!!
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45717047054935656		[learning rate: 0.0034895]
	Learning Rate: 0.00348955
	LOSS [training: 0.45717047054935656 | validation: 0.5713691774864019]
	TIME [epoch: 9.68 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5547544832758653		[learning rate: 0.0034813]
	Learning Rate: 0.00348132
	LOSS [training: 0.5547544832758653 | validation: 0.42314815749105167]
	TIME [epoch: 9.66 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5764575025975883		[learning rate: 0.0034731]
	Learning Rate: 0.00347311
	LOSS [training: 0.5764575025975883 | validation: 0.5587474353346931]
	TIME [epoch: 9.66 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4999579468904095		[learning rate: 0.0034649]
	Learning Rate: 0.00346491
	LOSS [training: 0.4999579468904095 | validation: 0.5249739562869212]
	TIME [epoch: 9.67 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.574650896729037		[learning rate: 0.0034567]
	Learning Rate: 0.00345674
	LOSS [training: 0.574650896729037 | validation: 0.5028190061364086]
	TIME [epoch: 9.67 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7069538851617924		[learning rate: 0.0034486]
	Learning Rate: 0.00344859
	LOSS [training: 0.7069538851617924 | validation: 0.7320074789574069]
	TIME [epoch: 9.66 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7316730070042372		[learning rate: 0.0034405]
	Learning Rate: 0.00344045
	LOSS [training: 0.7316730070042372 | validation: 0.6199630849552878]
	TIME [epoch: 9.66 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5954615543862795		[learning rate: 0.0034323]
	Learning Rate: 0.00343234
	LOSS [training: 0.5954615543862795 | validation: 0.7749567434556727]
	TIME [epoch: 9.68 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6951851855667943		[learning rate: 0.0034242]
	Learning Rate: 0.00342424
	LOSS [training: 0.6951851855667943 | validation: 0.5049096326285678]
	TIME [epoch: 9.66 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7021911383492171		[learning rate: 0.0034162]
	Learning Rate: 0.00341616
	LOSS [training: 0.7021911383492171 | validation: 0.4618232179439438]
	TIME [epoch: 9.65 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6264047388150819		[learning rate: 0.0034081]
	Learning Rate: 0.0034081
	LOSS [training: 0.6264047388150819 | validation: 1.3708193513388869]
	TIME [epoch: 9.68 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5937357837156563		[learning rate: 0.0034001]
	Learning Rate: 0.00340006
	LOSS [training: 0.5937357837156563 | validation: 0.5569990719258864]
	TIME [epoch: 9.66 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4352464633059799		[learning rate: 0.003392]
	Learning Rate: 0.00339204
	LOSS [training: 0.4352464633059799 | validation: 0.6948800107188171]
	TIME [epoch: 9.66 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5592664749769207		[learning rate: 0.003384]
	Learning Rate: 0.00338404
	LOSS [training: 0.5592664749769207 | validation: 0.6009549576764772]
	TIME [epoch: 9.66 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47207551703151446		[learning rate: 0.0033761]
	Learning Rate: 0.00337606
	LOSS [training: 0.47207551703151446 | validation: 0.8433092321685912]
	TIME [epoch: 9.68 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5268945482062427		[learning rate: 0.0033681]
	Learning Rate: 0.0033681
	LOSS [training: 0.5268945482062427 | validation: 0.5521630780628253]
	TIME [epoch: 9.66 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4953722794750438		[learning rate: 0.0033602]
	Learning Rate: 0.00336015
	LOSS [training: 0.4953722794750438 | validation: 0.8708126281558985]
	TIME [epoch: 9.66 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6376699834269672		[learning rate: 0.0033522]
	Learning Rate: 0.00335223
	LOSS [training: 0.6376699834269672 | validation: 0.5497879311274566]
	TIME [epoch: 9.69 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5805579388355826		[learning rate: 0.0033443]
	Learning Rate: 0.00334432
	LOSS [training: 0.5805579388355826 | validation: 0.8336851408255452]
	TIME [epoch: 9.66 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5628418762240581		[learning rate: 0.0033364]
	Learning Rate: 0.00333643
	LOSS [training: 0.5628418762240581 | validation: 0.7120432837946702]
	TIME [epoch: 9.67 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4799918486167192		[learning rate: 0.0033286]
	Learning Rate: 0.00332856
	LOSS [training: 0.4799918486167192 | validation: 0.4648355666622813]
	TIME [epoch: 9.66 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5217291252405094		[learning rate: 0.0033207]
	Learning Rate: 0.00332071
	LOSS [training: 0.5217291252405094 | validation: 0.537412737277956]
	TIME [epoch: 9.67 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43214510771248865		[learning rate: 0.0033129]
	Learning Rate: 0.00331288
	LOSS [training: 0.43214510771248865 | validation: 0.4209485637089292]
	TIME [epoch: 9.66 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0507283070804831		[learning rate: 0.0033051]
	Learning Rate: 0.00330506
	LOSS [training: 1.0507283070804831 | validation: 1.0634024077327453]
	TIME [epoch: 9.66 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6868988724448064		[learning rate: 0.0032973]
	Learning Rate: 0.00329727
	LOSS [training: 0.6868988724448064 | validation: 0.4607704436792952]
	TIME [epoch: 9.68 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5593917199592668		[learning rate: 0.0032895]
	Learning Rate: 0.00328949
	LOSS [training: 0.5593917199592668 | validation: 0.48930032563981757]
	TIME [epoch: 9.65 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5156350101857115		[learning rate: 0.0032817]
	Learning Rate: 0.00328173
	LOSS [training: 0.5156350101857115 | validation: 0.4541237093320728]
	TIME [epoch: 9.66 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5128146719134444		[learning rate: 0.003274]
	Learning Rate: 0.00327399
	LOSS [training: 0.5128146719134444 | validation: 0.5397224812687762]
	TIME [epoch: 9.67 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5538310000713295		[learning rate: 0.0032663]
	Learning Rate: 0.00326626
	LOSS [training: 0.5538310000713295 | validation: 0.7244162506461156]
	TIME [epoch: 9.67 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5391835012198057		[learning rate: 0.0032586]
	Learning Rate: 0.00325856
	LOSS [training: 0.5391835012198057 | validation: 0.526079259832246]
	TIME [epoch: 9.66 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6374956995452645		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 0.6374956995452645 | validation: 0.43418958762339777]
	TIME [epoch: 9.66 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5314590296702214		[learning rate: 0.0032432]
	Learning Rate: 0.0032432
	LOSS [training: 0.5314590296702214 | validation: 0.5573949623556465]
	TIME [epoch: 9.68 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4504960431912127		[learning rate: 0.0032356]
	Learning Rate: 0.00323555
	LOSS [training: 0.4504960431912127 | validation: 0.45614064797808496]
	TIME [epoch: 9.65 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6139649310259297		[learning rate: 0.0032279]
	Learning Rate: 0.00322792
	LOSS [training: 0.6139649310259297 | validation: 0.863091881046544]
	TIME [epoch: 9.67 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6132814318144109		[learning rate: 0.0032203]
	Learning Rate: 0.00322031
	LOSS [training: 0.6132814318144109 | validation: 1.5897527048177902]
	TIME [epoch: 9.67 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6612354941414307		[learning rate: 0.0032127]
	Learning Rate: 0.00321271
	LOSS [training: 0.6612354941414307 | validation: 0.5360359793647129]
	TIME [epoch: 9.67 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4962316569467037		[learning rate: 0.0032051]
	Learning Rate: 0.00320513
	LOSS [training: 0.4962316569467037 | validation: 0.49547673276014964]
	TIME [epoch: 9.66 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4754237403873214		[learning rate: 0.0031976]
	Learning Rate: 0.00319757
	LOSS [training: 0.4754237403873214 | validation: 0.4284076273364392]
	TIME [epoch: 9.66 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5440129803987179		[learning rate: 0.00319]
	Learning Rate: 0.00319003
	LOSS [training: 0.5440129803987179 | validation: 0.5401427672277983]
	TIME [epoch: 9.67 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6596434079567817		[learning rate: 0.0031825]
	Learning Rate: 0.00318251
	LOSS [training: 0.6596434079567817 | validation: 0.6847803851998444]
	TIME [epoch: 9.66 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45231417936802887		[learning rate: 0.003175]
	Learning Rate: 0.003175
	LOSS [training: 0.45231417936802887 | validation: 0.42968114632909415]
	TIME [epoch: 9.65 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6146867337711194		[learning rate: 0.0031675]
	Learning Rate: 0.00316751
	LOSS [training: 0.6146867337711194 | validation: 1.2309825772879646]
	TIME [epoch: 9.68 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7372409351384211		[learning rate: 0.00316]
	Learning Rate: 0.00316004
	LOSS [training: 0.7372409351384211 | validation: 0.5526810435115428]
	TIME [epoch: 9.67 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6844590239257522		[learning rate: 0.0031526]
	Learning Rate: 0.00315258
	LOSS [training: 0.6844590239257522 | validation: 0.6533566412721318]
	TIME [epoch: 9.66 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5488654635130752		[learning rate: 0.0031451]
	Learning Rate: 0.00314515
	LOSS [training: 0.5488654635130752 | validation: 0.5725686229330298]
	TIME [epoch: 9.67 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5878173532187663		[learning rate: 0.0031377]
	Learning Rate: 0.00313773
	LOSS [training: 0.5878173532187663 | validation: 0.5163510955012341]
	TIME [epoch: 9.69 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.502899248697567		[learning rate: 0.0031303]
	Learning Rate: 0.00313033
	LOSS [training: 0.502899248697567 | validation: 0.7759410458414968]
	TIME [epoch: 9.67 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5916284290473147		[learning rate: 0.0031229]
	Learning Rate: 0.00312294
	LOSS [training: 0.5916284290473147 | validation: 0.6516017047643929]
	TIME [epoch: 9.66 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5525851635609929		[learning rate: 0.0031156]
	Learning Rate: 0.00311558
	LOSS [training: 0.5525851635609929 | validation: 0.557115787468113]
	TIME [epoch: 9.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5247295138290899		[learning rate: 0.0031082]
	Learning Rate: 0.00310823
	LOSS [training: 0.5247295138290899 | validation: 0.5435820948301208]
	TIME [epoch: 9.67 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5830322673084772		[learning rate: 0.0031009]
	Learning Rate: 0.0031009
	LOSS [training: 0.5830322673084772 | validation: 0.5757674905333504]
	TIME [epoch: 9.65 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6260296954366347		[learning rate: 0.0030936]
	Learning Rate: 0.00309358
	LOSS [training: 0.6260296954366347 | validation: 0.6902406377811073]
	TIME [epoch: 9.67 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5684886398542479		[learning rate: 0.0030863]
	Learning Rate: 0.00308628
	LOSS [training: 0.5684886398542479 | validation: 0.5257437481587629]
	TIME [epoch: 9.67 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6093569161336462		[learning rate: 0.003079]
	Learning Rate: 0.003079
	LOSS [training: 0.6093569161336462 | validation: 0.3430082646749631]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_549.pth
	Model improved!!!
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4590231363781033		[learning rate: 0.0030717]
	Learning Rate: 0.00307174
	LOSS [training: 0.4590231363781033 | validation: 0.8934307631810703]
	TIME [epoch: 9.67 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46403850857341267		[learning rate: 0.0030645]
	Learning Rate: 0.0030645
	LOSS [training: 0.46403850857341267 | validation: 0.42899851568732167]
	TIME [epoch: 9.69 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.605690246716088		[learning rate: 0.0030573]
	Learning Rate: 0.00305727
	LOSS [training: 0.605690246716088 | validation: 0.500485248907017]
	TIME [epoch: 9.67 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5046659687009539		[learning rate: 0.0030501]
	Learning Rate: 0.00305006
	LOSS [training: 0.5046659687009539 | validation: 0.5471104980453804]
	TIME [epoch: 9.67 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.683271738788424		[learning rate: 0.0030429]
	Learning Rate: 0.00304286
	LOSS [training: 0.683271738788424 | validation: 0.8418094571037072]
	TIME [epoch: 9.67 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.589886309099459		[learning rate: 0.0030357]
	Learning Rate: 0.00303568
	LOSS [training: 0.589886309099459 | validation: 0.5935750612150598]
	TIME [epoch: 9.68 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46138649771733925		[learning rate: 0.0030285]
	Learning Rate: 0.00302852
	LOSS [training: 0.46138649771733925 | validation: 0.6738085374664371]
	TIME [epoch: 9.67 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45772871607063337		[learning rate: 0.0030214]
	Learning Rate: 0.00302138
	LOSS [training: 0.45772871607063337 | validation: 0.543844187365824]
	TIME [epoch: 9.66 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49865895696535273		[learning rate: 0.0030143]
	Learning Rate: 0.00301425
	LOSS [training: 0.49865895696535273 | validation: 0.5239156676769194]
	TIME [epoch: 9.69 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49248481586848636		[learning rate: 0.0030071]
	Learning Rate: 0.00300714
	LOSS [training: 0.49248481586848636 | validation: 0.43877246989997026]
	TIME [epoch: 9.66 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48316808106272335		[learning rate: 0.003]
	Learning Rate: 0.00300005
	LOSS [training: 0.48316808106272335 | validation: 0.4417393228882351]
	TIME [epoch: 9.66 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4807285805810162		[learning rate: 0.002993]
	Learning Rate: 0.00299297
	LOSS [training: 0.4807285805810162 | validation: 0.4920585546310791]
	TIME [epoch: 9.68 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5339979703768762		[learning rate: 0.0029859]
	Learning Rate: 0.00298591
	LOSS [training: 0.5339979703768762 | validation: 0.49492043103630023]
	TIME [epoch: 9.67 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4648098432253723		[learning rate: 0.0029789]
	Learning Rate: 0.00297887
	LOSS [training: 0.4648098432253723 | validation: 0.3797005285373372]
	TIME [epoch: 9.66 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5010905592087986		[learning rate: 0.0029718]
	Learning Rate: 0.00297184
	LOSS [training: 0.5010905592087986 | validation: 0.6202143174223903]
	TIME [epoch: 9.66 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46681855292488017		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 0.46681855292488017 | validation: 0.5144277625830147]
	TIME [epoch: 9.68 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4647691425906218		[learning rate: 0.0029578]
	Learning Rate: 0.00295784
	LOSS [training: 0.4647691425906218 | validation: 0.5194215362740368]
	TIME [epoch: 9.65 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46458815434489253		[learning rate: 0.0029509]
	Learning Rate: 0.00295086
	LOSS [training: 0.46458815434489253 | validation: 0.5456616572168113]
	TIME [epoch: 9.66 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.502635576584899		[learning rate: 0.0029439]
	Learning Rate: 0.0029439
	LOSS [training: 0.502635576584899 | validation: 0.5384934241258381]
	TIME [epoch: 9.68 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5700631894392535		[learning rate: 0.002937]
	Learning Rate: 0.00293696
	LOSS [training: 0.5700631894392535 | validation: 0.8078765460401772]
	TIME [epoch: 9.67 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.564095003568949		[learning rate: 0.00293]
	Learning Rate: 0.00293003
	LOSS [training: 0.564095003568949 | validation: 0.37667060503335725]
	TIME [epoch: 9.67 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5188900414287044		[learning rate: 0.0029231]
	Learning Rate: 0.00292312
	LOSS [training: 0.5188900414287044 | validation: 0.598077205661231]
	TIME [epoch: 9.66 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5297346863889472		[learning rate: 0.0029162]
	Learning Rate: 0.00291622
	LOSS [training: 0.5297346863889472 | validation: 0.5961694310937212]
	TIME [epoch: 9.68 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4567108902394913		[learning rate: 0.0029093]
	Learning Rate: 0.00290934
	LOSS [training: 0.4567108902394913 | validation: 0.4582869154803021]
	TIME [epoch: 9.66 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43709025038293453		[learning rate: 0.0029025]
	Learning Rate: 0.00290248
	LOSS [training: 0.43709025038293453 | validation: 0.5677847460336279]
	TIME [epoch: 9.68 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5467652955382969		[learning rate: 0.0028956]
	Learning Rate: 0.00289563
	LOSS [training: 0.5467652955382969 | validation: 0.5961601480810899]
	TIME [epoch: 9.69 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.453857406286867		[learning rate: 0.0028888]
	Learning Rate: 0.0028888
	LOSS [training: 0.453857406286867 | validation: 0.6606572304893998]
	TIME [epoch: 9.68 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4798627708650244		[learning rate: 0.002882]
	Learning Rate: 0.00288199
	LOSS [training: 0.4798627708650244 | validation: 0.3509114029883796]
	TIME [epoch: 9.65 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8002643066010056		[learning rate: 0.0028752]
	Learning Rate: 0.00287519
	LOSS [training: 0.8002643066010056 | validation: 1.3927482823782862]
	TIME [epoch: 9.66 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7061387968573859		[learning rate: 0.0028684]
	Learning Rate: 0.00286841
	LOSS [training: 0.7061387968573859 | validation: 0.5676583518942202]
	TIME [epoch: 9.68 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5289733319763938		[learning rate: 0.0028616]
	Learning Rate: 0.00286164
	LOSS [training: 0.5289733319763938 | validation: 0.6118016030503545]
	TIME [epoch: 9.67 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5370358575994032		[learning rate: 0.0028549]
	Learning Rate: 0.00285489
	LOSS [training: 0.5370358575994032 | validation: 0.5106873185459788]
	TIME [epoch: 9.67 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40646860460947687		[learning rate: 0.0028482]
	Learning Rate: 0.00284816
	LOSS [training: 0.40646860460947687 | validation: 0.6253436770880392]
	TIME [epoch: 9.69 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47854007568748136		[learning rate: 0.0028414]
	Learning Rate: 0.00284144
	LOSS [training: 0.47854007568748136 | validation: 0.48386601540648555]
	TIME [epoch: 9.66 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44671240496981623		[learning rate: 0.0028347]
	Learning Rate: 0.00283474
	LOSS [training: 0.44671240496981623 | validation: 0.6344848318351015]
	TIME [epoch: 9.67 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4292518185201158		[learning rate: 0.0028281]
	Learning Rate: 0.00282805
	LOSS [training: 0.4292518185201158 | validation: 0.5674274192490101]
	TIME [epoch: 9.69 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4227165176046812		[learning rate: 0.0028214]
	Learning Rate: 0.00282138
	LOSS [training: 0.4227165176046812 | validation: 0.3968928105878186]
	TIME [epoch: 9.67 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47195214135135244		[learning rate: 0.0028147]
	Learning Rate: 0.00281472
	LOSS [training: 0.47195214135135244 | validation: 0.4447954639534346]
	TIME [epoch: 9.66 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5355988177595516		[learning rate: 0.0028081]
	Learning Rate: 0.00280808
	LOSS [training: 0.5355988177595516 | validation: 0.5160459197989735]
	TIME [epoch: 9.66 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.643473682709929		[learning rate: 0.0028015]
	Learning Rate: 0.00280146
	LOSS [training: 0.643473682709929 | validation: 0.528352403587586]
	TIME [epoch: 9.68 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4933667657380737		[learning rate: 0.0027949]
	Learning Rate: 0.00279485
	LOSS [training: 0.4933667657380737 | validation: 0.523899527158964]
	TIME [epoch: 9.66 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4224740290006417		[learning rate: 0.0027883]
	Learning Rate: 0.00278826
	LOSS [training: 0.4224740290006417 | validation: 0.3962384717097882]
	TIME [epoch: 9.66 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4118519116580327		[learning rate: 0.0027817]
	Learning Rate: 0.00278168
	LOSS [training: 0.4118519116580327 | validation: 0.8531550590374186]
	TIME [epoch: 9.68 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5271535030673608		[learning rate: 0.0027751]
	Learning Rate: 0.00277512
	LOSS [training: 0.5271535030673608 | validation: 0.6258235042052492]
	TIME [epoch: 9.67 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45113157973839046		[learning rate: 0.0027686]
	Learning Rate: 0.00276858
	LOSS [training: 0.45113157973839046 | validation: 0.5286241028527612]
	TIME [epoch: 9.67 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4856668156369162		[learning rate: 0.002762]
	Learning Rate: 0.00276205
	LOSS [training: 0.4856668156369162 | validation: 0.5275809730210546]
	TIME [epoch: 9.68 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3825420734305302		[learning rate: 0.0027555]
	Learning Rate: 0.00275553
	LOSS [training: 0.3825420734305302 | validation: 0.5257796374649436]
	TIME [epoch: 9.69 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4695282190731633		[learning rate: 0.002749]
	Learning Rate: 0.00274903
	LOSS [training: 0.4695282190731633 | validation: 0.5702207097261626]
	TIME [epoch: 9.67 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40172479043542986		[learning rate: 0.0027425]
	Learning Rate: 0.00274255
	LOSS [training: 0.40172479043542986 | validation: 0.5230331526037485]
	TIME [epoch: 9.67 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45870072977298043		[learning rate: 0.0027361]
	Learning Rate: 0.00273608
	LOSS [training: 0.45870072977298043 | validation: 0.34084305026648426]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_599.pth
	Model improved!!!
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7279462745025775		[learning rate: 0.0027296]
	Learning Rate: 0.00272962
	LOSS [training: 0.7279462745025775 | validation: 0.4777968066099503]
	TIME [epoch: 9.67 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43627484255298354		[learning rate: 0.0027232]
	Learning Rate: 0.00272318
	LOSS [training: 0.43627484255298354 | validation: 0.4728455533804511]
	TIME [epoch: 9.67 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4007556746603134		[learning rate: 0.0027168]
	Learning Rate: 0.00271676
	LOSS [training: 0.4007556746603134 | validation: 0.6098141063620098]
	TIME [epoch: 9.68 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42696026345731736		[learning rate: 0.0027104]
	Learning Rate: 0.00271035
	LOSS [training: 0.42696026345731736 | validation: 0.379373236983316]
	TIME [epoch: 9.67 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41222952359708265		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 0.41222952359708265 | validation: 0.3624170807530541]
	TIME [epoch: 9.67 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35730736054427015		[learning rate: 0.0026976]
	Learning Rate: 0.00269758
	LOSS [training: 0.35730736054427015 | validation: 0.5464846991486403]
	TIME [epoch: 9.66 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4234027837324382		[learning rate: 0.0026912]
	Learning Rate: 0.00269122
	LOSS [training: 0.4234027837324382 | validation: 0.4620788803192171]
	TIME [epoch: 9.67 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5369542496080182		[learning rate: 0.0026849]
	Learning Rate: 0.00268487
	LOSS [training: 0.5369542496080182 | validation: 0.6481502492261063]
	TIME [epoch: 9.67 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6630260604619265		[learning rate: 0.0026785]
	Learning Rate: 0.00267854
	LOSS [training: 0.6630260604619265 | validation: 0.5021315154117393]
	TIME [epoch: 9.66 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5948041794733929		[learning rate: 0.0026722]
	Learning Rate: 0.00267222
	LOSS [training: 0.5948041794733929 | validation: 0.4033296609447387]
	TIME [epoch: 9.67 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5004167343288498		[learning rate: 0.0026659]
	Learning Rate: 0.00266591
	LOSS [training: 0.5004167343288498 | validation: 0.6307588876594812]
	TIME [epoch: 9.69 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6153415788299186		[learning rate: 0.0026596]
	Learning Rate: 0.00265963
	LOSS [training: 0.6153415788299186 | validation: 0.45542707175624847]
	TIME [epoch: 9.67 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45459754823977844		[learning rate: 0.0026534]
	Learning Rate: 0.00265335
	LOSS [training: 0.45459754823977844 | validation: 0.4531883423032707]
	TIME [epoch: 9.67 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5101535689695403		[learning rate: 0.0026471]
	Learning Rate: 0.00264709
	LOSS [training: 0.5101535689695403 | validation: 0.7300524501164327]
	TIME [epoch: 9.69 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5148335093748733		[learning rate: 0.0026408]
	Learning Rate: 0.00264085
	LOSS [training: 0.5148335093748733 | validation: 0.3672267524008538]
	TIME [epoch: 9.67 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4556946045782226		[learning rate: 0.0026346]
	Learning Rate: 0.00263462
	LOSS [training: 0.4556946045782226 | validation: 0.6512250202209782]
	TIME [epoch: 9.67 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5103643107767131		[learning rate: 0.0026284]
	Learning Rate: 0.00262841
	LOSS [training: 0.5103643107767131 | validation: 0.4068590667374785]
	TIME [epoch: 9.67 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4402843040229296		[learning rate: 0.0026222]
	Learning Rate: 0.00262221
	LOSS [training: 0.4402843040229296 | validation: 0.4228405633305357]
	TIME [epoch: 9.67 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4462517183002184		[learning rate: 0.002616]
	Learning Rate: 0.00261602
	LOSS [training: 0.4462517183002184 | validation: 0.8424968641998234]
	TIME [epoch: 9.66 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5373141428597935		[learning rate: 0.0026098]
	Learning Rate: 0.00260985
	LOSS [training: 0.5373141428597935 | validation: 0.331260583245841]
	TIME [epoch: 9.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_619.pth
	Model improved!!!
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4521305753903988		[learning rate: 0.0026037]
	Learning Rate: 0.00260369
	LOSS [training: 0.4521305753903988 | validation: 0.4480630208349411]
	TIME [epoch: 9.71 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.508335741661169		[learning rate: 0.0025976]
	Learning Rate: 0.00259755
	LOSS [training: 0.508335741661169 | validation: 0.6646859623588901]
	TIME [epoch: 9.68 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5239932509184732		[learning rate: 0.0025914]
	Learning Rate: 0.00259142
	LOSS [training: 0.5239932509184732 | validation: 0.44176961450856556]
	TIME [epoch: 9.67 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46867770509373774		[learning rate: 0.0025853]
	Learning Rate: 0.00258531
	LOSS [training: 0.46867770509373774 | validation: 0.5667839019362145]
	TIME [epoch: 9.69 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42369541796432564		[learning rate: 0.0025792]
	Learning Rate: 0.00257921
	LOSS [training: 0.42369541796432564 | validation: 0.49280194897468643]
	TIME [epoch: 9.69 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38342976388534306		[learning rate: 0.0025731]
	Learning Rate: 0.00257313
	LOSS [training: 0.38342976388534306 | validation: 0.6406625175099024]
	TIME [epoch: 9.68 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43551367458142537		[learning rate: 0.0025671]
	Learning Rate: 0.00256706
	LOSS [training: 0.43551367458142537 | validation: 0.5912724163814499]
	TIME [epoch: 9.67 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5017596979941199		[learning rate: 0.002561]
	Learning Rate: 0.002561
	LOSS [training: 0.5017596979941199 | validation: 0.44890093954329496]
	TIME [epoch: 9.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5337174972093146		[learning rate: 0.002555]
	Learning Rate: 0.00255496
	LOSS [training: 0.5337174972093146 | validation: 0.6027101941329319]
	TIME [epoch: 9.68 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4646017692507664		[learning rate: 0.0025489]
	Learning Rate: 0.00254894
	LOSS [training: 0.4646017692507664 | validation: 0.44391824387456635]
	TIME [epoch: 9.68 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4142919051536545		[learning rate: 0.0025429]
	Learning Rate: 0.00254292
	LOSS [training: 0.4142919051536545 | validation: 0.4667896165713735]
	TIME [epoch: 9.68 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4320203074040528		[learning rate: 0.0025369]
	Learning Rate: 0.00253693
	LOSS [training: 0.4320203074040528 | validation: 0.6153234383678668]
	TIME [epoch: 9.67 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.582616985263488		[learning rate: 0.0025309]
	Learning Rate: 0.00253094
	LOSS [training: 0.582616985263488 | validation: 0.5532878320215988]
	TIME [epoch: 9.67 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5596376532229693		[learning rate: 0.002525]
	Learning Rate: 0.00252497
	LOSS [training: 0.5596376532229693 | validation: 0.4625840741552725]
	TIME [epoch: 9.67 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43871204708250666		[learning rate: 0.002519]
	Learning Rate: 0.00251901
	LOSS [training: 0.43871204708250666 | validation: 0.33907181652494073]
	TIME [epoch: 9.69 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4134818249876907		[learning rate: 0.0025131]
	Learning Rate: 0.00251307
	LOSS [training: 0.4134818249876907 | validation: 0.522606695098333]
	TIME [epoch: 9.68 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.420169980310943		[learning rate: 0.0025071]
	Learning Rate: 0.00250715
	LOSS [training: 0.420169980310943 | validation: 0.3843936038894223]
	TIME [epoch: 9.66 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38707733659033317		[learning rate: 0.0025012]
	Learning Rate: 0.00250123
	LOSS [training: 0.38707733659033317 | validation: 0.33043547786435556]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_637.pth
	Model improved!!!
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47889730793698304		[learning rate: 0.0024953]
	Learning Rate: 0.00249533
	LOSS [training: 0.47889730793698304 | validation: 0.5321537097489459]
	TIME [epoch: 9.67 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43005006981981386		[learning rate: 0.0024894]
	Learning Rate: 0.00248945
	LOSS [training: 0.43005006981981386 | validation: 0.6470852923798157]
	TIME [epoch: 9.66 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4969887580471787		[learning rate: 0.0024836]
	Learning Rate: 0.00248357
	LOSS [training: 0.4969887580471787 | validation: 0.5691664289052172]
	TIME [epoch: 9.66 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.433501087921086		[learning rate: 0.0024777]
	Learning Rate: 0.00247771
	LOSS [training: 0.433501087921086 | validation: 0.3605247263697228]
	TIME [epoch: 9.68 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3546159055436349		[learning rate: 0.0024719]
	Learning Rate: 0.00247187
	LOSS [training: 0.3546159055436349 | validation: 0.36941655914231436]
	TIME [epoch: 9.67 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33840601603286524		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 0.33840601603286524 | validation: 0.4289263607681293]
	TIME [epoch: 9.68 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4440438551172325		[learning rate: 0.0024602]
	Learning Rate: 0.00246022
	LOSS [training: 0.4440438551172325 | validation: 0.7227746730931542]
	TIME [epoch: 9.68 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5548700242969538		[learning rate: 0.0024544]
	Learning Rate: 0.00245442
	LOSS [training: 0.5548700242969538 | validation: 0.41439957796998783]
	TIME [epoch: 9.65 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4515385141932839		[learning rate: 0.0024486]
	Learning Rate: 0.00244863
	LOSS [training: 0.4515385141932839 | validation: 0.419728452289651]
	TIME [epoch: 9.66 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4977554918442043		[learning rate: 0.0024429]
	Learning Rate: 0.00244285
	LOSS [training: 0.4977554918442043 | validation: 0.477890250233919]
	TIME [epoch: 9.65 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4126168577818386		[learning rate: 0.0024371]
	Learning Rate: 0.00243709
	LOSS [training: 0.4126168577818386 | validation: 0.3188465983777972]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_648.pth
	Model improved!!!
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41518254299087076		[learning rate: 0.0024313]
	Learning Rate: 0.00243134
	LOSS [training: 0.41518254299087076 | validation: 0.6039521193254102]
	TIME [epoch: 9.67 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4488840605619238		[learning rate: 0.0024256]
	Learning Rate: 0.00242561
	LOSS [training: 0.4488840605619238 | validation: 0.4634604341049743]
	TIME [epoch: 9.66 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6052046518213092		[learning rate: 0.0024199]
	Learning Rate: 0.00241989
	LOSS [training: 0.6052046518213092 | validation: 0.5966272966906778]
	TIME [epoch: 9.69 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5190688822573777		[learning rate: 0.0024142]
	Learning Rate: 0.00241418
	LOSS [training: 0.5190688822573777 | validation: 0.45849979796497004]
	TIME [epoch: 9.67 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3890761886821748		[learning rate: 0.0024085]
	Learning Rate: 0.00240848
	LOSS [training: 0.3890761886821748 | validation: 0.3614873696878611]
	TIME [epoch: 9.66 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35968385496489863		[learning rate: 0.0024028]
	Learning Rate: 0.0024028
	LOSS [training: 0.35968385496489863 | validation: 0.4847816577302166]
	TIME [epoch: 9.67 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4276660153840032		[learning rate: 0.0023971]
	Learning Rate: 0.00239713
	LOSS [training: 0.4276660153840032 | validation: 0.4190086268743508]
	TIME [epoch: 9.7 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35681721594171123		[learning rate: 0.0023915]
	Learning Rate: 0.00239148
	LOSS [training: 0.35681721594171123 | validation: 0.4116364393117772]
	TIME [epoch: 9.67 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3964243330372451		[learning rate: 0.0023858]
	Learning Rate: 0.00238584
	LOSS [training: 0.3964243330372451 | validation: 0.3751138793488128]
	TIME [epoch: 9.67 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3427627701948002		[learning rate: 0.0023802]
	Learning Rate: 0.00238021
	LOSS [training: 0.3427627701948002 | validation: 0.39757852422468953]
	TIME [epoch: 9.69 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5482691536792724		[learning rate: 0.0023746]
	Learning Rate: 0.0023746
	LOSS [training: 0.5482691536792724 | validation: 0.7104329091472533]
	TIME [epoch: 9.68 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5778883915289745		[learning rate: 0.002369]
	Learning Rate: 0.00236899
	LOSS [training: 0.5778883915289745 | validation: 0.6363213394934211]
	TIME [epoch: 9.66 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6284395963408226		[learning rate: 0.0023634]
	Learning Rate: 0.00236341
	LOSS [training: 0.6284395963408226 | validation: 1.0219026053712983]
	TIME [epoch: 9.67 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.686040354440868		[learning rate: 0.0023578]
	Learning Rate: 0.00235783
	LOSS [training: 0.686040354440868 | validation: 0.43600484328015726]
	TIME [epoch: 9.68 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36121114996704246		[learning rate: 0.0023523]
	Learning Rate: 0.00235227
	LOSS [training: 0.36121114996704246 | validation: 0.3206715273438479]
	TIME [epoch: 9.67 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3977024912075093		[learning rate: 0.0023467]
	Learning Rate: 0.00234672
	LOSS [training: 0.3977024912075093 | validation: 0.32064308557207866]
	TIME [epoch: 9.67 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5625382143111979		[learning rate: 0.0023412]
	Learning Rate: 0.00234119
	LOSS [training: 0.5625382143111979 | validation: 0.40278831287315714]
	TIME [epoch: 9.68 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3966293192176367		[learning rate: 0.0023357]
	Learning Rate: 0.00233566
	LOSS [training: 0.3966293192176367 | validation: 0.4073565827673405]
	TIME [epoch: 9.67 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40302031679017103		[learning rate: 0.0023302]
	Learning Rate: 0.00233015
	LOSS [training: 0.40302031679017103 | validation: 0.38498614105839435]
	TIME [epoch: 9.66 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3848590025089169		[learning rate: 0.0023247]
	Learning Rate: 0.00232466
	LOSS [training: 0.3848590025089169 | validation: 0.5228333160544107]
	TIME [epoch: 9.66 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38757696279097736		[learning rate: 0.0023192]
	Learning Rate: 0.00231917
	LOSS [training: 0.38757696279097736 | validation: 0.48194218798942595]
	TIME [epoch: 9.68 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4604298091622637		[learning rate: 0.0023137]
	Learning Rate: 0.0023137
	LOSS [training: 0.4604298091622637 | validation: 0.47657482688591685]
	TIME [epoch: 9.66 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39152832052188197		[learning rate: 0.0023082]
	Learning Rate: 0.00230825
	LOSS [training: 0.39152832052188197 | validation: 0.48287509033418036]
	TIME [epoch: 9.67 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5196684849906198		[learning rate: 0.0023028]
	Learning Rate: 0.0023028
	LOSS [training: 0.5196684849906198 | validation: 0.34281600766003406]
	TIME [epoch: 9.69 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33872722787587595		[learning rate: 0.0022974]
	Learning Rate: 0.00229737
	LOSS [training: 0.33872722787587595 | validation: 0.34167625805374]
	TIME [epoch: 9.67 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3819718172936541		[learning rate: 0.0022919]
	Learning Rate: 0.00229195
	LOSS [training: 0.3819718172936541 | validation: 0.4587271326263367]
	TIME [epoch: 9.68 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4736402656053225		[learning rate: 0.0022865]
	Learning Rate: 0.00228654
	LOSS [training: 0.4736402656053225 | validation: 0.6072357275869299]
	TIME [epoch: 9.68 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5303145334852027		[learning rate: 0.0022811]
	Learning Rate: 0.00228115
	LOSS [training: 0.5303145334852027 | validation: 0.5480793196447854]
	TIME [epoch: 9.68 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46691485843758473		[learning rate: 0.0022758]
	Learning Rate: 0.00227577
	LOSS [training: 0.46691485843758473 | validation: 0.42030439051447205]
	TIME [epoch: 9.67 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3527538619938775		[learning rate: 0.0022704]
	Learning Rate: 0.0022704
	LOSS [training: 0.3527538619938775 | validation: 0.3326746595195399]
	TIME [epoch: 9.66 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44762339656565386		[learning rate: 0.002265]
	Learning Rate: 0.00226505
	LOSS [training: 0.44762339656565386 | validation: 0.6349832151830475]
	TIME [epoch: 9.69 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4845937084004731		[learning rate: 0.0022597]
	Learning Rate: 0.0022597
	LOSS [training: 0.4845937084004731 | validation: 0.43002215504129226]
	TIME [epoch: 9.66 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41100573277540564		[learning rate: 0.0022544]
	Learning Rate: 0.00225437
	LOSS [training: 0.41100573277540564 | validation: 0.5269077392527524]
	TIME [epoch: 9.66 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4709223433132954		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 0.4709223433132954 | validation: 0.3960827236261247]
	TIME [epoch: 9.7 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4656590008906815		[learning rate: 0.0022437]
	Learning Rate: 0.00224375
	LOSS [training: 0.4656590008906815 | validation: 0.39362467493192327]
	TIME [epoch: 9.68 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3900664998405716		[learning rate: 0.0022385]
	Learning Rate: 0.00223846
	LOSS [training: 0.3900664998405716 | validation: 0.4120839984814799]
	TIME [epoch: 9.66 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3399474695866485		[learning rate: 0.0022332]
	Learning Rate: 0.00223318
	LOSS [training: 0.3399474695866485 | validation: 0.5310666762585393]
	TIME [epoch: 9.68 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47099542546334006		[learning rate: 0.0022279]
	Learning Rate: 0.00222791
	LOSS [training: 0.47099542546334006 | validation: 0.39220711492844185]
	TIME [epoch: 9.69 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34785838629533894		[learning rate: 0.0022227]
	Learning Rate: 0.00222265
	LOSS [training: 0.34785838629533894 | validation: 0.3125330617330135]
	TIME [epoch: 9.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_687.pth
	Model improved!!!
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4161019182471235		[learning rate: 0.0022174]
	Learning Rate: 0.00221741
	LOSS [training: 0.4161019182471235 | validation: 0.5208163888058988]
	TIME [epoch: 9.67 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35177390384241225		[learning rate: 0.0022122]
	Learning Rate: 0.00221218
	LOSS [training: 0.35177390384241225 | validation: 0.29754089398557354]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_689.pth
	Model improved!!!
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35381203542121864		[learning rate: 0.002207]
	Learning Rate: 0.00220696
	LOSS [training: 0.35381203542121864 | validation: 0.43212245072275507]
	TIME [epoch: 9.69 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43416344720814753		[learning rate: 0.0022018]
	Learning Rate: 0.00220176
	LOSS [training: 0.43416344720814753 | validation: 0.3578083363413891]
	TIME [epoch: 9.68 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5490870196113093		[learning rate: 0.0021966]
	Learning Rate: 0.00219656
	LOSS [training: 0.5490870196113093 | validation: 0.37608930639706745]
	TIME [epoch: 9.68 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.566828507484835		[learning rate: 0.0021914]
	Learning Rate: 0.00219138
	LOSS [training: 0.566828507484835 | validation: 0.4008306985867292]
	TIME [epoch: 9.7 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3600587316229779		[learning rate: 0.0021862]
	Learning Rate: 0.00218621
	LOSS [training: 0.3600587316229779 | validation: 0.46462434404377984]
	TIME [epoch: 9.68 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3897848189303854		[learning rate: 0.0021811]
	Learning Rate: 0.00218106
	LOSS [training: 0.3897848189303854 | validation: 0.3530900585461195]
	TIME [epoch: 9.68 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6124644977689094		[learning rate: 0.0021759]
	Learning Rate: 0.00217591
	LOSS [training: 0.6124644977689094 | validation: 0.515981760963547]
	TIME [epoch: 9.69 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35226649128220294		[learning rate: 0.0021708]
	Learning Rate: 0.00217078
	LOSS [training: 0.35226649128220294 | validation: 0.5386653877618285]
	TIME [epoch: 9.68 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43920542409256325		[learning rate: 0.0021657]
	Learning Rate: 0.00216566
	LOSS [training: 0.43920542409256325 | validation: 0.32020311149714287]
	TIME [epoch: 9.68 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4352898095311767		[learning rate: 0.0021605]
	Learning Rate: 0.00216055
	LOSS [training: 0.4352898095311767 | validation: 0.4397824992129209]
	TIME [epoch: 9.68 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34423138937354275		[learning rate: 0.0021555]
	Learning Rate: 0.00215545
	LOSS [training: 0.34423138937354275 | validation: 0.35440138084942285]
	TIME [epoch: 9.7 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33979722581097604		[learning rate: 0.0021504]
	Learning Rate: 0.00215037
	LOSS [training: 0.33979722581097604 | validation: 0.4838412206222585]
	TIME [epoch: 9.68 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33151227707228903		[learning rate: 0.0021453]
	Learning Rate: 0.0021453
	LOSS [training: 0.33151227707228903 | validation: 0.36093989356235634]
	TIME [epoch: 9.68 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4186132627827434		[learning rate: 0.0021402]
	Learning Rate: 0.00214024
	LOSS [training: 0.4186132627827434 | validation: 0.3057536915363825]
	TIME [epoch: 9.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.356911314362325		[learning rate: 0.0021352]
	Learning Rate: 0.00213519
	LOSS [training: 0.356911314362325 | validation: 0.5402571374300926]
	TIME [epoch: 9.68 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39109491330443696		[learning rate: 0.0021302]
	Learning Rate: 0.00213015
	LOSS [training: 0.39109491330443696 | validation: 0.2820427605689301]
	TIME [epoch: 9.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_705.pth
	Model improved!!!
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3240445941614915		[learning rate: 0.0021251]
	Learning Rate: 0.00212513
	LOSS [training: 0.3240445941614915 | validation: 0.2589507245770292]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_706.pth
	Model improved!!!
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35261483744500777		[learning rate: 0.0021201]
	Learning Rate: 0.00212011
	LOSS [training: 0.35261483744500777 | validation: 0.37048087321799683]
	TIME [epoch: 9.71 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4073633357704575		[learning rate: 0.0021151]
	Learning Rate: 0.00211511
	LOSS [training: 0.4073633357704575 | validation: 0.4696516617597294]
	TIME [epoch: 9.69 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3925774906332452		[learning rate: 0.0021101]
	Learning Rate: 0.00211012
	LOSS [training: 0.3925774906332452 | validation: 0.4715404316074641]
	TIME [epoch: 9.69 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38632983325337505		[learning rate: 0.0021051]
	Learning Rate: 0.00210515
	LOSS [training: 0.38632983325337505 | validation: 0.2601734132198029]
	TIME [epoch: 9.69 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4126300677383729		[learning rate: 0.0021002]
	Learning Rate: 0.00210018
	LOSS [training: 0.4126300677383729 | validation: 0.5727105695390702]
	TIME [epoch: 9.68 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39939717148783344		[learning rate: 0.0020952]
	Learning Rate: 0.00209523
	LOSS [training: 0.39939717148783344 | validation: 0.26706793478149105]
	TIME [epoch: 9.68 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.325375751060388		[learning rate: 0.0020903]
	Learning Rate: 0.00209028
	LOSS [training: 0.325375751060388 | validation: 0.577293496029217]
	TIME [epoch: 9.67 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5721165075000394		[learning rate: 0.0020854]
	Learning Rate: 0.00208535
	LOSS [training: 0.5721165075000394 | validation: 0.7930143383999717]
	TIME [epoch: 9.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43619009835003786		[learning rate: 0.0020804]
	Learning Rate: 0.00208043
	LOSS [training: 0.43619009835003786 | validation: 0.3339448558672949]
	TIME [epoch: 9.67 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4403838727557098		[learning rate: 0.0020755]
	Learning Rate: 0.00207553
	LOSS [training: 0.4403838727557098 | validation: 0.49603795688724406]
	TIME [epoch: 9.68 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4619379253485703		[learning rate: 0.0020706]
	Learning Rate: 0.00207063
	LOSS [training: 0.4619379253485703 | validation: 0.6966686033777328]
	TIME [epoch: 9.69 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.368328649850886		[learning rate: 0.0020657]
	Learning Rate: 0.00206575
	LOSS [training: 0.368328649850886 | validation: 0.3951515948015022]
	TIME [epoch: 9.68 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3542900188260958		[learning rate: 0.0020609]
	Learning Rate: 0.00206087
	LOSS [training: 0.3542900188260958 | validation: 0.28455002224532666]
	TIME [epoch: 9.68 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4454487419171561		[learning rate: 0.002056]
	Learning Rate: 0.00205601
	LOSS [training: 0.4454487419171561 | validation: 0.40903563765748263]
	TIME [epoch: 9.69 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4182183285249428		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 0.4182183285249428 | validation: 0.4066628873922541]
	TIME [epoch: 9.71 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5280099389170112		[learning rate: 0.0020463]
	Learning Rate: 0.00204632
	LOSS [training: 0.5280099389170112 | validation: 0.43553171345551905]
	TIME [epoch: 9.69 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3260681622590441		[learning rate: 0.0020415]
	Learning Rate: 0.0020415
	LOSS [training: 0.3260681622590441 | validation: 0.4486865503111575]
	TIME [epoch: 9.69 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3340622865034323		[learning rate: 0.0020367]
	Learning Rate: 0.00203668
	LOSS [training: 0.3340622865034323 | validation: 0.3587649943016204]
	TIME [epoch: 9.71 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32620672210530677		[learning rate: 0.0020319]
	Learning Rate: 0.00203188
	LOSS [training: 0.32620672210530677 | validation: 0.428082971901856]
	TIME [epoch: 9.69 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4236833858559711		[learning rate: 0.0020271]
	Learning Rate: 0.00202708
	LOSS [training: 0.4236833858559711 | validation: 0.597027239789862]
	TIME [epoch: 9.69 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4294303000124275		[learning rate: 0.0020223]
	Learning Rate: 0.0020223
	LOSS [training: 0.4294303000124275 | validation: 0.49232037690675895]
	TIME [epoch: 9.69 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31941653063121417		[learning rate: 0.0020175]
	Learning Rate: 0.00201753
	LOSS [training: 0.31941653063121417 | validation: 0.3139361218469609]
	TIME [epoch: 9.69 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.319503411741366		[learning rate: 0.0020128]
	Learning Rate: 0.00201277
	LOSS [training: 0.319503411741366 | validation: 0.3244528671673952]
	TIME [epoch: 9.69 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35661517406285786		[learning rate: 0.002008]
	Learning Rate: 0.00200803
	LOSS [training: 0.35661517406285786 | validation: 0.4952800866734701]
	TIME [epoch: 9.69 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3339091285226692		[learning rate: 0.0020033]
	Learning Rate: 0.00200329
	LOSS [training: 0.3339091285226692 | validation: 0.2866254589656566]
	TIME [epoch: 9.7 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3913058066421462		[learning rate: 0.0019986]
	Learning Rate: 0.00199856
	LOSS [training: 0.3913058066421462 | validation: 0.3500498664741099]
	TIME [epoch: 9.69 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3151459704033276		[learning rate: 0.0019938]
	Learning Rate: 0.00199385
	LOSS [training: 0.3151459704033276 | validation: 0.3369207772285691]
	TIME [epoch: 9.68 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.426861881328729		[learning rate: 0.0019891]
	Learning Rate: 0.00198915
	LOSS [training: 0.426861881328729 | validation: 0.4316385908324048]
	TIME [epoch: 9.7 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45124145622088746		[learning rate: 0.0019845]
	Learning Rate: 0.00198445
	LOSS [training: 0.45124145622088746 | validation: 0.42067787335617535]
	TIME [epoch: 9.69 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3244207431365126		[learning rate: 0.0019798]
	Learning Rate: 0.00197977
	LOSS [training: 0.3244207431365126 | validation: 0.2855394619959406]
	TIME [epoch: 9.68 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3518517422357347		[learning rate: 0.0019751]
	Learning Rate: 0.0019751
	LOSS [training: 0.3518517422357347 | validation: 0.4891853399577062]
	TIME [epoch: 9.69 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41444933832173997		[learning rate: 0.0019704]
	Learning Rate: 0.00197044
	LOSS [training: 0.41444933832173997 | validation: 0.35147327359532216]
	TIME [epoch: 9.7 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3861619817764182		[learning rate: 0.0019658]
	Learning Rate: 0.0019658
	LOSS [training: 0.3861619817764182 | validation: 0.4141487335538949]
	TIME [epoch: 9.69 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3467150003403526		[learning rate: 0.0019612]
	Learning Rate: 0.00196116
	LOSS [training: 0.3467150003403526 | validation: 0.6027747934691616]
	TIME [epoch: 9.68 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4773825111898907		[learning rate: 0.0019565]
	Learning Rate: 0.00195653
	LOSS [training: 0.4773825111898907 | validation: 0.428002915186762]
	TIME [epoch: 9.71 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.350293056552224		[learning rate: 0.0019519]
	Learning Rate: 0.00195192
	LOSS [training: 0.350293056552224 | validation: 0.4635682293083503]
	TIME [epoch: 9.68 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40973396506070314		[learning rate: 0.0019473]
	Learning Rate: 0.00194731
	LOSS [training: 0.40973396506070314 | validation: 0.38669235847236627]
	TIME [epoch: 9.68 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33437345815113334		[learning rate: 0.0019427]
	Learning Rate: 0.00194272
	LOSS [training: 0.33437345815113334 | validation: 0.29003480112228036]
	TIME [epoch: 9.69 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32066081002492297		[learning rate: 0.0019381]
	Learning Rate: 0.00193814
	LOSS [training: 0.32066081002492297 | validation: 0.4755658059928718]
	TIME [epoch: 9.69 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34103511653424673		[learning rate: 0.0019336]
	Learning Rate: 0.00193357
	LOSS [training: 0.34103511653424673 | validation: 0.2767694933673097]
	TIME [epoch: 9.69 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3597272044739806		[learning rate: 0.001929]
	Learning Rate: 0.001929
	LOSS [training: 0.3597272044739806 | validation: 0.37791159189435064]
	TIME [epoch: 9.68 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31368898931534617		[learning rate: 0.0019245]
	Learning Rate: 0.00192445
	LOSS [training: 0.31368898931534617 | validation: 0.21555835234474555]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_748.pth
	Model improved!!!
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39053891970743343		[learning rate: 0.0019199]
	Learning Rate: 0.00191992
	LOSS [training: 0.39053891970743343 | validation: 0.4000632562443775]
	TIME [epoch: 9.67 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5013113222748686		[learning rate: 0.0019154]
	Learning Rate: 0.00191539
	LOSS [training: 0.5013113222748686 | validation: 0.3865385109483395]
	TIME [epoch: 9.67 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.343345091489783		[learning rate: 0.0019109]
	Learning Rate: 0.00191087
	LOSS [training: 0.343345091489783 | validation: 0.27255850812145865]
	TIME [epoch: 9.69 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3293794811164228		[learning rate: 0.0019064]
	Learning Rate: 0.00190636
	LOSS [training: 0.3293794811164228 | validation: 0.3948707156313725]
	TIME [epoch: 9.68 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3217965253768482		[learning rate: 0.0019019]
	Learning Rate: 0.00190186
	LOSS [training: 0.3217965253768482 | validation: 0.3295622770921875]
	TIME [epoch: 9.67 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3708266448572809		[learning rate: 0.0018974]
	Learning Rate: 0.00189738
	LOSS [training: 0.3708266448572809 | validation: 0.25878257847398356]
	TIME [epoch: 9.68 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27789847320326333		[learning rate: 0.0018929]
	Learning Rate: 0.0018929
	LOSS [training: 0.27789847320326333 | validation: 0.3163575232849242]
	TIME [epoch: 9.7 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3546707686474953		[learning rate: 0.0018884]
	Learning Rate: 0.00188844
	LOSS [training: 0.3546707686474953 | validation: 0.44917430758681115]
	TIME [epoch: 9.68 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3404531413479723		[learning rate: 0.001884]
	Learning Rate: 0.00188398
	LOSS [training: 0.3404531413479723 | validation: 0.43512608962237337]
	TIME [epoch: 9.67 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34571477745780343		[learning rate: 0.0018795]
	Learning Rate: 0.00187954
	LOSS [training: 0.34571477745780343 | validation: 0.6850730448641227]
	TIME [epoch: 9.69 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4800175521193351		[learning rate: 0.0018751]
	Learning Rate: 0.00187511
	LOSS [training: 0.4800175521193351 | validation: 0.3202578999149037]
	TIME [epoch: 9.68 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2919744011417218		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 0.2919744011417218 | validation: 0.3059711005441462]
	TIME [epoch: 9.67 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3421253105474957		[learning rate: 0.0018663]
	Learning Rate: 0.00186627
	LOSS [training: 0.3421253105474957 | validation: 0.3536070764602259]
	TIME [epoch: 9.67 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3268343991487096		[learning rate: 0.0018619]
	Learning Rate: 0.00186187
	LOSS [training: 0.3268343991487096 | validation: 0.27909666185956]
	TIME [epoch: 9.69 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38459963132860414		[learning rate: 0.0018575]
	Learning Rate: 0.00185748
	LOSS [training: 0.38459963132860414 | validation: 0.389113763252333]
	TIME [epoch: 9.67 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33690710801834906		[learning rate: 0.0018531]
	Learning Rate: 0.00185309
	LOSS [training: 0.33690710801834906 | validation: 0.2839927774884853]
	TIME [epoch: 9.67 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32471193888687716		[learning rate: 0.0018487]
	Learning Rate: 0.00184872
	LOSS [training: 0.32471193888687716 | validation: 0.318638490176872]
	TIME [epoch: 9.69 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3740708027839287		[learning rate: 0.0018444]
	Learning Rate: 0.00184436
	LOSS [training: 0.3740708027839287 | validation: 0.2881517902980689]
	TIME [epoch: 9.68 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3349009048738981		[learning rate: 0.00184]
	Learning Rate: 0.00184001
	LOSS [training: 0.3349009048738981 | validation: 0.5077159963123679]
	TIME [epoch: 9.68 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3826364550720987		[learning rate: 0.0018357]
	Learning Rate: 0.00183567
	LOSS [training: 0.3826364550720987 | validation: 0.2302127560308426]
	TIME [epoch: 9.68 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3383995161595977		[learning rate: 0.0018313]
	Learning Rate: 0.00183134
	LOSS [training: 0.3383995161595977 | validation: 0.28025569584487114]
	TIME [epoch: 9.69 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2929048944002354		[learning rate: 0.001827]
	Learning Rate: 0.00182702
	LOSS [training: 0.2929048944002354 | validation: 0.40533856540945595]
	TIME [epoch: 9.67 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3019085673839521		[learning rate: 0.0018227]
	Learning Rate: 0.00182271
	LOSS [training: 0.3019085673839521 | validation: 0.32039366618402965]
	TIME [epoch: 9.67 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3224410443859		[learning rate: 0.0018184]
	Learning Rate: 0.00181841
	LOSS [training: 0.3224410443859 | validation: 0.4667157312625315]
	TIME [epoch: 9.7 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33428162556725116		[learning rate: 0.0018141]
	Learning Rate: 0.00181412
	LOSS [training: 0.33428162556725116 | validation: 0.3152956518364854]
	TIME [epoch: 9.67 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34509019395902907		[learning rate: 0.0018098]
	Learning Rate: 0.00180984
	LOSS [training: 0.34509019395902907 | validation: 0.2215115613857352]
	TIME [epoch: 9.67 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2932053999409814		[learning rate: 0.0018056]
	Learning Rate: 0.00180557
	LOSS [training: 0.2932053999409814 | validation: 0.2636322469601555]
	TIME [epoch: 9.68 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2969119860991081		[learning rate: 0.0018013]
	Learning Rate: 0.00180132
	LOSS [training: 0.2969119860991081 | validation: 0.4006851025634525]
	TIME [epoch: 9.69 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30848124814370087		[learning rate: 0.0017971]
	Learning Rate: 0.00179707
	LOSS [training: 0.30848124814370087 | validation: 0.4112711538640528]
	TIME [epoch: 9.67 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32170998550968444		[learning rate: 0.0017928]
	Learning Rate: 0.00179283
	LOSS [training: 0.32170998550968444 | validation: 0.3251768150731904]
	TIME [epoch: 9.67 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31612099955525436		[learning rate: 0.0017886]
	Learning Rate: 0.0017886
	LOSS [training: 0.31612099955525436 | validation: 0.378043084397942]
	TIME [epoch: 9.69 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2748935846293371		[learning rate: 0.0017844]
	Learning Rate: 0.00178438
	LOSS [training: 0.2748935846293371 | validation: 0.31890613565399967]
	TIME [epoch: 9.67 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3103598662418158		[learning rate: 0.0017802]
	Learning Rate: 0.00178017
	LOSS [training: 0.3103598662418158 | validation: 0.512991118382186]
	TIME [epoch: 9.67 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3944602632900412		[learning rate: 0.001776]
	Learning Rate: 0.00177597
	LOSS [training: 0.3944602632900412 | validation: 0.3197817711388562]
	TIME [epoch: 9.7 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40206158315683604		[learning rate: 0.0017718]
	Learning Rate: 0.00177178
	LOSS [training: 0.40206158315683604 | validation: 0.5218347511371867]
	TIME [epoch: 9.68 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4440889131273978		[learning rate: 0.0017676]
	Learning Rate: 0.0017676
	LOSS [training: 0.4440889131273978 | validation: 0.40092069197716107]
	TIME [epoch: 9.67 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2809461908703689		[learning rate: 0.0017634]
	Learning Rate: 0.00176343
	LOSS [training: 0.2809461908703689 | validation: 0.2605338968453382]
	TIME [epoch: 9.67 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2623432804314168		[learning rate: 0.0017593]
	Learning Rate: 0.00175927
	LOSS [training: 0.2623432804314168 | validation: 0.30746627771845353]
	TIME [epoch: 9.69 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3419238710778703		[learning rate: 0.0017551]
	Learning Rate: 0.00175512
	LOSS [training: 0.3419238710778703 | validation: 0.4228480651884563]
	TIME [epoch: 9.67 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35424637119102587		[learning rate: 0.001751]
	Learning Rate: 0.00175098
	LOSS [training: 0.35424637119102587 | validation: 0.2834256168374231]
	TIME [epoch: 9.67 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3224157350120965		[learning rate: 0.0017469]
	Learning Rate: 0.00174685
	LOSS [training: 0.3224157350120965 | validation: 0.47457366203960877]
	TIME [epoch: 9.69 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33709729794418114		[learning rate: 0.0017427]
	Learning Rate: 0.00174273
	LOSS [training: 0.33709729794418114 | validation: 0.2535555724409831]
	TIME [epoch: 9.68 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26357329860062845		[learning rate: 0.0017386]
	Learning Rate: 0.00173862
	LOSS [training: 0.26357329860062845 | validation: 0.2478709422945971]
	TIME [epoch: 9.68 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2709210960625323		[learning rate: 0.0017345]
	Learning Rate: 0.00173452
	LOSS [training: 0.2709210960625323 | validation: 0.2612446779622551]
	TIME [epoch: 9.68 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2696545447917983		[learning rate: 0.0017304]
	Learning Rate: 0.00173043
	LOSS [training: 0.2696545447917983 | validation: 0.2738263338232712]
	TIME [epoch: 9.69 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34119694082723134		[learning rate: 0.0017263]
	Learning Rate: 0.00172635
	LOSS [training: 0.34119694082723134 | validation: 0.5559507360343284]
	TIME [epoch: 9.68 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3272351267613499		[learning rate: 0.0017223]
	Learning Rate: 0.00172228
	LOSS [training: 0.3272351267613499 | validation: 0.3292189263328896]
	TIME [epoch: 9.67 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3145070543747659		[learning rate: 0.0017182]
	Learning Rate: 0.00171821
	LOSS [training: 0.3145070543747659 | validation: 0.2668416341040665]
	TIME [epoch: 9.69 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30388756483900403		[learning rate: 0.0017142]
	Learning Rate: 0.00171416
	LOSS [training: 0.30388756483900403 | validation: 0.27701340027750776]
	TIME [epoch: 9.67 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29619798123143426		[learning rate: 0.0017101]
	Learning Rate: 0.00171012
	LOSS [training: 0.29619798123143426 | validation: 0.3292198571068323]
	TIME [epoch: 9.67 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31468942908963105		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 0.31468942908963105 | validation: 0.28277008689363187]
	TIME [epoch: 9.69 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3048008514144137		[learning rate: 0.0017021]
	Learning Rate: 0.00170206
	LOSS [training: 0.3048008514144137 | validation: 0.2943237612581308]
	TIME [epoch: 9.69 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24808850330369606		[learning rate: 0.001698]
	Learning Rate: 0.00169804
	LOSS [training: 0.24808850330369606 | validation: 0.353641713555623]
	TIME [epoch: 9.67 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3093138325917537		[learning rate: 0.001694]
	Learning Rate: 0.00169404
	LOSS [training: 0.3093138325917537 | validation: 0.45771076638427693]
	TIME [epoch: 9.67 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3088801367326091		[learning rate: 0.00169]
	Learning Rate: 0.00169004
	LOSS [training: 0.3088801367326091 | validation: 0.33904604026957574]
	TIME [epoch: 9.69 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.308253612643128		[learning rate: 0.0016861]
	Learning Rate: 0.00168606
	LOSS [training: 0.308253612643128 | validation: 0.3852243281272346]
	TIME [epoch: 9.67 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2975348936570186		[learning rate: 0.0016821]
	Learning Rate: 0.00168208
	LOSS [training: 0.2975348936570186 | validation: 0.29389878152130955]
	TIME [epoch: 9.67 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2937458909884775		[learning rate: 0.0016781]
	Learning Rate: 0.00167811
	LOSS [training: 0.2937458909884775 | validation: 0.2785884542125413]
	TIME [epoch: 9.69 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30063243277563145		[learning rate: 0.0016742]
	Learning Rate: 0.00167415
	LOSS [training: 0.30063243277563145 | validation: 0.3978114224816416]
	TIME [epoch: 9.68 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3396636845135782		[learning rate: 0.0016702]
	Learning Rate: 0.0016702
	LOSS [training: 0.3396636845135782 | validation: 0.5087380061877502]
	TIME [epoch: 9.67 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3050045449853477		[learning rate: 0.0016663]
	Learning Rate: 0.00166626
	LOSS [training: 0.3050045449853477 | validation: 0.2579746064546445]
	TIME [epoch: 9.67 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25477898709032487		[learning rate: 0.0016623]
	Learning Rate: 0.00166233
	LOSS [training: 0.25477898709032487 | validation: 0.2803441681276604]
	TIME [epoch: 9.69 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34515473581907957		[learning rate: 0.0016584]
	Learning Rate: 0.00165841
	LOSS [training: 0.34515473581907957 | validation: 0.31437357814757005]
	TIME [epoch: 9.67 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27448157969070974		[learning rate: 0.0016545]
	Learning Rate: 0.0016545
	LOSS [training: 0.27448157969070974 | validation: 0.31461771170515035]
	TIME [epoch: 9.67 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2985963378375559		[learning rate: 0.0016506]
	Learning Rate: 0.0016506
	LOSS [training: 0.2985963378375559 | validation: 0.26654223738596167]
	TIME [epoch: 9.69 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32975654827995887		[learning rate: 0.0016467]
	Learning Rate: 0.0016467
	LOSS [training: 0.32975654827995887 | validation: 0.4647284056124964]
	TIME [epoch: 9.68 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3292653512894753		[learning rate: 0.0016428]
	Learning Rate: 0.00164282
	LOSS [training: 0.3292653512894753 | validation: 0.26953592494696177]
	TIME [epoch: 9.67 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2838302093908222		[learning rate: 0.0016389]
	Learning Rate: 0.00163894
	LOSS [training: 0.2838302093908222 | validation: 0.31657218026654377]
	TIME [epoch: 9.68 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2732755133790433		[learning rate: 0.0016351]
	Learning Rate: 0.00163508
	LOSS [training: 0.2732755133790433 | validation: 0.27478557095388356]
	TIME [epoch: 9.69 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28668701320253404		[learning rate: 0.0016312]
	Learning Rate: 0.00163122
	LOSS [training: 0.28668701320253404 | validation: 0.3111929586566732]
	TIME [epoch: 9.67 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3465190727976202		[learning rate: 0.0016274]
	Learning Rate: 0.00162737
	LOSS [training: 0.3465190727976202 | validation: 0.29032854492748267]
	TIME [epoch: 9.68 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3252755660922239		[learning rate: 0.0016235]
	Learning Rate: 0.00162353
	LOSS [training: 0.3252755660922239 | validation: 0.30664297967682513]
	TIME [epoch: 9.68 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2845393972261857		[learning rate: 0.0016197]
	Learning Rate: 0.0016197
	LOSS [training: 0.2845393972261857 | validation: 0.3253169698243009]
	TIME [epoch: 9.67 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2932927891032756		[learning rate: 0.0016159]
	Learning Rate: 0.00161588
	LOSS [training: 0.2932927891032756 | validation: 0.4347847356796602]
	TIME [epoch: 9.67 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33074827102610727		[learning rate: 0.0016121]
	Learning Rate: 0.00161207
	LOSS [training: 0.33074827102610727 | validation: 0.279837127637372]
	TIME [epoch: 9.68 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2919208933572587		[learning rate: 0.0016083]
	Learning Rate: 0.00160827
	LOSS [training: 0.2919208933572587 | validation: 0.28761759305503837]
	TIME [epoch: 9.68 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3350849246596181		[learning rate: 0.0016045]
	Learning Rate: 0.00160448
	LOSS [training: 0.3350849246596181 | validation: 0.32418455745284985]
	TIME [epoch: 9.67 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2807554649995806		[learning rate: 0.0016007]
	Learning Rate: 0.00160069
	LOSS [training: 0.2807554649995806 | validation: 0.3461628525749768]
	TIME [epoch: 9.67 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3494289228270694		[learning rate: 0.0015969]
	Learning Rate: 0.00159692
	LOSS [training: 0.3494289228270694 | validation: 0.29900218339554974]
	TIME [epoch: 9.69 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2763617849498624		[learning rate: 0.0015931]
	Learning Rate: 0.00159315
	LOSS [training: 0.2763617849498624 | validation: 0.3057980024371879]
	TIME [epoch: 9.67 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3035465112736191		[learning rate: 0.0015894]
	Learning Rate: 0.00158939
	LOSS [training: 0.3035465112736191 | validation: 0.2570732815672222]
	TIME [epoch: 9.67 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2417573785376666		[learning rate: 0.0015856]
	Learning Rate: 0.00158564
	LOSS [training: 0.2417573785376666 | validation: 0.2457723142814112]
	TIME [epoch: 9.69 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2522338528789555		[learning rate: 0.0015819]
	Learning Rate: 0.0015819
	LOSS [training: 0.2522338528789555 | validation: 0.40586391069636585]
	TIME [epoch: 9.67 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3046705038090037		[learning rate: 0.0015782]
	Learning Rate: 0.00157817
	LOSS [training: 0.3046705038090037 | validation: 0.3774442232392632]
	TIME [epoch: 9.67 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.378363711692133		[learning rate: 0.0015744]
	Learning Rate: 0.00157445
	LOSS [training: 0.378363711692133 | validation: 0.46227479859491377]
	TIME [epoch: 9.67 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36330665306129406		[learning rate: 0.0015707]
	Learning Rate: 0.00157073
	LOSS [training: 0.36330665306129406 | validation: 0.32574945271105904]
	TIME [epoch: 9.69 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2629688964050558		[learning rate: 0.001567]
	Learning Rate: 0.00156703
	LOSS [training: 0.2629688964050558 | validation: 0.3047753735988289]
	TIME [epoch: 9.67 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2911729913185052		[learning rate: 0.0015633]
	Learning Rate: 0.00156333
	LOSS [training: 0.2911729913185052 | validation: 0.34605161967599146]
	TIME [epoch: 9.67 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2544109385792613		[learning rate: 0.0015596]
	Learning Rate: 0.00155964
	LOSS [training: 0.2544109385792613 | validation: 0.35786285309693716]
	TIME [epoch: 9.69 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2779257868095021		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 0.2779257868095021 | validation: 0.272912524427744]
	TIME [epoch: 9.67 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3134036646208994		[learning rate: 0.0015523]
	Learning Rate: 0.0015523
	LOSS [training: 0.3134036646208994 | validation: 0.23724705584548544]
	TIME [epoch: 9.67 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23135280740730443		[learning rate: 0.0015486]
	Learning Rate: 0.00154863
	LOSS [training: 0.23135280740730443 | validation: 0.2995903991602043]
	TIME [epoch: 9.68 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2599715447633741		[learning rate: 0.001545]
	Learning Rate: 0.00154498
	LOSS [training: 0.2599715447633741 | validation: 0.39534771854316525]
	TIME [epoch: 9.69 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32416077559781725		[learning rate: 0.0015413]
	Learning Rate: 0.00154134
	LOSS [training: 0.32416077559781725 | validation: 0.2332842163586013]
	TIME [epoch: 9.67 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22810538759998908		[learning rate: 0.0015377]
	Learning Rate: 0.0015377
	LOSS [training: 0.22810538759998908 | validation: 0.25243299027287125]
	TIME [epoch: 9.67 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3242381041554047		[learning rate: 0.0015341]
	Learning Rate: 0.00153407
	LOSS [training: 0.3242381041554047 | validation: 0.4261067635739297]
	TIME [epoch: 9.69 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3470428822375201		[learning rate: 0.0015305]
	Learning Rate: 0.00153045
	LOSS [training: 0.3470428822375201 | validation: 0.4150021459724114]
	TIME [epoch: 9.67 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2724402883335795		[learning rate: 0.0015268]
	Learning Rate: 0.00152684
	LOSS [training: 0.2724402883335795 | validation: 0.23256713206263158]
	TIME [epoch: 9.67 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2726182048966739		[learning rate: 0.0015232]
	Learning Rate: 0.00152324
	LOSS [training: 0.2726182048966739 | validation: 0.26113713657023424]
	TIME [epoch: 9.69 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2821004345590044		[learning rate: 0.0015196]
	Learning Rate: 0.00151965
	LOSS [training: 0.2821004345590044 | validation: 0.31667368179430694]
	TIME [epoch: 9.68 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34574015112285367		[learning rate: 0.0015161]
	Learning Rate: 0.00151607
	LOSS [training: 0.34574015112285367 | validation: 0.3302655277707571]
	TIME [epoch: 9.66 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2407081632858879		[learning rate: 0.0015125]
	Learning Rate: 0.00151249
	LOSS [training: 0.2407081632858879 | validation: 0.26399327912239134]
	TIME [epoch: 9.67 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27040926539009236		[learning rate: 0.0015089]
	Learning Rate: 0.00150892
	LOSS [training: 0.27040926539009236 | validation: 0.28859619060500913]
	TIME [epoch: 9.68 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2311110602970822		[learning rate: 0.0015054]
	Learning Rate: 0.00150536
	LOSS [training: 0.2311110602970822 | validation: 0.22308257038805138]
	TIME [epoch: 9.67 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27282384777190793		[learning rate: 0.0015018]
	Learning Rate: 0.00150181
	LOSS [training: 0.27282384777190793 | validation: 0.2783788871516476]
	TIME [epoch: 9.67 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26628753912429276		[learning rate: 0.0014983]
	Learning Rate: 0.00149827
	LOSS [training: 0.26628753912429276 | validation: 0.4004811851229053]
	TIME [epoch: 9.69 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3307994949796932		[learning rate: 0.0014947]
	Learning Rate: 0.00149473
	LOSS [training: 0.3307994949796932 | validation: 0.533629625776612]
	TIME [epoch: 9.68 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32141136544757		[learning rate: 0.0014912]
	Learning Rate: 0.00149121
	LOSS [training: 0.32141136544757 | validation: 0.3067474432845682]
	TIME [epoch: 9.68 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3084770482089102		[learning rate: 0.0014877]
	Learning Rate: 0.00148769
	LOSS [training: 0.3084770482089102 | validation: 0.3023194402206168]
	TIME [epoch: 9.68 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25600260069756964		[learning rate: 0.0014842]
	Learning Rate: 0.00148418
	LOSS [training: 0.25600260069756964 | validation: 0.2932176552708486]
	TIME [epoch: 9.69 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25403753715787103		[learning rate: 0.0014807]
	Learning Rate: 0.00148068
	LOSS [training: 0.25403753715787103 | validation: 0.25958100813761137]
	TIME [epoch: 9.67 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24690512883955051		[learning rate: 0.0014772]
	Learning Rate: 0.00147719
	LOSS [training: 0.24690512883955051 | validation: 0.34407853342866174]
	TIME [epoch: 9.68 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.337624204195508		[learning rate: 0.0014737]
	Learning Rate: 0.0014737
	LOSS [training: 0.337624204195508 | validation: 0.43886232738142256]
	TIME [epoch: 9.69 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36456709227809375		[learning rate: 0.0014702]
	Learning Rate: 0.00147023
	LOSS [training: 0.36456709227809375 | validation: 0.2960150365548868]
	TIME [epoch: 9.67 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3170786802934259		[learning rate: 0.0014668]
	Learning Rate: 0.00146676
	LOSS [training: 0.3170786802934259 | validation: 0.26753656196175357]
	TIME [epoch: 9.67 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2532500404620026		[learning rate: 0.0014633]
	Learning Rate: 0.0014633
	LOSS [training: 0.2532500404620026 | validation: 0.28870306921815597]
	TIME [epoch: 9.69 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2501083780942074		[learning rate: 0.0014598]
	Learning Rate: 0.00145985
	LOSS [training: 0.2501083780942074 | validation: 0.23945498180374553]
	TIME [epoch: 9.69 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26425447338414537		[learning rate: 0.0014564]
	Learning Rate: 0.0014564
	LOSS [training: 0.26425447338414537 | validation: 0.2605957034145187]
	TIME [epoch: 9.68 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28481034713986725		[learning rate: 0.001453]
	Learning Rate: 0.00145297
	LOSS [training: 0.28481034713986725 | validation: 0.24244306146703687]
	TIME [epoch: 9.66 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3352579988008634		[learning rate: 0.0014495]
	Learning Rate: 0.00144954
	LOSS [training: 0.3352579988008634 | validation: 0.3382595594384853]
	TIME [epoch: 9.69 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27200065762031034		[learning rate: 0.0014461]
	Learning Rate: 0.00144612
	LOSS [training: 0.27200065762031034 | validation: 0.26114071417710344]
	TIME [epoch: 9.66 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27471793614453277		[learning rate: 0.0014427]
	Learning Rate: 0.00144271
	LOSS [training: 0.27471793614453277 | validation: 0.2469772603560373]
	TIME [epoch: 9.65 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24514034305404503		[learning rate: 0.0014393]
	Learning Rate: 0.00143931
	LOSS [training: 0.24514034305404503 | validation: 0.2713369195852172]
	TIME [epoch: 9.66 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2674389910109015		[learning rate: 0.0014359]
	Learning Rate: 0.00143591
	LOSS [training: 0.2674389910109015 | validation: 0.5661558822760813]
	TIME [epoch: 9.66 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37641872314587266		[learning rate: 0.0014325]
	Learning Rate: 0.00143253
	LOSS [training: 0.37641872314587266 | validation: 0.4585869908019484]
	TIME [epoch: 9.66 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32603289553356013		[learning rate: 0.0014291]
	Learning Rate: 0.00142915
	LOSS [training: 0.32603289553356013 | validation: 0.22102893491357797]
	TIME [epoch: 9.67 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26065882431707876		[learning rate: 0.0014258]
	Learning Rate: 0.00142578
	LOSS [training: 0.26065882431707876 | validation: 0.27285672864886407]
	TIME [epoch: 9.69 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24012422194683158		[learning rate: 0.0014224]
	Learning Rate: 0.00142241
	LOSS [training: 0.24012422194683158 | validation: 0.2605612227577634]
	TIME [epoch: 9.66 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24360302412736806		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.24360302412736806 | validation: 0.33779378641340985]
	TIME [epoch: 9.66 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25614862310529773		[learning rate: 0.0014157]
	Learning Rate: 0.00141571
	LOSS [training: 0.25614862310529773 | validation: 0.2151084319888297]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_878.pth
	Model improved!!!
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2497852135664687		[learning rate: 0.0014124]
	Learning Rate: 0.00141237
	LOSS [training: 0.2497852135664687 | validation: 0.31204316421838035]
	TIME [epoch: 9.64 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2706016805023329		[learning rate: 0.001409]
	Learning Rate: 0.00140904
	LOSS [training: 0.2706016805023329 | validation: 0.32887295313881987]
	TIME [epoch: 9.65 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31926957042564386		[learning rate: 0.0014057]
	Learning Rate: 0.00140572
	LOSS [training: 0.31926957042564386 | validation: 0.2627388705261158]
	TIME [epoch: 9.66 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21506046246354232		[learning rate: 0.0014024]
	Learning Rate: 0.0014024
	LOSS [training: 0.21506046246354232 | validation: 0.23245764728736007]
	TIME [epoch: 9.68 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2408548451412095		[learning rate: 0.0013991]
	Learning Rate: 0.00139909
	LOSS [training: 0.2408548451412095 | validation: 0.23579386209892889]
	TIME [epoch: 9.66 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2410437938143776		[learning rate: 0.0013958]
	Learning Rate: 0.00139579
	LOSS [training: 0.2410437938143776 | validation: 0.31222784624821576]
	TIME [epoch: 9.66 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24010017602499495		[learning rate: 0.0013925]
	Learning Rate: 0.0013925
	LOSS [training: 0.24010017602499495 | validation: 0.25696940459558903]
	TIME [epoch: 9.67 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23810142575667284		[learning rate: 0.0013892]
	Learning Rate: 0.00138921
	LOSS [training: 0.23810142575667284 | validation: 0.19588899609473656]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_886.pth
	Model improved!!!
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21654621022709625		[learning rate: 0.0013859]
	Learning Rate: 0.00138594
	LOSS [training: 0.21654621022709625 | validation: 0.3315763478212419]
	TIME [epoch: 9.67 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29433362321866346		[learning rate: 0.0013827]
	Learning Rate: 0.00138267
	LOSS [training: 0.29433362321866346 | validation: 0.25260865057232584]
	TIME [epoch: 9.67 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2333824468201704		[learning rate: 0.0013794]
	Learning Rate: 0.00137941
	LOSS [training: 0.2333824468201704 | validation: 0.33906918182289875]
	TIME [epoch: 9.69 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24888746787844074		[learning rate: 0.0013762]
	Learning Rate: 0.00137615
	LOSS [training: 0.24888746787844074 | validation: 0.4281875227788159]
	TIME [epoch: 9.66 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3111395222508131		[learning rate: 0.0013729]
	Learning Rate: 0.00137291
	LOSS [training: 0.3111395222508131 | validation: 0.5278354902917084]
	TIME [epoch: 9.66 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4828370013007383		[learning rate: 0.0013697]
	Learning Rate: 0.00136967
	LOSS [training: 0.4828370013007383 | validation: 0.45983695922485246]
	TIME [epoch: 9.68 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2581305189562462		[learning rate: 0.0013664]
	Learning Rate: 0.00136644
	LOSS [training: 0.2581305189562462 | validation: 0.28004873857253865]
	TIME [epoch: 9.67 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22295537370661767		[learning rate: 0.0013632]
	Learning Rate: 0.00136321
	LOSS [training: 0.22295537370661767 | validation: 0.35178814133690645]
	TIME [epoch: 9.66 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2412191046700373		[learning rate: 0.00136]
	Learning Rate: 0.00136
	LOSS [training: 0.2412191046700373 | validation: 0.2391945812054087]
	TIME [epoch: 9.65 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22675974805607316		[learning rate: 0.0013568]
	Learning Rate: 0.00135679
	LOSS [training: 0.22675974805607316 | validation: 0.48327967636950625]
	TIME [epoch: 9.69 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3194388232290188		[learning rate: 0.0013536]
	Learning Rate: 0.00135359
	LOSS [training: 0.3194388232290188 | validation: 0.24100861719834066]
	TIME [epoch: 9.66 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25536561798030455		[learning rate: 0.0013504]
	Learning Rate: 0.0013504
	LOSS [training: 0.25536561798030455 | validation: 0.3620939489822778]
	TIME [epoch: 9.66 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2623952968375953		[learning rate: 0.0013472]
	Learning Rate: 0.00134721
	LOSS [training: 0.2623952968375953 | validation: 0.36029920780969465]
	TIME [epoch: 9.67 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2583208684266719		[learning rate: 0.001344]
	Learning Rate: 0.00134403
	LOSS [training: 0.2583208684266719 | validation: 0.38087804942156367]
	TIME [epoch: 9.68 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28364452968951503		[learning rate: 0.0013409]
	Learning Rate: 0.00134086
	LOSS [training: 0.28364452968951503 | validation: 0.2768974953235094]
	TIME [epoch: 9.66 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23394160726116678		[learning rate: 0.0013377]
	Learning Rate: 0.0013377
	LOSS [training: 0.23394160726116678 | validation: 0.30752481355092876]
	TIME [epoch: 9.67 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3129332697653201		[learning rate: 0.0013345]
	Learning Rate: 0.00133455
	LOSS [training: 0.3129332697653201 | validation: 0.5143273725262584]
	TIME [epoch: 9.68 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.349696868542254		[learning rate: 0.0013314]
	Learning Rate: 0.0013314
	LOSS [training: 0.349696868542254 | validation: 0.3331222210865434]
	TIME [epoch: 9.66 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30934935895326837		[learning rate: 0.0013283]
	Learning Rate: 0.00132826
	LOSS [training: 0.30934935895326837 | validation: 0.3408426885287875]
	TIME [epoch: 9.67 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25262994768350516		[learning rate: 0.0013251]
	Learning Rate: 0.00132512
	LOSS [training: 0.25262994768350516 | validation: 0.20970342622631777]
	TIME [epoch: 9.68 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21812462341309344		[learning rate: 0.001322]
	Learning Rate: 0.001322
	LOSS [training: 0.21812462341309344 | validation: 0.1945170664313932]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_907.pth
	Model improved!!!
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20672774972109872		[learning rate: 0.0013189]
	Learning Rate: 0.00131888
	LOSS [training: 0.20672774972109872 | validation: 0.34751270257070827]
	TIME [epoch: 9.66 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27509743575573686		[learning rate: 0.0013158]
	Learning Rate: 0.00131577
	LOSS [training: 0.27509743575573686 | validation: 0.2667022199554951]
	TIME [epoch: 9.66 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2342864482156684		[learning rate: 0.0013127]
	Learning Rate: 0.00131266
	LOSS [training: 0.2342864482156684 | validation: 0.2089857240467884]
	TIME [epoch: 9.69 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18813582107795446		[learning rate: 0.0013096]
	Learning Rate: 0.00130957
	LOSS [training: 0.18813582107795446 | validation: 0.22961225290557263]
	TIME [epoch: 9.65 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2772926035364671		[learning rate: 0.0013065]
	Learning Rate: 0.00130648
	LOSS [training: 0.2772926035364671 | validation: 0.2033321658209799]
	TIME [epoch: 9.67 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20157427933059124		[learning rate: 0.0013034]
	Learning Rate: 0.0013034
	LOSS [training: 0.20157427933059124 | validation: 0.17603426851525747]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_913.pth
	Model improved!!!
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21995691125182354		[learning rate: 0.0013003]
	Learning Rate: 0.00130032
	LOSS [training: 0.21995691125182354 | validation: 0.259110673048964]
	TIME [epoch: 9.68 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29653108888579405		[learning rate: 0.0012973]
	Learning Rate: 0.00129726
	LOSS [training: 0.29653108888579405 | validation: 0.20438590704367393]
	TIME [epoch: 9.66 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23242720598127725		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 0.23242720598127725 | validation: 0.22370377785831294]
	TIME [epoch: 9.66 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20709411534976113		[learning rate: 0.0012911]
	Learning Rate: 0.00129114
	LOSS [training: 0.20709411534976113 | validation: 0.22490911596136257]
	TIME [epoch: 9.67 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23949345650182852		[learning rate: 0.0012881]
	Learning Rate: 0.0012881
	LOSS [training: 0.23949345650182852 | validation: 0.25028938954698987]
	TIME [epoch: 9.67 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22631162354291656		[learning rate: 0.0012851]
	Learning Rate: 0.00128506
	LOSS [training: 0.22631162354291656 | validation: 0.26949589855444195]
	TIME [epoch: 9.67 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2440696188217654		[learning rate: 0.001282]
	Learning Rate: 0.00128203
	LOSS [training: 0.2440696188217654 | validation: 0.4638549376981142]
	TIME [epoch: 9.66 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32913842737590115		[learning rate: 0.001279]
	Learning Rate: 0.001279
	LOSS [training: 0.32913842737590115 | validation: 0.23609124765822637]
	TIME [epoch: 9.69 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23636097090970024		[learning rate: 0.001276]
	Learning Rate: 0.00127599
	LOSS [training: 0.23636097090970024 | validation: 0.2605010823474195]
	TIME [epoch: 9.65 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2358704682723364		[learning rate: 0.001273]
	Learning Rate: 0.00127298
	LOSS [training: 0.2358704682723364 | validation: 0.24448765715991871]
	TIME [epoch: 9.66 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2638294176773257		[learning rate: 0.00127]
	Learning Rate: 0.00126997
	LOSS [training: 0.2638294176773257 | validation: 0.34393779332089724]
	TIME [epoch: 9.67 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24527951256636524		[learning rate: 0.001267]
	Learning Rate: 0.00126698
	LOSS [training: 0.24527951256636524 | validation: 0.19204724242591542]
	TIME [epoch: 9.66 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19762139194653028		[learning rate: 0.001264]
	Learning Rate: 0.00126399
	LOSS [training: 0.19762139194653028 | validation: 0.2013004985878171]
	TIME [epoch: 9.66 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22731341716527947		[learning rate: 0.001261]
	Learning Rate: 0.00126101
	LOSS [training: 0.22731341716527947 | validation: 0.22173180122717867]
	TIME [epoch: 9.67 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20161626412875017		[learning rate: 0.001258]
	Learning Rate: 0.00125803
	LOSS [training: 0.20161626412875017 | validation: 0.21758968973114756]
	TIME [epoch: 9.66 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21029172642746397		[learning rate: 0.0012551]
	Learning Rate: 0.00125507
	LOSS [training: 0.21029172642746397 | validation: 0.3662910106532239]
	TIME [epoch: 9.66 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2892374983839279		[learning rate: 0.0012521]
	Learning Rate: 0.00125211
	LOSS [training: 0.2892374983839279 | validation: 0.24681910652416225]
	TIME [epoch: 9.65 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22383616409555773		[learning rate: 0.0012492]
	Learning Rate: 0.00124915
	LOSS [training: 0.22383616409555773 | validation: 0.32935700205366986]
	TIME [epoch: 9.69 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27462206618908347		[learning rate: 0.0012462]
	Learning Rate: 0.00124621
	LOSS [training: 0.27462206618908347 | validation: 0.28668955964657444]
	TIME [epoch: 9.66 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24198035656986683		[learning rate: 0.0012433]
	Learning Rate: 0.00124327
	LOSS [training: 0.24198035656986683 | validation: 0.27453513974194155]
	TIME [epoch: 9.66 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2147290297566511		[learning rate: 0.0012403]
	Learning Rate: 0.00124033
	LOSS [training: 0.2147290297566511 | validation: 0.19678059516115431]
	TIME [epoch: 9.69 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20237511378991985		[learning rate: 0.0012374]
	Learning Rate: 0.00123741
	LOSS [training: 0.20237511378991985 | validation: 0.18550235551010882]
	TIME [epoch: 9.66 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21247334099260215		[learning rate: 0.0012345]
	Learning Rate: 0.00123449
	LOSS [training: 0.21247334099260215 | validation: 0.19962441944660034]
	TIME [epoch: 9.67 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2677361865518357		[learning rate: 0.0012316]
	Learning Rate: 0.00123158
	LOSS [training: 0.2677361865518357 | validation: 0.2907098146942926]
	TIME [epoch: 9.65 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2832143204929439		[learning rate: 0.0012287]
	Learning Rate: 0.00122867
	LOSS [training: 0.2832143204929439 | validation: 0.3169761916528913]
	TIME [epoch: 9.69 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2574046499883532		[learning rate: 0.0012258]
	Learning Rate: 0.00122577
	LOSS [training: 0.2574046499883532 | validation: 0.23884125191834663]
	TIME [epoch: 9.67 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23746556742627695		[learning rate: 0.0012229]
	Learning Rate: 0.00122288
	LOSS [training: 0.23746556742627695 | validation: 0.3163886057787876]
	TIME [epoch: 9.67 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2221835073786187		[learning rate: 0.00122]
	Learning Rate: 0.00122
	LOSS [training: 0.2221835073786187 | validation: 0.2685004420884534]
	TIME [epoch: 9.67 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2858599566082064		[learning rate: 0.0012171]
	Learning Rate: 0.00121712
	LOSS [training: 0.2858599566082064 | validation: 0.2544070364615962]
	TIME [epoch: 9.67 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.264060510105434		[learning rate: 0.0012142]
	Learning Rate: 0.00121425
	LOSS [training: 0.264060510105434 | validation: 0.2654952593129925]
	TIME [epoch: 9.65 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19590073494232607		[learning rate: 0.0012114]
	Learning Rate: 0.00121138
	LOSS [training: 0.19590073494232607 | validation: 0.22534508229264558]
	TIME [epoch: 9.67 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2300491885752934		[learning rate: 0.0012085]
	Learning Rate: 0.00120853
	LOSS [training: 0.2300491885752934 | validation: 0.27703734800063007]
	TIME [epoch: 9.67 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27666695572154393		[learning rate: 0.0012057]
	Learning Rate: 0.00120568
	LOSS [training: 0.27666695572154393 | validation: 0.21384865642107317]
	TIME [epoch: 9.66 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23302487485445073		[learning rate: 0.0012028]
	Learning Rate: 0.00120283
	LOSS [training: 0.23302487485445073 | validation: 0.29125346283533193]
	TIME [epoch: 9.65 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2611413832295693		[learning rate: 0.0012]
	Learning Rate: 0.0012
	LOSS [training: 0.2611413832295693 | validation: 0.27449845368818204]
	TIME [epoch: 9.69 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24827114666363173		[learning rate: 0.0011972]
	Learning Rate: 0.00119716
	LOSS [training: 0.24827114666363173 | validation: 0.3606531050069819]
	TIME [epoch: 9.65 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4169098537242809		[learning rate: 0.0011943]
	Learning Rate: 0.00119434
	LOSS [training: 0.4169098537242809 | validation: 0.3293760478281273]
	TIME [epoch: 9.66 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32773418772436247		[learning rate: 0.0011915]
	Learning Rate: 0.00119152
	LOSS [training: 0.32773418772436247 | validation: 0.23682690970073594]
	TIME [epoch: 9.67 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2452033183921431		[learning rate: 0.0011887]
	Learning Rate: 0.00118871
	LOSS [training: 0.2452033183921431 | validation: 0.30742490004157297]
	TIME [epoch: 9.68 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2579722885508341		[learning rate: 0.0011859]
	Learning Rate: 0.00118591
	LOSS [training: 0.2579722885508341 | validation: 0.3012610236568704]
	TIME [epoch: 9.65 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2966470530940221		[learning rate: 0.0011831]
	Learning Rate: 0.00118311
	LOSS [training: 0.2966470530940221 | validation: 0.2909731022657458]
	TIME [epoch: 9.66 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22327415426232036		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.22327415426232036 | validation: 0.34700818184573734]
	TIME [epoch: 9.68 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26479841571785523		[learning rate: 0.0011775]
	Learning Rate: 0.00117754
	LOSS [training: 0.26479841571785523 | validation: 0.22166505943218276]
	TIME [epoch: 9.65 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24237709498436494		[learning rate: 0.0011748]
	Learning Rate: 0.00117476
	LOSS [training: 0.24237709498436494 | validation: 0.23578470358651912]
	TIME [epoch: 9.65 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2642292995210348		[learning rate: 0.001172]
	Learning Rate: 0.00117199
	LOSS [training: 0.2642292995210348 | validation: 0.28497189552125657]
	TIME [epoch: 9.68 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.259537022855194		[learning rate: 0.0011692]
	Learning Rate: 0.00116922
	LOSS [training: 0.259537022855194 | validation: 0.23577006272577167]
	TIME [epoch: 9.67 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1926636131327659		[learning rate: 0.0011665]
	Learning Rate: 0.00116646
	LOSS [training: 0.1926636131327659 | validation: 0.1851339277592655]
	TIME [epoch: 9.66 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19561774716785246		[learning rate: 0.0011637]
	Learning Rate: 0.00116371
	LOSS [training: 0.19561774716785246 | validation: 0.2989441835727511]
	TIME [epoch: 9.67 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2953953949661981		[learning rate: 0.001161]
	Learning Rate: 0.00116097
	LOSS [training: 0.2953953949661981 | validation: 0.32905804223692514]
	TIME [epoch: 9.68 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20005765358992753		[learning rate: 0.0011582]
	Learning Rate: 0.00115823
	LOSS [training: 0.20005765358992753 | validation: 0.1697912935840408]
	TIME [epoch: 9.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_963.pth
	Model improved!!!
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17698596335564548		[learning rate: 0.0011555]
	Learning Rate: 0.0011555
	LOSS [training: 0.17698596335564548 | validation: 0.19275056864179024]
	TIME [epoch: 9.67 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2116210100260579		[learning rate: 0.0011528]
	Learning Rate: 0.00115277
	LOSS [training: 0.2116210100260579 | validation: 0.20872542076029255]
	TIME [epoch: 9.68 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24345991211551224		[learning rate: 0.0011501]
	Learning Rate: 0.00115005
	LOSS [training: 0.24345991211551224 | validation: 0.26145690751553147]
	TIME [epoch: 9.66 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28084190745110027		[learning rate: 0.0011473]
	Learning Rate: 0.00114734
	LOSS [training: 0.28084190745110027 | validation: 0.3118628555459378]
	TIME [epoch: 9.66 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25886431715913016		[learning rate: 0.0011446]
	Learning Rate: 0.00114463
	LOSS [training: 0.25886431715913016 | validation: 0.28089719230666155]
	TIME [epoch: 9.65 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28109326349718283		[learning rate: 0.0011419]
	Learning Rate: 0.00114193
	LOSS [training: 0.28109326349718283 | validation: 0.27064002281611355]
	TIME [epoch: 9.68 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2845664610312159		[learning rate: 0.0011392]
	Learning Rate: 0.00113924
	LOSS [training: 0.2845664610312159 | validation: 0.27011601334488605]
	TIME [epoch: 9.65 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22754403989628927		[learning rate: 0.0011366]
	Learning Rate: 0.00113655
	LOSS [training: 0.22754403989628927 | validation: 0.2988323542357995]
	TIME [epoch: 9.66 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2233917756396658		[learning rate: 0.0011339]
	Learning Rate: 0.00113387
	LOSS [training: 0.2233917756396658 | validation: 0.259933181783944]
	TIME [epoch: 9.68 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24983300276543022		[learning rate: 0.0011312]
	Learning Rate: 0.0011312
	LOSS [training: 0.24983300276543022 | validation: 0.2002394033955469]
	TIME [epoch: 9.66 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20169337275538615		[learning rate: 0.0011285]
	Learning Rate: 0.00112853
	LOSS [training: 0.20169337275538615 | validation: 0.19208273086367583]
	TIME [epoch: 9.67 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2161201907128411		[learning rate: 0.0011259]
	Learning Rate: 0.00112587
	LOSS [training: 0.2161201907128411 | validation: 0.18621522765603002]
	TIME [epoch: 9.65 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.256246651202917		[learning rate: 0.0011232]
	Learning Rate: 0.00112321
	LOSS [training: 0.256246651202917 | validation: 0.20011349344571996]
	TIME [epoch: 9.68 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2268528762159235		[learning rate: 0.0011206]
	Learning Rate: 0.00112056
	LOSS [training: 0.2268528762159235 | validation: 0.23200748332255047]
	TIME [epoch: 9.65 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.243705461125659		[learning rate: 0.0011179]
	Learning Rate: 0.00111792
	LOSS [training: 0.243705461125659 | validation: 0.17472967920856255]
	TIME [epoch: 9.66 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21071414787460602		[learning rate: 0.0011153]
	Learning Rate: 0.00111528
	LOSS [training: 0.21071414787460602 | validation: 0.2809634178327582]
	TIME [epoch: 9.69 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2861447540775409		[learning rate: 0.0011127]
	Learning Rate: 0.00111265
	LOSS [training: 0.2861447540775409 | validation: 0.2705717557355592]
	TIME [epoch: 9.65 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2722477052837001		[learning rate: 0.00111]
	Learning Rate: 0.00111003
	LOSS [training: 0.2722477052837001 | validation: 0.2718470326085252]
	TIME [epoch: 9.66 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25902463106406853		[learning rate: 0.0011074]
	Learning Rate: 0.00110741
	LOSS [training: 0.25902463106406853 | validation: 0.22000883766140863]
	TIME [epoch: 9.67 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19571989783889715		[learning rate: 0.0011048]
	Learning Rate: 0.0011048
	LOSS [training: 0.19571989783889715 | validation: 0.20115189559942892]
	TIME [epoch: 9.67 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1834492243597964		[learning rate: 0.0011022]
	Learning Rate: 0.00110219
	LOSS [training: 0.1834492243597964 | validation: 0.28259821113173017]
	TIME [epoch: 9.66 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24868046531375326		[learning rate: 0.0010996]
	Learning Rate: 0.00109959
	LOSS [training: 0.24868046531375326 | validation: 0.23411131133660118]
	TIME [epoch: 9.66 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21849827968213834		[learning rate: 0.001097]
	Learning Rate: 0.001097
	LOSS [training: 0.21849827968213834 | validation: 0.1740195693024296]
	TIME [epoch: 9.68 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20436561446365062		[learning rate: 0.0010944]
	Learning Rate: 0.00109441
	LOSS [training: 0.20436561446365062 | validation: 0.23729416642042417]
	TIME [epoch: 9.65 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19276324404450887		[learning rate: 0.0010918]
	Learning Rate: 0.00109183
	LOSS [training: 0.19276324404450887 | validation: 0.19865920834367004]
	TIME [epoch: 9.66 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2125583234505728		[learning rate: 0.0010893]
	Learning Rate: 0.00108925
	LOSS [training: 0.2125583234505728 | validation: 0.2591302542643408]
	TIME [epoch: 9.66 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19846210105875364		[learning rate: 0.0010867]
	Learning Rate: 0.00108668
	LOSS [training: 0.19846210105875364 | validation: 0.3253580978567925]
	TIME [epoch: 9.67 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2460086434188704		[learning rate: 0.0010841]
	Learning Rate: 0.00108412
	LOSS [training: 0.2460086434188704 | validation: 0.1847792078225598]
	TIME [epoch: 9.66 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2165580693641588		[learning rate: 0.0010816]
	Learning Rate: 0.00108156
	LOSS [training: 0.2165580693641588 | validation: 0.1868372673041766]
	TIME [epoch: 9.66 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2327887502850352		[learning rate: 0.001079]
	Learning Rate: 0.00107901
	LOSS [training: 0.2327887502850352 | validation: 0.22812218851725363]
	TIME [epoch: 9.68 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19396814658334852		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.19396814658334852 | validation: 0.19794041493986975]
	TIME [epoch: 9.66 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20529190067460004		[learning rate: 0.0010739]
	Learning Rate: 0.00107393
	LOSS [training: 0.20529190067460004 | validation: 0.23136439203081285]
	TIME [epoch: 9.66 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18342769729080666		[learning rate: 0.0010714]
	Learning Rate: 0.00107139
	LOSS [training: 0.18342769729080666 | validation: 0.3073039139482118]
	TIME [epoch: 9.68 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2276482773126932		[learning rate: 0.0010689]
	Learning Rate: 0.00106887
	LOSS [training: 0.2276482773126932 | validation: 0.1975685421810897]
	TIME [epoch: 9.66 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21558129336987292		[learning rate: 0.0010663]
	Learning Rate: 0.00106634
	LOSS [training: 0.21558129336987292 | validation: 0.19540878802493974]
	TIME [epoch: 9.66 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22106865856450778		[learning rate: 0.0010638]
	Learning Rate: 0.00106383
	LOSS [training: 0.22106865856450778 | validation: 0.16919517695420946]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_999.pth
	Model improved!!!
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1959498506856021		[learning rate: 0.0010613]
	Learning Rate: 0.00106132
	LOSS [training: 0.1959498506856021 | validation: 0.19016671605730026]
	TIME [epoch: 9.68 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18415907574533671		[learning rate: 0.0010588]
	Learning Rate: 0.00105882
	LOSS [training: 0.18415907574533671 | validation: 0.17630834828746764]
	TIME [epoch: 9.66 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22405223282932307		[learning rate: 0.0010563]
	Learning Rate: 0.00105632
	LOSS [training: 0.22405223282932307 | validation: 0.2412152862283842]
	TIME [epoch: 9.66 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24290036958381783		[learning rate: 0.0010538]
	Learning Rate: 0.00105383
	LOSS [training: 0.24290036958381783 | validation: 0.23846325582074904]
	TIME [epoch: 9.67 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21305710912131107		[learning rate: 0.0010513]
	Learning Rate: 0.00105134
	LOSS [training: 0.21305710912131107 | validation: 0.24237606897867608]
	TIME [epoch: 9.67 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24986468784184077		[learning rate: 0.0010489]
	Learning Rate: 0.00104886
	LOSS [training: 0.24986468784184077 | validation: 0.2533160355717697]
	TIME [epoch: 9.66 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19035091989434552		[learning rate: 0.0010464]
	Learning Rate: 0.00104639
	LOSS [training: 0.19035091989434552 | validation: 0.23736774094433954]
	TIME [epoch: 9.66 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24880391098632063		[learning rate: 0.0010439]
	Learning Rate: 0.00104392
	LOSS [training: 0.24880391098632063 | validation: 0.2036657337714271]
	TIME [epoch: 9.68 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19472456298607305		[learning rate: 0.0010415]
	Learning Rate: 0.00104146
	LOSS [training: 0.19472456298607305 | validation: 0.2080887065529498]
	TIME [epoch: 9.66 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19651079404420285		[learning rate: 0.001039]
	Learning Rate: 0.001039
	LOSS [training: 0.19651079404420285 | validation: 0.22341926824899955]
	TIME [epoch: 9.66 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24131105846318873		[learning rate: 0.0010365]
	Learning Rate: 0.00103655
	LOSS [training: 0.24131105846318873 | validation: 0.24739295342213344]
	TIME [epoch: 9.68 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23937897566807237		[learning rate: 0.0010341]
	Learning Rate: 0.0010341
	LOSS [training: 0.23937897566807237 | validation: 0.21262787946871697]
	TIME [epoch: 9.67 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19654233106203353		[learning rate: 0.0010317]
	Learning Rate: 0.00103166
	LOSS [training: 0.19654233106203353 | validation: 0.29545426733822716]
	TIME [epoch: 9.66 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2252130260689842		[learning rate: 0.0010292]
	Learning Rate: 0.00102923
	LOSS [training: 0.2252130260689842 | validation: 0.21203185143796943]
	TIME [epoch: 9.67 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2034291441733091		[learning rate: 0.0010268]
	Learning Rate: 0.0010268
	LOSS [training: 0.2034291441733091 | validation: 0.2228947775953482]
	TIME [epoch: 9.68 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2009672517544275		[learning rate: 0.0010244]
	Learning Rate: 0.00102438
	LOSS [training: 0.2009672517544275 | validation: 0.16774699138030053]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_1015.pth
	Model improved!!!
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17520172764407005		[learning rate: 0.001022]
	Learning Rate: 0.00102196
	LOSS [training: 0.17520172764407005 | validation: 0.18248128689819992]
	TIME [epoch: 9.66 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20328828574039792		[learning rate: 0.0010196]
	Learning Rate: 0.00101955
	LOSS [training: 0.20328828574039792 | validation: 0.20727093648569458]
	TIME [epoch: 9.68 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18889221751819085		[learning rate: 0.0010171]
	Learning Rate: 0.00101715
	LOSS [training: 0.18889221751819085 | validation: 0.23890779037145457]
	TIME [epoch: 9.66 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18549364040355612		[learning rate: 0.0010147]
	Learning Rate: 0.00101475
	LOSS [training: 0.18549364040355612 | validation: 0.21696696526722378]
	TIME [epoch: 9.66 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19261306164024034		[learning rate: 0.0010124]
	Learning Rate: 0.00101236
	LOSS [training: 0.19261306164024034 | validation: 0.20740687217730236]
	TIME [epoch: 9.66 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18273864272086868		[learning rate: 0.00101]
	Learning Rate: 0.00100997
	LOSS [training: 0.18273864272086868 | validation: 0.20390274421708857]
	TIME [epoch: 9.67 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19043743846786726		[learning rate: 0.0010076]
	Learning Rate: 0.00100759
	LOSS [training: 0.19043743846786726 | validation: 0.26522510850249426]
	TIME [epoch: 9.66 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20771200522888872		[learning rate: 0.0010052]
	Learning Rate: 0.00100521
	LOSS [training: 0.20771200522888872 | validation: 0.1975886708445187]
	TIME [epoch: 9.66 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20157884147386032		[learning rate: 0.0010028]
	Learning Rate: 0.00100284
	LOSS [training: 0.20157884147386032 | validation: 0.23018967655899056]
	TIME [epoch: 9.68 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20065397510714966		[learning rate: 0.0010005]
	Learning Rate: 0.00100047
	LOSS [training: 0.20065397510714966 | validation: 0.20763159140460857]
	TIME [epoch: 9.66 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2407762285690505		[learning rate: 0.00099811]
	Learning Rate: 0.000998112
	LOSS [training: 0.2407762285690505 | validation: 0.3309187963352709]
	TIME [epoch: 9.66 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22089285558520108		[learning rate: 0.00099576]
	Learning Rate: 0.000995758
	LOSS [training: 0.22089285558520108 | validation: 0.20580425159860533]
	TIME [epoch: 9.66 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20303615659464014		[learning rate: 0.00099341]
	Learning Rate: 0.000993409
	LOSS [training: 0.20303615659464014 | validation: 0.1815910006513107]
	TIME [epoch: 9.67 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19450965092616423		[learning rate: 0.00099107]
	Learning Rate: 0.000991066
	LOSS [training: 0.19450965092616423 | validation: 0.2054188716604941]
	TIME [epoch: 9.66 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17902157810702812		[learning rate: 0.00098873]
	Learning Rate: 0.000988728
	LOSS [training: 0.17902157810702812 | validation: 0.23352405539355595]
	TIME [epoch: 9.65 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20556610690692767		[learning rate: 0.0009864]
	Learning Rate: 0.000986396
	LOSS [training: 0.20556610690692767 | validation: 0.22046770853558845]
	TIME [epoch: 9.68 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30648305456381514		[learning rate: 0.00098407]
	Learning Rate: 0.000984069
	LOSS [training: 0.30648305456381514 | validation: 0.2508966510128112]
	TIME [epoch: 9.65 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21109944120823876		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 0.21109944120823876 | validation: 0.21169784027433858]
	TIME [epoch: 9.66 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19926960802349028		[learning rate: 0.00097943]
	Learning Rate: 0.000979432
	LOSS [training: 0.19926960802349028 | validation: 0.21690713724708052]
	TIME [epoch: 9.67 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19556912116511718		[learning rate: 0.00097712]
	Learning Rate: 0.000977122
	LOSS [training: 0.19556912116511718 | validation: 0.18118004878018862]
	TIME [epoch: 9.66 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17450141588546247		[learning rate: 0.00097482]
	Learning Rate: 0.000974817
	LOSS [training: 0.17450141588546247 | validation: 0.20520965794967544]
	TIME [epoch: 9.66 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19972614888935417		[learning rate: 0.00097252]
	Learning Rate: 0.000972517
	LOSS [training: 0.19972614888935417 | validation: 0.2018193577300999]
	TIME [epoch: 9.66 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1903852903428089		[learning rate: 0.00097022]
	Learning Rate: 0.000970224
	LOSS [training: 0.1903852903428089 | validation: 0.2190217249748629]
	TIME [epoch: 9.69 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2512271944963487		[learning rate: 0.00096793]
	Learning Rate: 0.000967935
	LOSS [training: 0.2512271944963487 | validation: 0.42257664657264143]
	TIME [epoch: 9.64 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23700262082224216		[learning rate: 0.00096565]
	Learning Rate: 0.000965652
	LOSS [training: 0.23700262082224216 | validation: 0.2531336461944688]
	TIME [epoch: 9.66 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29061152211013963		[learning rate: 0.00096337]
	Learning Rate: 0.000963374
	LOSS [training: 0.29061152211013963 | validation: 0.22038358102722647]
	TIME [epoch: 9.66 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20054027529364973		[learning rate: 0.0009611]
	Learning Rate: 0.000961101
	LOSS [training: 0.20054027529364973 | validation: 0.21700751328514442]
	TIME [epoch: 9.66 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19796209035849027		[learning rate: 0.00095883]
	Learning Rate: 0.000958834
	LOSS [training: 0.19796209035849027 | validation: 0.21531810961838108]
	TIME [epoch: 9.66 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1760785157622753		[learning rate: 0.00095657]
	Learning Rate: 0.000956572
	LOSS [training: 0.1760785157622753 | validation: 0.21259173163342987]
	TIME [epoch: 9.65 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19882982586583592		[learning rate: 0.00095432]
	Learning Rate: 0.000954316
	LOSS [training: 0.19882982586583592 | validation: 0.23565866947650804]
	TIME [epoch: 9.67 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21569901792010276		[learning rate: 0.00095207]
	Learning Rate: 0.000952065
	LOSS [training: 0.21569901792010276 | validation: 0.28663488729818926]
	TIME [epoch: 9.65 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20430999726768886		[learning rate: 0.00094982]
	Learning Rate: 0.000949819
	LOSS [training: 0.20430999726768886 | validation: 0.20285629408331912]
	TIME [epoch: 9.66 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18757571043144391		[learning rate: 0.00094758]
	Learning Rate: 0.000947579
	LOSS [training: 0.18757571043144391 | validation: 0.23904361386598008]
	TIME [epoch: 9.67 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23758169752797306		[learning rate: 0.00094534]
	Learning Rate: 0.000945344
	LOSS [training: 0.23758169752797306 | validation: 0.2559907378912251]
	TIME [epoch: 9.66 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22317686970132328		[learning rate: 0.00094311]
	Learning Rate: 0.000943114
	LOSS [training: 0.22317686970132328 | validation: 0.5217629000559827]
	TIME [epoch: 9.65 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27991058657015777		[learning rate: 0.00094089]
	Learning Rate: 0.000940889
	LOSS [training: 0.27991058657015777 | validation: 0.27492698656680875]
	TIME [epoch: 9.68 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2445394525684062		[learning rate: 0.00093867]
	Learning Rate: 0.00093867
	LOSS [training: 0.2445394525684062 | validation: 0.242162821900942]
	TIME [epoch: 9.66 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21887896672800342		[learning rate: 0.00093646]
	Learning Rate: 0.000936456
	LOSS [training: 0.21887896672800342 | validation: 0.21819087856529634]
	TIME [epoch: 9.66 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20453585990439524		[learning rate: 0.00093425]
	Learning Rate: 0.000934246
	LOSS [training: 0.20453585990439524 | validation: 0.2668614275169332]
	TIME [epoch: 9.64 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2516787011268443		[learning rate: 0.00093204]
	Learning Rate: 0.000932043
	LOSS [training: 0.2516787011268443 | validation: 0.2624401182253235]
	TIME [epoch: 9.68 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21062499519567757		[learning rate: 0.00092984]
	Learning Rate: 0.000929844
	LOSS [training: 0.21062499519567757 | validation: 0.2805271000164265]
	TIME [epoch: 9.66 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20908786208169405		[learning rate: 0.00092765]
	Learning Rate: 0.000927651
	LOSS [training: 0.20908786208169405 | validation: 0.28772934717409293]
	TIME [epoch: 9.65 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22342237259163147		[learning rate: 0.00092546]
	Learning Rate: 0.000925463
	LOSS [training: 0.22342237259163147 | validation: 0.22149052887712292]
	TIME [epoch: 9.68 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1786350017292911		[learning rate: 0.00092328]
	Learning Rate: 0.00092328
	LOSS [training: 0.1786350017292911 | validation: 0.1853266523864442]
	TIME [epoch: 9.66 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18090004527202408		[learning rate: 0.0009211]
	Learning Rate: 0.000921102
	LOSS [training: 0.18090004527202408 | validation: 0.2094634956564172]
	TIME [epoch: 9.66 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1925830297574989		[learning rate: 0.00091893]
	Learning Rate: 0.000918929
	LOSS [training: 0.1925830297574989 | validation: 0.20000986040514235]
	TIME [epoch: 9.65 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20467029733595546		[learning rate: 0.00091676]
	Learning Rate: 0.000916762
	LOSS [training: 0.20467029733595546 | validation: 0.17815957512174552]
	TIME [epoch: 9.68 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18588956120343808		[learning rate: 0.0009146]
	Learning Rate: 0.000914599
	LOSS [training: 0.18588956120343808 | validation: 0.204205395075834]
	TIME [epoch: 9.65 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1779460868324812		[learning rate: 0.00091244]
	Learning Rate: 0.000912442
	LOSS [training: 0.1779460868324812 | validation: 0.2007978207608643]
	TIME [epoch: 9.66 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17895946073981683		[learning rate: 0.00091029]
	Learning Rate: 0.000910289
	LOSS [training: 0.17895946073981683 | validation: 0.19709520550013943]
	TIME [epoch: 9.68 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.175946193904205		[learning rate: 0.00090814]
	Learning Rate: 0.000908142
	LOSS [training: 0.175946193904205 | validation: 0.1904871745922386]
	TIME [epoch: 9.66 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2772847853161574		[learning rate: 0.000906]
	Learning Rate: 0.000906
	LOSS [training: 0.2772847853161574 | validation: 0.2542591733836289]
	TIME [epoch: 9.65 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20894876943951624		[learning rate: 0.00090386]
	Learning Rate: 0.000903863
	LOSS [training: 0.20894876943951624 | validation: 0.1814407319951794]
	TIME [epoch: 9.67 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1853945409115087		[learning rate: 0.00090173]
	Learning Rate: 0.000901731
	LOSS [training: 0.1853945409115087 | validation: 0.16736308878106024]
	TIME [epoch: 9.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_1069.pth
	Model improved!!!
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17946535811090747		[learning rate: 0.0008996]
	Learning Rate: 0.000899604
	LOSS [training: 0.17946535811090747 | validation: 0.1420641819392597]
	TIME [epoch: 9.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_1070.pth
	Model improved!!!
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20142558440714917		[learning rate: 0.00089748]
	Learning Rate: 0.000897482
	LOSS [training: 0.20142558440714917 | validation: 0.24709385922310265]
	TIME [epoch: 9.67 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19507338516634387		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.19507338516634387 | validation: 0.21774168534453986]
	TIME [epoch: 9.69 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19125164206045148		[learning rate: 0.00089325]
	Learning Rate: 0.000893253
	LOSS [training: 0.19125164206045148 | validation: 0.2124609645524488]
	TIME [epoch: 9.66 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.189681525219671		[learning rate: 0.00089115]
	Learning Rate: 0.000891146
	LOSS [training: 0.189681525219671 | validation: 0.24246930976653777]
	TIME [epoch: 9.66 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2122066807474377		[learning rate: 0.00088904]
	Learning Rate: 0.000889044
	LOSS [training: 0.2122066807474377 | validation: 0.20633444808348436]
	TIME [epoch: 9.67 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20477389006512697		[learning rate: 0.00088695]
	Learning Rate: 0.000886946
	LOSS [training: 0.20477389006512697 | validation: 0.23740670609627926]
	TIME [epoch: 9.68 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2199129165923651		[learning rate: 0.00088485]
	Learning Rate: 0.000884854
	LOSS [training: 0.2199129165923651 | validation: 0.2892569349343954]
	TIME [epoch: 9.66 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23662576437332192		[learning rate: 0.00088277]
	Learning Rate: 0.000882767
	LOSS [training: 0.23662576437332192 | validation: 0.18729878685603538]
	TIME [epoch: 9.66 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18002123548477086		[learning rate: 0.00088068]
	Learning Rate: 0.000880685
	LOSS [training: 0.18002123548477086 | validation: 0.21281129907387186]
	TIME [epoch: 9.68 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1837841509015151		[learning rate: 0.00087861]
	Learning Rate: 0.000878607
	LOSS [training: 0.1837841509015151 | validation: 0.1802965790175209]
	TIME [epoch: 9.66 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1692658771965649		[learning rate: 0.00087653]
	Learning Rate: 0.000876535
	LOSS [training: 0.1692658771965649 | validation: 0.18382725238090075]
	TIME [epoch: 9.66 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16950627803768206		[learning rate: 0.00087447]
	Learning Rate: 0.000874467
	LOSS [training: 0.16950627803768206 | validation: 0.2219013536824074]
	TIME [epoch: 9.68 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19571535905768966		[learning rate: 0.0008724]
	Learning Rate: 0.000872405
	LOSS [training: 0.19571535905768966 | validation: 0.19468048135190785]
	TIME [epoch: 9.67 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19058330913387694		[learning rate: 0.00087035]
	Learning Rate: 0.000870346
	LOSS [training: 0.19058330913387694 | validation: 0.22944271561500046]
	TIME [epoch: 9.66 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3192394438383538		[learning rate: 0.00086829]
	Learning Rate: 0.000868294
	LOSS [training: 0.3192394438383538 | validation: 0.28639775297792136]
	TIME [epoch: 9.66 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23010690091463215		[learning rate: 0.00086625]
	Learning Rate: 0.000866246
	LOSS [training: 0.23010690091463215 | validation: 0.20437060083293174]
	TIME [epoch: 9.69 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2284224653185684		[learning rate: 0.0008642]
	Learning Rate: 0.000864202
	LOSS [training: 0.2284224653185684 | validation: 0.3082544879461703]
	TIME [epoch: 9.66 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.281959541748983		[learning rate: 0.00086216]
	Learning Rate: 0.000862164
	LOSS [training: 0.281959541748983 | validation: 0.2769371727564858]
	TIME [epoch: 9.66 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24313963418554754		[learning rate: 0.00086013]
	Learning Rate: 0.00086013
	LOSS [training: 0.24313963418554754 | validation: 0.25171325085932306]
	TIME [epoch: 9.68 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2394734700947591		[learning rate: 0.0008581]
	Learning Rate: 0.000858101
	LOSS [training: 0.2394734700947591 | validation: 0.2930590765757468]
	TIME [epoch: 9.67 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24239012641694863		[learning rate: 0.00085608]
	Learning Rate: 0.000856077
	LOSS [training: 0.24239012641694863 | validation: 0.21195819857925016]
	TIME [epoch: 9.66 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1925580981663446		[learning rate: 0.00085406]
	Learning Rate: 0.000854058
	LOSS [training: 0.1925580981663446 | validation: 0.2291997078813484]
	TIME [epoch: 9.65 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22701500858803145		[learning rate: 0.00085204]
	Learning Rate: 0.000852043
	LOSS [training: 0.22701500858803145 | validation: 0.2793526167347023]
	TIME [epoch: 9.68 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22809714092671976		[learning rate: 0.00085003]
	Learning Rate: 0.000850033
	LOSS [training: 0.22809714092671976 | validation: 0.21234396440527203]
	TIME [epoch: 9.65 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20332976491895374		[learning rate: 0.00084803]
	Learning Rate: 0.000848028
	LOSS [training: 0.20332976491895374 | validation: 0.21326100759366015]
	TIME [epoch: 9.65 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20272859333840101		[learning rate: 0.00084603]
	Learning Rate: 0.000846028
	LOSS [training: 0.20272859333840101 | validation: 0.20809210468516134]
	TIME [epoch: 9.68 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18396877285789995		[learning rate: 0.00084403]
	Learning Rate: 0.000844032
	LOSS [training: 0.18396877285789995 | validation: 0.24808093401361667]
	TIME [epoch: 9.66 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20239233262483786		[learning rate: 0.00084204]
	Learning Rate: 0.000842041
	LOSS [training: 0.20239233262483786 | validation: 0.24346682123131935]
	TIME [epoch: 9.66 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21182283311352168		[learning rate: 0.00084005]
	Learning Rate: 0.000840055
	LOSS [training: 0.21182283311352168 | validation: 0.22596096786209546]
	TIME [epoch: 9.66 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18972523739173014		[learning rate: 0.00083807]
	Learning Rate: 0.000838073
	LOSS [training: 0.18972523739173014 | validation: 0.20872798194847586]
	TIME [epoch: 9.67 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17117886651620604		[learning rate: 0.0008361]
	Learning Rate: 0.000836096
	LOSS [training: 0.17117886651620604 | validation: 0.19314094412751054]
	TIME [epoch: 9.66 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18592336232719037		[learning rate: 0.00083412]
	Learning Rate: 0.000834124
	LOSS [training: 0.18592336232719037 | validation: 0.18429493995156443]
	TIME [epoch: 9.65 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1698591380575231		[learning rate: 0.00083216]
	Learning Rate: 0.000832157
	LOSS [training: 0.1698591380575231 | validation: 0.20526205153252858]
	TIME [epoch: 9.68 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.162568665568816		[learning rate: 0.00083019]
	Learning Rate: 0.000830194
	LOSS [training: 0.162568665568816 | validation: 0.21041030072932443]
	TIME [epoch: 9.66 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21565136420456069		[learning rate: 0.00082824]
	Learning Rate: 0.000828236
	LOSS [training: 0.21565136420456069 | validation: 0.25829657511058396]
	TIME [epoch: 9.66 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20962954790329977		[learning rate: 0.00082628]
	Learning Rate: 0.000826282
	LOSS [training: 0.20962954790329977 | validation: 0.23635379010904906]
	TIME [epoch: 9.67 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2131834875040158		[learning rate: 0.00082433]
	Learning Rate: 0.000824333
	LOSS [training: 0.2131834875040158 | validation: 0.24457387931382196]
	TIME [epoch: 9.67 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19765360042343602		[learning rate: 0.00082239]
	Learning Rate: 0.000822388
	LOSS [training: 0.19765360042343602 | validation: 0.1528285067050668]
	TIME [epoch: 9.66 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16371277171908813		[learning rate: 0.00082045]
	Learning Rate: 0.000820448
	LOSS [training: 0.16371277171908813 | validation: 0.16782044182264425]
	TIME [epoch: 9.66 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1543767377547357		[learning rate: 0.00081851]
	Learning Rate: 0.000818513
	LOSS [training: 0.1543767377547357 | validation: 0.22880379810393933]
	TIME [epoch: 9.68 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18484663336310794		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.18484663336310794 | validation: 0.17573029845521201]
	TIME [epoch: 9.66 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18329906710425353		[learning rate: 0.00081466]
	Learning Rate: 0.000814656
	LOSS [training: 0.18329906710425353 | validation: 0.17971808199076356]
	TIME [epoch: 9.65 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1817186620778678		[learning rate: 0.00081273]
	Learning Rate: 0.000812734
	LOSS [training: 0.1817186620778678 | validation: 0.18059650580187786]
	TIME [epoch: 9.68 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18447316567584765		[learning rate: 0.00081082]
	Learning Rate: 0.000810817
	LOSS [training: 0.18447316567584765 | validation: 0.27889087263716644]
	TIME [epoch: 9.66 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20252186039166364		[learning rate: 0.0008089]
	Learning Rate: 0.000808905
	LOSS [training: 0.20252186039166364 | validation: 0.2675578401993281]
	TIME [epoch: 9.66 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2312105763725131		[learning rate: 0.000807]
	Learning Rate: 0.000806997
	LOSS [training: 0.2312105763725131 | validation: 0.1776467850454219]
	TIME [epoch: 9.66 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20921333894132363		[learning rate: 0.00080509]
	Learning Rate: 0.000805093
	LOSS [training: 0.20921333894132363 | validation: 0.22159775059404294]
	TIME [epoch: 9.68 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19476064119832734		[learning rate: 0.00080319]
	Learning Rate: 0.000803194
	LOSS [training: 0.19476064119832734 | validation: 0.21383938264678023]
	TIME [epoch: 9.66 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18187080570224962		[learning rate: 0.0008013]
	Learning Rate: 0.000801299
	LOSS [training: 0.18187080570224962 | validation: 0.1672102707459335]
	TIME [epoch: 9.66 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17236311180585437		[learning rate: 0.00079941]
	Learning Rate: 0.000799409
	LOSS [training: 0.17236311180585437 | validation: 0.19433682413768918]
	TIME [epoch: 9.67 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1808522446990038		[learning rate: 0.00079752]
	Learning Rate: 0.000797524
	LOSS [training: 0.1808522446990038 | validation: 0.21280900358461396]
	TIME [epoch: 9.66 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16902649686031654		[learning rate: 0.00079564]
	Learning Rate: 0.000795642
	LOSS [training: 0.16902649686031654 | validation: 0.19404607591830325]
	TIME [epoch: 9.65 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.184766829546288		[learning rate: 0.00079377]
	Learning Rate: 0.000793766
	LOSS [training: 0.184766829546288 | validation: 0.22210362834296335]
	TIME [epoch: 9.66 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19659968442199816		[learning rate: 0.00079189]
	Learning Rate: 0.000791893
	LOSS [training: 0.19659968442199816 | validation: 0.1826626202692092]
	TIME [epoch: 9.67 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17436477092646294		[learning rate: 0.00079003]
	Learning Rate: 0.000790025
	LOSS [training: 0.17436477092646294 | validation: 0.24074307496228262]
	TIME [epoch: 9.65 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19974112309681144		[learning rate: 0.00078816]
	Learning Rate: 0.000788162
	LOSS [training: 0.19974112309681144 | validation: 0.18056414562219036]
	TIME [epoch: 9.65 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1659985931400039		[learning rate: 0.0007863]
	Learning Rate: 0.000786302
	LOSS [training: 0.1659985931400039 | validation: 0.1794928690088205]
	TIME [epoch: 9.68 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18445780882191662		[learning rate: 0.00078445]
	Learning Rate: 0.000784448
	LOSS [training: 0.18445780882191662 | validation: 0.19315951497441297]
	TIME [epoch: 9.65 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16247913990904378		[learning rate: 0.0007826]
	Learning Rate: 0.000782598
	LOSS [training: 0.16247913990904378 | validation: 0.16240712271830823]
	TIME [epoch: 9.66 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1546330126972222		[learning rate: 0.00078075]
	Learning Rate: 0.000780751
	LOSS [training: 0.1546330126972222 | validation: 0.1885671602551273]
	TIME [epoch: 9.67 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2576165154512233		[learning rate: 0.00077891]
	Learning Rate: 0.00077891
	LOSS [training: 0.2576165154512233 | validation: 0.36474641348988657]
	TIME [epoch: 9.67 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2433121586745461		[learning rate: 0.00077707]
	Learning Rate: 0.000777073
	LOSS [training: 0.2433121586745461 | validation: 0.24978750917590034]
	TIME [epoch: 9.66 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20172587092269761		[learning rate: 0.00077524]
	Learning Rate: 0.000775239
	LOSS [training: 0.20172587092269761 | validation: 0.17392733827961454]
	TIME [epoch: 9.66 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17691706734142124		[learning rate: 0.00077341]
	Learning Rate: 0.000773411
	LOSS [training: 0.17691706734142124 | validation: 0.28583657505179266]
	TIME [epoch: 9.68 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21513057452175727		[learning rate: 0.00077159]
	Learning Rate: 0.000771586
	LOSS [training: 0.21513057452175727 | validation: 0.16911865563870215]
	TIME [epoch: 9.66 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1533875919276626		[learning rate: 0.00076977]
	Learning Rate: 0.000769766
	LOSS [training: 0.1533875919276626 | validation: 0.17990848350730634]
	TIME [epoch: 9.65 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1808981212220211		[learning rate: 0.00076795]
	Learning Rate: 0.000767951
	LOSS [training: 0.1808981212220211 | validation: 0.20978618284618694]
	TIME [epoch: 9.67 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18180214874444917		[learning rate: 0.00076614]
	Learning Rate: 0.000766139
	LOSS [training: 0.18180214874444917 | validation: 0.188730455465221]
	TIME [epoch: 9.66 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16871802472196562		[learning rate: 0.00076433]
	Learning Rate: 0.000764332
	LOSS [training: 0.16871802472196562 | validation: 0.14629511734815231]
	TIME [epoch: 9.66 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17229744081166704		[learning rate: 0.00076253]
	Learning Rate: 0.000762529
	LOSS [training: 0.17229744081166704 | validation: 0.21898263662759088]
	TIME [epoch: 9.66 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1897074808580504		[learning rate: 0.00076073]
	Learning Rate: 0.00076073
	LOSS [training: 0.1897074808580504 | validation: 0.24896038651335248]
	TIME [epoch: 9.67 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20044621343235436		[learning rate: 0.00075894]
	Learning Rate: 0.000758936
	LOSS [training: 0.20044621343235436 | validation: 0.1718053267135238]
	TIME [epoch: 9.66 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1448524541773537		[learning rate: 0.00075715]
	Learning Rate: 0.000757146
	LOSS [training: 0.1448524541773537 | validation: 0.1720958101227873]
	TIME [epoch: 9.66 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15426551256423154		[learning rate: 0.00075536]
	Learning Rate: 0.00075536
	LOSS [training: 0.15426551256423154 | validation: 0.18271678263446056]
	TIME [epoch: 9.67 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21170746428326637		[learning rate: 0.00075358]
	Learning Rate: 0.000753578
	LOSS [training: 0.21170746428326637 | validation: 0.24421307022204997]
	TIME [epoch: 9.66 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1749150152775505		[learning rate: 0.0007518]
	Learning Rate: 0.0007518
	LOSS [training: 0.1749150152775505 | validation: 0.1798510557017007]
	TIME [epoch: 9.65 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15184718568051378		[learning rate: 0.00075003]
	Learning Rate: 0.000750027
	LOSS [training: 0.15184718568051378 | validation: 0.16599385190342084]
	TIME [epoch: 9.66 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14442529430444667		[learning rate: 0.00074826]
	Learning Rate: 0.000748258
	LOSS [training: 0.14442529430444667 | validation: 0.1623424153860991]
	TIME [epoch: 9.67 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18047220092799662		[learning rate: 0.00074649]
	Learning Rate: 0.000746493
	LOSS [training: 0.18047220092799662 | validation: 0.1801136749153382]
	TIME [epoch: 9.65 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16481731891063361		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.16481731891063361 | validation: 0.1773953811416917]
	TIME [epoch: 9.65 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17811148478874173		[learning rate: 0.00074298]
	Learning Rate: 0.000742975
	LOSS [training: 0.17811148478874173 | validation: 0.20732040529178214]
	TIME [epoch: 9.67 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1751728564287061		[learning rate: 0.00074122]
	Learning Rate: 0.000741223
	LOSS [training: 0.1751728564287061 | validation: 0.20520642469646766]
	TIME [epoch: 9.65 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16783228884341633		[learning rate: 0.00073947]
	Learning Rate: 0.000739474
	LOSS [training: 0.16783228884341633 | validation: 0.2271406672227802]
	TIME [epoch: 9.65 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21431770501305544		[learning rate: 0.00073773]
	Learning Rate: 0.00073773
	LOSS [training: 0.21431770501305544 | validation: 0.24121460486814997]
	TIME [epoch: 9.67 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21026396654285975		[learning rate: 0.00073599]
	Learning Rate: 0.00073599
	LOSS [training: 0.21026396654285975 | validation: 0.21580582796565037]
	TIME [epoch: 9.65 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1664167783199598		[learning rate: 0.00073425]
	Learning Rate: 0.000734254
	LOSS [training: 0.1664167783199598 | validation: 0.2146494973959464]
	TIME [epoch: 9.65 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14614780207499328		[learning rate: 0.00073252]
	Learning Rate: 0.000732522
	LOSS [training: 0.14614780207499328 | validation: 0.18955598503697274]
	TIME [epoch: 9.65 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1540531565230799		[learning rate: 0.00073079]
	Learning Rate: 0.000730794
	LOSS [training: 0.1540531565230799 | validation: 0.17543024826334253]
	TIME [epoch: 9.67 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14891825762388383		[learning rate: 0.00072907]
	Learning Rate: 0.00072907
	LOSS [training: 0.14891825762388383 | validation: 0.18148203565803533]
	TIME [epoch: 9.65 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14928805599580716		[learning rate: 0.00072735]
	Learning Rate: 0.00072735
	LOSS [training: 0.14928805599580716 | validation: 0.19056680143638766]
	TIME [epoch: 9.65 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18130658041958952		[learning rate: 0.00072563]
	Learning Rate: 0.000725634
	LOSS [training: 0.18130658041958952 | validation: 0.14495204087729763]
	TIME [epoch: 9.67 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17045368527151955		[learning rate: 0.00072392]
	Learning Rate: 0.000723923
	LOSS [training: 0.17045368527151955 | validation: 0.23954106117471508]
	TIME [epoch: 9.65 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20756588431954034		[learning rate: 0.00072222]
	Learning Rate: 0.000722215
	LOSS [training: 0.20756588431954034 | validation: 0.2200595241567997]
	TIME [epoch: 9.65 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18321307829804095		[learning rate: 0.00072051]
	Learning Rate: 0.000720512
	LOSS [training: 0.18321307829804095 | validation: 0.22261000167293618]
	TIME [epoch: 9.66 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.185275608227932		[learning rate: 0.00071881]
	Learning Rate: 0.000718812
	LOSS [training: 0.185275608227932 | validation: 0.1458218452372179]
	TIME [epoch: 9.68 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17438401936130665		[learning rate: 0.00071712]
	Learning Rate: 0.000717117
	LOSS [training: 0.17438401936130665 | validation: 0.22668279443625416]
	TIME [epoch: 9.65 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17309629785986297		[learning rate: 0.00071542]
	Learning Rate: 0.000715425
	LOSS [training: 0.17309629785986297 | validation: 0.17538688397989127]
	TIME [epoch: 9.65 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16821779448306556		[learning rate: 0.00071374]
	Learning Rate: 0.000713738
	LOSS [training: 0.16821779448306556 | validation: 0.20395351099756284]
	TIME [epoch: 9.68 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16765284773189223		[learning rate: 0.00071205]
	Learning Rate: 0.000712054
	LOSS [training: 0.16765284773189223 | validation: 0.15871640750796873]
	TIME [epoch: 9.65 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15886063338389403		[learning rate: 0.00071037]
	Learning Rate: 0.000710374
	LOSS [training: 0.15886063338389403 | validation: 0.16601754537884353]
	TIME [epoch: 9.66 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15576432144674873		[learning rate: 0.0007087]
	Learning Rate: 0.000708698
	LOSS [training: 0.15576432144674873 | validation: 0.19524018513814453]
	TIME [epoch: 9.67 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1637938363645311		[learning rate: 0.00070703]
	Learning Rate: 0.000707027
	LOSS [training: 0.1637938363645311 | validation: 0.18482932175990727]
	TIME [epoch: 9.67 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17099022779781872		[learning rate: 0.00070536]
	Learning Rate: 0.000705359
	LOSS [training: 0.17099022779781872 | validation: 0.21353866075255262]
	TIME [epoch: 9.65 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17051410240736403		[learning rate: 0.0007037]
	Learning Rate: 0.000703695
	LOSS [training: 0.17051410240736403 | validation: 0.20123545027268214]
	TIME [epoch: 9.65 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1783388915740982		[learning rate: 0.00070204]
	Learning Rate: 0.000702035
	LOSS [training: 0.1783388915740982 | validation: 0.17020565473653876]
	TIME [epoch: 9.68 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17516371127560357		[learning rate: 0.00070038]
	Learning Rate: 0.000700379
	LOSS [training: 0.17516371127560357 | validation: 0.25068117406302093]
	TIME [epoch: 9.66 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18298394343050883		[learning rate: 0.00069873]
	Learning Rate: 0.000698727
	LOSS [training: 0.18298394343050883 | validation: 0.16793231705295056]
	TIME [epoch: 9.65 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512181499904714		[learning rate: 0.00069708]
	Learning Rate: 0.000697079
	LOSS [training: 0.1512181499904714 | validation: 0.19263005659491683]
	TIME [epoch: 9.67 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15943441461007346		[learning rate: 0.00069543]
	Learning Rate: 0.000695435
	LOSS [training: 0.15943441461007346 | validation: 0.16171295157635832]
	TIME [epoch: 9.66 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512089189976446		[learning rate: 0.00069379]
	Learning Rate: 0.000693794
	LOSS [training: 0.1512089189976446 | validation: 0.21565344595018324]
	TIME [epoch: 9.65 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19574519428326684		[learning rate: 0.00069216]
	Learning Rate: 0.000692158
	LOSS [training: 0.19574519428326684 | validation: 0.1703074816527184]
	TIME [epoch: 9.65 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14754394756254205		[learning rate: 0.00069053]
	Learning Rate: 0.000690525
	LOSS [training: 0.14754394756254205 | validation: 0.2910624690514244]
	TIME [epoch: 9.68 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20666760202602505		[learning rate: 0.0006889]
	Learning Rate: 0.000688896
	LOSS [training: 0.20666760202602505 | validation: 0.15601833606604917]
	TIME [epoch: 9.65 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1679360912920131		[learning rate: 0.00068727]
	Learning Rate: 0.000687271
	LOSS [training: 0.1679360912920131 | validation: 0.21105186731184225]
	TIME [epoch: 9.65 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17606696930981117		[learning rate: 0.00068565]
	Learning Rate: 0.00068565
	LOSS [training: 0.17606696930981117 | validation: 0.17600148941445767]
	TIME [epoch: 9.67 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1675319854190891		[learning rate: 0.00068403]
	Learning Rate: 0.000684033
	LOSS [training: 0.1675319854190891 | validation: 0.1768847506985347]
	TIME [epoch: 9.66 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13878087491375551		[learning rate: 0.00068242]
	Learning Rate: 0.000682419
	LOSS [training: 0.13878087491375551 | validation: 0.21491496261365034]
	TIME [epoch: 9.65 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1772264549407319		[learning rate: 0.00068081]
	Learning Rate: 0.00068081
	LOSS [training: 0.1772264549407319 | validation: 0.2522803840066001]
	TIME [epoch: 9.66 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20370723428535734		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.20370723428535734 | validation: 0.19510314849732596]
	TIME [epoch: 9.67 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1563341490792225		[learning rate: 0.0006776]
	Learning Rate: 0.000677601
	LOSS [training: 0.1563341490792225 | validation: 0.20882548701948736]
	TIME [epoch: 9.65 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15323410735391182		[learning rate: 0.000676]
	Learning Rate: 0.000676003
	LOSS [training: 0.15323410735391182 | validation: 0.16293023491118344]
	TIME [epoch: 9.65 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18114669903230057		[learning rate: 0.00067441]
	Learning Rate: 0.000674409
	LOSS [training: 0.18114669903230057 | validation: 0.26389787465175063]
	TIME [epoch: 9.68 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18448882818706885		[learning rate: 0.00067282]
	Learning Rate: 0.000672818
	LOSS [training: 0.18448882818706885 | validation: 0.24714789041075833]
	TIME [epoch: 9.65 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18629574830777534		[learning rate: 0.00067123]
	Learning Rate: 0.000671231
	LOSS [training: 0.18629574830777534 | validation: 0.1769871194048893]
	TIME [epoch: 9.65 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17235357128080492		[learning rate: 0.00066965]
	Learning Rate: 0.000669647
	LOSS [training: 0.17235357128080492 | validation: 0.17081292035542892]
	TIME [epoch: 9.66 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16269856391897222		[learning rate: 0.00066807]
	Learning Rate: 0.000668068
	LOSS [training: 0.16269856391897222 | validation: 0.1984059547329371]
	TIME [epoch: 9.67 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21390780083929056		[learning rate: 0.00066649]
	Learning Rate: 0.000666492
	LOSS [training: 0.21390780083929056 | validation: 0.2906421943151495]
	TIME [epoch: 9.66 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2581639813006854		[learning rate: 0.00066492]
	Learning Rate: 0.00066492
	LOSS [training: 0.2581639813006854 | validation: 0.18937956788744964]
	TIME [epoch: 9.66 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15154059520865676		[learning rate: 0.00066335]
	Learning Rate: 0.000663351
	LOSS [training: 0.15154059520865676 | validation: 0.16295178385065384]
	TIME [epoch: 9.68 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15665319360698324		[learning rate: 0.00066179]
	Learning Rate: 0.000661786
	LOSS [training: 0.15665319360698324 | validation: 0.29493074192261814]
	TIME [epoch: 9.65 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17144579808342825		[learning rate: 0.00066023]
	Learning Rate: 0.000660225
	LOSS [training: 0.17144579808342825 | validation: 0.1887396560959617]
	TIME [epoch: 9.65 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16261009788105038		[learning rate: 0.00065867]
	Learning Rate: 0.000658668
	LOSS [training: 0.16261009788105038 | validation: 0.18287761028822783]
	TIME [epoch: 9.68 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17289786331091733		[learning rate: 0.00065711]
	Learning Rate: 0.000657114
	LOSS [training: 0.17289786331091733 | validation: 0.2384280959824787]
	TIME [epoch: 9.66 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19477493227824932		[learning rate: 0.00065556]
	Learning Rate: 0.000655564
	LOSS [training: 0.19477493227824932 | validation: 0.17592099453222584]
	TIME [epoch: 9.66 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16600880492579728		[learning rate: 0.00065402]
	Learning Rate: 0.000654018
	LOSS [training: 0.16600880492579728 | validation: 0.18228043658126475]
	TIME [epoch: 9.65 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1732165536486967		[learning rate: 0.00065248]
	Learning Rate: 0.000652475
	LOSS [training: 0.1732165536486967 | validation: 0.1676286111079514]
	TIME [epoch: 9.68 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15224124930411498		[learning rate: 0.00065094]
	Learning Rate: 0.000650936
	LOSS [training: 0.15224124930411498 | validation: 0.22234235616935377]
	TIME [epoch: 9.66 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15846262568231462		[learning rate: 0.0006494]
	Learning Rate: 0.000649401
	LOSS [training: 0.15846262568231462 | validation: 0.1644867454461298]
	TIME [epoch: 9.65 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19336835215970688		[learning rate: 0.00064787]
	Learning Rate: 0.000647869
	LOSS [training: 0.19336835215970688 | validation: 0.25931770567054024]
	TIME [epoch: 9.67 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2120919369519679		[learning rate: 0.00064634]
	Learning Rate: 0.000646341
	LOSS [training: 0.2120919369519679 | validation: 0.23164092262720368]
	TIME [epoch: 9.66 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19210531059746389		[learning rate: 0.00064482]
	Learning Rate: 0.000644816
	LOSS [training: 0.19210531059746389 | validation: 0.1988897066741957]
	TIME [epoch: 9.66 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15418156290068774		[learning rate: 0.0006433]
	Learning Rate: 0.000643295
	LOSS [training: 0.15418156290068774 | validation: 0.18044224247523288]
	TIME [epoch: 9.65 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16757459043403822		[learning rate: 0.00064178]
	Learning Rate: 0.000641778
	LOSS [training: 0.16757459043403822 | validation: 0.23800905204572406]
	TIME [epoch: 9.67 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1769202550852563		[learning rate: 0.00064026]
	Learning Rate: 0.000640264
	LOSS [training: 0.1769202550852563 | validation: 0.16171443748424494]
	TIME [epoch: 9.65 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13632490231239297		[learning rate: 0.00063875]
	Learning Rate: 0.000638754
	LOSS [training: 0.13632490231239297 | validation: 0.20184315620889492]
	TIME [epoch: 9.65 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17041581169145192		[learning rate: 0.00063725]
	Learning Rate: 0.000637247
	LOSS [training: 0.17041581169145192 | validation: 0.24115576844657938]
	TIME [epoch: 9.68 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19008560550881226		[learning rate: 0.00063574]
	Learning Rate: 0.000635744
	LOSS [training: 0.19008560550881226 | validation: 0.19959680390358245]
	TIME [epoch: 9.66 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16576911368747507		[learning rate: 0.00063424]
	Learning Rate: 0.000634244
	LOSS [training: 0.16576911368747507 | validation: 0.19703942594646917]
	TIME [epoch: 9.66 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1495382337503397		[learning rate: 0.00063275]
	Learning Rate: 0.000632748
	LOSS [training: 0.1495382337503397 | validation: 0.17511429509442594]
	TIME [epoch: 9.67 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1504087829217656		[learning rate: 0.00063126]
	Learning Rate: 0.000631255
	LOSS [training: 0.1504087829217656 | validation: 0.2146896102567003]
	TIME [epoch: 9.66 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16828392418084018		[learning rate: 0.00062977]
	Learning Rate: 0.000629766
	LOSS [training: 0.16828392418084018 | validation: 0.18364542161484135]
	TIME [epoch: 9.66 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14387936815929575		[learning rate: 0.00062828]
	Learning Rate: 0.000628281
	LOSS [training: 0.14387936815929575 | validation: 0.18159419166231264]
	TIME [epoch: 9.65 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15108621555961635		[learning rate: 0.0006268]
	Learning Rate: 0.000626799
	LOSS [training: 0.15108621555961635 | validation: 0.15849036797307947]
	TIME [epoch: 9.67 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13897944210200658		[learning rate: 0.00062532]
	Learning Rate: 0.00062532
	LOSS [training: 0.13897944210200658 | validation: 0.1765791563035735]
	TIME [epoch: 9.66 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14680995080952766		[learning rate: 0.00062385]
	Learning Rate: 0.000623845
	LOSS [training: 0.14680995080952766 | validation: 0.21078262892644262]
	TIME [epoch: 9.65 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23634201130887042		[learning rate: 0.00062237]
	Learning Rate: 0.000622374
	LOSS [training: 0.23634201130887042 | validation: 0.18491874768685523]
	TIME [epoch: 9.67 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17211395601488863		[learning rate: 0.00062091]
	Learning Rate: 0.000620906
	LOSS [training: 0.17211395601488863 | validation: 0.1686696269895798]
	TIME [epoch: 9.66 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15976201646068314		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.15976201646068314 | validation: 0.195831560530632]
	TIME [epoch: 9.65 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1942600100411244		[learning rate: 0.00061798]
	Learning Rate: 0.00061798
	LOSS [training: 0.1942600100411244 | validation: 0.2065679708851853]
	TIME [epoch: 9.65 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18578346631961376		[learning rate: 0.00061652]
	Learning Rate: 0.000616522
	LOSS [training: 0.18578346631961376 | validation: 0.2284989928051511]
	TIME [epoch: 9.67 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16683571026578398		[learning rate: 0.00061507]
	Learning Rate: 0.000615068
	LOSS [training: 0.16683571026578398 | validation: 0.15345882087541526]
	TIME [epoch: 9.65 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15181408570411184		[learning rate: 0.00061362]
	Learning Rate: 0.000613617
	LOSS [training: 0.15181408570411184 | validation: 0.17028530802184594]
	TIME [epoch: 9.65 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1667462654433925		[learning rate: 0.00061217]
	Learning Rate: 0.00061217
	LOSS [training: 0.1667462654433925 | validation: 0.2020309458456353]
	TIME [epoch: 9.68 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16636594788159778		[learning rate: 0.00061073]
	Learning Rate: 0.000610726
	LOSS [training: 0.16636594788159778 | validation: 0.19784115586094494]
	TIME [epoch: 9.65 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1843964341562853		[learning rate: 0.00060929]
	Learning Rate: 0.000609285
	LOSS [training: 0.1843964341562853 | validation: 0.18375331322968158]
	TIME [epoch: 9.66 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16539676603001824		[learning rate: 0.00060785]
	Learning Rate: 0.000607848
	LOSS [training: 0.16539676603001824 | validation: 0.19410526832571506]
	TIME [epoch: 9.65 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15525091273248698		[learning rate: 0.00060641]
	Learning Rate: 0.000606414
	LOSS [training: 0.15525091273248698 | validation: 0.2363958133947237]
	TIME [epoch: 9.67 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16666268695747152		[learning rate: 0.00060498]
	Learning Rate: 0.000604983
	LOSS [training: 0.16666268695747152 | validation: 0.15080362992196603]
	TIME [epoch: 9.65 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14942752109058888		[learning rate: 0.00060356]
	Learning Rate: 0.000603557
	LOSS [training: 0.14942752109058888 | validation: 0.1814149655038607]
	TIME [epoch: 9.66 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17633995973984445		[learning rate: 0.00060213]
	Learning Rate: 0.000602133
	LOSS [training: 0.17633995973984445 | validation: 0.19134156120209903]
	TIME [epoch: 9.68 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1778894444984414		[learning rate: 0.00060071]
	Learning Rate: 0.000600712
	LOSS [training: 0.1778894444984414 | validation: 0.18678064162235433]
	TIME [epoch: 9.66 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13505868232035245		[learning rate: 0.0005993]
	Learning Rate: 0.000599296
	LOSS [training: 0.13505868232035245 | validation: 0.15744902510953676]
	TIME [epoch: 9.65 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.144604536063408		[learning rate: 0.00059788]
	Learning Rate: 0.000597882
	LOSS [training: 0.144604536063408 | validation: 0.19509550114170143]
	TIME [epoch: 9.67 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15063831997244445		[learning rate: 0.00059647]
	Learning Rate: 0.000596471
	LOSS [training: 0.15063831997244445 | validation: 0.15211227386085158]
	TIME [epoch: 9.66 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14763477057083368		[learning rate: 0.00059506]
	Learning Rate: 0.000595065
	LOSS [training: 0.14763477057083368 | validation: 0.2159669234711602]
	TIME [epoch: 9.65 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1376216728231244		[learning rate: 0.00059366]
	Learning Rate: 0.000593661
	LOSS [training: 0.1376216728231244 | validation: 0.2071321207960357]
	TIME [epoch: 9.65 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1588958722456508		[learning rate: 0.00059226]
	Learning Rate: 0.000592261
	LOSS [training: 0.1588958722456508 | validation: 0.21852481804062465]
	TIME [epoch: 9.67 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16533302294074076		[learning rate: 0.00059086]
	Learning Rate: 0.000590863
	LOSS [training: 0.16533302294074076 | validation: 0.2450810408335382]
	TIME [epoch: 9.65 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17203386792619507		[learning rate: 0.00058947]
	Learning Rate: 0.00058947
	LOSS [training: 0.17203386792619507 | validation: 0.1936704553662903]
	TIME [epoch: 9.65 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13176843065989335		[learning rate: 0.00058808]
	Learning Rate: 0.000588079
	LOSS [training: 0.13176843065989335 | validation: 0.24365526000300947]
	TIME [epoch: 9.67 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14338769547677313		[learning rate: 0.00058669]
	Learning Rate: 0.000586692
	LOSS [training: 0.14338769547677313 | validation: 0.19252978306840426]
	TIME [epoch: 9.65 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15854531452577103		[learning rate: 0.00058531]
	Learning Rate: 0.000585308
	LOSS [training: 0.15854531452577103 | validation: 0.24096122452486712]
	TIME [epoch: 9.65 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15276836933771953		[learning rate: 0.00058393]
	Learning Rate: 0.000583927
	LOSS [training: 0.15276836933771953 | validation: 0.19689234032085345]
	TIME [epoch: 9.66 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13842001374290033		[learning rate: 0.00058255]
	Learning Rate: 0.00058255
	LOSS [training: 0.13842001374290033 | validation: 0.16242444829306363]
	TIME [epoch: 9.66 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16466118777494748		[learning rate: 0.00058118]
	Learning Rate: 0.000581176
	LOSS [training: 0.16466118777494748 | validation: 0.16306142387848305]
	TIME [epoch: 9.65 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13494753371723256		[learning rate: 0.00057981]
	Learning Rate: 0.000579805
	LOSS [training: 0.13494753371723256 | validation: 0.17954675979932191]
	TIME [epoch: 9.65 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17288216432049827		[learning rate: 0.00057844]
	Learning Rate: 0.000578437
	LOSS [training: 0.17288216432049827 | validation: 0.24006777825186576]
	TIME [epoch: 9.68 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19625014502803373		[learning rate: 0.00057707]
	Learning Rate: 0.000577073
	LOSS [training: 0.19625014502803373 | validation: 0.16468176652243485]
	TIME [epoch: 9.66 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14992345465285076		[learning rate: 0.00057571]
	Learning Rate: 0.000575712
	LOSS [training: 0.14992345465285076 | validation: 0.14942273207996998]
	TIME [epoch: 9.65 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15221150786537374		[learning rate: 0.00057435]
	Learning Rate: 0.000574354
	LOSS [training: 0.15221150786537374 | validation: 0.21534362635667856]
	TIME [epoch: 9.66 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16917832176783162		[learning rate: 0.000573]
	Learning Rate: 0.000572999
	LOSS [training: 0.16917832176783162 | validation: 0.20397355820857674]
	TIME [epoch: 9.67 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12949137435597383		[learning rate: 0.00057165]
	Learning Rate: 0.000571647
	LOSS [training: 0.12949137435597383 | validation: 0.16216889756329828]
	TIME [epoch: 9.65 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15195378200822895		[learning rate: 0.0005703]
	Learning Rate: 0.000570299
	LOSS [training: 0.15195378200822895 | validation: 0.23238508057586582]
	TIME [epoch: 9.66 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1454417145711821		[learning rate: 0.00056895]
	Learning Rate: 0.000568954
	LOSS [training: 0.1454417145711821 | validation: 0.16467728107354027]
	TIME [epoch: 9.67 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15242074520218762		[learning rate: 0.00056761]
	Learning Rate: 0.000567612
	LOSS [training: 0.15242074520218762 | validation: 0.18073313228334908]
	TIME [epoch: 9.66 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.162327400032169		[learning rate: 0.00056627]
	Learning Rate: 0.000566273
	LOSS [training: 0.162327400032169 | validation: 0.19179077515334683]
	TIME [epoch: 9.64 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13451057086322488		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.13451057086322488 | validation: 0.14849105261440318]
	TIME [epoch: 9.67 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15434247008233723		[learning rate: 0.0005636]
	Learning Rate: 0.000563604
	LOSS [training: 0.15434247008233723 | validation: 0.15979217214741057]
	TIME [epoch: 9.66 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15328596204768166		[learning rate: 0.00056227]
	Learning Rate: 0.000562275
	LOSS [training: 0.15328596204768166 | validation: 0.1690871649785272]
	TIME [epoch: 9.65 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14838645687885685		[learning rate: 0.00056095]
	Learning Rate: 0.000560949
	LOSS [training: 0.14838645687885685 | validation: 0.22490336973346733]
	TIME [epoch: 9.65 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1613979694219131		[learning rate: 0.00055963]
	Learning Rate: 0.000559625
	LOSS [training: 0.1613979694219131 | validation: 0.1793685705271352]
	TIME [epoch: 9.67 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15005364089564915		[learning rate: 0.00055831]
	Learning Rate: 0.000558305
	LOSS [training: 0.15005364089564915 | validation: 0.16996925256311357]
	TIME [epoch: 9.65 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16116499230504489		[learning rate: 0.00055699]
	Learning Rate: 0.000556988
	LOSS [training: 0.16116499230504489 | validation: 0.1927090850205024]
	TIME [epoch: 9.65 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14643450576270464		[learning rate: 0.00055567]
	Learning Rate: 0.000555674
	LOSS [training: 0.14643450576270464 | validation: 0.15896597974787777]
	TIME [epoch: 9.67 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17571658434892756		[learning rate: 0.00055436]
	Learning Rate: 0.000554364
	LOSS [training: 0.17571658434892756 | validation: 0.180057480993708]
	TIME [epoch: 9.65 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15822647379092247		[learning rate: 0.00055306]
	Learning Rate: 0.000553056
	LOSS [training: 0.15822647379092247 | validation: 0.20193371888517683]
	TIME [epoch: 9.65 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1766260429509326		[learning rate: 0.00055175]
	Learning Rate: 0.000551752
	LOSS [training: 0.1766260429509326 | validation: 0.21058094123843923]
	TIME [epoch: 9.65 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14845724083386042		[learning rate: 0.00055045]
	Learning Rate: 0.00055045
	LOSS [training: 0.14845724083386042 | validation: 0.1665605609237671]
	TIME [epoch: 9.67 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1279358702027235		[learning rate: 0.00054915]
	Learning Rate: 0.000549152
	LOSS [training: 0.1279358702027235 | validation: 0.15488722457014498]
	TIME [epoch: 9.65 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1601212844042329		[learning rate: 0.00054786]
	Learning Rate: 0.000547856
	LOSS [training: 0.1601212844042329 | validation: 0.16252973666640588]
	TIME [epoch: 9.65 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14004436778293342		[learning rate: 0.00054656]
	Learning Rate: 0.000546564
	LOSS [training: 0.14004436778293342 | validation: 0.19476226621829554]
	TIME [epoch: 9.68 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20246592738779232		[learning rate: 0.00054527]
	Learning Rate: 0.000545275
	LOSS [training: 0.20246592738779232 | validation: 0.21184825204477734]
	TIME [epoch: 9.64 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21298882687706513		[learning rate: 0.00054399]
	Learning Rate: 0.000543988
	LOSS [training: 0.21298882687706513 | validation: 0.286171054877356]
	TIME [epoch: 9.66 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2693388085448408		[learning rate: 0.00054271]
	Learning Rate: 0.000542705
	LOSS [training: 0.2693388085448408 | validation: 0.20257978137775176]
	TIME [epoch: 9.66 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.189760342301224		[learning rate: 0.00054143]
	Learning Rate: 0.000541425
	LOSS [training: 0.189760342301224 | validation: 0.19110183172370934]
	TIME [epoch: 9.68 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14927371850578933		[learning rate: 0.00054015]
	Learning Rate: 0.000540148
	LOSS [training: 0.14927371850578933 | validation: 0.17802057047976902]
	TIME [epoch: 9.65 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14138107773570208		[learning rate: 0.00053887]
	Learning Rate: 0.000538874
	LOSS [training: 0.14138107773570208 | validation: 0.1499437901591626]
	TIME [epoch: 9.65 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12726173342827382		[learning rate: 0.0005376]
	Learning Rate: 0.000537603
	LOSS [training: 0.12726173342827382 | validation: 0.1533619175952857]
	TIME [epoch: 9.67 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15482329536258438		[learning rate: 0.00053633]
	Learning Rate: 0.000536335
	LOSS [training: 0.15482329536258438 | validation: 0.27145573616375596]
	TIME [epoch: 9.65 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1813807457686945		[learning rate: 0.00053507]
	Learning Rate: 0.00053507
	LOSS [training: 0.1813807457686945 | validation: 0.22712110582314743]
	TIME [epoch: 9.65 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14744006725051295		[learning rate: 0.00053381]
	Learning Rate: 0.000533807
	LOSS [training: 0.14744006725051295 | validation: 0.22701214246250648]
	TIME [epoch: 9.67 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1721447008944788		[learning rate: 0.00053255]
	Learning Rate: 0.000532548
	LOSS [training: 0.1721447008944788 | validation: 0.19103450694241111]
	TIME [epoch: 9.65 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17254572482924896		[learning rate: 0.00053129]
	Learning Rate: 0.000531292
	LOSS [training: 0.17254572482924896 | validation: 0.19168395050522308]
	TIME [epoch: 9.65 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14091969737774693		[learning rate: 0.00053004]
	Learning Rate: 0.000530039
	LOSS [training: 0.14091969737774693 | validation: 0.18058571626177902]
	TIME [epoch: 9.65 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13984470442663768		[learning rate: 0.00052879]
	Learning Rate: 0.000528789
	LOSS [training: 0.13984470442663768 | validation: 0.18612815369800248]
	TIME [epoch: 9.67 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1334055709972784		[learning rate: 0.00052754]
	Learning Rate: 0.000527541
	LOSS [training: 0.1334055709972784 | validation: 0.21660561923307398]
	TIME [epoch: 9.64 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14441859741656032		[learning rate: 0.0005263]
	Learning Rate: 0.000526297
	LOSS [training: 0.14441859741656032 | validation: 0.23149344387231807]
	TIME [epoch: 9.65 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1526045853689089		[learning rate: 0.00052506]
	Learning Rate: 0.000525055
	LOSS [training: 0.1526045853689089 | validation: 0.24039862304685208]
	TIME [epoch: 9.67 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1709438415968416		[learning rate: 0.00052382]
	Learning Rate: 0.000523817
	LOSS [training: 0.1709438415968416 | validation: 0.2580133239110525]
	TIME [epoch: 9.65 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1629157502953177		[learning rate: 0.00052258]
	Learning Rate: 0.000522581
	LOSS [training: 0.1629157502953177 | validation: 0.20468889119144812]
	TIME [epoch: 9.65 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16019834667194502		[learning rate: 0.00052135]
	Learning Rate: 0.000521348
	LOSS [training: 0.16019834667194502 | validation: 0.26988970940651064]
	TIME [epoch: 9.66 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14288951526510613		[learning rate: 0.00052012]
	Learning Rate: 0.000520119
	LOSS [training: 0.14288951526510613 | validation: 0.17929483624728212]
	TIME [epoch: 9.66 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13126796298509497		[learning rate: 0.00051889]
	Learning Rate: 0.000518892
	LOSS [training: 0.13126796298509497 | validation: 0.16309866897298517]
	TIME [epoch: 9.65 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1473205740346662		[learning rate: 0.00051767]
	Learning Rate: 0.000517668
	LOSS [training: 0.1473205740346662 | validation: 0.17247813534063305]
	TIME [epoch: 9.65 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14200507023307896		[learning rate: 0.00051645]
	Learning Rate: 0.000516447
	LOSS [training: 0.14200507023307896 | validation: 0.18375686896357507]
	TIME [epoch: 9.67 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1593012812710544		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.1593012812710544 | validation: 0.15037101470566824]
	TIME [epoch: 9.65 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1458837514508774		[learning rate: 0.00051401]
	Learning Rate: 0.000514013
	LOSS [training: 0.1458837514508774 | validation: 0.1779897249496592]
	TIME [epoch: 9.65 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1442508398039431		[learning rate: 0.0005128]
	Learning Rate: 0.000512801
	LOSS [training: 0.1442508398039431 | validation: 0.15697743577528064]
	TIME [epoch: 9.66 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1412386210406276		[learning rate: 0.00051159]
	Learning Rate: 0.000511591
	LOSS [training: 0.1412386210406276 | validation: 0.21213779977767785]
	TIME [epoch: 9.66 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1451191188551776		[learning rate: 0.00051038]
	Learning Rate: 0.000510384
	LOSS [training: 0.1451191188551776 | validation: 0.17715327363883035]
	TIME [epoch: 9.65 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1277081894644389		[learning rate: 0.00050918]
	Learning Rate: 0.00050918
	LOSS [training: 0.1277081894644389 | validation: 0.1776849830357417]
	TIME [epoch: 9.65 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15184288803408147		[learning rate: 0.00050798]
	Learning Rate: 0.000507979
	LOSS [training: 0.15184288803408147 | validation: 0.2561090539622264]
	TIME [epoch: 9.67 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15842607753911592		[learning rate: 0.00050678]
	Learning Rate: 0.000506781
	LOSS [training: 0.15842607753911592 | validation: 0.2471659975031107]
	TIME [epoch: 9.65 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14439808792655484		[learning rate: 0.00050559]
	Learning Rate: 0.000505586
	LOSS [training: 0.14439808792655484 | validation: 0.17671470810254303]
	TIME [epoch: 9.65 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14383737873195857		[learning rate: 0.00050439]
	Learning Rate: 0.000504393
	LOSS [training: 0.14383737873195857 | validation: 0.1728818931079682]
	TIME [epoch: 9.67 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14378529818753655		[learning rate: 0.0005032]
	Learning Rate: 0.000503203
	LOSS [training: 0.14378529818753655 | validation: 0.15562995390798215]
	TIME [epoch: 9.65 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14664741474771711		[learning rate: 0.00050202]
	Learning Rate: 0.000502016
	LOSS [training: 0.14664741474771711 | validation: 0.19123868758386386]
	TIME [epoch: 9.65 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1464693093472388		[learning rate: 0.00050083]
	Learning Rate: 0.000500832
	LOSS [training: 0.1464693093472388 | validation: 0.19930157743068755]
	TIME [epoch: 9.65 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14904882957511933		[learning rate: 0.00049965]
	Learning Rate: 0.000499651
	LOSS [training: 0.14904882957511933 | validation: 0.18302780426309284]
	TIME [epoch: 9.67 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14254581608421835		[learning rate: 0.00049847]
	Learning Rate: 0.000498472
	LOSS [training: 0.14254581608421835 | validation: 0.16463394310684035]
	TIME [epoch: 9.65 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1484686970331833		[learning rate: 0.0004973]
	Learning Rate: 0.000497296
	LOSS [training: 0.1484686970331833 | validation: 0.23085916933970418]
	TIME [epoch: 9.65 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15565805699244364		[learning rate: 0.00049612]
	Learning Rate: 0.000496123
	LOSS [training: 0.15565805699244364 | validation: 0.16648355945270052]
	TIME [epoch: 9.67 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1396452203268439		[learning rate: 0.00049495]
	Learning Rate: 0.000494953
	LOSS [training: 0.1396452203268439 | validation: 0.21231690438982864]
	TIME [epoch: 9.65 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1727552544675167		[learning rate: 0.00049379]
	Learning Rate: 0.000493786
	LOSS [training: 0.1727552544675167 | validation: 0.19158331176995944]
	TIME [epoch: 9.65 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16928203866771319		[learning rate: 0.00049262]
	Learning Rate: 0.000492621
	LOSS [training: 0.16928203866771319 | validation: 0.24007042314386987]
	TIME [epoch: 9.65 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13450897219146304		[learning rate: 0.00049146]
	Learning Rate: 0.000491459
	LOSS [training: 0.13450897219146304 | validation: 0.21560363789297923]
	TIME [epoch: 9.67 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12258325177389011		[learning rate: 0.0004903]
	Learning Rate: 0.0004903
	LOSS [training: 0.12258325177389011 | validation: 0.16719767643375724]
	TIME [epoch: 9.65 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1435493106240298		[learning rate: 0.00048914]
	Learning Rate: 0.000489143
	LOSS [training: 0.1435493106240298 | validation: 0.1596225580865028]
	TIME [epoch: 9.65 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15973009959743784		[learning rate: 0.00048799]
	Learning Rate: 0.000487989
	LOSS [training: 0.15973009959743784 | validation: 0.1944310985577775]
	TIME [epoch: 9.67 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.140285616243169		[learning rate: 0.00048684]
	Learning Rate: 0.000486838
	LOSS [training: 0.140285616243169 | validation: 0.20073702889972314]
	TIME [epoch: 9.65 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12887161275263687		[learning rate: 0.00048569]
	Learning Rate: 0.00048569
	LOSS [training: 0.12887161275263687 | validation: 0.1538452466191355]
	TIME [epoch: 9.65 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13520529123175934		[learning rate: 0.00048454]
	Learning Rate: 0.000484544
	LOSS [training: 0.13520529123175934 | validation: 0.16514355477925297]
	TIME [epoch: 9.66 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16929087106743695		[learning rate: 0.0004834]
	Learning Rate: 0.000483401
	LOSS [training: 0.16929087106743695 | validation: 0.21169902355173265]
	TIME [epoch: 9.65 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1833480047462662		[learning rate: 0.00048226]
	Learning Rate: 0.000482261
	LOSS [training: 0.1833480047462662 | validation: 0.1717759438632825]
	TIME [epoch: 9.65 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16304473840664385		[learning rate: 0.00048112]
	Learning Rate: 0.000481123
	LOSS [training: 0.16304473840664385 | validation: 0.1798312843331091]
	TIME [epoch: 9.65 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14156277480470292		[learning rate: 0.00047999]
	Learning Rate: 0.000479988
	LOSS [training: 0.14156277480470292 | validation: 0.15799836315033722]
	TIME [epoch: 9.67 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14296687799305483		[learning rate: 0.00047886]
	Learning Rate: 0.000478856
	LOSS [training: 0.14296687799305483 | validation: 0.17344932988182024]
	TIME [epoch: 9.65 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15070037208212703		[learning rate: 0.00047773]
	Learning Rate: 0.000477727
	LOSS [training: 0.15070037208212703 | validation: 0.16686689271865482]
	TIME [epoch: 9.65 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13853795425774681		[learning rate: 0.0004766]
	Learning Rate: 0.0004766
	LOSS [training: 0.13853795425774681 | validation: 0.1494356850282984]
	TIME [epoch: 9.66 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1464543782646901		[learning rate: 0.00047548]
	Learning Rate: 0.000475476
	LOSS [training: 0.1464543782646901 | validation: 0.14101246837957604]
	TIME [epoch: 9.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_1340.pth
	Model improved!!!
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13873989472342899		[learning rate: 0.00047435]
	Learning Rate: 0.000474354
	LOSS [training: 0.13873989472342899 | validation: 0.1305876200135422]
	TIME [epoch: 9.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_1341.pth
	Model improved!!!
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13792401442358587		[learning rate: 0.00047324]
	Learning Rate: 0.000473235
	LOSS [training: 0.13792401442358587 | validation: 0.1806579329843354]
	TIME [epoch: 9.65 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1423134761572126		[learning rate: 0.00047212]
	Learning Rate: 0.000472119
	LOSS [training: 0.1423134761572126 | validation: 0.2313230377334983]
	TIME [epoch: 9.67 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19372121051275976		[learning rate: 0.00047101]
	Learning Rate: 0.000471005
	LOSS [training: 0.19372121051275976 | validation: 0.17152244078868376]
	TIME [epoch: 9.65 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14835465253673474		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.14835465253673474 | validation: 0.15167649235086614]
	TIME [epoch: 9.65 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13840622232699784		[learning rate: 0.00046879]
	Learning Rate: 0.000468786
	LOSS [training: 0.13840622232699784 | validation: 0.15205271739273704]
	TIME [epoch: 9.67 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14502442396257692		[learning rate: 0.00046768]
	Learning Rate: 0.00046768
	LOSS [training: 0.14502442396257692 | validation: 0.1589375914730806]
	TIME [epoch: 9.64 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15386276789357908		[learning rate: 0.00046658]
	Learning Rate: 0.000466577
	LOSS [training: 0.15386276789357908 | validation: 0.16755763905677576]
	TIME [epoch: 9.65 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18005074950343425		[learning rate: 0.00046548]
	Learning Rate: 0.000465476
	LOSS [training: 0.18005074950343425 | validation: 0.21025936699666672]
	TIME [epoch: 9.65 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17170518874353974		[learning rate: 0.00046438]
	Learning Rate: 0.000464378
	LOSS [training: 0.17170518874353974 | validation: 0.21932911346884382]
	TIME [epoch: 9.67 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1785493202412276		[learning rate: 0.00046328]
	Learning Rate: 0.000463283
	LOSS [training: 0.1785493202412276 | validation: 0.1807867975344734]
	TIME [epoch: 9.65 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15096468502822907		[learning rate: 0.00046219]
	Learning Rate: 0.00046219
	LOSS [training: 0.15096468502822907 | validation: 0.17353049051599326]
	TIME [epoch: 9.64 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15247256863104588		[learning rate: 0.0004611]
	Learning Rate: 0.0004611
	LOSS [training: 0.15247256863104588 | validation: 0.15483201395586846]
	TIME [epoch: 9.67 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13095127762301534		[learning rate: 0.00046001]
	Learning Rate: 0.000460012
	LOSS [training: 0.13095127762301534 | validation: 0.16724335968856113]
	TIME [epoch: 9.66 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1622289330481132		[learning rate: 0.00045893]
	Learning Rate: 0.000458927
	LOSS [training: 0.1622289330481132 | validation: 0.15849651077242083]
	TIME [epoch: 9.66 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14050477402415895		[learning rate: 0.00045784]
	Learning Rate: 0.000457844
	LOSS [training: 0.14050477402415895 | validation: 0.1612690121628257]
	TIME [epoch: 9.65 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14399945673248177		[learning rate: 0.00045676]
	Learning Rate: 0.000456764
	LOSS [training: 0.14399945673248177 | validation: 0.14992228803002286]
	TIME [epoch: 9.66 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14499032327473835		[learning rate: 0.00045569]
	Learning Rate: 0.000455687
	LOSS [training: 0.14499032327473835 | validation: 0.1287744450037189]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_1358.pth
	Model improved!!!
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14253478362325248		[learning rate: 0.00045461]
	Learning Rate: 0.000454612
	LOSS [training: 0.14253478362325248 | validation: 0.13483003882261269]
	TIME [epoch: 9.65 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12907465758476255		[learning rate: 0.00045354]
	Learning Rate: 0.00045354
	LOSS [training: 0.12907465758476255 | validation: 0.14303197105899204]
	TIME [epoch: 9.68 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13587348969993307		[learning rate: 0.00045247]
	Learning Rate: 0.00045247
	LOSS [training: 0.13587348969993307 | validation: 0.14222769333644536]
	TIME [epoch: 9.65 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1402666894790948		[learning rate: 0.0004514]
	Learning Rate: 0.000451403
	LOSS [training: 0.1402666894790948 | validation: 0.19010952340532872]
	TIME [epoch: 9.66 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1425485323988913		[learning rate: 0.00045034]
	Learning Rate: 0.000450338
	LOSS [training: 0.1425485323988913 | validation: 0.14854406996372366]
	TIME [epoch: 9.65 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1458808986711555		[learning rate: 0.00044928]
	Learning Rate: 0.000449276
	LOSS [training: 0.1458808986711555 | validation: 0.19167460556235186]
	TIME [epoch: 9.69 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14646113213174888		[learning rate: 0.00044822]
	Learning Rate: 0.000448216
	LOSS [training: 0.14646113213174888 | validation: 0.14062557704374615]
	TIME [epoch: 9.65 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13516942593867456		[learning rate: 0.00044716]
	Learning Rate: 0.000447159
	LOSS [training: 0.13516942593867456 | validation: 0.21274089475616884]
	TIME [epoch: 9.65 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15066802573194576		[learning rate: 0.0004461]
	Learning Rate: 0.000446104
	LOSS [training: 0.15066802573194576 | validation: 0.20962790859830077]
	TIME [epoch: 9.68 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14047577471152814		[learning rate: 0.00044505]
	Learning Rate: 0.000445051
	LOSS [training: 0.14047577471152814 | validation: 0.14681569938103042]
	TIME [epoch: 9.65 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12660897046671907		[learning rate: 0.000444]
	Learning Rate: 0.000444002
	LOSS [training: 0.12660897046671907 | validation: 0.16753204853759165]
	TIME [epoch: 9.64 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1386516787568706		[learning rate: 0.00044295]
	Learning Rate: 0.000442954
	LOSS [training: 0.1386516787568706 | validation: 0.1665258813485702]
	TIME [epoch: 9.65 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14769509975179582		[learning rate: 0.00044191]
	Learning Rate: 0.000441909
	LOSS [training: 0.14769509975179582 | validation: 0.1692314253213724]
	TIME [epoch: 9.69 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1524779284234523		[learning rate: 0.00044087]
	Learning Rate: 0.000440867
	LOSS [training: 0.1524779284234523 | validation: 0.1860461383234455]
	TIME [epoch: 9.65 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.154430197086118		[learning rate: 0.00043983]
	Learning Rate: 0.000439827
	LOSS [training: 0.154430197086118 | validation: 0.21154729255969656]
	TIME [epoch: 9.65 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15747326526876154		[learning rate: 0.00043879]
	Learning Rate: 0.00043879
	LOSS [training: 0.15747326526876154 | validation: 0.18124670416008512]
	TIME [epoch: 9.66 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13119515119637096		[learning rate: 0.00043775]
	Learning Rate: 0.000437755
	LOSS [training: 0.13119515119637096 | validation: 0.192599275415226]
	TIME [epoch: 9.65 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13824493765498425		[learning rate: 0.00043672]
	Learning Rate: 0.000436722
	LOSS [training: 0.13824493765498425 | validation: 0.1887276476225516]
	TIME [epoch: 9.65 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13506415574478722		[learning rate: 0.00043569]
	Learning Rate: 0.000435692
	LOSS [training: 0.13506415574478722 | validation: 0.16196885431241664]
	TIME [epoch: 9.66 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15653242867107056		[learning rate: 0.00043466]
	Learning Rate: 0.000434664
	LOSS [training: 0.15653242867107056 | validation: 0.23723151065574663]
	TIME [epoch: 9.65 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1493004714059059		[learning rate: 0.00043364]
	Learning Rate: 0.000433639
	LOSS [training: 0.1493004714059059 | validation: 0.17132157930797426]
	TIME [epoch: 9.65 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12888774412920095		[learning rate: 0.00043262]
	Learning Rate: 0.000432616
	LOSS [training: 0.12888774412920095 | validation: 0.15503290877490414]
	TIME [epoch: 9.66 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12288478478048648		[learning rate: 0.0004316]
	Learning Rate: 0.000431595
	LOSS [training: 0.12288478478048648 | validation: 0.14510333936332093]
	TIME [epoch: 9.67 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14438223373311773		[learning rate: 0.00043058]
	Learning Rate: 0.000430577
	LOSS [training: 0.14438223373311773 | validation: 0.2247884881985133]
	TIME [epoch: 9.66 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14108433053613093		[learning rate: 0.00042956]
	Learning Rate: 0.000429562
	LOSS [training: 0.14108433053613093 | validation: 0.13349205102347486]
	TIME [epoch: 9.67 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12909317650689178		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.12909317650689178 | validation: 0.17382939265872643]
	TIME [epoch: 9.66 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14106527020772294		[learning rate: 0.00042754]
	Learning Rate: 0.000427538
	LOSS [training: 0.14106527020772294 | validation: 0.17850750307613197]
	TIME [epoch: 9.64 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13668228354752804		[learning rate: 0.00042653]
	Learning Rate: 0.000426529
	LOSS [training: 0.13668228354752804 | validation: 0.17430886828338088]
	TIME [epoch: 9.64 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1342284580087911		[learning rate: 0.00042552]
	Learning Rate: 0.000425523
	LOSS [training: 0.1342284580087911 | validation: 0.13793324261640955]
	TIME [epoch: 9.64 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11922593431230255		[learning rate: 0.00042452]
	Learning Rate: 0.000424519
	LOSS [training: 0.11922593431230255 | validation: 0.12308357848460973]
	TIME [epoch: 9.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_1388.pth
	Model improved!!!
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1244975121896805		[learning rate: 0.00042352]
	Learning Rate: 0.000423518
	LOSS [training: 0.1244975121896805 | validation: 0.167507669619344]
	TIME [epoch: 9.65 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14531876846640135		[learning rate: 0.00042252]
	Learning Rate: 0.000422519
	LOSS [training: 0.14531876846640135 | validation: 0.18750562506023624]
	TIME [epoch: 9.65 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1583529816140059		[learning rate: 0.00042152]
	Learning Rate: 0.000421522
	LOSS [training: 0.1583529816140059 | validation: 0.1891867581382383]
	TIME [epoch: 9.66 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16693915065543635		[learning rate: 0.00042053]
	Learning Rate: 0.000420528
	LOSS [training: 0.16693915065543635 | validation: 0.18863198520669272]
	TIME [epoch: 9.64 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21358647583935314		[learning rate: 0.00041954]
	Learning Rate: 0.000419536
	LOSS [training: 0.21358647583935314 | validation: 0.2109251558442621]
	TIME [epoch: 9.64 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1730935325406405		[learning rate: 0.00041855]
	Learning Rate: 0.000418546
	LOSS [training: 0.1730935325406405 | validation: 0.1487361152313158]
	TIME [epoch: 9.63 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12234101751229565		[learning rate: 0.00041756]
	Learning Rate: 0.000417559
	LOSS [training: 0.12234101751229565 | validation: 0.13649293057752063]
	TIME [epoch: 9.66 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13072288024092946		[learning rate: 0.00041657]
	Learning Rate: 0.000416574
	LOSS [training: 0.13072288024092946 | validation: 0.17235073768926198]
	TIME [epoch: 9.63 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12136010018846055		[learning rate: 0.00041559]
	Learning Rate: 0.000415591
	LOSS [training: 0.12136010018846055 | validation: 0.13911097076132162]
	TIME [epoch: 9.64 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12957034396333073		[learning rate: 0.00041461]
	Learning Rate: 0.000414611
	LOSS [training: 0.12957034396333073 | validation: 0.12426995300848274]
	TIME [epoch: 9.65 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1253547528062931		[learning rate: 0.00041363]
	Learning Rate: 0.000413633
	LOSS [training: 0.1253547528062931 | validation: 0.15958932472419085]
	TIME [epoch: 9.64 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14451354192380822		[learning rate: 0.00041266]
	Learning Rate: 0.000412657
	LOSS [training: 0.14451354192380822 | validation: 0.1497978661634939]
	TIME [epoch: 9.64 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15031841842778143		[learning rate: 0.00041168]
	Learning Rate: 0.000411684
	LOSS [training: 0.15031841842778143 | validation: 0.1455441580029835]
	TIME [epoch: 9.64 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13192680210997215		[learning rate: 0.00041071]
	Learning Rate: 0.000410713
	LOSS [training: 0.13192680210997215 | validation: 0.177660495206531]
	TIME [epoch: 9.66 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13464485778923077		[learning rate: 0.00040974]
	Learning Rate: 0.000409744
	LOSS [training: 0.13464485778923077 | validation: 0.13240382183094357]
	TIME [epoch: 9.64 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12996369769536192		[learning rate: 0.00040878]
	Learning Rate: 0.000408778
	LOSS [training: 0.12996369769536192 | validation: 0.1362382281756722]
	TIME [epoch: 9.64 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13188213072258673		[learning rate: 0.00040781]
	Learning Rate: 0.000407813
	LOSS [training: 0.13188213072258673 | validation: 0.14962167964261938]
	TIME [epoch: 9.66 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12603884302330154		[learning rate: 0.00040685]
	Learning Rate: 0.000406851
	LOSS [training: 0.12603884302330154 | validation: 0.1732804986498194]
	TIME [epoch: 9.64 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.135311944977677		[learning rate: 0.00040589]
	Learning Rate: 0.000405892
	LOSS [training: 0.135311944977677 | validation: 0.16702603603033736]
	TIME [epoch: 9.64 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1337639874233494		[learning rate: 0.00040493]
	Learning Rate: 0.000404934
	LOSS [training: 0.1337639874233494 | validation: 0.13742216939792293]
	TIME [epoch: 9.64 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1397736342943224		[learning rate: 0.00040398]
	Learning Rate: 0.000403979
	LOSS [training: 0.1397736342943224 | validation: 0.2082327853276879]
	TIME [epoch: 9.66 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15472657911497562		[learning rate: 0.00040303]
	Learning Rate: 0.000403026
	LOSS [training: 0.15472657911497562 | validation: 0.2081658707503838]
	TIME [epoch: 9.65 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15770561234957756		[learning rate: 0.00040208]
	Learning Rate: 0.000402076
	LOSS [training: 0.15770561234957756 | validation: 0.19488032558738788]
	TIME [epoch: 9.65 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1659999144776941		[learning rate: 0.00040113]
	Learning Rate: 0.000401127
	LOSS [training: 0.1659999144776941 | validation: 0.2097551102205976]
	TIME [epoch: 9.67 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1410885228575084		[learning rate: 0.00040018]
	Learning Rate: 0.000400181
	LOSS [training: 0.1410885228575084 | validation: 0.1562233012054288]
	TIME [epoch: 9.64 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13552950861468138		[learning rate: 0.00039924]
	Learning Rate: 0.000399237
	LOSS [training: 0.13552950861468138 | validation: 0.19151561310663873]
	TIME [epoch: 9.64 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18366454725099807		[learning rate: 0.0003983]
	Learning Rate: 0.000398295
	LOSS [training: 0.18366454725099807 | validation: 0.1942151737745958]
	TIME [epoch: 9.65 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17189088918473186		[learning rate: 0.00039736]
	Learning Rate: 0.000397356
	LOSS [training: 0.17189088918473186 | validation: 0.1775576051032814]
	TIME [epoch: 9.65 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14755242762509577		[learning rate: 0.00039642]
	Learning Rate: 0.000396418
	LOSS [training: 0.14755242762509577 | validation: 0.19322690758799177]
	TIME [epoch: 9.64 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14925426528401312		[learning rate: 0.00039548]
	Learning Rate: 0.000395483
	LOSS [training: 0.14925426528401312 | validation: 0.15009637665040595]
	TIME [epoch: 9.64 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1278899050622318		[learning rate: 0.00039455]
	Learning Rate: 0.00039455
	LOSS [training: 0.1278899050622318 | validation: 0.20027057837486525]
	TIME [epoch: 9.66 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1292447853632916		[learning rate: 0.00039362]
	Learning Rate: 0.00039362
	LOSS [training: 0.1292447853632916 | validation: 0.14649321750889413]
	TIME [epoch: 9.64 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1305029968177745		[learning rate: 0.00039269]
	Learning Rate: 0.000392691
	LOSS [training: 0.1305029968177745 | validation: 0.1662257459851442]
	TIME [epoch: 9.63 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1383986040182122		[learning rate: 0.00039177]
	Learning Rate: 0.000391765
	LOSS [training: 0.1383986040182122 | validation: 0.17958039141065926]
	TIME [epoch: 9.65 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1374507485558925		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.1374507485558925 | validation: 0.15463188400208688]
	TIME [epoch: 9.64 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16906525592961033		[learning rate: 0.00038992]
	Learning Rate: 0.000389919
	LOSS [training: 0.16906525592961033 | validation: 0.16576762179912855]
	TIME [epoch: 9.63 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1306410939554989		[learning rate: 0.000389]
	Learning Rate: 0.000388999
	LOSS [training: 0.1306410939554989 | validation: 0.13156373984694822]
	TIME [epoch: 9.64 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13674718004182954		[learning rate: 0.00038808]
	Learning Rate: 0.000388082
	LOSS [training: 0.13674718004182954 | validation: 0.15700375776013625]
	TIME [epoch: 9.65 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14239922671713373		[learning rate: 0.00038717]
	Learning Rate: 0.000387166
	LOSS [training: 0.14239922671713373 | validation: 0.15015988611771333]
	TIME [epoch: 9.64 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15327590202988906		[learning rate: 0.00038625]
	Learning Rate: 0.000386253
	LOSS [training: 0.15327590202988906 | validation: 0.14500610537442213]
	TIME [epoch: 9.64 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12756918960841004		[learning rate: 0.00038534]
	Learning Rate: 0.000385342
	LOSS [training: 0.12756918960841004 | validation: 0.15393187189630805]
	TIME [epoch: 9.65 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13358263852824076		[learning rate: 0.00038443]
	Learning Rate: 0.000384433
	LOSS [training: 0.13358263852824076 | validation: 0.1460898664447997]
	TIME [epoch: 9.64 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13099590209432743		[learning rate: 0.00038353]
	Learning Rate: 0.000383526
	LOSS [training: 0.13099590209432743 | validation: 0.14629271110079578]
	TIME [epoch: 9.63 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12901739679708377		[learning rate: 0.00038262]
	Learning Rate: 0.000382621
	LOSS [training: 0.12901739679708377 | validation: 0.1406503375108975]
	TIME [epoch: 9.64 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13159416927211545		[learning rate: 0.00038172]
	Learning Rate: 0.000381719
	LOSS [training: 0.13159416927211545 | validation: 0.13742911627562213]
	TIME [epoch: 9.66 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12452508011209931		[learning rate: 0.00038082]
	Learning Rate: 0.000380818
	LOSS [training: 0.12452508011209931 | validation: 0.16055141343507082]
	TIME [epoch: 9.64 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17317928722917889		[learning rate: 0.00037992]
	Learning Rate: 0.00037992
	LOSS [training: 0.17317928722917889 | validation: 0.19980288324027531]
	TIME [epoch: 9.64 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14623027818235906		[learning rate: 0.00037902]
	Learning Rate: 0.000379024
	LOSS [training: 0.14623027818235906 | validation: 0.17624815258748655]
	TIME [epoch: 9.66 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14135557466675083		[learning rate: 0.00037813]
	Learning Rate: 0.00037813
	LOSS [training: 0.14135557466675083 | validation: 0.14859787157329923]
	TIME [epoch: 9.63 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13705947399190227		[learning rate: 0.00037724]
	Learning Rate: 0.000377238
	LOSS [training: 0.13705947399190227 | validation: 0.1585612430029374]
	TIME [epoch: 9.63 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1427164851040747		[learning rate: 0.00037635]
	Learning Rate: 0.000376348
	LOSS [training: 0.1427164851040747 | validation: 0.16917341945693565]
	TIME [epoch: 9.64 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1303634267435763		[learning rate: 0.00037546]
	Learning Rate: 0.00037546
	LOSS [training: 0.1303634267435763 | validation: 0.15039666629795687]
	TIME [epoch: 9.64 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12188594869086375		[learning rate: 0.00037457]
	Learning Rate: 0.000374575
	LOSS [training: 0.12188594869086375 | validation: 0.14817011209648695]
	TIME [epoch: 9.64 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13321278662161365		[learning rate: 0.00037369]
	Learning Rate: 0.000373691
	LOSS [training: 0.13321278662161365 | validation: 0.1403170138009627]
	TIME [epoch: 9.64 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12309528732864516		[learning rate: 0.00037281]
	Learning Rate: 0.00037281
	LOSS [training: 0.12309528732864516 | validation: 0.1396302725628028]
	TIME [epoch: 9.66 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1258251264352404		[learning rate: 0.00037193]
	Learning Rate: 0.00037193
	LOSS [training: 0.1258251264352404 | validation: 0.13834171303696652]
	TIME [epoch: 9.64 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13154225936559202		[learning rate: 0.00037105]
	Learning Rate: 0.000371053
	LOSS [training: 0.13154225936559202 | validation: 0.1422755816517736]
	TIME [epoch: 9.63 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13740466065888063		[learning rate: 0.00037018]
	Learning Rate: 0.000370178
	LOSS [training: 0.13740466065888063 | validation: 0.18066015086008208]
	TIME [epoch: 9.66 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12809478335931151		[learning rate: 0.0003693]
	Learning Rate: 0.000369305
	LOSS [training: 0.12809478335931151 | validation: 0.15243147853363673]
	TIME [epoch: 9.65 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12441583103265574		[learning rate: 0.00036843]
	Learning Rate: 0.000368433
	LOSS [training: 0.12441583103265574 | validation: 0.17421404243949598]
	TIME [epoch: 9.64 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12668628636818097		[learning rate: 0.00036756]
	Learning Rate: 0.000367564
	LOSS [training: 0.12668628636818097 | validation: 0.16393484537844416]
	TIME [epoch: 9.64 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14199274180747695		[learning rate: 0.0003667]
	Learning Rate: 0.000366697
	LOSS [training: 0.14199274180747695 | validation: 0.1443521957429187]
	TIME [epoch: 9.66 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13646794562637393		[learning rate: 0.00036583]
	Learning Rate: 0.000365832
	LOSS [training: 0.13646794562637393 | validation: 0.15776657282174888]
	TIME [epoch: 9.64 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14221945448738288		[learning rate: 0.00036497]
	Learning Rate: 0.000364969
	LOSS [training: 0.14221945448738288 | validation: 0.16973787142460858]
	TIME [epoch: 9.64 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1343228622696458		[learning rate: 0.00036411]
	Learning Rate: 0.000364108
	LOSS [training: 0.1343228622696458 | validation: 0.15226880705144483]
	TIME [epoch: 9.66 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12590872942632392		[learning rate: 0.00036325]
	Learning Rate: 0.00036325
	LOSS [training: 0.12590872942632392 | validation: 0.13997232652236488]
	TIME [epoch: 9.64 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12348018135107992		[learning rate: 0.00036239]
	Learning Rate: 0.000362393
	LOSS [training: 0.12348018135107992 | validation: 0.18150726329075612]
	TIME [epoch: 9.64 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13838460343528197		[learning rate: 0.00036154]
	Learning Rate: 0.000361538
	LOSS [training: 0.13838460343528197 | validation: 0.17954076641696964]
	TIME [epoch: 9.64 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14801996633739817		[learning rate: 0.00036069]
	Learning Rate: 0.000360685
	LOSS [training: 0.14801996633739817 | validation: 0.18608929162425927]
	TIME [epoch: 9.66 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14158503221397994		[learning rate: 0.00035983]
	Learning Rate: 0.000359834
	LOSS [training: 0.14158503221397994 | validation: 0.19092282577046576]
	TIME [epoch: 9.64 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12861262006375607		[learning rate: 0.00035899]
	Learning Rate: 0.000358986
	LOSS [training: 0.12861262006375607 | validation: 0.16383740510381983]
	TIME [epoch: 9.64 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1356257539344057		[learning rate: 0.00035814]
	Learning Rate: 0.000358139
	LOSS [training: 0.1356257539344057 | validation: 0.1312044900177755]
	TIME [epoch: 9.66 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14830318675159818		[learning rate: 0.00035729]
	Learning Rate: 0.000357294
	LOSS [training: 0.14830318675159818 | validation: 0.15825872174689806]
	TIME [epoch: 9.64 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12321360663237427		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.12321360663237427 | validation: 0.14912311156571106]
	TIME [epoch: 9.64 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12592902535892075		[learning rate: 0.00035561]
	Learning Rate: 0.00035561
	LOSS [training: 0.12592902535892075 | validation: 0.12637967201265027]
	TIME [epoch: 9.66 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.135686106044745		[learning rate: 0.00035477]
	Learning Rate: 0.000354771
	LOSS [training: 0.135686106044745 | validation: 0.15493024421486112]
	TIME [epoch: 9.65 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1445505384062089		[learning rate: 0.00035393]
	Learning Rate: 0.000353935
	LOSS [training: 0.1445505384062089 | validation: 0.15836449462773788]
	TIME [epoch: 9.64 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13909638396285445		[learning rate: 0.0003531]
	Learning Rate: 0.0003531
	LOSS [training: 0.13909638396285445 | validation: 0.14279353211244464]
	TIME [epoch: 9.64 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1351765721287687		[learning rate: 0.00035227]
	Learning Rate: 0.000352267
	LOSS [training: 0.1351765721287687 | validation: 0.17018099712836182]
	TIME [epoch: 9.66 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1433018547441302		[learning rate: 0.00035144]
	Learning Rate: 0.000351436
	LOSS [training: 0.1433018547441302 | validation: 0.225039617480493]
	TIME [epoch: 9.65 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16825634581525514		[learning rate: 0.00035061]
	Learning Rate: 0.000350607
	LOSS [training: 0.16825634581525514 | validation: 0.17533391888174255]
	TIME [epoch: 9.64 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.148285543631064		[learning rate: 0.00034978]
	Learning Rate: 0.00034978
	LOSS [training: 0.148285543631064 | validation: 0.17417080997632037]
	TIME [epoch: 9.66 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12889848655494718		[learning rate: 0.00034895]
	Learning Rate: 0.000348955
	LOSS [training: 0.12889848655494718 | validation: 0.17784612608131084]
	TIME [epoch: 9.65 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14662485945744383		[learning rate: 0.00034813]
	Learning Rate: 0.000348132
	LOSS [training: 0.14662485945744383 | validation: 0.18631802254495305]
	TIME [epoch: 9.64 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15019423326369885		[learning rate: 0.00034731]
	Learning Rate: 0.000347311
	LOSS [training: 0.15019423326369885 | validation: 0.24146351295197518]
	TIME [epoch: 9.65 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.160721037579358		[learning rate: 0.00034649]
	Learning Rate: 0.000346491
	LOSS [training: 0.160721037579358 | validation: 0.1528296935741304]
	TIME [epoch: 9.66 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14074050651240738		[learning rate: 0.00034567]
	Learning Rate: 0.000345674
	LOSS [training: 0.14074050651240738 | validation: 0.1525813315407097]
	TIME [epoch: 9.64 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15630501428814564		[learning rate: 0.00034486]
	Learning Rate: 0.000344859
	LOSS [training: 0.15630501428814564 | validation: 0.17861407688820335]
	TIME [epoch: 9.64 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1559296433445792		[learning rate: 0.00034405]
	Learning Rate: 0.000344045
	LOSS [training: 0.1559296433445792 | validation: 0.16120561883957732]
	TIME [epoch: 9.66 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1393797475975962		[learning rate: 0.00034323]
	Learning Rate: 0.000343233
	LOSS [training: 0.1393797475975962 | validation: 0.14904927638120946]
	TIME [epoch: 9.64 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12567228800745703		[learning rate: 0.00034242]
	Learning Rate: 0.000342424
	LOSS [training: 0.12567228800745703 | validation: 0.15789669338967507]
	TIME [epoch: 9.64 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13526672843564308		[learning rate: 0.00034162]
	Learning Rate: 0.000341616
	LOSS [training: 0.13526672843564308 | validation: 0.1957348455858569]
	TIME [epoch: 9.65 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13864032752911343		[learning rate: 0.00034081]
	Learning Rate: 0.00034081
	LOSS [training: 0.13864032752911343 | validation: 0.14786584617401935]
	TIME [epoch: 9.66 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11822635829161972		[learning rate: 0.00034001]
	Learning Rate: 0.000340006
	LOSS [training: 0.11822635829161972 | validation: 0.13101904066516254]
	TIME [epoch: 9.65 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11106087693747888		[learning rate: 0.0003392]
	Learning Rate: 0.000339204
	LOSS [training: 0.11106087693747888 | validation: 0.14832150072671596]
	TIME [epoch: 9.64 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13833595697660644		[learning rate: 0.0003384]
	Learning Rate: 0.000338404
	LOSS [training: 0.13833595697660644 | validation: 0.1624928811302331]
	TIME [epoch: 9.66 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15030608955415245		[learning rate: 0.00033761]
	Learning Rate: 0.000337606
	LOSS [training: 0.15030608955415245 | validation: 0.12501642595440093]
	TIME [epoch: 9.64 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11668902584769772		[learning rate: 0.00033681]
	Learning Rate: 0.00033681
	LOSS [training: 0.11668902584769772 | validation: 0.1552333935052397]
	TIME [epoch: 9.64 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12868752314176565		[learning rate: 0.00033602]
	Learning Rate: 0.000336015
	LOSS [training: 0.12868752314176565 | validation: 0.14595238631927848]
	TIME [epoch: 9.66 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12767677355539525		[learning rate: 0.00033522]
	Learning Rate: 0.000335223
	LOSS [training: 0.12767677355539525 | validation: 0.15922289614826843]
	TIME [epoch: 9.65 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11820401790779848		[learning rate: 0.00033443]
	Learning Rate: 0.000334432
	LOSS [training: 0.11820401790779848 | validation: 0.1375053140565143]
	TIME [epoch: 9.64 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1166509908585541		[learning rate: 0.00033364]
	Learning Rate: 0.000333643
	LOSS [training: 0.1166509908585541 | validation: 0.13517830047354132]
	TIME [epoch: 9.64 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14197183327027402		[learning rate: 0.00033286]
	Learning Rate: 0.000332856
	LOSS [training: 0.14197183327027402 | validation: 0.13455742580064142]
	TIME [epoch: 9.67 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1341613684732929		[learning rate: 0.00033207]
	Learning Rate: 0.000332071
	LOSS [training: 0.1341613684732929 | validation: 0.15732908308362667]
	TIME [epoch: 9.64 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1333489564574682		[learning rate: 0.00033129]
	Learning Rate: 0.000331288
	LOSS [training: 0.1333489564574682 | validation: 0.13094253457853428]
	TIME [epoch: 9.64 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12768343702488846		[learning rate: 0.00033051]
	Learning Rate: 0.000330506
	LOSS [training: 0.12768343702488846 | validation: 0.1615189454961969]
	TIME [epoch: 9.66 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13050342580624688		[learning rate: 0.00032973]
	Learning Rate: 0.000329726
	LOSS [training: 0.13050342580624688 | validation: 0.12406449389373723]
	TIME [epoch: 9.65 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1379429434906098		[learning rate: 0.00032895]
	Learning Rate: 0.000328949
	LOSS [training: 0.1379429434906098 | validation: 0.17069403395223234]
	TIME [epoch: 9.65 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15834407634333575		[learning rate: 0.00032817]
	Learning Rate: 0.000328173
	LOSS [training: 0.15834407634333575 | validation: 0.12452788394766141]
	TIME [epoch: 9.65 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1269371940513802		[learning rate: 0.0003274]
	Learning Rate: 0.000327399
	LOSS [training: 0.1269371940513802 | validation: 0.13158821549653074]
	TIME [epoch: 9.66 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12893887898154777		[learning rate: 0.00032663]
	Learning Rate: 0.000326626
	LOSS [training: 0.12893887898154777 | validation: 0.16488179780879272]
	TIME [epoch: 9.64 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14796073346579147		[learning rate: 0.00032586]
	Learning Rate: 0.000325856
	LOSS [training: 0.14796073346579147 | validation: 0.16617600408980132]
	TIME [epoch: 9.65 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1390624861819268		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.1390624861819268 | validation: 0.14582502402253408]
	TIME [epoch: 9.66 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11848887881963163		[learning rate: 0.00032432]
	Learning Rate: 0.00032432
	LOSS [training: 0.11848887881963163 | validation: 0.15298951741078523]
	TIME [epoch: 9.65 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13790779445593038		[learning rate: 0.00032356]
	Learning Rate: 0.000323555
	LOSS [training: 0.13790779445593038 | validation: 0.1285897113778907]
	TIME [epoch: 9.64 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11368958579535286		[learning rate: 0.00032279]
	Learning Rate: 0.000322792
	LOSS [training: 0.11368958579535286 | validation: 0.11035843070604533]
	TIME [epoch: 9.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r1_20240219_184940/states/model_tr_study5_1504.pth
	Model improved!!!
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11915525241270841		[learning rate: 0.00032203]
	Learning Rate: 0.000322031
	LOSS [training: 0.11915525241270841 | validation: 0.1670896125712342]
	TIME [epoch: 9.67 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1241058712729588		[learning rate: 0.00032127]
	Learning Rate: 0.000321271
	LOSS [training: 0.1241058712729588 | validation: 0.12393754780771804]
	TIME [epoch: 9.64 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13181377806122657		[learning rate: 0.00032051]
	Learning Rate: 0.000320513
	LOSS [training: 0.13181377806122657 | validation: 0.15139540022336423]
	TIME [epoch: 9.64 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11757935052293889		[learning rate: 0.00031976]
	Learning Rate: 0.000319757
	LOSS [training: 0.11757935052293889 | validation: 0.1343059262428769]
	TIME [epoch: 9.65 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11601963344102359		[learning rate: 0.000319]
	Learning Rate: 0.000319003
	LOSS [training: 0.11601963344102359 | validation: 0.15312144967355512]
	TIME [epoch: 9.63 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11569249744962835		[learning rate: 0.00031825]
	Learning Rate: 0.000318251
	LOSS [training: 0.11569249744962835 | validation: 0.11646105586641665]
	TIME [epoch: 9.63 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12647994106125854		[learning rate: 0.0003175]
	Learning Rate: 0.0003175
	LOSS [training: 0.12647994106125854 | validation: 0.1364149034778314]
	TIME [epoch: 9.64 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12636563033711137		[learning rate: 0.00031675]
	Learning Rate: 0.000316751
	LOSS [training: 0.12636563033711137 | validation: 0.1638181908655815]
	TIME [epoch: 9.65 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1208433420030185		[learning rate: 0.000316]
	Learning Rate: 0.000316004
	LOSS [training: 0.1208433420030185 | validation: 0.16416820983193417]
	TIME [epoch: 9.63 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12229255852822996		[learning rate: 0.00031526]
	Learning Rate: 0.000315258
	LOSS [training: 0.12229255852822996 | validation: 0.12657349778599294]
	TIME [epoch: 9.64 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1256379862463209		[learning rate: 0.00031451]
	Learning Rate: 0.000314515
	LOSS [training: 0.1256379862463209 | validation: 0.14531723302470187]
	TIME [epoch: 9.66 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12000862197664779		[learning rate: 0.00031377]
	Learning Rate: 0.000313773
	LOSS [training: 0.12000862197664779 | validation: 0.13879471988342243]
	TIME [epoch: 9.64 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12084884642276594		[learning rate: 0.00031303]
	Learning Rate: 0.000313033
	LOSS [training: 0.12084884642276594 | validation: 0.14162670175687725]
	TIME [epoch: 9.63 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11652910295381894		[learning rate: 0.00031229]
	Learning Rate: 0.000312294
	LOSS [training: 0.11652910295381894 | validation: 0.14373784477443746]
	TIME [epoch: 9.65 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11391608301163739		[learning rate: 0.00031156]
	Learning Rate: 0.000311558
	LOSS [training: 0.11391608301163739 | validation: 0.16007984111670162]
	TIME [epoch: 9.64 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13896360851014694		[learning rate: 0.00031082]
	Learning Rate: 0.000310823
	LOSS [training: 0.13896360851014694 | validation: 0.22523225421552923]
	TIME [epoch: 9.64 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16235344115870504		[learning rate: 0.00031009]
	Learning Rate: 0.00031009
	LOSS [training: 0.16235344115870504 | validation: 0.22127421862518695]
	TIME [epoch: 9.63 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1315136381014917		[learning rate: 0.00030936]
	Learning Rate: 0.000309358
	LOSS [training: 0.1315136381014917 | validation: 0.1625562619537366]
	TIME [epoch: 9.66 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11845188321435891		[learning rate: 0.00030863]
	Learning Rate: 0.000308628
	LOSS [training: 0.11845188321435891 | validation: 0.14608627027905421]
	TIME [epoch: 9.64 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1191801760805495		[learning rate: 0.0003079]
	Learning Rate: 0.0003079
	LOSS [training: 0.1191801760805495 | validation: 0.16652654355540064]
	TIME [epoch: 9.64 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1224772761470273		[learning rate: 0.00030717]
	Learning Rate: 0.000307174
	LOSS [training: 0.1224772761470273 | validation: 0.13969075958357452]
	TIME [epoch: 9.65 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12651515291499224		[learning rate: 0.00030645]
	Learning Rate: 0.00030645
	LOSS [training: 0.12651515291499224 | validation: 0.1562659444090244]
	TIME [epoch: 9.64 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13229613988431121		[learning rate: 0.00030573]
	Learning Rate: 0.000305727
	LOSS [training: 0.13229613988431121 | validation: 0.16106620304233032]
	TIME [epoch: 9.64 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12224327153113726		[learning rate: 0.00030501]
	Learning Rate: 0.000305005
	LOSS [training: 0.12224327153113726 | validation: 0.15900567231107854]
	TIME [epoch: 9.64 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12763150150018063		[learning rate: 0.00030429]
	Learning Rate: 0.000304286
	LOSS [training: 0.12763150150018063 | validation: 0.1604321247100432]
	TIME [epoch: 9.66 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12443644508559489		[learning rate: 0.00030357]
	Learning Rate: 0.000303568
	LOSS [training: 0.12443644508559489 | validation: 0.16416082271800314]
	TIME [epoch: 9.63 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12451704001075052		[learning rate: 0.00030285]
	Learning Rate: 0.000302852
	LOSS [training: 0.12451704001075052 | validation: 0.182299366936238]
	TIME [epoch: 9.63 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13872433969913806		[learning rate: 0.00030214]
	Learning Rate: 0.000302138
	LOSS [training: 0.13872433969913806 | validation: 0.22927149887221332]
	TIME [epoch: 9.66 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1579681746247782		[learning rate: 0.00030143]
	Learning Rate: 0.000301425
	LOSS [training: 0.1579681746247782 | validation: 0.17159833951939107]
	TIME [epoch: 9.64 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1154128701755162		[learning rate: 0.00030071]
	Learning Rate: 0.000300714
	LOSS [training: 0.1154128701755162 | validation: 0.1536196621639359]
	TIME [epoch: 9.64 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11278167069995124		[learning rate: 0.0003]
	Learning Rate: 0.000300005
	LOSS [training: 0.11278167069995124 | validation: 0.18391649922624637]
	TIME [epoch: 9.64 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13544400840700438		[learning rate: 0.0002993]
	Learning Rate: 0.000299297
	LOSS [training: 0.13544400840700438 | validation: 0.16714050297558808]
	TIME [epoch: 9.65 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1279903731059521		[learning rate: 0.00029859]
	Learning Rate: 0.000298591
	LOSS [training: 0.1279903731059521 | validation: 0.16175413073665745]
	TIME [epoch: 9.63 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13473330005219797		[learning rate: 0.00029789]
	Learning Rate: 0.000297887
	LOSS [training: 0.13473330005219797 | validation: 0.22059736477502134]
	TIME [epoch: 9.63 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12726264530822623		[learning rate: 0.00029718]
	Learning Rate: 0.000297184
	LOSS [training: 0.12726264530822623 | validation: 0.14784342339796655]
	TIME [epoch: 9.65 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11601845337470744		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.11601845337470744 | validation: 0.13166793275206168]
	TIME [epoch: 9.63 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13048014470740454		[learning rate: 0.00029578]
	Learning Rate: 0.000295784
	LOSS [training: 0.13048014470740454 | validation: 0.209519728041358]
	TIME [epoch: 9.63 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13895449607932503		[learning rate: 0.00029509]
	Learning Rate: 0.000295086
	LOSS [training: 0.13895449607932503 | validation: 0.1385291477992319]
	TIME [epoch: 9.65 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13605270011072448		[learning rate: 0.00029439]
	Learning Rate: 0.00029439
	LOSS [training: 0.13605270011072448 | validation: 0.12581744515733023]
	TIME [epoch: 9.64 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12920466842731826		[learning rate: 0.0002937]
	Learning Rate: 0.000293696
	LOSS [training: 0.12920466842731826 | validation: 0.15092742365948622]
	TIME [epoch: 9.64 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1313341172803733		[learning rate: 0.000293]
	Learning Rate: 0.000293003
	LOSS [training: 0.1313341172803733 | validation: 0.13687544558001669]
	TIME [epoch: 9.63 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14427486392005773		[learning rate: 0.00029231]
	Learning Rate: 0.000292312
	LOSS [training: 0.14427486392005773 | validation: 0.16985439614749978]
	TIME [epoch: 9.66 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13987889659779604		[learning rate: 0.00029162]
	Learning Rate: 0.000291622
	LOSS [training: 0.13987889659779604 | validation: 0.1355385497360446]
	TIME [epoch: 9.64 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1341142835077458		[learning rate: 0.00029093]
	Learning Rate: 0.000290934
	LOSS [training: 0.1341142835077458 | validation: 0.15730305431857716]
	TIME [epoch: 9.64 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1340226027556665		[learning rate: 0.00029025]
	Learning Rate: 0.000290248
	LOSS [training: 0.1340226027556665 | validation: 0.1559035567399113]
	TIME [epoch: 9.65 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12953927711693272		[learning rate: 0.00028956]
	Learning Rate: 0.000289563
	LOSS [training: 0.12953927711693272 | validation: 0.1540251287009709]
	TIME [epoch: 9.64 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12454210764014437		[learning rate: 0.00028888]
	Learning Rate: 0.00028888
	LOSS [training: 0.12454210764014437 | validation: 0.16922109135990307]
	TIME [epoch: 9.63 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12108400743785382		[learning rate: 0.0002882]
	Learning Rate: 0.000288199
	LOSS [training: 0.12108400743785382 | validation: 0.15310995741217379]
	TIME [epoch: 9.64 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11990396802306302		[learning rate: 0.00028752]
	Learning Rate: 0.000287519
	LOSS [training: 0.11990396802306302 | validation: 0.12646453169190275]
	TIME [epoch: 9.65 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11727436467437016		[learning rate: 0.00028684]
	Learning Rate: 0.000286841
	LOSS [training: 0.11727436467437016 | validation: 0.1282571210010683]
	TIME [epoch: 9.63 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1260185522003329		[learning rate: 0.00028616]
	Learning Rate: 0.000286164
	LOSS [training: 0.1260185522003329 | validation: 0.15369589905031425]
	TIME [epoch: 9.63 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11676614958897644		[learning rate: 0.00028549]
	Learning Rate: 0.000285489
	LOSS [training: 0.11676614958897644 | validation: 0.14297769936824925]
	TIME [epoch: 9.65 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1304279678773717		[learning rate: 0.00028482]
	Learning Rate: 0.000284816
	LOSS [training: 0.1304279678773717 | validation: 0.15545159952958046]
	TIME [epoch: 9.64 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12091315536322297		[learning rate: 0.00028414]
	Learning Rate: 0.000284144
	LOSS [training: 0.12091315536322297 | validation: 0.13481213637156106]
	TIME [epoch: 9.63 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.128209912018675		[learning rate: 0.00028347]
	Learning Rate: 0.000283474
	LOSS [training: 0.128209912018675 | validation: 0.15089181229865076]
	TIME [epoch: 9.64 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11544522832641899		[learning rate: 0.00028281]
	Learning Rate: 0.000282805
	LOSS [training: 0.11544522832641899 | validation: 0.17268427310177814]
	TIME [epoch: 9.65 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13829440822253558		[learning rate: 0.00028214]
	Learning Rate: 0.000282138
	LOSS [training: 0.13829440822253558 | validation: 0.19343792016381522]
	TIME [epoch: 9.64 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1272610415241518		[learning rate: 0.00028147]
	Learning Rate: 0.000281472
	LOSS [training: 0.1272610415241518 | validation: 0.14599622588445388]
	TIME [epoch: 9.64 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1227404807930342		[learning rate: 0.00028081]
	Learning Rate: 0.000280808
	LOSS [training: 0.1227404807930342 | validation: 0.1402807909201096]
	TIME [epoch: 9.66 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13023413426847513		[learning rate: 0.00028015]
	Learning Rate: 0.000280146
	LOSS [training: 0.13023413426847513 | validation: 0.14537762852012645]
	TIME [epoch: 9.64 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14244128915637327		[learning rate: 0.00027949]
	Learning Rate: 0.000279485
	LOSS [training: 0.14244128915637327 | validation: 0.14128024684227558]
	TIME [epoch: 9.64 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12314097087973123		[learning rate: 0.00027883]
	Learning Rate: 0.000278826
	LOSS [training: 0.12314097087973123 | validation: 0.18195404559217726]
	TIME [epoch: 9.65 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13146851468970602		[learning rate: 0.00027817]
	Learning Rate: 0.000278168
	LOSS [training: 0.13146851468970602 | validation: 0.14309309252978208]
	TIME [epoch: 9.65 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10964928313574514		[learning rate: 0.00027751]
	Learning Rate: 0.000277512
	LOSS [training: 0.10964928313574514 | validation: 0.1305457104441884]
	TIME [epoch: 9.64 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13488504168262824		[learning rate: 0.00027686]
	Learning Rate: 0.000276858
	LOSS [training: 0.13488504168262824 | validation: 0.15316457842797132]
	TIME [epoch: 9.64 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12099837477276218		[learning rate: 0.0002762]
	Learning Rate: 0.000276204
	LOSS [training: 0.12099837477276218 | validation: 0.1543187650862068]
	TIME [epoch: 9.66 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11899327473540292		[learning rate: 0.00027555]
	Learning Rate: 0.000275553
	LOSS [training: 0.11899327473540292 | validation: 0.1655606804902018]
	TIME [epoch: 9.63 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1260615931900791		[learning rate: 0.0002749]
	Learning Rate: 0.000274903
	LOSS [training: 0.1260615931900791 | validation: 0.19124980940801478]
	TIME [epoch: 9.63 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14669385202089283		[learning rate: 0.00027425]
	Learning Rate: 0.000274255
	LOSS [training: 0.14669385202089283 | validation: 0.24365439247701304]
	TIME [epoch: 9.66 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15123561198252897		[learning rate: 0.00027361]
	Learning Rate: 0.000273608
	LOSS [training: 0.15123561198252897 | validation: 0.1747048658104861]
	TIME [epoch: 9.64 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12013280190306305		[learning rate: 0.00027296]
	Learning Rate: 0.000272962
	LOSS [training: 0.12013280190306305 | validation: 0.16209386016875335]
	TIME [epoch: 9.64 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12349089381890702		[learning rate: 0.00027232]
	Learning Rate: 0.000272318
	LOSS [training: 0.12349089381890702 | validation: 0.1408219543101927]
	TIME [epoch: 9.64 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11242978406594428		[learning rate: 0.00027168]
	Learning Rate: 0.000271676
	LOSS [training: 0.11242978406594428 | validation: 0.1639004115044065]
	TIME [epoch: 9.66 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11691002829174443		[learning rate: 0.00027104]
	Learning Rate: 0.000271035
	LOSS [training: 0.11691002829174443 | validation: 0.1297184488326554]
	TIME [epoch: 9.64 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.122090294157206		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.122090294157206 | validation: 0.14105155747751652]
	TIME [epoch: 9.64 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11581448358237148		[learning rate: 0.00026976]
	Learning Rate: 0.000269758
	LOSS [training: 0.11581448358237148 | validation: 0.14935438221847902]
	TIME [epoch: 9.65 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11454030695895104		[learning rate: 0.00026912]
	Learning Rate: 0.000269122
	LOSS [training: 0.11454030695895104 | validation: 0.1368306633639049]
	TIME [epoch: 9.64 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12331443508557842		[learning rate: 0.00026849]
	Learning Rate: 0.000268487
	LOSS [training: 0.12331443508557842 | validation: 0.13977765125796007]
	TIME [epoch: 9.64 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13224692242982175		[learning rate: 0.00026785]
	Learning Rate: 0.000267854
	LOSS [training: 0.13224692242982175 | validation: 0.1518051583722446]
	TIME [epoch: 9.64 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1199193811917629		[learning rate: 0.00026722]
	Learning Rate: 0.000267222
	LOSS [training: 0.1199193811917629 | validation: 0.1987089171089013]
	TIME [epoch: 9.65 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1360007038308834		[learning rate: 0.00026659]
	Learning Rate: 0.000266591
	LOSS [training: 0.1360007038308834 | validation: 0.20366433610252846]
	TIME [epoch: 9.64 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1556861668257384		[learning rate: 0.00026596]
	Learning Rate: 0.000265963
	LOSS [training: 0.1556861668257384 | validation: 0.2029010223258775]
	TIME [epoch: 9.64 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14925314336286938		[learning rate: 0.00026534]
	Learning Rate: 0.000265335
	LOSS [training: 0.14925314336286938 | validation: 0.19409610506140978]
	TIME [epoch: 9.67 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13432821941153456		[learning rate: 0.00026471]
	Learning Rate: 0.000264709
	LOSS [training: 0.13432821941153456 | validation: 0.190606710969217]
	TIME [epoch: 9.63 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12941748953549329		[learning rate: 0.00026408]
	Learning Rate: 0.000264085
	LOSS [training: 0.12941748953549329 | validation: 0.1953417764047431]
	TIME [epoch: 9.63 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12673112690207397		[learning rate: 0.00026346]
	Learning Rate: 0.000263462
	LOSS [training: 0.12673112690207397 | validation: 0.20485240968116336]
	TIME [epoch: 9.65 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12553983517767814		[learning rate: 0.00026284]
	Learning Rate: 0.00026284
	LOSS [training: 0.12553983517767814 | validation: 0.17592706457778295]
	TIME [epoch: 9.65 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12369839461846507		[learning rate: 0.00026222]
	Learning Rate: 0.00026222
	LOSS [training: 0.12369839461846507 | validation: 0.1534592652491511]
	TIME [epoch: 9.64 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13204320126603997		[learning rate: 0.0002616]
	Learning Rate: 0.000261602
	LOSS [training: 0.13204320126603997 | validation: 0.18437343282113325]
	TIME [epoch: 9.63 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13125027024452748		[learning rate: 0.00026098]
	Learning Rate: 0.000260985
	LOSS [training: 0.13125027024452748 | validation: 0.16439574547493366]
	TIME [epoch: 9.65 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12436558559999225		[learning rate: 0.00026037]
	Learning Rate: 0.000260369
	LOSS [training: 0.12436558559999225 | validation: 0.164255869225401]
	TIME [epoch: 9.64 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12181038250030966		[learning rate: 0.00025976]
	Learning Rate: 0.000259755
	LOSS [training: 0.12181038250030966 | validation: 0.15419092351996078]
	TIME [epoch: 9.64 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12476853812900457		[learning rate: 0.00025914]
	Learning Rate: 0.000259142
	LOSS [training: 0.12476853812900457 | validation: 0.17209232666161411]
	TIME [epoch: 9.66 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13496910320384242		[learning rate: 0.00025853]
	Learning Rate: 0.000258531
	LOSS [training: 0.13496910320384242 | validation: 0.16959645650023866]
	TIME [epoch: 9.65 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13357867676312404		[learning rate: 0.00025792]
	Learning Rate: 0.000257921
	LOSS [training: 0.13357867676312404 | validation: 0.1731721849674241]
	TIME [epoch: 9.64 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14186178257659665		[learning rate: 0.00025731]
	Learning Rate: 0.000257313
	LOSS [training: 0.14186178257659665 | validation: 0.1926059483128556]
	TIME [epoch: 9.64 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13867753318545334		[learning rate: 0.00025671]
	Learning Rate: 0.000256706
	LOSS [training: 0.13867753318545334 | validation: 0.1599228388770324]
	TIME [epoch: 9.66 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12241146833774315		[learning rate: 0.0002561]
	Learning Rate: 0.0002561
	LOSS [training: 0.12241146833774315 | validation: 0.1711910202199011]
	TIME [epoch: 9.64 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1287852103789901		[learning rate: 0.0002555]
	Learning Rate: 0.000255496
	LOSS [training: 0.1287852103789901 | validation: 0.16011976110431703]
	TIME [epoch: 9.64 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11962744142283803		[learning rate: 0.00025489]
	Learning Rate: 0.000254894
	LOSS [training: 0.11962744142283803 | validation: 0.15131984138212395]
	TIME [epoch: 9.65 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12591800971737785		[learning rate: 0.00025429]
	Learning Rate: 0.000254292
	LOSS [training: 0.12591800971737785 | validation: 0.16417701301561913]
	TIME [epoch: 9.64 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12155812088484279		[learning rate: 0.00025369]
	Learning Rate: 0.000253693
	LOSS [training: 0.12155812088484279 | validation: 0.17523603431309873]
	TIME [epoch: 9.64 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12238780959710686		[learning rate: 0.00025309]
	Learning Rate: 0.000253094
	LOSS [training: 0.12238780959710686 | validation: 0.1478347268688982]
	TIME [epoch: 9.64 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1207018393701013		[learning rate: 0.0002525]
	Learning Rate: 0.000252497
	LOSS [training: 0.1207018393701013 | validation: 0.1493505577604726]
	TIME [epoch: 9.66 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11783598382552903		[learning rate: 0.0002519]
	Learning Rate: 0.000251902
	LOSS [training: 0.11783598382552903 | validation: 0.14335458012378532]
	TIME [epoch: 9.64 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12091915841075378		[learning rate: 0.00025131]
	Learning Rate: 0.000251307
	LOSS [training: 0.12091915841075378 | validation: 0.17709248636196048]
	TIME [epoch: 9.64 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12732968950982554		[learning rate: 0.00025071]
	Learning Rate: 0.000250714
	LOSS [training: 0.12732968950982554 | validation: 0.15704422257626194]
	TIME [epoch: 9.66 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11774467452571061		[learning rate: 0.00025012]
	Learning Rate: 0.000250123
	LOSS [training: 0.11774467452571061 | validation: 0.14658810054027435]
	TIME [epoch: 9.64 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13230704480257055		[learning rate: 0.00024953]
	Learning Rate: 0.000249533
	LOSS [training: 0.13230704480257055 | validation: 0.14377420684179107]
	TIME [epoch: 9.64 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12592181686412351		[learning rate: 0.00024894]
	Learning Rate: 0.000248945
	LOSS [training: 0.12592181686412351 | validation: 0.15000255064399035]
	TIME [epoch: 9.65 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1141209113120915		[learning rate: 0.00024836]
	Learning Rate: 0.000248357
	LOSS [training: 0.1141209113120915 | validation: 0.16243260341053808]
	TIME [epoch: 9.65 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1233691844556886		[learning rate: 0.00024777]
	Learning Rate: 0.000247771
	LOSS [training: 0.1233691844556886 | validation: 0.1866310145575193]
	TIME [epoch: 9.64 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12390745500406189		[learning rate: 0.00024719]
	Learning Rate: 0.000247187
	LOSS [training: 0.12390745500406189 | validation: 0.19719962281224152]
	TIME [epoch: 9.63 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12926994056991586		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.12926994056991586 | validation: 0.21447219445519394]
	TIME [epoch: 9.66 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14298467844648502		[learning rate: 0.00024602]
	Learning Rate: 0.000246022
	LOSS [training: 0.14298467844648502 | validation: 0.14507965072444434]
	TIME [epoch: 9.64 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12299472969452993		[learning rate: 0.00024544]
	Learning Rate: 0.000245442
	LOSS [training: 0.12299472969452993 | validation: 0.16111444760814583]
	TIME [epoch: 9.64 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12995213503212072		[learning rate: 0.00024486]
	Learning Rate: 0.000244863
	LOSS [training: 0.12995213503212072 | validation: 0.16184614141239345]
	TIME [epoch: 9.65 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1303679695774005		[learning rate: 0.00024429]
	Learning Rate: 0.000244285
	LOSS [training: 0.1303679695774005 | validation: 0.16330699622339231]
	TIME [epoch: 9.64 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11849429074539641		[learning rate: 0.00024371]
	Learning Rate: 0.000243709
	LOSS [training: 0.11849429074539641 | validation: 0.15881827750034014]
	TIME [epoch: 9.63 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13120337425955583		[learning rate: 0.00024313]
	Learning Rate: 0.000243134
	LOSS [training: 0.13120337425955583 | validation: 0.1687842838166182]
	TIME [epoch: 9.64 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14374216382503072		[learning rate: 0.00024256]
	Learning Rate: 0.000242561
	LOSS [training: 0.14374216382503072 | validation: 0.1623070800078437]
	TIME [epoch: 9.66 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12506831853658873		[learning rate: 0.00024199]
	Learning Rate: 0.000241989
	LOSS [training: 0.12506831853658873 | validation: 0.12856165123213462]
	TIME [epoch: 9.63 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11767688831627643		[learning rate: 0.00024142]
	Learning Rate: 0.000241418
	LOSS [training: 0.11767688831627643 | validation: 0.13264185130339035]
	TIME [epoch: 9.64 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11152652939301921		[learning rate: 0.00024085]
	Learning Rate: 0.000240848
	LOSS [training: 0.11152652939301921 | validation: 0.1584602137177133]
	TIME [epoch: 9.66 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13407174090148466		[learning rate: 0.00024028]
	Learning Rate: 0.00024028
	LOSS [training: 0.13407174090148466 | validation: 0.15447620630998568]
	TIME [epoch: 9.64 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12952058704195699		[learning rate: 0.00023971]
	Learning Rate: 0.000239713
	LOSS [training: 0.12952058704195699 | validation: 0.17315905797020087]
	TIME [epoch: 9.63 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13004132322279277		[learning rate: 0.00023915]
	Learning Rate: 0.000239148
	LOSS [training: 0.13004132322279277 | validation: 0.1487181623209172]
	TIME [epoch: 9.64 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12607354625133707		[learning rate: 0.00023858]
	Learning Rate: 0.000238584
	LOSS [training: 0.12607354625133707 | validation: 0.15136308685652627]
	TIME [epoch: 9.65 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13457503187380265		[learning rate: 0.00023802]
	Learning Rate: 0.000238021
	LOSS [training: 0.13457503187380265 | validation: 0.22219939562148733]
	TIME [epoch: 9.64 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13537176093792921		[learning rate: 0.00023746]
	Learning Rate: 0.00023746
	LOSS [training: 0.13537176093792921 | validation: 0.18483904583247154]
	TIME [epoch: 9.64 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1217253154897752		[learning rate: 0.0002369]
	Learning Rate: 0.000236899
	LOSS [training: 0.1217253154897752 | validation: 0.17079188404173853]
	TIME [epoch: 9.65 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12865397712774534		[learning rate: 0.00023634]
	Learning Rate: 0.000236341
	LOSS [training: 0.12865397712774534 | validation: 0.19786177057983498]
	TIME [epoch: 9.64 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14186610250014492		[learning rate: 0.00023578]
	Learning Rate: 0.000235783
	LOSS [training: 0.14186610250014492 | validation: 0.20375557460442506]
	TIME [epoch: 9.63 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12577920408079374		[learning rate: 0.00023523]
	Learning Rate: 0.000235227
	LOSS [training: 0.12577920408079374 | validation: 0.16720768365923405]
	TIME [epoch: 9.65 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12816852516668362		[learning rate: 0.00023467]
	Learning Rate: 0.000234672
	LOSS [training: 0.12816852516668362 | validation: 0.18399619237699733]
	TIME [epoch: 9.65 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12428594402050534		[learning rate: 0.00023412]
	Learning Rate: 0.000234119
	LOSS [training: 0.12428594402050534 | validation: 0.1958029152312118]
	TIME [epoch: 9.64 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1335701784662601		[learning rate: 0.00023357]
	Learning Rate: 0.000233566
	LOSS [training: 0.1335701784662601 | validation: 0.2255990671423843]
	TIME [epoch: 9.63 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1427426013670441		[learning rate: 0.00023302]
	Learning Rate: 0.000233015
	LOSS [training: 0.1427426013670441 | validation: 0.2468355275515526]
	TIME [epoch: 9.66 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14375415483343815		[learning rate: 0.00023247]
	Learning Rate: 0.000232466
	LOSS [training: 0.14375415483343815 | validation: 0.18728186217350257]
	TIME [epoch: 9.63 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13485400891091093		[learning rate: 0.00023192]
	Learning Rate: 0.000231917
	LOSS [training: 0.13485400891091093 | validation: 0.18967530764543583]
	TIME [epoch: 9.64 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1257335667003071		[learning rate: 0.00023137]
	Learning Rate: 0.00023137
	LOSS [training: 0.1257335667003071 | validation: 0.17271053525619565]
	TIME [epoch: 9.66 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12495487256512261		[learning rate: 0.00023082]
	Learning Rate: 0.000230825
	LOSS [training: 0.12495487256512261 | validation: 0.17451363030032183]
	TIME [epoch: 9.64 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12053240978356054		[learning rate: 0.00023028]
	Learning Rate: 0.00023028
	LOSS [training: 0.12053240978356054 | validation: 0.15910602333479418]
	TIME [epoch: 9.64 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12457553463592315		[learning rate: 0.00022974]
	Learning Rate: 0.000229737
	LOSS [training: 0.12457553463592315 | validation: 0.18568562524288335]
	TIME [epoch: 9.64 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1330876054863511		[learning rate: 0.00022919]
	Learning Rate: 0.000229195
	LOSS [training: 0.1330876054863511 | validation: 0.1707360856587941]
	TIME [epoch: 9.66 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13304512846667066		[learning rate: 0.00022865]
	Learning Rate: 0.000228654
	LOSS [training: 0.13304512846667066 | validation: 0.16197650952163187]
	TIME [epoch: 9.64 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12210938571547988		[learning rate: 0.00022811]
	Learning Rate: 0.000228115
	LOSS [training: 0.12210938571547988 | validation: 0.1702182956372333]
	TIME [epoch: 9.64 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12090375570967885		[learning rate: 0.00022758]
	Learning Rate: 0.000227577
	LOSS [training: 0.12090375570967885 | validation: 0.14795556664946932]
	TIME [epoch: 9.66 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12074503339383047		[learning rate: 0.00022704]
	Learning Rate: 0.00022704
	LOSS [training: 0.12074503339383047 | validation: 0.16582956312088074]
	TIME [epoch: 9.64 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12794734626161652		[learning rate: 0.0002265]
	Learning Rate: 0.000226505
	LOSS [training: 0.12794734626161652 | validation: 0.16629061591406175]
	TIME [epoch: 9.64 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12019182955878835		[learning rate: 0.00022597]
	Learning Rate: 0.00022597
	LOSS [training: 0.12019182955878835 | validation: 0.16367471108758327]
	TIME [epoch: 9.64 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11804065362768716		[learning rate: 0.00022544]
	Learning Rate: 0.000225437
	LOSS [training: 0.11804065362768716 | validation: 0.1575052560633752]
	TIME [epoch: 9.66 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12936607454070573		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.12936607454070573 | validation: 0.18273127358713695]
	TIME [epoch: 9.64 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1220519467116069		[learning rate: 0.00022437]
	Learning Rate: 0.000224375
	LOSS [training: 0.1220519467116069 | validation: 0.15133358092805105]
	TIME [epoch: 9.64 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1135734115996263		[learning rate: 0.00022385]
	Learning Rate: 0.000223846
	LOSS [training: 0.1135734115996263 | validation: 0.15222998779220645]
	TIME [epoch: 9.66 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12156810677168868		[learning rate: 0.00022332]
	Learning Rate: 0.000223318
	LOSS [training: 0.12156810677168868 | validation: 0.1611224060172084]
	TIME [epoch: 9.64 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12250395882491863		[learning rate: 0.00022279]
	Learning Rate: 0.000222791
	LOSS [training: 0.12250395882491863 | validation: 0.16555001089641969]
	TIME [epoch: 9.64 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1237461695233056		[learning rate: 0.00022227]
	Learning Rate: 0.000222265
	LOSS [training: 0.1237461695233056 | validation: 0.15933329946236235]
	TIME [epoch: 9.65 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13463445721192727		[learning rate: 0.00022174]
	Learning Rate: 0.000221741
	LOSS [training: 0.13463445721192727 | validation: 0.17654264893900504]
	TIME [epoch: 9.65 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1264037138201134		[learning rate: 0.00022122]
	Learning Rate: 0.000221218
	LOSS [training: 0.1264037138201134 | validation: 0.18015129333035354]
	TIME [epoch: 9.64 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12035916181709436		[learning rate: 0.0002207]
	Learning Rate: 0.000220696
	LOSS [training: 0.12035916181709436 | validation: 0.15982123836255407]
	TIME [epoch: 9.64 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11696942279661275		[learning rate: 0.00022018]
	Learning Rate: 0.000220176
	LOSS [training: 0.11696942279661275 | validation: 0.15942328809142473]
	TIME [epoch: 9.66 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12440724551354618		[learning rate: 0.00021966]
	Learning Rate: 0.000219656
	LOSS [training: 0.12440724551354618 | validation: 0.20291479263492668]
	TIME [epoch: 9.64 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12048555859012544		[learning rate: 0.00021914]
	Learning Rate: 0.000219138
	LOSS [training: 0.12048555859012544 | validation: 0.16624276475349908]
	TIME [epoch: 9.64 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11138214200476619		[learning rate: 0.00021862]
	Learning Rate: 0.000218621
	LOSS [training: 0.11138214200476619 | validation: 0.14128102060454384]
	TIME [epoch: 9.65 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11532904594151874		[learning rate: 0.00021811]
	Learning Rate: 0.000218106
	LOSS [training: 0.11532904594151874 | validation: 0.1351689071551866]
	TIME [epoch: 9.64 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11211216611691077		[learning rate: 0.00021759]
	Learning Rate: 0.000217591
	LOSS [training: 0.11211216611691077 | validation: 0.162223436996161]
	TIME [epoch: 9.64 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1360457883100706		[learning rate: 0.00021708]
	Learning Rate: 0.000217078
	LOSS [training: 0.1360457883100706 | validation: 0.19226819063621384]
	TIME [epoch: 9.64 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12337399487803864		[learning rate: 0.00021657]
	Learning Rate: 0.000216566
	LOSS [training: 0.12337399487803864 | validation: 0.16176806985453038]
	TIME [epoch: 9.66 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11860937417883455		[learning rate: 0.00021605]
	Learning Rate: 0.000216055
	LOSS [training: 0.11860937417883455 | validation: 0.14651261185710915]
	TIME [epoch: 9.65 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11499964612718856		[learning rate: 0.00021555]
	Learning Rate: 0.000215545
	LOSS [training: 0.11499964612718856 | validation: 0.13271511030482402]
	TIME [epoch: 9.64 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11981783346886829		[learning rate: 0.00021504]
	Learning Rate: 0.000215037
	LOSS [training: 0.11981783346886829 | validation: 0.16912178851083576]
	TIME [epoch: 9.66 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10946606231792666		[learning rate: 0.00021453]
	Learning Rate: 0.00021453
	LOSS [training: 0.10946606231792666 | validation: 0.15827911638687606]
	TIME [epoch: 9.64 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11324297866637414		[learning rate: 0.00021402]
	Learning Rate: 0.000214024
	LOSS [training: 0.11324297866637414 | validation: 0.14431406205898706]
	TIME [epoch: 9.64 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11110330502651242		[learning rate: 0.00021352]
	Learning Rate: 0.000213519
	LOSS [training: 0.11110330502651242 | validation: 0.1589632231537835]
	TIME [epoch: 9.64 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11467716734733421		[learning rate: 0.00021302]
	Learning Rate: 0.000213015
	LOSS [training: 0.11467716734733421 | validation: 0.1571724106527984]
	TIME [epoch: 9.65 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1200736188172277		[learning rate: 0.00021251]
	Learning Rate: 0.000212513
	LOSS [training: 0.1200736188172277 | validation: 0.17504064162799005]
	TIME [epoch: 9.64 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13086662350176653		[learning rate: 0.00021201]
	Learning Rate: 0.000212011
	LOSS [training: 0.13086662350176653 | validation: 0.1504447722163121]
	TIME [epoch: 9.64 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11631326192956855		[learning rate: 0.00021151]
	Learning Rate: 0.000211511
	LOSS [training: 0.11631326192956855 | validation: 0.16146856693119319]
	TIME [epoch: 9.66 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11329114409608701		[learning rate: 0.00021101]
	Learning Rate: 0.000211012
	LOSS [training: 0.11329114409608701 | validation: 0.19116047077686124]
	TIME [epoch: 9.64 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11386981523328232		[learning rate: 0.00021051]
	Learning Rate: 0.000210514
	LOSS [training: 0.11386981523328232 | validation: 0.14526934859084253]
	TIME [epoch: 9.64 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10686177458336599		[learning rate: 0.00021002]
	Learning Rate: 0.000210018
	LOSS [training: 0.10686177458336599 | validation: 0.1665469725572057]
	TIME [epoch: 9.65 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12702489116156332		[learning rate: 0.00020952]
	Learning Rate: 0.000209523
	LOSS [training: 0.12702489116156332 | validation: 0.1385578136410602]
	TIME [epoch: 9.64 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11687366179025052		[learning rate: 0.00020903]
	Learning Rate: 0.000209028
	LOSS [training: 0.11687366179025052 | validation: 0.14690353183244242]
	TIME [epoch: 9.64 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1316894326743993		[learning rate: 0.00020854]
	Learning Rate: 0.000208535
	LOSS [training: 0.1316894326743993 | validation: 0.13456893112007517]
	TIME [epoch: 9.64 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11319511977415861		[learning rate: 0.00020804]
	Learning Rate: 0.000208043
	LOSS [training: 0.11319511977415861 | validation: 0.13991206530170502]
	TIME [epoch: 9.65 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11338717233604703		[learning rate: 0.00020755]
	Learning Rate: 0.000207553
	LOSS [training: 0.11338717233604703 | validation: 0.16505538038126324]
	TIME [epoch: 9.64 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1159462286661314		[learning rate: 0.00020706]
	Learning Rate: 0.000207063
	LOSS [training: 0.1159462286661314 | validation: 0.15020341050083827]
	TIME [epoch: 9.64 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10970998636119882		[learning rate: 0.00020657]
	Learning Rate: 0.000206575
	LOSS [training: 0.10970998636119882 | validation: 0.12487108407124949]
	TIME [epoch: 9.65 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12019802304997851		[learning rate: 0.00020609]
	Learning Rate: 0.000206087
	LOSS [training: 0.12019802304997851 | validation: 0.15044141200969854]
	TIME [epoch: 9.65 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1258154606340603		[learning rate: 0.0002056]
	Learning Rate: 0.000205601
	LOSS [training: 0.1258154606340603 | validation: 0.16776233767390372]
	TIME [epoch: 9.64 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12028872334687295		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.12028872334687295 | validation: 0.16965916593380848]
	TIME [epoch: 9.64 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12471059454777227		[learning rate: 0.00020463]
	Learning Rate: 0.000204632
	LOSS [training: 0.12471059454777227 | validation: 0.16532982985124556]
	TIME [epoch: 9.67 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1287205453103486		[learning rate: 0.00020415]
	Learning Rate: 0.00020415
	LOSS [training: 0.1287205453103486 | validation: 0.1604556066160957]
	TIME [epoch: 9.64 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12064858668694381		[learning rate: 0.00020367]
	Learning Rate: 0.000203668
	LOSS [training: 0.12064858668694381 | validation: 0.15382847976599714]
	TIME [epoch: 9.64 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1178132586845521		[learning rate: 0.00020319]
	Learning Rate: 0.000203188
	LOSS [training: 0.1178132586845521 | validation: 0.15654933348277303]
	TIME [epoch: 9.66 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11663103525562832		[learning rate: 0.00020271]
	Learning Rate: 0.000202708
	LOSS [training: 0.11663103525562832 | validation: 0.13009025257372164]
	TIME [epoch: 9.64 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11201541913564547		[learning rate: 0.00020223]
	Learning Rate: 0.00020223
	LOSS [training: 0.11201541913564547 | validation: 0.14377876238436305]
	TIME [epoch: 9.63 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12251246738305237		[learning rate: 0.00020175]
	Learning Rate: 0.000201753
	LOSS [training: 0.12251246738305237 | validation: 0.15353469406116965]
	TIME [epoch: 9.65 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11765985634071344		[learning rate: 0.00020128]
	Learning Rate: 0.000201277
	LOSS [training: 0.11765985634071344 | validation: 0.15988935678765412]
	TIME [epoch: 9.66 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13174248896117555		[learning rate: 0.0002008]
	Learning Rate: 0.000200803
	LOSS [training: 0.13174248896117555 | validation: 0.13919443482587632]
	TIME [epoch: 9.64 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12554810416597015		[learning rate: 0.00020033]
	Learning Rate: 0.000200329
	LOSS [training: 0.12554810416597015 | validation: 0.16601605462885755]
	TIME [epoch: 9.64 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12064689062941461		[learning rate: 0.00019986]
	Learning Rate: 0.000199856
	LOSS [training: 0.12064689062941461 | validation: 0.2008093937791018]
	TIME [epoch: 9.66 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14421091478763917		[learning rate: 0.00019938]
	Learning Rate: 0.000199385
	LOSS [training: 0.14421091478763917 | validation: 0.17621936495159038]
	TIME [epoch: 9.64 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1276392868909023		[learning rate: 0.00019891]
	Learning Rate: 0.000198915
	LOSS [training: 0.1276392868909023 | validation: 0.11796643689891259]
	TIME [epoch: 9.64 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11931735222744892		[learning rate: 0.00019845]
	Learning Rate: 0.000198445
	LOSS [training: 0.11931735222744892 | validation: 0.14041127177329618]
	TIME [epoch: 9.66 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12518832849405653		[learning rate: 0.00019798]
	Learning Rate: 0.000197977
	LOSS [training: 0.12518832849405653 | validation: 0.16320253132698526]
	TIME [epoch: 9.64 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10659267610104037		[learning rate: 0.00019751]
	Learning Rate: 0.00019751
	LOSS [training: 0.10659267610104037 | validation: 0.13748098626398844]
	TIME [epoch: 9.64 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10892783471738562		[learning rate: 0.00019704]
	Learning Rate: 0.000197044
	LOSS [training: 0.10892783471738562 | validation: 0.15904182212660184]
	TIME [epoch: 9.63 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12075692242568836		[learning rate: 0.00019658]
	Learning Rate: 0.00019658
	LOSS [training: 0.12075692242568836 | validation: 0.1580606076141903]
	TIME [epoch: 9.66 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11080211019682795		[learning rate: 0.00019612]
	Learning Rate: 0.000196116
	LOSS [training: 0.11080211019682795 | validation: 0.15379895280206923]
	TIME [epoch: 9.64 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11395486516071		[learning rate: 0.00019565]
	Learning Rate: 0.000195653
	LOSS [training: 0.11395486516071 | validation: 0.138755152557639]
	TIME [epoch: 9.64 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1286819088658157		[learning rate: 0.00019519]
	Learning Rate: 0.000195192
	LOSS [training: 0.1286819088658157 | validation: 0.14594491858746383]
	TIME [epoch: 9.66 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1371408854010744		[learning rate: 0.00019473]
	Learning Rate: 0.000194731
	LOSS [training: 0.1371408854010744 | validation: 0.15118044686788656]
	TIME [epoch: 9.64 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12450789267810052		[learning rate: 0.00019427]
	Learning Rate: 0.000194272
	LOSS [training: 0.12450789267810052 | validation: 0.1317236481764286]
	TIME [epoch: 9.64 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11346349137541434		[learning rate: 0.00019381]
	Learning Rate: 0.000193814
	LOSS [training: 0.11346349137541434 | validation: 0.13750062215546932]
	TIME [epoch: 9.64 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10574573399082929		[learning rate: 0.00019336]
	Learning Rate: 0.000193357
	LOSS [training: 0.10574573399082929 | validation: 0.1313161452768029]
	TIME [epoch: 9.65 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12332909146550666		[learning rate: 0.0001929]
	Learning Rate: 0.0001929
	LOSS [training: 0.12332909146550666 | validation: 0.1594372803501669]
	TIME [epoch: 9.64 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1305635452446162		[learning rate: 0.00019245]
	Learning Rate: 0.000192445
	LOSS [training: 0.1305635452446162 | validation: 0.19113451495623676]
	TIME [epoch: 9.63 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12927728805215377		[learning rate: 0.00019199]
	Learning Rate: 0.000191992
	LOSS [training: 0.12927728805215377 | validation: 0.13738046285601138]
	TIME [epoch: 9.65 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11916932255785344		[learning rate: 0.00019154]
	Learning Rate: 0.000191539
	LOSS [training: 0.11916932255785344 | validation: 0.13596071139743676]
	TIME [epoch: 9.64 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1253187417972761		[learning rate: 0.00019109]
	Learning Rate: 0.000191087
	LOSS [training: 0.1253187417972761 | validation: 0.15541388339247134]
	TIME [epoch: 9.64 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13045453868414492		[learning rate: 0.00019064]
	Learning Rate: 0.000190636
	LOSS [training: 0.13045453868414492 | validation: 0.1345790578042597]
	TIME [epoch: 9.64 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12326884486847914		[learning rate: 0.00019019]
	Learning Rate: 0.000190186
	LOSS [training: 0.12326884486847914 | validation: 0.12352274761054084]
	TIME [epoch: 9.65 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1105868729252613		[learning rate: 0.00018974]
	Learning Rate: 0.000189738
	LOSS [training: 0.1105868729252613 | validation: 0.1318246492595267]
	TIME [epoch: 9.64 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12307000600842626		[learning rate: 0.00018929]
	Learning Rate: 0.00018929
	LOSS [training: 0.12307000600842626 | validation: 0.13051573232349126]
	TIME [epoch: 9.64 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12375310382700574		[learning rate: 0.00018884]
	Learning Rate: 0.000188844
	LOSS [training: 0.12375310382700574 | validation: 0.13799718452440227]
	TIME [epoch: 9.65 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11381383142856996		[learning rate: 0.0001884]
	Learning Rate: 0.000188398
	LOSS [training: 0.11381383142856996 | validation: 0.1374690830713291]
	TIME [epoch: 9.64 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11305876707110149		[learning rate: 0.00018795]
	Learning Rate: 0.000187954
	LOSS [training: 0.11305876707110149 | validation: 0.1328751532810697]
	TIME [epoch: 9.64 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10359555161716176		[learning rate: 0.00018751]
	Learning Rate: 0.000187511
	LOSS [training: 0.10359555161716176 | validation: 0.1489713001134933]
	TIME [epoch: 9.65 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11032378433302541		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.11032378433302541 | validation: 0.12196047591237927]
	TIME [epoch: 9.64 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1145065837992381		[learning rate: 0.00018663]
	Learning Rate: 0.000186627
	LOSS [training: 0.1145065837992381 | validation: 0.16663569291404687]
	TIME [epoch: 9.64 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12076557139971034		[learning rate: 0.00018619]
	Learning Rate: 0.000186187
	LOSS [training: 0.12076557139971034 | validation: 0.1353338507372976]
	TIME [epoch: 9.64 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1097850053971601		[learning rate: 0.00018575]
	Learning Rate: 0.000185748
	LOSS [training: 0.1097850053971601 | validation: 0.14070492764996487]
	TIME [epoch: 9.66 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11066311359230183		[learning rate: 0.00018531]
	Learning Rate: 0.000185309
	LOSS [training: 0.11066311359230183 | validation: 0.13945180690566447]
	TIME [epoch: 9.63 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11058804863890118		[learning rate: 0.00018487]
	Learning Rate: 0.000184872
	LOSS [training: 0.11058804863890118 | validation: 0.13233675763449307]
	TIME [epoch: 9.63 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1283373361105938		[learning rate: 0.00018444]
	Learning Rate: 0.000184436
	LOSS [training: 0.1283373361105938 | validation: 0.14828889939211287]
	TIME [epoch: 9.65 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12223964058778844		[learning rate: 0.000184]
	Learning Rate: 0.000184001
	LOSS [training: 0.12223964058778844 | validation: 0.1430541850099256]
	TIME [epoch: 9.66 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11133012910414941		[learning rate: 0.00018357]
	Learning Rate: 0.000183567
	LOSS [training: 0.11133012910414941 | validation: 0.12336156980651543]
	TIME [epoch: 9.64 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10699223549752084		[learning rate: 0.00018313]
	Learning Rate: 0.000183134
	LOSS [training: 0.10699223549752084 | validation: 0.12506683251961134]
	TIME [epoch: 9.65 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11328932687232005		[learning rate: 0.0001827]
	Learning Rate: 0.000182702
	LOSS [training: 0.11328932687232005 | validation: 0.12966280513091671]
	TIME [epoch: 9.66 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1255357873696051		[learning rate: 0.00018227]
	Learning Rate: 0.000182271
	LOSS [training: 0.1255357873696051 | validation: 0.15263206297055518]
	TIME [epoch: 9.64 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12028606259808919		[learning rate: 0.00018184]
	Learning Rate: 0.000181841
	LOSS [training: 0.12028606259808919 | validation: 0.13322227797611866]
	TIME [epoch: 9.64 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1124180079366941		[learning rate: 0.00018141]
	Learning Rate: 0.000181412
	LOSS [training: 0.1124180079366941 | validation: 0.13867507943804508]
	TIME [epoch: 9.67 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11457784471908423		[learning rate: 0.00018098]
	Learning Rate: 0.000180984
	LOSS [training: 0.11457784471908423 | validation: 0.14279664232246242]
	TIME [epoch: 9.64 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12485983358030994		[learning rate: 0.00018056]
	Learning Rate: 0.000180557
	LOSS [training: 0.12485983358030994 | validation: 0.14866364094408838]
	TIME [epoch: 9.64 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12840746534256312		[learning rate: 0.00018013]
	Learning Rate: 0.000180132
	LOSS [training: 0.12840746534256312 | validation: 0.14778828772411964]
	TIME [epoch: 9.65 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11822507572507993		[learning rate: 0.00017971]
	Learning Rate: 0.000179707
	LOSS [training: 0.11822507572507993 | validation: 0.1510436873237317]
	TIME [epoch: 9.66 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11186595807977855		[learning rate: 0.00017928]
	Learning Rate: 0.000179283
	LOSS [training: 0.11186595807977855 | validation: 0.16898314853722757]
	TIME [epoch: 9.64 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12914430659187448		[learning rate: 0.00017886]
	Learning Rate: 0.00017886
	LOSS [training: 0.12914430659187448 | validation: 0.16430665360945576]
	TIME [epoch: 9.64 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13609794006401815		[learning rate: 0.00017844]
	Learning Rate: 0.000178438
	LOSS [training: 0.13609794006401815 | validation: 0.16919785765545114]
	TIME [epoch: 9.67 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1282156796227583		[learning rate: 0.00017802]
	Learning Rate: 0.000178017
	LOSS [training: 0.1282156796227583 | validation: 0.1479312618013365]
	TIME [epoch: 9.64 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1164963130534793		[learning rate: 0.0001776]
	Learning Rate: 0.000177597
	LOSS [training: 0.1164963130534793 | validation: 0.15451899530068774]
	TIME [epoch: 9.64 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10758964901544883		[learning rate: 0.00017718]
	Learning Rate: 0.000177178
	LOSS [training: 0.10758964901544883 | validation: 0.13258026606313356]
	TIME [epoch: 9.66 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11235410042836405		[learning rate: 0.00017676]
	Learning Rate: 0.00017676
	LOSS [training: 0.11235410042836405 | validation: 0.15396763883104644]
	TIME [epoch: 9.65 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11120705747216567		[learning rate: 0.00017634]
	Learning Rate: 0.000176343
	LOSS [training: 0.11120705747216567 | validation: 0.12603901589300487]
	TIME [epoch: 9.65 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10900207362699157		[learning rate: 0.00017593]
	Learning Rate: 0.000175927
	LOSS [training: 0.10900207362699157 | validation: 0.14182088436285958]
	TIME [epoch: 9.64 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11207402852564938		[learning rate: 0.00017551]
	Learning Rate: 0.000175512
	LOSS [training: 0.11207402852564938 | validation: 0.15916872014150302]
	TIME [epoch: 9.66 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11398919572945157		[learning rate: 0.0001751]
	Learning Rate: 0.000175098
	LOSS [training: 0.11398919572945157 | validation: 0.14658163613295633]
	TIME [epoch: 9.64 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11701921724451918		[learning rate: 0.00017469]
	Learning Rate: 0.000174685
	LOSS [training: 0.11701921724451918 | validation: 0.15138723118393915]
	TIME [epoch: 9.64 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1278195630845101		[learning rate: 0.00017427]
	Learning Rate: 0.000174273
	LOSS [training: 0.1278195630845101 | validation: 0.15275554850228149]
	TIME [epoch: 9.65 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1202085782817804		[learning rate: 0.00017386]
	Learning Rate: 0.000173862
	LOSS [training: 0.1202085782817804 | validation: 0.16350874621100608]
	TIME [epoch: 9.64 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11005046856265707		[learning rate: 0.00017345]
	Learning Rate: 0.000173452
	LOSS [training: 0.11005046856265707 | validation: 0.13053431629884987]
	TIME [epoch: 9.65 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11525790991520717		[learning rate: 0.00017304]
	Learning Rate: 0.000173043
	LOSS [training: 0.11525790991520717 | validation: 0.14312130757651692]
	TIME [epoch: 9.64 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11299576880506315		[learning rate: 0.00017263]
	Learning Rate: 0.000172635
	LOSS [training: 0.11299576880506315 | validation: 0.14819285920590658]
	TIME [epoch: 9.66 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11034205759693232		[learning rate: 0.00017223]
	Learning Rate: 0.000172228
	LOSS [training: 0.11034205759693232 | validation: 0.13677008624376336]
	TIME [epoch: 9.64 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11307918438161457		[learning rate: 0.00017182]
	Learning Rate: 0.000171821
	LOSS [training: 0.11307918438161457 | validation: 0.1543870573066416]
	TIME [epoch: 9.64 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11455761852581452		[learning rate: 0.00017142]
	Learning Rate: 0.000171416
	LOSS [training: 0.11455761852581452 | validation: 0.16766221030792633]
	TIME [epoch: 9.66 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12257352858989626		[learning rate: 0.00017101]
	Learning Rate: 0.000171012
	LOSS [training: 0.12257352858989626 | validation: 0.18534315479889826]
	TIME [epoch: 9.64 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12392579768302774		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.12392579768302774 | validation: 0.17289610877793288]
	TIME [epoch: 9.64 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12372935667219769		[learning rate: 0.00017021]
	Learning Rate: 0.000170206
	LOSS [training: 0.12372935667219769 | validation: 0.13623598743489232]
	TIME [epoch: 9.66 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1287946651898299		[learning rate: 0.0001698]
	Learning Rate: 0.000169804
	LOSS [training: 0.1287946651898299 | validation: 0.18243346478445308]
	TIME [epoch: 9.65 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1324323851048651		[learning rate: 0.0001694]
	Learning Rate: 0.000169404
	LOSS [training: 0.1324323851048651 | validation: 0.17149186879792092]
	TIME [epoch: 9.64 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1200181727352229		[learning rate: 0.000169]
	Learning Rate: 0.000169004
	LOSS [training: 0.1200181727352229 | validation: 0.15471044869330025]
	TIME [epoch: 9.63 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1142051467706767		[learning rate: 0.00016861]
	Learning Rate: 0.000168606
	LOSS [training: 0.1142051467706767 | validation: 0.15732332883783212]
	TIME [epoch: 9.66 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12314572478689065		[learning rate: 0.00016821]
	Learning Rate: 0.000168208
	LOSS [training: 0.12314572478689065 | validation: 0.149606461713512]
	TIME [epoch: 9.63 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12232591744527761		[learning rate: 0.00016781]
	Learning Rate: 0.000167811
	LOSS [training: 0.12232591744527761 | validation: 0.1381483007023229]
	TIME [epoch: 9.63 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11118795991113503		[learning rate: 0.00016742]
	Learning Rate: 0.000167415
	LOSS [training: 0.11118795991113503 | validation: 0.14834417887364437]
	TIME [epoch: 9.65 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10434663486620258		[learning rate: 0.00016702]
	Learning Rate: 0.00016702
	LOSS [training: 0.10434663486620258 | validation: 0.13616676890467697]
	TIME [epoch: 9.64 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11741086637081984		[learning rate: 0.00016663]
	Learning Rate: 0.000166626
	LOSS [training: 0.11741086637081984 | validation: 0.13805142996761544]
	TIME [epoch: 9.64 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12641590240594533		[learning rate: 0.00016623]
	Learning Rate: 0.000166233
	LOSS [training: 0.12641590240594533 | validation: 0.13089526047575098]
	TIME [epoch: 9.64 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.124936217127062		[learning rate: 0.00016584]
	Learning Rate: 0.000165841
	LOSS [training: 0.124936217127062 | validation: 0.13275109229826815]
	TIME [epoch: 9.66 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12169719074394073		[learning rate: 0.00016545]
	Learning Rate: 0.00016545
	LOSS [training: 0.12169719074394073 | validation: 0.14023319319620575]
	TIME [epoch: 9.63 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11133455306962925		[learning rate: 0.00016506]
	Learning Rate: 0.00016506
	LOSS [training: 0.11133455306962925 | validation: 0.14577031229154788]
	TIME [epoch: 9.64 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10933637807860641		[learning rate: 0.00016467]
	Learning Rate: 0.00016467
	LOSS [training: 0.10933637807860641 | validation: 0.15726100084993633]
	TIME [epoch: 9.66 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11444609846809957		[learning rate: 0.00016428]
	Learning Rate: 0.000164282
	LOSS [training: 0.11444609846809957 | validation: 0.13438826443559893]
	TIME [epoch: 9.64 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11349878494920082		[learning rate: 0.00016389]
	Learning Rate: 0.000163894
	LOSS [training: 0.11349878494920082 | validation: 0.14295044351198494]
	TIME [epoch: 9.64 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12027083557298526		[learning rate: 0.00016351]
	Learning Rate: 0.000163508
	LOSS [training: 0.12027083557298526 | validation: 0.12772733036108594]
	TIME [epoch: 9.64 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1177718794970998		[learning rate: 0.00016312]
	Learning Rate: 0.000163122
	LOSS [training: 0.1177718794970998 | validation: 0.13311311569959478]
	TIME [epoch: 9.65 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11400526715708051		[learning rate: 0.00016274]
	Learning Rate: 0.000162737
	LOSS [training: 0.11400526715708051 | validation: 0.13839045361375762]
	TIME [epoch: 9.64 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11629327683487907		[learning rate: 0.00016235]
	Learning Rate: 0.000162353
	LOSS [training: 0.11629327683487907 | validation: 0.15264206611576484]
	TIME [epoch: 9.64 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12505960561842616		[learning rate: 0.00016197]
	Learning Rate: 0.00016197
	LOSS [training: 0.12505960561842616 | validation: 0.14779897195799627]
	TIME [epoch: 9.67 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11765840710489912		[learning rate: 0.00016159]
	Learning Rate: 0.000161588
	LOSS [training: 0.11765840710489912 | validation: 0.13785012759550166]
	TIME [epoch: 9.64 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11501744429378295		[learning rate: 0.00016121]
	Learning Rate: 0.000161207
	LOSS [training: 0.11501744429378295 | validation: 0.13521631481353028]
	TIME [epoch: 9.63 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10859433071185494		[learning rate: 0.00016083]
	Learning Rate: 0.000160827
	LOSS [training: 0.10859433071185494 | validation: 0.13644779900397497]
	TIME [epoch: 9.65 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11558862482809096		[learning rate: 0.00016045]
	Learning Rate: 0.000160448
	LOSS [training: 0.11558862482809096 | validation: 0.1486365687506483]
	TIME [epoch: 9.65 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11414688099354434		[learning rate: 0.00016007]
	Learning Rate: 0.000160069
	LOSS [training: 0.11414688099354434 | validation: 0.13876971097759122]
	TIME [epoch: 9.64 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11101174512745426		[learning rate: 0.00015969]
	Learning Rate: 0.000159692
	LOSS [training: 0.11101174512745426 | validation: 0.1530683298060311]
	TIME [epoch: 9.64 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10371047451060948		[learning rate: 0.00015931]
	Learning Rate: 0.000159315
	LOSS [training: 0.10371047451060948 | validation: 0.14863163680260166]
	TIME [epoch: 9.66 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11441974536901986		[learning rate: 0.00015894]
	Learning Rate: 0.000158939
	LOSS [training: 0.11441974536901986 | validation: 0.17057779476573842]
	TIME [epoch: 9.64 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11746610193565607		[learning rate: 0.00015856]
	Learning Rate: 0.000158564
	LOSS [training: 0.11746610193565607 | validation: 0.13237046108593037]
	TIME [epoch: 9.64 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1132525433558278		[learning rate: 0.00015819]
	Learning Rate: 0.00015819
	LOSS [training: 0.1132525433558278 | validation: 0.1331187021984167]
	TIME [epoch: 9.66 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1168226797428932		[learning rate: 0.00015782]
	Learning Rate: 0.000157817
	LOSS [training: 0.1168226797428932 | validation: 0.1305380948566865]
	TIME [epoch: 9.64 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11480063195727357		[learning rate: 0.00015744]
	Learning Rate: 0.000157445
	LOSS [training: 0.11480063195727357 | validation: 0.14486168655548978]
	TIME [epoch: 9.63 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11926007621333004		[learning rate: 0.00015707]
	Learning Rate: 0.000157073
	LOSS [training: 0.11926007621333004 | validation: 0.14898606224467265]
	TIME [epoch: 9.63 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10680535121139104		[learning rate: 0.0001567]
	Learning Rate: 0.000156703
	LOSS [training: 0.10680535121139104 | validation: 0.1260580285437888]
	TIME [epoch: 9.66 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11197970655307599		[learning rate: 0.00015633]
	Learning Rate: 0.000156333
	LOSS [training: 0.11197970655307599 | validation: 0.1334799133294603]
	TIME [epoch: 9.64 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11740039542715726		[learning rate: 0.00015596]
	Learning Rate: 0.000155964
	LOSS [training: 0.11740039542715726 | validation: 0.1285001249149088]
	TIME [epoch: 9.64 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11126489389088878		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.11126489389088878 | validation: 0.11731858798248108]
	TIME [epoch: 9.66 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10318482902972745		[learning rate: 0.00015523]
	Learning Rate: 0.00015523
	LOSS [training: 0.10318482902972745 | validation: 0.12161916966912546]
	TIME [epoch: 9.64 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10934748382852866		[learning rate: 0.00015486]
	Learning Rate: 0.000154863
	LOSS [training: 0.10934748382852866 | validation: 0.13282786899533341]
	TIME [epoch: 9.64 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11106918732925875		[learning rate: 0.0001545]
	Learning Rate: 0.000154498
	LOSS [training: 0.11106918732925875 | validation: 0.1375310405541482]
	TIME [epoch: 9.64 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1115837905549911		[learning rate: 0.00015413]
	Learning Rate: 0.000154134
	LOSS [training: 0.1115837905549911 | validation: 0.1356717901202494]
	TIME [epoch: 9.65 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10745474730569533		[learning rate: 0.00015377]
	Learning Rate: 0.00015377
	LOSS [training: 0.10745474730569533 | validation: 0.12592374524142788]
	TIME [epoch: 9.64 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13510809057547535		[learning rate: 0.00015341]
	Learning Rate: 0.000153407
	LOSS [training: 0.13510809057547535 | validation: 0.13786918054737263]
	TIME [epoch: 9.64 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12693891241752386		[learning rate: 0.00015305]
	Learning Rate: 0.000153045
	LOSS [training: 0.12693891241752386 | validation: 0.12176857755400564]
	TIME [epoch: 9.66 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11417234166166557		[learning rate: 0.00015268]
	Learning Rate: 0.000152684
	LOSS [training: 0.11417234166166557 | validation: 0.12585296540156876]
	TIME [epoch: 9.64 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10756984037611739		[learning rate: 0.00015232]
	Learning Rate: 0.000152324
	LOSS [training: 0.10756984037611739 | validation: 0.11876007260949405]
	TIME [epoch: 9.64 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11115526849641802		[learning rate: 0.00015196]
	Learning Rate: 0.000151965
	LOSS [training: 0.11115526849641802 | validation: 0.1538499705242363]
	TIME [epoch: 9.65 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12554551524779556		[learning rate: 0.00015161]
	Learning Rate: 0.000151607
	LOSS [training: 0.12554551524779556 | validation: 0.1263918147226433]
	TIME [epoch: 9.65 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11039867249150812		[learning rate: 0.00015125]
	Learning Rate: 0.000151249
	LOSS [training: 0.11039867249150812 | validation: 0.12526973536596941]
	TIME [epoch: 9.64 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11074734584837427		[learning rate: 0.00015089]
	Learning Rate: 0.000150892
	LOSS [training: 0.11074734584837427 | validation: 0.13775425020647458]
	TIME [epoch: 9.63 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10913025566106649		[learning rate: 0.00015054]
	Learning Rate: 0.000150536
	LOSS [training: 0.10913025566106649 | validation: 0.14388422020141334]
	TIME [epoch: 9.65 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11193416844332298		[learning rate: 0.00015018]
	Learning Rate: 0.000150181
	LOSS [training: 0.11193416844332298 | validation: 0.1221729410136285]
	TIME [epoch: 9.64 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11864024790680402		[learning rate: 0.00014983]
	Learning Rate: 0.000149827
	LOSS [training: 0.11864024790680402 | validation: 0.13220067731972635]
	TIME [epoch: 9.63 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11302705829430952		[learning rate: 0.00014947]
	Learning Rate: 0.000149473
	LOSS [training: 0.11302705829430952 | validation: 0.12229475021377616]
	TIME [epoch: 9.66 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10774239702036434		[learning rate: 0.00014912]
	Learning Rate: 0.000149121
	LOSS [training: 0.10774239702036434 | validation: 0.11580121581600458]
	TIME [epoch: 9.64 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10134782286024915		[learning rate: 0.00014877]
	Learning Rate: 0.000148769
	LOSS [training: 0.10134782286024915 | validation: 0.13141577164707877]
	TIME [epoch: 9.64 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1119741371020154		[learning rate: 0.00014842]
	Learning Rate: 0.000148418
	LOSS [training: 0.1119741371020154 | validation: 0.12875653518322464]
	TIME [epoch: 9.64 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11868428078458651		[learning rate: 0.00014807]
	Learning Rate: 0.000148068
	LOSS [training: 0.11868428078458651 | validation: 0.15859710952862777]
	TIME [epoch: 9.66 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11660885902580118		[learning rate: 0.00014772]
	Learning Rate: 0.000147719
	LOSS [training: 0.11660885902580118 | validation: 0.13817968825323457]
	TIME [epoch: 9.64 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11934737829178732		[learning rate: 0.00014737]
	Learning Rate: 0.00014737
	LOSS [training: 0.11934737829178732 | validation: 0.1294238402226636]
	TIME [epoch: 9.64 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11352172826852522		[learning rate: 0.00014702]
	Learning Rate: 0.000147023
	LOSS [training: 0.11352172826852522 | validation: 0.12641277833671805]
	TIME [epoch: 9.65 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11084214864058055		[learning rate: 0.00014668]
	Learning Rate: 0.000146676
	LOSS [training: 0.11084214864058055 | validation: 0.14143780798711472]
	TIME [epoch: 9.64 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11153783065475756		[learning rate: 0.00014633]
	Learning Rate: 0.00014633
	LOSS [training: 0.11153783065475756 | validation: 0.12155380341504377]
	TIME [epoch: 9.63 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11540041231845918		[learning rate: 0.00014598]
	Learning Rate: 0.000145985
	LOSS [training: 0.11540041231845918 | validation: 0.12467174127879554]
	TIME [epoch: 9.64 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11454991862617807		[learning rate: 0.00014564]
	Learning Rate: 0.00014564
	LOSS [training: 0.11454991862617807 | validation: 0.13963286699140975]
	TIME [epoch: 9.65 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11578818743326294		[learning rate: 0.0001453]
	Learning Rate: 0.000145297
	LOSS [training: 0.11578818743326294 | validation: 0.12930062825546393]
	TIME [epoch: 9.64 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11306639011940349		[learning rate: 0.00014495]
	Learning Rate: 0.000144954
	LOSS [training: 0.11306639011940349 | validation: 0.14032627995255276]
	TIME [epoch: 9.64 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10889994501211198		[learning rate: 0.00014461]
	Learning Rate: 0.000144612
	LOSS [training: 0.10889994501211198 | validation: 0.14265665627010454]
	TIME [epoch: 9.66 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11292621850822977		[learning rate: 0.00014427]
	Learning Rate: 0.000144271
	LOSS [training: 0.11292621850822977 | validation: 0.13859572620056054]
	TIME [epoch: 9.64 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11164514761138186		[learning rate: 0.00014393]
	Learning Rate: 0.000143931
	LOSS [training: 0.11164514761138186 | validation: 0.13126595467008959]
	TIME [epoch: 9.64 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10976597718795975		[learning rate: 0.00014359]
	Learning Rate: 0.000143591
	LOSS [training: 0.10976597718795975 | validation: 0.13200107619462645]
	TIME [epoch: 9.65 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11157863751201927		[learning rate: 0.00014325]
	Learning Rate: 0.000143253
	LOSS [training: 0.11157863751201927 | validation: 0.13921379497515923]
	TIME [epoch: 9.64 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10529987396455198		[learning rate: 0.00014291]
	Learning Rate: 0.000142915
	LOSS [training: 0.10529987396455198 | validation: 0.13478259737973655]
	TIME [epoch: 9.64 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11525935619031313		[learning rate: 0.00014258]
	Learning Rate: 0.000142578
	LOSS [training: 0.11525935619031313 | validation: 0.14518068415979474]
	TIME [epoch: 9.64 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11199913135568935		[learning rate: 0.00014224]
	Learning Rate: 0.000142241
	LOSS [training: 0.11199913135568935 | validation: 0.13290190663338375]
	TIME [epoch: 9.66 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10999741496506552		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.10999741496506552 | validation: 0.12932500445972275]
	TIME [epoch: 9.63 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11006280300320101		[learning rate: 0.00014157]
	Learning Rate: 0.000141571
	LOSS [training: 0.11006280300320101 | validation: 0.13034503114428242]
	TIME [epoch: 9.64 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10989450474993082		[learning rate: 0.00014124]
	Learning Rate: 0.000141237
	LOSS [training: 0.10989450474993082 | validation: 0.11563297172443529]
	TIME [epoch: 9.65 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11080597631976614		[learning rate: 0.0001409]
	Learning Rate: 0.000140904
	LOSS [training: 0.11080597631976614 | validation: 0.11563151292710667]
	TIME [epoch: 9.64 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10630134747371593		[learning rate: 0.00014057]
	Learning Rate: 0.000140572
	LOSS [training: 0.10630134747371593 | validation: 0.13561045071108155]
	TIME [epoch: 9.64 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1118128973535197		[learning rate: 0.00014024]
	Learning Rate: 0.00014024
	LOSS [training: 0.1118128973535197 | validation: 0.1260775207028296]
	TIME [epoch: 9.64 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10901719694645873		[learning rate: 0.00013991]
	Learning Rate: 0.000139909
	LOSS [training: 0.10901719694645873 | validation: 0.11331246406582743]
	TIME [epoch: 9.65 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10941202694511054		[learning rate: 0.00013958]
	Learning Rate: 0.000139579
	LOSS [training: 0.10941202694511054 | validation: 0.1370801162605323]
	TIME [epoch: 9.64 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11072071687958163		[learning rate: 0.00013925]
	Learning Rate: 0.00013925
	LOSS [training: 0.11072071687958163 | validation: 0.15081127034768346]
	TIME [epoch: 9.64 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11757149077856155		[learning rate: 0.00013892]
	Learning Rate: 0.000138921
	LOSS [training: 0.11757149077856155 | validation: 0.12997093903526405]
	TIME [epoch: 9.66 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10137013193155349		[learning rate: 0.00013859]
	Learning Rate: 0.000138594
	LOSS [training: 0.10137013193155349 | validation: 0.11961274628736514]
	TIME [epoch: 9.64 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11213210257368518		[learning rate: 0.00013827]
	Learning Rate: 0.000138267
	LOSS [training: 0.11213210257368518 | validation: 0.1292197067913419]
	TIME [epoch: 9.63 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10834847183802268		[learning rate: 0.00013794]
	Learning Rate: 0.000137941
	LOSS [training: 0.10834847183802268 | validation: 0.12631909969492766]
	TIME [epoch: 9.64 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10634063587870783		[learning rate: 0.00013762]
	Learning Rate: 0.000137615
	LOSS [training: 0.10634063587870783 | validation: 0.13232009904228598]
	TIME [epoch: 9.65 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10739821485388415		[learning rate: 0.00013729]
	Learning Rate: 0.000137291
	LOSS [training: 0.10739821485388415 | validation: 0.13300217243471893]
	TIME [epoch: 9.64 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10414272696178792		[learning rate: 0.00013697]
	Learning Rate: 0.000136967
	LOSS [training: 0.10414272696178792 | validation: 0.13768132670086128]
	TIME [epoch: 9.64 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11000662464016922		[learning rate: 0.00013664]
	Learning Rate: 0.000136644
	LOSS [training: 0.11000662464016922 | validation: 0.1465551108158111]
	TIME [epoch: 9.65 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11212639923914813		[learning rate: 0.00013632]
	Learning Rate: 0.000136321
	LOSS [training: 0.11212639923914813 | validation: 0.135942673753976]
	TIME [epoch: 9.64 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11104683878528429		[learning rate: 0.000136]
	Learning Rate: 0.000136
	LOSS [training: 0.11104683878528429 | validation: 0.13262454369829801]
	TIME [epoch: 9.64 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10983131096421488		[learning rate: 0.00013568]
	Learning Rate: 0.000135679
	LOSS [training: 0.10983131096421488 | validation: 0.1327957027823638]
	TIME [epoch: 9.65 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1074543987551972		[learning rate: 0.00013536]
	Learning Rate: 0.000135359
	LOSS [training: 0.1074543987551972 | validation: 0.15720201671957906]
	TIME [epoch: 9.65 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11808441093001099		[learning rate: 0.00013504]
	Learning Rate: 0.00013504
	LOSS [training: 0.11808441093001099 | validation: 0.12880654822415907]
	TIME [epoch: 9.64 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1187814952505227		[learning rate: 0.00013472]
	Learning Rate: 0.000134721
	LOSS [training: 0.1187814952505227 | validation: 0.12901121260966675]
	TIME [epoch: 9.63 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10257268896096387		[learning rate: 0.0001344]
	Learning Rate: 0.000134403
	LOSS [training: 0.10257268896096387 | validation: 0.1143917449221039]
	TIME [epoch: 9.66 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1119456507281014		[learning rate: 0.00013409]
	Learning Rate: 0.000134086
	LOSS [training: 0.1119456507281014 | validation: 0.14670683257341025]
	TIME [epoch: 9.64 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11489822766721951		[learning rate: 0.00013377]
	Learning Rate: 0.00013377
	LOSS [training: 0.11489822766721951 | validation: 0.1299076036477653]
	TIME [epoch: 9.64 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11373882150953352		[learning rate: 0.00013345]
	Learning Rate: 0.000133455
	LOSS [training: 0.11373882150953352 | validation: 0.11439899337793666]
	TIME [epoch: 9.66 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10641576655873171		[learning rate: 0.00013314]
	Learning Rate: 0.00013314
	LOSS [training: 0.10641576655873171 | validation: 0.11395569158625281]
	TIME [epoch: 9.64 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10886580106482291		[learning rate: 0.00013283]
	Learning Rate: 0.000132826
	LOSS [training: 0.10886580106482291 | validation: 0.13506581223046393]
	TIME [epoch: 9.63 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10829654878928467		[learning rate: 0.00013251]
	Learning Rate: 0.000132512
	LOSS [training: 0.10829654878928467 | validation: 0.12934033211444482]
	TIME [epoch: 9.64 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11020545624955655		[learning rate: 0.0001322]
	Learning Rate: 0.0001322
	LOSS [training: 0.11020545624955655 | validation: 0.12356612947813427]
	TIME [epoch: 9.66 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10837781475985706		[learning rate: 0.00013189]
	Learning Rate: 0.000131888
	LOSS [training: 0.10837781475985706 | validation: 0.14382620848231725]
	TIME [epoch: 9.64 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11588544410840329		[learning rate: 0.00013158]
	Learning Rate: 0.000131577
	LOSS [training: 0.11588544410840329 | validation: 0.14847858642999814]
	TIME [epoch: 9.64 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12094739491283843		[learning rate: 0.00013127]
	Learning Rate: 0.000131266
	LOSS [training: 0.12094739491283843 | validation: 0.15942574468559131]
	TIME [epoch: 9.66 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11745411042610994		[learning rate: 0.00013096]
	Learning Rate: 0.000130957
	LOSS [training: 0.11745411042610994 | validation: 0.1416645078593528]
	TIME [epoch: 9.64 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11494916655665306		[learning rate: 0.00013065]
	Learning Rate: 0.000130648
	LOSS [training: 0.11494916655665306 | validation: 0.1413786859168137]
	TIME [epoch: 9.63 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11282913244823792		[learning rate: 0.00013034]
	Learning Rate: 0.00013034
	LOSS [training: 0.11282913244823792 | validation: 0.13490873112309257]
	TIME [epoch: 9.64 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11079653728213082		[learning rate: 0.00013003]
	Learning Rate: 0.000130032
	LOSS [training: 0.11079653728213082 | validation: 0.1295488650402693]
	TIME [epoch: 9.66 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11746707501705637		[learning rate: 0.00012973]
	Learning Rate: 0.000129726
	LOSS [training: 0.11746707501705637 | validation: 0.12552837307229994]
	TIME [epoch: 9.63 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10743916727679792		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.10743916727679792 | validation: 0.137958746654737]
	TIME [epoch: 9.64 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1069744802697014		[learning rate: 0.00012911]
	Learning Rate: 0.000129114
	LOSS [training: 0.1069744802697014 | validation: 0.14430149219253913]
	TIME [epoch: 9.66 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11634373629412549		[learning rate: 0.00012881]
	Learning Rate: 0.00012881
	LOSS [training: 0.11634373629412549 | validation: 0.14368265073134154]
	TIME [epoch: 9.64 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11962633912177556		[learning rate: 0.00012851]
	Learning Rate: 0.000128506
	LOSS [training: 0.11962633912177556 | validation: 0.13411350532271718]
	TIME [epoch: 9.63 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11926199085157478		[learning rate: 0.0001282]
	Learning Rate: 0.000128203
	LOSS [training: 0.11926199085157478 | validation: 0.12856194627884057]
	TIME [epoch: 9.65 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10943133076071328		[learning rate: 0.0001279]
	Learning Rate: 0.0001279
	LOSS [training: 0.10943133076071328 | validation: 0.12522408781333183]
	TIME [epoch: 9.64 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11306313353867677		[learning rate: 0.0001276]
	Learning Rate: 0.000127599
	LOSS [training: 0.11306313353867677 | validation: 0.15221045754212556]
	TIME [epoch: 9.64 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1146638911548169		[learning rate: 0.0001273]
	Learning Rate: 0.000127298
	LOSS [training: 0.1146638911548169 | validation: 0.157984006221433]
	TIME [epoch: 9.64 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10644685077141243		[learning rate: 0.000127]
	Learning Rate: 0.000126997
	LOSS [training: 0.10644685077141243 | validation: 0.12107385258183347]
	TIME [epoch: 9.65 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10511095739759586		[learning rate: 0.0001267]
	Learning Rate: 0.000126698
	LOSS [training: 0.10511095739759586 | validation: 0.1310869202602283]
	TIME [epoch: 9.64 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10442428303131061		[learning rate: 0.0001264]
	Learning Rate: 0.000126399
	LOSS [training: 0.10442428303131061 | validation: 0.1243699265602249]
	TIME [epoch: 9.63 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09703088116822024		[learning rate: 0.0001261]
	Learning Rate: 0.000126101
	LOSS [training: 0.09703088116822024 | validation: 0.13595871376927376]
	TIME [epoch: 9.65 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10737636331701161		[learning rate: 0.0001258]
	Learning Rate: 0.000125803
	LOSS [training: 0.10737636331701161 | validation: 0.140450318319861]
	TIME [epoch: 9.64 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10641163530176238		[learning rate: 0.00012551]
	Learning Rate: 0.000125507
	LOSS [training: 0.10641163530176238 | validation: 0.13686285750118893]
	TIME [epoch: 9.63 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10868041558373687		[learning rate: 0.00012521]
	Learning Rate: 0.000125211
	LOSS [training: 0.10868041558373687 | validation: 0.12048339145308241]
	TIME [epoch: 9.64 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10274861337906512		[learning rate: 0.00012492]
	Learning Rate: 0.000124915
	LOSS [training: 0.10274861337906512 | validation: 0.1271732029671042]
	TIME [epoch: 9.66 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1057818913160407		[learning rate: 0.00012462]
	Learning Rate: 0.000124621
	LOSS [training: 0.1057818913160407 | validation: 0.12194326594964756]
	TIME [epoch: 9.64 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11910328874888462		[learning rate: 0.00012433]
	Learning Rate: 0.000124327
	LOSS [training: 0.11910328874888462 | validation: 0.12667647569881546]
	TIME [epoch: 9.64 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1104520162370117		[learning rate: 0.00012403]
	Learning Rate: 0.000124033
	LOSS [training: 0.1104520162370117 | validation: 0.12719310239261677]
	TIME [epoch: 9.66 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10995480916664233		[learning rate: 0.00012374]
	Learning Rate: 0.000123741
	LOSS [training: 0.10995480916664233 | validation: 0.13265797339906304]
	TIME [epoch: 9.64 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1004479451476086		[learning rate: 0.00012345]
	Learning Rate: 0.000123449
	LOSS [training: 0.1004479451476086 | validation: 0.13803732429732649]
	TIME [epoch: 9.64 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10889422332381109		[learning rate: 0.00012316]
	Learning Rate: 0.000123158
	LOSS [training: 0.10889422332381109 | validation: 0.12555660141347455]
	TIME [epoch: 9.64 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11501662485251274		[learning rate: 0.00012287]
	Learning Rate: 0.000122867
	LOSS [training: 0.11501662485251274 | validation: 0.13029348534264495]
	TIME [epoch: 9.65 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10958076468594272		[learning rate: 0.00012258]
	Learning Rate: 0.000122577
	LOSS [training: 0.10958076468594272 | validation: 0.1114287676441335]
	TIME [epoch: 9.64 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09806571817499544		[learning rate: 0.00012229]
	Learning Rate: 0.000122288
	LOSS [training: 0.09806571817499544 | validation: 0.15017873810764137]
	TIME [epoch: 9.64 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10963425609166011		[learning rate: 0.000122]
	Learning Rate: 0.000122
	LOSS [training: 0.10963425609166011 | validation: 0.12068324189888774]
	TIME [epoch: 9.66 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11360408838306595		[learning rate: 0.00012171]
	Learning Rate: 0.000121712
	LOSS [training: 0.11360408838306595 | validation: 0.12178113559529623]
	TIME [epoch: 9.64 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10747933026630507		[learning rate: 0.00012142]
	Learning Rate: 0.000121425
	LOSS [training: 0.10747933026630507 | validation: 0.11927116083339881]
	TIME [epoch: 9.64 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1094733030420891		[learning rate: 0.00012114]
	Learning Rate: 0.000121138
	LOSS [training: 0.1094733030420891 | validation: 0.13751318633896023]
	TIME [epoch: 9.65 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10950430145987704		[learning rate: 0.00012085]
	Learning Rate: 0.000120853
	LOSS [training: 0.10950430145987704 | validation: 0.13036941467853685]
	TIME [epoch: 9.64 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11054954786848895		[learning rate: 0.00012057]
	Learning Rate: 0.000120568
	LOSS [training: 0.11054954786848895 | validation: 0.14063387623373996]
	TIME [epoch: 9.64 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11012816847273077		[learning rate: 0.00012028]
	Learning Rate: 0.000120283
	LOSS [training: 0.11012816847273077 | validation: 0.12429394374274916]
	TIME [epoch: 9.64 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10928600092017116		[learning rate: 0.00012]
	Learning Rate: 0.00012
	LOSS [training: 0.10928600092017116 | validation: 0.12877253446786213]
	TIME [epoch: 9.68 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1071696809514088		[learning rate: 0.00011972]
	Learning Rate: 0.000119716
	LOSS [training: 0.1071696809514088 | validation: 0.1383620353282593]
	TIME [epoch: 9.64 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1062446995361074		[learning rate: 0.00011943]
	Learning Rate: 0.000119434
	LOSS [training: 0.1062446995361074 | validation: 0.1143393494274773]
	TIME [epoch: 9.64 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10654635703614442		[learning rate: 0.00011915]
	Learning Rate: 0.000119152
	LOSS [training: 0.10654635703614442 | validation: 0.1409660413202316]
	TIME [epoch: 9.66 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11001141689455726		[learning rate: 0.00011887]
	Learning Rate: 0.000118871
	LOSS [training: 0.11001141689455726 | validation: 0.1401308495334864]
	TIME [epoch: 9.64 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10937772466466196		[learning rate: 0.00011859]
	Learning Rate: 0.000118591
	LOSS [training: 0.10937772466466196 | validation: 0.13956202003456597]
	TIME [epoch: 9.64 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11613069490726217		[learning rate: 0.00011831]
	Learning Rate: 0.000118311
	LOSS [training: 0.11613069490726217 | validation: 0.1722527162528743]
	TIME [epoch: 9.65 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13032974650566098		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.13032974650566098 | validation: 0.14937819305564914]
	TIME [epoch: 9.66 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10860584104945248		[learning rate: 0.00011775]
	Learning Rate: 0.000117754
	LOSS [training: 0.10860584104945248 | validation: 0.1512598561190949]
	TIME [epoch: 9.64 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1104524970605812		[learning rate: 0.00011748]
	Learning Rate: 0.000117476
	LOSS [training: 0.1104524970605812 | validation: 0.12023011692188465]
	TIME [epoch: 9.64 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11443267713247748		[learning rate: 0.0001172]
	Learning Rate: 0.000117199
	LOSS [training: 0.11443267713247748 | validation: 0.13074707858909004]
	TIME [epoch: 9.66 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11545241001157554		[learning rate: 0.00011692]
	Learning Rate: 0.000116922
	LOSS [training: 0.11545241001157554 | validation: 0.15374362273908868]
	TIME [epoch: 9.64 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11681794795905678		[learning rate: 0.00011665]
	Learning Rate: 0.000116647
	LOSS [training: 0.11681794795905678 | validation: 0.13171570097478796]
	TIME [epoch: 9.63 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11517325698174756		[learning rate: 0.00011637]
	Learning Rate: 0.000116371
	LOSS [training: 0.11517325698174756 | validation: 0.1240534990908071]
	TIME [epoch: 9.65 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11165396119876558		[learning rate: 0.0001161]
	Learning Rate: 0.000116097
	LOSS [training: 0.11165396119876558 | validation: 0.1337662516543878]
	TIME [epoch: 9.65 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10351818702186125		[learning rate: 0.00011582]
	Learning Rate: 0.000115823
	LOSS [training: 0.10351818702186125 | validation: 0.14124141365555037]
	TIME [epoch: 9.64 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11473946339730992		[learning rate: 0.00011555]
	Learning Rate: 0.00011555
	LOSS [training: 0.11473946339730992 | validation: 0.12458707941982698]
	TIME [epoch: 9.64 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11215276584851597		[learning rate: 0.00011528]
	Learning Rate: 0.000115277
	LOSS [training: 0.11215276584851597 | validation: 0.12234417191562486]
	TIME [epoch: 9.66 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11512810878880837		[learning rate: 0.00011501]
	Learning Rate: 0.000115005
	LOSS [training: 0.11512810878880837 | validation: 0.1285829121938068]
	TIME [epoch: 9.64 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11408164346358678		[learning rate: 0.00011473]
	Learning Rate: 0.000114734
	LOSS [training: 0.11408164346358678 | validation: 0.12831448801766648]
	TIME [epoch: 9.64 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11453960418749354		[learning rate: 0.00011446]
	Learning Rate: 0.000114463
	LOSS [training: 0.11453960418749354 | validation: 0.12096922471768062]
	TIME [epoch: 9.65 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11643902020659694		[learning rate: 0.00011419]
	Learning Rate: 0.000114193
	LOSS [training: 0.11643902020659694 | validation: 0.1375312211407246]
	TIME [epoch: 9.64 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10755826322425306		[learning rate: 0.00011392]
	Learning Rate: 0.000113924
	LOSS [training: 0.10755826322425306 | validation: 0.1207416035667828]
	TIME [epoch: 9.64 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10065687122142544		[learning rate: 0.00011366]
	Learning Rate: 0.000113655
	LOSS [training: 0.10065687122142544 | validation: 0.1251409319694274]
	TIME [epoch: 9.64 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11234273033734218		[learning rate: 0.00011339]
	Learning Rate: 0.000113387
	LOSS [training: 0.11234273033734218 | validation: 0.13339114878206312]
	TIME [epoch: 9.66 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10835641578495447		[learning rate: 0.00011312]
	Learning Rate: 0.00011312
	LOSS [training: 0.10835641578495447 | validation: 0.12229001413443533]
	TIME [epoch: 9.64 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1026112686220672		[learning rate: 0.00011285]
	Learning Rate: 0.000112853
	LOSS [training: 0.1026112686220672 | validation: 0.12545200622880417]
	TIME [epoch: 9.64 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.108846192085186		[learning rate: 0.00011259]
	Learning Rate: 0.000112587
	LOSS [training: 0.108846192085186 | validation: 0.12212346240572043]
	TIME [epoch: 9.65 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1168216820111307		[learning rate: 0.00011232]
	Learning Rate: 0.000112321
	LOSS [training: 0.1168216820111307 | validation: 0.12133685275729994]
	TIME [epoch: 9.64 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11081656848014754		[learning rate: 0.00011206]
	Learning Rate: 0.000112056
	LOSS [training: 0.11081656848014754 | validation: 0.13129019632591146]
	TIME [epoch: 9.63 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11568626896511099		[learning rate: 0.00011179]
	Learning Rate: 0.000111792
	LOSS [training: 0.11568626896511099 | validation: 0.1380995445280824]
	TIME [epoch: 9.64 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11596875473051735		[learning rate: 0.00011153]
	Learning Rate: 0.000111528
	LOSS [training: 0.11596875473051735 | validation: 0.11658948460002484]
	TIME [epoch: 9.66 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10499021798123429		[learning rate: 0.00011127]
	Learning Rate: 0.000111265
	LOSS [training: 0.10499021798123429 | validation: 0.11314603930001557]
	TIME [epoch: 9.64 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1062192644761331		[learning rate: 0.000111]
	Learning Rate: 0.000111003
	LOSS [training: 0.1062192644761331 | validation: 0.12446564715135364]
	TIME [epoch: 9.63 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1042735786291971		[learning rate: 0.00011074]
	Learning Rate: 0.000110741
	LOSS [training: 0.1042735786291971 | validation: 0.1527922745559982]
	TIME [epoch: 9.66 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11748943525891915		[learning rate: 0.00011048]
	Learning Rate: 0.00011048
	LOSS [training: 0.11748943525891915 | validation: 0.15575393006419322]
	TIME [epoch: 9.64 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11402362159509458		[learning rate: 0.00011022]
	Learning Rate: 0.000110219
	LOSS [training: 0.11402362159509458 | validation: 0.13290245578804566]
	TIME [epoch: 9.64 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10950913789390035		[learning rate: 0.00010996]
	Learning Rate: 0.000109959
	LOSS [training: 0.10950913789390035 | validation: 0.11980071001586944]
	TIME [epoch: 9.66 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10779694610495386		[learning rate: 0.0001097]
	Learning Rate: 0.0001097
	LOSS [training: 0.10779694610495386 | validation: 0.13196346794485433]
	TIME [epoch: 9.65 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11210941377811053		[learning rate: 0.00010944]
	Learning Rate: 0.000109441
	LOSS [training: 0.11210941377811053 | validation: 0.12129986804851153]
	TIME [epoch: 9.65 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11214373148642516		[learning rate: 0.00010918]
	Learning Rate: 0.000109183
	LOSS [training: 0.11214373148642516 | validation: 0.1278173208158545]
	TIME [epoch: 9.64 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10907091845240957		[learning rate: 0.00010893]
	Learning Rate: 0.000108925
	LOSS [training: 0.10907091845240957 | validation: 0.12244438521845794]
	TIME [epoch: 9.67 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11206055808258389		[learning rate: 0.00010867]
	Learning Rate: 0.000108668
	LOSS [training: 0.11206055808258389 | validation: 0.12553285766365974]
	TIME [epoch: 9.64 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09811927897492068		[learning rate: 0.00010841]
	Learning Rate: 0.000108412
	LOSS [training: 0.09811927897492068 | validation: 0.1353333679399005]
	TIME [epoch: 9.64 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10757179155362376		[learning rate: 0.00010816]
	Learning Rate: 0.000108156
	LOSS [training: 0.10757179155362376 | validation: 0.1195940230375352]
	TIME [epoch: 9.66 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11146156511660943		[learning rate: 0.0001079]
	Learning Rate: 0.000107901
	LOSS [training: 0.11146156511660943 | validation: 0.14316416983547176]
	TIME [epoch: 9.65 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11455274807602445		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.11455274807602445 | validation: 0.14307938922556304]
	TIME [epoch: 9.65 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11291353041405591		[learning rate: 0.00010739]
	Learning Rate: 0.000107393
	LOSS [training: 0.11291353041405591 | validation: 0.1368932350045296]
	TIME [epoch: 9.64 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11144282331385094		[learning rate: 0.00010714]
	Learning Rate: 0.000107139
	LOSS [training: 0.11144282331385094 | validation: 0.11734696468703491]
	TIME [epoch: 9.67 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10836867074191256		[learning rate: 0.00010689]
	Learning Rate: 0.000106887
	LOSS [training: 0.10836867074191256 | validation: 0.14843221182514338]
	TIME [epoch: 9.65 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10783982960454679		[learning rate: 0.00010663]
	Learning Rate: 0.000106634
	LOSS [training: 0.10783982960454679 | validation: 0.1274389069415959]
	TIME [epoch: 9.65 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10912746168000723		[learning rate: 0.00010638]
	Learning Rate: 0.000106383
	LOSS [training: 0.10912746168000723 | validation: 0.11959692470480651]
	TIME [epoch: 9.66 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11640988784381716		[learning rate: 0.00010613]
	Learning Rate: 0.000106132
	LOSS [training: 0.11640988784381716 | validation: 0.1379908977683374]
	TIME [epoch: 9.64 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10875840805783343		[learning rate: 0.00010588]
	Learning Rate: 0.000105882
	LOSS [training: 0.10875840805783343 | validation: 0.11760576663911715]
	TIME [epoch: 9.64 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10759115600081441		[learning rate: 0.00010563]
	Learning Rate: 0.000105632
	LOSS [training: 0.10759115600081441 | validation: 0.12314749969838742]
	TIME [epoch: 9.65 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10778938208887354		[learning rate: 0.00010538]
	Learning Rate: 0.000105383
	LOSS [training: 0.10778938208887354 | validation: 0.12885975764459673]
	TIME [epoch: 9.66 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10622956488494469		[learning rate: 0.00010513]
	Learning Rate: 0.000105134
	LOSS [training: 0.10622956488494469 | validation: 0.12155246307971766]
	TIME [epoch: 9.64 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10985317781669464		[learning rate: 0.00010489]
	Learning Rate: 0.000104886
	LOSS [training: 0.10985317781669464 | validation: 0.1311541223572686]
	TIME [epoch: 9.65 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11452884953779532		[learning rate: 0.00010464]
	Learning Rate: 0.000104639
	LOSS [training: 0.11452884953779532 | validation: 0.13024943233868763]
	TIME [epoch: 9.66 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10796573964627429		[learning rate: 0.00010439]
	Learning Rate: 0.000104392
	LOSS [training: 0.10796573964627429 | validation: 0.12933231066464515]
	TIME [epoch: 9.65 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10972795842466596		[learning rate: 0.00010415]
	Learning Rate: 0.000104146
	LOSS [training: 0.10972795842466596 | validation: 0.13094815838209856]
	TIME [epoch: 9.64 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11376083307144884		[learning rate: 0.0001039]
	Learning Rate: 0.0001039
	LOSS [training: 0.11376083307144884 | validation: 0.13407453198477204]
	TIME [epoch: 9.66 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11110916170761653		[learning rate: 0.00010365]
	Learning Rate: 0.000103655
	LOSS [training: 0.11110916170761653 | validation: 0.13880299028895088]
	TIME [epoch: 9.65 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1146428371734548		[learning rate: 0.00010341]
	Learning Rate: 0.00010341
	LOSS [training: 0.1146428371734548 | validation: 0.13533378286164444]
	TIME [epoch: 9.64 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1136189476181646		[learning rate: 0.00010317]
	Learning Rate: 0.000103166
	LOSS [training: 0.1136189476181646 | validation: 0.12678730844172623]
	TIME [epoch: 9.64 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1137450121161427		[learning rate: 0.00010292]
	Learning Rate: 0.000102923
	LOSS [training: 0.1137450121161427 | validation: 0.11901294153956228]
	TIME [epoch: 9.66 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1059272932363394		[learning rate: 0.00010268]
	Learning Rate: 0.00010268
	LOSS [training: 0.1059272932363394 | validation: 0.12990163734186566]
	TIME [epoch: 9.64 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11038476350328925		[learning rate: 0.00010244]
	Learning Rate: 0.000102438
	LOSS [training: 0.11038476350328925 | validation: 0.14549924408802428]
	TIME [epoch: 9.64 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10983449625944261		[learning rate: 0.0001022]
	Learning Rate: 0.000102196
	LOSS [training: 0.10983449625944261 | validation: 0.1256504237506484]
	TIME [epoch: 9.66 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11224956084094348		[learning rate: 0.00010196]
	Learning Rate: 0.000101955
	LOSS [training: 0.11224956084094348 | validation: 0.14041102822686408]
	TIME [epoch: 9.64 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11746477915774751		[learning rate: 0.00010171]
	Learning Rate: 0.000101715
	LOSS [training: 0.11746477915774751 | validation: 0.12743160538451365]
	TIME [epoch: 9.64 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11428284783280533		[learning rate: 0.00010147]
	Learning Rate: 0.000101475
	LOSS [training: 0.11428284783280533 | validation: 0.14394473922407883]
	TIME [epoch: 9.64 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11010108144158573		[learning rate: 0.00010124]
	Learning Rate: 0.000101236
	LOSS [training: 0.11010108144158573 | validation: 0.1203710592499858]
	TIME [epoch: 9.66 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10551575458764159		[learning rate: 0.000101]
	Learning Rate: 0.000100997
	LOSS [training: 0.10551575458764159 | validation: 0.13757590542995346]
	TIME [epoch: 9.64 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10341901068514803		[learning rate: 0.00010076]
	Learning Rate: 0.000100759
	LOSS [training: 0.10341901068514803 | validation: 0.13245298736096775]
	TIME [epoch: 9.64 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10755370910219		[learning rate: 0.00010052]
	Learning Rate: 0.000100521
	LOSS [training: 0.10755370910219 | validation: 0.1423866291934599]
	TIME [epoch: 9.66 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11115584738705013		[learning rate: 0.00010028]
	Learning Rate: 0.000100284
	LOSS [training: 0.11115584738705013 | validation: 0.12024656564801378]
	TIME [epoch: 9.64 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1083026523953899		[learning rate: 0.00010005]
	Learning Rate: 0.000100047
	LOSS [training: 0.1083026523953899 | validation: 0.13481741048078857]
	TIME [epoch: 9.64 sec]
Finished training in 19481.517 seconds.
